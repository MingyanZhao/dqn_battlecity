INFO:root:enemies_left [0]
INFO:root:frame =0 recording current_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =1 recording current_observation no.1
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =2 recording current_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root:frame =3 recording current_observation no.3
DEBUG:root: save sample needs time = 0.00046181678772
INFO:root:frame =4current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =5 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427961349487
INFO:root:frame =6 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000612020492554
DEBUG:root: save sample needs time = 0.000136852264404
INFO:root:frame =8 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame =9 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =10 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049614906311
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =12 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =13 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000405073165894
INFO:root:frame =14 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000415086746216
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =16 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:frame =17 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =18 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.999968333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =20 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =21 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =22 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.999936666667
DEBUG:root: dqn, choose action rondomly, need time 0.000244
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =24 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =25 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =26 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.999905
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =28 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =29 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =30 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000451803207397
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.999873333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =32 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =33 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =34 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000373125076294
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:random_action_porb = 0.999841666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =36 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =37 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000723123550415
INFO:root:frame =38 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504970550537
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:random_action_porb = 0.99981
DEBUG:root: dqn, choose action rondomly, need time 0.000293
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =40 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000491142272949
INFO:root:frame =41 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471830368042
INFO:root:frame =42 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame = 43 State into memory, numbers recorded 1 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000529050827026
INFO:root:random_action_porb = 0.999778333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =44current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame =45 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000451803207397
INFO:root:frame =46 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.999746666667
DEBUG:root: dqn, choose action rondomly, need time 0.000218
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =48 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:frame =49 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =50 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000601053237915
INFO:root:frame = 51 State into memory, numbers recorded 2 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.00055718421936
INFO:root:random_action_porb = 0.999715
DEBUG:root: dqn, choose action rondomly, need time 0.000293
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =52current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame =53 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000616073608398
INFO:root:frame =54 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000410795211792
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:random_action_porb = 0.999683333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =56 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =57 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000428199768066
INFO:root:frame =58 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438213348389
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.999651666667
DEBUG:root: dqn, choose action rondomly, need time 0.00044
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =60 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =61 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =62 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.99962
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =64 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000694036483765
INFO:root:frame =65 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000596046447754
INFO:root: ememy has been killed for 1 times 
INFO:root:enemies_left [0]
INFO:root:frame =66 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000359058380127
INFO:root:frame = 67 State into memory, numbers recorded 3 action = 3, reward = 1
DEBUG:root: save sample needs time = 0.00056791305542
INFO:root:random_action_porb = 0.999588333333
DEBUG:root: dqn, choose action rondomly, need time 0.000638
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =68current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =69 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00036096572876
INFO:root:frame =70 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.999556666667
DEBUG:root: dqn, choose action rondomly, need time 0.000541
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =72 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =73 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =74 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame = 75 State into memory, numbers recorded 4 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.00058388710022
INFO:root:random_action_porb = 0.999525
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =76current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =77 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456809997559
INFO:root:frame =78 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000360012054443
DEBUG:root: save sample needs time = 0.000137805938721
INFO:root:random_action_porb = 0.999493333333
DEBUG:root: dqn, choose action rondomly, need time 0.000395
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =80 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =81 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000425815582275
INFO:root:frame =82 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000261068344116
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.999461666667
DEBUG:root: dqn, choose action rondomly, need time 0.000409
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =84 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =85 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =86 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.99943
DEBUG:root: dqn, choose action rondomly, need time 0.000383
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =88 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root:frame =89 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00041389465332
INFO:root:frame =90 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000418901443481
INFO:root:frame = 91 State into memory, numbers recorded 5 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000521898269653
INFO:root:random_action_porb = 0.999398333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =92current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =93 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =94 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000560998916626
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.999366666667
DEBUG:root: dqn, choose action rondomly, need time 0.000204
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =96 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root:frame =97 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =98 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000246047973633
DEBUG:root: save sample needs time = 0.000105142593384
INFO:root:random_action_porb = 0.999335
DEBUG:root: dqn, choose action rondomly, need time 0.000168
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:frame =101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame = 103 State into memory, numbers recorded 6 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000572919845581
INFO:root:random_action_porb = 0.999303333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =104current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.999271666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame = 111 State into memory, numbers recorded 7 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00054407119751
INFO:root:random_action_porb = 0.99924
DEBUG:root: dqn, choose action rondomly, need time 0.000272
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =112current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:frame =113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000410079956055
INFO:root:frame =114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.999208333333
DEBUG:root: dqn, choose action rondomly, need time 0.000278
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000107049942017
INFO:root:random_action_porb = 0.999176666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000136852264404
INFO:root:random_action_porb = 0.999145
DEBUG:root: dqn, choose action rondomly, need time 0.0002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000381946563721
INFO:root:frame =125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame = 127 State into memory, numbers recorded 8 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:random_action_porb = 0.999113333333
DEBUG:root: dqn, choose action rondomly, need time 0.000375
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =128current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000178098678589
INFO:root:random_action_porb = 0.999081666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.99905
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000367164611816
INFO:root:frame =137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.999018333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000535011291504
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.998986666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330209732056
INFO:root:frame =145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000495910644531
INFO:root:frame =146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.998955
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.998923333333
DEBUG:root: dqn, choose action rondomly, need time 0.000351
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000474214553833
INFO:root:frame =154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.998891666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000699043273926
INFO:root:frame =158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
DEBUG:root: save sample needs time = 0.000140190124512
INFO:root:random_action_porb = 0.99886
DEBUG:root: dqn, choose action rondomly, need time 0.000198
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:frame =161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:frame =162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000110864639282
INFO:root:random_action_porb = 0.998828333333
DEBUG:root: dqn, choose action rondomly, need time 0.000226
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:frame =166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000320911407471
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root:random_action_porb = 0.998796666667
DEBUG:root: dqn, choose action rondomly, need time 0.00022
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:frame =169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:random_action_porb = 0.998765
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000296115875244
DEBUG:root: save sample needs time = 0.000134944915771
INFO:root:random_action_porb = 0.998733333333
DEBUG:root: dqn, choose action rondomly, need time 0.000398
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.998701666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:frame =181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00148797035217
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.99867
DEBUG:root: dqn, choose action rondomly, need time 0.000311
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298976898193
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.998638333333
DEBUG:root: dqn, choose action rondomly, need time 0.000164
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:frame =189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame =190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame = 191 State into memory, numbers recorded 9 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:random_action_porb = 0.998606666667
DEBUG:root: dqn, choose action rondomly, need time 0.000219
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =192current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247001647949
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.998575
DEBUG:root: dqn, choose action rondomly, need time 0.000199
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000243186950684
INFO:root:frame =197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000221967697144
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.998543333333
DEBUG:root: dqn, choose action rondomly, need time 0.000386
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000166893005371
INFO:root:frame =201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247001647949
DEBUG:root: save sample needs time = 0.000136137008667
INFO:root:random_action_porb = 0.998511666667
DEBUG:root: dqn, choose action rondomly, need time 0.0002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:frame =205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000392913818359
INFO:root:frame =206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00022292137146
DEBUG:root: save sample needs time = 0.000182867050171
INFO:root:random_action_porb = 0.99848
DEBUG:root: dqn, choose action rondomly, need time 0.000256
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root:frame =209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:frame =210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.998448333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:frame =213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000359058380127
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:random_action_porb = 0.998416666667
DEBUG:root: dqn, choose action rondomly, need time 0.000316
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:frame =217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:frame =218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000292062759399
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:random_action_porb = 0.998385
DEBUG:root: dqn, choose action rondomly, need time 0.000198
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000341176986694
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:random_action_porb = 0.998353333333
DEBUG:root: dqn, choose action rondomly, need time 0.000164
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000424861907959
INFO:root:frame =226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000373840332031
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.998321666667
DEBUG:root: dqn, choose action rondomly, need time 0.000213
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235080718994
DEBUG:root: save sample needs time = 0.000107049942017
INFO:root:random_action_porb = 0.99829
DEBUG:root: dqn, choose action rondomly, need time 0.000223
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root:frame =233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000332832336426
INFO:root:frame =234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031590461731
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.998258333333
DEBUG:root: dqn, choose action rondomly, need time 0.000179
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:frame =237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000310897827148
DEBUG:root: save sample needs time = 0.000126838684082
INFO:root:random_action_porb = 0.998226666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000424861907959
INFO:root:frame =242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame = 243 State into memory, numbers recorded 10 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000569820404053
INFO:root:random_action_porb = 0.998195
DEBUG:root: dqn, choose action rondomly, need time 0.000315
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =244current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root:frame =245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000568866729736
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.998163333333
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000520944595337
INFO:root:frame =249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000416994094849
INFO:root:frame =250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.998131666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame =254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000396013259888
INFO:root:frame = 255 State into memory, numbers recorded 11 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000559091567993
INFO:root:random_action_porb = 0.9981
DEBUG:root: dqn, choose action rondomly, need time 0.000155
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =256current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000140190124512
INFO:root:frame =257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.998068333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355958938599
INFO:root:frame =261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000331163406372
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:random_action_porb = 0.998036666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000407934188843
INFO:root:frame =265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000369071960449
INFO:root:frame =266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000416994094849
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.998005
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000509023666382
INFO:root:frame =269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000594854354858
INFO:root:frame =270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.997973333333
DEBUG:root: dqn, choose action rondomly, need time 0.000342
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000424861907959
INFO:root:frame =273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000187873840332
INFO:root:random_action_porb = 0.997941666667
DEBUG:root: dqn, choose action rondomly, need time 0.000466
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000555992126465
INFO:root:frame =278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000276803970337
INFO:root:random_action_porb = 0.99791
DEBUG:root: dqn, choose action rondomly, need time 0.000316
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424146652222
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:random_action_porb = 0.997878333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454187393188
INFO:root:frame =286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:random_action_porb = 0.997846666667
DEBUG:root: dqn, choose action rondomly, need time 0.00016
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:frame =289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000638008117676
INFO:root:frame =290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.997815
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000524044036865
INFO:root:frame =294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.997783333333
DEBUG:root: dqn, choose action rondomly, need time 0.000268
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000360012054443
INFO:root:frame =298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.997751666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000566005706787
INFO:root:frame =302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000564098358154
DEBUG:root: save sample needs time = 0.000243186950684
INFO:root:random_action_porb = 0.99772
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame =306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:random_action_porb = 0.997688333333
DEBUG:root: dqn, choose action rondomly, need time 0.000245
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000404119491577
INFO:root:frame =310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227928161621
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.997656666667
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000529050827026
INFO:root:frame =314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame = 315 State into memory, numbers recorded 12 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000552892684937
INFO:root:random_action_porb = 0.997625
DEBUG:root: dqn, choose action rondomly, need time 0.000207
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =316current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:frame =317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000569820404053
INFO:root:frame =318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:random_action_porb = 0.997593333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338792800903
INFO:root:frame =321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000569105148315
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:random_action_porb = 0.997561666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000602006912231
INFO:root:frame =326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000299215316772
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.99753
DEBUG:root: dqn, choose action rondomly, need time 0.000213
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000487089157104
INFO:root:frame =330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.997498333333
DEBUG:root: dqn, choose action rondomly, need time 0.000612
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042200088501
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.997466666667
DEBUG:root: dqn, choose action rondomly, need time 0.000548
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031304359436
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.997435
DEBUG:root: dqn, choose action rondomly, need time 0.000534
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root:frame =342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00055718421936
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:random_action_porb = 0.997403333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294208526611
INFO:root:frame =345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00058913230896
INFO:root:frame =346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:random_action_porb = 0.997371666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.99734
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:random_action_porb = 0.997308333333
DEBUG:root: dqn, choose action rondomly, need time 0.000274
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00060510635376
INFO:root:frame =358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000530004501343
INFO:root:frame = 359 State into memory, numbers recorded 13 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000609159469604
INFO:root:random_action_porb = 0.997276666667
DEBUG:root: dqn, choose action rondomly, need time 0.000264
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =360current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000476121902466
INFO:root:frame =362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000615119934082
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.997245
DEBUG:root: dqn, choose action rondomly, need time 0.000155
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:frame =365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491142272949
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.997213333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000571966171265
INFO:root:frame =370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:random_action_porb = 0.997181666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.99715
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000384092330933
INFO:root:frame =377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.997118333333
DEBUG:root: dqn, choose action rondomly, need time 0.000499
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000403881072998
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.997086666667
DEBUG:root: dqn, choose action rondomly, need time 0.00031
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239133834839
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:random_action_porb = 0.997055
DEBUG:root: dqn, choose action rondomly, need time 0.000211
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:frame =390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.997023333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:frame =394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.996991666667
DEBUG:root: dqn, choose action rondomly, need time 0.000167
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root:frame =397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294923782349
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.99696
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000316858291626
DEBUG:root: save sample needs time = 0.00015115737915
INFO:root:random_action_porb = 0.996928333333
DEBUG:root: dqn, choose action rondomly, need time 0.000184
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000151872634888
INFO:root:frame =405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.996896666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000480175018311
INFO:root:frame =410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000499963760376
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.996865
DEBUG:root: dqn, choose action rondomly, need time 0.000292
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472784042358
INFO:root:frame =414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.996833333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.996801666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488042831421
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.99677
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000420808792114
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.996738333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.996706666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000659942626953
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.996675
DEBUG:root: dqn, choose action rondomly, need time 0.000274
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:random_action_porb = 0.996643333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433206558228
INFO:root:frame =442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:random_action_porb = 0.996611666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:random_action_porb = 0.99658
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000359058380127
INFO:root:frame =450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.996548333333
DEBUG:root: dqn, choose action rondomly, need time 0.000273
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000369071960449
INFO:root:frame =453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:random_action_porb = 0.996516666667
DEBUG:root: dqn, choose action rondomly, need time 0.000219
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000419855117798
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.996485
DEBUG:root: dqn, choose action rondomly, need time 0.000344
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000475168228149
INFO:root:frame =462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:random_action_porb = 0.996453333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root:frame =466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.996421666667
DEBUG:root: dqn, choose action rondomly, need time 0.000312
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000348806381226
DEBUG:root: save sample needs time = 0.000104188919067
INFO:root:random_action_porb = 0.99639
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000643968582153
INFO:root:frame =474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431776046753
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.996358333333
DEBUG:root: dqn, choose action rondomly, need time 0.000552
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285148620605
INFO:root:frame =478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000526905059814
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.996326666667
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342845916748
INFO:root:frame =481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame =482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.996295
DEBUG:root: dqn, choose action rondomly, need time 0.000366
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000115871429443
INFO:root:random_action_porb = 0.996263333333
DEBUG:root: dqn, choose action rondomly, need time 0.000358
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000411033630371
INFO:root:frame =490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.996231666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9962
DEBUG:root: dqn, choose action rondomly, need time 0.0003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root:frame =497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.996168333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root:frame =501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000476121902466
INFO:root:frame =502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000545978546143
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.996136666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000519990921021
INFO:root:frame = 507 State into memory, numbers recorded 14 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000566005706787
INFO:root:random_action_porb = 0.996105
DEBUG:root: dqn, choose action rondomly, need time 0.000377
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =508current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000337839126587
INFO:root:frame =509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000352144241333
INFO:root:frame = 511 State into memory, numbers recorded 15 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:random_action_porb = 0.996073333333
DEBUG:root: dqn, choose action rondomly, need time 0.000275
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =512current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.996041666667
DEBUG:root: dqn, choose action rondomly, need time 0.000456
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000425100326538
INFO:root:frame =518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.99601
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame =522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.995978333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476837158203
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.995946666667
DEBUG:root: dqn, choose action rondomly, need time 0.000173
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000177145004272
INFO:root:frame =529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:frame =530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.995915
DEBUG:root: dqn, choose action rondomly, need time 0.00031
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000416994094849
INFO:root:frame =534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042986869812
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.995883333333
DEBUG:root: dqn, choose action rondomly, need time 0.000182
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000141859054565
INFO:root:frame =537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000243902206421
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.995851666667
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000341892242432
INFO:root:frame =541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000214099884033
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.99582
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000530004501343
INFO:root:frame =546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame = 547 State into memory, numbers recorded 16 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.00056004524231
INFO:root:random_action_porb = 0.995788333333
DEBUG:root: dqn, choose action rondomly, need time 0.0003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =548current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000524997711182
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.995756666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root:frame =553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000501871109009
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.995725
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00036096572876
INFO:root:frame =557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000405073165894
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.995693333333
DEBUG:root: dqn, choose action rondomly, need time 0.000338
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.995661666667
DEBUG:root: dqn, choose action rondomly, need time 0.000173
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:frame =565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000501155853271
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.99563
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.995598333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470876693726
INFO:root:frame =574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000557899475098
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.995566666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000484943389893
INFO:root:frame =578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476121902466
DEBUG:root: save sample needs time = 0.000266790390015
INFO:root:random_action_porb = 0.995535
DEBUG:root: dqn, choose action rondomly, need time 0.00045
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000367879867554
INFO:root:frame =581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.995503333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000574827194214
INFO:root:frame =586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame = 587 State into memory, numbers recorded 17 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000581979751587
INFO:root:random_action_porb = 0.995471666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =588current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000424861907959
INFO:root:frame =590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411987304688
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:random_action_porb = 0.99544
DEBUG:root: dqn, choose action rondomly, need time 0.000286
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00051212310791
INFO:root:frame =594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044322013855
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.995408333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000753164291382
INFO:root:frame =598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042986869812
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.995376666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000451803207397
INFO:root:frame =602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000649929046631
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.995345
DEBUG:root: dqn, choose action rondomly, need time 0.000316000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:random_action_porb = 0.995313333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000422954559326
INFO:root:frame =610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430822372437
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.995281666667
DEBUG:root: dqn, choose action rondomly, need time 0.000538
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234842300415
DEBUG:root: save sample needs time = 0.000194072723389
INFO:root:random_action_porb = 0.99525
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root:frame =618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.995218333333
DEBUG:root: dqn, choose action rondomly, need time 0.000359
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame =622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000199794769287
INFO:root:random_action_porb = 0.995186666667
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.995155
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.995123333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:random_action_porb = 0.995091666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000634908676147
INFO:root:frame =638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231981277466
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:random_action_porb = 0.99506
DEBUG:root: dqn, choose action rondomly, need time 0.000526
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:random_action_porb = 0.995028333333
DEBUG:root: dqn, choose action rondomly, need time 0.000342
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000514984130859
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.994996666667
DEBUG:root: dqn, choose action rondomly, need time 0.000481
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428199768066
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.994965
DEBUG:root: dqn, choose action rondomly, need time 0.000313
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00236082077026
INFO:root:frame =653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000428915023804
INFO:root:frame =654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476121902466
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.994933333333
DEBUG:root: dqn, choose action rondomly, need time 0.000197999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:frame =657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476837158203
DEBUG:root: save sample needs time = 0.000171184539795
INFO:root:random_action_porb = 0.994901666667
DEBUG:root: dqn, choose action rondomly, need time 0.000319
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000810861587524
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.99487
DEBUG:root: dqn, choose action rondomly, need time 0.000426
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame = 667 State into memory, numbers recorded 18 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000549077987671
INFO:root:random_action_porb = 0.994838333333
DEBUG:root: dqn, choose action rondomly, need time 0.000209
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =668current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 9.51290130615e-05
INFO:root:random_action_porb = 0.994806666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000429153442383
INFO:root:frame =674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.994775
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.994743333333
DEBUG:root: dqn, choose action rondomly, need time 0.000279
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000411033630371
INFO:root:frame =682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000103950500488
INFO:root:random_action_porb = 0.994711666667
DEBUG:root: dqn, choose action rondomly, need time 0.000162
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000156164169312
INFO:root:frame =685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427961349487
INFO:root:frame =686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.99468
DEBUG:root: dqn, choose action rondomly, need time 0.000286
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000393867492676
INFO:root:frame =689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000330924987793
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.994648333333
DEBUG:root: dqn, choose action rondomly, need time 0.000280999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.994616666667
DEBUG:root: dqn, choose action rondomly, need time 0.000280999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000337839126587
INFO:root:frame =697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.994585
DEBUG:root: dqn, choose action rondomly, need time 0.000278
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:random_action_porb = 0.994553333333
DEBUG:root: dqn, choose action rondomly, need time 0.00031
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00061297416687
INFO:root:frame =706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.994521666667
DEBUG:root: dqn, choose action rondomly, need time 0.0003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.99449
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436782836914
INFO:root:frame =714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:random_action_porb = 0.994458333333
DEBUG:root: dqn, choose action rondomly, need time 0.0003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000563144683838
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:random_action_porb = 0.994426666667
DEBUG:root: dqn, choose action rondomly, need time 0.000247
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000209093093872
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.994395
DEBUG:root: dqn, choose action rondomly, need time 0.000323
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000519037246704
INFO:root:frame =726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000511884689331
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:random_action_porb = 0.994363333333
DEBUG:root: dqn, choose action rondomly, need time 0.000275
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000380992889404
INFO:root:frame =730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000510931015015
DEBUG:root: save sample needs time = 0.000173091888428
INFO:root:random_action_porb = 0.994331666667
DEBUG:root: dqn, choose action rondomly, need time 0.000539
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000375032424927
INFO:root:frame =733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00050687789917
INFO:root:frame =734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00037407875061
INFO:root:frame = 735 State into memory, numbers recorded 19 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.00062084197998
INFO:root:random_action_porb = 0.9943
DEBUG:root: dqn, choose action rondomly, need time 0.000555
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =736current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000384092330933
INFO:root:frame =737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049090385437
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:random_action_porb = 0.994268333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000217914581299
DEBUG:root: save sample needs time = 0.000115156173706
INFO:root:random_action_porb = 0.994236666667
DEBUG:root: dqn, choose action rondomly, need time 0.000168
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000388860702515
INFO:root:frame =745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471115112305
INFO:root:frame =746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.994205
DEBUG:root: dqn, choose action rondomly, need time 0.000487
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:random_action_porb = 0.994173333333
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294208526611
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.994141666667
DEBUG:root: dqn, choose action rondomly, need time 0.000271
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000385999679565
INFO:root:frame =758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000520944595337
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.99411
DEBUG:root: dqn, choose action rondomly, need time 0.000274
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000425100326538
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.994078333333
DEBUG:root: dqn, choose action rondomly, need time 0.000478999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000373125076294
INFO:root:frame =765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:random_action_porb = 0.994046666667
DEBUG:root: dqn, choose action rondomly, need time 0.000266
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:frame =770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:random_action_porb = 0.994015
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.993983333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:random_action_porb = 0.993951666667
DEBUG:root: dqn, choose action rondomly, need time 0.000278
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.99392
DEBUG:root: dqn, choose action rondomly, need time 0.000189
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame = 787 State into memory, numbers recorded 20 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:random_action_porb = 0.993888333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =788current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000328063964844
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.993856666667
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:frame =793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:random_action_porb = 0.993825
DEBUG:root: dqn, choose action rondomly, need time 0.000305
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000363111495972
INFO:root:frame =797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.993793333333
DEBUG:root: dqn, choose action rondomly, need time 0.000357999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000280141830444
INFO:root:frame =801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000360012054443
INFO:root:frame =802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.993761666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000530004501343
INFO:root:frame =806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000358819961548
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.99373
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000223159790039
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.993698333333
DEBUG:root: dqn, choose action rondomly, need time 0.000151
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:frame =813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265836715698
INFO:root:frame =814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.993666666667
DEBUG:root: dqn, choose action rondomly, need time 0.000174
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000178098678589
INFO:root:frame =817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000530958175659
INFO:root:frame =818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000627994537354
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.993635
DEBUG:root: dqn, choose action rondomly, need time 0.000291
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320196151733
INFO:root:frame =821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root:frame =822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.993603333333
DEBUG:root: dqn, choose action rondomly, need time 0.000245
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000396013259888
INFO:root:frame =826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000537157058716
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:random_action_porb = 0.993571666667
DEBUG:root: dqn, choose action rondomly, need time 0.000478999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root:frame =829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000282049179077
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.99354
DEBUG:root: dqn, choose action rondomly, need time 0.000183
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000172138214111
INFO:root:frame =833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.993508333333
DEBUG:root: dqn, choose action rondomly, need time 0.000224999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.993476666667
DEBUG:root: dqn, choose action rondomly, need time 0.000381999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000397920608521
INFO:root:frame =841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243186950684
INFO:root:frame =842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame = 843 State into memory, numbers recorded 21 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000607013702393
INFO:root:random_action_porb = 0.993445
DEBUG:root: dqn, choose action rondomly, need time 0.000323
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =844current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000550985336304
INFO:root:frame =846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000347852706909
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.993413333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000341892242432
DEBUG:root: save sample needs time = 0.000104904174805
INFO:root:random_action_porb = 0.993381666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root:frame =853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491142272949
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.99335
DEBUG:root: dqn, choose action rondomly, need time 0.000243
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00035285949707
INFO:root:frame =857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000588178634644
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.993318333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482082366943
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.993286666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00054407119751
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.993255
DEBUG:root: dqn, choose action rondomly, need time 0.000156
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142812728882
INFO:root:frame =869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000495910644531
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.993223333333
DEBUG:root: dqn, choose action rondomly, need time 0.000279
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000417947769165
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.993191666667
DEBUG:root: dqn, choose action rondomly, need time 0.000184999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root:frame =877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000515937805176
INFO:root:frame =878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame = 879 State into memory, numbers recorded 22 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000552892684937
INFO:root:random_action_porb = 0.99316
DEBUG:root: dqn, choose action rondomly, need time 0.000211
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =880current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000368118286133
INFO:root:frame =881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00048303604126
INFO:root:frame =882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000315189361572
INFO:root:frame = 883 State into memory, numbers recorded 23 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000402212142944
INFO:root:random_action_porb = 0.993128333333
DEBUG:root: dqn, choose action rondomly, need time 0.000252
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =884current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root:random_action_porb = 0.993096666667
DEBUG:root: dqn, choose action rondomly, need time 0.000221
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:frame =889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000266075134277
DEBUG:root: save sample needs time = 0.000103950500488
INFO:root:random_action_porb = 0.993065
DEBUG:root: dqn, choose action rondomly, need time 0.000165
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root:frame =893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245809555054
INFO:root:frame =894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249147415161
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.993033333333
DEBUG:root: dqn, choose action rondomly, need time 0.000384
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.993001666667
DEBUG:root: dqn, choose action rondomly, need time 0.000559
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000396013259888
INFO:root:frame =901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000761985778809
INFO:root:frame =902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000206232070923
INFO:root:random_action_porb = 0.99297
DEBUG:root: dqn, choose action rondomly, need time 0.000559
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00048303604126
INFO:root:frame =906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470876693726
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.992938333333
DEBUG:root: dqn, choose action rondomly, need time 0.000508
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame =910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000587940216064
INFO:root:frame = 911 State into memory, numbers recorded 24 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000541925430298
INFO:root:random_action_porb = 0.992906666667
DEBUG:root: dqn, choose action rondomly, need time 0.000526
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =912current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root:frame =914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00053596496582
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:random_action_porb = 0.992875
DEBUG:root: dqn, choose action rondomly, need time 0.000172999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000178098678589
INFO:root:frame =917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00032901763916
DEBUG:root: save sample needs time = 0.000121116638184
INFO:root:random_action_porb = 0.992843333333
DEBUG:root: dqn, choose action rondomly, need time 0.000216
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root:frame =921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000345945358276
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.992811666667
DEBUG:root: dqn, choose action rondomly, need time 0.000210999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:random_action_porb = 0.99278
DEBUG:root: dqn, choose action rondomly, need time 0.000451
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00051212310791
INFO:root:frame =930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00056791305542
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.992748333333
DEBUG:root: dqn, choose action rondomly, need time 0.000579
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000385999679565
INFO:root:frame =933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000416040420532
INFO:root:frame =934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233173370361
DEBUG:root: save sample needs time = 0.000105857849121
INFO:root:random_action_porb = 0.992716666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000244855880737
DEBUG:root: save sample needs time = 0.000107049942017
INFO:root:random_action_porb = 0.992685
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00023889541626
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:random_action_porb = 0.992653333333
DEBUG:root: dqn, choose action rondomly, need time 0.000224
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame =945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.992621666667
DEBUG:root: dqn, choose action rondomly, need time 0.000251
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000183820724487
INFO:root:frame =949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239133834839
DEBUG:root: save sample needs time = 0.000178813934326
INFO:root:random_action_porb = 0.99259
DEBUG:root: dqn, choose action rondomly, need time 0.000251
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:frame =953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:random_action_porb = 0.992558333333
DEBUG:root: dqn, choose action rondomly, need time 0.000528
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000498056411743
INFO:root:frame =958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000563859939575
DEBUG:root: save sample needs time = 0.000108957290649
INFO:root:random_action_porb = 0.992526666667
DEBUG:root: dqn, choose action rondomly, need time 0.000166
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:frame =961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000334978103638
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.992495
DEBUG:root: dqn, choose action rondomly, need time 0.000401
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180959701538
INFO:root:frame =965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047779083252
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.992463333333
DEBUG:root: dqn, choose action rondomly, need time 0.000542
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000533103942871
INFO:root:frame =970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:random_action_porb = 0.992431666667
DEBUG:root: dqn, choose action rondomly, need time 0.000375
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000576972961426
INFO:root:frame =973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000346899032593
INFO:root:frame =974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294923782349
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.9924
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000694990158081
INFO:root:frame =978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000270128250122
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.992368333333
DEBUG:root: dqn, choose action rondomly, need time 0.000534
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.992336666667
DEBUG:root: dqn, choose action rondomly, need time 0.000175
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:frame =985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000414133071899
INFO:root:frame =986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044322013855
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.992305
DEBUG:root: dqn, choose action rondomly, need time 0.000278
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049614906311
INFO:root:frame =990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000174045562744
INFO:root:random_action_porb = 0.992273333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000399112701416
INFO:root:frame =993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000418901443481
INFO:root:frame =994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
DEBUG:root: save sample needs time = 0.000146865844727
INFO:root:random_action_porb = 0.992241666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root:frame =998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000189065933228
DEBUG:root:one frame running time = 0.005567
DEBUG:root:total training time = 5.928199
INFO:root:frame num = 1000 frame round: 0
INFO:root:random_action_porb = 0.99221
DEBUG:root: dqn, choose action rondomly, need time 0.000235
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =1001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =1002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame = 1003 State into memory, numbers recorded 25 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000538110733032
INFO:root:random_action_porb = 0.992178333333
DEBUG:root: dqn, choose action rondomly, need time 0.000325
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1004current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000363826751709
INFO:root:frame =1005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =1006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000331163406372
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.992146666667
DEBUG:root: dqn, choose action rondomly, need time 0.000312
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =1009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000622987747192
INFO:root:frame =1010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000250816345215
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.992115
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =1013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =1014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.992083333333
DEBUG:root: dqn, choose action rondomly, need time 0.00032
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =1017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000566005706787
INFO:root:frame =1018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:random_action_porb = 0.992051666667
DEBUG:root: dqn, choose action rondomly, need time 0.000275
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:player has been killed for 1 times 
INFO:root:frame =1021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:frame =1022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame = 1023 State into memory, numbers recorded 26 action = 4, reward = -1
DEBUG:root: save sample needs time = 0.000695943832397
INFO:root:random_action_porb = 0.99202
DEBUG:root: dqn, choose action rondomly, need time 0.000333
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1024current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000377893447876
INFO:root:frame =1025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =1026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
DEBUG:root: save sample needs time = 0.000142812728882
INFO:root:random_action_porb = 0.991988333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000410079956055
INFO:root:frame =1029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =1030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000199794769287
INFO:root:random_action_porb = 0.991956666667
DEBUG:root: dqn, choose action rondomly, need time 0.000199
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:frame =1033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000423908233643
INFO:root:frame =1034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.991925
DEBUG:root: dqn, choose action rondomly, need time 0.000331999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000337839126587
INFO:root:frame =1037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =1038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.991893333333
DEBUG:root: dqn, choose action rondomly, need time 0.000182
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000160217285156
INFO:root:frame =1041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =1042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:random_action_porb = 0.991861666667
DEBUG:root: dqn, choose action rondomly, need time 0.000275
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame =1045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000475168228149
INFO:root:frame =1046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000339984893799
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:random_action_porb = 0.99183
DEBUG:root: dqn, choose action rondomly, need time 0.000293
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000388860702515
INFO:root:frame =1049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame =1050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.991798333333
DEBUG:root: dqn, choose action rondomly, need time 0.000346
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000428915023804
INFO:root:frame =1053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =1054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame = 1055 State into memory, numbers recorded 27 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000537872314453
INFO:root:random_action_porb = 0.991766666667
DEBUG:root: dqn, choose action rondomly, need time 0.000202
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1056current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =1057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =1058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.991735
DEBUG:root: dqn, choose action rondomly, need time 0.000277000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =1061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =1062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000383138656616
INFO:root:frame = 1063 State into memory, numbers recorded 28 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000519037246704
INFO:root:random_action_porb = 0.991703333333
DEBUG:root: dqn, choose action rondomly, need time 0.00034
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1064current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000377178192139
INFO:root:frame =1065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488042831421
INFO:root:frame =1066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.991671666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =1069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000756025314331
INFO:root:frame =1070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308990478516
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.99164
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:frame =1073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000565052032471
INFO:root:frame =1074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000850915908813
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.991608333333
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =1077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =1078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:random_action_porb = 0.991576666667
DEBUG:root: dqn, choose action rondomly, need time 0.000227000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =1081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =1082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:random_action_porb = 0.991545
DEBUG:root: dqn, choose action rondomly, need time 0.000163
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:frame =1085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =1086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234842300415
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.991513333333
DEBUG:root: dqn, choose action rondomly, need time 0.000168
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:frame =1089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =1090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234842300415
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.991481666667
DEBUG:root: dqn, choose action rondomly, need time 0.000159999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:frame =1093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =1094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.99145
DEBUG:root: dqn, choose action rondomly, need time 0.000383999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =1097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =1098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.991418333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333786010742
INFO:root:frame =1101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =1102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.991386666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342845916748
INFO:root:frame =1105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =1106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486850738525
INFO:root:frame = 1107 State into memory, numbers recorded 29 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000607967376709
INFO:root:random_action_porb = 0.991355
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1108current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =1109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame =1110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000235795974731
INFO:root:random_action_porb = 0.991323333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =1113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =1114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000115871429443
INFO:root:random_action_porb = 0.991291666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =1117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =1118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.99126
INFO:root:dqn select action Tensor("ArgMax:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010027
INFO:root:action choosen by dqn [0]
INFO:root:frame =1120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =1121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =1122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.991228333333
DEBUG:root: dqn, choose action rondomly, need time 0.000366
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =1125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =1126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446796417236
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.991196666667
DEBUG:root: dqn, choose action rondomly, need time 0.000317
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =1129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =1130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.991165
DEBUG:root: dqn, choose action rondomly, need time 0.000324
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =1133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame =1134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.991133333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000425100326538
INFO:root:frame =1138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248908996582
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.991101666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =1141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =1142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
DEBUG:root: save sample needs time = 0.000199794769287
INFO:root:random_action_porb = 0.99107
DEBUG:root: dqn, choose action rondomly, need time 0.000306
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =1145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame =1146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00032901763916
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.991038333333
DEBUG:root: dqn, choose action rondomly, need time 0.0003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =1149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00060510635376
INFO:root:frame =1150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00030779838562
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.991006666667
DEBUG:root: dqn, choose action rondomly, need time 0.000206
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:frame =1153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =1154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.990975
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =1157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000364780426025
INFO:root:frame =1158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.990943333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =1161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =1162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.990911666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000351905822754
INFO:root:frame =1165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000215768814087
INFO:root:frame =1166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:random_action_porb = 0.99088
DEBUG:root: dqn, choose action rondomly, need time 0.000278
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =1169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =1170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.990848333333
DEBUG:root: dqn, choose action rondomly, need time 0.000169
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000130176544189
INFO:root:frame =1173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =1174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.990816666667
DEBUG:root: dqn, choose action rondomly, need time 0.000276999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =1177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =1178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000168085098267
INFO:root:random_action_porb = 0.990785
DEBUG:root: dqn, choose action rondomly, need time 0.000437999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342845916748
INFO:root:frame =1181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =1182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:random_action_porb = 0.990753333333
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =1185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =1186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00048303604126
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.990721666667
DEBUG:root: dqn, choose action rondomly, need time 0.000242
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000196218490601
INFO:root:frame =1189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00044584274292
INFO:root:frame =1190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031304359436
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:random_action_porb = 0.99069
DEBUG:root: dqn, choose action rondomly, need time 0.000384
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =1193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =1194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000387907028198
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root:random_action_porb = 0.990658333333
DEBUG:root: dqn, choose action rondomly, need time 0.000252999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:frame =1197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =1198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000296831130981
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.990626666667
DEBUG:root: dqn, choose action rondomly, need time 0.000335
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root:frame =1201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =1202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000403881072998
DEBUG:root: save sample needs time = 0.000104904174805
INFO:root:random_action_porb = 0.990595
DEBUG:root: dqn, choose action rondomly, need time 0.000205999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:frame =1205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000356912612915
INFO:root:frame =1206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000322103500366
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:random_action_porb = 0.990563333333
DEBUG:root: dqn, choose action rondomly, need time 0.000274000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root:frame =1209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000504016876221
INFO:root:frame =1210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471830368042
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.990531666667
DEBUG:root: dqn, choose action rondomly, need time 0.00052
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =1214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame = 1215 State into memory, numbers recorded 30 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000575065612793
INFO:root:random_action_porb = 0.9905
DEBUG:root: dqn, choose action rondomly, need time 0.000506000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1216current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00037407875061
INFO:root:frame =1218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:random_action_porb = 0.990468333333
DEBUG:root: dqn, choose action rondomly, need time 0.000509999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =1221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =1222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000415086746216
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:random_action_porb = 0.990436666667
DEBUG:root: dqn, choose action rondomly, need time 0.000402000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =1225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =1226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame = 1227 State into memory, numbers recorded 31 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00038480758667
INFO:root:random_action_porb = 0.990405
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1228current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =1229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =1230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000344038009644
DEBUG:root: save sample needs time = 0.00010085105896
INFO:root:random_action_porb = 0.990373333333
DEBUG:root: dqn, choose action rondomly, need time 0.000446
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:frame =1233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =1234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 0.000110149383545
INFO:root:random_action_porb = 0.990341666667
DEBUG:root: dqn, choose action rondomly, need time 0.000214000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000156164169312
INFO:root:frame =1237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =1238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:random_action_porb = 0.99031
DEBUG:root: dqn, choose action rondomly, need time 0.000259
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =1241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:frame =1242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234842300415
DEBUG:root: save sample needs time = 0.000111103057861
INFO:root:random_action_porb = 0.990278333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:frame =1245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000525951385498
INFO:root:frame =1246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.990246666667
DEBUG:root: dqn, choose action rondomly, need time 0.000367000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =1249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000411033630371
INFO:root:frame =1250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000511884689331
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.990215
DEBUG:root: dqn, choose action rondomly, need time 0.000231000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000156879425049
INFO:root:frame =1253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =1254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000633001327515
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:random_action_porb = 0.990183333333
DEBUG:root: dqn, choose action rondomly, need time 0.000427
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =1257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:frame =1258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00079607963562
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:random_action_porb = 0.990151666667
DEBUG:root: dqn, choose action rondomly, need time 0.000451
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000393152236938
INFO:root:frame =1261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023078918457
INFO:root:frame =1262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485897064209
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:random_action_porb = 0.99012
DEBUG:root: dqn, choose action rondomly, need time 0.000245000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =1265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =1266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232219696045
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.990088333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:frame =1269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243186950684
INFO:root:frame =1270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234842300415
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.990056666667
DEBUG:root: dqn, choose action rondomly, need time 0.000166
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:frame =1273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028920173645
INFO:root:frame =1274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288963317871
DEBUG:root: save sample needs time = 0.000125169754028
INFO:root:random_action_porb = 0.990025
DEBUG:root: dqn, choose action rondomly, need time 0.000192999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root:frame =1277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =1278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275135040283
DEBUG:root: save sample needs time = 0.000131130218506
INFO:root:random_action_porb = 0.989993333333
DEBUG:root: dqn, choose action rondomly, need time 0.000194
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:frame =1281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =1282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000316143035889
DEBUG:root: save sample needs time = 0.000150918960571
INFO:root:random_action_porb = 0.989961666667
DEBUG:root: dqn, choose action rondomly, need time 0.000210000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =1285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =1286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293016433716
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.98993
DEBUG:root: dqn, choose action rondomly, need time 0.000199
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000188827514648
INFO:root:frame =1289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =1290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000289916992188
DEBUG:root: save sample needs time = 0.000126123428345
INFO:root:random_action_porb = 0.989898333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =1293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =1294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame = 1295 State into memory, numbers recorded 32 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000385999679565
INFO:root:random_action_porb = 0.989866666667
DEBUG:root: dqn, choose action rondomly, need time 0.000249999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1296current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:frame =1297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =1298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.989835
DEBUG:root: dqn, choose action rondomly, need time 0.000159
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:frame =1301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375032424927
INFO:root:frame =1302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.989803333333
DEBUG:root: dqn, choose action rondomly, need time 0.000229000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =1305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =1306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame = 1307 State into memory, numbers recorded 33 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000396013259888
INFO:root:random_action_porb = 0.989771666667
DEBUG:root: dqn, choose action rondomly, need time 0.000242999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1308current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:frame =1309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =1310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308990478516
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:random_action_porb = 0.98974
DEBUG:root: dqn, choose action rondomly, need time 0.000254999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:frame =1313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000380992889404
INFO:root:frame =1314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000339984893799
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:random_action_porb = 0.989708333333
DEBUG:root: dqn, choose action rondomly, need time 0.000514000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =1317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000495195388794
INFO:root:frame =1318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
DEBUG:root: save sample needs time = 0.000125169754028
INFO:root:random_action_porb = 0.989676666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:frame =1321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:frame =1322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000216007232666
DEBUG:root: save sample needs time = 0.000105142593384
INFO:root:random_action_porb = 0.989645
DEBUG:root: dqn, choose action rondomly, need time 0.000325999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000145196914673
INFO:root:frame =1325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =1326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000221967697144
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.989613333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:frame =1329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000627994537354
INFO:root:frame =1330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame = 1331 State into memory, numbers recorded 34 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:random_action_porb = 0.989581666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1332current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000861167907715
INFO:root:frame =1334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000338792800903
DEBUG:root: save sample needs time = 0.000157117843628
INFO:root:random_action_porb = 0.98955
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =1337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456809997559
INFO:root:frame =1338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000387907028198
DEBUG:root: save sample needs time = 0.000182151794434
INFO:root:random_action_porb = 0.989518333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =1341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =1342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.989486666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =1345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =1346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.989455
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =1349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =1350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame = 1351 State into memory, numbers recorded 35 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000568866729736
INFO:root:random_action_porb = 0.989423333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1352current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =1353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =1354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436782836914
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.989391666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =1357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =1358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444173812866
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.98936
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =1362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.989328333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =1365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436782836914
INFO:root:frame =1366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.989296666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =1369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =1370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame = 1371 State into memory, numbers recorded 36 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000548124313354
INFO:root:random_action_porb = 0.989265
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1372current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =1373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame =1374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:random_action_porb = 0.989233333333
DEBUG:root: dqn, choose action rondomly, need time 0.000494999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =1377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =1378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436782836914
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:random_action_porb = 0.989201666667
DEBUG:root: dqn, choose action rondomly, need time 0.000522999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =1381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =1382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000627994537354
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.98917
DEBUG:root: dqn, choose action rondomly, need time 0.000278
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =1385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000425100326538
INFO:root:frame =1386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000571966171265
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.989138333333
DEBUG:root: dqn, choose action rondomly, need time 0.000328
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =1389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =1390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000111103057861
INFO:root:random_action_porb = 0.989106666667
DEBUG:root: dqn, choose action rondomly, need time 0.000192999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root:frame =1393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =1394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002601146698
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.989075
DEBUG:root: dqn, choose action rondomly, need time 0.000162
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000161170959473
INFO:root:frame =1397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =1398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 0.000116109848022
INFO:root:random_action_porb = 0.989043333333
DEBUG:root: dqn, choose action rondomly, need time 0.000188000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:frame =1401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =1402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000251054763794
DEBUG:root: save sample needs time = 0.000111818313599
INFO:root:random_action_porb = 0.989011666667
DEBUG:root: dqn, choose action rondomly, need time 0.000172999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =1405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =1406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.98898
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000401973724365
INFO:root:frame =1409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =1410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame = 1411 State into memory, numbers recorded 37 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000603914260864
INFO:root:random_action_porb = 0.988948333333
DEBUG:root: dqn, choose action rondomly, need time 0.000350999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1412current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =1413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =1414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000613927841187
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.988916666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =1417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =1418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000514030456543
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:random_action_porb = 0.988885
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000372886657715
INFO:root:frame =1421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =1422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.988853333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000416994094849
INFO:root:frame =1425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000408172607422
INFO:root:frame =1426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.988821666667
DEBUG:root: dqn, choose action rondomly, need time 0.000330999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =1429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =1430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000537872314453
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.98879
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =1433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =1434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000508069992065
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.988758333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =1438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:random_action_porb = 0.988726666667
DEBUG:root: dqn, choose action rondomly, need time 0.000280999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =1441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =1442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485897064209
INFO:root:frame = 1443 State into memory, numbers recorded 38 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000553846359253
INFO:root:random_action_porb = 0.988695
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1444current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =1445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =1446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000573873519897
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.988663333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =1450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000580072402954
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root:random_action_porb = 0.988631666667
DEBUG:root: dqn, choose action rondomly, need time 0.000529
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =1453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =1454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9886
DEBUG:root: dqn, choose action rondomly, need time 0.000314999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =1457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000509977340698
INFO:root:frame =1458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame = 1459 State into memory, numbers recorded 39 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000869989395142
INFO:root:random_action_porb = 0.988568333333
DEBUG:root: dqn, choose action rondomly, need time 0.000196000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1460current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:frame =1461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =1462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042986869812
INFO:root:frame = 1463 State into memory, numbers recorded 40 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000568866729736
INFO:root:random_action_porb = 0.988536666667
DEBUG:root: dqn, choose action rondomly, need time 0.000280999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1464current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =1465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000403881072998
INFO:root:frame =1466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000412940979004
INFO:root:frame = 1467 State into memory, numbers recorded 41 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000536918640137
INFO:root:random_action_porb = 0.988505
DEBUG:root: dqn, choose action rondomly, need time 0.000596999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1468current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =1469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000599145889282
INFO:root:frame =1470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000191926956177
INFO:root:random_action_porb = 0.988473333333
DEBUG:root: dqn, choose action rondomly, need time 0.000527999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =1473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =1474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000380039215088
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.988441666667
DEBUG:root: dqn, choose action rondomly, need time 0.00057
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000543117523193
INFO:root:frame =1477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =1478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.98841
DEBUG:root: dqn, choose action rondomly, need time 0.000165000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:frame =1481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =1482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000290870666504
DEBUG:root: save sample needs time = 0.000180006027222
INFO:root:random_action_porb = 0.988378333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =1485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =1486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000370979309082
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.988346666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =1489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:frame =1490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486135482788
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.988315
DEBUG:root: dqn, choose action rondomly, need time 0.000175
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root:frame =1493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00104379653931
INFO:root:frame =1494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000396013259888
DEBUG:root: save sample needs time = 0.000137805938721
INFO:root:random_action_porb = 0.988283333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =1497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =1498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.988251666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =1502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485897064209
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.98822
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =1505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =1506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00036883354187
DEBUG:root: save sample needs time = 0.000186920166016
INFO:root:random_action_porb = 0.988188333333
DEBUG:root: dqn, choose action rondomly, need time 0.000278
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =1509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000422954559326
INFO:root:frame =1510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000538110733032
DEBUG:root: save sample needs time = 0.000111818313599
INFO:root:random_action_porb = 0.988156666667
DEBUG:root: dqn, choose action rondomly, need time 0.00019
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root:frame =1513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =1514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
DEBUG:root: save sample needs time = 0.000130176544189
INFO:root:random_action_porb = 0.988125
DEBUG:root: dqn, choose action rondomly, need time 0.000266999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000375032424927
INFO:root:frame =1517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000537872314453
INFO:root:frame =1518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:random_action_porb = 0.988093333333
DEBUG:root: dqn, choose action rondomly, need time 0.000154
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:frame =1521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =1522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231981277466
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.988061666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =1525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =1526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000608921051025
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.98803
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =1530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:random_action_porb = 0.987998333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =1533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =1534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441789627075
INFO:root:frame = 1535 State into memory, numbers recorded 42 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000519990921021
INFO:root:random_action_porb = 0.987966666667
DEBUG:root: dqn, choose action rondomly, need time 0.000376000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1536current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.00040602684021
INFO:root:frame =1537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =1538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.987935
DEBUG:root: dqn, choose action rondomly, need time 0.000268
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =1541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =1542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000244855880737
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.987903333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =1545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =1546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000641107559204
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.987871666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =1549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame =1550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:random_action_porb = 0.98784
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =1553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =1554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.987808333333
DEBUG:root: dqn, choose action rondomly, need time 0.000275
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000377893447876
INFO:root:frame =1557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =1558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000583171844482
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:random_action_porb = 0.987776666667
DEBUG:root: dqn, choose action rondomly, need time 0.000183
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root:frame =1561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =1562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame = 1563 State into memory, numbers recorded 43 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000559091567993
INFO:root:random_action_porb = 0.987745
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1564current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =1565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =1566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame = 1567 State into memory, numbers recorded 44 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:random_action_porb = 0.987713333333
DEBUG:root: dqn, choose action rondomly, need time 0.000178999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1568current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000156164169312
INFO:root:frame =1569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =1570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.987681666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336170196533
INFO:root:frame =1573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =1574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000507831573486
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:random_action_porb = 0.98765
DEBUG:root: dqn, choose action rondomly, need time 0.00037
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000495910644531
INFO:root:frame =1577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049090385437
INFO:root:frame =1578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486135482788
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:random_action_porb = 0.987618333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =1581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049090385437
INFO:root:frame =1582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000392198562622
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.987586666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =1586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000562191009521
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.987555
DEBUG:root: dqn, choose action rondomly, need time 0.00034
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:frame =1589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =1590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046181678772
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:random_action_porb = 0.987523333333
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root:frame =1593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441789627075
INFO:root:frame =1594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000556945800781
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.987491666667
DEBUG:root: dqn, choose action rondomly, need time 0.000201000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =1597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =1598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000307083129883
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:random_action_porb = 0.98746
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =1601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000423908233643
INFO:root:frame =1602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000270843505859
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:random_action_porb = 0.987428333333
DEBUG:root: dqn, choose action rondomly, need time 0.000177000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root:frame =1605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root:frame =1606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000520944595337
INFO:root:frame = 1607 State into memory, numbers recorded 45 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000491857528687
INFO:root:random_action_porb = 0.987396666667
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1608current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  43.86708832]
 [ 198.14900208]
 [ 201.40213013]
 [ 196.68681335]
 [ 196.82058716]
 [  15.27220631]
 [  44.81788254]
 [ 193.96987915]
 [  43.56396484]
 [  15.28574181]
 [  13.40767193]
 [  13.40767193]
 [ 170.06712341]
 [  42.42909622]
 [ 194.7175293 ]
 [  43.56396484]]
DEBUG:root:training time = %d0.22257
INFO:root:frame =1609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286817550659
INFO:root:frame =1610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000146865844727
INFO:root:random_action_porb = 0.987365
DEBUG:root: dqn, choose action rondomly, need time 0.000309
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326156616211
INFO:root:frame =1613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000417947769165
INFO:root:frame =1614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000338077545166
DEBUG:root: save sample needs time = 0.000346899032593
INFO:root:random_action_porb = 0.987333333333
DEBUG:root: dqn, choose action rondomly, need time 0.000323
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root:training error  = [[  1.73186096e+02]
 [  1.35786101e-01]
 [  1.74675293e+02]
 [  1.72539398e+02]
 [  1.72539398e+02]
 [  9.83708668e+00]
 [  2.46414394e+01]
 [  3.38604736e+01]
 [  1.78215563e-01]
 [  3.35976791e+01]
 [  9.83708668e+00]
 [  2.33543968e+01]
 [  2.38390312e+01]
 [  2.48065796e+01]
 [  1.72539398e+02]
 [  2.50654545e+01]]
DEBUG:root:training time = %d0.204474
INFO:root:frame =1617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000260829925537
INFO:root:frame =1618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.987301666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000157833099365
INFO:root:frame =1621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =1622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000600814819336
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.98727
DEBUG:root: dqn, choose action rondomly, need time 0.000225
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:training error  = [[  1.93308277e+01]
 [  2.84197674e+01]
 [  1.88820934e+01]
 [  2.94723473e+01]
 [  1.66783988e-01]
 [  1.60269241e+02]
 [  6.98023558e+00]
 [  6.79900694e+00]
 [  6.13829899e+00]
 [  2.87738304e+01]
 [  1.97024021e+01]
 [  1.85578861e+01]
 [  6.98023558e+00]
 [  1.58937378e+02]
 [  2.94723473e+01]
 [  1.15817778e-01]]
DEBUG:root:training time = %d0.23109
INFO:root:frame =1625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000364065170288
INFO:root:frame =1626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:random_action_porb = 0.987238333333
DEBUG:root: dqn, choose action rondomly, need time 0.000258000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =1629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =1630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.987206666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:training error  = [[  2.69016571e+01]
 [  4.65105295e+00]
 [  2.74970303e+01]
 [  1.50166336e+02]
 [  1.50073364e+02]
 [  2.72202930e+01]
 [  5.38353348e+00]
 [  7.51772523e-02]
 [  2.66924267e+01]
 [  1.01355426e-01]
 [  1.63919163e+01]
 [  1.49713181e+02]
 [  1.70630455e+01]
 [  2.63278027e+01]
 [  5.38353348e+00]
 [  1.01355426e-01]]
DEBUG:root:training time = %d0.200624
INFO:root:frame =1633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =1634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000333070755005
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.987175
DEBUG:root: dqn, choose action rondomly, need time 0.000363
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000351190567017
INFO:root:frame =1637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =1638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000612020492554
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.987143333333
DEBUG:root: dqn, choose action rondomly, need time 0.000563000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:training error  = [[ 141.21746826]
 [ 139.76950073]
 [ 138.10969543]
 [ 139.76950073]
 [ 140.88249207]
 [  13.87569141]
 [   3.95259309]
 [   3.35146213]
 [ 141.20613098]
 [  23.78688049]
 [  13.84158134]
 [  13.27020931]
 [ 140.93011475]
 [  13.27020931]
 [   3.97349858]
 [ 137.68217468]]
DEBUG:root:training time = %d0.181203
INFO:root:frame =1641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:frame =1642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319957733154
DEBUG:root: save sample needs time = 9.91821289062e-05
INFO:root:random_action_porb = 0.987111666667
DEBUG:root: dqn, choose action rondomly, need time 0.000348000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:frame =1645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =1646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000349998474121
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.98708
DEBUG:root: dqn, choose action rondomly, need time 0.000266
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.05374899e+01]
 [  2.00995312e+01]
 [  4.71055619e-02]
 [  1.29574219e+02]
 [  1.29286942e+02]
 [  1.93169272e+00]
 [  5.49022055e+00]
 [  4.71055619e-02]
 [  1.94775658e+01]
 [  5.15202321e-02]
 [  9.72628403e+00]
 [  1.88318272e+01]
 [  1.10592075e-01]
 [  1.00364323e+01]
 [  1.84104996e+01]
 [  1.32724167e+02]]
DEBUG:root:training time = %d0.218513
INFO:root:frame =1649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =1650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000329971313477
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.987048333333
DEBUG:root: dqn, choose action rondomly, need time 0.000183
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000172853469849
INFO:root:frame =1653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000607967376709
INFO:root:frame =1654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.987016666667
DEBUG:root: dqn, choose action rondomly, need time 0.000434
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000378847122192
INFO:root:training error  = [[  1.78036976e+01]
 [  1.81472816e+01]
 [  1.78036976e+01]
 [  1.24536339e+02]
 [  1.26554947e+02]
 [  1.78036976e+01]
 [  1.82182102e+01]
 [  8.20279026e+00]
 [  1.23481369e+02]
 [  1.22520065e+02]
 [  1.23481369e+02]
 [  1.71065593e+00]
 [  8.91442490e+00]
 [  1.08865833e+00]
 [  6.33223727e-02]
 [  1.82193056e-01]]
DEBUG:root:training time = %d0.188076
INFO:root:frame =1657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0017409324646
INFO:root:frame =1658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000336170196533
DEBUG:root: save sample needs time = 0.000108957290649
INFO:root:random_action_porb = 0.986985
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =1661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =1662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:random_action_porb = 0.986953333333
DEBUG:root: dqn, choose action rondomly, need time 0.000176999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000155925750732
INFO:root:training error  = [[ 115.83905792]
 [  15.13264084]
 [  15.13264084]
 [ 115.71854401]
 [   1.01067472]
 [   1.01067472]
 [   6.93531513]
 [  14.6733923 ]
 [  14.6733923 ]
 [  14.27974796]
 [ 115.68061066]
 [ 115.00750732]
 [   6.69948053]
 [ 115.68061066]
 [ 116.71582031]
 [  15.46693134]]
DEBUG:root:training time = %d0.211719
INFO:root:frame =1665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =1666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:frame = 1667 State into memory, numbers recorded 46 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:random_action_porb = 0.986921666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1668current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000545024871826
INFO:root:frame =1670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000420808792114
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.98689
DEBUG:root: dqn, choose action rondomly, need time 0.000314999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:training error  = [[  2.87156608e-02]
 [  2.74894357e-01]
 [  1.05395630e+02]
 [  4.56770539e-01]
 [  1.35409069e+01]
 [  1.48877606e-01]
 [  1.10906540e+02]
 [  1.07787827e+02]
 [  1.05050438e+02]
 [  1.08980087e+02]
 [  1.07848312e+02]
 [  1.23966932e+01]
 [  1.68197647e-01]
 [  4.56770539e-01]
 [  1.07917015e+02]
 [  1.28256845e+01]]
DEBUG:root:training time = %d0.22213
INFO:root:frame =1673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =1674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root:random_action_porb = 0.986858333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =1677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =1678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00055193901062
DEBUG:root: save sample needs time = 0.000182867050171
INFO:root:random_action_porb = 0.986826666667
DEBUG:root: dqn, choose action rondomly, need time 0.000264
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.16396999e+01]
 [  1.00064362e+02]
 [  1.02368164e+01]
 [  3.92565227e+00]
 [  1.02206177e+02]
 [  1.01142525e+02]
 [  1.17985821e+01]
 [  9.84845200e+01]
 [  8.15400314e+01]
 [  1.00064362e+02]
 [  1.34673670e-01]
 [  1.01142525e+02]
 [  4.29632568e+00]
 [  4.29632568e+00]
 [  5.11960462e-02]
 [  1.02206177e+02]]
DEBUG:root:training time = %d0.222457
INFO:root:frame =1681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =1682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000300884246826
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.986795
DEBUG:root: dqn, choose action rondomly, need time 0.000335
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =1685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =1686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0003821849823
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.986763333333
DEBUG:root: dqn, choose action rondomly, need time 0.000352999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000462770462036
INFO:root:training error  = [[  9.88850594e+00]
 [  9.16329803e+01]
 [  2.72800159e+00]
 [  2.79982615e+00]
 [  9.41011887e+01]
 [  3.86914518e-03]
 [  2.79982615e+00]
 [  3.86914518e-03]
 [  2.69892764e+00]
 [  8.46466351e+00]
 [  1.90695431e-02]
 [  9.74183464e+00]
 [  9.30698929e+01]
 [  9.41011887e+01]
 [  1.88289750e-02]
 [  6.15136744e-03]]
DEBUG:root:training time = %d0.234735
INFO:root:frame =1689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =1690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509977340698
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.986731666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =1693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root:frame =1694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:random_action_porb = 0.9867
DEBUG:root: dqn, choose action rondomly, need time 0.000244
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000193119049072
INFO:root:training error  = [[  8.38824749e+00]
 [  8.87655354e+00]
 [  8.99517975e+01]
 [  2.50214410e+00]
 [  1.21808881e-02]
 [  2.67568836e-03]
 [  9.03565063e+01]
 [  2.25931287e+00]
 [  1.69061664e-02]
 [  8.49840927e+00]
 [  2.78332876e-03]
 [  2.50214410e+00]
 [  8.99517975e+01]
 [  7.53007746e+00]
 [  9.18893204e+01]
 [  2.67568836e-03]]
DEBUG:root:training time = %d0.207189
INFO:root:frame =1697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root:frame =1698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000284910202026
DEBUG:root: save sample needs time = 0.000130891799927
INFO:root:random_action_porb = 0.986668333333
DEBUG:root: dqn, choose action rondomly, need time 0.000307999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000136852264404
INFO:root:frame =1701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =1702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319957733154
DEBUG:root: save sample needs time = 9.41753387451e-05
INFO:root:random_action_porb = 0.986636666667
DEBUG:root: dqn, choose action rondomly, need time 0.000167999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.86851788e+00]
 [  2.06706786e+00]
 [  9.03701172e+01]
 [  8.89277115e+01]
 [  7.88656902e+00]
 [  8.84838181e+01]
 [  1.93046415e+00]
 [  7.69776344e+00]
 [  8.59965210e+01]
 [  8.03851318e+00]
 [  6.42133355e-01]
 [  2.07683563e+00]
 [  7.69776344e+00]
 [  8.76459961e+01]
 [  2.06706786e+00]
 [  4.10645385e-04]]
DEBUG:root:training time = %d0.185785
INFO:root:frame =1705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =1706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000335931777954
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.986605
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =1709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00040602684021
INFO:root:frame =1710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.986573333333
DEBUG:root: dqn, choose action rondomly, need time 0.000155000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:training error  = [[  1.44646442e+00]
 [  8.74773865e+01]
 [  9.02530441e+01]
 [  8.74492950e+01]
 [  8.53716583e+01]
 [  1.53043497e+00]
 [  8.88955536e+01]
 [  8.73986282e+01]
 [  6.44517231e+00]
 [  6.97044277e+00]
 [  8.84030838e+01]
 [  8.74773865e+01]
 [  6.21168089e+00]
 [  1.92046384e-04]
 [  6.44517231e+00]
 [  1.44646442e+00]]
DEBUG:root:training time = %d0.193399
INFO:root:frame =1713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =1714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 0.000135183334351
INFO:root:random_action_porb = 0.986541666667
DEBUG:root: dqn, choose action rondomly, need time 0.000331000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =1717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =1718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:random_action_porb = 0.98651
DEBUG:root: dqn, choose action rondomly, need time 0.000528000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:training error  = [[  5.55232334e+00]
 [  7.49370875e-03]
 [  5.88558292e+00]
 [  6.01736355e+00]
 [  1.03820467e+00]
 [  8.33599854e+01]
 [  1.53786049e-03]
 [  5.55232334e+00]
 [  3.70563865e-02]
 [  7.94009628e+01]
 [  8.30391109e-01]
 [  9.68145669e-01]
 [  1.07063997e+00]
 [  8.24236450e+01]
 [  8.30391109e-01]
 [  8.17375641e+01]]
DEBUG:root:training time = %d0.20224
INFO:root:frame =1721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =1722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000290870666504
DEBUG:root: save sample needs time = 0.000158071517944
INFO:root:random_action_porb = 0.986478333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =1725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000419139862061
INFO:root:frame =1726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423192977905
DEBUG:root: save sample needs time = 0.000369071960449
INFO:root:random_action_porb = 0.986446666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.15796661e+01]
 [  7.46552587e-01]
 [  1.86540931e-02]
 [  2.23092106e-03]
 [  5.72106743e+00]
 [  4.30082679e-02]
 [  4.47032824e-02]
 [  3.42615992e-02]
 [  5.17967796e+00]
 [  3.12399468e-03]
 [  1.01809514e+00]
 [  4.30082679e-02]
 [  5.59867907e+00]
 [  5.72106743e+00]
 [  4.64861822e+00]
 [  8.15796661e+01]]
DEBUG:root:training time = %d0.199543
INFO:root:frame =1729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000549077987671
INFO:root:frame =1730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239849090576
DEBUG:root: save sample needs time = 0.000108003616333
INFO:root:random_action_porb = 0.986415
DEBUG:root: dqn, choose action rondomly, need time 0.000178
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:frame =1733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =1734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000313997268677
DEBUG:root: save sample needs time = 0.000125169754028
INFO:root:random_action_porb = 0.986383333333
DEBUG:root: dqn, choose action rondomly, need time 0.000261
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.99580991e-01]
 [  7.83874741e+01]
 [  7.93295975e+01]
 [  8.06703033e+01]
 [  5.15122318e+00]
 [  8.87904167e-02]
 [  4.40458775e+00]
 [  4.79205990e+00]
 [  7.89334869e+01]
 [  5.12202597e+00]
 [  4.40458775e+00]
 [  4.20889425e+00]
 [  5.40303349e-01]
 [  4.20889425e+00]
 [  9.38471034e-03]
 [  1.65685546e-03]]
DEBUG:root:training time = %d0.182978
INFO:root:frame =1737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =1738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.986351666667
DEBUG:root: dqn, choose action rondomly, need time 0.000783999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000657796859741
INFO:root:frame =1741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444173812866
INFO:root:frame =1742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234842300415
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.98632
DEBUG:root: dqn, choose action rondomly, need time 0.000338000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000409841537476
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.06599426e+00]
 [  3.74638653e+00]
 [  7.14251518e-01]
 [  4.13710117e+00]
 [  7.88115524e-03]
 [  4.27745074e-01]
 [  4.30002403e+00]
 [  7.63044357e+01]
 [  4.30002403e+00]
 [  7.63044357e+01]
 [  3.65493536e-01]
 [  7.73327026e+01]
 [  7.88115524e-03]
 [  7.92364273e+01]
 [  7.81313705e+01]
 [  4.49832187e-05]]
DEBUG:root:training time = %d0.214586
INFO:root:frame =1745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =1746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319957733154
DEBUG:root: save sample needs time = 0.000389814376831
INFO:root:random_action_porb = 0.986288333333
INFO:root:dqn select action Tensor("ArgMax_1:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.009514
INFO:root:action choosen by dqn [0]
INFO:root:frame =1748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:frame =1749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000397920608521
INFO:root:frame =1750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000709772109985
DEBUG:root: save sample needs time = 0.00019383430481
INFO:root:random_action_porb = 0.986256666667
DEBUG:root: dqn, choose action rondomly, need time 0.000487
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.29915085e+01]
 [  1.73083574e-01]
 [  1.91406589e-02]
 [  7.42173538e+01]
 [  2.04761952e-01]
 [  3.99311686e+00]
 [  7.51616745e+01]
 [  7.29915085e+01]
 [  7.46607666e+01]
 [  1.66461468e-01]
 [  1.72585011e-01]
 [  1.13761844e-03]
 [  3.74189353e+00]
 [  3.69948554e+00]
 [  1.71987619e-02]
 [  8.55502725e-01]]
DEBUG:root:training time = %d0.216243
INFO:root:frame =1753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =1754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481128692627
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:random_action_porb = 0.986225
DEBUG:root: dqn, choose action rondomly, need time 0.000323
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =1757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:frame =1758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.986193333333
DEBUG:root: dqn, choose action rondomly, need time 0.000188000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000167846679688
INFO:root:training error  = [[  1.31603867e-01]
 [  3.29623342e+00]
 [  1.82885723e-03]
 [  5.12027415e-03]
 [  7.27343597e+01]
 [  5.12027415e-03]
 [  3.37868547e+00]
 [  8.28806981e-02]
 [  2.38946434e-02]
 [  7.30592117e+01]
 [  7.13535233e+01]
 [  2.96540093e+00]
 [  7.26449722e-03]
 [  7.45293579e+01]
 [  3.14330292e+00]
 [  9.46195330e-04]]
DEBUG:root:training time = %d0.204879
INFO:root:frame =1761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =1762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00061297416687
DEBUG:root: save sample needs time = 0.000250816345215
INFO:root:random_action_porb = 0.986161666667
DEBUG:root: dqn, choose action rondomly, need time 0.000218
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =1765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000368118286133
INFO:root:frame =1766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000317811965942
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:random_action_porb = 0.98613
DEBUG:root: dqn, choose action rondomly, need time 0.000256
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.97865748e-01]
 [  6.57492643e-03]
 [  7.11745758e+01]
 [  5.58448105e+01]
 [  2.90057945e+00]
 [  7.09122086e+01]
 [  3.12126565e+00]
 [  4.69660107e-03]
 [  7.23332596e+01]
 [  2.51888651e-02]
 [  3.03863931e+00]
 [  3.12126565e+00]
 [  1.64001225e-03]
 [  2.90057945e+00]
 [  7.09122086e+01]
 [  2.67570708e-02]]
DEBUG:root:training time = %d0.208359
INFO:root:frame =1769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229835510254
INFO:root:frame =1770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame = 1771 State into memory, numbers recorded 47 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.00052809715271
INFO:root:random_action_porb = 0.986098333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1772current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000320196151733
INFO:root:frame =1773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =1774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000510931015015
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.986066666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:training error  = [[  2.26400065e-04]
 [  7.91399647e-03]
 [  6.93243942e+01]
 [  9.18040692e-04]
 [  6.94054871e+01]
 [  6.98057632e+01]
 [  1.92190886e+00]
 [  6.76608276e+01]
 [  1.92190886e+00]
 [  6.95369568e+01]
 [  3.28595121e-03]
 [  6.86930923e+01]
 [  1.12136593e-02]
 [  6.95369568e+01]
 [  1.92190886e+00]
 [  2.31330228e+00]]
DEBUG:root:training time = %d0.223008
INFO:root:frame =1777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290155410767
INFO:root:frame =1778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000287055969238
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.986035
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00036096572876
INFO:root:frame =1781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000475883483887
INFO:root:frame =1782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000557899475098
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.986003333333
DEBUG:root: dqn, choose action rondomly, need time 0.000522
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:training error  = [[  2.19799852e+00]
 [  2.03243542e+00]
 [  4.21153563e-05]
 [  7.96025898e-03]
 [  7.96025898e-03]
 [  2.03243542e+00]
 [  6.78719940e+01]
 [  6.72472534e+01]
 [  6.69789658e+01]
 [  6.74562683e+01]
 [  4.59130630e-02]
 [  6.74562683e+01]
 [  1.72219157e+00]
 [  2.45324094e-02]
 [  6.35463558e-03]
 [  2.19799852e+00]]
DEBUG:root:training time = %d0.224851
INFO:root:frame =1785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028920173645
INFO:root:frame =1786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000256061553955
DEBUG:root: save sample needs time = 0.000173091888428
INFO:root:random_action_porb = 0.985971666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365972518921
INFO:root:frame =1789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000547885894775
INFO:root:frame =1790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:random_action_porb = 0.98594
DEBUG:root: dqn, choose action rondomly, need time 0.000157999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000153779983521
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.56293640e+01]
 [  6.31645322e-03]
 [  1.93904079e-02]
 [  6.56293640e+01]
 [  6.67895813e+01]
 [  1.55445480e+00]
 [  1.93357527e+00]
 [  1.82617986e+00]
 [  5.21108475e+01]
 [  1.73559427e+00]
 [  6.31645322e-03]
 [  2.61912476e-02]
 [  2.52832752e-03]
 [  6.59345093e+01]
 [  1.76245904e+00]
 [  1.42783856e+00]]
DEBUG:root:training time = %d0.206276
INFO:root:frame =1793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =1794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.00018310546875
INFO:root:random_action_porb = 0.985908333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =1797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000646114349365
INFO:root:frame =1798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000391006469727
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:random_action_porb = 0.985876666667
DEBUG:root: dqn, choose action rondomly, need time 0.000195000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.51846466e+01]
 [  1.27597582e+00]
 [  5.89567516e-03]
 [  6.37236481e+01]
 [  1.57667375e+00]
 [  5.89567516e-03]
 [  6.45851669e+01]
 [  6.37236481e+01]
 [  1.48269987e+00]
 [  6.36267204e+01]
 [  6.49658508e+01]
 [  6.62920761e+01]
 [  3.39611986e-04]
 [  1.09155010e-03]
 [  5.04707184e+01]
 [  6.22255173e+01]]
DEBUG:root:training time = %d0.224831
INFO:root:frame =1801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00036096572876
INFO:root:frame =1802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:random_action_porb = 0.985845
DEBUG:root: dqn, choose action rondomly, need time 0.000558999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000379800796509
INFO:root:frame =1805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000429153442383
INFO:root:frame =1806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000753879547119
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.985813333333
DEBUG:root: dqn, choose action rondomly, need time 0.000381999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.59895762e-03]
 [  4.27681059e-02]
 [  3.91844846e-03]
 [  6.44557190e+01]
 [  1.25257158e+00]
 [  4.84123726e+01]
 [  1.63352434e-02]
 [  6.24337120e+01]
 [  6.28883743e+01]
 [  1.67099512e-04]
 [  6.38740692e+01]
 [  3.91844846e-03]
 [  8.94903004e-01]
 [  6.24347763e+01]
 [  1.15183651e+00]
 [  6.28106918e+01]]
DEBUG:root:training time = %d0.214606
INFO:root:frame =1809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =1810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000251054763794
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.985781666667
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =1813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =1814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298023223877
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:random_action_porb = 0.98575
DEBUG:root: dqn, choose action rondomly, need time 0.000191000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.34041834e-01]
 [  9.38592851e-01]
 [  6.05095062e+01]
 [  1.00834027e-03]
 [  1.52524244e-02]
 [  4.72417641e+01]
 [  1.02110195e+00]
 [  2.13676617e-02]
 [  6.05095062e+01]
 [  1.05883861e+00]
 [  6.11118164e+01]
 [  6.18795319e+01]
 [  2.76888665e-02]
 [  6.11118164e+01]
 [  6.02236366e+01]
 [  6.02236366e+01]]
DEBUG:root:training time = %d0.182387
INFO:root:frame =1817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =1818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.000156164169312
INFO:root:random_action_porb = 0.985718333333
DEBUG:root: dqn, choose action rondomly, need time 0.000423000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =1821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000341892242432
INFO:root:frame =1822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000305891036987
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:random_action_porb = 0.985686666667
DEBUG:root: dqn, choose action rondomly, need time 0.000178000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:training error  = [[  5.99578285e+01]
 [  3.28350533e-03]
 [  2.26995256e-03]
 [  4.37049195e-02]
 [  8.24522138e-01]
 [  6.02671013e+01]
 [  3.28350533e-03]
 [  3.45201604e-02]
 [  1.87523030e-02]
 [  6.02671013e+01]
 [  5.90117416e+01]
 [  5.87697639e+01]
 [  5.90117416e+01]
 [  6.05497971e+01]
 [  2.26995256e-03]
 [  8.24522138e-01]]
DEBUG:root:training time = %d0.178034
INFO:root:frame =1825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000364065170288
INFO:root:frame =1826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000326156616211
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.985655
DEBUG:root: dqn, choose action rondomly, need time 0.000179000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:frame =1829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =1830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000301837921143
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.985623333333
DEBUG:root: dqn, choose action rondomly, need time 0.000177999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000172853469849
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.16892618e-03]
 [  3.72699299e-03]
 [  3.36060929e-03]
 [  6.03587608e+01]
 [  3.72699299e-03]
 [  3.36060929e-03]
 [  1.21563971e+00]
 [  2.01974515e-04]
 [  1.60855517e-01]
 [  5.93974342e+01]
 [  5.88330421e+01]
 [  3.36060929e-03]
 [  6.26023263e-02]
 [  5.97179756e+01]
 [  5.69845177e-03]
 [  6.77973270e-01]]
DEBUG:root:training time = %d0.186344
INFO:root:frame =1833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =1834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000347852706909
INFO:root:frame = 1835 State into memory, numbers recorded 48 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:random_action_porb = 0.985591666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1836current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =1837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =1838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000281095504761
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.98556
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000178098678589
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.36837859e-02]
 [  5.67055435e+01]
 [  1.36185077e-03]
 [  1.25486974e-06]
 [  4.01147082e-02]
 [  4.20589000e-03]
 [  1.68521772e-04]
 [  5.77272072e+01]
 [  4.01733458e-01]
 [  5.56010551e+01]
 [  1.15691873e-04]
 [  2.44240999e-01]
 [  4.26516228e+01]
 [  5.71160851e+01]
 [  1.10793067e-02]
 [  3.73084396e-01]]
DEBUG:root:training time = %d0.183197
INFO:root:frame =1841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =1842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:random_action_porb = 0.985528333333
DEBUG:root: dqn, choose action rondomly, need time 0.000195000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143766403198
INFO:root:frame =1845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =1846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485181808472
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.985496666667
DEBUG:root: dqn, choose action rondomly, need time 0.000164000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000152111053467
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.09152261e-04]
 [  3.63778353e-01]
 [  5.59806862e+01]
 [  1.56706572e-01]
 [  8.09152261e-04]
 [  4.21984291e+01]
 [  3.73039842e-01]
 [  2.84730852e-01]
 [  3.95914819e-03]
 [  3.23844641e-01]
 [  5.59182396e+01]
 [  3.95230055e-01]
 [  5.52640457e+01]
 [  1.96379110e-01]
 [  4.21984291e+01]
 [  3.63778353e-01]]
DEBUG:root:training time = %d0.192275
INFO:root:frame =1849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =1850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509977340698
INFO:root:frame = 1851 State into memory, numbers recorded 49 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.00042986869812
INFO:root:random_action_porb = 0.985465
DEBUG:root: dqn, choose action rondomly, need time 0.000465999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1852current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root:frame =1853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =1854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:random_action_porb = 0.985433333333
DEBUG:root: dqn, choose action rondomly, need time 0.000351999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.44867706e+01]
 [  6.66297798e-04]
 [  2.68410444e-02]
 [  5.52710266e+01]
 [  1.08252920e-01]
 [  5.53965721e+01]
 [  1.30954164e-03]
 [  4.43784316e-04]
 [  2.85924652e-05]
 [  9.27084405e-03]
 [  1.05057778e-02]
 [  2.12917533e-02]
 [  4.15192146e+01]
 [  2.22428814e-01]
 [  5.46715126e+01]
 [  2.79492617e-01]]
DEBUG:root:training time = %d0.190333
INFO:root:frame =1857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =1858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324964523315
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:random_action_porb = 0.985401666667
DEBUG:root: dqn, choose action rondomly, need time 0.000207
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =1861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =1862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000332117080688
DEBUG:root: save sample needs time = 0.000135183334351
INFO:root:random_action_porb = 0.98537
DEBUG:root: dqn, choose action rondomly, need time 0.000194999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:training error  = [[  5.33646736e+01]
 [  9.67929882e-05]
 [  5.34771347e+01]
 [  5.37909164e+01]
 [  1.60274521e-01]
 [  5.39935608e+01]
 [  2.15862826e-01]
 [  4.84851524e-02]
 [  5.46890984e+01]
 [  2.84195971e-02]
 [  5.29886049e-04]
 [  3.81135233e-02]
 [  2.17500970e-01]
 [  6.27381523e-05]
 [  4.84851524e-02]
 [  1.50903361e-02]]
DEBUG:root:training time = %d0.182332
INFO:root:frame =1865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000370979309082
INFO:root:frame =1866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288963317871
DEBUG:root: save sample needs time = 0.000141859054565
INFO:root:random_action_porb = 0.985338333333
DEBUG:root: dqn, choose action rondomly, need time 0.000257999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:frame =1869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =1870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000278949737549
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.985306666667
DEBUG:root: dqn, choose action rondomly, need time 0.000225
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.10343513e+01]
 [  6.86186738e-03]
 [  3.92249413e-03]
 [  2.14495175e-02]
 [  8.32709577e-03]
 [  8.84806886e-02]
 [  7.35044107e-02]
 [  5.24226112e+01]
 [  8.03333521e-03]
 [  5.26881905e+01]
 [  8.03333521e-03]
 [  9.37573612e-02]
 [  2.50626784e-02]
 [  1.26905944e-02]
 [  5.11308403e+01]
 [  4.01247292e+01]]
DEBUG:root:training time = %d0.190272
INFO:root:frame =1873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:frame =1874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259160995483
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.985275
DEBUG:root: dqn, choose action rondomly, need time 0.000239000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000184059143066
INFO:root:frame =1877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =1878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000271797180176
INFO:root:random_action_porb = 0.985243333333
DEBUG:root: dqn, choose action rondomly, need time 0.000159
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.51190078e-02]
 [  5.25482445e+01]
 [  5.52487932e-02]
 [  4.91108894e-02]
 [  5.22955589e+01]
 [  3.83286743e+01]
 [  5.22955589e+01]
 [  4.61348658e-03]
 [  9.44093056e-03]
 [  1.97343854e-03]
 [  5.14406319e+01]
 [  6.84294850e-02]
 [  8.45196377e-03]
 [  7.56450184e-03]
 [  6.73333928e-02]
 [  3.89251560e-02]]
DEBUG:root:training time = %d0.196502
INFO:root:frame =1881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =1882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000406980514526
DEBUG:root: save sample needs time = 0.00015115737915
INFO:root:random_action_porb = 0.985211666667
DEBUG:root: dqn, choose action rondomly, need time 0.000245
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:frame =1885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =1886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000270843505859
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.98518
DEBUG:root: dqn, choose action rondomly, need time 0.000156999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000131130218506
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.02864952e+01]
 [  4.97842712e+01]
 [  3.77976799e+01]
 [  5.47942647e-04]
 [  4.97842712e+01]
 [  4.36817808e-03]
 [  1.34649957e-02]
 [  4.92955971e+01]
 [  4.94108276e+01]
 [  1.68684301e-06]
 [  1.90518994e-03]
 [  3.94787127e-03]
 [  2.90120207e-02]
 [  1.95329543e-02]
 [  5.00681038e+01]
 [  1.29486872e-02]]
DEBUG:root:training time = %d0.18573
INFO:root:frame =1889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =1890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000260829925537
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:random_action_porb = 0.985148333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =1893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =1894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000415086746216
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.985116666667
DEBUG:root: dqn, choose action rondomly, need time 0.000182000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.22431351e-03]
 [  2.17016716e-03]
 [  2.17016716e-03]
 [  3.63268261e-03]
 [  4.95400925e+01]
 [  4.92774887e+01]
 [  4.98549995e+01]
 [  3.71986504e+01]
 [  7.74005651e-02]
 [  7.74721205e-02]
 [  2.40724087e-02]
 [  1.23631012e+00]
 [  2.45183055e-05]
 [  3.07743996e-02]
 [  8.94915871e-03]
 [  1.17879562e-01]]
DEBUG:root:training time = %d0.172747
INFO:root:frame =1897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250816345215
INFO:root:frame =1898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.985085
DEBUG:root: dqn, choose action rondomly, need time 0.000158000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =1901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =1902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241041183472
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.985053333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.98113537e-04]
 [  1.20293098e-02]
 [  3.62690468e-03]
 [  1.03485155e+00]
 [  5.44888005e-02]
 [  7.28203962e-03]
 [  3.12959401e-06]
 [  4.86086578e+01]
 [  1.28719956e-02]
 [  4.82038422e+01]
 [  1.38567458e-03]
 [  2.66278861e-04]
 [  1.90208219e-02]
 [  3.77449533e-03]
 [  4.84598427e+01]
 [  7.28203962e-03]]
DEBUG:root:training time = %d0.181495
INFO:root:frame =1905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =1906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288963317871
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.985021666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:frame =1909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240802764893
INFO:root:frame =1910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.98499
DEBUG:root: dqn, choose action rondomly, need time 0.000317000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.16291508e-03]
 [  4.74081268e+01]
 [  4.79555359e+01]
 [  2.28561219e-02]
 [  2.27944180e-03]
 [  2.28561219e-02]
 [  1.56717942e-05]
 [  2.80120857e-02]
 [  1.45838902e-04]
 [  6.77025504e-03]
 [  1.62521051e-03]
 [  3.53803596e+01]
 [  2.27944180e-03]
 [  6.77025504e-03]
 [  3.53803596e+01]
 [  4.55211732e-04]]
DEBUG:root:training time = %d0.179546
INFO:root:frame =1913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =1914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:random_action_porb = 0.984958333333
DEBUG:root: dqn, choose action rondomly, need time 0.00027
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185012817383
INFO:root:frame =1917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000423192977905
INFO:root:frame =1918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:random_action_porb = 0.984926666667
DEBUG:root: dqn, choose action rondomly, need time 0.000250000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.46491286e-03]
 [  3.52404480e+01]
 [  4.61449928e+01]
 [  8.99812323e-04]
 [  3.82870436e-02]
 [  6.54099807e-02]
 [  3.34654003e-03]
 [  4.82919006e+01]
 [  4.69814568e+01]
 [  8.99812323e-04]
 [  8.99812323e-04]
 [  4.70511169e+01]
 [  3.34654003e-03]
 [  3.82870436e-02]
 [  1.33588619e-03]
 [  4.77966309e+01]]
DEBUG:root:training time = %d0.210935
INFO:root:frame =1921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =1922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000534057617188
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:random_action_porb = 0.984895
DEBUG:root: dqn, choose action rondomly, need time 0.000225999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root:frame =1925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000370025634766
INFO:root:frame =1926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000334024429321
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.984863333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000424146652222
INFO:root:training error  = [[  1.20592362e-03]
 [  1.72271032e-03]
 [  7.31425680e-05]
 [  5.23179024e-03]
 [  4.67281303e+01]
 [  4.60790672e+01]
 [  4.75182152e+01]
 [  1.60830241e-04]
 [  2.18904577e-02]
 [  4.75182152e+01]
 [  4.80498485e-02]
 [  4.65802269e+01]
 [  1.72271032e-03]
 [  1.63966734e-02]
 [  1.72271032e-03]
 [  1.37373130e-03]]
DEBUG:root:training time = %d0.213032
INFO:root:frame =1929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000379085540771
INFO:root:frame =1930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000243902206421
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.984831666667
DEBUG:root: dqn, choose action rondomly, need time 0.000197
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000184059143066
INFO:root:frame =1933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =1934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411987304688
DEBUG:root: save sample needs time = 0.000249147415161
INFO:root:random_action_porb = 0.9848
DEBUG:root: dqn, choose action rondomly, need time 0.000275999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000407934188843
INFO:root:training error  = [[  7.00487231e-04]
 [  3.31008341e-03]
 [  2.09127646e-02]
 [  1.86452381e-02]
 [  2.77890805e-02]
 [  4.53927917e+01]
 [  2.09127646e-02]
 [  4.66098137e+01]
 [  6.18692078e-02]
 [  6.18692078e-02]
 [  2.77890805e-02]
 [  3.79877351e-03]
 [  5.70350140e-02]
 [  1.42346323e-02]
 [  1.89289625e-03]
 [  5.41636981e-02]]
DEBUG:root:training time = %d0.230466
INFO:root:frame =1937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =1938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436782836914
INFO:root:frame = 1939 State into memory, numbers recorded 50 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000562906265259
INFO:root:random_action_porb = 0.984768333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1940current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =1941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =1942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame = 1943 State into memory, numbers recorded 51 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000584125518799
INFO:root:random_action_porb = 0.984736666667
DEBUG:root: dqn, choose action rondomly, need time 0.000353999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1944current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000389814376831
INFO:root:training error  = [[  3.72742750e-02]
 [  4.46958885e+01]
 [  4.45901789e-02]
 [  2.95029804e-02]
 [  4.38405380e+01]
 [  2.04389537e-04]
 [  4.42016907e+01]
 [  4.50086403e+01]
 [  4.00654459e-03]
 [  2.95029804e-02]
 [  2.86919493e-02]
 [  4.50086403e+01]
 [  3.42940204e-02]
 [  1.67413093e-02]
 [  1.62982405e-03]
 [  2.77218036e-02]]
DEBUG:root:training time = %d0.217464
INFO:root:frame =1945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =1946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000366926193237
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.984705
DEBUG:root: dqn, choose action rondomly, need time 0.000166999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000158786773682
INFO:root:frame =1949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =1950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.984673333333
DEBUG:root: dqn, choose action rondomly, need time 0.000325999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[  4.45200233e+01]
 [  4.41029739e+01]
 [  1.84709225e-02]
 [  4.35770340e+01]
 [  1.90831779e-03]
 [  7.85417110e-03]
 [  1.55450571e-02]
 [  4.41743061e-03]
 [  2.37953328e-02]
 [  4.75976238e-04]
 [  4.64048423e-02]
 [  7.08679145e-04]
 [  1.55450571e-02]
 [  7.08679145e-04]
 [  4.38036537e+01]
 [  4.47982063e+01]]
DEBUG:root:training time = %d0.220229
INFO:root:frame =1953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =1954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.984641666667
INFO:root:dqn select action Tensor("ArgMax_2:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012832
INFO:root:action choosen by dqn [0]
INFO:root:frame =1956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =1957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame =1958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.98461
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.71320972e-02]
 [  4.54718322e-02]
 [  4.10837866e-02]
 [  3.55017819e-02]
 [  4.10837866e-02]
 [  1.97732076e-02]
 [  4.71320972e-02]
 [  1.07372928e+00]
 [  4.90353617e-04]
 [  7.35852588e-03]
 [  4.32159119e+01]
 [  2.26661423e-03]
 [  4.66237627e-02]
 [  1.97732076e-02]
 [  1.36856765e-01]
 [  4.17961702e-02]]
DEBUG:root:training time = %d0.224905
INFO:root:frame =1961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =1962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288963317871
DEBUG:root: save sample needs time = 0.000179052352905
INFO:root:random_action_porb = 0.984578333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000337839126587
INFO:root:frame =1965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =1966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.984546666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:training error  = [[  2.51440069e-04]
 [  2.49920599e-02]
 [  9.29222628e-03]
 [  7.22082481e-02]
 [  7.75936013e-03]
 [  5.21639138e-02]
 [  6.67238655e-03]
 [  5.25511010e-03]
 [  6.87445863e-04]
 [  4.23567200e+01]
 [  3.42209381e-03]
 [  7.22082481e-02]
 [  1.41641498e-02]
 [  3.67565714e-02]
 [  7.53214397e-03]
 [  3.67565714e-02]]
DEBUG:root:training time = %d0.216045
INFO:root:frame =1969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =1970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000223159790039
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.984515
DEBUG:root: dqn, choose action rondomly, need time 0.000178999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162839889526
INFO:root:frame =1973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00105381011963
INFO:root:frame =1974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.984483333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.89509697e-03]
 [  3.37166153e-03]
 [  4.25254784e+01]
 [  4.18434753e+01]
 [  4.23296727e-02]
 [  4.18434753e+01]
 [  9.88922000e-01]
 [  1.88966386e-03]
 [  4.25254784e+01]
 [  4.23296727e-02]
 [  4.18434753e+01]
 [  4.25780525e+01]
 [  4.32868729e+01]
 [  4.25780525e+01]
 [  5.88136092e-02]
 [  1.13714496e-02]]
DEBUG:root:training time = %d0.234708
INFO:root:frame =1977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =1978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.984451666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =1981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =1982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000801086425781
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.98442
DEBUG:root: dqn, choose action rondomly, need time 0.000449999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000507116317749
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.66857054e-02]
 [  4.37763939e+01]
 [  4.02941018e-01]
 [  4.34786949e+01]
 [  4.24671478e+01]
 [  3.61028756e-03]
 [  3.31536657e-03]
 [  2.89538592e-01]
 [  1.74167939e-02]
 [  4.73393977e-01]
 [  1.33581441e-02]
 [  4.35670662e+01]
 [  4.35979614e+01]
 [  3.22369041e+01]
 [  1.20997652e-01]
 [  1.84712035e-03]]
DEBUG:root:training time = %d0.206752
INFO:root:frame =1985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =1986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:random_action_porb = 0.984388333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =1989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =1990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.984356666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:training error  = [[  7.44105875e-03]
 [  4.28074875e+01]
 [  1.22139104e-01]
 [  2.25035638e-01]
 [  3.53606977e-02]
 [  4.16550827e+01]
 [  2.91859172e-02]
 [  2.25035638e-01]
 [  4.19955368e+01]
 [  7.44105875e-03]
 [  1.80239484e-01]
 [  7.10050901e-03]
 [  7.10050901e-03]
 [  1.63153440e-01]
 [  1.18887715e-01]
 [  4.21019707e+01]]
DEBUG:root:training time = %d0.218633
INFO:root:frame =1993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224828720093
INFO:root:frame =1994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249147415161
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.984325
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =1997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =1998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436782836914
DEBUG:root: save sample needs time = 0.000218868255615
DEBUG:root:one frame running time = 0.0061
DEBUG:root:total training time = 21.610109
INFO:root:frame num = 2000 frame round: 0
INFO:root:random_action_porb = 0.984293333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.70836356e-02]
 [  4.11504669e+01]
 [  4.11181870e+01]
 [  4.11181870e+01]
 [  4.23452377e+01]
 [  2.85297298e+01]
 [  2.65082493e-02]
 [  4.07500038e+01]
 [  4.10198441e+01]
 [  4.11181870e+01]
 [  4.00145073e+01]
 [  3.91944084e+01]
 [  4.11504669e+01]
 [  8.67691338e-02]
 [  3.92848892e+01]
 [  2.85297298e+01]]
DEBUG:root:training time = %d0.211974
INFO:root:frame =2001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =2002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324010848999
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.984261666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =2005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =2006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.98423
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000379800796509
INFO:root:training error  = [[  3.93190117e+01]
 [  2.08026916e-02]
 [  3.87746544e+01]
 [  1.39646535e-03]
 [  3.93190117e+01]
 [  4.89808172e-02]
 [  3.97430916e+01]
 [  3.97430916e+01]
 [  3.89371067e-02]
 [  1.95771549e-03]
 [  3.97276618e-02]
 [  2.81652063e-03]
 [  8.78813444e-04]
 [  3.84494247e+01]
 [  3.71364341e-03]
 [  1.95771549e-03]]
DEBUG:root:training time = %d0.226098
INFO:root:frame =2009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =2010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.984198333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000346183776855
INFO:root:frame =2013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =2014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.984166666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.89408340e+01]
 [  1.31736568e-03]
 [  1.31736568e-03]
 [  1.41840518e-01]
 [  3.84678993e+01]
 [  2.74003735e+01]
 [  3.95932999e+01]
 [  3.78268814e+01]
 [  1.65488105e-03]
 [  3.67634697e+01]
 [  3.82324486e+01]
 [  3.78901978e+01]
 [  2.74003735e+01]
 [  1.21658146e-02]
 [  7.75414482e-02]
 [  4.93132770e-02]]
DEBUG:root:training time = %d0.221149
INFO:root:frame =2017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =2018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root:random_action_porb = 0.984135
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000361919403076
INFO:root:frame =2021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =2022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000529050827026
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.984103333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342845916748
INFO:root:training error  = [[  1.13129131e-01]
 [  8.65961239e-03]
 [  9.51366033e-03]
 [  4.80210129e-03]
 [  2.00318992e-02]
 [  3.59603157e+01]
 [  2.84067634e-03]
 [  1.34025946e-01]
 [  1.32313911e-02]
 [  3.63075371e+01]
 [  1.45270556e-01]
 [  3.70108032e+01]
 [  1.25914132e-02]
 [  1.42826796e-01]
 [  3.63075371e+01]
 [  1.25914132e-02]]
DEBUG:root:training time = %d0.217782
INFO:root:frame =2025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame =2026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00034499168396
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.984071666667
DEBUG:root: dqn, choose action rondomly, need time 0.000168000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:frame =2029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =2030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.98404
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.05613200e-03]
 [  1.95471607e-02]
 [  1.59206742e-03]
 [  3.67493744e+01]
 [  6.94214646e-03]
 [  2.18920056e-02]
 [  2.51646175e+01]
 [  1.44041807e-03]
 [  2.99374829e-03]
 [  3.51320610e+01]
 [  3.51320610e+01]
 [  6.94214646e-03]
 [  3.53444176e+01]
 [  1.53091578e-02]
 [  4.16849479e-02]
 [  1.53091578e-02]]
DEBUG:root:training time = %d0.215146
INFO:root:frame =2033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =2034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000385999679565
INFO:root:frame = 2035 State into memory, numbers recorded 52 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00056791305542
INFO:root:random_action_porb = 0.984008333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2036current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000396013259888
INFO:root:frame =2037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =2038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:random_action_porb = 0.983976666667
DEBUG:root: dqn, choose action rondomly, need time 0.000495999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:training error  = [[  3.57722118e-02]
 [  2.01428682e-02]
 [  6.53769076e-02]
 [  1.39840385e-02]
 [  3.41656265e+01]
 [  1.80376414e-02]
 [  4.68229093e-02]
 [  7.71714970e-02]
 [  3.57622643e+01]
 [  1.60387979e-04]
 [  3.49971237e+01]
 [  3.00168502e-03]
 [  2.33323853e-02]
 [  1.72459912e-02]
 [  9.24472511e-02]
 [  9.43729375e-03]]
DEBUG:root:training time = %d0.216205
INFO:root:frame =2041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root:frame =2042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000280141830444
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.983945
DEBUG:root: dqn, choose action rondomly, need time 0.000372000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =2045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =2046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.983913333333
DEBUG:root: dqn, choose action rondomly, need time 0.000558999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[  5.85797168e-02]
 [  9.98107158e-03]
 [  1.04309861e-02]
 [  3.44868889e+01]
 [  3.46602402e+01]
 [  1.00701991e-02]
 [  5.85797168e-02]
 [  5.98139688e-02]
 [  3.39647751e+01]
 [  7.51198679e-02]
 [  3.12723666e-02]
 [  6.14067577e-02]
 [  7.78278941e-03]
 [  3.48374863e+01]
 [  3.44868889e+01]
 [  7.41598532e-02]]
DEBUG:root:training time = %d0.201745
INFO:root:frame =2049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =2050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462770462036
DEBUG:root: save sample needs time = 0.000185012817383
INFO:root:random_action_porb = 0.983881666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =2053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430822372437
INFO:root:frame =2054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.98385
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.19554596e-02]
 [  1.95937883e-02]
 [  2.96586994e-02]
 [  6.12310786e-03]
 [  1.23536813e+00]
 [  3.48871727e+01]
 [  1.61865726e-03]
 [  2.75432365e-03]
 [  3.32134819e+01]
 [  1.34981396e-02]
 [  3.47872887e+01]
 [  3.37406960e+01]
 [  3.37033195e+01]
 [  7.11118653e-02]
 [  4.00308194e-03]
 [  3.40728909e-02]]
DEBUG:root:training time = %d0.213699
INFO:root:frame =2057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =2058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000284194946289
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.983818333333
DEBUG:root: dqn, choose action rondomly, need time 0.000167000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:frame =2061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449180603027
INFO:root:frame =2062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.983786666667
DEBUG:root: dqn, choose action rondomly, need time 0.000503999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.54383425e-02]
 [  8.37373063e-02]
 [  9.09726843e-02]
 [  3.33277206e+01]
 [  3.42764511e+01]
 [  2.36694565e+01]
 [  2.50319634e-02]
 [  8.06142464e-02]
 [  7.13124052e-02]
 [  4.01509088e-03]
 [  3.35170212e+01]
 [  2.28229398e-03]
 [  3.35978012e+01]
 [  3.27098389e+01]
 [  6.82333857e-02]
 [  2.50319634e-02]]
DEBUG:root:training time = %d0.212015
INFO:root:frame =2065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258207321167
INFO:root:frame =2066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265836715698
DEBUG:root: save sample needs time = 0.000201225280762
INFO:root:random_action_porb = 0.983755
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =2069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =2070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame = 2071 State into memory, numbers recorded 53 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000639200210571
INFO:root:random_action_porb = 0.983723333333
DEBUG:root: dqn, choose action rondomly, need time 0.000371999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2072current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.35530055e-03]
 [  5.48995696e-02]
 [  6.94395415e-03]
 [  4.79125232e-03]
 [  1.42231911e-01]
 [  4.38719019e-02]
 [  2.26051521e+01]
 [  1.42231911e-01]
 [  1.42231911e-01]
 [  1.16419636e-01]
 [  2.26051521e+01]
 [  3.19476967e+01]
 [  1.42231911e-01]
 [  4.38719019e-02]
 [  3.30544281e+01]
 [  3.28307266e+01]]
DEBUG:root:training time = %d0.217356
INFO:root:frame =2073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =2074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame = 2075 State into memory, numbers recorded 54 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000601053237915
INFO:root:random_action_porb = 0.983691666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2076current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =2077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =2078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.98366
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[  4.18621441e-03]
 [  1.97079908e-02]
 [  2.38906629e-02]
 [  1.06827997e-01]
 [  4.00252938e-02]
 [  4.00252938e-02]
 [  7.32077286e-03]
 [  3.11304722e+01]
 [  3.14981461e+01]
 [  2.41622515e-02]
 [  1.02092270e-02]
 [  4.21030112e-02]
 [  6.33283108e-02]
 [  4.21030112e-02]
 [  5.32885424e-05]
 [  5.57619929e-02]]
DEBUG:root:training time = %d0.221164
INFO:root:frame =2081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:frame =2082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.983628333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =2085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =2086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.983596666667
DEBUG:root: dqn, choose action rondomly, need time 0.000328
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.22787247e+01]
 [  7.06264935e-03]
 [  1.23419026e-02]
 [  2.96627637e-02]
 [  1.12034965e+00]
 [  3.15074921e+01]
 [  7.06561469e-03]
 [  1.70586891e-02]
 [  4.73408843e-04]
 [  9.67983447e-04]
 [  8.50926898e-03]
 [  5.33788763e-02]
 [  9.67983447e-04]
 [  1.12034965e+00]
 [  3.11887798e+01]
 [  3.13829460e+01]]
DEBUG:root:training time = %d0.187915
INFO:root:frame =2089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =2090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000574827194214
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:random_action_porb = 0.983565
DEBUG:root: dqn, choose action rondomly, need time 0.000174000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000146865844727
INFO:root:frame =2093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00039005279541
INFO:root:frame =2094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000407934188843
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:random_action_porb = 0.983533333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:training error  = [[  3.08952560e+01]
 [  3.06564693e+01]
 [  1.96747482e-03]
 [  2.74214465e-02]
 [  2.02789214e-02]
 [  5.27246797e-04]
 [  3.09200802e+01]
 [  6.23519951e-03]
 [  6.67382032e-02]
 [  1.37586826e-02]
 [  2.75338832e-02]
 [  3.08152905e+01]
 [  2.74214465e-02]
 [  1.08704148e-02]
 [  2.63920408e-02]
 [  9.76493210e-02]]
DEBUG:root:training time = %d0.187506
INFO:root:frame =2097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =2098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275850296021
DEBUG:root: save sample needs time = 0.000546932220459
INFO:root:random_action_porb = 0.983501666667
DEBUG:root: dqn, choose action rondomly, need time 0.000233999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =2101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =2102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475168228149
DEBUG:root: save sample needs time = 0.000136137008667
INFO:root:random_action_porb = 0.98347
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.55476823e-02]
 [  8.76572207e-02]
 [  8.59719813e-02]
 [  3.95239405e-02]
 [  7.02762883e-03]
 [  3.03944054e+01]
 [  4.18970101e-02]
 [  8.84982944e-03]
 [  7.39874179e-03]
 [  1.07078347e-02]
 [  3.00195770e+01]
 [  7.02762883e-03]
 [  3.09575768e+01]
 [  2.04113083e+01]
 [  1.22166742e-02]
 [  8.76572207e-02]]
DEBUG:root:training time = %d0.212674
INFO:root:frame =2105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270128250122
INFO:root:frame =2106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000372886657715
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.983438333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =2109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441789627075
INFO:root:frame =2110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.983406666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.97737110e-03]
 [  1.13190901e+00]
 [  2.94425125e+01]
 [  5.13666496e-03]
 [  3.09496112e-02]
 [  3.06967888e-02]
 [  1.14645950e-01]
 [  3.01721382e+01]
 [  3.00057487e+01]
 [  3.04542675e+01]
 [  2.32340135e-02]
 [  1.14645950e-01]
 [  4.84513752e-02]
 [  2.96210938e+01]
 [  7.69154262e-03]
 [  2.06329155e+01]]
DEBUG:root:training time = %d0.225038
INFO:root:frame =2113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =2114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000310897827148
DEBUG:root: save sample needs time = 0.00011420249939
INFO:root:random_action_porb = 0.983375
DEBUG:root: dqn, choose action rondomly, need time 0.000293000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320196151733
INFO:root:frame =2117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =2118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00048303604126
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:random_action_porb = 0.983343333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.05368137e+01]
 [  2.96606045e+01]
 [  2.48433545e-01]
 [  1.98380947e-01]
 [  3.05368137e+01]
 [  2.96506176e+01]
 [  3.21917497e-02]
 [  2.22040694e-02]
 [  5.08386306e-02]
 [  2.96506176e+01]
 [  1.79664660e-02]
 [  3.22469976e-04]
 [  3.02980328e+01]
 [  1.62530148e+00]
 [  2.99059544e+01]
 [  3.15376632e-02]]
DEBUG:root:training time = %d0.236808
INFO:root:frame =2121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =2122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000300884246826
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:random_action_porb = 0.983311666667
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =2125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =2126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000197172164917
INFO:root:random_action_porb = 0.98328
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root:training error  = [[  1.65934071e-05]
 [  2.81248379e+01]
 [  2.81248379e+01]
 [  8.19221362e-02]
 [  7.22872317e-02]
 [  3.11939102e-02]
 [  1.09968334e-02]
 [  7.00466242e-03]
 [  1.26555324e-01]
 [  8.27775672e-02]
 [  2.43821107e-02]
 [  2.92230854e+01]
 [  7.11431727e-03]
 [  2.87106342e+01]
 [  2.59469289e-07]
 [  2.89767742e+01]]
DEBUG:root:training time = %d0.201397
INFO:root:frame =2129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =2130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.983248333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =2133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =2134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.983216666667
DEBUG:root: dqn, choose action rondomly, need time 0.000280999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:training error  = [[  2.79139080e+01]
 [  2.73566856e+01]
 [  3.18133906e-02]
 [  2.72792511e+01]
 [  1.44616934e-02]
 [  2.79139080e+01]
 [  2.02518031e-02]
 [  2.76322994e+01]
 [  3.18133906e-02]
 [  2.69044973e-02]
 [  1.17165171e-01]
 [  3.57138272e-03]
 [  6.81483373e-02]
 [  9.87788010e-03]
 [  1.14059009e-01]
 [  1.71106700e-02]]
DEBUG:root:training time = %d0.211531
INFO:root:frame =2137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =2138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.983185
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root:frame =2141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =2142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.983153333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:training error  = [[  2.37553902e-02]
 [  3.61217223e-02]
 [  5.65558709e-02]
 [  3.07782572e-02]
 [  1.48572624e-01]
 [  2.78820116e-02]
 [  2.69361305e+01]
 [  1.45350859e-01]
 [  8.10750872e-02]
 [  2.72091389e+01]
 [  1.30507708e-01]
 [  2.23745331e-02]
 [  2.67630806e+01]
 [  2.62067719e+01]
 [  1.45416573e-01]
 [  8.19234271e-03]]
DEBUG:root:training time = %d0.207136
INFO:root:frame =2145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame =2146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame = 2147 State into memory, numbers recorded 55 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000538110733032
INFO:root:random_action_porb = 0.983121666667
DEBUG:root: dqn, choose action rondomly, need time 0.000323999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2148current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =2149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000428915023804
INFO:root:frame =2150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.98309
DEBUG:root: dqn, choose action rondomly, need time 0.000223999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312805175781
INFO:root:training error  = [[  2.71028767e+01]
 [  2.64774475e+01]
 [  2.58272552e+01]
 [  2.58272552e+01]
 [  8.74871947e-03]
 [  9.46052745e-03]
 [  7.17792809e-02]
 [  8.50722045e-02]
 [  2.68932686e+01]
 [  1.10243008e-01]
 [  2.60578175e+01]
 [  5.88127598e-02]
 [  2.56175232e+01]
 [  8.17542151e-02]
 [  9.60351899e-03]
 [  6.46766126e-02]]
DEBUG:root:training time = %d0.219417
INFO:root:frame =2153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =2154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247001647949
DEBUG:root: save sample needs time = 0.000110864639282
INFO:root:random_action_porb = 0.983058333333
DEBUG:root: dqn, choose action rondomly, need time 0.000177999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:frame =2157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =2158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.983026666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.55501595e+01]
 [  2.58214511e-02]
 [  3.23446020e-02]
 [  1.64833684e-02]
 [  1.60714895e-01]
 [  1.18453629e-01]
 [  2.61237106e+01]
 [  2.58563194e+01]
 [  1.24680325e-01]
 [  1.65087841e-02]
 [  2.64297371e+01]
 [  1.70970039e+01]
 [  5.36596775e-02]
 [  2.59850714e-02]
 [  1.58812478e-01]
 [  2.55562973e+01]]
DEBUG:root:training time = %d0.218091
INFO:root:frame =2161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =2162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
DEBUG:root: save sample needs time = 0.000150918960571
INFO:root:random_action_porb = 0.982995
DEBUG:root: dqn, choose action rondomly, need time 0.000201000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000167846679688
INFO:root:frame =2165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000518083572388
INFO:root:frame =2166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.982963333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:training error  = [[  1.02985814e-01]
 [  1.02985814e-01]
 [  4.86000627e-02]
 [  2.62590460e-02]
 [  4.77379337e-02]
 [  2.55853291e+01]
 [  2.62590460e-02]
 [  1.91728072e-03]
 [  2.62590460e-02]
 [  2.54466991e+01]
 [  3.76858786e-02]
 [  2.62590460e-02]
 [  2.52876492e+01]
 [  7.06768930e-02]
 [  2.71175411e-02]
 [  1.97827443e-01]]
DEBUG:root:training time = %d0.216927
INFO:root:frame =2169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000494956970215
INFO:root:frame =2170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.982931666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =2173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =2174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9829
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:training error  = [[  2.48840256e+01]
 [  2.47356186e+01]
 [  2.49148712e+01]
 [  5.47370166e-02]
 [  5.54386266e-02]
 [  1.81304500e-01]
 [  2.40012724e-02]
 [  1.81304500e-01]
 [  1.61229238e-01]
 [  5.19603752e-02]
 [  3.86483558e-02]
 [  1.56218410e-02]
 [  3.30781639e-02]
 [  2.44546261e+01]
 [  1.40591025e-01]
 [  5.54386266e-02]]
DEBUG:root:training time = %d0.231671
INFO:root:frame =2177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229835510254
INFO:root:frame =2178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240087509155
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.982868333333
DEBUG:root: dqn, choose action rondomly, need time 0.000278000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =2181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =2182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.982836666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:training error  = [[  2.32983418e+01]
 [  1.53364107e-01]
 [  3.08068320e-02]
 [  3.56243216e-02]
 [  1.67135876e-02]
 [  1.16937421e-01]
 [  2.36099987e+01]
 [  2.41684411e-02]
 [  6.65341765e-02]
 [  4.33245003e-02]
 [  1.36628710e-02]
 [  4.33245003e-02]
 [  1.67135876e-02]
 [  1.68695316e-01]
 [  4.11047451e-02]
 [  4.11047451e-02]]
DEBUG:root:training time = %d0.213154
INFO:root:frame =2185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =2186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame = 2187 State into memory, numbers recorded 56 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:random_action_porb = 0.982805
INFO:root:dqn select action Tensor("ArgMax_3:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.009388
INFO:root:action choosen by dqn [0]
INFO:root:frame =2188current_observation done, NOT record action [0], reward = 0
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =2189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =2190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.982773333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:training error  = [[  3.12188864e-02]
 [  2.36003380e+01]
 [  4.51547690e-02]
 [  2.27430744e+01]
 [  4.48583737e-02]
 [  5.18706329e-02]
 [  1.54556498e-01]
 [  2.36003380e+01]
 [  9.07435827e-03]
 [  7.59767462e-03]
 [  2.24253426e+01]
 [  1.25385791e-01]
 [  4.20405120e-02]
 [  4.48681712e-02]
 [  3.65376659e-02]
 [  5.18706329e-02]]
DEBUG:root:training time = %d0.210365
INFO:root:frame =2193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =2194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.982741666667
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =2197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000423908233643
INFO:root:frame =2198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.98271
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:training error  = [[  8.06245431e-02]
 [  3.53178158e-02]
 [  3.81222032e-02]
 [  5.00477925e-02]
 [  3.82179730e-02]
 [  3.05292625e-02]
 [  3.81867513e-02]
 [  3.55419293e-02]
 [  3.20672579e-02]
 [  4.38623130e-02]
 [  6.45434707e-02]
 [  1.85920801e-02]
 [  2.29564724e+01]
 [  3.55419293e-02]
 [  2.29564724e+01]
 [  5.12376986e-02]]
DEBUG:root:training time = %d0.212545
INFO:root:frame =2201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:frame =2202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.982678333333
DEBUG:root: dqn, choose action rondomly, need time 0.000179000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000135183334351
INFO:root:frame =2205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:frame =2206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.982646666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[  2.31221294e+01]
 [  1.90631561e-02]
 [  1.45569528e-02]
 [  4.65453789e-02]
 [  2.26675625e+01]
 [  8.90708342e-02]
 [  1.30484104e-01]
 [  1.45569528e-02]
 [  3.80836688e-02]
 [  2.25255775e+01]
 [  2.31221294e+01]
 [  4.37582172e-02]
 [  6.12827670e-03]
 [  2.17815914e+01]
 [  2.25299187e+01]
 [  2.44058669e-02]]
DEBUG:root:training time = %d0.223774
INFO:root:frame =2209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =2210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.982615
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root:frame =2213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =2214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047779083252
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:random_action_porb = 0.982583333333
DEBUG:root: dqn, choose action rondomly, need time 0.000316000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[  9.80407819e-02]
 [  5.46740033e-02]
 [  1.57636479e-02]
 [  1.89224537e-03]
 [  3.00244708e-02]
 [  1.37838637e-02]
 [  1.18326224e-01]
 [  7.47745857e-02]
 [  1.82777256e-01]
 [  4.81170826e-02]
 [  3.00244708e-02]
 [  2.13470154e+01]
 [  5.94087616e-02]
 [  2.13470154e+01]
 [  2.10681763e+01]
 [  2.10681763e+01]]
DEBUG:root:training time = %d0.221999
INFO:root:frame =2217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =2218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000246047973633
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.982551666667
DEBUG:root: dqn, choose action rondomly, need time 0.000187999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000156164169312
INFO:root:frame =2221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =2222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000256061553955
DEBUG:root: save sample needs time = 0.000111818313599
INFO:root:random_action_porb = 0.98252
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:training error  = [[  1.46654863e-02]
 [  2.19931850e+01]
 [  2.14718781e+01]
 [  7.14980587e-02]
 [  7.14980587e-02]
 [  1.48855537e-01]
 [  2.08992481e+01]
 [  2.22544479e+01]
 [  1.83699250e-01]
 [  2.04100113e+01]
 [  3.91785875e-02]
 [  9.99696329e-02]
 [  3.44951823e-02]
 [  2.19738178e+01]
 [  9.99696329e-02]
 [  5.20664081e-02]]
DEBUG:root:training time = %d0.220923
INFO:root:frame =2225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =2226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.982488333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =2229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =2230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.982456666667
DEBUG:root: dqn, choose action rondomly, need time 0.000358000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:training error  = [[  2.03568459e+01]
 [  4.60771434e-02]
 [  2.07880270e-02]
 [  3.88491303e-02]
 [  1.11994959e-01]
 [  1.80969841e-03]
 [  1.46817148e-01]
 [  4.00281586e-02]
 [  2.07837238e+01]
 [  6.71237707e-02]
 [  2.02497253e+01]
 [  2.05159645e+01]
 [  3.88491303e-02]
 [  2.01922092e+01]
 [  9.07667801e-02]
 [  4.60771434e-02]]
DEBUG:root:training time = %d0.212332
INFO:root:frame =2233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =2234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000501871109009
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.982425
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029182434082
INFO:root:frame =2237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =2238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.982393333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:training error  = [[  1.36576323e-02]
 [  1.95078239e+01]
 [  1.99681797e+01]
 [  1.51394978e-01]
 [  1.82720184e-01]
 [  3.86638269e-02]
 [  1.93281097e+01]
 [  4.69505526e-02]
 [  4.32962179e-02]
 [  1.96976147e+01]
 [  2.07434330e+01]
 [  4.40878011e-02]
 [  4.65785116e-02]
 [  5.91568239e-02]
 [  4.65785116e-02]
 [  1.26441186e-02]]
DEBUG:root:training time = %d0.233434
INFO:root:frame =2241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =2242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.982361666667
DEBUG:root: dqn, choose action rondomly, need time 0.000271000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =2245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491142272949
INFO:root:frame =2246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.98233
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  0.28239959]
 [ 20.23008347]
 [ 20.23008347]
 [  0.02111712]
 [ 19.77325249]
 [  0.12592736]
 [ 20.35751724]
 [  0.21269797]
 [ 19.21014977]
 [  0.10964457]
 [  0.30069986]
 [  0.03431891]
 [ 20.35751724]
 [ 12.5096302 ]
 [  0.20512655]
 [  0.21269797]]
DEBUG:root:training time = %d0.214973
INFO:root:frame =2249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =2250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root:random_action_porb = 0.982298333333
DEBUG:root: dqn, choose action rondomly, need time 0.000174000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000155925750732
INFO:root:frame =2253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =2254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470876693726
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.982266666667
DEBUG:root: dqn, choose action rondomly, need time 0.000413000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.31960917]
 [  1.31960917]
 [  0.0570905 ]
 [ 18.16048241]
 [  0.06811535]
 [  0.05383091]
 [  1.31960917]
 [  0.06824958]
 [  0.04602721]
 [  0.0836393 ]
 [ 18.04960442]
 [  0.03028082]
 [  1.31960917]
 [  0.07638462]
 [ 18.17900276]
 [  0.02560033]]
DEBUG:root:training time = %d0.206236
INFO:root:frame =2257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =2258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:random_action_porb = 0.982235
DEBUG:root: dqn, choose action rondomly, need time 0.000482000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =2261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =2262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000417947769165
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.982203333333
DEBUG:root: dqn, choose action rondomly, need time 0.000266
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:training error  = [[ 18.4070816 ]
 [  0.13512605]
 [  0.05359353]
 [  0.0470918 ]
 [  0.0965263 ]
 [  0.02896808]
 [  0.04556384]
 [  0.05468984]
 [ 18.40251732]
 [  0.10716951]
 [  0.14390494]
 [  0.04191429]
 [ 18.03034019]
 [  0.04556384]
 [  0.10138943]
 [ 17.71741676]]
DEBUG:root:training time = %d0.211159
INFO:root:frame =2265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =2266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000451803207397
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.982171666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =2269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =2270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000147104263306
INFO:root:random_action_porb = 0.98214
DEBUG:root: dqn, choose action rondomly, need time 0.000319999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.72030373e+01]
 [  7.74006322e-02]
 [  7.64198154e-02]
 [  8.44508931e-02]
 [  6.69136718e-02]
 [  7.54660740e-02]
 [  1.76658421e+01]
 [  1.33271122e+00]
 [  4.89216298e-02]
 [  7.16080070e-02]
 [  1.69040375e+01]
 [  1.82009430e+01]
 [  7.65516832e-02]
 [  1.00251764e-01]
 [  1.33176725e-02]
 [  1.72030373e+01]]
DEBUG:root:training time = %d0.225399
INFO:root:frame =2273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =2274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.982108333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =2277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =2278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.982076666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.54269922e-01]
 [  1.96152329e-01]
 [  1.52860396e-02]
 [  1.71366215e+01]
 [  1.72398955e-01]
 [  1.78532104e+01]
 [  2.35553216e-02]
 [  2.82530129e-01]
 [  1.71863461e+01]
 [  1.78868732e+01]
 [  1.71863461e+01]
 [  2.61906292e-02]
 [  1.78532104e+01]
 [  1.67759953e+01]
 [  1.25428349e-01]
 [  1.86322761e+00]]
DEBUG:root:training time = %d0.2139
INFO:root:frame =2281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =2282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000507116317749
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.982045
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =2285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =2286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.982013333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.80713844e-02]
 [  1.39793551e+00]
 [  4.62777764e-02]
 [  6.16285391e-03]
 [  1.62054005e+01]
 [  1.69797268e+01]
 [  1.17607087e-01]
 [  1.20324053e-01]
 [  1.12160660e-01]
 [  5.15253171e-02]
 [  8.63974020e-02]
 [  9.83892679e-02]
 [  1.62665958e+01]
 [  1.35546878e-01]
 [  1.65458755e+01]
 [  3.07886731e-02]]
DEBUG:root:training time = %d0.226825
INFO:root:frame =2289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000369071960449
INFO:root:frame =2290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.981981666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =2293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =2294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.98195
INFO:root:dqn select action Tensor("ArgMax_4:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.009175
INFO:root:action choosen by dqn [0]
INFO:root:frame =2296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:training error  = [[  0.0338054 ]
 [ 16.29986191]
 [  0.08268663]
 [  0.16043544]
 [  0.17784919]
 [  0.18273118]
 [  0.07334872]
 [ 16.98001099]
 [ 15.79223251]
 [  0.19494788]
 [ 15.67770481]
 [  0.03790967]
 [  0.14973253]
 [  0.10551673]
 [  0.02602675]
 [  0.14962018]]
DEBUG:root:training time = %d0.22134
INFO:root:frame =2297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame =2298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.981918333333
DEBUG:root: dqn, choose action rondomly, need time 0.000203999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:frame =2301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =2302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.981886666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332832336426
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.38108885]
 [ 14.77518749]
 [  0.05893748]
 [  0.08175469]
 [ 14.79467201]
 [ 15.43464756]
 [  0.13179888]
 [  0.05551533]
 [ 15.42670441]
 [  0.09252846]
 [ 15.08831787]
 [  8.51862144]
 [  0.07128465]
 [ 15.11057091]
 [ 15.14216709]
 [  1.38108885]]
DEBUG:root:training time = %d0.230218
INFO:root:frame =2305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =2306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.981855
DEBUG:root: dqn, choose action rondomly, need time 0.000373999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =2309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000481843948364
INFO:root:frame =2310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.981823333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000392913818359
INFO:root:training error  = [[  0.23772594]
 [ 15.27784443]
 [  0.14227597]
 [  0.13132343]
 [  0.05783553]
 [ 14.84728432]
 [ 14.72139168]
 [  0.05594828]
 [  0.06511592]
 [  0.07716004]
 [  0.03638424]
 [  0.03841912]
 [  0.03185304]
 [  0.03964699]
 [  0.15904744]
 [  0.18918948]]
DEBUG:root:training time = %d0.210844
INFO:root:frame =2313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =2314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046181678772
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.981791666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =2317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =2318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.98176
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:training error  = [[ 14.40970516]
 [  0.10782535]
 [  0.13562888]
 [  0.09982194]
 [  0.04060607]
 [ 14.65954494]
 [ 14.7224493 ]
 [  0.12094926]
 [  0.06886134]
 [ 14.90899658]
 [  0.02272619]
 [  0.12094926]
 [  0.09617212]
 [ 14.7224493 ]
 [  0.15769786]
 [ 14.0258255 ]]
DEBUG:root:training time = %d0.213582
INFO:root:frame =2321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =2322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000244855880737
DEBUG:root: save sample needs time = 0.000117778778076
INFO:root:random_action_porb = 0.981728333333
DEBUG:root: dqn, choose action rondomly, need time 0.000178999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000166893005371
INFO:root:frame =2325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000260829925537
INFO:root:frame =2326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.981696666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304222106934
INFO:root:training error  = [[  0.01920266]
 [  0.02787755]
 [  0.06381408]
 [  0.04343056]
 [ 14.05076313]
 [ 13.7901659 ]
 [ 14.40707874]
 [  0.13951106]
 [  0.08835036]
 [ 13.20051956]
 [  0.06938927]
 [ 13.734972  ]
 [  0.0966247 ]
 [  0.0422012 ]
 [  0.06571461]
 [ 14.11866379]]
DEBUG:root:training time = %d0.195427
INFO:root:frame =2329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =2330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root:random_action_porb = 0.981665
DEBUG:root: dqn, choose action rondomly, need time 0.000209000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =2333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =2334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.981633333333
DEBUG:root: dqn, choose action rondomly, need time 0.000418999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:training error  = [[  0.07086425]
 [ 14.20758247]
 [  0.05292315]
 [  0.04410933]
 [  0.0732115 ]
 [  0.14836419]
 [  0.08664299]
 [  0.06351246]
 [  0.0732115 ]
 [ 13.47072983]
 [  0.07086425]
 [  0.05292315]
 [  0.15344161]
 [  0.13783181]
 [ 13.01098633]
 [  0.07035577]]
DEBUG:root:training time = %d0.218636
INFO:root:frame =2337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =2338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.981601666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =2341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000408887863159
INFO:root:frame =2342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.98157
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336170196533
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  0.06512882]
 [  0.12123101]
 [ 12.7554884 ]
 [ 12.44271564]
 [  0.06492272]
 [  0.10612541]
 [  1.42553747]
 [ 12.63800144]
 [  0.06492272]
 [  0.06173441]
 [ 13.13356686]
 [  0.06512882]
 [  0.06634502]
 [  0.09583732]
 [ 12.96777153]
 [  0.0634196 ]]
DEBUG:root:training time = %d0.218808
INFO:root:frame =2345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =2346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.981538333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =2349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =2350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame = 2351 State into memory, numbers recorded 57 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00054407119751
INFO:root:random_action_porb = 0.981506666667
DEBUG:root: dqn, choose action rondomly, need time 0.000307999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2352current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[  2.89152772e-03]
 [  6.42610341e-02]
 [  3.48872058e-02]
 [  2.40387723e-01]
 [  3.52407992e-01]
 [  2.12806910e-02]
 [  3.75147432e-01]
 [  1.34027815e+01]
 [  3.92622575e-02]
 [  3.21285129e-02]
 [  3.48872058e-02]
 [  2.54945457e-02]
 [  1.28364639e+01]
 [  4.48068827e-02]
 [  1.32040834e+01]
 [  1.37732342e-01]]
DEBUG:root:training time = %d0.223417
INFO:root:frame =2353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =2354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.981475
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =2357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =2358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.981443333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.95983124]
 [  0.13531139]
 [  0.29385531]
 [ 12.96215725]
 [  0.09254035]
 [ 12.96215725]
 [  0.06110478]
 [  0.04812859]
 [  6.498878  ]
 [  0.23974453]
 [  0.12813057]
 [  0.10051555]
 [  0.13531139]
 [  0.13531139]
 [  0.06110478]
 [ 12.25588989]]
DEBUG:root:training time = %d0.20338
INFO:root:frame =2361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =2362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000329971313477
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:random_action_porb = 0.981411666667
DEBUG:root: dqn, choose action rondomly, need time 0.000385000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =2365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000364065170288
INFO:root:frame =2366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000746011734009
DEBUG:root: save sample needs time = 0.000157117843628
INFO:root:random_action_porb = 0.98138
DEBUG:root: dqn, choose action rondomly, need time 0.000251999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:training error  = [[  0.09970898]
 [  0.10848869]
 [ 11.94581413]
 [ 12.2331028 ]
 [  0.04511374]
 [ 11.94056034]
 [  0.09970898]
 [  0.17600055]
 [ 11.46911812]
 [ 11.97956085]
 [ 11.42412663]
 [ 12.70398712]
 [  0.07784355]
 [  0.09641715]
 [ 11.90867805]
 [ 11.94804859]]
DEBUG:root:training time = %d0.20625
INFO:root:frame =2369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =2370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000567197799683
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.981348333333
DEBUG:root: dqn, choose action rondomly, need time 0.000187000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =2373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =2374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.981316666667
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:training error  = [[  0.28024   ]
 [ 11.16575813]
 [ 10.84946632]
 [  0.11710332]
 [ 11.34300327]
 [  0.05088407]
 [  0.14541839]
 [ 10.48999596]
 [  0.07270391]
 [ 12.10485554]
 [  0.07270391]
 [  0.05527841]
 [ 11.04934311]
 [  0.14416753]
 [  0.10996311]
 [  0.0607947 ]]
DEBUG:root:training time = %d0.214002
INFO:root:frame =2377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =2378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.981285
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =2381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =2382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000131845474243
INFO:root:random_action_porb = 0.981253333333
DEBUG:root: dqn, choose action rondomly, need time 0.000658000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000422954559326
INFO:root:training error  = [[  0.22339717]
 [ 11.86461926]
 [ 11.31325817]
 [  0.36137965]
 [ 11.86461926]
 [ 11.08559036]
 [ 10.9920454 ]
 [  0.22802442]
 [  0.26124105]
 [  0.04609393]
 [  0.21433881]
 [  0.30502421]
 [  0.04609393]
 [  0.08332958]
 [  0.05215883]
 [  0.36137965]]
DEBUG:root:training time = %d0.196086
INFO:root:frame =2385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =2386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000389099121094
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:random_action_porb = 0.981221666667
DEBUG:root: dqn, choose action rondomly, need time 0.000552999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =2389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =2390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.98119
DEBUG:root: dqn, choose action rondomly, need time 0.000376000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:training error  = [[  1.52332813e-01]
 [  1.50338709e-01]
 [  1.22693941e-01]
 [  2.00197563e-01]
 [  1.98174566e-01]
 [  4.69696056e-03]
 [  3.84263210e-02]
 [  1.05087996e+01]
 [  1.05092573e+01]
 [  2.06244171e-01]
 [  2.09614381e-01]
 [  7.57515132e-02]
 [  1.07131081e+01]
 [  1.98174566e-01]
 [  8.97665173e-02]
 [  1.90068856e-01]]
DEBUG:root:training time = %d0.208186
INFO:root:frame =2393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =2394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.981158333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root:frame =2397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root:frame =2398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.981126666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:training error  = [[ 10.06269646]
 [ 10.32681179]
 [  0.09821614]
 [  9.95266056]
 [  0.10828901]
 [  9.43518353]
 [  0.1077524 ]
 [  0.10022761]
 [  9.95266056]
 [  0.1077524 ]
 [  0.12213471]
 [  0.14497578]
 [  9.87059784]
 [  0.09677669]
 [  9.91632175]
 [  0.12213471]]
DEBUG:root:training time = %d0.219826
INFO:root:frame =2401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =2402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000322818756104
DEBUG:root: save sample needs time = 0.000150918960571
INFO:root:random_action_porb = 0.981095
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331163406372
INFO:root:frame =2405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:frame =2406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042200088501
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:random_action_porb = 0.981063333333
DEBUG:root: dqn, choose action rondomly, need time 0.000503999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:training error  = [[ 0.1726186 ]
 [ 0.10238211]
 [ 0.11442994]
 [ 8.95897961]
 [ 0.17173061]
 [ 0.05941574]
 [ 0.09482528]
 [ 0.11480705]
 [ 9.1633873 ]
 [ 0.11480705]
 [ 0.06586407]
 [ 0.11480705]
 [ 0.06288707]
 [ 9.73736286]
 [ 0.06435197]
 [ 9.15242577]]
DEBUG:root:training time = %d0.220388
INFO:root:frame =2409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =2410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000358104705811
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:random_action_porb = 0.981031666667
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:frame =2413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =2414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247001647949
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:random_action_porb = 0.981
DEBUG:root: dqn, choose action rondomly, need time 0.000164999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:training error  = [[ 0.10638467]
 [ 0.13457325]
 [ 0.07770339]
 [ 0.07770339]
 [ 0.06011587]
 [ 0.11366569]
 [ 0.03439032]
 [ 0.11082657]
 [ 0.08462988]
 [ 0.11622578]
 [ 0.10638467]
 [ 0.23250824]
 [ 0.12393237]
 [ 0.23112339]
 [ 0.11587425]
 [ 0.09276737]]
DEBUG:root:training time = %d0.219038
INFO:root:frame =2417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =2418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.980968333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000347852706909
INFO:root:frame =2421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000524997711182
INFO:root:frame =2422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.980936666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:training error  = [[ 0.06255246]
 [ 9.23251629]
 [ 8.38463116]
 [ 0.16234241]
 [ 0.04548438]
 [ 0.08475866]
 [ 0.2149366 ]
 [ 8.70958996]
 [ 8.54055023]
 [ 0.14001091]
 [ 0.06427699]
 [ 0.2149366 ]
 [ 9.01339722]
 [ 8.40202618]
 [ 0.10119215]
 [ 0.17959067]]
DEBUG:root:training time = %d0.237084
INFO:root:frame =2425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root:frame =2426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame = 2427 State into memory, numbers recorded 58 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000541210174561
INFO:root:random_action_porb = 0.980905
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2428current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =2429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =2430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.980873333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 8.75959301]
 [ 8.77594376]
 [ 0.17874417]
 [ 0.32072693]
 [ 0.11369977]
 [ 0.12450309]
 [ 8.40511703]
 [ 8.89395332]
 [ 0.14396228]
 [ 0.103448  ]
 [ 0.01029819]
 [ 0.32072693]
 [ 0.14900495]
 [ 0.11592588]
 [ 0.03440606]
 [ 0.07299658]]
DEBUG:root:training time = %d0.209924
INFO:root:frame =2433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274181365967
INFO:root:frame =2434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.0002281665802
INFO:root:random_action_porb = 0.980841666667
DEBUG:root: dqn, choose action rondomly, need time 0.000166999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =2437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =2438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:random_action_porb = 0.98081
DEBUG:root: dqn, choose action rondomly, need time 0.000226999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000385999679565
INFO:root:training error  = [[ 0.04532567]
 [ 8.43672657]
 [ 8.18026924]
 [ 0.06595368]
 [ 0.14598554]
 [ 0.10637503]
 [ 0.09063926]
 [ 0.09441342]
 [ 0.09517007]
 [ 7.98720694]
 [ 0.16926827]
 [ 0.06876703]
 [ 8.18026924]
 [ 0.07083176]
 [ 0.16513555]
 [ 0.0651618 ]]
DEBUG:root:training time = %d0.216141
INFO:root:frame =2441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000358104705811
INFO:root:frame =2442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000561952590942
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:random_action_porb = 0.980778333333
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000602960586548
INFO:root:frame =2445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =2446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000536918640137
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:random_action_porb = 0.980746666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:training error  = [[ 0.06525604]
 [ 0.01733762]
 [ 0.09070731]
 [ 0.25117534]
 [ 7.8722887 ]
 [ 0.05128456]
 [ 7.94042969]
 [ 0.18030308]
 [ 0.08319749]
 [ 0.12460777]
 [ 8.15591049]
 [ 7.47795391]
 [ 7.8722887 ]
 [ 7.91701078]
 [ 8.01194382]
 [ 0.08319749]]
DEBUG:root:training time = %d0.209059
INFO:root:frame =2449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =2450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:random_action_porb = 0.980715
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =2453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =2454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.980683333333
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.20650455]
 [ 7.578475  ]
 [ 7.81910419]
 [ 0.30144578]
 [ 0.09837999]
 [ 0.30110919]
 [ 0.09837999]
 [ 7.64748669]
 [ 7.34749413]
 [ 0.20650455]
 [ 1.56430292]
 [ 0.27102619]
 [ 7.81910419]
 [ 7.9650569 ]
 [ 0.0834166 ]
 [ 7.33520699]]
DEBUG:root:training time = %d0.218382
INFO:root:frame =2457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =2458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000327110290527
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:random_action_porb = 0.980651666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =2461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000586032867432
INFO:root:frame =2462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame = 2463 State into memory, numbers recorded 59 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.00090503692627
INFO:root:random_action_porb = 0.98062
DEBUG:root: dqn, choose action rondomly, need time 0.000232999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2464current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 7.04811478]
 [ 0.09667703]
 [ 6.89862061]
 [ 0.3069571 ]
 [ 0.12215104]
 [ 1.57002044]
 [ 0.189812  ]
 [ 0.3069571 ]
 [ 7.67500019]
 [ 0.12226473]
 [ 0.12519152]
 [ 0.3069571 ]
 [ 0.19142336]
 [ 6.69025946]
 [ 0.11836248]
 [ 0.11406279]]
DEBUG:root:training time = %d0.207957
INFO:root:frame =2465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:frame =2466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000385999679565
INFO:root:frame = 2467 State into memory, numbers recorded 60 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000671148300171
INFO:root:random_action_porb = 0.980588333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2468current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =2469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000451803207397
INFO:root:frame =2470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000253915786743
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.980556666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.1154967 ]
 [ 0.1572475 ]
 [ 6.83969021]
 [ 0.06827599]
 [ 0.14035904]
 [ 0.20728754]
 [ 6.53350306]
 [ 0.11564615]
 [ 0.26388231]
 [ 0.27581239]
 [ 0.06190395]
 [ 0.14619368]
 [ 1.83886385]
 [ 6.63579416]
 [ 0.06190395]
 [ 0.0863618 ]]
DEBUG:root:training time = %d0.217026
INFO:root:frame =2473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =2474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000416994094849
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.980525
DEBUG:root: dqn, choose action rondomly, need time 0.000189000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000141143798828
INFO:root:frame =2477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =2478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000127792358398
INFO:root:random_action_porb = 0.980493333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 6.13497019]
 [ 0.10982274]
 [ 2.28588462]
 [ 0.12550925]
 [ 0.15289912]
 [ 6.35903311]
 [ 0.32348731]
 [ 6.47504282]
 [ 6.229496  ]
 [ 0.07958914]
 [ 0.1366414 ]
 [ 0.12643805]
 [ 0.08187008]
 [ 0.32348731]
 [ 0.25371492]
 [ 0.15289912]]
DEBUG:root:training time = %d0.212304
INFO:root:frame =2481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =2482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame = 2483 State into memory, numbers recorded 61 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000535011291504
INFO:root:random_action_porb = 0.980461666667
DEBUG:root: dqn, choose action rondomly, need time 0.000264000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2484current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =2485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =2486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000201225280762
INFO:root:random_action_porb = 0.98043
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:training error  = [[ 0.1624162 ]
 [ 6.06965685]
 [ 0.09530193]
 [ 0.12940963]
 [ 6.00111103]
 [ 0.12940963]
 [ 5.31325054]
 [ 0.1068206 ]
 [ 0.16094369]
 [ 5.31325054]
 [ 6.64518452]
 [ 0.16094369]
 [ 0.18736975]
 [ 0.21704943]
 [ 0.1624162 ]
 [ 0.1624162 ]]
DEBUG:root:training time = %d0.207164
INFO:root:frame =2489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =2490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000339984893799
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.980398333333
DEBUG:root: dqn, choose action rondomly, need time 0.000271000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame =2493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =2494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229835510254
DEBUG:root: save sample needs time = 0.000188112258911
INFO:root:random_action_porb = 0.980366666667
DEBUG:root: dqn, choose action rondomly, need time 0.000577
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000471830368042
INFO:root:training error  = [[ 5.60176182]
 [ 0.1625369 ]
 [ 0.10661747]
 [ 5.37509775]
 [ 0.12261846]
 [ 0.20403868]
 [ 0.18598323]
 [ 0.02354793]
 [ 5.46507692]
 [ 5.64644289]
 [ 0.18598323]
 [ 5.72654533]
 [ 0.14088404]
 [ 5.68629313]
 [ 0.15137661]
 [ 0.1625369 ]]
DEBUG:root:training time = %d0.204329
INFO:root:frame =2497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:frame =2498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00197005271912
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.980335
DEBUG:root: dqn, choose action rondomly, need time 0.000191000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000176906585693
INFO:root:frame =2501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =2502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259160995483
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:random_action_porb = 0.980303333333
DEBUG:root: dqn, choose action rondomly, need time 0.000343000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5.30512238]
 [ 0.11520875]
 [ 0.26259497]
 [ 0.09954252]
 [ 0.16812021]
 [ 1.62324893]
 [ 0.09954252]
 [ 0.11520875]
 [ 0.37967771]
 [ 5.56841898]
 [ 5.69124937]
 [ 0.26544198]
 [ 0.24021895]
 [ 0.18672302]
 [ 0.21731965]
 [ 0.03603536]]
DEBUG:root:training time = %d0.219479
INFO:root:frame =2505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =2506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485897064209
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:random_action_porb = 0.980271666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =2509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =2510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.98024
DEBUG:root: dqn, choose action rondomly, need time 0.000328000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:training error  = [[ 0.14436094]
 [ 0.17519689]
 [ 4.9414835 ]
 [ 0.12973952]
 [ 0.15966722]
 [ 0.20308819]
 [ 4.9414835 ]
 [ 4.85547447]
 [ 4.65271902]
 [ 4.9414835 ]
 [ 0.11303605]
 [ 5.00689793]
 [ 0.13979545]
 [ 0.18018   ]
 [ 0.13979545]
 [ 0.06924327]]
DEBUG:root:training time = %d0.209079
INFO:root:frame =2513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =2514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485181808472
INFO:root:frame = 2515 State into memory, numbers recorded 62 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000539064407349
INFO:root:random_action_porb = 0.980208333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2516current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =2517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =2518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433206558228
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.980176666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:training error  = [[ 0.09347425]
 [ 0.09347425]
 [ 0.15471607]
 [ 0.27886394]
 [ 0.19145381]
 [ 0.13035099]
 [ 0.15471607]
 [ 0.15376212]
 [ 0.21671189]
 [ 0.11584147]
 [ 4.59202051]
 [ 4.93206263]
 [ 4.94683552]
 [ 0.17546085]
 [ 0.16163157]
 [ 0.08669479]]
DEBUG:root:training time = %d0.220068
INFO:root:frame =2521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:frame =2522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000221014022827
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.980145
DEBUG:root: dqn, choose action rondomly, need time 0.000161000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000125885009766
INFO:root:frame =2525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =2526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000495910644531
DEBUG:root: save sample needs time = 0.000171899795532
INFO:root:random_action_porb = 0.980113333333
DEBUG:root: dqn, choose action rondomly, need time 0.000255000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:training error  = [[ 0.12707196]
 [ 4.52542448]
 [ 0.09252208]
 [ 0.12398911]
 [ 0.13417192]
 [ 0.07168075]
 [ 0.09252208]
 [ 0.13016823]
 [ 0.15342723]
 [ 0.21840623]
 [ 4.11107779]
 [ 0.09767503]
 [ 4.16299486]
 [ 0.13417192]
 [ 4.08055973]
 [ 4.38771152]]
DEBUG:root:training time = %d0.190808
INFO:root:frame =2529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =2530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.980081666667
DEBUG:root: dqn, choose action rondomly, need time 0.000205000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =2533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =2534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229835510254
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:random_action_porb = 0.98005
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:training error  = [[ 0.12516993]
 [ 3.98140979]
 [ 0.05007585]
 [ 0.08000401]
 [ 4.29719257]
 [ 0.3040106 ]
 [ 4.19993019]
 [ 0.03189347]
 [ 0.14510508]
 [ 0.07582135]
 [ 0.07582135]
 [ 0.09325425]
 [ 0.17175432]
 [ 0.08736269]
 [ 0.09759814]
 [ 0.18426806]]
DEBUG:root:training time = %d0.226309
INFO:root:frame =2537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =2538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.980018333333
DEBUG:root: dqn, choose action rondomly, need time 0.000185000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000172138214111
INFO:root:frame =2541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =2542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481128692627
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:random_action_porb = 0.979986666667
DEBUG:root: dqn, choose action rondomly, need time 0.000570000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.76936197]
 [ 0.13165541]
 [ 3.99193597]
 [ 0.09659609]
 [ 0.16448744]
 [ 0.09682149]
 [ 0.0677522 ]
 [ 0.19196032]
 [ 4.01862574]
 [ 0.08704108]
 [ 4.07678652]
 [ 0.17245539]
 [ 0.17676355]
 [ 0.15090352]
 [ 1.67565703]
 [ 0.202693  ]]
DEBUG:root:training time = %d0.218487
INFO:root:frame =2545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =2546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000129222869873
INFO:root:random_action_porb = 0.979955
DEBUG:root: dqn, choose action rondomly, need time 0.000221000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000172138214111
INFO:root:frame =2549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =2550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000377893447876
DEBUG:root: save sample needs time = 0.00011682510376
INFO:root:random_action_porb = 0.979923333333
DEBUG:root: dqn, choose action rondomly, need time 0.000329000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:training error  = [[ 0.04454373]
 [ 0.06999968]
 [ 3.91560912]
 [ 3.91560912]
 [ 3.86938739]
 [ 0.38441759]
 [ 3.62969065]
 [ 0.17568623]
 [ 3.66139579]
 [ 0.07094932]
 [ 0.18340528]
 [ 0.13727385]
 [ 0.21558349]
 [ 0.26599109]
 [ 0.06999968]
 [ 0.18907896]]
DEBUG:root:training time = %d0.20214
INFO:root:frame =2553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =2554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.979891666667
DEBUG:root: dqn, choose action rondomly, need time 0.000307999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000356912612915
INFO:root:frame =2557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =2558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.97986
DEBUG:root: dqn, choose action rondomly, need time 0.000278999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:training error  = [[ 3.69390774]
 [ 0.32436281]
 [ 3.93322253]
 [ 0.3759256 ]
 [ 0.14302482]
 [ 3.35487986]
 [ 0.14909221]
 [ 0.13711983]
 [ 3.31585908]
 [ 0.14909221]
 [ 3.93322253]
 [ 0.28065866]
 [ 3.61817884]
 [ 0.15097354]
 [ 0.23192047]
 [ 0.23192047]]
DEBUG:root:training time = %d0.20245
INFO:root:frame =2561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =2562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.979828333333
DEBUG:root: dqn, choose action rondomly, need time 0.000329999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =2565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =2566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root:random_action_porb = 0.979796666667
DEBUG:root: dqn, choose action rondomly, need time 0.000433000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:training error  = [[ 0.18937391]
 [ 0.32483551]
 [ 0.17718801]
 [ 3.51615071]
 [ 3.04596996]
 [ 2.87328744]
 [ 0.16078381]
 [ 0.16055597]
 [ 0.19910456]
 [ 0.09508625]
 [ 0.14038764]
 [ 0.10714906]
 [ 0.09330929]
 [ 0.19910456]
 [ 3.51615071]
 [ 0.06388566]]
DEBUG:root:training time = %d0.214239
INFO:root:frame =2569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:frame =2570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000364065170288
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:random_action_porb = 0.979765
DEBUG:root: dqn, choose action rondomly, need time 0.000239999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:frame =2573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =2574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.979733333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:training error  = [[ 0.16283579]
 [ 2.75850368]
 [ 0.12515339]
 [ 3.12502027]
 [ 2.95520639]
 [ 0.19048777]
 [ 2.79985404]
 [ 0.25172865]
 [ 0.19447805]
 [ 0.12431405]
 [ 0.11447866]
 [ 0.24485828]
 [ 0.16709843]
 [ 0.15742378]
 [ 2.95021319]
 [ 2.79985404]]
DEBUG:root:training time = %d0.22638
INFO:root:frame =2577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:frame =2578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 0.000224828720093
INFO:root:random_action_porb = 0.979701666667
DEBUG:root: dqn, choose action rondomly, need time 0.000329999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =2581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000356912612915
INFO:root:frame =2582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000389099121094
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:random_action_porb = 0.97967
DEBUG:root: dqn, choose action rondomly, need time 0.000388999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:training error  = [[ 2.75063705]
 [ 2.79114318]
 [ 0.18987724]
 [ 2.30957961]
 [ 0.15070538]
 [ 0.26420575]
 [ 0.27759579]
 [ 0.23710722]
 [ 2.86321878]
 [ 2.60918379]
 [ 0.24601297]
 [ 0.16533984]
 [ 0.20083685]
 [ 2.84095407]
 [ 0.16533984]
 [ 0.15779747]]
DEBUG:root:training time = %d0.212402
INFO:root:frame =2585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237226486206
INFO:root:frame =2586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247001647949
DEBUG:root: save sample needs time = 0.000111818313599
INFO:root:random_action_porb = 0.979638333333
DEBUG:root: dqn, choose action rondomly, need time 0.000186999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000156879425049
INFO:root:frame =2589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =2590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.979606666667
INFO:root:dqn select action Tensor("ArgMax_5:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015411
INFO:root:action choosen by dqn [0]
INFO:root:frame =2592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.15513444]
 [ 2.59834576]
 [ 2.42425847]
 [ 0.17461218]
 [ 0.18865082]
 [ 2.39434648]
 [ 0.26026759]
 [ 0.18865082]
 [ 0.36056775]
 [ 0.15362005]
 [ 0.2097729 ]
 [ 0.21856269]
 [ 2.7516005 ]
 [ 0.36506152]
 [ 0.16465186]
 [ 2.7049582 ]]
DEBUG:root:training time = %d0.230773
INFO:root:frame =2593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =2594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000402927398682
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.979575
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355958938599
INFO:root:frame =2597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =2598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000420093536377
INFO:root:frame = 2599 State into memory, numbers recorded 63 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:random_action_porb = 0.979543333333
DEBUG:root: dqn, choose action rondomly, need time 0.000267999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2600current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.16703723]
 [ 0.19213544]
 [ 0.19849947]
 [ 2.39706397]
 [ 0.13329238]
 [ 0.14790371]
 [ 2.30853319]
 [ 2.46781516]
 [ 0.12203775]
 [ 2.07574725]
 [ 0.13751671]
 [ 0.15582389]
 [ 2.20968008]
 [ 0.19149847]
 [ 0.2295215 ]
 [ 0.14778124]]
DEBUG:root:training time = %d0.221591
INFO:root:frame =2601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =2602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame = 2603 State into memory, numbers recorded 64 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.00073504447937
INFO:root:random_action_porb = 0.979511666667
DEBUG:root: dqn, choose action rondomly, need time 0.000212000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2604current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =2605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:frame =2606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000507116317749
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.97948
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.20333238]
 [ 0.21697657]
 [ 2.02082825]
 [ 0.21697657]
 [ 0.13671085]
 [ 0.12359284]
 [ 0.22772714]
 [ 0.18365245]
 [ 1.92271113]
 [ 0.24251428]
 [ 0.24251428]
 [ 0.12283428]
 [ 1.75975895]
 [ 0.16036536]
 [ 2.13217521]
 [ 0.13671085]]
DEBUG:root:training time = %d0.213298
INFO:root:frame =2609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =2610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482797622681
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:random_action_porb = 0.979448333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =2613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =2614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.979416666667
DEBUG:root: dqn, choose action rondomly, need time 0.000183
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:training error  = [[ 1.78634107]
 [ 0.10094474]
 [ 0.12765668]
 [ 0.16211464]
 [ 0.13468698]
 [ 1.78286302]
 [ 0.11610876]
 [ 2.01599526]
 [ 0.11610876]
 [ 0.17977136]
 [ 1.78286302]
 [ 1.78634107]
 [ 0.16450097]
 [ 0.23388754]
 [ 0.05547995]
 [ 0.25110129]]
DEBUG:root:training time = %d0.21552
INFO:root:frame =2617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root:frame =2618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000307083129883
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.979385
DEBUG:root: dqn, choose action rondomly, need time 0.000246000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =2621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000508785247803
INFO:root:frame =2622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000380039215088
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.979353333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:training error  = [[ 0.1930805 ]
 [ 0.36649656]
 [ 0.33077505]
 [ 1.96922624]
 [ 1.72718906]
 [ 0.17831825]
 [ 0.20314364]
 [ 1.71420896]
 [ 0.25434506]
 [ 0.19638407]
 [ 0.08505739]
 [ 0.11991519]
 [ 0.36649656]
 [ 1.56441987]
 [ 1.96922624]
 [ 0.34246778]]
DEBUG:root:training time = %d0.200114
INFO:root:frame =2625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =2626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00032114982605
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.979321666667
DEBUG:root: dqn, choose action rondomly, need time 0.000219000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =2629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000485181808472
INFO:root:frame =2630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.97929
DEBUG:root: dqn, choose action rondomly, need time 0.000192000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:training error  = [[ 0.2455813 ]
 [ 1.3774482 ]
 [ 0.26531082]
 [ 0.22673793]
 [ 0.22673793]
 [ 0.24565929]
 [ 0.28384963]
 [ 0.2455813 ]
 [ 1.68534219]
 [ 0.20514858]
 [ 1.63080192]
 [ 0.10105113]
 [ 0.32281181]
 [ 0.17494948]
 [ 1.92023778]
 [ 0.3496154 ]]
DEBUG:root:training time = %d0.211562
INFO:root:frame =2633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =2634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000136137008667
INFO:root:random_action_porb = 0.979258333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000363826751709
INFO:root:frame =2637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000541925430298
INFO:root:frame =2638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000584840774536
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.979226666667
DEBUG:root: dqn, choose action rondomly, need time 0.000276999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[ 0.09270637]
 [ 0.16511036]
 [ 1.38890421]
 [ 1.38910317]
 [ 0.21820615]
 [ 0.36068285]
 [ 0.16511036]
 [ 0.12005096]
 [ 0.23629758]
 [ 0.1394847 ]
 [ 0.20067063]
 [ 0.18425904]
 [ 0.20944107]
 [ 0.30010948]
 [ 0.09710687]
 [ 0.50701988]]
DEBUG:root:training time = %d0.219226
INFO:root:frame =2641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:frame =2642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:frame = 2643 State into memory, numbers recorded 65 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:random_action_porb = 0.979195
DEBUG:root: dqn, choose action rondomly, need time 0.000275999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2644current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =2645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame =2646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.979163333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294208526611
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.21013604]
 [ 0.13824548]
 [ 1.17867625]
 [ 0.12758444]
 [ 0.22683875]
 [ 1.33797503]
 [ 0.18928263]
 [ 1.90167701]
 [ 0.06347245]
 [ 0.30218977]
 [ 0.18928263]
 [ 0.09548307]
 [ 1.21978605]
 [ 1.07469308]
 [ 0.29212755]
 [ 0.20021464]]
DEBUG:root:training time = %d0.215082
INFO:root:frame =2649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =2650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:random_action_porb = 0.979131666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =2653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =2654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9791
DEBUG:root: dqn, choose action rondomly, need time 0.000278999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.04037559]
 [ 0.15591991]
 [ 0.30305174]
 [ 0.35314861]
 [ 1.0499723 ]
 [ 0.99943835]
 [ 0.33926067]
 [ 1.06942797]
 [ 0.15263557]
 [ 0.42577386]
 [ 1.06839764]
 [ 0.13930917]
 [ 0.1864285 ]
 [ 0.13408531]
 [ 0.09770484]
 [ 1.83028686]]
DEBUG:root:training time = %d0.21203
INFO:root:frame =2657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =2658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:random_action_porb = 0.979068333333
DEBUG:root: dqn, choose action rondomly, need time 0.000550000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =2661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =2662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000399827957153
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.979036666667
DEBUG:root: dqn, choose action rondomly, need time 0.000307999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.26876557e-07]
 [  1.83258265e-01]
 [  1.80286482e-01]
 [  1.77364290e-01]
 [  2.13992804e-01]
 [  3.15915585e-01]
 [  2.09047586e-01]
 [  1.03606308e+00]
 [  2.28035808e-01]
 [  1.05749166e+00]
 [  2.14034706e-01]
 [  2.46360302e-01]
 [  9.55586374e-01]
 [  1.86331332e-01]
 [  2.91332215e-01]
 [  3.35029542e-01]]
DEBUG:root:training time = %d0.207528
INFO:root:frame =2665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229835510254
INFO:root:frame =2666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000349044799805
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:random_action_porb = 0.979005
DEBUG:root: dqn, choose action rondomly, need time 0.000499999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000152826309204
INFO:root:frame =2669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000492095947266
INFO:root:frame =2670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045919418335
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.978973333333
DEBUG:root: dqn, choose action rondomly, need time 0.000596999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:training error  = [[ 0.19074218]
 [ 0.26758265]
 [ 0.19074218]
 [ 0.15296811]
 [ 1.10314739]
 [ 0.23561659]
 [ 0.2366593 ]
 [ 0.35752138]
 [ 0.17544286]
 [ 0.83828634]
 [ 0.16576901]
 [ 1.10314739]
 [ 0.32861152]
 [ 0.35752138]
 [ 0.23934521]
 [ 0.86383569]]
DEBUG:root:training time = %d0.206627
INFO:root:frame =2673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000373840332031
INFO:root:frame =2674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000514984130859
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:random_action_porb = 0.978941666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =2677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000522136688232
INFO:root:frame =2678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.97891
DEBUG:root: dqn, choose action rondomly, need time 0.000334000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000356197357178
INFO:root:training error  = [[ 0.78208643]
 [ 0.40531725]
 [ 0.74856949]
 [ 0.8136065 ]
 [ 0.34783241]
 [ 0.25934982]
 [ 0.28350729]
 [ 0.69886166]
 [ 0.23357402]
 [ 0.72170484]
 [ 0.10364962]
 [ 0.92081654]
 [ 0.12806112]
 [ 0.22322321]
 [ 0.87064135]
 [ 0.13262887]]
DEBUG:root:training time = %d0.211842
INFO:root:frame =2681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =2682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.978878333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =2685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =2686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000563859939575
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.978846666667
DEBUG:root: dqn, choose action rondomly, need time 0.000382999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.35467476]
 [ 0.81610906]
 [ 0.1855808 ]
 [ 0.30921897]
 [ 0.24513961]
 [ 0.70619559]
 [ 0.02872067]
 [ 0.27451622]
 [ 0.1762639 ]
 [ 0.20496979]
 [ 0.73953545]
 [ 0.43268603]
 [ 0.02872067]
 [ 0.09272757]
 [ 0.09272757]
 [ 0.17560948]]
DEBUG:root:training time = %d0.21985
INFO:root:frame =2689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =2690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame = 2691 State into memory, numbers recorded 66 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000562191009521
INFO:root:random_action_porb = 0.978815
DEBUG:root: dqn, choose action rondomly, need time 0.000360999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2692current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:frame =2693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =2694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000649929046631
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:random_action_porb = 0.978783333333
DEBUG:root: dqn, choose action rondomly, need time 0.000526000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000490188598633
INFO:root:training error  = [[ 0.24218658]
 [ 0.32334846]
 [ 0.35045215]
 [ 0.15761304]
 [ 0.31942984]
 [ 0.07979293]
 [ 0.53313679]
 [ 0.53227645]
 [ 0.23525704]
 [ 0.21276152]
 [ 0.31290606]
 [ 0.12550688]
 [ 0.35045215]
 [ 0.22859266]
 [ 0.35446125]
 [ 0.7377519 ]]
DEBUG:root:training time = %d0.226416
INFO:root:frame =2697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =2698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:frame = 2699 State into memory, numbers recorded 67 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000552892684937
INFO:root:random_action_porb = 0.978751666667
DEBUG:root: dqn, choose action rondomly, need time 0.000354999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2700current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =2701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000486135482788
INFO:root:frame =2702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000345230102539
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.97872
DEBUG:root: dqn, choose action rondomly, need time 0.000267000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332832336426
INFO:root:training error  = [[ 0.07694812]
 [ 0.2606813 ]
 [ 0.14995439]
 [ 0.11095455]
 [ 0.57942098]
 [ 0.157187  ]
 [ 0.45092916]
 [ 0.29762363]
 [ 0.26553094]
 [ 0.11095455]
 [ 0.29762363]
 [ 0.34179893]
 [ 0.40780857]
 [ 0.43574142]
 [ 0.47651604]
 [ 0.53521663]]
DEBUG:root:training time = %d0.223059
INFO:root:frame =2705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253200531006
INFO:root:frame =2706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:random_action_porb = 0.978688333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =2709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000578880310059
INFO:root:frame =2710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.978656666667
DEBUG:root: dqn, choose action rondomly, need time 0.000346
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:training error  = [[ 0.34417543]
 [ 0.3420828 ]
 [ 0.26425281]
 [ 0.187326  ]
 [ 0.19945195]
 [ 0.16410668]
 [ 0.15298675]
 [ 0.17119315]
 [ 0.26289707]
 [ 0.21993046]
 [ 0.27815732]
 [ 0.27558905]
 [ 0.1689067 ]
 [ 0.33889639]
 [ 0.43536001]
 [ 0.2362693 ]]
DEBUG:root:training time = %d0.220748
INFO:root:frame =2713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =2714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.978625
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =2717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000383853912354
INFO:root:frame =2718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000243186950684
DEBUG:root: save sample needs time = 0.000189065933228
INFO:root:random_action_porb = 0.978593333333
DEBUG:root: dqn, choose action rondomly, need time 0.0002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.08812939]
 [ 0.47222754]
 [ 0.24889448]
 [ 0.22114326]
 [ 0.25477764]
 [ 0.2741251 ]
 [ 0.30951655]
 [ 0.24558367]
 [ 0.24889448]
 [ 0.11503337]
 [ 0.30083975]
 [ 0.20904148]
 [ 0.08166092]
 [ 0.28603965]
 [ 0.32761621]
 [ 0.08812939]]
DEBUG:root:training time = %d0.182127
INFO:root:frame =2721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =2722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.978561666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =2725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =2726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231981277466
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.97853
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:training error  = [[ 0.2135047 ]
 [ 0.20685877]
 [ 0.28829646]
 [ 0.25417289]
 [ 0.27605584]
 [ 0.21017145]
 [ 0.28441542]
 [ 0.309921  ]
 [ 0.28829646]
 [ 0.1717476 ]
 [ 0.33355236]
 [ 0.24748294]
 [ 0.19781514]
 [ 0.18563709]
 [ 0.25751191]
 [ 0.21602784]]
DEBUG:root:training time = %d0.181718
INFO:root:frame =2729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:frame =2730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227928161621
DEBUG:root: save sample needs time = 0.000130176544189
INFO:root:random_action_porb = 0.978498333333
DEBUG:root: dqn, choose action rondomly, need time 0.000178000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:frame =2733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =2734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000338077545166
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root:random_action_porb = 0.978466666667
DEBUG:root: dqn, choose action rondomly, need time 0.000317000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:training error  = [[ 0.2233566 ]
 [ 0.3598763 ]
 [ 0.22564755]
 [ 0.28139225]
 [ 0.22564755]
 [ 0.2362248 ]
 [ 0.22399887]
 [ 0.37963954]
 [ 0.2899189 ]
 [ 0.20831002]
 [ 0.22645193]
 [ 0.2648797 ]
 [ 0.13782738]
 [ 0.23971862]
 [ 0.23047601]
 [ 0.68509227]]
DEBUG:root:training time = %d0.185978
INFO:root:frame =2737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =2738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234127044678
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:random_action_porb = 0.978435
DEBUG:root: dqn, choose action rondomly, need time 0.000228
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00018310546875
INFO:root:frame =2741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =2742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000335931777954
DEBUG:root: save sample needs time = 0.000162124633789
INFO:root:random_action_porb = 0.978403333333
DEBUG:root: dqn, choose action rondomly, need time 0.000249999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:training error  = [[ 0.24077456]
 [ 0.25342292]
 [ 0.20405117]
 [ 0.15920037]
 [ 0.21272677]
 [ 0.18398078]
 [ 0.22532965]
 [ 0.21272677]
 [ 0.21523337]
 [ 0.2621851 ]
 [ 0.18398078]
 [ 0.1792675 ]
 [ 0.21558216]
 [ 0.25783139]
 [ 0.18652898]
 [ 0.24900441]]
DEBUG:root:training time = %d0.176195
INFO:root:frame =2745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =2746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000323057174683
DEBUG:root: save sample needs time = 0.00016713142395
INFO:root:random_action_porb = 0.978371666667
DEBUG:root: dqn, choose action rondomly, need time 0.000388000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:frame =2749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000352144241333
INFO:root:frame =2750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423192977905
DEBUG:root: save sample needs time = 0.000121116638184
INFO:root:random_action_porb = 0.97834
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:training error  = [[ 0.31030655]
 [ 0.15581863]
 [ 0.33719909]
 [ 0.13819017]
 [ 0.207725  ]
 [ 0.25452498]
 [ 0.20831046]
 [ 0.2466065 ]
 [ 0.29063413]
 [ 0.2961567 ]
 [ 0.30053174]
 [ 0.23019545]
 [ 0.15581863]
 [ 0.17742935]
 [ 0.15581863]
 [ 0.22152014]]
DEBUG:root:training time = %d0.198633
INFO:root:frame =2753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =2754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000571012496948
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.978308333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =2757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =2758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.978276666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000370979309082
INFO:root:training error  = [[ 0.19121771]
 [ 0.19256791]
 [ 0.22887088]
 [ 0.13535595]
 [ 0.25795975]
 [ 0.33837914]
 [ 0.18121253]
 [ 0.25795975]
 [ 0.33837914]
 [ 0.27136537]
 [ 0.20849679]
 [ 0.33633575]
 [ 0.19564645]
 [ 0.23891942]
 [ 0.20849679]
 [ 0.15022115]]
DEBUG:root:training time = %d0.210774
INFO:root:frame =2761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =2762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000369071960449
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:random_action_porb = 0.978245
DEBUG:root: dqn, choose action rondomly, need time 0.000313999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =2765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =2766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000570058822632
DEBUG:root: save sample needs time = 0.000229835510254
INFO:root:random_action_porb = 0.978213333333
DEBUG:root: dqn, choose action rondomly, need time 0.000169
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.27003214]
 [ 0.16163579]
 [ 0.21411237]
 [ 0.24042466]
 [ 0.37480551]
 [ 0.34706452]
 [ 0.25910363]
 [ 0.14972663]
 [ 0.14077882]
 [ 0.25173104]
 [ 0.19053231]
 [ 0.50689906]
 [ 0.32167116]
 [ 0.22105716]
 [ 0.25173104]
 [ 0.14711548]]
DEBUG:root:training time = %d0.224794
INFO:root:frame =2769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =2770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427007675171
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.978181666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =2773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame =2774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504970550537
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.97815
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:training error  = [[ 0.27589804]
 [ 0.1697689 ]
 [ 0.34432149]
 [ 0.27760029]
 [ 0.27760029]
 [ 0.20928092]
 [ 0.10165258]
 [ 0.24113268]
 [ 0.28688085]
 [ 0.28612944]
 [ 0.27656066]
 [ 0.27760029]
 [ 0.24113268]
 [ 0.21652059]
 [ 0.43891054]
 [ 0.20737569]]
DEBUG:root:training time = %d0.23254
INFO:root:frame =2777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =2778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.978118333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336170196533
INFO:root:frame =2781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =2782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449180603027
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:random_action_porb = 0.978086666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322818756104
INFO:root:training error  = [[ 0.50873053]
 [ 0.23294301]
 [ 0.14593345]
 [ 0.20714037]
 [ 0.29813474]
 [ 0.10229333]
 [ 0.23294301]
 [ 0.77492648]
 [ 0.18496342]
 [ 0.32671124]
 [ 0.36026201]
 [ 0.30658525]
 [ 0.23294301]
 [ 0.22612575]
 [ 0.37276131]
 [ 0.32690042]]
DEBUG:root:training time = %d0.221081
INFO:root:frame =2785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =2786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame = 2787 State into memory, numbers recorded 68 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00052285194397
INFO:root:random_action_porb = 0.978055
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2788current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =2789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:frame =2790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000505924224854
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.978023333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:training error  = [[ 0.20669354]
 [ 0.23186766]
 [ 0.27776766]
 [ 0.38321349]
 [ 0.3059783 ]
 [ 0.24003623]
 [ 0.27652556]
 [ 0.27652556]
 [ 0.23519322]
 [ 0.27700219]
 [ 0.28427505]
 [ 0.23713045]
 [ 0.28413677]
 [ 0.27652556]
 [ 0.24097723]
 [ 0.17172982]]
DEBUG:root:training time = %d0.206426
INFO:root:frame =2793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =2794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.977991666667
DEBUG:root: dqn, choose action rondomly, need time 0.000178999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:frame =2797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =2798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.97796
DEBUG:root: dqn, choose action rondomly, need time 0.000202999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:training error  = [[ 0.30421573]
 [ 0.13785926]
 [ 0.5212236 ]
 [ 0.19757599]
 [ 0.3671793 ]
 [ 0.28786191]
 [ 0.18035209]
 [ 0.54276067]
 [ 0.30421573]
 [ 0.2862677 ]
 [ 0.38795808]
 [ 0.2298076 ]
 [ 0.28786191]
 [ 0.24371335]
 [ 0.2298076 ]
 [ 0.26324582]]
DEBUG:root:training time = %d0.191544
INFO:root:frame =2801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =2802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.977928333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =2805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =2806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475883483887
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.977896666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.33967796]
 [ 0.46088678]
 [ 0.17604455]
 [ 0.1570925 ]
 [ 0.32977647]
 [ 0.28508005]
 [ 0.20391852]
 [ 0.2225897 ]
 [ 0.28861147]
 [ 0.2225897 ]
 [ 0.45526871]
 [ 0.2225897 ]
 [ 0.27072293]
 [ 0.58882195]
 [ 0.32865909]
 [ 0.48191699]]
DEBUG:root:training time = %d0.216795
INFO:root:frame =2809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270128250122
INFO:root:frame =2810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
DEBUG:root: save sample needs time = 0.000141143798828
INFO:root:random_action_porb = 0.977865
DEBUG:root: dqn, choose action rondomly, need time 0.000230999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:frame =2813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =2814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000451803207397
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.977833333333
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.26600194]
 [ 0.27092937]
 [ 0.23558836]
 [ 0.53919321]
 [ 0.36834639]
 [ 0.45608243]
 [ 0.47043228]
 [ 0.19728614]
 [ 0.57413816]
 [ 0.51883167]
 [ 0.2219162 ]
 [ 0.22371776]
 [ 0.26600194]
 [ 0.11244685]
 [ 0.28355145]
 [ 0.22371776]]
DEBUG:root:training time = %d0.216319
INFO:root:frame =2817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =2818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000401020050049
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.977801666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =2821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =2822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.97777
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 0.25935468]
 [ 0.18386094]
 [ 0.24272849]
 [ 0.20044854]
 [ 0.21377359]
 [ 0.32390997]
 [ 0.23802945]
 [ 0.35921812]
 [ 0.25469774]
 [ 0.37472668]
 [ 0.20061681]
 [ 0.33064124]
 [ 0.29328018]
 [ 0.38236031]
 [ 0.25935468]
 [ 0.34513003]]
DEBUG:root:training time = %d0.216142
INFO:root:frame =2825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:frame =2826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000365018844604
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.977738333333
DEBUG:root: dqn, choose action rondomly, need time 0.000169
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =2829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00036096572876
INFO:root:frame =2830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000291109085083
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.977706666667
DEBUG:root: dqn, choose action rondomly, need time 0.000347000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.33739629]
 [ 0.52449501]
 [ 0.2096515 ]
 [ 0.37673762]
 [ 0.27856237]
 [ 0.27121142]
 [ 0.49766248]
 [ 0.27121142]
 [ 2.15333986]
 [ 0.26043692]
 [ 0.44580775]
 [ 0.31256419]
 [ 0.14229505]
 [ 0.34981391]
 [ 0.20796239]
 [ 0.33711272]]
DEBUG:root:training time = %d0.223483
INFO:root:frame =2833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =2834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000419855117798
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.977675
DEBUG:root: dqn, choose action rondomly, need time 0.000258000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =2837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =2838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.977643333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.25131208]
 [ 0.25131208]
 [ 0.24784744]
 [ 0.43153569]
 [ 0.55913335]
 [ 2.05642986]
 [ 0.41377974]
 [ 0.42257762]
 [ 0.28220224]
 [ 0.37517285]
 [ 0.46855295]
 [ 0.48879349]
 [ 0.40868542]
 [ 0.39363366]
 [ 0.28764191]
 [ 0.36968929]]
DEBUG:root:training time = %d0.216485
INFO:root:frame =2841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =2842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:random_action_porb = 0.977611666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =2845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =2846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:random_action_porb = 0.97758
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:training error  = [[ 0.61853874]
 [ 0.46354508]
 [ 0.46354508]
 [ 0.28703257]
 [ 0.12331673]
 [ 0.24114673]
 [ 0.3605935 ]
 [ 0.30066404]
 [ 0.39015189]
 [ 0.61853874]
 [ 0.48339185]
 [ 0.46846026]
 [ 0.31204295]
 [ 0.30763379]
 [ 0.29909208]
 [ 0.2748301 ]]
DEBUG:root:training time = %d0.21462
INFO:root:frame =2849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =2850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000131130218506
INFO:root:random_action_porb = 0.977548333333
DEBUG:root: dqn, choose action rondomly, need time 0.000242
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =2853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =2854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000594854354858
DEBUG:root: save sample needs time = 9.08374786377e-05
INFO:root:random_action_porb = 0.977516666667
DEBUG:root: dqn, choose action rondomly, need time 0.000221000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:training error  = [[ 0.24898632]
 [ 0.29679227]
 [ 0.25004101]
 [ 0.49907225]
 [ 0.55805993]
 [ 0.25903228]
 [ 0.40903178]
 [ 0.21799193]
 [ 0.56210238]
 [ 0.30951551]
 [ 0.2504217 ]
 [ 0.30951551]
 [ 0.25097179]
 [ 0.24042045]
 [ 0.30951551]
 [ 0.62288004]]
DEBUG:root:training time = %d0.193342
INFO:root:frame =2857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =2858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000385999679565
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:random_action_porb = 0.977485
DEBUG:root: dqn, choose action rondomly, need time 0.000275999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:frame =2861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000502824783325
INFO:root:frame =2862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.977453333333
DEBUG:root: dqn, choose action rondomly, need time 0.000245999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:training error  = [[ 0.3778424 ]
 [ 0.33279106]
 [ 0.48682326]
 [ 0.19775575]
 [ 0.21752821]
 [ 0.41638491]
 [ 0.4945001 ]
 [ 0.25909635]
 [ 0.40570593]
 [ 0.33279106]
 [ 0.41638491]
 [ 0.40570593]
 [ 0.34796065]
 [ 0.34538218]
 [ 0.52864724]
 [ 0.3778424 ]]
DEBUG:root:training time = %d0.200875
INFO:root:frame =2865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =2866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.977421666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00041389465332
INFO:root:frame =2869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =2870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000490188598633
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.97739
DEBUG:root: dqn, choose action rondomly, need time 0.000520000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.36298665]
 [ 0.62624294]
 [ 0.33195755]
 [ 0.35349327]
 [ 0.6422025 ]
 [ 0.36436236]
 [ 0.58317   ]
 [ 0.34457558]
 [ 0.77341193]
 [ 2.10994005]
 [ 0.35787499]
 [ 0.77341193]
 [ 0.19715655]
 [ 0.3004643 ]
 [ 0.28657597]
 [ 0.03215852]]
DEBUG:root:training time = %d0.222011
INFO:root:frame =2873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =2874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame = 2875 State into memory, numbers recorded 69 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:random_action_porb = 0.977358333333
DEBUG:root: dqn, choose action rondomly, need time 0.000175999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2876current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000178098678589
INFO:root:frame =2877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444173812866
INFO:root: ememy has been killed for 2 times 
INFO:root:enemies_left [0]
INFO:root:frame =2878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame = 2879 State into memory, numbers recorded 70 action = 0, reward = 1
DEBUG:root: save sample needs time = 0.000530004501343
INFO:root:random_action_porb = 0.977326666667
DEBUG:root: dqn, choose action rondomly, need time 0.000222999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2880current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.17569502]
 [ 0.60550195]
 [ 0.21435161]
 [ 0.28469622]
 [ 0.36566681]
 [ 0.21435161]
 [ 0.73051059]
 [ 0.45278057]
 [ 0.84604746]
 [ 3.5322063 ]
 [ 0.84604746]
 [ 0.37715217]
 [ 0.29181424]
 [ 0.29181424]
 [ 0.64091921]
 [ 0.65764344]]
DEBUG:root:training time = %d0.223465
INFO:root:frame =2881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =2882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame = 2883 State into memory, numbers recorded 71 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000549077987671
INFO:root:random_action_porb = 0.977295
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2884current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =2885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =2886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000580072402954
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.977263333333
DEBUG:root: dqn, choose action rondomly, need time 0.000233999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:training error  = [[ 0.61189181]
 [ 0.32802302]
 [ 0.19963983]
 [ 0.19881657]
 [ 0.51612186]
 [ 0.17915203]
 [ 0.47809404]
 [ 0.47809404]
 [ 0.57268804]
 [ 0.19963983]
 [ 0.30573145]
 [ 0.36474699]
 [ 0.55228716]
 [ 0.23781639]
 [ 0.69845194]
 [ 0.47372818]]
DEBUG:root:training time = %d0.221903
INFO:root:frame =2889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =2890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.977231666667
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =2893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =2894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:random_action_porb = 0.9772
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000404119491577
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.35256511]
 [ 0.31472406]
 [ 0.25070527]
 [ 0.27531025]
 [ 0.18860526]
 [ 0.36075386]
 [ 0.31472406]
 [ 0.26302567]
 [ 0.20630611]
 [ 3.29345155]
 [ 0.16705829]
 [ 0.31572318]
 [ 0.32283837]
 [ 0.26508784]
 [ 0.37700695]
 [ 0.38931122]]
DEBUG:root:training time = %d0.222483
INFO:root:frame =2897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =2898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.977168333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000407934188843
INFO:root:frame =2901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000401973724365
INFO:root:frame =2902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457763671875
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.977136666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:training error  = [[ 0.49744722]
 [ 0.303381  ]
 [ 0.27340308]
 [ 0.14535913]
 [ 0.43003094]
 [ 0.27863282]
 [ 0.31810153]
 [ 0.44854236]
 [ 0.27340308]
 [ 0.4081369 ]
 [ 0.37537849]
 [ 0.15015979]
 [ 0.37555495]
 [ 0.27863282]
 [ 0.37537849]
 [ 0.36598751]]
DEBUG:root:training time = %d0.211022
INFO:root:frame =2905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =2906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226020812988
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.977105
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =2909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =2910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:random_action_porb = 0.977073333333
DEBUG:root: dqn, choose action rondomly, need time 0.000249000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:training error  = [[ 0.27923825]
 [ 0.38089687]
 [ 0.3186267 ]
 [ 0.33409068]
 [ 0.38089687]
 [ 0.2324595 ]
 [ 0.38507065]
 [ 0.82071185]
 [ 0.27814978]
 [ 0.2949259 ]
 [ 0.3186267 ]
 [ 0.47264445]
 [ 0.20996514]
 [ 0.28261173]
 [ 0.41674682]
 [ 0.29550001]]
DEBUG:root:training time = %d0.212226
INFO:root:frame =2913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =2914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.977041666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =2917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000422954559326
INFO:root:frame =2918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.97701
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:training error  = [[ 0.28918764]
 [ 0.39952523]
 [ 0.25497213]
 [ 0.31011322]
 [ 0.47736105]
 [ 0.33822218]
 [ 0.29946041]
 [ 0.16362026]
 [ 0.53042382]
 [ 0.37636542]
 [ 0.39734969]
 [ 0.26560366]
 [ 0.37636542]
 [ 0.28354129]
 [ 0.22817656]
 [ 0.43675241]]
DEBUG:root:training time = %d0.232306
INFO:root:frame =2921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =2922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.976978333333
DEBUG:root: dqn, choose action rondomly, need time 0.000449000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =2925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =2926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000543117523193
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.976946666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:training error  = [[ 0.43421617]
 [ 0.34088963]
 [ 0.36999318]
 [ 0.4212074 ]
 [ 0.33801809]
 [ 0.49548778]
 [ 0.36160326]
 [ 0.39702752]
 [ 0.48109642]
 [ 0.39383113]
 [ 0.33801809]
 [ 0.34192163]
 [ 0.39702752]
 [ 0.48109642]
 [ 0.32695878]
 [ 0.21839999]]
DEBUG:root:training time = %d0.202095
INFO:root:frame =2929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275850296021
INFO:root:frame =2930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000295162200928
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.976915
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =2933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =2934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.976883333333
DEBUG:root: dqn, choose action rondomly, need time 0.000215000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:training error  = [[ 0.29978406]
 [ 0.1915448 ]
 [ 0.26628926]
 [ 0.3213878 ]
 [ 0.28061673]
 [ 0.31182563]
 [ 0.27567068]
 [ 0.32808089]
 [ 0.27899337]
 [ 0.33239946]
 [ 0.22663577]
 [ 0.33671305]
 [ 0.26628926]
 [ 0.33528903]
 [ 0.33528903]
 [ 0.36945042]]
DEBUG:root:training time = %d0.211796
INFO:root:frame =2937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =2938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.976851666667
DEBUG:root: dqn, choose action rondomly, need time 0.000164999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000146865844727
INFO:root:frame =2941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =2942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.97682
DEBUG:root: dqn, choose action rondomly, need time 0.000270999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:training error  = [[ 0.32721403]
 [ 0.44892949]
 [ 0.37393197]
 [ 0.36820287]
 [ 0.31317016]
 [ 0.62887657]
 [ 0.27530026]
 [ 0.29596159]
 [ 0.3140471 ]
 [ 0.29018342]
 [ 0.56945503]
 [ 0.53340489]
 [ 0.37393197]
 [ 0.51249295]
 [ 0.3994734 ]
 [ 0.44394782]]
DEBUG:root:training time = %d0.22149
INFO:root:frame =2945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =2946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.976788333333
DEBUG:root: dqn, choose action rondomly, need time 0.000180999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =2949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000579118728638
INFO:root:frame =2950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.976756666667
DEBUG:root: dqn, choose action rondomly, need time 0.000267000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.22679198]
 [ 0.35629302]
 [ 0.37873399]
 [ 0.33679387]
 [ 0.2804935 ]
 [ 0.36065993]
 [ 0.24108398]
 [ 0.35001475]
 [ 0.32778054]
 [ 0.41404358]
 [ 3.12252235]
 [ 0.32778054]
 [ 0.32817268]
 [ 0.31586683]
 [ 0.31499377]
 [ 0.48427808]]
DEBUG:root:training time = %d0.209288
INFO:root:frame =2953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =2954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000282049179077
DEBUG:root: save sample needs time = 0.000166893005371
INFO:root:random_action_porb = 0.976725
DEBUG:root: dqn, choose action rondomly, need time 0.000194999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:frame =2957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =2958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255107879639
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.976693333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.31616813]
 [ 0.41719761]
 [ 0.4376756 ]
 [ 0.31750691]
 [ 0.37672707]
 [ 0.37139484]
 [ 0.57555825]
 [ 0.35584003]
 [ 3.19666123]
 [ 0.33015883]
 [ 0.41933906]
 [ 0.31779608]
 [ 0.30824026]
 [ 0.48072475]
 [ 0.36522174]
 [ 0.57555825]]
DEBUG:root:training time = %d0.212927
INFO:root:frame =2961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002281665802
INFO:root:frame =2962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000221014022827
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.976661666667
DEBUG:root: dqn, choose action rondomly, need time 0.000278999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =2965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =2966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000243902206421
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:random_action_porb = 0.97663
INFO:root:dqn select action Tensor("ArgMax_6:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01073
INFO:root:action choosen by dqn [0]
INFO:root:frame =2968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000158071517944
INFO:root:training error  = [[ 0.27391094]
 [ 0.42259869]
 [ 0.16354388]
 [ 0.35381654]
 [ 0.63669497]
 [ 0.42739084]
 [ 0.27391094]
 [ 0.42920956]
 [ 0.50141281]
 [ 0.17334206]
 [ 0.49102297]
 [ 0.25739142]
 [ 0.77414006]
 [ 0.31259724]
 [ 0.17334206]
 [ 0.54773515]]
DEBUG:root:training time = %d0.215174
INFO:root:frame =2969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =2970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.976598333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =2973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000425100326538
INFO:root:frame =2974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000420093536377
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.976566666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.57006836]
 [ 0.28394261]
 [ 0.54475087]
 [ 0.40481469]
 [ 0.52916741]
 [ 0.52136821]
 [ 0.55085784]
 [ 0.57728875]
 [ 0.57728875]
 [ 0.26922348]
 [ 0.55367571]
 [ 0.31936464]
 [ 0.20456931]
 [ 0.4716104 ]
 [ 0.30603632]
 [ 0.47817448]]
DEBUG:root:training time = %d0.233722
INFO:root:frame =2977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000269174575806
INFO:root:frame =2978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486850738525
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.976535
INFO:root:dqn select action Tensor("ArgMax_7:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012477
INFO:root:action choosen by dqn [0]
INFO:root:frame =2980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =2981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000527858734131
INFO:root:frame =2982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481843948364
DEBUG:root: save sample needs time = 0.000265836715698
INFO:root:random_action_porb = 0.976503333333
DEBUG:root: dqn, choose action rondomly, need time 0.000225
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000136852264404
INFO:root:training error  = [[ 0.44666907]
 [ 0.3637892 ]
 [ 0.50900745]
 [ 0.46061748]
 [ 0.34072259]
 [ 0.77827728]
 [ 0.25637057]
 [ 0.458931  ]
 [ 0.32763532]
 [ 0.32054925]
 [ 0.3637892 ]
 [ 0.77827728]
 [ 0.37092075]
 [ 0.46835843]
 [ 0.35037482]
 [ 0.27921507]]
DEBUG:root:training time = %d0.177047
INFO:root:frame =2985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =2986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274896621704
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.976471666667
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root:frame =2989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =2990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000349998474121
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.97644
DEBUG:root: dqn, choose action rondomly, need time 0.000501999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.50896662]
 [ 0.30725729]
 [ 0.31809831]
 [ 0.63457513]
 [ 0.4804841 ]
 [ 2.30433154]
 [ 0.34571296]
 [ 0.39931187]
 [ 0.3610644 ]
 [ 0.39571741]
 [ 0.4480992 ]
 [ 0.29679748]
 [ 0.26609147]
 [ 0.36492211]
 [ 0.4480992 ]
 [ 0.50896662]]
DEBUG:root:training time = %d0.208163
INFO:root:frame =2993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =2994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000305891036987
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.976408333333
DEBUG:root: dqn, choose action rondomly, need time 0.000194
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root:frame =2997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =2998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000102043151855
DEBUG:root:one frame running time = 0.003538
DEBUG:root:total training time = 53.919004
INFO:root:frame num = 3000 frame round: 0
INFO:root:random_action_porb = 0.976376666667
DEBUG:root: dqn, choose action rondomly, need time 0.000437000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:training error  = [[ 0.4470911 ]
 [ 0.44161254]
 [ 0.33231041]
 [ 0.37903219]
 [ 0.49324682]
 [ 0.36265463]
 [ 0.50025469]
 [ 0.45750818]
 [ 0.5522517 ]
 [ 0.40180102]
 [ 0.57376969]
 [ 0.36145189]
 [ 0.40989712]
 [ 0.51268822]
 [ 0.60974526]
 [ 0.57376969]]
DEBUG:root:training time = %d0.178431
INFO:root:frame =3001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =3002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000291109085083
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.976345
DEBUG:root: dqn, choose action rondomly, need time 0.000176000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root:frame =3005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =3006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
DEBUG:root: save sample needs time = 0.000121116638184
INFO:root:random_action_porb = 0.976313333333
DEBUG:root: dqn, choose action rondomly, need time 0.000160999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000147104263306
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.44850147]
 [ 0.37538433]
 [ 0.3948696 ]
 [ 0.72703916]
 [ 0.3530024 ]
 [ 0.72703916]
 [ 0.20651929]
 [ 0.36259148]
 [ 0.35737085]
 [ 0.37829393]
 [ 0.72703916]
 [ 0.48536712]
 [ 0.38299862]
 [ 0.46816787]
 [ 0.41817635]
 [ 2.33016062]]
DEBUG:root:training time = %d0.183485
INFO:root:frame =3009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000647068023682
INFO:root:frame =3010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.976281666667
DEBUG:root: dqn, choose action rondomly, need time 0.000165000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000173091888428
INFO:root:frame =3013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =3014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.97625
INFO:root:dqn select action Tensor("ArgMax_8:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012026
INFO:root:action choosen by dqn [4]
INFO:root:frame =3016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.45521465]
 [ 0.41216916]
 [ 0.29322958]
 [ 0.5308184 ]
 [ 0.35961261]
 [ 0.49513069]
 [ 0.34003824]
 [ 0.51064032]
 [ 0.41216916]
 [ 0.43305311]
 [ 0.5155232 ]
 [ 0.18465348]
 [ 0.37046319]
 [ 0.29322958]
 [ 0.35759324]
 [ 0.30044445]]
DEBUG:root:training time = %d0.220844
INFO:root:frame =3017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =3018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475883483887
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.976218333333
DEBUG:root: dqn, choose action rondomly, need time 0.000267999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322818756104
INFO:root:frame =3021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000410079956055
INFO:root:frame =3022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.976186666667
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:training error  = [[ 0.23072469]
 [ 0.57594323]
 [ 0.34732077]
 [ 0.34990191]
 [ 0.3860513 ]
 [ 0.62894619]
 [ 0.37086034]
 [ 0.4121165 ]
 [ 0.34244823]
 [ 0.62894619]
 [ 0.35602665]
 [ 0.31728664]
 [ 0.35655376]
 [ 0.75691307]
 [ 0.68205267]
 [ 0.37086034]]
DEBUG:root:training time = %d0.236798
INFO:root:frame =3025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =3026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000403165817261
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.976155
DEBUG:root: dqn, choose action rondomly, need time 0.000360999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000490188598633
INFO:root:frame =3029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000394821166992
INFO:root:frame =3030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.976123333333
DEBUG:root: dqn, choose action rondomly, need time 0.000279000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000408172607422
INFO:root:training error  = [[ 0.51794457]
 [ 0.55427766]
 [ 0.32772374]
 [ 0.59051949]
 [ 0.53206009]
 [ 0.49081719]
 [ 0.57104951]
 [ 0.48800573]
 [ 0.62066162]
 [ 0.78803176]
 [ 0.72628635]
 [ 0.33784515]
 [ 0.53206009]
 [ 0.51157987]
 [ 0.60694098]
 [ 0.2014275 ]]
DEBUG:root:training time = %d0.217307
INFO:root:frame =3033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =3034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.976091666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000386953353882
INFO:root:frame =3037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000582933425903
INFO:root:frame =3038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:random_action_porb = 0.97606
DEBUG:root: dqn, choose action rondomly, need time 0.000391
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000493049621582
INFO:root:training error  = [[ 0.25780767]
 [ 0.49069959]
 [ 0.57842547]
 [ 0.43152064]
 [ 0.69279981]
 [ 0.33278665]
 [ 0.3567645 ]
 [ 0.37215427]
 [ 0.64229727]
 [ 0.4562138 ]
 [ 0.77562594]
 [ 0.39752525]
 [ 0.48511997]
 [ 0.41028798]
 [ 0.42442334]
 [ 0.37788463]]
DEBUG:root:training time = %d0.234003
INFO:root:frame =3041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =3042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000281095504761
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.976028333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =3045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488042831421
INFO:root:frame =3046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.975996666667
DEBUG:root: dqn, choose action rondomly, need time 0.000411999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000406980514526
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.51127839]
 [ 0.31080401]
 [ 0.56293637]
 [ 0.430121  ]
 [ 0.51127839]
 [ 0.70890617]
 [ 0.49406832]
 [ 0.50579017]
 [ 0.30327594]
 [ 0.46059287]
 [ 0.40483168]
 [ 0.47717261]
 [ 1.07352579]
 [ 0.51127839]
 [ 0.70890617]
 [ 3.3613863 ]]
DEBUG:root:training time = %d0.228617
INFO:root:frame =3049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =3050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.975965
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =3053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =3054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.975933333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.46553275]
 [ 0.77225995]
 [ 0.28932714]
 [ 0.76637453]
 [ 0.71055806]
 [ 0.17968525]
 [ 0.55497366]
 [ 0.41134545]
 [ 0.38016269]
 [ 0.62221634]
 [ 0.39361092]
 [ 0.31166485]
 [ 0.5404222 ]
 [ 0.6853646 ]
 [ 0.67591375]
 [ 0.62221634]]
DEBUG:root:training time = %d0.20396
INFO:root:frame =3057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290155410767
INFO:root:frame =3058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.975901666667
INFO:root:dqn select action Tensor("ArgMax_9:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00901500000001
INFO:root:action choosen by dqn [4]
INFO:root:frame =3060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000361204147339
INFO:root:frame =3061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =3062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.97587
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.64838332]
 [ 0.50937903]
 [ 0.4985671 ]
 [ 0.64838332]
 [ 0.81557238]
 [ 0.32527593]
 [ 0.39213923]
 [ 0.6272788 ]
 [ 0.43142042]
 [ 0.40582865]
 [ 0.43683434]
 [ 0.23510443]
 [ 0.31425878]
 [ 3.07143521]
 [ 0.47822592]
 [ 0.68360829]]
DEBUG:root:training time = %d0.220875
INFO:root:frame =3065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:frame =3066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000306844711304
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.975838333333
DEBUG:root: dqn, choose action rondomly, need time 0.000253999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =3069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =3070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411987304688
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.975806666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.51756853]
 [ 0.32725659]
 [ 0.58860534]
 [ 3.04838037]
 [ 0.63488817]
 [ 0.32596162]
 [ 2.50680447]
 [ 0.53651023]
 [ 0.57289159]
 [ 0.3862682 ]
 [ 0.424191  ]
 [ 0.37528384]
 [ 0.498182  ]
 [ 0.62368715]
 [ 0.36378232]
 [ 0.56430101]]
DEBUG:root:training time = %d0.208498
INFO:root:frame =3073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =3074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.975775
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =3077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000326156616211
INFO:root:frame =3078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.975743333333
DEBUG:root: dqn, choose action rondomly, need time 0.000229999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.4498066 ]
 [ 2.55887222]
 [ 0.40090078]
 [ 0.48593998]
 [ 0.46576184]
 [ 0.34397796]
 [ 0.50740433]
 [ 0.64493531]
 [ 0.43410432]
 [ 0.47085756]
 [ 0.4140313 ]
 [ 0.41375399]
 [ 0.15810941]
 [ 0.46576184]
 [ 0.36130282]
 [ 0.50353009]]
DEBUG:root:training time = %d0.219595
INFO:root:frame =3081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =3082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame = 3083 State into memory, numbers recorded 72 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000540971755981
INFO:root:random_action_porb = 0.975711666667
DEBUG:root: dqn, choose action rondomly, need time 0.000422999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3084current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =3085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =3086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.97568
DEBUG:root: dqn, choose action rondomly, need time 0.000512999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:training error  = [[ 0.25428975]
 [ 0.54998332]
 [ 0.52552879]
 [ 0.42520902]
 [ 0.32707113]
 [ 0.6485768 ]
 [ 0.48125783]
 [ 0.43717477]
 [ 0.40726492]
 [ 0.54442006]
 [ 0.42367563]
 [ 0.61078227]
 [ 0.54831123]
 [ 0.32707113]
 [ 0.6485768 ]
 [ 0.42448422]]
DEBUG:root:training time = %d0.216156
INFO:root:frame =3089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000331163406372
INFO:root:frame =3090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.975648333333
DEBUG:root: dqn, choose action rondomly, need time 0.000488000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =3093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =3094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.975616666667
DEBUG:root: dqn, choose action rondomly, need time 0.000408
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:training error  = [[ 0.52192473]
 [ 0.49628156]
 [ 0.40073657]
 [ 0.42948452]
 [ 0.52192473]
 [ 0.49512398]
 [ 0.39826879]
 [ 0.3208949 ]
 [ 0.52192473]
 [ 0.40862569]
 [ 0.47768793]
 [ 0.441984  ]
 [ 0.92145544]
 [ 0.42948452]
 [ 0.4086647 ]
 [ 0.4086647 ]]
DEBUG:root:training time = %d0.226151
INFO:root:frame =3097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =3098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000145196914673
INFO:root:random_action_porb = 0.975585
INFO:root:dqn select action Tensor("ArgMax_10:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01471
INFO:root:action choosen by dqn [4]
INFO:root:frame =3100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:frame =3101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =3102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.975553333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4.14025784]
 [ 0.47296053]
 [ 0.49728984]
 [ 0.50569928]
 [ 0.5051325 ]
 [ 0.49094281]
 [ 4.14025784]
 [ 0.52015281]
 [ 0.35462025]
 [ 0.59612882]
 [ 0.32816502]
 [ 0.43723911]
 [ 0.54872799]
 [ 0.55902779]
 [ 0.52734721]
 [ 0.66732603]]
DEBUG:root:training time = %d0.210221
INFO:root:frame =3105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:frame =3106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430822372437
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:random_action_porb = 0.975521666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =3109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame =3110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.97549
DEBUG:root: dqn, choose action rondomly, need time 0.000283000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:training error  = [[ 0.60942805]
 [ 0.85306197]
 [ 0.2663857 ]
 [ 0.41327319]
 [ 0.46261185]
 [ 0.36994794]
 [ 0.71672601]
 [ 0.72597915]
 [ 0.8023169 ]
 [ 0.62116212]
 [ 0.26520374]
 [ 0.3488557 ]
 [ 0.3488557 ]
 [ 0.46017745]
 [ 0.46017745]
 [ 0.72046417]]
DEBUG:root:training time = %d0.224826
INFO:root:frame =3113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =3114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.975458333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =3117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000417947769165
INFO:root:frame =3118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.975426666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00037407875061
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.50630987]
 [ 0.35654351]
 [ 0.33861718]
 [ 0.35654351]
 [ 0.59336489]
 [ 0.81733721]
 [ 0.50248307]
 [ 0.48389721]
 [ 3.67338562]
 [ 0.36623564]
 [ 0.36623564]
 [ 0.64215207]
 [ 0.59263784]
 [ 0.56181216]
 [ 0.40806258]
 [ 0.67411631]]
DEBUG:root:training time = %d0.203531
INFO:root:frame =3121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290155410767
INFO:root:frame =3122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000386953353882
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.975395
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =3125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444173812866
INFO:root:frame =3126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000193119049072
INFO:root:random_action_porb = 0.975363333333
DEBUG:root: dqn, choose action rondomly, need time 0.000422999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.62280327]
 [ 0.59003735]
 [ 0.44918513]
 [ 0.47101986]
 [ 0.57549745]
 [ 0.55722666]
 [ 1.01172817]
 [ 0.5091694 ]
 [ 0.59983385]
 [ 0.86272365]
 [ 2.76332736]
 [ 1.00814176]
 [ 0.54892439]
 [ 0.3737081 ]
 [ 0.65632474]
 [ 0.4181073 ]]
DEBUG:root:training time = %d0.197868
INFO:root:frame =3129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =3130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000417947769165
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:random_action_porb = 0.975331666667
DEBUG:root: dqn, choose action rondomly, need time 0.000268999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =3133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000540018081665
INFO:root:frame =3134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470876693726
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9753
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.80718309]
 [ 0.59746081]
 [ 0.65045375]
 [ 0.54591852]
 [ 0.66890687]
 [ 0.79957205]
 [ 0.77374071]
 [ 2.54400158]
 [ 0.72827566]
 [ 3.60024953]
 [ 0.50166136]
 [ 0.66890687]
 [ 0.75518167]
 [ 0.47937018]
 [ 0.68001425]
 [ 0.60691422]]
DEBUG:root:training time = %d0.218552
INFO:root:frame =3137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =3138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000314950942993
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.975268333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =3141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =3142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000524997711182
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.975236666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000271797180176
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.66849357]
 [ 3.51871204]
 [ 3.22475457]
 [ 0.3438527 ]
 [ 0.61615586]
 [ 0.48056209]
 [ 0.84251958]
 [ 0.79142684]
 [ 0.42878982]
 [ 0.7103619 ]
 [ 0.61615586]
 [ 0.5230056 ]
 [ 0.37521255]
 [ 0.48443207]
 [ 0.98049802]
 [ 0.57965916]]
DEBUG:root:training time = %d0.186364
INFO:root:frame =3145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:frame =3146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:random_action_porb = 0.975205
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =3149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000658988952637
INFO:root:frame =3150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000347852706909
INFO:root:frame = 3151 State into memory, numbers recorded 73 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000508069992065
INFO:root:random_action_porb = 0.975173333333
DEBUG:root: dqn, choose action rondomly, need time 0.000195000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3152current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.61898583]
 [ 0.45594975]
 [ 0.84543878]
 [ 0.72725707]
 [ 0.52917987]
 [ 0.05038813]
 [ 0.76273715]
 [ 0.41749457]
 [ 0.79920197]
 [ 0.72725707]
 [ 0.45594975]
 [ 0.84543878]
 [ 0.69053143]
 [ 0.53738379]
 [ 0.55880105]
 [ 0.87206745]]
DEBUG:root:training time = %d0.177578
INFO:root:frame =3153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =3154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00040602684021
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:random_action_porb = 0.975141666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root:frame =3157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =3158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475168228149
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.97511
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:training error  = [[ 0.36702329]
 [ 0.75365251]
 [ 0.58125329]
 [ 0.40528083]
 [ 0.32191461]
 [ 0.50720596]
 [ 0.76699245]
 [ 0.42717391]
 [ 0.48025405]
 [ 0.42918956]
 [ 0.67703539]
 [ 0.44264743]
 [ 0.89341742]
 [ 0.61640292]
 [ 0.72225261]
 [ 0.50110358]]
DEBUG:root:training time = %d0.187139
INFO:root:frame =3161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =3162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.975078333333
DEBUG:root: dqn, choose action rondomly, need time 0.000213000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:frame =3165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290155410767
INFO:root:frame =3166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.975046666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.47817448]
 [ 2.71362472]
 [ 0.58827615]
 [ 0.67372173]
 [ 0.73307717]
 [ 0.53282273]
 [ 0.64601409]
 [ 0.80858886]
 [ 0.7314499 ]
 [ 0.50408107]
 [ 0.4562138 ]
 [ 0.60216862]
 [ 0.58827615]
 [ 0.49830854]
 [ 0.57370609]
 [ 0.29602903]]
DEBUG:root:training time = %d0.202317
INFO:root:frame =3169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000355958938599
INFO:root:frame =3170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000290155410767
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:random_action_porb = 0.975015
INFO:root:dqn select action Tensor("ArgMax_11:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014002
INFO:root:action choosen by dqn [0]
INFO:root:frame =3172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:frame =3173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000414133071899
INFO:root:frame =3174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046181678772
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.974983333333
DEBUG:root: dqn, choose action rondomly, need time 0.000161000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:training error  = [[ 0.63090503]
 [ 0.53753477]
 [ 0.75450885]
 [ 0.46568245]
 [ 0.6151427 ]
 [ 0.87728161]
 [ 0.58513945]
 [ 0.41321433]
 [ 1.16332436]
 [ 0.99700773]
 [ 0.69045854]
 [ 0.8743667 ]
 [ 0.78234792]
 [ 0.90128785]
 [ 0.37659833]
 [ 0.64036351]]
DEBUG:root:training time = %d0.199379
INFO:root:frame =3177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275850296021
INFO:root:frame =3178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239133834839
DEBUG:root: save sample needs time = 0.000134944915771
INFO:root:random_action_porb = 0.974951666667
DEBUG:root: dqn, choose action rondomly, need time 0.000245999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =3181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =3182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00032114982605
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:random_action_porb = 0.97492
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:training error  = [[ 0.50146008]
 [ 0.78377074]
 [ 0.55679393]
 [ 0.69042683]
 [ 0.69502258]
 [ 0.65469551]
 [ 0.67682511]
 [ 0.75021893]
 [ 0.64124453]
 [ 0.80680954]
 [ 0.54128206]
 [ 0.80680954]
 [ 0.61044842]
 [ 0.75021893]
 [ 0.65751815]
 [ 0.45236099]]
DEBUG:root:training time = %d0.190766
INFO:root:frame =3185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =3186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002281665802
DEBUG:root: save sample needs time = 0.000101804733276
INFO:root:random_action_porb = 0.974888333333
DEBUG:root: dqn, choose action rondomly, need time 0.000180999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:frame =3189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =3190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000238180160522
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.974856666667
DEBUG:root: dqn, choose action rondomly, need time 0.000167999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.51081479]
 [ 0.80423319]
 [ 0.094368  ]
 [ 0.60701531]
 [ 0.38288414]
 [ 0.53619319]
 [ 0.38288414]
 [ 0.094368  ]
 [ 0.56833726]
 [ 0.85011375]
 [ 0.60701531]
 [ 0.5994764 ]
 [ 0.3730554 ]
 [ 0.47569153]
 [ 0.53325307]
 [ 0.65903628]]
DEBUG:root:training time = %d0.175128
INFO:root:frame =3193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =3194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240087509155
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.974825
DEBUG:root: dqn, choose action rondomly, need time 0.000163000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:frame =3197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =3198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.974793333333
DEBUG:root: dqn, choose action rondomly, need time 0.000230000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:training error  = [[ 0.3559356 ]
 [ 0.65966356]
 [ 0.30476511]
 [ 0.62420243]
 [ 0.88591355]
 [ 0.64125061]
 [ 0.68756914]
 [ 0.77632993]
 [ 0.57914376]
 [ 0.41550291]
 [ 0.30010998]
 [ 0.70490187]
 [ 0.66345507]
 [ 0.76299369]
 [ 0.68398839]
 [ 0.68398839]]
DEBUG:root:training time = %d0.176551
INFO:root:frame =3201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000402927398682
INFO:root:frame =3202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000295162200928
DEBUG:root: save sample needs time = 0.000125169754028
INFO:root:random_action_porb = 0.974761666667
DEBUG:root: dqn, choose action rondomly, need time 0.000278999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =3205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =3206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000111103057861
INFO:root:random_action_porb = 0.97473
DEBUG:root: dqn, choose action rondomly, need time 0.000269000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.57795262]
 [ 0.70155096]
 [ 0.6291852 ]
 [ 0.53525782]
 [ 0.64657074]
 [ 0.72654158]
 [ 0.4725579 ]
 [ 0.63828331]
 [ 0.57795262]
 [ 0.45703611]
 [ 0.65807354]
 [ 0.68957919]
 [ 0.47353131]
 [ 3.72577   ]
 [ 0.62686646]
 [ 2.66385651]]
DEBUG:root:training time = %d0.181323
INFO:root:frame =3209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =3210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000284910202026
DEBUG:root: save sample needs time = 0.000125169754028
INFO:root:random_action_porb = 0.974698333333
INFO:root:dqn select action Tensor("ArgMax_12:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014139
INFO:root:action choosen by dqn [0]
INFO:root:frame =3212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =3213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:frame =3214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000723123550415
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:random_action_porb = 0.974666666667
DEBUG:root: dqn, choose action rondomly, need time 0.000213000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:training error  = [[ 0.4074682 ]
 [ 0.5300141 ]
 [ 0.63525599]
 [ 0.45174414]
 [ 0.90155947]
 [ 0.72161734]
 [ 0.48648927]
 [ 0.45569092]
 [ 0.43043879]
 [ 0.49196437]
 [ 0.45020965]
 [ 0.65831953]
 [ 0.50117111]
 [ 0.48648927]
 [ 0.520311  ]
 [ 0.72161734]]
DEBUG:root:training time = %d0.182642
INFO:root:frame =3217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =3218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000357866287231
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:random_action_porb = 0.974635
DEBUG:root: dqn, choose action rondomly, need time 0.000354999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =3221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =3222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000849962234497
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.974603333333
DEBUG:root: dqn, choose action rondomly, need time 0.000391
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0010461807251
INFO:root:training error  = [[ 0.46754035]
 [ 0.47732019]
 [ 0.63866889]
 [ 0.98774868]
 [ 0.62082243]
 [ 0.82151896]
 [ 0.50144386]
 [ 0.55242747]
 [ 0.85991442]
 [ 0.87645108]
 [ 0.90119189]
 [ 0.50794792]
 [ 0.34896949]
 [ 0.54814178]
 [ 0.62082243]
 [ 0.76051658]]
DEBUG:root:training time = %d0.199369
INFO:root:frame =3225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =3226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame = 3227 State into memory, numbers recorded 74 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000357866287231
INFO:root:random_action_porb = 0.974571666667
DEBUG:root: dqn, choose action rondomly, need time 0.000207000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3228current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =3229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000351905822754
INFO:root:frame =3230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000429153442383
DEBUG:root: save sample needs time = 0.000152826309204
INFO:root:random_action_porb = 0.97454
DEBUG:root: dqn, choose action rondomly, need time 0.000455000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000496864318848
INFO:root:training error  = [[ 0.49289191]
 [ 0.5544495 ]
 [ 0.49870312]
 [ 0.45317337]
 [ 0.45317337]
 [ 0.6289764 ]
 [ 0.74497956]
 [ 0.5568822 ]
 [ 0.61557364]
 [ 0.69262993]
 [ 0.62592602]
 [ 0.76911372]
 [ 0.70361656]
 [ 0.39696744]
 [ 0.69262993]
 [ 0.74161512]]
DEBUG:root:training time = %d0.19427
INFO:root:frame =3233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =3234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000307083129883
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.974508333333
DEBUG:root: dqn, choose action rondomly, need time 0.000323000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =3237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =3238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.974476666667
DEBUG:root: dqn, choose action rondomly, need time 0.000458999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.60750282]
 [ 0.39654693]
 [ 0.56720042]
 [ 0.64796561]
 [ 0.70105904]
 [ 0.57620668]
 [ 0.55333799]
 [ 0.64214593]
 [ 0.04528913]
 [ 0.66693187]
 [ 0.65576392]
 [ 0.56114185]
 [ 0.67527413]
 [ 3.5652914 ]
 [ 0.52238232]
 [ 0.86674637]]
DEBUG:root:training time = %d0.204732
INFO:root:frame =3241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000366926193237
INFO:root:frame =3242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000425100326538
DEBUG:root: save sample needs time = 0.000125885009766
INFO:root:random_action_porb = 0.974445
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =3245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000584125518799
INFO:root:frame =3246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root:random_action_porb = 0.974413333333
DEBUG:root: dqn, choose action rondomly, need time 0.000273999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.6021257 ]
 [ 0.49589333]
 [ 0.6021257 ]
 [ 0.81130964]
 [ 0.50911087]
 [ 1.26066887]
 [ 0.54370117]
 [ 0.57470047]
 [ 0.33531445]
 [ 3.27837706]
 [ 0.50152761]
 [ 0.60530013]
 [ 0.47438875]
 [ 0.51942122]
 [ 0.55396104]
 [ 0.44693682]]
DEBUG:root:training time = %d0.206925
INFO:root:frame =3249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000410079956055
INFO:root:frame =3250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000289916992188
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:random_action_porb = 0.974381666667
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =3253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =3254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000329971313477
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.97435
DEBUG:root: dqn, choose action rondomly, need time 0.000505000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.57338542]
 [ 0.63501889]
 [ 0.58408648]
 [ 0.60065693]
 [ 0.69042367]
 [ 0.54681093]
 [ 0.60473341]
 [ 0.80526155]
 [ 0.58969456]
 [ 0.76006925]
 [ 0.553653  ]
 [ 0.64144003]
 [ 0.68934482]
 [ 3.59132314]
 [ 0.34826225]
 [ 0.53865129]]
DEBUG:root:training time = %d0.207374
INFO:root:frame =3257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =3258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame = 3259 State into memory, numbers recorded 75 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.00070595741272
INFO:root:random_action_porb = 0.974318333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3260current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =3261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000510931015015
INFO:root:frame =3262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.974286666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.61219323]
 [ 0.67929727]
 [ 0.06869552]
 [ 0.76428378]
 [ 0.52972114]
 [ 0.72763938]
 [ 0.53251791]
 [ 0.51005036]
 [ 0.49953318]
 [ 0.76610905]
 [ 0.62796485]
 [ 0.55989951]
 [ 0.63169461]
 [ 0.60897547]
 [ 0.44792557]
 [ 0.53166085]]
DEBUG:root:training time = %d0.202531
INFO:root:frame =3265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:frame =3266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047492980957
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.974255
DEBUG:root: dqn, choose action rondomly, need time 0.000199000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180006027222
INFO:root:frame =3269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =3270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.974223333333
DEBUG:root: dqn, choose action rondomly, need time 0.000338000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:training error  = [[ 0.59169847]
 [ 0.44745338]
 [ 0.49543139]
 [ 0.47232455]
 [ 0.41954535]
 [ 0.47232455]
 [ 0.41907847]
 [ 0.70863324]
 [ 0.90104157]
 [ 0.59320623]
 [ 0.65189898]
 [ 0.64580721]
 [ 0.65824217]
 [ 0.44413847]
 [ 0.5100435 ]
 [ 0.37984639]]
DEBUG:root:training time = %d0.223507
INFO:root:frame =3273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:frame =3274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.974191666667
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =3277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =3278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.97416
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:training error  = [[ 0.45775849]
 [ 0.57046878]
 [ 0.61810374]
 [ 0.43074417]
 [ 0.52467185]
 [ 0.3677921 ]
 [ 0.74429321]
 [ 0.51854736]
 [ 0.85465878]
 [ 0.70805693]
 [ 0.3677921 ]
 [ 0.81578946]
 [ 0.68541354]
 [ 0.46260536]
 [ 0.79886782]
 [ 0.7962957 ]]
DEBUG:root:training time = %d0.220558
INFO:root:frame =3281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =3282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000152826309204
INFO:root:random_action_porb = 0.974128333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =3285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =3286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:random_action_porb = 0.974096666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.69227916]
 [ 0.58670747]
 [ 0.67566758]
 [ 0.50503218]
 [ 0.52966148]
 [ 0.52296561]
 [ 0.55174583]
 [ 0.58670747]
 [ 3.67785048]
 [ 0.79831046]
 [ 0.38214096]
 [ 0.51379502]
 [ 0.51772767]
 [ 0.76221418]
 [ 0.62227654]
 [ 0.57250476]]
DEBUG:root:training time = %d0.198656
INFO:root:frame =3289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =3290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000467777252197
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.974065
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294208526611
INFO:root:frame =3293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =3294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.974033333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:training error  = [[ 0.60373557]
 [ 0.54203725]
 [ 0.61537462]
 [ 0.49834758]
 [ 0.72943997]
 [ 0.62966639]
 [ 0.55199093]
 [ 0.41295934]
 [ 0.45336857]
 [ 0.61596727]
 [ 0.64991695]
 [ 0.64991695]
 [ 0.55455458]
 [ 0.45203263]
 [ 0.56802815]
 [ 0.65126926]]
DEBUG:root:training time = %d0.208754
INFO:root:frame =3297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =3298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277996063232
DEBUG:root: save sample needs time = 0.000123977661133
INFO:root:random_action_porb = 0.974001666667
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000177145004272
INFO:root:frame =3301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =3302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000287055969238
DEBUG:root: save sample needs time = 0.000179052352905
INFO:root:random_action_porb = 0.97397
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:training error  = [[ 0.88687068]
 [ 0.65340906]
 [ 0.51266772]
 [ 0.58562541]
 [ 0.7806685 ]
 [ 0.63819796]
 [ 0.70466328]
 [ 0.62628973]
 [ 0.62931681]
 [ 0.58664614]
 [ 0.62116814]
 [ 0.61497664]
 [ 0.37981114]
 [ 0.46035084]
 [ 0.37981114]
 [ 0.8156327 ]]
DEBUG:root:training time = %d0.203816
INFO:root:frame =3305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =3306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000622034072876
DEBUG:root: save sample needs time = 0.000130176544189
INFO:root:random_action_porb = 0.973938333333
DEBUG:root: dqn, choose action rondomly, need time 0.00027
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =3309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =3310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00029182434082
DEBUG:root: save sample needs time = 0.000180006027222
INFO:root:random_action_porb = 0.973906666667
DEBUG:root: dqn, choose action rondomly, need time 0.000348000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000353097915649
INFO:root:training error  = [[ 0.54729062]
 [ 0.53507781]
 [ 0.5153178 ]
 [ 0.56213671]
 [ 0.56193221]
 [ 0.54266375]
 [ 0.48861217]
 [ 0.55941004]
 [ 0.56353903]
 [ 0.71077675]
 [ 0.44844273]
 [ 0.56353903]
 [ 0.56193221]
 [ 0.65542883]
 [ 0.67137074]
 [ 0.51033777]]
DEBUG:root:training time = %d0.197689
INFO:root:frame =3313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255823135376
INFO:root:frame =3314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000325918197632
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.973875
DEBUG:root: dqn, choose action rondomly, need time 0.00027399999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =3317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =3318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.000249147415161
INFO:root:random_action_porb = 0.973843333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000276803970337
INFO:root:training error  = [[ 0.58257729]
 [ 0.7973206 ]
 [ 0.86126804]
 [ 0.62146431]
 [ 0.63989657]
 [ 0.75869799]
 [ 0.51314306]
 [ 0.57975787]
 [ 0.82456446]
 [ 0.61785936]
 [ 0.48948985]
 [ 0.71510893]
 [ 0.70459282]
 [ 0.72771424]
 [ 0.45114052]
 [ 0.69112909]]
DEBUG:root:training time = %d0.220857
INFO:root:frame =3321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =3322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00029993057251
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:random_action_porb = 0.973811666667
DEBUG:root: dqn, choose action rondomly, need time 0.000623999999988
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =3325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00055718421936
INFO:root:frame =3326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000576972961426
DEBUG:root: save sample needs time = 0.000120878219604
INFO:root:random_action_porb = 0.97378
DEBUG:root: dqn, choose action rondomly, need time 0.000190000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000179052352905
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.84957922]
 [ 0.84957922]
 [ 0.75554967]
 [ 4.00098801]
 [ 0.55920035]
 [ 0.55162257]
 [ 0.82227635]
 [ 0.59646463]
 [ 0.57308793]
 [ 0.56633598]
 [ 0.45398393]
 [ 0.06462926]
 [ 0.71125925]
 [ 0.65548903]
 [ 0.56633598]
 [ 0.51353937]]
DEBUG:root:training time = %d0.216675
INFO:root:frame =3329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =3330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame = 3331 State into memory, numbers recorded 76 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000625133514404
INFO:root:random_action_porb = 0.973748333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3332current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =3333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =3334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00023889541626
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.973716666667
DEBUG:root: dqn, choose action rondomly, need time 0.000635000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000166893005371
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.62561822]
 [ 0.59544271]
 [ 2.98846531]
 [ 0.62561822]
 [ 0.61555868]
 [ 0.51961923]
 [ 0.87268382]
 [ 1.07972622]
 [ 0.70148391]
 [ 0.47426659]
 [ 0.58559912]
 [ 0.60457325]
 [ 0.63120204]
 [ 0.51961923]
 [ 3.5083046 ]
 [ 0.64806849]]
DEBUG:root:training time = %d0.186935
INFO:root:frame =3337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000385999679565
INFO:root:frame =3338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000270128250122
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:random_action_porb = 0.973685
DEBUG:root: dqn, choose action rondomly, need time 0.000270999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:frame =3341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root:frame =3342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000497817993164
INFO:root:frame = 3343 State into memory, numbers recorded 77 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000543832778931
INFO:root:random_action_porb = 0.973653333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3344current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.71335834]
 [ 0.93577528]
 [ 0.80882043]
 [ 0.58584142]
 [ 0.03088061]
 [ 0.70599443]
 [ 0.77985305]
 [ 0.66706741]
 [ 0.71027511]
 [ 0.97508883]
 [ 0.40049994]
 [ 0.75829929]
 [ 0.57048899]
 [ 0.87197304]
 [ 0.84821552]
 [ 0.73791414]]
DEBUG:root:training time = %d0.215642
INFO:root:frame =3345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =3346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000126838684082
INFO:root:random_action_porb = 0.973621666667
DEBUG:root: dqn, choose action rondomly, need time 0.000187000000011
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:frame =3349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =3350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000266790390015
INFO:root:random_action_porb = 0.97359
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:training error  = [[ 0.6928665 ]
 [ 0.8967973 ]
 [ 0.656708  ]
 [ 1.00441277]
 [ 0.55551374]
 [ 0.72514081]
 [ 0.48109642]
 [ 0.64122921]
 [ 0.74509972]
 [ 0.57614297]
 [ 0.73552722]
 [ 0.70732206]
 [ 0.81335014]
 [ 0.83160257]
 [ 0.61504847]
 [ 0.80713511]]
DEBUG:root:training time = %d0.230147
INFO:root:frame =3353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000418186187744
INFO:root:frame =3354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002601146698
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.973558333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =3357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =3358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:random_action_porb = 0.973526666667
DEBUG:root: dqn, choose action rondomly, need time 0.000349
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000419855117798
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.63523626]
 [ 0.4661355 ]
 [ 3.57812762]
 [ 0.47652724]
 [ 0.92003518]
 [ 0.48763406]
 [ 0.96190065]
 [ 0.81029457]
 [ 0.80124265]
 [ 0.76593715]
 [ 0.4661355 ]
 [ 0.7520588 ]
 [ 0.57505625]
 [ 1.09456599]
 [ 0.54931873]
 [ 0.44331771]]
DEBUG:root:training time = %d0.211678
INFO:root:frame =3361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =3362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000360012054443
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.973495
DEBUG:root: dqn, choose action rondomly, need time 0.000506999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =3365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =3366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.973463333333
DEBUG:root: dqn, choose action rondomly, need time 0.000579999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312805175781
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.99117899]
 [ 3.74964666]
 [ 0.56495458]
 [ 0.56288058]
 [ 0.79092634]
 [ 0.63424546]
 [ 0.72635627]
 [ 0.6348806 ]
 [ 1.26297212]
 [ 0.62055194]
 [ 0.63424546]
 [ 0.72635627]
 [ 0.62055194]
 [ 0.49308476]
 [ 0.60669881]
 [ 0.94344801]]
DEBUG:root:training time = %d0.217063
INFO:root:frame =3369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =3370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00022292137146
DEBUG:root: save sample needs time = 0.00010085105896
INFO:root:random_action_porb = 0.973431666667
DEBUG:root: dqn, choose action rondomly, need time 0.000157999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000136852264404
INFO:root:frame =3373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =3374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436782836914
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.9734
DEBUG:root: dqn, choose action rondomly, need time 0.000365000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000356912612915
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.63309306]
 [ 0.80338675]
 [ 0.92060792]
 [ 0.80338675]
 [ 0.81208807]
 [ 0.92658728]
 [ 2.95792842]
 [ 0.66812402]
 [ 0.80042332]
 [ 0.40995452]
 [ 0.68405306]
 [ 0.86753672]
 [ 0.89706826]
 [ 0.01408381]
 [ 0.88747972]
 [ 0.67622739]]
DEBUG:root:training time = %d0.230265
INFO:root:frame =3377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:frame =3378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.973368333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =3381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame =3382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.973336666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:training error  = [[ 0.70298314]
 [ 0.4272562 ]
 [ 0.7761485 ]
 [ 1.01438892]
 [ 0.70306152]
 [ 1.01438892]
 [ 1.37031984]
 [ 1.04987562]
 [ 0.75563586]
 [ 0.53240931]
 [ 0.65342909]
 [ 0.65854245]
 [ 0.88068277]
 [ 0.64082301]
 [ 0.75563586]
 [ 0.64082301]]
DEBUG:root:training time = %d0.202896
INFO:root:frame =3385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =3386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229120254517
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.973305
DEBUG:root: dqn, choose action rondomly, need time 0.000167000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:frame =3389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =3390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000320911407471
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.973273333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:training error  = [[ 0.5267393 ]
 [ 0.57559878]
 [ 0.44138315]
 [ 0.60240841]
 [ 0.71707159]
 [ 0.81264508]
 [ 0.85537481]
 [ 0.81264508]
 [ 0.80727047]
 [ 0.57750469]
 [ 0.94885802]
 [ 0.85306901]
 [ 0.83492279]
 [ 0.59704953]
 [ 0.67994666]
 [ 0.83336371]]
DEBUG:root:training time = %d0.209089
INFO:root:frame =3393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =3394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000559091567993
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.973241666667
DEBUG:root: dqn, choose action rondomly, need time 0.000734000000008
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000476121902466
INFO:root:frame =3397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =3398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame = 3399 State into memory, numbers recorded 78 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000542163848877
INFO:root:random_action_porb = 0.97321
DEBUG:root: dqn, choose action rondomly, need time 0.00036999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3400current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.71461064]
 [ 0.71461064]
 [ 0.74615216]
 [ 3.94540095]
 [ 0.47328719]
 [ 0.42497772]
 [ 0.74248916]
 [ 0.86589599]
 [ 0.67074263]
 [ 0.99800402]
 [ 0.79849792]
 [ 0.98104012]
 [ 0.99800402]
 [ 0.62703866]
 [ 0.74615216]
 [ 0.77152431]]
DEBUG:root:training time = %d0.218788
INFO:root:frame =3401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000380992889404
INFO:root:frame =3402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235080718994
DEBUG:root: save sample needs time = 9.41753387451e-05
INFO:root:random_action_porb = 0.973178333333
DEBUG:root: dqn, choose action rondomly, need time 0.000158999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:frame =3405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =3406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.973146666667
DEBUG:root: dqn, choose action rondomly, need time 0.000224000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:training error  = [[ 0.86385077]
 [ 0.99158728]
 [ 0.8912499 ]
 [ 0.68169671]
 [ 0.6153028 ]
 [ 0.80758929]
 [ 0.99158728]
 [ 0.82426482]
 [ 0.60957843]
 [ 1.0808363 ]
 [ 0.67669487]
 [ 0.69784313]
 [ 0.68578154]
 [ 0.68027538]
 [ 0.73423547]
 [ 0.89985788]]
DEBUG:root:training time = %d0.187362
INFO:root:frame =3409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =3410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000589847564697
DEBUG:root: save sample needs time = 0.000184059143066
INFO:root:random_action_porb = 0.973115
DEBUG:root: dqn, choose action rondomly, need time 0.000277999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =3413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =3414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:random_action_porb = 0.973083333333
DEBUG:root: dqn, choose action rondomly, need time 0.000264000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:training error  = [[ 0.65809363]
 [ 0.61039627]
 [ 0.92011935]
 [ 0.70689058]
 [ 1.12194562]
 [ 0.88292879]
 [ 0.58467704]
 [ 0.62714285]
 [ 0.59517193]
 [ 0.59803885]
 [ 0.54129046]
 [ 0.69819534]
 [ 0.61899334]
 [ 1.02578163]
 [ 0.59803885]
 [ 0.56881618]]
DEBUG:root:training time = %d0.219731
INFO:root:frame =3417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =3418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.973051666667
INFO:root:dqn select action Tensor("ArgMax_13:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011916
INFO:root:action choosen by dqn [4]
INFO:root:frame =3420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:frame =3421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =3422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000338077545166
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.97302
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.63676345]
 [ 0.88960487]
 [ 0.49165136]
 [ 0.75101215]
 [ 0.66363686]
 [ 1.21704805]
 [ 3.55829358]
 [ 0.92490625]
 [ 0.97550696]
 [ 0.63191593]
 [ 0.63191593]
 [ 0.67830408]
 [ 1.09986639]
 [ 0.88960487]
 [ 0.49165136]
 [ 0.63191593]]
DEBUG:root:training time = %d0.213431
INFO:root:frame =3425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =3426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.972988333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =3429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000417947769165
INFO:root:frame =3430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame = 3431 State into memory, numbers recorded 79 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000541925430298
INFO:root:random_action_porb = 0.972956666667
DEBUG:root: dqn, choose action rondomly, need time 0.000249000000011
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3432current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:training error  = [[ 0.77663922]
 [ 0.69410861]
 [ 0.73289591]
 [ 1.14569342]
 [ 0.83646244]
 [ 0.92065912]
 [ 0.80274403]
 [ 0.72211158]
 [ 0.76387697]
 [ 0.51940614]
 [ 0.84979022]
 [ 0.99161768]
 [ 0.4378182 ]
 [ 0.84979022]
 [ 0.92834884]
 [ 0.84665108]]
DEBUG:root:training time = %d0.212525
INFO:root:frame =3433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =3434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:random_action_porb = 0.972925
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =3437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274181365967
INFO:root:frame =3438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.972893333333
DEBUG:root: dqn, choose action rondomly, need time 0.000377
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.77597708]
 [ 0.6126709 ]
 [ 3.06258345]
 [ 0.67675608]
 [ 0.57686275]
 [ 0.62044978]
 [ 0.92336792]
 [ 0.69432312]
 [ 0.69432312]
 [ 0.79170173]
 [ 0.56514096]
 [ 0.62044978]
 [ 0.62917763]
 [ 0.60353106]
 [ 0.5931989 ]
 [ 0.73824018]]
DEBUG:root:training time = %d0.204876
INFO:root:frame =3441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =3442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000276803970337
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.972861666667
DEBUG:root: dqn, choose action rondomly, need time 0.000197
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000175952911377
INFO:root:frame =3445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =3446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
DEBUG:root: save sample needs time = 0.00016713142395
INFO:root:random_action_porb = 0.97283
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.7474131 ]
 [ 0.5344432 ]
 [ 0.89616883]
 [ 0.47258413]
 [ 0.74794418]
 [ 0.52552599]
 [ 0.55487704]
 [ 0.97829896]
 [ 0.81108111]
 [ 0.56059331]
 [ 0.86123973]
 [ 3.97474861]
 [ 0.61862272]
 [ 0.77133334]
 [ 0.47258413]
 [ 1.05667198]]
DEBUG:root:training time = %d0.214671
INFO:root:frame =3449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =3450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428915023804
INFO:root:frame = 3451 State into memory, numbers recorded 80 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.00056791305542
INFO:root:random_action_porb = 0.972798333333
DEBUG:root: dqn, choose action rondomly, need time 0.000330000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3452current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =3453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =3454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.972766666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:training error  = [[ 0.70779371]
 [ 0.66688985]
 [ 0.68103701]
 [ 0.76753879]
 [ 0.65821898]
 [ 0.7515825 ]
 [ 0.74451375]
 [ 0.92965043]
 [ 0.8600347 ]
 [ 1.04389989]
 [ 0.74023271]
 [ 0.70977849]
 [ 0.68814176]
 [ 0.70977849]
 [ 0.58867705]
 [ 0.56631589]]
DEBUG:root:training time = %d0.211131
INFO:root:frame =3457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000326156616211
INFO:root:frame =3458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000258922576904
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.972735
DEBUG:root: dqn, choose action rondomly, need time 0.000242999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =3461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000451803207397
INFO:root:frame =3462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root:random_action_porb = 0.972703333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:training error  = [[ 0.76408535]
 [ 0.87301171]
 [ 0.66367257]
 [ 0.79787934]
 [ 0.85536957]
 [ 0.58490747]
 [ 0.84281898]
 [ 0.67476952]
 [ 0.91797817]
 [ 0.82863963]
 [ 0.93371546]
 [ 0.70353019]
 [ 0.62815529]
 [ 0.74139827]
 [ 0.7795499 ]
 [ 0.83844179]]
DEBUG:root:training time = %d0.211228
INFO:root:frame =3465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000519990921021
INFO:root:frame =3466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.972671666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =3469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049090385437
INFO:root:frame =3470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.97264
DEBUG:root: dqn, choose action rondomly, need time 0.000250999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.70153183]
 [ 0.61205   ]
 [ 0.70486987]
 [ 0.70486987]
 [ 1.12867117]
 [ 0.94859791]
 [ 0.69954586]
 [ 0.80139631]
 [ 0.74769014]
 [ 3.11241913]
 [ 0.57889122]
 [ 0.82523483]
 [ 0.89000428]
 [ 0.58384746]
 [ 0.80148166]
 [ 0.60065395]]
DEBUG:root:training time = %d0.219573
INFO:root:frame =3473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =3474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000282049179077
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.972608333333
DEBUG:root: dqn, choose action rondomly, need time 0.000450999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =3477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =3478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.972576666667
DEBUG:root: dqn, choose action rondomly, need time 0.000318000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:training error  = [[ 0.58375859]
 [ 0.81320912]
 [ 0.84832448]
 [ 0.81320912]
 [ 0.81320912]
 [ 0.83096784]
 [ 0.86093175]
 [ 0.79132164]
 [ 0.73940915]
 [ 0.58375859]
 [ 0.68084502]
 [ 0.91934741]
 [ 0.69032383]
 [ 0.91809148]
 [ 0.88041431]
 [ 0.81018984]]
DEBUG:root:training time = %d0.203355
INFO:root:frame =3481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =3482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275135040283
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.972545
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =3485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =3486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031590461731
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.972513333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.55474633]
 [ 0.5729782 ]
 [ 1.07227719]
 [ 0.64478981]
 [ 0.5729782 ]
 [ 0.62957406]
 [ 0.76810038]
 [ 0.88296461]
 [ 0.4803175 ]
 [ 0.73653191]
 [ 0.70000219]
 [ 1.14022851]
 [ 1.03563416]
 [ 0.67013204]
 [ 1.1123476 ]
 [ 0.02950431]]
DEBUG:root:training time = %d0.208688
INFO:root:frame =3489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =3490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470161437988
INFO:root:frame = 3491 State into memory, numbers recorded 81 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000562906265259
INFO:root:random_action_porb = 0.972481666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3492current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =3493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =3494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000339984893799
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.97245
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:training error  = [[ 0.75076753]
 [ 0.94370002]
 [ 0.74640924]
 [ 0.87327373]
 [ 0.70492268]
 [ 0.91230357]
 [ 0.77049768]
 [ 0.57701194]
 [ 0.87327373]
 [ 0.57701194]
 [ 0.71992517]
 [ 0.70492268]
 [ 0.91230357]
 [ 0.75591445]
 [ 0.69101495]
 [ 0.81692517]]
DEBUG:root:training time = %d0.205324
INFO:root:frame =3497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =3498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233173370361
DEBUG:root: save sample needs time = 0.000192165374756
INFO:root:random_action_porb = 0.972418333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =3501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =3502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000451803207397
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.972386666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.10356379e-01]
 [  8.06765020e-01]
 [  8.92256737e-01]
 [  9.67811644e-01]
 [  8.24112475e-01]
 [  1.35988605e+00]
 [  1.13220179e+00]
 [  7.48006821e-01]
 [  6.90953076e-01]
 [  3.12402123e-03]
 [  1.29449606e+00]
 [  1.25274253e+00]
 [  3.12402123e-03]
 [  6.90953076e-01]
 [  3.91811752e+00]
 [  6.65622532e-01]]
DEBUG:root:training time = %d0.193727
INFO:root:frame =3505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =3506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.972355
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =3509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =3510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.972323333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000008
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:training error  = [[ 0.83768225]
 [ 1.27617621]
 [ 0.8982628 ]
 [ 1.04575789]
 [ 0.97737664]
 [ 0.97227323]
 [ 1.27617621]
 [ 0.70324224]
 [ 0.8982628 ]
 [ 0.96019161]
 [ 1.25016499]
 [ 1.06142604]
 [ 1.08069158]
 [ 1.06466103]
 [ 0.66089255]
 [ 0.99023163]]
DEBUG:root:training time = %d0.222424
INFO:root:frame =3513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame =3514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000341892242432
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.972291666667
DEBUG:root: dqn, choose action rondomly, need time 0.000478000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =3517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470161437988
INFO:root:frame =3518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.97226
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.89369684]
 [ 1.08405709]
 [ 0.9587456 ]
 [ 0.67506725]
 [ 0.85561651]
 [ 0.90492207]
 [ 1.27324963]
 [ 1.30374408]
 [ 0.89942187]
 [ 0.96337718]
 [ 1.43152964]
 [ 0.76550317]
 [ 0.89942187]
 [ 4.5036478 ]
 [ 0.77289367]
 [ 0.70478982]]
DEBUG:root:training time = %d0.218205
INFO:root:frame =3521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =3522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000325918197632
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.972228333333
DEBUG:root: dqn, choose action rondomly, need time 0.000537999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =3525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =3526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.972196666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291999999988
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:training error  = [[ 0.72176641]
 [ 0.76293039]
 [ 0.84743053]
 [ 0.70306152]
 [ 1.33113778]
 [ 0.74271274]
 [ 0.86435962]
 [ 0.83797729]
 [ 0.78109491]
 [ 0.7244637 ]
 [ 0.96344084]
 [ 0.76901001]
 [ 0.6211952 ]
 [ 1.0827508 ]
 [ 1.45507169]
 [ 0.84743053]]
DEBUG:root:training time = %d0.217362
INFO:root:frame =3529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =3530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.972165
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =3533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =3534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000637054443359
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.972133333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000360012054443
INFO:root:training error  = [[ 1.24858105]
 [ 1.33314109]
 [ 0.76280046]
 [ 0.86139727]
 [ 0.75966853]
 [ 1.24990487]
 [ 1.24990487]
 [ 0.61271864]
 [ 0.67313635]
 [ 0.8152107 ]
 [ 0.80967319]
 [ 0.75966853]
 [ 1.17301333]
 [ 0.86139727]
 [ 1.18047225]
 [ 0.76280046]]
DEBUG:root:training time = %d0.225391
INFO:root:frame =3537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =3538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:random_action_porb = 0.972101666667
DEBUG:root: dqn, choose action rondomly, need time 0.000269000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =3541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000429153442383
INFO:root:frame =3542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000418901443481
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.97207
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.80451548]
 [ 0.70198238]
 [ 3.84618473]
 [ 0.80871409]
 [ 0.77470738]
 [ 0.82522273]
 [ 0.68244493]
 [ 3.84618473]
 [ 0.75072294]
 [ 0.80871409]
 [ 0.72769469]
 [ 3.84618473]
 [ 0.78002656]
 [ 0.71487021]
 [ 0.77470738]
 [ 0.86768419]]
DEBUG:root:training time = %d0.214237
INFO:root:frame =3545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:frame =3546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.972038333333
DEBUG:root: dqn, choose action rondomly, need time 0.000376000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root:frame =3549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =3550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428199768066
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.972006666667
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:training error  = [[ 1.22344685]
 [ 1.29916596]
 [ 0.82437044]
 [ 0.69098479]
 [ 0.95433193]
 [ 0.87715119]
 [ 0.77229851]
 [ 1.3893168 ]
 [ 0.76534796]
 [ 1.22344685]
 [ 0.58835661]
 [ 0.7202521 ]
 [ 0.78075445]
 [ 0.76396698]
 [ 0.58047557]
 [ 0.60701382]]
DEBUG:root:training time = %d0.226962
INFO:root:frame =3553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =3554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.971975
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =3557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =3558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.971943333333
DEBUG:root: dqn, choose action rondomly, need time 0.000358999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 0.83479732]
 [ 0.85860962]
 [ 1.01994061]
 [ 0.85860962]
 [ 0.98353541]
 [ 0.67552489]
 [ 0.6224255 ]
 [ 0.74026388]
 [ 1.2409755 ]
 [ 1.0159936 ]
 [ 0.89875996]
 [ 1.06259358]
 [ 0.67799467]
 [ 0.74691027]
 [ 0.80937976]
 [ 0.75482035]]
DEBUG:root:training time = %d0.208983
INFO:root:frame =3561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:frame =3562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.971911666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =3565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame =3566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.97188
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.75171316]
 [ 0.79781121]
 [ 0.80163878]
 [ 0.93904942]
 [ 0.6479165 ]
 [ 1.15939629]
 [ 3.29584718]
 [ 0.79086357]
 [ 0.98876691]
 [ 0.95983094]
 [ 0.90576053]
 [ 1.03446007]
 [ 0.98876691]
 [ 0.96676117]
 [ 0.5720315 ]
 [ 0.65712231]]
DEBUG:root:training time = %d0.218042
INFO:root:frame =3569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000378131866455
INFO:root:frame =3570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.971848333333
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =3573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =3574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.971816666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:training error  = [[ 0.94655746]
 [ 0.9909929 ]
 [ 1.20439494]
 [ 0.78166479]
 [ 0.78483319]
 [ 0.79196143]
 [ 1.53506982]
 [ 1.36718011]
 [ 0.78483319]
 [ 0.82044923]
 [ 0.66528958]
 [ 0.89007086]
 [ 0.63356364]
 [ 0.75848866]
 [ 0.94521999]
 [ 0.79621571]]
DEBUG:root:training time = %d0.216973
INFO:root:frame =3577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =3578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.971785
DEBUG:root: dqn, choose action rondomly, need time 0.000294000000011
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =3581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000424861907959
INFO:root:frame =3582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000420093536377
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.971753333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:training error  = [[ 1.08278847]
 [ 0.73619145]
 [ 0.73841065]
 [ 0.97930288]
 [ 0.91804391]
 [ 0.75260144]
 [ 0.79853714]
 [ 0.63166732]
 [ 0.75260144]
 [ 1.14387512]
 [ 0.76953864]
 [ 0.89141554]
 [ 0.76953864]
 [ 0.76272213]
 [ 0.86299652]
 [ 0.76272213]]
DEBUG:root:training time = %d0.242339
INFO:root:frame =3585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =3586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.971721666667
DEBUG:root: dqn, choose action rondomly, need time 0.000263000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =3589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438213348389
INFO:root:frame =3590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.97169
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.85266036]
 [ 0.89774221]
 [ 0.0096582 ]
 [ 0.8079201 ]
 [ 0.8079201 ]
 [ 0.99610901]
 [ 0.80311662]
 [ 0.7615416 ]
 [ 1.1155827 ]
 [ 0.59120268]
 [ 0.78989363]
 [ 1.00541461]
 [ 1.15422869]
 [ 0.81730443]
 [ 0.89911985]
 [ 4.4462409 ]]
DEBUG:root:training time = %d0.212668
INFO:root:frame =3593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =3594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.971658333333
DEBUG:root: dqn, choose action rondomly, need time 0.000266999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =3597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =3598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.971626666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:training error  = [[ 0.97610426]
 [ 1.04449046]
 [ 1.09966433]
 [ 1.01441002]
 [ 1.0358845 ]
 [ 1.12102461]
 [ 1.04500711]
 [ 0.56115043]
 [ 1.04904127]
 [ 0.94032151]
 [ 0.97610426]
 [ 1.1536243 ]
 [ 0.66538602]
 [ 0.79581577]
 [ 1.17746925]
 [ 1.13530707]]
DEBUG:root:training time = %d0.227295
INFO:root:frame =3601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000397920608521
INFO:root:frame =3602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000514030456543
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.971595
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =3605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =3606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.971563333333
DEBUG:root: dqn, choose action rondomly, need time 0.000263999999987
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.46151829]
 [ 1.19888151]
 [ 1.24405825]
 [ 3.46151829]
 [ 0.77794415]
 [ 1.1377064 ]
 [ 0.66869164]
 [ 0.82482946]
 [ 0.80097461]
 [ 0.78802669]
 [ 1.14037311]
 [ 1.2592473 ]
 [ 0.93770438]
 [ 1.49622953]
 [ 0.77099162]
 [ 1.1377064 ]]
DEBUG:root:training time = %d0.214083
INFO:root:frame =3609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =3610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.971531666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =3613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =3614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9715
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:training error  = [[ 1.66136253]
 [ 0.66640705]
 [ 1.09634662]
 [ 0.69449955]
 [ 0.69538999]
 [ 1.08013451]
 [ 1.16600442]
 [ 1.03805208]
 [ 1.18285453]
 [ 0.75770479]
 [ 0.63742876]
 [ 0.94127613]
 [ 0.74911249]
 [ 0.97352052]
 [ 0.86013556]
 [ 0.8668316 ]]
DEBUG:root:training time = %d0.226811
INFO:root:frame =3617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =3618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.971468333333
DEBUG:root: dqn, choose action rondomly, need time 0.000445999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =3621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =3622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464200973511
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.971436666667
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.80564153]
 [ 0.82644469]
 [ 0.79292071]
 [ 0.71437526]
 [ 1.05395818]
 [ 3.40750718]
 [ 1.06979191]
 [ 0.82510662]
 [ 0.66353583]
 [ 1.27729034]
 [ 1.18614686]
 [ 0.01047869]
 [ 0.8306427 ]
 [ 0.94604903]
 [ 0.8577491 ]
 [ 0.96060848]]
DEBUG:root:training time = %d0.217553
INFO:root:frame =3625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000260829925537
INFO:root:frame =3626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240087509155
DEBUG:root: save sample needs time = 0.000158071517944
INFO:root:random_action_porb = 0.971405
INFO:root:dqn select action Tensor("ArgMax_14:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00904300000001
INFO:root:action choosen by dqn [4]
INFO:root:frame =3628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =3629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000557899475098
INFO:root:frame =3630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.971373333333
INFO:root:dqn select action Tensor("ArgMax_15:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010834
INFO:root:action choosen by dqn [4]
INFO:root:frame =3632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.78038538]
 [ 0.98436034]
 [ 1.08059835]
 [ 0.87714404]
 [ 1.08059835]
 [ 0.87714404]
 [ 0.87714404]
 [ 0.76931107]
 [ 4.32263136]
 [ 0.87714404]
 [ 0.96313381]
 [ 0.96643859]
 [ 0.88360101]
 [ 0.98436034]
 [ 0.7187022 ]
 [ 0.87714404]]
DEBUG:root:training time = %d0.225159
INFO:root:frame =3633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =3634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249147415161
DEBUG:root: save sample needs time = 0.000174045562744
INFO:root:random_action_porb = 0.971341666667
DEBUG:root: dqn, choose action rondomly, need time 0.000499000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =3637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000591993331909
INFO:root:frame =3638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000346899032593
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.97131
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.92700773]
 [ 1.08909321]
 [ 1.02267194]
 [ 0.6913051 ]
 [ 1.48827732]
 [ 1.42006242]
 [ 0.9807719 ]
 [ 1.48827732]
 [ 1.45371687]
 [ 0.83239591]
 [ 0.92067927]
 [ 0.95435989]
 [ 1.90525591]
 [ 1.13923681]
 [ 1.42006242]
 [ 4.185287  ]]
DEBUG:root:training time = %d0.21504
INFO:root:frame =3641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =3642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.971278333333
DEBUG:root: dqn, choose action rondomly, need time 0.000454999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =3645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =3646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.971246666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.84850365]
 [ 1.05925572]
 [ 1.48475647]
 [ 0.01394022]
 [ 1.01981926]
 [ 3.53213096]
 [ 1.05925572]
 [ 1.1922828 ]
 [ 0.91155499]
 [ 0.80590868]
 [ 0.68509305]
 [ 0.87896705]
 [ 0.95764214]
 [ 0.85671425]
 [ 0.78901243]
 [ 0.92683512]]
DEBUG:root:training time = %d0.244226
INFO:root:frame =3649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =3650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame = 3651 State into memory, numbers recorded 82 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000592947006226
INFO:root:random_action_porb = 0.971215
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3652current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =3653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =3654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.971183333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:training error  = [[ 0.78207123]
 [ 0.7894733 ]
 [ 0.894301  ]
 [ 0.70498198]
 [ 0.86430466]
 [ 1.39245021]
 [ 0.93853569]
 [ 1.01778626]
 [ 0.894301  ]
 [ 1.08527875]
 [ 0.79382455]
 [ 1.28507113]
 [ 0.8922928 ]
 [ 1.02246368]
 [ 0.91726011]
 [ 1.08527875]]
DEBUG:root:training time = %d0.208034
INFO:root:frame =3657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =3658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000396966934204
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.971151666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =3661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =3662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:random_action_porb = 0.97112
DEBUG:root: dqn, choose action rondomly, need time 0.000277999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.91734415]
 [ 1.10372436]
 [ 0.87892413]
 [ 1.00014114]
 [ 0.9025377 ]
 [ 1.08842444]
 [ 1.21306181]
 [ 0.97623241]
 [ 0.99889404]
 [ 0.98468208]
 [ 0.96510029]
 [ 0.72877544]
 [ 4.51564121]
 [ 1.22597349]
 [ 1.16543603]
 [ 0.92664421]]
DEBUG:root:training time = %d0.213647
INFO:root:frame =3665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =3666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000211000442505
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.971088333333
DEBUG:root: dqn, choose action rondomly, need time 0.000174999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000136852264404
INFO:root:frame =3669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =3670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame = 3671 State into memory, numbers recorded 83 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:random_action_porb = 0.971056666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3672current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.68164241e+00]
 [  1.03209090e+00]
 [  8.09127510e-01]
 [  9.94601905e-01]
 [  1.76627779e+00]
 [  1.09278667e+00]
 [  8.49139810e-01]
 [  1.10396795e-05]
 [  1.11133194e+00]
 [  6.54567420e-01]
 [  1.40972590e+00]
 [  1.40972590e+00]
 [  7.01881707e-01]
 [  9.96596396e-01]
 [  8.60988379e-01]
 [  1.07335377e+00]]
DEBUG:root:training time = %d0.21983
INFO:root:frame =3673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =3674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.971025
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =3677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =3678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.970993333333
DEBUG:root: dqn, choose action rondomly, need time 0.000221999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.21400309e+00]
 [  1.51761341e+00]
 [  9.97426748e-01]
 [  1.35070658e+00]
 [  1.01906049e+00]
 [  1.07336175e+00]
 [  1.40159857e-04]
 [  7.90924668e-01]
 [  1.01421416e+00]
 [  1.12475967e+00]
 [  9.78072584e-01]
 [  8.90650392e-01]
 [  9.78072584e-01]
 [  8.78344893e-01]
 [  1.71496439e+00]
 [  1.21400309e+00]]
DEBUG:root:training time = %d0.215531
INFO:root:frame =3681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =3682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000246047973633
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.970961666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =3685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =3686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:random_action_porb = 0.97093
DEBUG:root: dqn, choose action rondomly, need time 0.000278999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:training error  = [[ 1.10503125]
 [ 1.00542426]
 [ 1.30387259]
 [ 1.13932645]
 [ 0.98317987]
 [ 0.83424848]
 [ 0.93843961]
 [ 0.82712108]
 [ 1.2475071 ]
 [ 0.96845347]
 [ 0.77937812]
 [ 0.97952557]
 [ 1.06200576]
 [ 0.84007728]
 [ 1.31536686]
 [ 1.55998802]]
DEBUG:root:training time = %d0.230602
INFO:root:frame =3689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000357866287231
INFO:root:frame =3690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame = 3691 State into memory, numbers recorded 84 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000540018081665
INFO:root:random_action_porb = 0.970898333333
DEBUG:root: dqn, choose action rondomly, need time 0.000278000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3692current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =3693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =3694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:random_action_porb = 0.970866666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.14176261]
 [ 1.12751651]
 [ 1.2332449 ]
 [ 0.81509876]
 [ 0.90513802]
 [ 0.83861995]
 [ 1.2505554 ]
 [ 1.22025275]
 [ 1.00177848]
 [ 0.82815528]
 [ 0.84302735]
 [ 0.00179423]
 [ 0.91340244]
 [ 0.85798234]
 [ 0.6842345 ]
 [ 0.85332096]]
DEBUG:root:training time = %d0.228051
INFO:root:frame =3697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =3698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame = 3699 State into memory, numbers recorded 85 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000576019287109
INFO:root:random_action_porb = 0.970835
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3700current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =3701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =3702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475168228149
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.970803333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:training error  = [[ 0.96051872]
 [ 1.22315359]
 [ 1.05042875]
 [ 1.10289896]
 [ 0.83011436]
 [ 1.0842855 ]
 [ 1.52369106]
 [ 1.52369106]
 [ 0.88421786]
 [ 0.67271233]
 [ 0.74041486]
 [ 1.24957442]
 [ 1.00241995]
 [ 0.68391895]
 [ 1.32035041]
 [ 0.86101317]]
DEBUG:root:training time = %d0.21734
INFO:root:frame =3705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =3706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.970771666667
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: ememy has been killed for 3 times 
INFO:root:enemies_left [0]
INFO:root:frame =3709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =3710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame = 3711 State into memory, numbers recorded 86 action = 4, reward = 1
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:random_action_porb = 0.97074
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3712current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:training error  = [[ 1.04772496]
 [ 0.79832071]
 [ 1.10111296]
 [ 1.22045076]
 [ 0.87833416]
 [ 1.09623885]
 [ 1.19118762]
 [ 0.97001201]
 [ 0.92218792]
 [ 1.04867399]
 [ 1.09444225]
 [ 0.87009501]
 [ 1.03018498]
 [ 1.12040269]
 [ 1.10111296]
 [ 1.10000038]]
DEBUG:root:training time = %d0.210756
INFO:root:frame =3713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =3714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000284910202026
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.970708333333
DEBUG:root: dqn, choose action rondomly, need time 0.000244000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =3717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =3718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.970676666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.76107895]
 [ 1.19683158]
 [ 1.23374486]
 [ 0.91534305]
 [ 0.80022371]
 [ 0.88036597]
 [ 1.05350006]
 [ 3.61176729]
 [ 0.89926094]
 [ 0.78053027]
 [ 3.61176729]
 [ 0.87058616]
 [ 1.14524627]
 [ 1.60762477]
 [ 0.82964867]
 [ 0.82964867]]
DEBUG:root:training time = %d0.22685
INFO:root:frame =3721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame =3722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000278949737549
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:random_action_porb = 0.970645
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =3725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491857528687
INFO:root:frame =3726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494956970215
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.970613333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:training error  = [[ 1.11213243]
 [ 0.98658323]
 [ 0.93795556]
 [ 1.85199404]
 [ 1.30561984]
 [ 1.39870524]
 [ 1.23359227]
 [ 1.61177742]
 [ 0.85336679]
 [ 0.93087929]
 [ 1.0815345 ]
 [ 1.13599408]
 [ 1.05840397]
 [ 1.14912784]
 [ 1.19451654]
 [ 1.31773925]]
DEBUG:root:training time = %d0.220502
INFO:root:frame =3729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =3730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000310897827148
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:random_action_porb = 0.970581666667
DEBUG:root: dqn, choose action rondomly, need time 0.000197999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:frame =3733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =3734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.97055
DEBUG:root: dqn, choose action rondomly, need time 0.000380000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:training error  = [[ 1.09659028]
 [ 0.98450798]
 [ 1.03538764]
 [ 0.90261018]
 [ 0.98693186]
 [ 1.43039572]
 [ 1.30097759]
 [ 1.15256131]
 [ 1.03538764]
 [ 1.28991461]
 [ 0.8738246 ]
 [ 1.32078445]
 [ 1.35875189]
 [ 1.28323388]
 [ 0.79100609]
 [ 1.15256131]]
DEBUG:root:training time = %d0.215166
INFO:root:frame =3737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root:frame =3738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.970518333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =3741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =3742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
DEBUG:root: save sample needs time = 0.000199794769287
INFO:root:random_action_porb = 0.970486666667
DEBUG:root: dqn, choose action rondomly, need time 0.000336999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:training error  = [[ 1.20180702]
 [ 1.1192925 ]
 [ 0.82011753]
 [ 1.04192293]
 [ 1.13711655]
 [ 0.74123573]
 [ 1.08890212]
 [ 1.12757719]
 [ 1.231987  ]
 [ 0.76743186]
 [ 1.05090189]
 [ 0.92047429]
 [ 0.97073728]
 [ 1.17686296]
 [ 1.22045505]
 [ 0.93883878]]
DEBUG:root:training time = %d0.227237
INFO:root:frame =3745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =3746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042200088501
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:random_action_porb = 0.970455
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =3749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =3750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424146652222
INFO:root:frame = 3751 State into memory, numbers recorded 87 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000526189804077
INFO:root:random_action_porb = 0.970423333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3752current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.80920303]
 [ 1.22360933]
 [ 0.91903657]
 [ 0.00962262]
 [ 1.02895033]
 [ 0.7599678 ]
 [ 0.93699157]
 [ 3.82417274]
 [ 4.50449371]
 [ 1.22328866]
 [ 0.96503657]
 [ 0.91903657]
 [ 0.89806032]
 [ 1.21025681]
 [ 1.50316441]
 [ 1.15119791]]
DEBUG:root:training time = %d0.222908
INFO:root:frame =3753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =3754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000522136688232
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.970391666667
DEBUG:root: dqn, choose action rondomly, need time 0.000270999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =3757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =3758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.97036
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:training error  = [[ 0.98234791]
 [ 1.00861681]
 [ 1.07837892]
 [ 1.19560075]
 [ 1.01339602]
 [ 1.49876666]
 [ 0.96016359]
 [ 0.97373134]
 [ 1.14007986]
 [ 1.24379873]
 [ 0.93309999]
 [ 0.88031948]
 [ 1.1312989 ]
 [ 1.20917857]
 [ 1.01339602]
 [ 0.98234791]]
DEBUG:root:training time = %d0.219832
INFO:root:frame =3761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =3762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame = 3763 State into memory, numbers recorded 88 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000615835189819
INFO:root:random_action_porb = 0.970328333333
DEBUG:root: dqn, choose action rondomly, need time 0.000211999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root: ememy has been killed for 4 times 
INFO:root:enemies_left [0]
INFO:root:frame =3764current_observation done, NOT record action 0, reward = 1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =3765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =3766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame = 3767 State into memory, numbers recorded 89 action = 0, reward = 1
DEBUG:root: save sample needs time = 0.000533103942871
INFO:root:random_action_porb = 0.970296666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3768current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.16681182e+00]
 [  8.38661849e-01]
 [  1.16681182e+00]
 [  1.41517079e+00]
 [  1.39842999e+00]
 [  1.07379651e+00]
 [  7.78522954e-05]
 [  7.58515239e-01]
 [  1.01547456e+00]
 [  1.14021420e+00]
 [  9.78329122e-01]
 [  1.01017666e+00]
 [  1.30445194e+00]
 [  1.62233782e+00]
 [  9.09112751e-01]
 [  1.25760829e+00]]
DEBUG:root:training time = %d0.21644
INFO:root:frame =3769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =3770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000380992889404
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.970265
DEBUG:root: dqn, choose action rondomly, need time 0.000257000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =3773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =3774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480890274048
INFO:root:frame = 3775 State into memory, numbers recorded 90 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000590085983276
INFO:root:random_action_porb = 0.970233333333
DEBUG:root: dqn, choose action rondomly, need time 0.000328999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3776current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000416994094849
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.15730035]
 [ 1.01255131]
 [ 1.00711942]
 [ 1.09450209]
 [ 4.45412302]
 [ 0.91874033]
 [ 1.00738358]
 [ 0.98935115]
 [ 0.9651565 ]
 [ 4.59382105]
 [ 0.99990082]
 [ 1.06226528]
 [ 1.03116095]
 [ 1.11946607]
 [ 1.01836741]
 [ 0.97577262]]
DEBUG:root:training time = %d0.207228
INFO:root:frame =3777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000346899032593
INFO:root:frame =3778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000256061553955
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.970201666667
DEBUG:root: dqn, choose action rondomly, need time 0.000169
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:frame =3781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =3782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.97017
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:training error  = [[ 1.17769074]
 [ 0.89452469]
 [ 0.98783022]
 [ 0.98820943]
 [ 1.17461693]
 [ 0.98820943]
 [ 1.42242277]
 [ 0.93047082]
 [ 0.8109197 ]
 [ 1.05588591]
 [ 1.44109607]
 [ 0.98820943]
 [ 1.03345156]
 [ 1.00900376]
 [ 1.13508761]
 [ 1.04389024]]
DEBUG:root:training time = %d0.201288
INFO:root:frame =3785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =3786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000396966934204
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:random_action_porb = 0.970138333333
DEBUG:root: dqn, choose action rondomly, need time 0.000278000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =3789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000378847122192
INFO:root:frame =3790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000416040420532
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.970106666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.42056251]
 [ 1.15754247]
 [ 1.25833988]
 [ 1.03273427]
 [ 0.95028734]
 [ 0.92269719]
 [ 1.2240988 ]
 [ 1.1391269 ]
 [ 4.34907436]
 [ 1.31134486]
 [ 0.88726234]
 [ 1.29885077]
 [ 1.09359634]
 [ 1.13435614]
 [ 1.32815111]
 [ 0.99345326]]
DEBUG:root:training time = %d0.220033
INFO:root:frame =3793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292778015137
INFO:root:frame =3794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame = 3795 State into memory, numbers recorded 91 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:random_action_porb = 0.970075
DEBUG:root: dqn, choose action rondomly, need time 0.000207000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3796current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =3797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =3798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.970043333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:training error  = [[ 1.04240191]
 [ 1.22867823]
 [ 0.98985964]
 [ 0.99447632]
 [ 1.05990362]
 [ 1.01743603]
 [ 1.13402712]
 [ 0.87135869]
 [ 1.05990362]
 [ 1.07890189]
 [ 1.02832735]
 [ 0.91772783]
 [ 1.16302395]
 [ 0.95884454]
 [ 0.82238185]
 [ 1.02091742]]
DEBUG:root:training time = %d0.221091
INFO:root:frame =3801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =3802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
DEBUG:root: save sample needs time = 0.000245809555054
INFO:root:random_action_porb = 0.970011666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =3805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =3806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.96998
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000327825546265
INFO:root:training error  = [[ 1.09789693]
 [ 0.9588483 ]
 [ 1.03683984]
 [ 0.90323365]
 [ 0.91193378]
 [ 1.27993894]
 [ 1.43935645]
 [ 0.96723378]
 [ 1.37805605]
 [ 0.97070348]
 [ 1.40208185]
 [ 0.90323365]
 [ 0.98540139]
 [ 0.89011765]
 [ 1.38722003]
 [ 0.98673481]]
DEBUG:root:training time = %d0.226841
INFO:root:frame =3809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =3810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466823577881
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.969948333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =3813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =3814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.969916666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:training error  = [[ 1.17820001]
 [ 1.25659883]
 [ 1.46613872]
 [ 1.15218866]
 [ 1.44801462]
 [ 0.879475  ]
 [ 1.16723633]
 [ 1.14368331]
 [ 1.19888985]
 [ 0.96948236]
 [ 1.01265502]
 [ 0.92606407]
 [ 1.10370839]
 [ 1.15416718]
 [ 0.888524  ]
 [ 1.31120956]]
DEBUG:root:training time = %d0.221987
INFO:root:frame =3817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =3818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.969885
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =3821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000406980514526
INFO:root:frame =3822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.969853333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.98691672]
 [ 0.92032063]
 [ 1.22023165]
 [ 4.34132957]
 [ 1.17875075]
 [ 1.27517009]
 [ 0.87982202]
 [ 1.39298594]
 [ 1.24708104]
 [ 1.01034915]
 [ 0.82821774]
 [ 1.41398215]
 [ 1.01053715]
 [ 1.01709366]
 [ 1.55825901]
 [ 1.27223825]]
DEBUG:root:training time = %d0.229432
INFO:root:frame =3825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =3826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.969821666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =3829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame =3830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame = 3831 State into memory, numbers recorded 92 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000545024871826
INFO:root:random_action_porb = 0.96979
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3832current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[ 1.05518043]
 [ 1.03077757]
 [ 1.00225198]
 [ 1.11868322]
 [ 0.97748417]
 [ 0.90794921]
 [ 1.05533326]
 [ 1.43073785]
 [ 1.20871294]
 [ 1.17084527]
 [ 1.07195127]
 [ 1.24527967]
 [ 0.97748417]
 [ 1.01279318]
 [ 1.07195127]
 [ 0.8828159 ]]
DEBUG:root:training time = %d0.213651
INFO:root: ememy has been killed for 5 times 
INFO:root:enemies_left [0]
INFO:root:frame =3833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =3834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame = 3835 State into memory, numbers recorded 93 action = 0, reward = 1
DEBUG:root: save sample needs time = 0.000357151031494
INFO:root:random_action_porb = 0.969758333333
DEBUG:root: dqn, choose action rondomly, need time 0.000155000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3836current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:frame =3837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =3838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000666856765747
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.969726666667
DEBUG:root: dqn, choose action rondomly, need time 0.000526000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.41352403]
 [ 1.41352403]
 [ 1.02139926]
 [ 1.15838397]
 [ 1.03196681]
 [ 1.566064  ]
 [ 1.26369452]
 [ 1.05859625]
 [ 4.96681738]
 [ 1.67101359]
 [ 1.11090171]
 [ 4.54884863]
 [ 1.52560341]
 [ 1.62156534]
 [ 0.9040423 ]
 [ 1.04433453]]
DEBUG:root:training time = %d0.229066
INFO:root:frame =3841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000331163406372
INFO:root:frame =3842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424146652222
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.969695
DEBUG:root: dqn, choose action rondomly, need time 0.000379999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =3845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000418186187744
INFO:root:frame =3846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000400066375732
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.969663333333
DEBUG:root: dqn, choose action rondomly, need time 0.000266000000011
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.34693635]
 [ 1.43687248]
 [ 1.22107041]
 [ 1.0818876 ]
 [ 1.06560981]
 [ 1.41104877]
 [ 1.39018691]
 [ 1.0818876 ]
 [ 4.87231731]
 [ 1.12967241]
 [ 1.31069851]
 [ 1.20913661]
 [ 1.12969673]
 [ 1.6136812 ]
 [ 0.94218308]
 [ 0.93444175]]
DEBUG:root:training time = %d0.197469
INFO:root:frame =3849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =3850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000326871871948
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.969631666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =3853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =3854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000589847564697
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.9696
DEBUG:root: dqn, choose action rondomly, need time 0.000231999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.83127141]
 [ 1.31459701]
 [ 1.16049123]
 [ 0.90000987]
 [ 1.20131361]
 [ 1.20760179]
 [ 1.00085855]
 [ 1.22615504]
 [ 1.44289172]
 [ 1.75979948]
 [ 0.97238046]
 [ 0.03047871]
 [ 1.15613115]
 [ 1.06478298]
 [ 1.38957536]
 [ 1.85088849]]
DEBUG:root:training time = %d0.223297
INFO:root:frame =3857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =3858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000290155410767
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.969568333333
DEBUG:root: dqn, choose action rondomly, need time 0.000280000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =3861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438213348389
INFO:root:frame =3862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234842300415
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:random_action_porb = 0.969536666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.31110024]
 [ 1.38646078]
 [ 1.25547874]
 [ 0.97580653]
 [ 1.14343858]
 [ 4.35197878]
 [ 1.25547874]
 [ 1.28881872]
 [ 1.24765193]
 [ 1.76203692]
 [ 1.48903596]
 [ 1.30711544]
 [ 0.00445958]
 [ 1.03445232]
 [ 1.29619575]
 [ 1.51269245]]
DEBUG:root:training time = %d0.199121
INFO:root:frame =3865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =3866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.969505
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =3869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =3870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.969473333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.09491718]
 [ 1.04669046]
 [ 1.60436165]
 [ 1.36797202]
 [ 0.92314065]
 [ 1.54570818]
 [ 1.12675917]
 [ 1.44935989]
 [ 0.89857376]
 [ 1.02360952]
 [ 0.9936282 ]
 [ 1.51637769]
 [ 0.92314065]
 [ 4.3467679 ]
 [ 0.79005301]
 [ 1.2790457 ]]
DEBUG:root:training time = %d0.217812
INFO:root:frame =3873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =3874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000385999679565
DEBUG:root: save sample needs time = 0.000156164169312
INFO:root:random_action_porb = 0.969441666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =3877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433206558228
INFO:root:frame =3878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:random_action_porb = 0.96941
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.0446074 ]
 [ 1.2404443 ]
 [ 1.15766978]
 [ 1.60162318]
 [ 0.93235576]
 [ 1.14627528]
 [ 1.33967221]
 [ 0.93296361]
 [ 1.32773793]
 [ 1.37193239]
 [ 1.22723246]
 [ 4.44956732]
 [ 1.28620005]
 [ 1.31313217]
 [ 1.06924748]
 [ 1.14627528]]
DEBUG:root:training time = %d0.234361
INFO:root:frame =3881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:frame =3882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042200088501
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.969378333333
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000186920166016
INFO:root:frame =3885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000418901443481
INFO:root:frame =3886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000229835510254
INFO:root:random_action_porb = 0.969346666667
DEBUG:root: dqn, choose action rondomly, need time 0.000519999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.06192327]
 [ 1.21660626]
 [ 1.21227205]
 [ 1.14234567]
 [ 1.10193372]
 [ 1.29228127]
 [ 1.11117911]
 [ 1.07837498]
 [ 4.34924173]
 [ 1.13570952]
 [ 1.34392309]
 [ 1.20468175]
 [ 0.98036391]
 [ 1.17008173]
 [ 0.91974247]
 [ 1.24441147]]
DEBUG:root:training time = %d0.225805
INFO:root:frame =3889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =3890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:random_action_porb = 0.969315
DEBUG:root: dqn, choose action rondomly, need time 0.000504000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =3893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =3894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000495910644531
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.969283333333
DEBUG:root: dqn, choose action rondomly, need time 0.000210999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:training error  = [[ 1.1904757 ]
 [ 1.24822724]
 [ 1.13749492]
 [ 1.13395393]
 [ 1.07539415]
 [ 1.3178575 ]
 [ 0.89996648]
 [ 1.28786623]
 [ 1.19671881]
 [ 1.07539415]
 [ 1.31033599]
 [ 1.24971938]
 [ 1.07666433]
 [ 1.26311564]
 [ 1.05324173]
 [ 1.62708831]]
DEBUG:root:training time = %d0.220157
INFO:root:frame =3897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =3898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame = 3899 State into memory, numbers recorded 94 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000540971755981
INFO:root:random_action_porb = 0.969251666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3900current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =3901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =3902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.00019383430481
INFO:root:random_action_porb = 0.96922
INFO:root:dqn select action Tensor("ArgMax_16:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012998
INFO:root:action choosen by dqn [4]
INFO:root:frame =3904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root:training error  = [[ 1.21326768]
 [ 1.21214187]
 [ 1.39927375]
 [ 0.98339546]
 [ 1.05951095]
 [ 1.39836693]
 [ 0.97559553]
 [ 0.98339546]
 [ 1.30825388]
 [ 1.38571072]
 [ 1.20828938]
 [ 1.40979838]
 [ 1.26066458]
 [ 1.05999792]
 [ 1.21144474]
 [ 1.16655636]]
DEBUG:root:training time = %d0.219281
INFO:root:frame =3905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =3906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:random_action_porb = 0.969188333333
DEBUG:root: dqn, choose action rondomly, need time 0.000279000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =3909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =3910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.969156666667
DEBUG:root: dqn, choose action rondomly, need time 0.000371000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root:training error  = [[ 1.15263903]
 [ 1.25122523]
 [ 1.03200567]
 [ 0.98492056]
 [ 1.14135098]
 [ 1.15726757]
 [ 0.93344271]
 [ 1.02778971]
 [ 1.11085343]
 [ 1.15640593]
 [ 1.07706809]
 [ 1.34319794]
 [ 1.21333075]
 [ 1.13427079]
 [ 1.15344191]
 [ 1.22436476]]
DEBUG:root:training time = %d0.199977
INFO:root:frame =3913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =3914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000401973724365
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.969125
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =3917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =3918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.969093333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.35957015]
 [ 1.27463174]
 [ 1.05581534]
 [ 1.38831198]
 [ 1.3259846 ]
 [ 1.1677351 ]
 [ 1.01762068]
 [ 1.12443197]
 [ 1.25468385]
 [ 0.97902727]
 [ 1.12443197]
 [ 1.28276289]
 [ 4.50966072]
 [ 1.0971936 ]
 [ 1.37191892]
 [ 1.2886802 ]]
DEBUG:root:training time = %d0.223249
INFO:root:frame =3921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000336170196533
INFO:root:frame =3922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000420093536377
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.969061666667
DEBUG:root: dqn, choose action rondomly, need time 0.000564999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000391960144043
INFO:root:frame =3925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =3926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:random_action_porb = 0.96903
DEBUG:root: dqn, choose action rondomly, need time 0.000540999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:training error  = [[ 1.1048187 ]
 [ 1.18257248]
 [ 0.92198646]
 [ 1.01884484]
 [ 1.1048187 ]
 [ 1.56059325]
 [ 0.99969482]
 [ 1.17042017]
 [ 1.09145916]
 [ 1.08619297]
 [ 1.10338378]
 [ 0.92198646]
 [ 1.389256  ]
 [ 1.19876873]
 [ 1.06737864]
 [ 1.36170602]]
DEBUG:root:training time = %d0.205436
INFO:root:frame =3929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000410079956055
INFO:root:frame =3930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319957733154
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.968998333333
DEBUG:root: dqn, choose action rondomly, need time 0.00028300000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =3933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =3934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000592947006226
INFO:root:frame = 3935 State into memory, numbers recorded 95 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000280857086182
INFO:root:random_action_porb = 0.968966666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3936current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.26539326]
 [ 1.07620919]
 [ 1.17199719]
 [ 1.00517178]
 [ 1.02723289]
 [ 1.13755584]
 [ 1.12598181]
 [ 1.43583918]
 [ 1.2545172 ]
 [ 1.12761366]
 [ 1.1789993 ]
 [ 1.3626188 ]
 [ 1.22022319]
 [ 1.3227185 ]
 [ 4.7645421 ]
 [ 1.12545156]]
DEBUG:root:training time = %d0.22129
INFO:root:frame =3937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =3938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.968935
DEBUG:root: dqn, choose action rondomly, need time 0.00028300000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =3941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =3942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.968903333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000346899032593
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.28887939]
 [ 1.34840655]
 [ 1.24876857]
 [ 0.96297282]
 [ 1.19269526]
 [ 1.44437218]
 [ 1.29547489]
 [ 1.09186971]
 [ 1.14566278]
 [ 1.22572422]
 [ 1.33157802]
 [ 1.06716192]
 [ 1.39760911]
 [ 5.00541258]
 [ 1.24585879]
 [ 1.13245952]]
DEBUG:root:training time = %d0.237643
INFO:root:frame =3945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =3946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.968871666667
DEBUG:root: dqn, choose action rondomly, need time 0.000512000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =3949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000503063201904
INFO:root:frame =3950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047779083252
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.96884
DEBUG:root: dqn, choose action rondomly, need time 0.000540000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.03494132]
 [ 1.07793522]
 [ 1.56066942]
 [ 1.32373214]
 [ 5.09731245]
 [ 1.19031346]
 [ 2.06175327]
 [ 1.18874907]
 [ 1.56066942]
 [ 1.33855534]
 [ 1.7512778 ]
 [ 1.43702328]
 [ 1.41501653]
 [ 2.06175327]
 [ 1.20639479]
 [ 1.30257916]]
DEBUG:root:training time = %d0.218927
INFO:root:frame =3953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =3954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.968808333333
DEBUG:root: dqn, choose action rondomly, need time 0.00027200000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000157833099365
INFO:root:frame =3957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =3958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame = 3959 State into memory, numbers recorded 96 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000486135482788
INFO:root:random_action_porb = 0.968776666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3960current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:training error  = [[ 1.37979865]
 [ 1.47725916]
 [ 1.51956427]
 [ 1.51956427]
 [ 1.70846128]
 [ 1.38460636]
 [ 1.43680382]
 [ 1.43002164]
 [ 0.95440835]
 [ 1.1130538 ]
 [ 0.99406552]
 [ 1.05169189]
 [ 1.21191919]
 [ 1.05849028]
 [ 1.08744967]
 [ 1.46829653]]
DEBUG:root:training time = %d0.208825
INFO:root:frame =3961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =3962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.968745
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =3965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =3966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.968713333333
DEBUG:root: dqn, choose action rondomly, need time 0.000267000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4.34756327]
 [ 1.20883453]
 [ 1.071051  ]
 [ 1.15932441]
 [ 1.17511725]
 [ 1.43380129]
 [ 1.15184879]
 [ 1.28988862]
 [ 1.05295205]
 [ 1.12759745]
 [ 1.0916146 ]
 [ 0.9699294 ]
 [ 1.20040655]
 [ 1.01996946]
 [ 1.19592607]
 [ 1.1553601 ]]
DEBUG:root:training time = %d0.218461
INFO:root:frame =3969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:frame =3970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000284910202026
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.968681666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =3973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000425100326538
INFO:root:frame =3974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000175952911377
INFO:root:random_action_porb = 0.96865
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:training error  = [[ 1.1807189 ]
 [ 1.14727616]
 [ 1.20564079]
 [ 1.38247502]
 [ 1.68425536]
 [ 1.17131996]
 [ 1.1122812 ]
 [ 1.19300354]
 [ 1.01234794]
 [ 1.15808845]
 [ 1.09610701]
 [ 1.22544551]
 [ 1.09047496]
 [ 1.68425536]
 [ 1.21535683]
 [ 1.05276406]]
DEBUG:root:training time = %d0.205492
INFO:root:frame =3977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =3978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame = 3979 State into memory, numbers recorded 97 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000363826751709
INFO:root:random_action_porb = 0.968618333333
DEBUG:root: dqn, choose action rondomly, need time 0.000279999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3980current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =3981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =3982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00057315826416
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:random_action_porb = 0.968586666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.06379128]
 [ 1.44129765]
 [ 1.34648037]
 [ 1.40516412]
 [ 5.25330687]
 [ 0.94515508]
 [ 1.04996741]
 [ 1.39697778]
 [ 1.39474237]
 [ 1.52757359]
 [ 1.28527439]
 [ 1.59595561]
 [ 1.23146629]
 [ 1.35273337]
 [ 1.23146629]
 [ 1.28071153]]
DEBUG:root:training time = %d0.211628
INFO:root:frame =3985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root:frame =3986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.968555
DEBUG:root: dqn, choose action rondomly, need time 0.000331000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =3989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470161437988
INFO:root:frame =3990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:random_action_porb = 0.968523333333
DEBUG:root: dqn, choose action rondomly, need time 0.000204999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:training error  = [[ 1.17608511]
 [ 1.40110636]
 [ 1.15333128]
 [ 1.46985006]
 [ 1.50195801]
 [ 1.405743  ]
 [ 1.53456414]
 [ 1.73030007]
 [ 1.4748075 ]
 [ 1.42535424]
 [ 1.48104489]
 [ 1.0184406 ]
 [ 1.44083965]
 [ 1.53456414]
 [ 1.477018  ]
 [ 1.50195801]]
DEBUG:root:training time = %d0.201087
INFO:root:frame =3993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =3994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame = 3995 State into memory, numbers recorded 98 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.00085186958313
INFO:root:random_action_porb = 0.968491666667
DEBUG:root: dqn, choose action rondomly, need time 0.000349999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3996current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000263214111328
INFO:root:frame =3997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =3998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294923782349
DEBUG:root: save sample needs time = 0.000221014022827
DEBUG:root:one frame running time = 0.006411
DEBUG:root:total training time = 86.303567
INFO:root:frame num = 4000 frame round: 0
INFO:root:random_action_porb = 0.96846
DEBUG:root: dqn, choose action rondomly, need time 0.000219000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000396013259888
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.82703054]
 [ 1.20485759]
 [ 1.14986813]
 [ 1.37265182]
 [ 3.9991684 ]
 [ 1.34165978]
 [ 1.77509499]
 [ 1.13544118]
 [ 1.62027836]
 [ 1.49744534]
 [ 1.38509119]
 [ 1.4640286 ]
 [ 1.44770253]
 [ 1.36534977]
 [ 1.49744534]
 [ 1.14986813]]
DEBUG:root:training time = %d0.199414
INFO:root:frame =4001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =4002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000359058380127
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.968428333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294000000011
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =4005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =4006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.968396666667
DEBUG:root: dqn, choose action rondomly, need time 0.000279000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:training error  = [[ 1.7275213 ]
 [ 1.3640753 ]
 [ 1.20782399]
 [ 1.24054635]
 [ 1.32724118]
 [ 1.71103513]
 [ 1.19017196]
 [ 1.12392235]
 [ 1.2446413 ]
 [ 1.08028913]
 [ 1.4629302 ]
 [ 1.7603662 ]
 [ 1.30288839]
 [ 1.1349535 ]
 [ 1.38101768]
 [ 2.16406751]]
DEBUG:root:training time = %d0.195583
INFO:root:frame =4009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root:frame =4010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00057578086853
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.968365
DEBUG:root: dqn, choose action rondomly, need time 0.000243999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000177145004272
INFO:root:frame =4013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =4014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000382900238037
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.968333333333
DEBUG:root: dqn, choose action rondomly, need time 0.000266999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.00609815]
 [ 1.00496912]
 [ 1.52549028]
 [ 1.31515253]
 [ 1.49089849]
 [ 1.42829776]
 [ 1.63729846]
 [ 1.0096246 ]
 [ 1.49224031]
 [ 1.13119745]
 [ 1.75349474]
 [ 2.10156202]
 [ 1.31515253]
 [ 1.49207258]
 [ 1.44187927]
 [ 1.46970212]]
DEBUG:root:training time = %d0.198492
INFO:root:frame =4017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =4018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame = 4019 State into memory, numbers recorded 99 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:random_action_porb = 0.968301666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4020current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000315189361572
INFO:root:frame =4021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00036096572876
INFO:root:frame =4022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.96827
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:training error  = [[ 1.88699186]
 [ 1.88699186]
 [ 1.47003973]
 [ 1.65257776]
 [ 1.69800651]
 [ 1.87505794]
 [ 1.66371357]
 [ 1.76599383]
 [ 2.10490894]
 [ 1.42621505]
 [ 1.00003815]
 [ 1.67743027]
 [ 1.17063892]
 [ 1.02234793]
 [ 1.11836445]
 [ 1.00003815]]
DEBUG:root:training time = %d0.220095
INFO:root:frame =4025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =4026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324964523315
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.968238333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =4029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =4030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.968206666667
DEBUG:root: dqn, choose action rondomly, need time 0.000308999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root:training error  = [[ 1.57910919]
 [ 1.69703233]
 [ 1.51702607]
 [ 1.41267598]
 [ 1.69703233]
 [ 1.57704389]
 [ 1.30677962]
 [ 1.46077633]
 [ 1.20600522]
 [ 1.61536801]
 [ 1.45034289]
 [ 1.30677962]
 [ 1.44642222]
 [ 1.76531458]
 [ 1.49759936]
 [ 1.31726635]]
DEBUG:root:training time = %d0.235373
INFO:root:frame =4033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279188156128
INFO:root:frame =4034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000289916992188
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.968175
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =4037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =4038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000287055969238
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.968143333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.36295724]
 [ 1.27870059]
 [ 1.07141423]
 [ 1.06464922]
 [ 1.24878132]
 [ 1.57861078]
 [ 1.44860232]
 [ 1.0022366 ]
 [ 5.27253342]
 [ 1.56489944]
 [ 1.16312277]
 [ 1.37143648]
 [ 1.16312277]
 [ 1.30259228]
 [ 1.24066103]
 [ 1.24878132]]
DEBUG:root:training time = %d0.216183
INFO:root:frame =4041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =4042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.968111666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =4045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =4046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.96808
INFO:root:dqn select action Tensor("ArgMax_17:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00945900000001
INFO:root:action choosen by dqn [4]
INFO:root:frame =4048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.16995382]
 [ 1.22694933]
 [ 1.16381395]
 [ 4.13026285]
 [ 1.57165909]
 [ 1.17807996]
 [ 1.21620655]
 [ 1.28386056]
 [ 1.40064132]
 [ 1.17755413]
 [ 1.31362617]
 [ 1.17183614]
 [ 1.57165909]
 [ 1.2575655 ]
 [ 1.26913357]
 [ 1.40064132]]
DEBUG:root:training time = %d0.226726
INFO:root:frame =4049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025200843811
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.968048333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =4053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000416994094849
INFO:root:frame =4054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.968016666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.62105536]
 [ 5.22635984]
 [ 1.32356095]
 [ 1.18997216]
 [ 1.1875391 ]
 [ 1.26659942]
 [ 1.39789331]
 [ 1.76824033]
 [ 1.42621505]
 [ 1.25379527]
 [ 1.57365882]
 [ 1.1434834 ]
 [ 1.76824033]
 [ 1.50812614]
 [ 1.33160877]
 [ 1.80101264]]
DEBUG:root:training time = %d0.204073
INFO:root:frame =4057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =4058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.967985
DEBUG:root: dqn, choose action rondomly, need time 0.000151000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000145196914673
INFO:root:frame =4061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =4062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000290155410767
INFO:root:random_action_porb = 0.967953333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:training error  = [[ 1.59517992]
 [ 1.37795305]
 [ 1.33031058]
 [ 1.0764308 ]
 [ 1.31939936]
 [ 1.2888577 ]
 [ 1.05530977]
 [ 1.64690888]
 [ 1.35956132]
 [ 1.07482851]
 [ 1.30723751]
 [ 1.55468965]
 [ 1.82994497]
 [ 1.32508421]
 [ 1.44365251]
 [ 1.60432303]]
DEBUG:root:training time = %d0.224799
INFO:root:frame =4065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =4066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.967921666667
DEBUG:root: dqn, choose action rondomly, need time 0.000169999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000157117843628
INFO:root:frame =4069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248193740845
INFO:root:frame =4070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000261068344116
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.96789
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:training error  = [[ 1.30233109]
 [ 1.14998674]
 [ 1.29136646]
 [ 1.14350796]
 [ 1.416646  ]
 [ 1.26305568]
 [ 1.18207467]
 [ 1.14998674]
 [ 1.32867432]
 [ 1.4655844 ]
 [ 1.60176325]
 [ 1.44024909]
 [ 1.45437014]
 [ 1.52210462]
 [ 1.416646  ]
 [ 1.38099074]]
DEBUG:root:training time = %d0.220316
INFO:root:frame =4073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =4074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.967858333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =4078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.967826666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:training error  = [[ 1.27047479]
 [ 1.38605213]
 [ 1.28620434]
 [ 1.3775053 ]
 [ 1.65917027]
 [ 1.07975793]
 [ 1.06933832]
 [ 1.65917027]
 [ 2.04589915]
 [ 1.52845061]
 [ 2.0931592 ]
 [ 1.49212384]
 [ 1.39796996]
 [ 1.61336625]
 [ 1.2570864 ]
 [ 1.99423063]]
DEBUG:root:training time = %d0.22555
INFO:root:frame =4081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =4082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.967795
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =4085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =4086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.967763333333
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000367879867554
INFO:root:training error  = [[ 1.36310422]
 [ 1.57243395]
 [ 1.41122103]
 [ 1.36310422]
 [ 1.16707969]
 [ 1.17305875]
 [ 1.3265425 ]
 [ 1.41122103]
 [ 1.38157809]
 [ 1.93233156]
 [ 1.16274428]
 [ 1.26453519]
 [ 1.43817592]
 [ 1.16312277]
 [ 1.22826385]
 [ 1.35530794]]
DEBUG:root:training time = %d0.216116
INFO:root:frame =4089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:frame =4090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.967731666667
DEBUG:root: dqn, choose action rondomly, need time 0.000358999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =4093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =4094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9677
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.42592359]
 [ 1.57308459]
 [ 1.48107278]
 [ 1.37850392]
 [ 1.51463544]
 [ 1.09848464]
 [ 5.1650238 ]
 [ 4.25418186]
 [ 1.57308459]
 [ 1.37672639]
 [ 1.2520659 ]
 [ 1.58655775]
 [ 1.53629887]
 [ 1.43381953]
 [ 1.61057651]
 [ 1.10835814]]
DEBUG:root:training time = %d0.19937
INFO:root:frame =4097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =4098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.967668333333
DEBUG:root: dqn, choose action rondomly, need time 0.000340000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000377178192139
INFO:root:frame =4101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000503063201904
INFO:root:frame =4102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame = 4103 State into memory, numbers recorded 100 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.00054407119751
INFO:root:random_action_porb = 0.967636666667
DEBUG:root: dqn, choose action rondomly, need time 0.000273000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4104current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:training error  = [[ 1.74579978]
 [ 1.21249044]
 [ 1.65614486]
 [ 1.34218121]
 [ 1.51149631]
 [ 1.30159545]
 [ 1.35977042]
 [ 1.86521399]
 [ 1.73636198]
 [ 1.17321575]
 [ 1.1414814 ]
 [ 1.26682687]
 [ 1.17124987]
 [ 1.71369076]
 [ 1.8999362 ]
 [ 1.39420629]]
DEBUG:root:training time = %d0.223638
INFO:root:frame =4105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =4106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000287055969238
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.967605
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =4109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =4110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.967573333333
DEBUG:root: dqn, choose action rondomly, need time 0.000191000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.28478146]
 [ 6.34933519]
 [ 1.30850697]
 [ 1.55172777]
 [ 1.83166385]
 [ 1.36633503]
 [ 1.12901568]
 [ 1.47188568]
 [ 1.37416291]
 [ 1.61079931]
 [ 1.59923434]
 [ 1.3364774 ]
 [ 0.01851875]
 [ 1.44197094]
 [ 1.23453307]
 [ 1.54136705]]
DEBUG:root:training time = %d0.211943
INFO:root:frame =4113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =4114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000313997268677
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.967541666667
DEBUG:root: dqn, choose action rondomly, need time 0.000562000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =4117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454187393188
INFO:root:frame =4118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000535011291504
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.96751
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:training error  = [[ 2.07401347]
 [ 1.47905397]
 [ 1.35401595]
 [ 1.35702717]
 [ 1.62329519]
 [ 1.57020557]
 [ 1.70935392]
 [ 1.46905935]
 [ 1.27037585]
 [ 1.70935392]
 [ 1.29094601]
 [ 1.38542342]
 [ 1.39936399]
 [ 2.08420587]
 [ 1.4783628 ]
 [ 1.23548687]]
DEBUG:root:training time = %d0.21639
INFO:root:frame =4121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261783599854
INFO:root:frame =4122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248908996582
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.967478333333
DEBUG:root: dqn, choose action rondomly, need time 0.000506999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =4125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =4126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.967446666667
DEBUG:root: dqn, choose action rondomly, need time 0.000548999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:training error  = [[ 1.56765413]
 [ 1.96401179]
 [ 1.70822203]
 [ 1.90141404]
 [ 2.01100326]
 [ 1.90410817]
 [ 1.80294836]
 [ 2.34694099]
 [ 2.05888963]
 [ 1.96401179]
 [ 1.9995836 ]
 [ 1.17607272]
 [ 1.90410817]
 [ 1.73940945]
 [ 1.38533807]
 [ 1.15726757]]
DEBUG:root:training time = %d0.229281
INFO:root:frame =4129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000370979309082
INFO:root:frame =4130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000566005706787
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.967415
DEBUG:root: dqn, choose action rondomly, need time 0.000278999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root:frame =4133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000422954559326
INFO:root:frame =4134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.967383333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.2740891 ]
 [ 1.06006467]
 [ 1.79920089]
 [ 1.57981873]
 [ 1.47830713]
 [ 1.49820161]
 [ 1.93311119]
 [ 1.58335924]
 [ 0.12460676]
 [ 1.85122585]
 [ 1.66800201]
 [ 1.54796183]
 [ 1.75075281]
 [ 1.49820161]
 [ 1.55541742]
 [ 1.23968816]]
DEBUG:root:training time = %d0.217602
INFO:root:frame =4137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =4138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.967351666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =4141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =4142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.96732
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.25166047]
 [ 1.34141684]
 [ 1.39050186]
 [ 1.22229731]
 [ 1.66627812]
 [ 4.78065109]
 [ 1.61592567]
 [ 1.33519888]
 [ 1.33400893]
 [ 1.39279234]
 [ 1.35865402]
 [ 1.27606201]
 [ 1.62688398]
 [ 1.45681393]
 [ 1.58849955]
 [ 1.74282718]]
DEBUG:root:training time = %d0.229694
INFO:root:frame =4145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =4146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000282049179077
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.967288333333
DEBUG:root: dqn, choose action rondomly, need time 0.000332
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =4149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471830368042
INFO:root:frame =4150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame = 4151 State into memory, numbers recorded 101 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000556945800781
INFO:root:random_action_porb = 0.967256666667
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4152current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000401020050049
INFO:root:training error  = [[ 1.59759462]
 [ 1.80279982]
 [ 1.81425524]
 [ 1.37955666]
 [ 1.373528  ]
 [ 1.75951612]
 [ 1.45333982]
 [ 1.57041121]
 [ 1.50020075]
 [ 1.40822268]
 [ 1.61108971]
 [ 1.40727663]
 [ 1.11180651]
 [ 1.53483355]
 [ 1.26328719]
 [ 1.59759462]]
DEBUG:root:training time = %d0.2153
INFO:root:frame =4153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =4154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448226928711
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.967225
DEBUG:root: dqn, choose action rondomly, need time 0.000574
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =4158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame = 4159 State into memory, numbers recorded 102 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000543832778931
INFO:root:random_action_porb = 0.967193333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4160current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.81217992]
 [ 2.28929734]
 [ 1.53898096]
 [ 1.86067379]
 [ 2.28929734]
 [ 1.55545557]
 [ 1.39315701]
 [ 1.46641123]
 [ 4.41775131]
 [ 1.42652488]
 [ 2.28929734]
 [ 1.72187531]
 [ 1.86067379]
 [ 1.3853246 ]
 [ 1.19863093]
 [ 1.75852442]]
DEBUG:root:training time = %d0.219747
INFO:root:frame =4161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =4162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255107879639
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.967161666667
DEBUG:root: dqn, choose action rondomly, need time 0.000183000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000196218490601
INFO:root:frame =4165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271797180176
INFO:root:frame =4166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame = 4167 State into memory, numbers recorded 103 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:random_action_porb = 0.96713
DEBUG:root: dqn, choose action rondomly, need time 0.00018399999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4168current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000141859054565
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.57046854]
 [ 1.72509038]
 [ 1.19458318]
 [ 1.92753565]
 [ 1.22670853]
 [ 1.46918881]
 [ 1.34558189]
 [ 1.82139909]
 [ 1.39813232]
 [ 1.42840266]
 [ 1.48758399]
 [ 1.24743891]
 [ 1.45775795]
 [ 5.33582449]
 [ 1.42840266]
 [ 1.48254943]]
DEBUG:root:training time = %d0.219222
INFO:root:frame =4169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000342845916748
INFO:root:frame =4170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.967098333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =4173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =4174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.967066666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[ 1.51793766]
 [ 1.87302125]
 [ 1.73766911]
 [ 1.44633055]
 [ 1.2912364 ]
 [ 1.57273531]
 [ 1.28588855]
 [ 1.26946449]
 [ 1.31711745]
 [ 1.47701335]
 [ 1.73766911]
 [ 1.31165946]
 [ 1.53907561]
 [ 1.34505987]
 [ 1.17086589]
 [ 1.3073684 ]]
DEBUG:root:training time = %d0.229521
INFO:root:frame =4177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =4178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:random_action_porb = 0.967035
DEBUG:root: dqn, choose action rondomly, need time 0.000318000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000359058380127
INFO:root:frame =4181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =4182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.967003333333
DEBUG:root: dqn, choose action rondomly, need time 0.000208000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.46843982]
 [ 1.37877715]
 [ 1.37877715]
 [ 1.4255501 ]
 [ 1.61439371]
 [ 5.41537142]
 [ 1.4990983 ]
 [ 1.3034457 ]
 [ 1.21259546]
 [ 1.34335709]
 [ 1.41629195]
 [ 1.32018387]
 [ 1.44264436]
 [ 1.21259546]
 [ 4.75645208]
 [ 0.03831181]]
DEBUG:root:training time = %d0.236428
INFO:root:frame =4185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =4186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.966971666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294000000011
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =4189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454187393188
INFO:root:frame =4190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.96694
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:training error  = [[ 1.45042562]
 [ 1.69128764]
 [ 1.53988028]
 [ 1.36964118]
 [ 1.43490684]
 [ 1.6016618 ]
 [ 1.77025473]
 [ 1.30583787]
 [ 1.41940343]
 [ 1.73929369]
 [ 1.40255165]
 [ 1.73929369]
 [ 1.38214314]
 [ 1.69503033]
 [ 1.7294873 ]
 [ 1.47464991]]
DEBUG:root:training time = %d0.202948
INFO:root:frame =4193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =4194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000385046005249
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.966908333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =4197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =4198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428199768066
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.966876666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328779220581
INFO:root:training error  = [[ 1.84579051]
 [ 1.48181105]
 [ 1.32534337]
 [ 1.92688429]
 [ 1.58127189]
 [ 1.65227377]
 [ 1.56030726]
 [ 1.21787298]
 [ 1.3398267 ]
 [ 1.40596461]
 [ 1.80532575]
 [ 1.80532575]
 [ 1.94270182]
 [ 1.43228972]
 [ 1.84579051]
 [ 1.38580954]]
DEBUG:root:training time = %d0.233943
INFO:root:frame =4201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =4202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.966845
DEBUG:root: dqn, choose action rondomly, need time 0.000213000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =4205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =4206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.966813333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:training error  = [[ 1.31999981]
 [ 1.31719196]
 [ 1.44276345]
 [ 1.77065063]
 [ 1.67464983]
 [ 1.58181405]
 [ 2.02106142]
 [ 1.77517629]
 [ 1.47477508]
 [ 1.51326954]
 [ 1.35935223]
 [ 1.76972687]
 [ 1.48590016]
 [ 1.31999981]
 [ 1.73576891]
 [ 1.13165998]]
DEBUG:root:training time = %d0.21752
INFO:root:frame =4209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:frame =4210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000287055969238
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.966781666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =4213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =4214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.96675
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.47812164]
 [ 1.65240133]
 [ 1.42853034]
 [ 1.29308367]
 [ 5.12127495]
 [ 1.65202856]
 [ 1.64992583]
 [ 1.44019866]
 [ 1.78258419]
 [ 1.86965537]
 [ 1.40473461]
 [ 1.46390855]
 [ 1.29085064]
 [ 1.74644494]
 [ 1.45953631]
 [ 1.48395717]]
DEBUG:root:training time = %d0.218707
INFO:root:frame =4217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =4218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.966718333333
DEBUG:root: dqn, choose action rondomly, need time 0.000328999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =4221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =4222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000130176544189
INFO:root:random_action_porb = 0.966686666667
DEBUG:root: dqn, choose action rondomly, need time 0.000439
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.8300792 ]
 [ 1.59754634]
 [ 1.91221261]
 [ 1.14911556]
 [ 1.70980787]
 [ 1.61396229]
 [ 1.45481181]
 [ 1.30583346]
 [ 1.27828217]
 [ 1.53614283]
 [ 4.83215952]
 [ 1.18390441]
 [ 1.71086049]
 [ 1.31358242]
 [ 1.88751066]
 [ 1.66208041]]
DEBUG:root:training time = %d0.229672
INFO:root:frame =4225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =4226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame = 4227 State into memory, numbers recorded 104 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000322818756104
INFO:root:random_action_porb = 0.966655
DEBUG:root: dqn, choose action rondomly, need time 0.000173000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4228current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:frame =4229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470876693726
INFO:root:frame =4230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.966623333333
INFO:root:dqn select action Tensor("ArgMax_18:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010657
INFO:root:action choosen by dqn [4]
INFO:root:frame =4232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162124633789
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.47866428]
 [ 1.71007216]
 [ 2.01060843]
 [ 1.80242074]
 [ 1.2732023 ]
 [ 1.74411166]
 [ 5.98078442]
 [ 2.0617094 ]
 [ 1.47795463]
 [ 1.56962252]
 [ 5.33546305]
 [ 1.25126362]
 [ 1.73876548]
 [ 2.25625277]
 [ 1.49305117]
 [ 2.14639878]]
DEBUG:root:training time = %d0.239466
INFO:root:frame =4233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =4234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.966591666667
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =4237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000418901443481
INFO:root:frame =4238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.96656
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:training error  = [[ 1.30848515]
 [ 1.46692395]
 [ 1.71357095]
 [ 1.88067746]
 [ 1.88139427]
 [ 1.63698602]
 [ 1.30848515]
 [ 1.94928443]
 [ 1.73659325]
 [ 2.02661848]
 [ 1.52788472]
 [ 1.54408669]
 [ 1.88067746]
 [ 1.77518642]
 [ 1.65227866]
 [ 1.67055011]]
DEBUG:root:training time = %d0.218109
INFO:root:frame =4241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =4242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.966528333333
DEBUG:root: dqn, choose action rondomly, need time 0.000326000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =4245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =4246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame = 4247 State into memory, numbers recorded 105 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000526905059814
INFO:root:random_action_porb = 0.966496666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4248current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.99759352]
 [ 1.61074114]
 [ 1.72027886]
 [ 5.0979414 ]
 [ 1.34281778]
 [ 1.46743226]
 [ 4.54949951]
 [ 1.39423788]
 [ 1.62772584]
 [ 1.25106728]
 [ 1.68368113]
 [ 5.0979414 ]
 [ 1.75912142]
 [ 1.72027886]
 [ 1.43109381]
 [ 1.43393373]]
DEBUG:root:training time = %d0.197597
INFO:root:frame =4249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =4250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000401973724365
INFO:root:frame = 4251 State into memory, numbers recorded 106 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.00059700012207
INFO:root:random_action_porb = 0.966465
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4252current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =4253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =4254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.966433333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.68596864]
 [ 1.45174444]
 [ 1.39200008]
 [ 1.6624887 ]
 [ 1.81012642]
 [ 2.44620681]
 [ 1.17376125]
 [ 1.55608833]
 [ 5.30503654]
 [ 1.67303109]
 [ 1.27339172]
 [ 1.81258047]
 [ 2.42507219]
 [ 1.62036574]
 [ 1.74281716]
 [ 1.40962625]]
DEBUG:root:training time = %d0.221458
INFO:root:frame =4257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000400066375732
INFO:root:frame =4258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.966401666667
DEBUG:root: dqn, choose action rondomly, need time 0.00027
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =4261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =4262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000627994537354
DEBUG:root: save sample needs time = 9.10758972168e-05
INFO:root:random_action_porb = 0.96637
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5.01988077]
 [ 1.35575652]
 [ 1.23787105]
 [ 1.46930897]
 [ 1.10647535]
 [ 1.62114763]
 [ 1.54925776]
 [ 1.23377442]
 [ 1.10647535]
 [ 1.40399778]
 [ 1.46335936]
 [ 0.07129318]
 [ 1.72304177]
 [ 1.33829057]
 [ 1.55754006]
 [ 1.4683243 ]]
DEBUG:root:training time = %d0.220109
INFO:root:frame =4265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =4266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274896621704
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.966338333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =4269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =4270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.966306666667
DEBUG:root: dqn, choose action rondomly, need time 0.000280000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.53843212]
 [ 0.06164654]
 [ 1.24486256]
 [ 1.25588489]
 [ 1.71735311]
 [ 1.64447677]
 [ 1.36827099]
 [ 1.3426497 ]
 [ 1.39241421]
 [ 1.55731153]
 [ 1.66198707]
 [ 1.4360677 ]
 [ 1.4360677 ]
 [ 1.71735311]
 [ 1.41872633]
 [ 1.6599369 ]]
DEBUG:root:training time = %d0.228573
INFO:root:frame =4273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =4274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.966275
DEBUG:root: dqn, choose action rondomly, need time 0.000635000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =4277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000653982162476
INFO:root:frame =4278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294923782349
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.966243333333
DEBUG:root: dqn, choose action rondomly, need time 0.000279000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:training error  = [[ 1.20284855]
 [ 1.68882287]
 [ 1.45574129]
 [ 1.6901865 ]
 [ 1.60697186]
 [ 1.76053834]
 [ 1.54969466]
 [ 1.78555465]
 [ 1.67573607]
 [ 1.49263179]
 [ 1.75800848]
 [ 1.20284855]
 [ 1.53279257]
 [ 1.72146487]
 [ 1.53021967]
 [ 1.60053718]]
DEBUG:root:training time = %d0.217586
INFO:root:frame =4281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =4282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042200088501
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.966211666667
DEBUG:root: dqn, choose action rondomly, need time 0.000280000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =4285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =4286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000418901443481
INFO:root:frame = 4287 State into memory, numbers recorded 107 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000545978546143
INFO:root:random_action_porb = 0.96618
DEBUG:root: dqn, choose action rondomly, need time 0.000375999999989
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4288current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:training error  = [[ 1.31704748]
 [ 1.7412262 ]
 [ 1.90120363]
 [ 1.90120363]
 [ 1.93970942]
 [ 1.75174737]
 [ 1.60158455]
 [ 1.8838228 ]
 [ 1.35437548]
 [ 1.87656784]
 [ 1.93421459]
 [ 1.59749818]
 [ 2.04764557]
 [ 1.33388114]
 [ 1.43835437]
 [ 1.31608891]]
DEBUG:root:training time = %d0.226216
INFO:root:frame =4289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375032424927
INFO:root:frame =4290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000250101089478
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.966148333333
DEBUG:root: dqn, choose action rondomly, need time 0.000267999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:frame =4293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =4294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.966116666667
DEBUG:root: dqn, choose action rondomly, need time 0.000213000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:training error  = [[ 1.41762698]
 [ 1.42118549]
 [ 1.51334465]
 [ 1.86965537]
 [ 1.72861445]
 [ 1.5662024 ]
 [ 1.57033467]
 [ 1.62037539]
 [ 1.54252279]
 [ 1.76889467]
 [ 1.56178963]
 [ 1.41722727]
 [ 1.37011886]
 [ 1.4326961 ]
 [ 1.82666969]
 [ 1.67333698]]
DEBUG:root:training time = %d0.227475
INFO:root:frame =4297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =4298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000501871109009
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.966085
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =4301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =4302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000584840774536
INFO:root:frame = 4303 State into memory, numbers recorded 108 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:random_action_porb = 0.966053333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4304current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.38688755]
 [ 5.55108166]
 [ 1.39446759]
 [ 1.54608762]
 [ 1.51152909]
 [ 2.00285387]
 [ 1.70411122]
 [ 1.60055649]
 [ 1.31611514]
 [ 1.81256509]
 [ 1.70411122]
 [ 1.90020967]
 [ 2.37965202]
 [ 1.88517392]
 [ 1.74855793]
 [ 1.66311836]]
DEBUG:root:training time = %d0.209651
INFO:root:frame =4305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000347852706909
INFO:root:frame =4306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000346183776855
DEBUG:root: save sample needs time = 0.000136137008667
INFO:root:random_action_porb = 0.966021666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000351905822754
INFO:root:frame =4309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =4310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:random_action_porb = 0.96599
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.55077755]
 [ 1.75140905]
 [ 1.35847616]
 [ 1.83485055]
 [ 1.5123359 ]
 [ 1.73472869]
 [ 4.70128775]
 [ 1.54275024]
 [ 1.31851447]
 [ 1.57186472]
 [ 1.89376295]
 [ 1.6670661 ]
 [ 1.46407473]
 [ 1.55694973]
 [ 1.55077755]
 [ 1.35169542]]
DEBUG:root:training time = %d0.244374
INFO:root:frame =4313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =4314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264883041382
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.965958333333
DEBUG:root: dqn, choose action rondomly, need time 0.000235000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:frame =4317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444173812866
INFO:root:frame =4318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000223875045776
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.965926666667
INFO:root:dqn select action Tensor("ArgMax_19:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013152
INFO:root:action choosen by dqn [4]
INFO:root:frame =4320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000341176986694
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.60063362]
 [ 2.20522118]
 [ 1.7374177 ]
 [ 1.5952425 ]
 [ 1.70498776]
 [ 1.39039385]
 [ 1.39659917]
 [ 1.55765915]
 [ 1.39039385]
 [ 4.71838331]
 [ 0.0561968 ]
 [ 2.20522118]
 [ 1.32527316]
 [ 2.03959656]
 [ 1.66006958]
 [ 1.64335179]]
DEBUG:root:training time = %d0.211648
INFO:root:frame =4321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000364065170288
INFO:root:frame =4322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000311851501465
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.965895
DEBUG:root: dqn, choose action rondomly, need time 0.000332999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =4325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000520944595337
INFO:root:frame =4326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.965863333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:training error  = [[ 1.5372541 ]
 [ 1.41075432]
 [ 1.81235969]
 [ 1.81010592]
 [ 1.5372541 ]
 [ 1.4924407 ]
 [ 1.71679831]
 [ 1.73608553]
 [ 1.80710983]
 [ 1.81010592]
 [ 1.3639015 ]
 [ 1.17460454]
 [ 1.91439188]
 [ 1.92788517]
 [ 1.85292351]
 [ 1.30473959]]
DEBUG:root:training time = %d0.212213
INFO:root:frame =4329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =4330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000508069992065
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.965831666667
DEBUG:root: dqn, choose action rondomly, need time 0.000201000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:frame =4333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =4334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000574111938477
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9658
DEBUG:root: dqn, choose action rondomly, need time 0.000319999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.62890387]
 [ 1.42561841]
 [ 1.43403423]
 [ 1.62284803]
 [ 1.54062355]
 [ 1.66413188]
 [ 1.72644842]
 [ 1.57777691]
 [ 1.66413188]
 [ 1.41976249]
 [ 1.75060642]
 [ 5.47647572]
 [ 1.57777691]
 [ 1.28872776]
 [ 1.46227968]
 [ 1.65169036]]
DEBUG:root:training time = %d0.221171
INFO:root:frame =4337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =4338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.965768333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:frame =4341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000519037246704
INFO:root:frame =4342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.965736666667
INFO:root:dqn select action Tensor("ArgMax_20:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013768
INFO:root:action choosen by dqn [4]
INFO:root:frame =4344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000161170959473
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.15264302]
 [ 2.59351468]
 [ 1.55132389]
 [ 1.49022317]
 [ 1.97859061]
 [ 1.84385788]
 [ 1.66723359]
 [ 1.63407838]
 [ 0.15264302]
 [ 1.55132389]
 [ 1.56949341]
 [ 2.04145479]
 [ 1.59375405]
 [ 1.69768345]
 [ 2.54693818]
 [ 1.91778183]]
DEBUG:root:training time = %d0.212815
INFO:root:frame =4345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:frame =4346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.965705
DEBUG:root: dqn, choose action rondomly, need time 0.000163999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:frame =4349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =4350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.965673333333
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:training error  = [[ 1.44424844]
 [ 2.50098252]
 [ 1.25047851]
 [ 1.74373388]
 [ 2.28832221]
 [ 1.6943152 ]
 [ 1.45353758]
 [ 2.03076959]
 [ 2.39482903]
 [ 1.71344614]
 [ 1.69674909]
 [ 1.70483339]
 [ 1.85297537]
 [ 1.9890517 ]
 [ 1.88794041]
 [ 1.62043858]]
DEBUG:root:training time = %d0.217775
INFO:root:frame =4353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:frame =4354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047492980957
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.965641666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =4357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =4358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame = 4359 State into memory, numbers recorded 109 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000661134719849
INFO:root:random_action_porb = 0.96561
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4360current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000322818756104
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.59791279]
 [ 1.63054502]
 [ 1.7841481 ]
 [ 1.9029187 ]
 [ 1.43832231]
 [ 6.52409935]
 [ 5.06655216]
 [ 1.65375006]
 [ 2.07224488]
 [ 2.12419081]
 [ 1.36268115]
 [ 1.55628824]
 [ 1.50567234]
 [ 1.90758395]
 [ 1.88292241]
 [ 2.07224488]]
DEBUG:root:training time = %d0.212042
INFO:root:frame =4361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =4362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000380039215088
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:random_action_porb = 0.965578333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =4365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =4366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000201225280762
INFO:root:random_action_porb = 0.965546666667
DEBUG:root: dqn, choose action rondomly, need time 0.000279999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.67544472]
 [ 1.97202826]
 [ 1.443483  ]
 [ 1.95811415]
 [ 2.71803784]
 [ 2.26622248]
 [ 1.78061879]
 [ 2.36227727]
 [ 2.34439373]
 [ 6.48614502]
 [ 2.34439373]
 [ 1.7220304 ]
 [ 2.34439373]
 [ 2.28689694]
 [ 1.64093697]
 [ 1.17453837]]
DEBUG:root:training time = %d0.217176
INFO:root:frame =4369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =4370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264883041382
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.965515
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =4373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =4374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:random_action_porb = 0.965483333333
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[ 2.40796423]
 [ 2.37891054]
 [ 2.25234103]
 [ 1.57268274]
 [ 1.58661544]
 [ 2.09099627]
 [ 2.47066379]
 [ 2.11619234]
 [ 1.75387359]
 [ 2.41793108]
 [ 1.88811862]
 [ 2.13243842]
 [ 1.45290291]
 [ 2.18056345]
 [ 1.84813893]
 [ 1.63424909]]
DEBUG:root:training time = %d0.233159
INFO:root:frame =4377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =4378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.965451666667
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =4381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =4382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.96542
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.97975516]
 [ 2.19377041]
 [ 1.66010404]
 [ 2.04073524]
 [ 1.81995785]
 [ 1.95063746]
 [ 2.12640429]
 [ 5.96769381]
 [ 2.06596208]
 [ 1.26491272]
 [ 1.56444609]
 [ 1.84694636]
 [ 2.04130769]
 [ 2.70254493]
 [ 2.23680711]
 [ 2.21633816]]
DEBUG:root:training time = %d0.191637
INFO:root:frame =4385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:frame =4386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424861907959
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:random_action_porb = 0.965388333333
DEBUG:root: dqn, choose action rondomly, need time 0.000234000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180959701538
INFO:root:frame =4389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =4390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.965356666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.47096491]
 [ 1.54069459]
 [ 1.4551568 ]
 [ 1.78598797]
 [ 1.66996837]
 [ 4.86735916]
 [ 1.54069459]
 [ 1.55231237]
 [ 1.64236414]
 [ 1.99066067]
 [ 5.23054647]
 [ 5.54373217]
 [ 1.76915348]
 [ 2.18098044]
 [ 1.40408361]
 [ 1.91337335]]
DEBUG:root:training time = %d0.216097
INFO:root:frame =4393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =4394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:random_action_porb = 0.965325
DEBUG:root: dqn, choose action rondomly, need time 0.00018399999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174999237061
INFO:root:frame =4397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =4398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.965293333333
DEBUG:root: dqn, choose action rondomly, need time 0.000384999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:training error  = [[ 1.84371281]
 [ 1.54005063]
 [ 1.81418324]
 [ 1.83108044]
 [ 1.79361248]
 [ 1.82351053]
 [ 1.70403647]
 [ 1.89657247]
 [ 1.74977374]
 [ 1.56599712]
 [ 1.8147279 ]
 [ 1.66240501]
 [ 1.82351053]
 [ 1.49361062]
 [ 1.87506843]
 [ 1.92574596]]
DEBUG:root:training time = %d0.226944
INFO:root:frame =4401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =4402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00048303604126
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.965261666667
DEBUG:root: dqn, choose action rondomly, need time 0.000227999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =4405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =4406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.96523
DEBUG:root: dqn, choose action rondomly, need time 0.000277999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.90475571]
 [ 1.54655731]
 [ 1.98506176]
 [ 6.10720158]
 [ 1.57710612]
 [ 1.61340022]
 [ 1.47495103]
 [ 2.14885283]
 [ 2.14885283]
 [ 1.56471336]
 [ 2.04046297]
 [ 1.93085241]
 [ 1.61496568]
 [ 1.39444506]
 [ 2.06946182]
 [ 1.58608687]]
DEBUG:root:training time = %d0.216297
INFO:root:frame =4409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =4410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.965198333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =4413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =4414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000287055969238
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.965166666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[ 1.61471355]
 [ 1.5503453 ]
 [ 2.05378032]
 [ 1.96198618]
 [ 1.94188833]
 [ 1.71232271]
 [ 1.57162559]
 [ 1.8077817 ]
 [ 1.52474129]
 [ 1.74171948]
 [ 1.67566204]
 [ 1.90489781]
 [ 1.93215132]
 [ 1.69121325]
 [ 1.61471355]
 [ 1.57706296]]
DEBUG:root:training time = %d0.213826
INFO:root:frame =4417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =4418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000378131866455
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.965135
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =4421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =4422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.965103333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:training error  = [[ 1.8908453 ]
 [ 1.40837204]
 [ 1.83200967]
 [ 1.61456335]
 [ 1.73254383]
 [ 1.53554249]
 [ 1.71170378]
 [ 2.12454677]
 [ 2.11367369]
 [ 1.53138077]
 [ 1.71783805]
 [ 1.75449502]
 [ 1.78347552]
 [ 1.91405928]
 [ 1.53138077]
 [ 1.72455931]]
DEBUG:root:training time = %d0.20743
INFO:root:frame =4425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:frame =4426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.965071666667
DEBUG:root: dqn, choose action rondomly, need time 0.000163999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:frame =4429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250816345215
INFO:root:frame =4430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000256061553955
DEBUG:root: save sample needs time = 0.000110864639282
INFO:root:random_action_porb = 0.96504
DEBUG:root: dqn, choose action rondomly, need time 0.000202999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:training error  = [[ 1.39527404]
 [ 1.98013091]
 [ 1.99392903]
 [ 1.60409594]
 [ 2.02859569]
 [ 1.70686615]
 [ 1.70686615]
 [ 1.66960359]
 [ 1.33840978]
 [ 1.47607243]
 [ 1.92071486]
 [ 1.93702209]
 [ 1.88074028]
 [ 1.70432031]
 [ 1.60409594]
 [ 2.11757421]]
DEBUG:root:training time = %d0.215095
INFO:root:frame =4433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:frame =4434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.965008333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291999999988
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =4437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =4438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488996505737
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.964976666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 1.85230041]
 [ 1.94770825]
 [ 1.76916873]
 [ 1.99084902]
 [ 1.58966327]
 [ 1.6634233 ]
 [ 1.88261878]
 [ 1.88701797]
 [ 1.83419955]
 [ 1.91978455]
 [ 2.25725555]
 [ 2.11273098]
 [ 1.91074646]
 [ 1.92940032]
 [ 1.86438572]
 [ 1.94054902]]
DEBUG:root:training time = %d0.21955
INFO:root:frame =4441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000341892242432
INFO:root:frame =4442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.964945
DEBUG:root: dqn, choose action rondomly, need time 0.000387999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =4445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:frame =4446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.964913333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:training error  = [[ 2.35896564]
 [ 1.94606888]
 [ 2.02939987]
 [ 1.87529302]
 [ 2.4023025 ]
 [ 1.88398516]
 [ 1.89870596]
 [ 1.28864551]
 [ 1.84175014]
 [ 1.50005591]
 [ 1.62120104]
 [ 1.86252666]
 [ 1.95126081]
 [ 1.91096258]
 [ 1.90972888]
 [ 1.91096258]]
DEBUG:root:training time = %d0.221336
INFO:root:frame =4449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =4450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame = 4451 State into memory, numbers recorded 110 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000562906265259
INFO:root:random_action_porb = 0.964881666667
DEBUG:root: dqn, choose action rondomly, need time 0.000325000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4452current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =4453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =4454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000111818313599
INFO:root:random_action_porb = 0.96485
DEBUG:root: dqn, choose action rondomly, need time 0.000221999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.84890652]
 [ 1.96405447]
 [ 1.6837405 ]
 [ 1.6837405 ]
 [ 6.10488272]
 [ 1.47463608]
 [ 0.08694067]
 [ 1.34260118]
 [ 2.03669381]
 [ 1.80733037]
 [ 1.52780461]
 [ 1.77892411]
 [ 1.47463608]
 [ 1.64456964]
 [ 6.29514217]
 [ 1.92426395]]
DEBUG:root:training time = %d0.230826
INFO:root:frame =4457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =4458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame = 4459 State into memory, numbers recorded 111 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000541210174561
INFO:root:random_action_porb = 0.964818333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4460current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =4461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =4462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.964786666667
DEBUG:root: dqn, choose action rondomly, need time 0.00028300000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:training error  = [[ 1.66838145]
 [ 2.56539345]
 [ 1.79007387]
 [ 2.46694183]
 [ 1.77169645]
 [ 2.05663514]
 [ 1.68886757]
 [ 1.73856437]
 [ 1.47919786]
 [ 2.36924767]
 [ 1.77169645]
 [ 2.46694183]
 [ 2.42991018]
 [ 2.65637493]
 [ 1.73856437]
 [ 1.6510334 ]]
DEBUG:root:training time = %d0.239224
INFO:root:frame =4465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =4466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:frame = 4467 State into memory, numbers recorded 112 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000535011291504
INFO:root:random_action_porb = 0.964755
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4468current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =4469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =4470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.964723333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.50648737]
 [ 2.97212648]
 [ 2.24842095]
 [ 1.81966972]
 [ 2.58870673]
 [ 1.80776632]
 [ 1.65613008]
 [ 1.54050517]
 [ 2.58858395]
 [ 2.32337308]
 [ 2.35390639]
 [ 2.19325638]
 [ 2.26184297]
 [ 1.63392723]
 [ 5.83134508]
 [ 2.03758669]]
DEBUG:root:training time = %d0.224661
INFO:root:frame =4473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =4474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.00010085105896
INFO:root:random_action_porb = 0.964691666667
DEBUG:root: dqn, choose action rondomly, need time 0.000169
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000130176544189
INFO:root:frame =4477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =4478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 9.29832458496e-05
INFO:root:random_action_porb = 0.96466
DEBUG:root: dqn, choose action rondomly, need time 0.000158999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000136137008667
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5.59788895]
 [ 1.74837124]
 [ 1.79761493]
 [ 1.4857142 ]
 [ 1.74467087]
 [ 2.05157781]
 [ 2.1231513 ]
 [ 1.83919883]
 [ 2.22822905]
 [ 2.47979236]
 [ 2.17671776]
 [ 1.97394121]
 [ 1.99501181]
 [ 1.79761493]
 [ 1.93145144]
 [ 5.59788895]]
DEBUG:root:training time = %d0.222457
INFO:root:frame =4481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =4482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.964628333333
DEBUG:root: dqn, choose action rondomly, need time 0.00034500000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =4485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =4486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.964596666667
INFO:root:dqn select action Tensor("ArgMax_21:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014529
INFO:root:action choosen by dqn [4]
INFO:root:frame =4488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:training error  = [[ 1.77612686]
 [ 1.72338235]
 [ 1.91441822]
 [ 2.1189456 ]
 [ 1.53884852]
 [ 2.17465281]
 [ 1.66007948]
 [ 2.05527854]
 [ 1.82517481]
 [ 1.66007948]
 [ 1.7437892 ]
 [ 1.75931871]
 [ 2.05527854]
 [ 1.75931871]
 [ 1.71041143]
 [ 1.77384484]]
DEBUG:root:training time = %d0.213321
INFO:root:frame =4489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =4490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:player has been killed for 2 times 
INFO:root:frame =4492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =4493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00044584274292
INFO:root:frame =4494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame = 4495 State into memory, numbers recorded 113 action = [4], reward = -1
DEBUG:root: save sample needs time = 0.00127911567688
INFO:root:random_action_porb = 0.964565
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4496current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:training error  = [[ 1.63400042]
 [ 2.00507855]
 [ 1.77878666]
 [ 2.10952187]
 [ 1.79662287]
 [ 1.80518734]
 [ 2.1808846 ]
 [ 2.35044289]
 [ 1.49321437]
 [ 1.8695302 ]
 [ 1.59511244]
 [ 1.98138189]
 [ 1.84892726]
 [ 1.57252967]
 [ 1.8490206 ]
 [ 1.79058421]]
DEBUG:root:training time = %d0.232815
INFO:root:frame =4497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000322818756104
INFO:root:frame =4498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:random_action_porb = 0.964533333333
INFO:root:dqn select action Tensor("ArgMax_22:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010671
INFO:root:action choosen by dqn [4]
INFO:root:frame =4500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000151872634888
INFO:root:frame =4501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000498056411743
INFO:root:frame =4502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424146652222
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.964501666667
DEBUG:root: dqn, choose action rondomly, need time 0.000279000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:training error  = [[ 1.96233344]
 [ 1.87502658]
 [ 1.64907336]
 [ 1.73217726]
 [ 1.71646845]
 [ 1.82593763]
 [ 1.96084821]
 [ 1.90739429]
 [ 1.92219019]
 [ 1.58795631]
 [ 1.98179531]
 [ 1.68748474]
 [ 1.70762372]
 [ 1.99189878]
 [ 1.73217726]
 [ 1.86990058]]
DEBUG:root:training time = %d0.222446
INFO:root:frame =4505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =4506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000256776809692
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.96447
DEBUG:root: dqn, choose action rondomly, need time 0.000256000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =4509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =4510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.964438333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.72293162]
 [ 2.31960678]
 [ 2.00351238]
 [ 1.85660684]
 [ 1.74795771]
 [ 2.12361813]
 [ 1.75154543]
 [ 2.20197082]
 [ 1.98333693]
 [ 2.50784659]
 [ 1.95538211]
 [ 1.73110807]
 [ 0.22344179]
 [ 1.70040333]
 [ 1.70124412]
 [ 6.11866093]]
DEBUG:root:training time = %d0.222592
INFO:root:frame =4513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =4514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.964406666667
DEBUG:root: dqn, choose action rondomly, need time 0.000217000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00018310546875
INFO:root:frame =4517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =4518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.964375
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.21705389]
 [ 1.85918069]
 [ 1.98572826]
 [ 1.82911944]
 [ 1.62517655]
 [ 5.11567354]
 [ 1.75461125]
 [ 2.02028608]
 [ 1.62517655]
 [ 1.5691781 ]
 [ 1.77585733]
 [ 2.02103424]
 [ 5.92596245]
 [ 1.82636547]
 [ 1.98572826]
 [ 2.32414055]]
DEBUG:root:training time = %d0.222862
INFO:root:frame =4521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =4522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.964343333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =4525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000480890274048
INFO:root:frame =4526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame = 4527 State into memory, numbers recorded 114 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000582933425903
INFO:root:random_action_porb = 0.964311666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4528current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.83081198]
 [ 1.64151847]
 [ 2.2371552 ]
 [ 1.89885318]
 [ 2.1100316 ]
 [ 1.71412027]
 [ 0.12746967]
 [ 2.1737473 ]
 [ 1.78648758]
 [ 1.91640329]
 [ 6.40467787]
 [ 1.94190431]
 [ 2.02708554]
 [ 1.49737525]
 [ 1.87680304]
 [ 1.49737525]]
DEBUG:root:training time = %d0.227136
INFO:root:frame =4529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root:frame =4530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.96428
INFO:root:dqn select action Tensor("ArgMax_23:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013098
INFO:root:action choosen by dqn [4]
INFO:root:frame =4532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000341892242432
INFO:root:frame =4533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000606060028076
INFO:root:frame =4534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248193740845
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.964248333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:training error  = [[ 2.01557159]
 [ 1.76471663]
 [ 1.79615247]
 [ 1.85810411]
 [ 1.77406847]
 [ 1.9773674 ]
 [ 1.85810411]
 [ 1.879511  ]
 [ 2.0134275 ]
 [ 2.26218724]
 [ 1.84010947]
 [ 1.96654665]
 [ 1.65303385]
 [ 1.91786635]
 [ 2.26218724]
 [ 2.49879313]]
DEBUG:root:training time = %d0.219651
INFO:root:frame =4537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =4538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.964216666667
DEBUG:root: dqn, choose action rondomly, need time 0.000185999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000168085098267
INFO:root:frame =4541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000425100326538
INFO:root:frame =4542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000516176223755
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.964185
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333786010742
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.01815557]
 [ 2.06831503]
 [ 2.16342211]
 [ 2.29670286]
 [ 1.70830178]
 [ 1.8952961 ]
 [ 1.89744461]
 [ 2.18904376]
 [ 5.18113565]
 [ 1.71382558]
 [ 2.16342211]
 [ 1.62845111]
 [ 1.72319698]
 [ 1.95849323]
 [ 2.06831503]
 [ 2.16957045]]
DEBUG:root:training time = %d0.226244
INFO:root:frame =4545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =4546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000412940979004
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.964153333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =4549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =4550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476837158203
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.964121666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.91655648]
 [ 0.11493699]
 [ 1.77333176]
 [ 1.53275955]
 [ 1.83033204]
 [ 1.99152732]
 [ 2.10277319]
 [ 2.00409031]
 [ 1.97439671]
 [ 1.80567944]
 [ 1.78226328]
 [ 1.70692098]
 [ 1.70482838]
 [ 6.15091801]
 [ 1.83386898]
 [ 1.53275955]]
DEBUG:root:training time = %d0.217725
INFO:root:frame =4553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =4554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428915023804
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.96409
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342845916748
INFO:root:frame =4557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =4558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.964058333333
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:training error  = [[ 2.17174554]
 [ 1.89911079]
 [ 1.88045251]
 [ 2.04463363]
 [ 1.97944927]
 [ 2.23870182]
 [ 1.50006056]
 [ 2.05196023]
 [ 2.10770488]
 [ 2.17626762]
 [ 2.04400635]
 [ 2.05196023]
 [ 1.91183805]
 [ 1.90017807]
 [ 2.16026998]
 [ 2.15715933]]
DEBUG:root:training time = %d0.222416
INFO:root:frame =4561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =4562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247001647949
DEBUG:root: save sample needs time = 0.000110864639282
INFO:root:random_action_porb = 0.964026666667
DEBUG:root: dqn, choose action rondomly, need time 0.000180999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000157833099365
INFO:root:frame =4565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =4566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000246047973633
DEBUG:root: save sample needs time = 0.000172138214111
INFO:root:random_action_porb = 0.963995
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.987836  ]
 [ 1.95787394]
 [ 2.02704763]
 [ 2.2355237 ]
 [ 2.37090373]
 [ 2.2355237 ]
 [ 2.14807558]
 [ 1.98628199]
 [ 0.12617503]
 [ 0.20041354]
 [ 2.09443974]
 [ 2.23627663]
 [ 5.77931356]
 [ 1.91903937]
 [ 1.8921622 ]
 [ 1.75784659]]
DEBUG:root:training time = %d0.20779
INFO:root:frame =4569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =4570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.963963333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =4574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.963931666667
DEBUG:root: dqn, choose action rondomly, need time 0.000332999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.93952882]
 [ 6.32146168]
 [ 1.92814469]
 [ 2.12718868]
 [ 1.53206062]
 [ 2.7942605 ]
 [ 0.1620463 ]
 [ 1.88010728]
 [ 1.99614346]
 [ 1.88399565]
 [ 2.23592877]
 [ 2.53242087]
 [ 2.08515882]
 [ 0.17056593]
 [ 1.8551414 ]
 [ 2.32942986]]
DEBUG:root:training time = %d0.231111
INFO:root:frame =4577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:frame =4578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame = 4579 State into memory, numbers recorded 115 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000530004501343
INFO:root:random_action_porb = 0.9639
DEBUG:root: dqn, choose action rondomly, need time 0.000308999999987
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4580current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =4581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446796417236
INFO:root:frame =4582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482082366943
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.963868333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.92803884]
 [ 1.5764451 ]
 [ 1.98533046]
 [ 1.99543214]
 [ 1.7310077 ]
 [ 1.95668912]
 [ 2.13139129]
 [ 2.122751  ]
 [ 2.06410933]
 [ 6.09490538]
 [ 2.2155261 ]
 [ 2.07626653]
 [ 2.36334443]
 [ 2.62335849]
 [ 2.01822615]
 [ 1.68864441]]
DEBUG:root:training time = %d0.216781
INFO:root:frame =4585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:frame =4586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000284194946289
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.963836666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =4589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =4590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:random_action_porb = 0.963805
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:training error  = [[ 1.80302513]
 [ 1.90655136]
 [ 1.51995933]
 [ 2.03138947]
 [ 1.90737319]
 [ 2.096632  ]
 [ 2.52117848]
 [ 1.99991262]
 [ 2.07704711]
 [ 1.79689395]
 [ 1.79592752]
 [ 1.76627266]
 [ 1.75761902]
 [ 2.05627942]
 [ 1.75897467]
 [ 1.99844015]]
DEBUG:root:training time = %d0.220918
INFO:root:frame =4593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =4594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.963773333333
DEBUG:root: dqn, choose action rondomly, need time 0.000199000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root:frame =4597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =4598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.963741666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.76687598]
 [ 5.65951252]
 [ 2.03311872]
 [ 2.4721992 ]
 [ 1.93854082]
 [ 2.15714264]
 [ 1.77593875]
 [ 2.06990075]
 [ 1.9080739 ]
 [ 1.75827146]
 [ 1.82993984]
 [ 2.14091396]
 [ 1.71197331]
 [ 1.77593875]
 [ 5.65951252]
 [ 2.12382388]]
DEBUG:root:training time = %d0.227402
INFO:root:frame =4601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =4602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274896621704
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.96371
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =4605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:frame =4606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame = 4607 State into memory, numbers recorded 116 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000591039657593
INFO:root:random_action_porb = 0.963678333333
DEBUG:root: dqn, choose action rondomly, need time 0.000159999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4608current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000367164611816
INFO:root:training error  = [[ 2.15541172]
 [ 2.24556184]
 [ 2.31003022]
 [ 1.92257631]
 [ 2.12771726]
 [ 1.85454917]
 [ 1.93522799]
 [ 1.97015381]
 [ 2.1066916 ]
 [ 2.1895237 ]
 [ 2.20574808]
 [ 2.13234377]
 [ 2.27360201]
 [ 2.32523417]
 [ 1.81526756]
 [ 1.81839895]]
DEBUG:root:training time = %d0.212593
INFO:root:frame =4609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =4610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226020812988
DEBUG:root: save sample needs time = 0.000130891799927
INFO:root:random_action_porb = 0.963646666667
DEBUG:root: dqn, choose action rondomly, need time 0.000489999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =4613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00044322013855
INFO:root:frame =4614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.963615
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:training error  = [[ 1.76126218]
 [ 2.00959158]
 [ 1.93596041]
 [ 1.67361343]
 [ 1.97064114]
 [ 1.96703339]
 [ 1.91457653]
 [ 1.67590404]
 [ 2.09345722]
 [ 1.90520322]
 [ 2.05768013]
 [ 1.9176656 ]
 [ 1.93779731]
 [ 1.986696  ]
 [ 1.55393827]
 [ 2.00959158]]
DEBUG:root:training time = %d0.238226
INFO:root:frame =4617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281810760498
INFO:root:frame =4618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000278949737549
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.963583333333
DEBUG:root: dqn, choose action rondomly, need time 0.000176999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:frame =4621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =4622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000284910202026
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.963551666667
DEBUG:root: dqn, choose action rondomly, need time 0.00028300000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.88814485]
 [ 1.89042044]
 [ 2.25979543]
 [ 0.12009425]
 [ 2.08421683]
 [ 2.30311275]
 [ 2.09670949]
 [ 2.09670949]
 [ 1.70563531]
 [ 2.04466629]
 [ 1.99137115]
 [ 2.04761839]
 [ 2.30043316]
 [ 2.14534259]
 [ 2.19343138]
 [ 2.04761839]]
DEBUG:root:training time = %d0.227054
INFO:root:frame =4625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =4626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.96352
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =4629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000416040420532
INFO:root:frame =4630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000331878662109
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:random_action_porb = 0.963488333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:training error  = [[ 1.6644026 ]
 [ 2.32321024]
 [ 2.69575763]
 [ 1.84761524]
 [ 2.35438037]
 [ 2.09763193]
 [ 1.8261025 ]
 [ 2.41596222]
 [ 2.75959659]
 [ 2.15398383]
 [ 1.8382057 ]
 [ 2.38403797]
 [ 2.27031898]
 [ 2.69150639]
 [ 2.47186923]
 [ 2.89349246]]
DEBUG:root:training time = %d0.227005
INFO:root:frame =4633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =4634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000256061553955
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.963456666667
DEBUG:root: dqn, choose action rondomly, need time 0.000181999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root:frame =4637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =4638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.963425
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.85597277]
 [ 1.93498385]
 [ 2.98660588]
 [ 1.85094035]
 [ 1.57083189]
 [ 2.13925672]
 [ 1.72215557]
 [ 2.52258396]
 [ 2.46971655]
 [ 2.73464131]
 [ 6.03420973]
 [ 2.64637446]
 [ 1.70024419]
 [ 7.67582989]
 [ 1.75872171]
 [ 2.84647846]]
DEBUG:root:training time = %d0.214668
INFO:root:frame =4641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =4642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame = 4643 State into memory, numbers recorded 117 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000539064407349
INFO:root:random_action_porb = 0.963393333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4644current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =4645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =4646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.963361666667
DEBUG:root: dqn, choose action rondomly, need time 0.00029099999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.35898328]
 [ 2.64307404]
 [ 2.35898328]
 [ 2.32528639]
 [ 1.90321863]
 [ 2.3518641 ]
 [ 2.13392043]
 [ 2.66688657]
 [ 2.02370334]
 [ 2.13625598]
 [ 2.20862699]
 [ 7.09884501]
 [ 2.62634969]
 [ 1.76923978]
 [ 3.18830156]
 [ 2.58021927]]
DEBUG:root:training time = %d0.225025
INFO:root:frame =4649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290155410767
INFO:root:frame =4650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00034499168396
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:random_action_porb = 0.96333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000391960144043
INFO:root:frame =4653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =4654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.963298333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000360012054443
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.76506627]
 [ 0.39241996]
 [ 2.89197445]
 [ 2.54902673]
 [ 2.21046996]
 [ 2.35522342]
 [ 2.27312469]
 [ 2.50336599]
 [ 2.55337715]
 [ 2.09312057]
 [ 2.35045457]
 [ 1.94007075]
 [ 2.21026015]
 [ 2.50436211]
 [ 1.95172441]
 [ 2.13438296]]
DEBUG:root:training time = %d0.221554
INFO:root:frame =4657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =4658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000492095947266
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.963266666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =4661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =4662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.963235
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.84477484]
 [ 2.04634118]
 [ 2.20612192]
 [ 0.19909392]
 [ 2.04634118]
 [ 2.46457553]
 [ 2.46457553]
 [ 2.43223572]
 [ 2.55252385]
 [ 1.84586298]
 [ 1.84477484]
 [ 2.60419059]
 [ 2.77065301]
 [ 2.16928959]
 [ 2.29290056]
 [ 2.43223572]]
DEBUG:root:training time = %d0.217389
INFO:root:frame =4665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =4666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.963203333333
DEBUG:root: dqn, choose action rondomly, need time 0.000517000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root: ememy has been killed for 6 times 
INFO:root:enemies_left [0]
INFO:root:frame =4668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =4669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =4670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame = 4671 State into memory, numbers recorded 118 action = 4, reward = 1
DEBUG:root: save sample needs time = 0.000534057617188
INFO:root:random_action_porb = 0.963171666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4672current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:training error  = [[ 1.91725361]
 [ 2.57572365]
 [ 2.36998177]
 [ 1.93207181]
 [ 1.69646096]
 [ 2.16565585]
 [ 2.55187178]
 [ 2.34115314]
 [ 1.94377589]
 [ 2.48746943]
 [ 1.96313512]
 [ 2.1563189 ]
 [ 1.72153997]
 [ 2.79810047]
 [ 1.6227411 ]
 [ 2.08222938]]
DEBUG:root:training time = %d0.228902
INFO:root:frame =4673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =4674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259160995483
INFO:root:frame = 4675 State into memory, numbers recorded 119 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000600099563599
INFO:root:random_action_porb = 0.96314
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4676current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =4677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =4678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424861907959
INFO:root:frame = 4679 State into memory, numbers recorded 120 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000550031661987
INFO:root:random_action_porb = 0.963108333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4680current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.07858682]
 [ 1.88074028]
 [ 2.03204179]
 [ 2.80797434]
 [ 2.29115057]
 [ 2.16884565]
 [ 2.09927869]
 [ 1.89229333]
 [ 2.27954197]
 [ 1.8568356 ]
 [ 2.48263454]
 [ 2.27168703]
 [ 2.36221266]
 [ 2.03233552]
 [ 6.71785593]
 [ 1.89006376]]
DEBUG:root:training time = %d0.219449
INFO:root:frame =4681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =4682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000253915786743
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.963076666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =4685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000515937805176
INFO:root:frame =4686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000300884246826
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.963045
DEBUG:root: dqn, choose action rondomly, need time 0.000160000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320196151733
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.595186  ]
 [ 1.78007925]
 [ 2.24557328]
 [ 2.21557713]
 [ 1.76778889]
 [ 2.13081217]
 [ 2.47483897]
 [ 2.50535822]
 [ 1.8531208 ]
 [ 1.83037329]
 [ 2.93239355]
 [ 2.26721048]
 [ 2.363796  ]
 [ 6.17344618]
 [ 1.78007925]
 [ 2.16332674]]
DEBUG:root:training time = %d0.213103
INFO:root:frame =4689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =4690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.963013333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =4693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =4694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.962981666667
DEBUG:root: dqn, choose action rondomly, need time 0.000446999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000367879867554
INFO:root:training error  = [[ 2.58823419]
 [ 2.11818504]
 [ 2.11703587]
 [ 2.31702209]
 [ 1.99334192]
 [ 2.22560477]
 [ 2.48764992]
 [ 1.93631601]
 [ 1.95865333]
 [ 2.29777241]
 [ 2.41220427]
 [ 1.92260802]
 [ 2.38878775]
 [ 1.89287066]
 [ 2.42453766]
 [ 2.38878775]]
DEBUG:root:training time = %d0.193144
INFO:root:frame =4697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00036883354187
INFO:root:frame =4698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000316858291626
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:random_action_porb = 0.96295
DEBUG:root: dqn, choose action rondomly, need time 0.000154000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000131845474243
INFO:root:frame =4701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000500917434692
INFO:root:frame =4702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000362873077393
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:random_action_porb = 0.962918333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000251770019531
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.62208581]
 [ 2.18096352]
 [ 2.40188265]
 [ 0.17243321]
 [ 2.08436561]
 [ 1.88511109]
 [ 2.40855622]
 [ 2.45266056]
 [ 1.87196684]
 [ 7.15477419]
 [ 2.69234514]
 [ 2.21799684]
 [ 2.53494692]
 [ 2.17968488]
 [ 1.99538898]
 [ 2.2582531 ]]
DEBUG:root:training time = %d0.193705
INFO:root:frame =4705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:frame =4706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root:random_action_porb = 0.962886666667
DEBUG:root: dqn, choose action rondomly, need time 0.000194000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:frame =4709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =4710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000280857086182
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:random_action_porb = 0.962855
DEBUG:root: dqn, choose action rondomly, need time 0.000639000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.44496584]
 [ 2.23296356]
 [ 2.31472898]
 [ 2.10371923]
 [ 2.10371923]
 [ 1.96623635]
 [ 6.55233765]
 [ 1.88373387]
 [ 2.10903978]
 [ 1.88678217]
 [ 6.71650171]
 [ 2.00154209]
 [ 1.95903778]
 [ 2.15645337]
 [ 2.69184446]
 [ 2.02010155]]
DEBUG:root:training time = %d0.221401
INFO:root:frame =4713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =4714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.962823333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =4717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000602006912231
INFO:root:frame =4718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.962791666667
DEBUG:root: dqn, choose action rondomly, need time 0.000360000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000156879425049
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.23871875]
 [ 2.10233617]
 [ 2.19091797]
 [ 2.14495134]
 [ 1.90260828]
 [ 6.11208582]
 [ 1.84755814]
 [ 2.3563416 ]
 [ 1.80260003]
 [ 1.95071733]
 [ 1.86414611]
 [ 2.2283771 ]
 [ 2.22978377]
 [ 1.87095964]
 [ 1.97010565]
 [ 2.19709969]]
DEBUG:root:training time = %d0.195458
INFO:root:frame =4721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =4722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00030517578125
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.96276
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000401973724365
INFO:root:frame =4725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =4726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame = 4727 State into memory, numbers recorded 121 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000582933425903
INFO:root:random_action_porb = 0.962728333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4728current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:training error  = [[ 2.26667619]
 [ 2.45829749]
 [ 1.90078282]
 [ 2.06848502]
 [ 2.05806851]
 [ 2.07603574]
 [ 2.23168111]
 [ 1.9706893 ]
 [ 2.25828743]
 [ 2.24587059]
 [ 2.1090951 ]
 [ 2.09801316]
 [ 2.21575904]
 [ 1.67649662]
 [ 2.41401768]
 [ 2.2226181 ]]
DEBUG:root:training time = %d0.234005
INFO:root:frame =4729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame =4730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000318050384521
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.962696666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =4733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =4734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000141143798828
INFO:root:random_action_porb = 0.962665
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:training error  = [[ 2.26937056]
 [ 2.76863432]
 [ 2.13646221]
 [ 2.18950677]
 [ 2.55160975]
 [ 2.37505245]
 [ 2.02410483]
 [ 2.3586669 ]
 [ 2.69927859]
 [ 2.60499096]
 [ 2.25487208]
 [ 1.77950919]
 [ 2.16419101]
 [ 2.05703998]
 [ 2.36951184]
 [ 1.84897912]]
DEBUG:root:training time = %d0.223691
INFO:root:frame =4737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000387191772461
INFO:root:frame =4738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025486946106
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.962633333333
DEBUG:root: dqn, choose action rondomly, need time 0.000318000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =4741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000486135482788
INFO:root:frame =4742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.962601666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294000000011
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root:training error  = [[ 2.12187314]
 [ 2.3176434 ]
 [ 2.61527681]
 [ 1.85633659]
 [ 2.2060709 ]
 [ 1.82240319]
 [ 1.82240319]
 [ 2.47852492]
 [ 1.63287902]
 [ 2.70261383]
 [ 2.73618698]
 [ 2.32924366]
 [ 1.82240319]
 [ 2.89931607]
 [ 2.24515605]
 [ 2.42140245]]
DEBUG:root:training time = %d0.215517
INFO:root:frame =4745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =4746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.96257
DEBUG:root: dqn, choose action rondomly, need time 0.00028300000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000372886657715
INFO:root:frame =4749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:frame =4750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000417947769165
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.962538333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:training error  = [[ 3.19025683]
 [ 2.35023236]
 [ 2.03524065]
 [ 2.12005091]
 [ 2.11061335]
 [ 2.19703174]
 [ 2.46388698]
 [ 2.03279781]
 [ 1.92767859]
 [ 2.50235224]
 [ 2.38040519]
 [ 2.62171531]
 [ 1.96981108]
 [ 2.51818132]
 [ 2.21911049]
 [ 1.87080836]]
DEBUG:root:training time = %d0.200921
INFO:root:frame =4753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =4754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.962506666667
INFO:root:dqn select action Tensor("ArgMax_24:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.008239
INFO:root:action choosen by dqn [4]
INFO:root:frame =4756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =4757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000509023666382
INFO:root:frame =4758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:random_action_porb = 0.962475
DEBUG:root: dqn, choose action rondomly, need time 0.00029099999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 6.6952529 ]
 [ 1.95042431]
 [ 2.205374  ]
 [ 2.0243926 ]
 [ 2.03996158]
 [ 2.03111219]
 [ 2.57036328]
 [ 2.02483773]
 [ 2.22967553]
 [ 2.30896354]
 [ 2.61472797]
 [ 2.26965785]
 [ 2.0709877 ]
 [ 0.1505281 ]
 [ 1.90391862]
 [ 2.03007936]]
DEBUG:root:training time = %d0.23638
INFO:root:frame =4761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =4762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame = 4763 State into memory, numbers recorded 122 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000607013702393
INFO:root:random_action_porb = 0.962443333333
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4764current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =4765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =4766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.962411666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.18759918]
 [ 2.42016196]
 [ 2.00030637]
 [ 2.18759918]
 [ 2.03773928]
 [ 2.50296164]
 [ 1.88963377]
 [ 2.80658746]
 [ 1.72233582]
 [ 6.14701128]
 [ 2.76152349]
 [ 1.93693709]
 [ 2.34682393]
 [ 2.16978383]
 [ 2.01146841]
 [ 2.45952988]]
DEBUG:root:training time = %d0.21885
INFO:root:frame =4769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =4770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:random_action_porb = 0.96238
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000495910644531
INFO:root:frame =4774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame = 4775 State into memory, numbers recorded 123 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000560998916626
INFO:root:random_action_porb = 0.962348333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4776current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.07473326]
 [ 2.18560791]
 [ 5.70030546]
 [ 1.98285878]
 [ 2.29370928]
 [ 2.1882031 ]
 [ 0.18314113]
 [ 2.19919229]
 [ 5.9396677 ]
 [ 5.70030546]
 [ 1.96958089]
 [ 2.53461289]
 [ 2.18560791]
 [ 1.95954502]
 [ 2.29584742]
 [ 2.53461289]]
DEBUG:root:training time = %d0.202992
INFO:root:frame =4777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =4778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000301122665405
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.962316666667
DEBUG:root: dqn, choose action rondomly, need time 0.000373999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000470876693726
INFO:root:frame =4781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =4782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487089157104
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.962285
DEBUG:root: dqn, choose action rondomly, need time 0.000531000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root:training error  = [[ 2.27845931]
 [ 2.71032667]
 [ 2.27646756]
 [ 1.88095474]
 [ 2.09388232]
 [ 1.97455215]
 [ 2.2144134 ]
 [ 1.89987314]
 [ 2.59971094]
 [ 2.47922158]
 [ 2.01809072]
 [ 2.78168082]
 [ 2.01764631]
 [ 2.5104568 ]
 [ 2.21791148]
 [ 2.27782607]]
DEBUG:root:training time = %d0.225842
INFO:root:frame =4785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =4786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.962253333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =4789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000385046005249
INFO:root:frame =4790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436782836914
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.962221666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.2340467 ]
 [ 2.48308539]
 [ 2.05881834]
 [ 2.01154971]
 [ 2.42352796]
 [ 2.32982588]
 [ 2.22701073]
 [ 1.91332579]
 [ 2.06094265]
 [ 2.32773614]
 [ 3.08391976]
 [ 2.02179909]
 [ 2.10851908]
 [ 2.50062656]
 [ 6.80606079]
 [ 2.07409596]]
DEBUG:root:training time = %d0.213196
INFO:root:frame =4793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =4794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.96219
DEBUG:root: dqn, choose action rondomly, need time 0.000159000000011
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:frame =4797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:frame =4798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000253915786743
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.962158333333
DEBUG:root: dqn, choose action rondomly, need time 0.000160999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.63236213]
 [ 2.51944661]
 [ 2.27427506]
 [ 1.98941219]
 [ 2.35834479]
 [ 2.19199657]
 [ 2.58518481]
 [ 2.07081199]
 [ 2.25645328]
 [ 2.22844553]
 [ 2.5389812 ]
 [ 2.91415095]
 [ 2.850734  ]
 [ 2.22844553]
 [ 2.19987679]
 [ 6.91515017]]
DEBUG:root:training time = %d0.230946
INFO:root:frame =4801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =4802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000346899032593
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.962126666667
DEBUG:root: dqn, choose action rondomly, need time 0.000184999999988
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000168085098267
INFO:root:frame =4805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433206558228
INFO:root:frame =4806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.962095
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:training error  = [[ 2.0082345 ]
 [ 2.84257936]
 [ 2.30464149]
 [ 2.27487922]
 [ 2.30464149]
 [ 2.10009122]
 [ 3.25893497]
 [ 3.36780977]
 [ 2.10540724]
 [ 1.9851048 ]
 [ 1.84218514]
 [ 2.60189486]
 [ 2.22623658]
 [ 2.00552702]
 [ 2.3684082 ]
 [ 2.19322801]]
DEBUG:root:training time = %d0.215141
INFO:root:frame =4809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =4810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000281095504761
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:random_action_porb = 0.962063333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =4814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:random_action_porb = 0.962031666667
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.69640899]
 [ 6.07371521]
 [ 2.53049088]
 [ 2.51344371]
 [ 2.63733435]
 [ 1.96612406]
 [ 2.35987401]
 [ 2.02788401]
 [ 2.41375089]
 [ 1.95387805]
 [ 2.05954099]
 [ 2.40612936]
 [ 2.30892897]
 [ 2.19517183]
 [ 5.84144545]
 [ 0.15036239]]
DEBUG:root:training time = %d0.211913
INFO:root:frame =4817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =4818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000396013259888
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.962
DEBUG:root: dqn, choose action rondomly, need time 0.000268000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =4821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =4822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.961968333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.57794023]
 [ 2.9024477 ]
 [ 2.04916358]
 [ 1.96737051]
 [ 2.66697979]
 [ 2.24545336]
 [ 2.27163529]
 [ 2.11043048]
 [ 2.12643766]
 [ 7.39954805]
 [ 3.19681478]
 [ 2.93066287]
 [ 2.98103786]
 [ 0.48061234]
 [ 2.44490623]
 [ 2.63154531]]
DEBUG:root:training time = %d0.220314
INFO:root:frame =4825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =4826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475168228149
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.961936666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =4829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =4830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame = 4831 State into memory, numbers recorded 124 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000565052032471
INFO:root:random_action_porb = 0.961905
DEBUG:root: dqn, choose action rondomly, need time 0.000456999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4832current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root:training error  = [[ 2.26217008]
 [ 2.20810556]
 [ 2.09532309]
 [ 2.51750922]
 [ 1.96517205]
 [ 2.43515182]
 [ 2.51750922]
 [ 2.77483273]
 [ 2.60928392]
 [ 2.7598629 ]
 [ 2.77483273]
 [ 2.52060318]
 [ 2.24252176]
 [ 2.55848765]
 [ 2.00852108]
 [ 2.86711073]]
DEBUG:root:training time = %d0.208607
INFO:root:frame =4833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =4834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.961873333333
DEBUG:root: dqn, choose action rondomly, need time 0.00027200000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =4837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =4838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000167846679688
INFO:root:random_action_porb = 0.961841666667
DEBUG:root: dqn, choose action rondomly, need time 0.000253000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:training error  = [[ 2.33041406]
 [ 2.55262136]
 [ 1.869452  ]
 [ 2.36823201]
 [ 2.34988141]
 [ 2.02884555]
 [ 2.74310732]
 [ 2.45568442]
 [ 2.69905925]
 [ 2.27171588]
 [ 2.42161608]
 [ 2.06755257]
 [ 2.74310732]
 [ 2.49227881]
 [ 2.70204329]
 [ 2.08077621]]
DEBUG:root:training time = %d0.223472
INFO:root:frame =4841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =4842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288009643555
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.96181
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =4846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame = 4847 State into memory, numbers recorded 125 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000559091567993
INFO:root:random_action_porb = 0.961778333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4848current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.69206357]
 [ 1.75448489]
 [ 1.98999333]
 [ 2.6226418 ]
 [ 2.39507699]
 [ 2.09654379]
 [ 2.44935799]
 [ 2.15147638]
 [ 0.28610238]
 [ 2.02082276]
 [ 2.61117601]
 [ 2.78859448]
 [ 2.50324535]
 [ 2.50324535]
 [ 2.07239318]
 [ 2.37099195]]
DEBUG:root:training time = %d0.220908
INFO:root:frame =4849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266790390015
INFO:root:frame =4850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000314950942993
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.961746666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =4853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =4854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.961715
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342845916748
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.33146238]
 [ 2.39792919]
 [ 2.41658473]
 [ 2.58855939]
 [ 2.49356174]
 [ 2.30261493]
 [ 2.65252781]
 [ 2.33002973]
 [ 2.12199521]
 [ 2.24242473]
 [ 2.26125216]
 [ 2.92343807]
 [ 5.94764709]
 [ 2.51865339]
 [ 2.87127852]
 [ 2.20774841]]
DEBUG:root:training time = %d0.216867
INFO:root:frame =4857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =4858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.961683333333
DEBUG:root: dqn, choose action rondomly, need time 0.000271999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =4861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root:frame =4862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.961651666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.00845075]
 [ 2.29128337]
 [ 2.54315281]
 [ 2.29693985]
 [ 2.46882939]
 [ 2.16254687]
 [ 6.90439034]
 [ 2.33661413]
 [ 2.17753959]
 [ 2.04850817]
 [ 2.1704638 ]
 [ 2.51993704]
 [ 2.67770576]
 [ 2.3781929 ]
 [ 1.86838293]
 [ 2.28110313]]
DEBUG:root:training time = %d0.236877
INFO:root:frame =4865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279188156128
INFO:root:frame =4866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264883041382
DEBUG:root: save sample needs time = 0.000156879425049
INFO:root:random_action_porb = 0.96162
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =4869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456809997559
INFO:root:frame =4870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.961588333333
DEBUG:root: dqn, choose action rondomly, need time 0.000339000000011
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.19466329]
 [ 2.3930583 ]
 [ 2.24791765]
 [ 3.19871116]
 [ 0.30506003]
 [ 2.11521029]
 [ 2.22285128]
 [ 2.02057886]
 [ 2.16246843]
 [ 2.02155495]
 [ 5.90949106]
 [ 2.22860479]
 [ 2.11521029]
 [ 2.81477976]
 [ 2.36644173]
 [ 2.88884187]]
DEBUG:root:training time = %d0.215598
INFO:root:frame =4873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =4874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000278234481812
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.961556666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =4877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =4878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487804412842
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.961525
DEBUG:root: dqn, choose action rondomly, need time 0.000471000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.22387505]
 [ 2.07704163]
 [ 2.31347561]
 [ 2.31749249]
 [ 2.15641975]
 [ 2.68712735]
 [ 2.28456712]
 [ 2.60691214]
 [ 2.95461297]
 [ 3.01650476]
 [ 2.68712735]
 [ 7.04811716]
 [ 2.45243955]
 [ 2.42797804]
 [ 2.40969896]
 [ 2.32108259]]
DEBUG:root:training time = %d0.185627
INFO:root:frame =4881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000342845916748
INFO:root:frame =4882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031590461731
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root:random_action_porb = 0.961493333333
DEBUG:root: dqn, choose action rondomly, need time 0.000195000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:frame =4885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =4886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000322103500366
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:random_action_porb = 0.961461666667
DEBUG:root: dqn, choose action rondomly, need time 0.000189000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000150918960571
INFO:root:training error  = [[ 2.15022874]
 [ 2.54738259]
 [ 2.26552773]
 [ 1.92120135]
 [ 2.65368366]
 [ 2.36824369]
 [ 2.51399398]
 [ 2.33488846]
 [ 2.04788589]
 [ 2.76546788]
 [ 2.05204225]
 [ 2.45757389]
 [ 2.5787487 ]
 [ 2.33488846]
 [ 3.2932024 ]
 [ 2.4875958 ]]
DEBUG:root:training time = %d0.192933
INFO:root:frame =4889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =4890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame = 4891 State into memory, numbers recorded 126 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000541925430298
INFO:root:random_action_porb = 0.96143
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4892current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =4893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000574827194214
INFO:root:frame =4894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root:random_action_porb = 0.961398333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:training error  = [[ 2.21248937]
 [ 2.13947988]
 [ 2.27891421]
 [ 2.57080364]
 [ 2.36248231]
 [ 2.70489073]
 [ 2.20833778]
 [ 2.23604846]
 [ 2.04017949]
 [ 2.59797668]
 [ 2.70177984]
 [ 2.06856728]
 [ 2.44104862]
 [ 2.19776678]
 [ 2.45658731]
 [ 2.29463959]]
DEBUG:root:training time = %d0.207898
INFO:root:frame =4897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =4898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000524044036865
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:random_action_porb = 0.961366666667
DEBUG:root: dqn, choose action rondomly, need time 0.000226999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:frame =4901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000401973724365
INFO:root:frame =4902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000497102737427
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:random_action_porb = 0.961335
DEBUG:root: dqn, choose action rondomly, need time 0.00036399999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000487804412842
INFO:root:training error  = [[ 2.40265727]
 [ 2.46566582]
 [ 2.28196168]
 [ 2.12270117]
 [ 2.28897429]
 [ 2.39032102]
 [ 2.79848337]
 [ 1.86877918]
 [ 2.44222283]
 [ 2.35479021]
 [ 2.56441593]
 [ 2.19301915]
 [ 2.08799648]
 [ 2.284446  ]
 [ 2.07171226]
 [ 2.43136716]]
DEBUG:root:training time = %d0.19667
INFO:root:frame =4905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =4906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000266075134277
DEBUG:root: save sample needs time = 0.000176906585693
INFO:root:random_action_porb = 0.961303333333
DEBUG:root: dqn, choose action rondomly, need time 0.000377
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =4909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =4910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.961271666667
DEBUG:root: dqn, choose action rondomly, need time 0.000210999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000197172164917
INFO:root:training error  = [[ 2.57579088]
 [ 2.37096834]
 [ 2.37096834]
 [ 2.17541242]
 [ 2.13753295]
 [ 2.69862056]
 [ 2.41242957]
 [ 2.4972074 ]
 [ 2.43528867]
 [ 3.01677632]
 [ 3.00312972]
 [ 2.39593291]
 [ 2.30952024]
 [ 2.33167195]
 [ 2.33614206]
 [ 2.4978466 ]]
DEBUG:root:training time = %d0.211812
INFO:root:frame =4913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =4914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.96124
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =4917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =4918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000140190124512
INFO:root:random_action_porb = 0.961208333333
INFO:root:dqn select action Tensor("ArgMax_25:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015465
INFO:root:action choosen by dqn [4]
INFO:root:frame =4920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000406980514526
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.35891891]
 [ 2.44308734]
 [ 2.78360248]
 [ 2.29387689]
 [ 2.74655795]
 [ 2.27842474]
 [ 2.42343879]
 [ 2.27842474]
 [ 2.40595198]
 [ 2.25108743]
 [ 2.38592911]
 [ 2.33178282]
 [ 2.34406662]
 [ 6.73978376]
 [ 2.20387316]
 [ 2.78360248]]
DEBUG:root:training time = %d0.193783
INFO:root:frame =4921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =4922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame = 4923 State into memory, numbers recorded 127 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.000647068023682
INFO:root:random_action_porb = 0.961176666667
INFO:root:dqn select action Tensor("ArgMax_26:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011382
INFO:root:action choosen by dqn [4]
INFO:root:frame =4924current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000858068466187
INFO:root:frame =4925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =4926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.961145
DEBUG:root: dqn, choose action rondomly, need time 0.000394999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.15444374]
 [ 2.54289126]
 [ 7.20998001]
 [ 2.9036305 ]
 [ 2.44789553]
 [ 3.15270281]
 [ 2.65915489]
 [ 2.65447283]
 [ 2.16462302]
 [ 2.59798288]
 [ 2.69141889]
 [ 2.95177436]
 [ 2.87111688]
 [ 2.32917953]
 [ 2.96320891]
 [ 2.57431555]]
DEBUG:root:training time = %d0.192662
INFO:root:frame =4929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:frame =4930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:random_action_porb = 0.961113333333
INFO:root:dqn select action Tensor("ArgMax_27:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010856
INFO:root:action choosen by dqn [4]
INFO:root:frame =4932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162839889526
INFO:root:frame =4933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000192880630493
INFO:root:frame =4934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000607013702393
DEBUG:root: save sample needs time = 0.000140190124512
INFO:root:random_action_porb = 0.961081666667
DEBUG:root: dqn, choose action rondomly, need time 0.000258000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.34425354]
 [ 2.26238227]
 [ 2.34302711]
 [ 2.39059806]
 [ 2.97663331]
 [ 2.43809938]
 [ 2.20964766]
 [ 2.34302711]
 [ 2.99816704]
 [ 2.75713205]
 [ 6.07104588]
 [ 2.98503041]
 [ 2.71378183]
 [ 2.04371738]
 [ 2.18563628]
 [ 2.39059806]]
DEBUG:root:training time = %d0.197547
INFO:root:frame =4937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =4938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:frame = 4939 State into memory, numbers recorded 128 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000399112701416
INFO:root:random_action_porb = 0.96105
DEBUG:root: dqn, choose action rondomly, need time 0.000643999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4940current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =4941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00068211555481
INFO:root:frame =4942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428199768066
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:random_action_porb = 0.961018333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:training error  = [[ 2.54115796]
 [ 2.32173944]
 [ 2.29763365]
 [ 2.40126204]
 [ 2.24345875]
 [ 2.11361814]
 [ 2.50638485]
 [ 2.39269829]
 [ 2.89418697]
 [ 2.28138542]
 [ 2.39300513]
 [ 2.5484786 ]
 [ 2.71203518]
 [ 3.25307727]
 [ 2.56962943]
 [ 2.96142983]]
DEBUG:root:training time = %d0.208213
INFO:root:frame =4945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =4946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000495910644531
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.960986666667
DEBUG:root: dqn, choose action rondomly, need time 0.000485999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =4949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =4950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049614906311
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.960955
DEBUG:root: dqn, choose action rondomly, need time 0.000179999999986
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000176906585693
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.27456856]
 [ 2.85036707]
 [ 2.89236355]
 [ 2.54874039]
 [ 2.57282233]
 [ 3.01557732]
 [ 2.41728449]
 [ 2.68621445]
 [ 2.36058903]
 [ 2.61610365]
 [ 0.28471455]
 [ 2.29306793]
 [ 2.36058903]
 [ 2.94083953]
 [ 2.8760767 ]
 [ 2.02239037]]
DEBUG:root:training time = %d0.207222
INFO:root:frame =4953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =4954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000258922576904
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.960923333333
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =4957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =4958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000289916992188
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.960891666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.3975457 ]
 [ 2.5117867 ]
 [ 2.63714862]
 [ 2.72139096]
 [ 2.45543337]
 [ 2.30115652]
 [ 2.81271291]
 [ 2.14577842]
 [ 2.6974175 ]
 [ 2.6478889 ]
 [ 2.66340518]
 [ 2.5462563 ]
 [ 2.6552062 ]
 [ 2.3937428 ]
 [ 2.38691926]
 [ 2.50293756]]
DEBUG:root:training time = %d0.217207
INFO:root:frame =4961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =4962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482082366943
DEBUG:root: save sample needs time = 0.000227212905884
INFO:root:random_action_porb = 0.96086
DEBUG:root: dqn, choose action rondomly, need time 0.00029099999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =4965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =4966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.960828333333
DEBUG:root: dqn, choose action rondomly, need time 0.000171000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000420808792114
INFO:root:training error  = [[ 2.3504312 ]
 [ 2.34639168]
 [ 2.35143137]
 [ 3.02342558]
 [ 2.93685031]
 [ 3.82589626]
 [ 3.2740891 ]
 [ 2.63833809]
 [ 2.5609901 ]
 [ 2.60446143]
 [ 2.830302  ]
 [ 2.29898691]
 [ 2.37871647]
 [ 2.37641668]
 [ 2.39638782]
 [ 2.53274274]]
DEBUG:root:training time = %d0.204475
INFO:root:frame =4969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000276803970337
INFO:root:frame =4970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000282049179077
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:random_action_porb = 0.960796666667
DEBUG:root: dqn, choose action rondomly, need time 0.00029099999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =4973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000508069992065
INFO:root:frame =4974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000174999237061
INFO:root:random_action_porb = 0.960765
DEBUG:root: dqn, choose action rondomly, need time 0.00028300000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.23764586]
 [ 2.67335677]
 [ 2.35253119]
 [ 2.52999926]
 [ 2.54864907]
 [ 6.50612497]
 [ 2.51704335]
 [ 2.54954433]
 [ 2.61321068]
 [ 2.68472052]
 [ 2.69181323]
 [ 2.44617701]
 [ 2.4333365 ]
 [ 2.33583879]
 [ 2.60407352]
 [ 2.53829455]]
DEBUG:root:training time = %d0.22139
INFO:root:frame =4977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =4978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:random_action_porb = 0.960733333333
INFO:root:dqn select action Tensor("ArgMax_28:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013219
INFO:root:action choosen by dqn [4]
INFO:root:frame =4980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162124633789
INFO:root:frame =4981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:frame =4982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000545978546143
INFO:root:frame = 4983 State into memory, numbers recorded 129 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00114703178406
INFO:root:random_action_porb = 0.960701666667
DEBUG:root: dqn, choose action rondomly, need time 0.000259
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4984current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:training error  = [[ 2.41411853]
 [ 3.00772595]
 [ 2.42011452]
 [ 3.33505702]
 [ 3.22410035]
 [ 3.11801767]
 [ 2.3984313 ]
 [ 3.03055358]
 [ 2.40995932]
 [ 2.71822667]
 [ 2.4968338 ]
 [ 2.5529809 ]
 [ 3.2999692 ]
 [ 2.3527534 ]
 [ 2.49919724]
 [ 3.4145174 ]]
DEBUG:root:training time = %d0.211563
INFO:root:frame =4985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =4986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.96067
DEBUG:root: dqn, choose action rondomly, need time 0.000355999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304222106934
INFO:root:frame =4989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000549077987671
INFO:root:frame =4990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.960638333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000405788421631
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.33304119]
 [ 3.57674241]
 [ 2.72671127]
 [ 2.49202585]
 [ 2.16585231]
 [ 2.92341852]
 [ 2.79767942]
 [ 2.42738366]
 [ 0.59643662]
 [ 2.1698401 ]
 [ 3.21990299]
 [ 2.39552569]
 [ 2.18708014]
 [ 3.19496679]
 [ 2.79767942]
 [ 3.03305101]]
DEBUG:root:training time = %d0.206848
INFO:root:frame =4993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000409126281738
INFO:root:frame =4994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.960606666667
DEBUG:root: dqn, choose action rondomly, need time 0.000349999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000514984130859
INFO:root:frame =4997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root:frame =4998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427007675171
DEBUG:root: save sample needs time = 0.000174045562744
DEBUG:root:one frame running time = 0.0052
DEBUG:root:total training time = 119.340067
INFO:root:frame num = 5000 frame round: 0
INFO:root:random_action_porb = 0.960575
DEBUG:root: dqn, choose action rondomly, need time 0.000528000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.12102938]
 [ 3.0879941 ]
 [ 3.57126856]
 [ 3.07610679]
 [ 2.97663975]
 [ 3.36153316]
 [ 1.97643948]
 [ 2.2604146 ]
 [ 2.37096262]
 [ 2.21395922]
 [ 7.27072573]
 [ 2.57143974]
 [ 3.19565535]
 [ 2.14635396]
 [ 1.97643948]
 [ 2.95741343]]
DEBUG:root:training time = %d0.198561
INFO:root:frame =5001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =5002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000347852706909
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.960543333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =5005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =5006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000545024871826
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.960511666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.26007628]
 [ 2.92094064]
 [ 2.92094064]
 [ 3.12385368]
 [ 2.31230354]
 [ 2.37034583]
 [ 2.29790545]
 [ 2.44269395]
 [ 2.53446698]
 [ 2.53446698]
 [ 2.25144219]
 [ 2.38762641]
 [ 6.80408049]
 [ 2.53949809]
 [ 2.65428638]
 [ 2.92094064]]
DEBUG:root:training time = %d0.209684
INFO:root:frame =5009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =5010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.96048
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =5013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =5014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame = 5015 State into memory, numbers recorded 130 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000581979751587
INFO:root:random_action_porb = 0.960448333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5016current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.3424139 ]
 [ 2.73411775]
 [ 2.67893577]
 [ 2.52864647]
 [ 2.84889245]
 [ 2.4971714 ]
 [ 7.4459219 ]
 [ 2.71864176]
 [ 2.39896894]
 [ 2.89503074]
 [ 2.69982386]
 [ 2.65636253]
 [ 2.16493177]
 [ 2.36314511]
 [ 2.24990273]
 [ 0.2801047 ]]
DEBUG:root:training time = %d0.232218
INFO:root:frame =5017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =5018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:random_action_porb = 0.960416666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000358104705811
INFO:root:frame =5021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =5022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000528812408447
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.960385
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.7988472 ]
 [ 2.9478302 ]
 [ 2.53686047]
 [ 0.24937478]
 [ 2.60532331]
 [ 2.81013536]
 [ 2.90196037]
 [ 2.79651833]
 [ 2.81013536]
 [ 2.75785422]
 [ 2.86363673]
 [ 2.90888524]
 [ 2.27329731]
 [ 2.40640759]
 [ 2.37615204]
 [ 2.29799795]]
DEBUG:root:training time = %d0.225596
INFO:root:frame =5025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =5026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259160995483
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.960353333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =5029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =5030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.960321666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.55659652]
 [ 2.47722793]
 [ 2.25596642]
 [ 2.33291292]
 [ 2.53098845]
 [ 2.36264062]
 [ 2.81965876]
 [ 2.82635021]
 [ 2.51169014]
 [ 2.47722793]
 [ 2.84315181]
 [ 2.52959275]
 [ 6.36988354]
 [ 2.44193673]
 [ 2.94895697]
 [ 2.4000504 ]]
DEBUG:root:training time = %d0.224619
INFO:root:frame =5033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =5034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00023889541626
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:random_action_porb = 0.96029
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =5037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =5038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049090385437
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.960258333333
DEBUG:root: dqn, choose action rondomly, need time 0.000195000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000171899795532
INFO:root:training error  = [[ 2.73893261]
 [ 2.49748468]
 [ 3.13620424]
 [ 2.30991435]
 [ 2.441293  ]
 [ 2.4522903 ]
 [ 2.48228598]
 [ 2.55024481]
 [ 2.33072257]
 [ 2.95079803]
 [ 2.58914256]
 [ 2.85097885]
 [ 2.34397316]
 [ 2.88928938]
 [ 2.51544571]
 [ 3.17429233]]
DEBUG:root:training time = %d0.217092
INFO:root:frame =5041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =5042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.960226666667
INFO:root:dqn select action Tensor("ArgMax_29:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011052
INFO:root:action choosen by dqn [4]
INFO:root:frame =5044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000179052352905
INFO:root:frame =5045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =5046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:random_action_porb = 0.960195
DEBUG:root: dqn, choose action rondomly, need time 0.000446999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.66899252]
 [ 7.07411766]
 [ 2.50085592]
 [ 2.41365623]
 [ 2.847682  ]
 [ 2.58164716]
 [ 2.52271724]
 [ 2.48572493]
 [ 2.79291511]
 [ 2.44138241]
 [ 2.66085958]
 [ 2.43297362]
 [ 0.40303153]
 [ 2.28212881]
 [ 2.80846643]
 [ 6.41557217]]
DEBUG:root:training time = %d0.202916
INFO:root:frame =5049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000381946563721
INFO:root:frame =5050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame = 5051 State into memory, numbers recorded 131 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000622034072876
INFO:root:random_action_porb = 0.960163333333
DEBUG:root: dqn, choose action rondomly, need time 0.000190000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5052current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:frame =5053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame =5054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame = 5055 State into memory, numbers recorded 132 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000552892684937
INFO:root:random_action_porb = 0.960131666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5056current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[ 2.4510181 ]
 [ 2.88016033]
 [ 2.64724946]
 [ 2.3852222 ]
 [ 3.04545403]
 [ 2.96040583]
 [ 2.49138165]
 [ 2.68223953]
 [ 2.5920651 ]
 [ 2.93239355]
 [ 3.23787594]
 [ 2.99608684]
 [ 2.74358749]
 [ 3.1046946 ]
 [ 2.51711583]
 [ 2.88016033]]
DEBUG:root:training time = %d0.230611
INFO:root:frame =5057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =5058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.9601
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335216522217
INFO:root: ememy has been killed for 7 times 
INFO:root:enemies_left [0]
INFO:root:frame =5061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =5062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000497102737427
INFO:root:frame = 5063 State into memory, numbers recorded 133 action = 3, reward = 1
DEBUG:root: save sample needs time = 0.000555038452148
INFO:root:random_action_porb = 0.960068333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5064current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.42917371]
 [ 6.49339437]
 [ 3.06057763]
 [ 2.63779283]
 [ 2.6419208 ]
 [ 2.31454897]
 [ 2.62160397]
 [ 2.76870418]
 [ 2.42616534]
 [ 2.51403642]
 [ 3.18175244]
 [ 2.60912991]
 [ 2.82758164]
 [ 2.38875246]
 [ 2.58193517]
 [ 2.73599768]]
DEBUG:root:training time = %d0.227954
INFO:root:frame =5065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =5066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000416994094849
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:random_action_porb = 0.960036666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =5069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =5070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
DEBUG:root: save sample needs time = 0.000240802764893
INFO:root:random_action_porb = 0.960005
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.58386016]
 [ 3.56796765]
 [ 2.6078608 ]
 [ 2.58910561]
 [ 3.08381915]
 [ 7.35672283]
 [ 2.68111515]
 [ 2.66295075]
 [ 2.87138176]
 [ 2.66295075]
 [ 2.66295075]
 [ 2.55444384]
 [ 2.64922976]
 [ 2.79484725]
 [ 2.37471151]
 [ 2.39462233]]
DEBUG:root:training time = %d0.225632
INFO:root:frame =5073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =5074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000326156616211
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:random_action_porb = 0.959973333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =5077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame =5078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:random_action_porb = 0.959941666667
DEBUG:root: dqn, choose action rondomly, need time 0.000322999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.39321184]
 [ 3.39605284]
 [ 2.8007493 ]
 [ 2.92756176]
 [ 3.77168775]
 [ 4.29717875]
 [ 2.95452118]
 [ 2.63818312]
 [ 3.06873155]
 [ 2.77472472]
 [ 2.6174736 ]
 [ 2.92312503]
 [ 2.32204747]
 [ 2.81498456]
 [ 2.48910022]
 [ 0.53806633]]
DEBUG:root:training time = %d0.219539
INFO:root:frame =5081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284194946289
INFO:root:frame =5082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
INFO:root:frame = 5083 State into memory, numbers recorded 134 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000562191009521
INFO:root:random_action_porb = 0.95991
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5084current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =5085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =5086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.959878333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.37018728]
 [ 3.0133121 ]
 [ 3.0133121 ]
 [ 3.34263372]
 [ 2.66431427]
 [ 8.21391869]
 [ 2.66940999]
 [ 8.21391869]
 [ 2.66431427]
 [ 3.0423193 ]
 [ 0.40578005]
 [ 2.63001704]
 [ 2.82090807]
 [ 2.20243502]
 [ 2.67514706]
 [ 2.65098119]]
DEBUG:root:training time = %d0.210593
INFO:root:frame =5089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =5090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046181678772
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.959846666667
DEBUG:root: dqn, choose action rondomly, need time 0.00027200000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000396013259888
INFO:root:frame =5093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =5094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000372171401978
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:random_action_porb = 0.959815
DEBUG:root: dqn, choose action rondomly, need time 0.000278999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 6.82266092]
 [ 2.49819613]
 [ 2.69704175]
 [ 2.54966021]
 [ 2.49497747]
 [ 3.25541711]
 [ 2.76062965]
 [ 2.88137746]
 [ 2.49497747]
 [ 2.64598966]
 [ 2.36084676]
 [ 2.63660336]
 [ 2.48173308]
 [ 2.61071992]
 [ 2.45725703]
 [ 0.33188832]]
DEBUG:root:training time = %d0.223053
INFO:root:frame =5097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290155410767
INFO:root:frame =5098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000314950942993
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.959783333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331163406372
INFO:root:frame =5101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =5102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.959751666667
DEBUG:root: dqn, choose action rondomly, need time 0.000202999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:training error  = [[ 2.97162032]
 [ 2.77372074]
 [ 2.44751358]
 [ 2.40310669]
 [ 2.58317971]
 [ 2.64916158]
 [ 2.5497942 ]
 [ 3.21091461]
 [ 2.62729573]
 [ 2.5497942 ]
 [ 2.75616312]
 [ 3.16845679]
 [ 3.14495206]
 [ 2.91476965]
 [ 2.78687477]
 [ 2.56311488]]
DEBUG:root:training time = %d0.210457
INFO:root:frame =5105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292778015137
INFO:root:frame =5106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.95972
DEBUG:root: dqn, choose action rondomly, need time 0.00027
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00036096572876
INFO:root:frame =5109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470876693726
INFO:root:frame =5110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:random_action_porb = 0.959688333333
DEBUG:root: dqn, choose action rondomly, need time 0.000275999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.15177488]
 [ 2.48834181]
 [ 7.08385134]
 [ 2.5688467 ]
 [ 2.56255317]
 [ 3.11496019]
 [ 2.97175169]
 [ 2.20028424]
 [ 2.77039289]
 [ 2.78703403]
 [ 2.76795506]
 [ 2.94309044]
 [ 3.22886944]
 [ 2.76795506]
 [ 3.01300097]
 [ 2.53459454]]
DEBUG:root:training time = %d0.220752
INFO:root:frame =5113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =5114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042200088501
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root:random_action_porb = 0.959656666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =5117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =5118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame = 5119 State into memory, numbers recorded 135 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000558853149414
INFO:root:random_action_porb = 0.959625
DEBUG:root: dqn, choose action rondomly, need time 0.000282000000013
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5120current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:training error  = [[ 3.26120114]
 [ 2.86480522]
 [ 2.46647453]
 [ 2.72537589]
 [ 2.91230845]
 [ 3.18793368]
 [ 2.35590243]
 [ 2.74114895]
 [ 2.41887426]
 [ 2.54676771]
 [ 2.71755362]
 [ 2.78511739]
 [ 2.72725916]
 [ 2.94237709]
 [ 2.72976708]
 [ 3.11213994]]
DEBUG:root:training time = %d0.211009
INFO:root:frame =5121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =5122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000301122665405
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.959593333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =5125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =5126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.959561666667
DEBUG:root: dqn, choose action rondomly, need time 0.000276999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:training error  = [[ 2.59025979]
 [ 2.61120081]
 [ 2.64618206]
 [ 2.84340286]
 [ 3.28358698]
 [ 3.02604628]
 [ 2.69372225]
 [ 2.81563115]
 [ 2.51984024]
 [ 2.75372553]
 [ 2.51228857]
 [ 2.60484934]
 [ 2.58357215]
 [ 2.65405631]
 [ 2.69493079]
 [ 3.08091927]]
DEBUG:root:training time = %d0.212779
INFO:root:frame =5129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290155410767
INFO:root:frame =5130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000306844711304
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.95953
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =5133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =5134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042986869812
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.959498333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.98306012]
 [ 2.64981341]
 [ 2.54332924]
 [ 2.88844633]
 [ 3.32240391]
 [ 2.56745291]
 [ 2.44118571]
 [ 3.27435136]
 [ 2.54332924]
 [ 7.51609898]
 [ 2.7084744 ]
 [ 2.44134665]
 [ 2.97841716]
 [ 2.88095665]
 [ 2.98306012]
 [ 2.9931097 ]]
DEBUG:root:training time = %d0.233081
INFO:root:frame =5137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =5138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.959466666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =5141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046181678772
INFO:root:frame =5142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.959435
DEBUG:root: dqn, choose action rondomly, need time 0.000382000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.66341138]
 [ 2.95072603]
 [ 3.10433173]
 [ 2.91656089]
 [ 2.49969172]
 [ 2.71156406]
 [ 3.42677951]
 [ 3.3778069 ]
 [ 2.88409781]
 [ 2.97206092]
 [ 2.62458205]
 [ 3.02141619]
 [ 0.44384107]
 [ 2.88832974]
 [ 2.84974241]
 [ 2.5239172 ]]
DEBUG:root:training time = %d0.204172
INFO:root:frame =5145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =5146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000281095504761
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:random_action_porb = 0.959403333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =5149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =5150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame = 5151 State into memory, numbers recorded 136 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:random_action_porb = 0.959371666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5152current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.84727001]
 [ 2.74018264]
 [ 2.42077923]
 [ 7.60792875]
 [ 3.1090517 ]
 [ 3.00114679]
 [ 2.55760312]
 [ 2.64091635]
 [ 3.32482409]
 [ 2.86194563]
 [ 2.88912082]
 [ 2.66671824]
 [ 2.67151093]
 [ 2.88912082]
 [ 2.63618851]
 [ 2.74018264]]
DEBUG:root:training time = %d0.198533
INFO:root: ememy has been killed for 8 times 
INFO:root:enemies_left [0]
INFO:root:frame =5153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:frame =5154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame = 5155 State into memory, numbers recorded 137 action = 3, reward = 1
DEBUG:root: save sample needs time = 0.000545024871826
INFO:root:random_action_porb = 0.95934
DEBUG:root: dqn, choose action rondomly, need time 0.000249000000011
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5156current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =5157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000414848327637
INFO:root:frame =5158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000616073608398
INFO:root: ememy has been killed for 9 times 
INFO:root:enemies_left [0]
INFO:root:frame = 5159 State into memory, numbers recorded 138 action = 4, reward = 1
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:random_action_porb = 0.959308333333
DEBUG:root: dqn, choose action rondomly, need time 0.000417999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5160current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.33640862]
 [ 2.64223075]
 [ 2.51138783]
 [ 2.67926669]
 [ 2.52066374]
 [ 2.54479551]
 [ 7.54676199]
 [ 6.99486732]
 [ 2.64223075]
 [ 2.80906105]
 [ 3.33661079]
 [ 2.58951688]
 [ 2.76500487]
 [ 2.83432746]
 [ 2.88742852]
 [ 2.73649001]]
DEBUG:root:training time = %d0.222842
INFO:root:frame =5161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root: ememy has been killed for 10 times 
INFO:root:enemies_left [0]
INFO:root:frame =5162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame = 5163 State into memory, numbers recorded 139 action = 2, reward = 1
DEBUG:root: save sample needs time = 0.000562191009521
INFO:root:random_action_porb = 0.959276666667
DEBUG:root: dqn, choose action rondomly, need time 0.000311999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5164current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =5165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =5166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00062108039856
INFO:root:frame = 5167 State into memory, numbers recorded 140 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000533819198608
INFO:root:random_action_porb = 0.959245
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5168current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.65321755]
 [ 2.80307984]
 [ 2.79474521]
 [ 2.68428922]
 [ 2.48905206]
 [ 3.23575521]
 [ 2.78237438]
 [ 2.64609528]
 [ 2.92333364]
 [ 3.0186584 ]
 [ 8.27948284]
 [ 6.40354824]
 [ 3.38021898]
 [ 7.15958071]
 [ 3.23575521]
 [ 2.57246757]]
DEBUG:root:training time = %d0.221696
INFO:root:frame =5169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =5170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame = 5171 State into memory, numbers recorded 141 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000574111938477
INFO:root:random_action_porb = 0.959213333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5172current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =5173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =5174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227928161621
DEBUG:root: save sample needs time = 0.00017786026001
INFO:root:random_action_porb = 0.959181666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:training error  = [[ 2.92748332]
 [ 3.01447773]
 [ 3.102     ]
 [ 3.02977014]
 [ 2.7993896 ]
 [ 3.3588829 ]
 [ 3.21765137]
 [ 3.76289916]
 [ 3.3588829 ]
 [ 3.17493105]
 [ 3.01537848]
 [ 2.68270826]
 [ 3.28104353]
 [ 3.76289916]
 [ 3.64541125]
 [ 3.63500357]]
DEBUG:root:training time = %d0.186054
INFO:root:frame =5177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =5178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame = 5179 State into memory, numbers recorded 142 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000372171401978
INFO:root:random_action_porb = 0.95915
DEBUG:root: dqn, choose action rondomly, need time 0.000270999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5180current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =5181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000416040420532
INFO:root:frame =5182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000499963760376
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root:random_action_porb = 0.959118333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.18272543]
 [ 2.897686  ]
 [ 2.77765489]
 [ 2.57850385]
 [ 3.3904314 ]
 [ 2.89010644]
 [ 2.89827037]
 [ 3.32053375]
 [ 7.565763  ]
 [ 2.75578308]
 [ 3.34644985]
 [ 2.65991378]
 [ 2.99756598]
 [ 3.61951399]
 [ 2.46401882]
 [ 2.61980081]]
DEBUG:root:training time = %d0.213686
INFO:root:frame =5185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =5186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000370979309082
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.959086666667
DEBUG:root: dqn, choose action rondomly, need time 0.000278000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336170196533
INFO:root:frame =5189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =5190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000175952911377
INFO:root:random_action_porb = 0.959055
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:training error  = [[ 2.95623946]
 [ 3.38661146]
 [ 2.81331444]
 [ 2.34034777]
 [ 3.0830555 ]
 [ 2.46248603]
 [ 2.99140716]
 [ 2.79748154]
 [ 2.90376711]
 [ 3.03800249]
 [ 3.14091468]
 [ 2.57764006]
 [ 3.21406674]
 [ 2.69957948]
 [ 2.99449563]
 [ 2.46248603]]
DEBUG:root:training time = %d0.20709
INFO:root:frame =5193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000331163406372
INFO:root:frame =5194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.959023333333
DEBUG:root: dqn, choose action rondomly, need time 0.000263000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =5197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =5198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000545978546143
DEBUG:root: save sample needs time = 0.000188827514648
INFO:root:random_action_porb = 0.958991666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000370979309082
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.81640577]
 [ 6.49622345]
 [ 6.87237215]
 [ 2.7091651 ]
 [ 2.98573565]
 [ 0.55161548]
 [ 2.87957764]
 [ 2.96795845]
 [ 2.88720179]
 [ 2.93189073]
 [ 3.12189198]
 [ 2.93524241]
 [ 3.18883967]
 [ 2.49962544]
 [ 3.00151014]
 [ 2.9086771 ]]
DEBUG:root:training time = %d0.194447
INFO:root:frame =5201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000403165817261
INFO:root: ememy has been killed for 11 times 
INFO:root:enemies_left [0]
INFO:root:frame =5202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:frame = 5203 State into memory, numbers recorded 143 action = 4, reward = 1
DEBUG:root: save sample needs time = 0.000610113143921
INFO:root:random_action_porb = 0.95896
DEBUG:root: dqn, choose action rondomly, need time 0.000364000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5204current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.00404810905457
INFO:root:frame =5205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00044584274292
INFO:root:frame =5206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047492980957
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.958928333333
DEBUG:root: dqn, choose action rondomly, need time 0.000444999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.07302332]
 [ 3.00752068]
 [ 2.89958239]
 [ 2.49507403]
 [ 2.7824316 ]
 [ 2.76026201]
 [ 3.00831461]
 [ 2.7824316 ]
 [ 2.74994135]
 [ 2.78470993]
 [ 3.07302332]
 [ 3.3363111 ]
 [ 2.50727868]
 [ 7.36431932]
 [ 2.72052908]
 [ 0.43013102]]
DEBUG:root:training time = %d0.21986
INFO:root:frame =5209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00038480758667
INFO:root:frame =5210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00038480758667
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:random_action_porb = 0.958896666667
DEBUG:root: dqn, choose action rondomly, need time 0.00022899999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =5213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =5214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000317096710205
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:random_action_porb = 0.958865
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.82014561]
 [ 3.70889044]
 [ 2.93189716]
 [ 3.26891422]
 [ 2.70772743]
 [ 2.98864985]
 [ 7.14419651]
 [ 3.17866397]
 [ 2.74499035]
 [ 2.5789938 ]
 [ 2.65626311]
 [ 3.65026379]
 [ 2.91199589]
 [ 2.88707209]
 [ 2.7061646 ]
 [ 2.63407063]]
DEBUG:root:training time = %d0.210227
INFO:root:frame =5217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: ememy has been killed for 12 times 
INFO:root:enemies_left [0]
INFO:root:frame =5218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame = 5219 State into memory, numbers recorded 144 action = 4, reward = 1
DEBUG:root: save sample needs time = 0.000495910644531
INFO:root:random_action_porb = 0.958833333333
DEBUG:root: dqn, choose action rondomly, need time 0.000374000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5220current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =5221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000322818756104
INFO:root:frame =5222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049901008606
INFO:root:frame = 5223 State into memory, numbers recorded 145 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000584125518799
INFO:root:random_action_porb = 0.958801666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5224current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 8.26786232]
 [ 3.04502797]
 [ 3.34097409]
 [ 3.19108129]
 [ 2.83338976]
 [ 3.24871659]
 [ 3.46563601]
 [ 2.77435613]
 [ 3.03268576]
 [ 3.95374775]
 [ 2.49056292]
 [ 3.32889462]
 [ 3.74467325]
 [ 2.72633338]
 [ 3.6869204 ]
 [ 3.42860866]]
DEBUG:root:training time = %d0.218883
INFO:root:frame =5225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000372886657715
INFO:root:frame =5226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000408887863159
DEBUG:root: save sample needs time = 0.000108003616333
INFO:root:random_action_porb = 0.95877
DEBUG:root: dqn, choose action rondomly, need time 0.000154999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:frame =5229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000536918640137
INFO:root:frame =5230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.958738333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.67153573]
 [ 2.68095899]
 [ 2.66811395]
 [ 2.54600668]
 [ 3.25915551]
 [ 2.70447683]
 [ 3.18759322]
 [ 3.07923222]
 [ 2.66811395]
 [ 3.47263455]
 [ 2.6617682 ]
 [ 2.98290205]
 [ 3.48574805]
 [ 8.22267818]
 [ 2.97231078]
 [ 2.45476389]]
DEBUG:root:training time = %d0.212528
INFO:root:frame =5233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =5234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.958706666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =5237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000568866729736
INFO:root:frame =5238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438213348389
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:random_action_porb = 0.958675
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.23467803]
 [ 2.49308586]
 [ 0.61497366]
 [ 3.27849436]
 [ 2.87518406]
 [ 3.56762171]
 [ 7.84368134]
 [ 3.27849436]
 [ 7.8037858 ]
 [ 3.01639199]
 [ 3.63662553]
 [ 3.5537796 ]
 [ 3.44209909]
 [ 2.6529007 ]
 [ 2.68361425]
 [ 2.81872368]]
DEBUG:root:training time = %d0.210566
INFO:root:frame =5241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:frame =5242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324010848999
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.958643333333
DEBUG:root: dqn, choose action rondomly, need time 0.000208000000015
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:frame =5245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000530958175659
INFO:root:frame =5246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.958611666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.95592451]
 [ 2.6095984 ]
 [ 7.49637699]
 [ 2.67633891]
 [ 2.79764104]
 [ 3.56201839]
 [ 3.63207316]
 [ 2.81750059]
 [ 2.84410405]
 [ 7.49637699]
 [ 3.08301544]
 [ 7.72279501]
 [ 3.04915643]
 [ 3.04927635]
 [ 3.63207316]
 [ 7.19784737]]
DEBUG:root:training time = %d0.219832
INFO:root:frame =5249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =5250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235795974731
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:random_action_porb = 0.95858
DEBUG:root: dqn, choose action rondomly, need time 0.000279000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =5253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =5254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.958548333333
DEBUG:root: dqn, choose action rondomly, need time 0.000402000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.64910507]
 [ 3.47137642]
 [ 2.63896394]
 [ 2.92928505]
 [ 3.56974053]
 [ 2.8295064 ]
 [ 2.81266189]
 [ 7.49163628]
 [ 2.75332022]
 [ 2.58469439]
 [ 2.77502346]
 [ 2.78784919]
 [ 3.37524843]
 [ 3.12040925]
 [ 2.79085636]
 [ 3.30752683]]
DEBUG:root:training time = %d0.21522
INFO:root:frame =5257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame =5258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319957733154
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.958516666667
INFO:root:dqn select action Tensor("ArgMax_30:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013414
INFO:root:action choosen by dqn [4]
INFO:root:frame =5260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root:frame =5261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285148620605
INFO:root:frame =5262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
INFO:root:frame = 5263 State into memory, numbers recorded 146 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00134897232056
INFO:root:random_action_porb = 0.958485
DEBUG:root: dqn, choose action rondomly, need time 0.000159999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5264current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.39385295]
 [ 8.2387991 ]
 [ 2.76625443]
 [ 3.10620713]
 [ 3.53819156]
 [ 3.10620713]
 [ 2.84198785]
 [ 2.98408818]
 [ 3.18246007]
 [ 2.32457685]
 [ 3.61592245]
 [ 3.09384227]
 [ 3.29357624]
 [ 3.00936007]
 [ 3.63790607]
 [ 3.0808053 ]]
DEBUG:root:training time = %d0.200532
INFO:root:frame =5265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =5266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277996063232
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:random_action_porb = 0.958453333333
DEBUG:root: dqn, choose action rondomly, need time 0.000196000000017
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root:frame =5269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000486135482788
INFO:root:frame =5270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000618934631348
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.958421666667
DEBUG:root: dqn, choose action rondomly, need time 0.000248999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.14215183]
 [ 3.53162193]
 [ 3.84876251]
 [ 2.77212644]
 [ 3.43724561]
 [ 3.07698345]
 [ 2.73226357]
 [ 0.5948174 ]
 [ 2.98229599]
 [ 7.0083828 ]
 [ 3.06937981]
 [ 3.00382376]
 [ 3.07698345]
 [ 3.43724561]
 [ 2.63756371]
 [ 2.99272013]]
DEBUG:root:training time = %d0.193312
INFO:root:frame =5273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =5274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000347137451172
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.95839
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =5277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =5278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000744104385376
DEBUG:root: save sample needs time = 0.000145196914673
INFO:root:random_action_porb = 0.958358333333
DEBUG:root: dqn, choose action rondomly, need time 0.000317000000024
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.0878129 ]
 [ 3.48882556]
 [ 3.33304405]
 [ 2.52957463]
 [ 2.65531182]
 [ 3.00533795]
 [ 2.76343822]
 [ 2.7351017 ]
 [ 3.25629807]
 [ 3.1116488 ]
 [ 3.23434186]
 [ 3.25629807]
 [ 2.76205587]
 [ 8.40786266]
 [ 3.88773894]
 [ 2.85842323]]
DEBUG:root:training time = %d0.221425
INFO:root:frame =5281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375032424927
INFO:root:frame =5282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000543117523193
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:random_action_porb = 0.958326666667
DEBUG:root: dqn, choose action rondomly, need time 0.000233000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:frame =5285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =5286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame = 5287 State into memory, numbers recorded 147 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.00039005279541
INFO:root:random_action_porb = 0.958295
DEBUG:root: dqn, choose action rondomly, need time 0.000273000000021
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5288current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 7.89616108]
 [ 3.56232071]
 [ 2.87380648]
 [ 2.99080014]
 [ 2.51993704]
 [ 3.20324969]
 [ 2.77452135]
 [ 3.4692018 ]
 [ 3.1531024 ]
 [ 7.7444787 ]
 [ 3.01830721]
 [ 2.74420667]
 [ 2.93796849]
 [ 3.00837421]
 [ 3.26096678]
 [ 3.4458015 ]]
DEBUG:root:training time = %d0.214915
INFO:root:frame =5289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375032424927
INFO:root:frame =5290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00050687789917
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.958263333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =5293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000481128692627
INFO:root:frame =5294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000258922576904
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.958231666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999981
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:training error  = [[ 3.4598577 ]
 [ 3.15703225]
 [ 3.70519614]
 [ 3.19450307]
 [ 2.45972729]
 [ 2.65056491]
 [ 3.8622601 ]
 [ 3.04823065]
 [ 2.65056491]
 [ 3.15138197]
 [ 3.95707083]
 [ 2.7915318 ]
 [ 3.11784935]
 [ 2.74006915]
 [ 3.15703225]
 [ 3.18182039]]
DEBUG:root:training time = %d0.208307
INFO:root:frame =5297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =5298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000519990921021
DEBUG:root: save sample needs time = 0.000151872634888
INFO:root:random_action_porb = 0.9582
DEBUG:root: dqn, choose action rondomly, need time 0.000344000000013
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =5301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =5302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000548124313354
DEBUG:root: save sample needs time = 0.000192880630493
INFO:root:random_action_porb = 0.958168333333
DEBUG:root: dqn, choose action rondomly, need time 0.000273000000021
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:training error  = [[ 3.18621755]
 [ 3.00093532]
 [ 3.32560325]
 [ 2.64448214]
 [ 2.81176615]
 [ 3.06964707]
 [ 3.00093532]
 [ 3.36010647]
 [ 2.81176615]
 [ 3.14715099]
 [ 3.1467855 ]
 [ 3.19736052]
 [ 3.39260912]
 [ 2.80684948]
 [ 2.97961545]
 [ 2.81176615]]
DEBUG:root:training time = %d0.202663
INFO:root:frame =5305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000380992889404
INFO:root:frame =5306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:random_action_porb = 0.958136666667
DEBUG:root: dqn, choose action rondomly, need time 0.000269000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =5309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000348806381226
INFO:root:frame =5310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.958105
DEBUG:root: dqn, choose action rondomly, need time 0.000527000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.94083953]
 [ 2.80115151]
 [ 3.05955672]
 [ 8.56595612]
 [ 2.95258069]
 [ 3.12842655]
 [ 3.03249311]
 [ 3.00041986]
 [ 3.25839114]
 [ 3.2182672 ]
 [ 3.08702874]
 [ 2.90353322]
 [ 3.00819564]
 [ 2.9476862 ]
 [ 3.06664038]
 [ 3.08702874]]
DEBUG:root:training time = %d0.221234
INFO:root:frame =5313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000325202941895
INFO:root:frame =5314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.958073333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000022
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =5317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =5318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.958041666667
DEBUG:root: dqn, choose action rondomly, need time 0.000272999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.1596086 ]
 [ 2.99045706]
 [ 3.8411479 ]
 [ 7.39297056]
 [ 3.23434854]
 [ 3.42322135]
 [ 3.39171696]
 [ 2.88851118]
 [ 3.1596086 ]
 [ 3.03154325]
 [ 3.02556181]
 [ 2.95845008]
 [ 7.17424583]
 [ 2.78935885]
 [ 3.29649138]
 [ 7.54434156]]
DEBUG:root:training time = %d0.21465
INFO:root:frame =5321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:frame =5322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275850296021
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:random_action_porb = 0.95801
DEBUG:root: dqn, choose action rondomly, need time 0.000205999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000188827514648
INFO:root:frame =5325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =5326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame = 5327 State into memory, numbers recorded 148 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000366926193237
INFO:root:random_action_porb = 0.957978333333
DEBUG:root: dqn, choose action rondomly, need time 0.000237999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5328current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:training error  = [[ 2.87586331]
 [ 3.03293824]
 [ 3.0917089 ]
 [ 3.5677948 ]
 [ 3.17056203]
 [ 2.62861896]
 [ 3.1078949 ]
 [ 3.10776043]
 [ 4.08778715]
 [ 2.77584958]
 [ 2.74357486]
 [ 2.86926198]
 [ 2.86924911]
 [ 3.60909271]
 [ 2.88820004]
 [ 2.76696515]]
DEBUG:root:training time = %d0.180482
INFO:root:frame =5329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =5330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000295877456665
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.957946666667
DEBUG:root: dqn, choose action rondomly, need time 0.000223000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000152111053467
INFO:root:frame =5333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =5334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000295162200928
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:random_action_porb = 0.957915
DEBUG:root: dqn, choose action rondomly, need time 0.000418999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.19152427]
 [ 2.85761046]
 [ 3.19343281]
 [ 3.51985335]
 [ 2.93364811]
 [ 2.91659999]
 [ 2.75390267]
 [ 7.03525114]
 [ 2.92424679]
 [ 3.08613753]
 [ 3.23453379]
 [ 3.12883139]
 [ 2.85937762]
 [ 2.86997294]
 [ 3.41946054]
 [ 2.88622952]]
DEBUG:root:training time = %d0.186338
INFO:root:frame =5337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224828720093
INFO:root:frame =5338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248908996582
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:random_action_porb = 0.957883333333
DEBUG:root: dqn, choose action rondomly, need time 0.000271999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =5341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000348806381226
INFO:root:frame =5342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000378847122192
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:random_action_porb = 0.957851666667
DEBUG:root: dqn, choose action rondomly, need time 0.000229000000019
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000168085098267
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.91325235]
 [ 2.71228027]
 [ 3.45162463]
 [ 3.97644472]
 [ 3.21018338]
 [ 2.83826566]
 [ 2.98001695]
 [ 2.85258937]
 [ 2.98482609]
 [ 3.33987951]
 [ 0.56759268]
 [ 3.16416001]
 [ 2.8706708 ]
 [ 3.12980986]
 [ 3.07121134]
 [ 3.06594563]]
DEBUG:root:training time = %d0.183667
INFO:root:frame =5345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =5346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000300168991089
DEBUG:root: save sample needs time = 0.000106811523438
INFO:root:random_action_porb = 0.95782
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000166893005371
INFO:root:frame =5349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =5350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.957788333333
DEBUG:root: dqn, choose action rondomly, need time 0.000170999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.06891203]
 [ 2.93862224]
 [ 3.27353692]
 [ 3.0829215 ]
 [ 3.67741895]
 [ 3.1289866 ]
 [ 2.92741156]
 [ 3.27353692]
 [ 3.05997705]
 [ 2.88012791]
 [ 3.1289866 ]
 [ 3.12796116]
 [ 0.51805574]
 [ 3.43820763]
 [ 2.8499999 ]
 [ 3.32506061]]
DEBUG:root:training time = %d0.207884
INFO:root:frame =5353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =5354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 0.000176906585693
INFO:root:random_action_porb = 0.957756666667
DEBUG:root: dqn, choose action rondomly, need time 0.00026299999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:frame =5357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000393867492676
INFO:root:frame =5358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000555038452148
DEBUG:root: save sample needs time = 0.000107049942017
INFO:root:random_action_porb = 0.957725
DEBUG:root: dqn, choose action rondomly, need time 0.00055900000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000541925430298
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.99479938]
 [ 3.29196334]
 [ 3.10009217]
 [ 7.51013899]
 [ 3.22692299]
 [ 3.31734395]
 [ 2.71471834]
 [ 3.321069  ]
 [ 3.89656663]
 [ 2.92108393]
 [ 2.95976901]
 [ 3.22692299]
 [ 3.24994755]
 [ 2.65343499]
 [ 2.64419675]
 [ 3.14950657]]
DEBUG:root:training time = %d0.207146
INFO:root:frame =5361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =5362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000180959701538
INFO:root:random_action_porb = 0.957693333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =5365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =5366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000172138214111
INFO:root:random_action_porb = 0.957661666667
DEBUG:root: dqn, choose action rondomly, need time 0.000348000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.82618332]
 [ 3.59616113]
 [ 2.90571761]
 [ 3.82680655]
 [ 3.68284893]
 [ 3.03222728]
 [ 3.69099402]
 [ 8.16568851]
 [ 3.52419901]
 [ 2.98718596]
 [ 3.19787884]
 [ 3.1779635 ]
 [ 3.81103253]
 [ 3.12260652]
 [ 3.11142659]
 [ 2.97989845]]
DEBUG:root:training time = %d0.222816
INFO:root:frame =5369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000327825546265
INFO:root:frame =5370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045919418335
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.95763
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =5373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =5374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481128692627
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.957598333333
INFO:root:dqn select action Tensor("ArgMax_31:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.008781
INFO:root:action choosen by dqn [4]
INFO:root:frame =5376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.70651793]
 [ 3.06303406]
 [ 3.37927246]
 [ 7.00008392]
 [ 8.47622681]
 [ 3.41703439]
 [ 2.83600378]
 [ 3.6553309 ]
 [ 3.79609346]
 [ 3.44449162]
 [ 2.93901467]
 [ 2.95802355]
 [ 7.77016878]
 [ 0.72404164]
 [ 3.11834764]
 [ 3.49709582]]
DEBUG:root:training time = %d0.20611
INFO:root:frame =5377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =5378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame = 5379 State into memory, numbers recorded 149 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.000726938247681
INFO:root:random_action_porb = 0.957566666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5380current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =5381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =5382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000523090362549
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.957535
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.37927246]
 [ 3.25587821]
 [ 3.28819919]
 [ 2.97740984]
 [ 4.30801916]
 [ 3.27230859]
 [ 3.47555685]
 [ 3.45042706]
 [ 3.2765882 ]
 [ 3.52462864]
 [ 8.74595165]
 [ 3.33830404]
 [ 3.39289021]
 [ 3.13430619]
 [ 4.5881238 ]
 [ 3.34554267]]
DEBUG:root:training time = %d0.22133
INFO:root:frame =5385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =5386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000187158584595
INFO:root:random_action_porb = 0.957503333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =5389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =5390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.957471666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:training error  = [[ 3.10425782]
 [ 3.38428116]
 [ 2.95404911]
 [ 3.28880787]
 [ 3.76895452]
 [ 3.10959673]
 [ 3.18269825]
 [ 3.14504004]
 [ 3.27629828]
 [ 3.09831929]
 [ 2.97344851]
 [ 2.67788672]
 [ 3.45168829]
 [ 3.11301494]
 [ 3.75582814]
 [ 3.14504004]]
DEBUG:root:training time = %d0.233309
INFO:root:frame =5393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =5394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000382900238037
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:random_action_porb = 0.95744
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =5397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =5398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.957408333333
DEBUG:root: dqn, choose action rondomly, need time 0.000357000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000486135482788
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.43895745]
 [ 3.36691356]
 [ 3.11107683]
 [ 3.86230516]
 [ 3.75371408]
 [ 3.74600196]
 [ 3.76420164]
 [ 3.42032099]
 [ 3.85376334]
 [ 2.97995114]
 [ 4.10424709]
 [ 3.25044274]
 [ 4.04656744]
 [ 3.69889855]
 [ 3.08495808]
 [ 0.89490718]]
DEBUG:root:training time = %d0.208888
INFO:root:frame =5401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000388860702515
INFO:root:frame =5402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444173812866
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:random_action_porb = 0.957376666667
DEBUG:root: dqn, choose action rondomly, need time 0.000272000000024
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =5405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =5406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456809997559
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.957345
DEBUG:root: dqn, choose action rondomly, need time 0.000354999999985
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.26142836]
 [ 3.24888849]
 [ 2.96866179]
 [ 7.79903364]
 [ 2.91484141]
 [ 4.00786209]
 [ 3.26144218]
 [ 2.82100415]
 [ 8.9087944 ]
 [ 2.96866179]
 [ 3.26162124]
 [ 2.82100415]
 [ 3.48277164]
 [ 3.75510359]
 [ 3.35028911]
 [ 3.6279304 ]]
DEBUG:root:training time = %d0.224705
INFO:root:frame =5409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =5410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000410795211792
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.957313333333
DEBUG:root: dqn, choose action rondomly, need time 0.00025500000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000290155410767
INFO:root:frame =5413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245809555054
INFO:root:frame =5414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:random_action_porb = 0.957281666667
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.14279437]
 [ 0.64369673]
 [ 3.12121797]
 [ 8.63529491]
 [ 8.60501003]
 [ 2.74038482]
 [ 3.48265791]
 [ 4.11009169]
 [ 4.58699656]
 [ 7.59148121]
 [ 3.6904223 ]
 [ 4.06192923]
 [ 3.17028356]
 [ 0.64369673]
 [ 3.6904223 ]
 [ 3.10635519]]
DEBUG:root:training time = %d0.207906
INFO:root:frame =5417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =5418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000336885452271
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.95725
DEBUG:root: dqn, choose action rondomly, need time 0.000326000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =5421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471115112305
INFO:root:frame =5422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424861907959
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.957218333333
DEBUG:root: dqn, choose action rondomly, need time 0.000246999999973
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000416040420532
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.15821862]
 [ 0.58861995]
 [ 3.90619612]
 [ 4.25064945]
 [ 8.29811954]
 [ 7.72962332]
 [ 3.15123987]
 [ 3.13232088]
 [ 3.29926229]
 [ 3.4841814 ]
 [ 0.58861995]
 [ 3.61383367]
 [ 7.87695312]
 [ 3.43007803]
 [ 2.76049018]
 [ 3.24307418]]
DEBUG:root:training time = %d0.185634
INFO:root:frame =5425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:frame =5426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000360012054443
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:random_action_porb = 0.957186666667
DEBUG:root: dqn, choose action rondomly, need time 0.000207999999986
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:frame =5429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =5430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446796417236
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.957155
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.18577504]
 [ 3.00307012]
 [ 3.37000823]
 [ 3.34488702]
 [ 3.11774158]
 [ 3.45140481]
 [ 3.85004973]
 [ 3.21544838]
 [ 3.00345349]
 [ 3.85004973]
 [ 3.53438973]
 [ 3.0405364 ]
 [ 3.34488702]
 [ 3.27595305]
 [ 3.32364178]
 [ 8.62012291]]
DEBUG:root:training time = %d0.207994
INFO:root:frame =5433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root:frame =5434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:random_action_porb = 0.957123333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =5437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =5438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433206558228
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:random_action_porb = 0.957091666667
DEBUG:root: dqn, choose action rondomly, need time 0.000500999999986
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.17521667]
 [ 3.33724475]
 [ 3.7814064 ]
 [ 3.84488702]
 [ 3.47641015]
 [ 3.15777111]
 [ 3.83319712]
 [ 3.22880101]
 [ 3.38982725]
 [ 3.59308004]
 [ 8.03927517]
 [ 3.22880101]
 [ 3.53668499]
 [ 3.59308004]
 [ 2.90535355]
 [ 2.71849084]]
DEBUG:root:training time = %d0.214798
INFO:root:frame =5441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243186950684
INFO:root:frame =5442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259160995483
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.95706
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000015
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =5445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0022439956665
INFO:root:frame =5446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:random_action_porb = 0.957028333333
DEBUG:root: dqn, choose action rondomly, need time 0.000189000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.27201867]
 [ 3.1847403 ]
 [ 3.03839493]
 [ 3.14448524]
 [ 2.94972348]
 [ 4.25258446]
 [ 7.55876589]
 [ 3.51626873]
 [ 3.21316409]
 [ 3.08572197]
 [ 3.21970439]
 [ 3.21970439]
 [ 3.17164207]
 [ 3.07521033]
 [ 3.06229973]
 [ 3.10445952]]
DEBUG:root:training time = %d0.205269
INFO:root:frame =5449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280857086182
INFO:root:frame =5450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.956996666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000022
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =5453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =5454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.956965
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.88398647]
 [ 3.44365621]
 [ 2.78056741]
 [ 3.25770926]
 [ 7.95784235]
 [ 3.07968068]
 [ 3.20787358]
 [ 3.83395886]
 [ 3.21234345]
 [ 3.88664842]
 [ 2.87936401]
 [ 3.88398647]
 [ 3.55393767]
 [ 3.75309324]
 [ 3.55019927]
 [ 3.84135723]]
DEBUG:root:training time = %d0.208319
INFO:root:frame =5457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =5458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000325918197632
DEBUG:root: save sample needs time = 0.000123977661133
INFO:root:random_action_porb = 0.956933333333
DEBUG:root: dqn, choose action rondomly, need time 0.000177000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000152826309204
INFO:root:frame =5461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame =5462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000591039657593
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.956901666667
DEBUG:root: dqn, choose action rondomly, need time 0.00036399999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:training error  = [[ 3.61225295]
 [ 3.34522176]
 [ 3.10915279]
 [ 3.67914557]
 [ 3.09205103]
 [ 3.55613875]
 [ 3.45442462]
 [ 3.46763897]
 [ 4.17752552]
 [ 3.33263302]
 [ 3.09017301]
 [ 3.41721773]
 [ 3.08783984]
 [ 3.30211782]
 [ 3.27040434]
 [ 3.50433302]]
DEBUG:root:training time = %d0.206499
INFO:root:frame =5465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =5466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.95687
DEBUG:root: dqn, choose action rondomly, need time 0.000224000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000594854354858
INFO:root:frame =5469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =5470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000365972518921
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.956838333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999977
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.09736586]
 [ 3.01684928]
 [ 3.19283295]
 [ 3.50700426]
 [ 8.63814259]
 [ 3.55881524]
 [ 3.38724327]
 [ 3.70557809]
 [ 3.05196142]
 [ 3.64955688]
 [ 3.64955688]
 [ 2.86241674]
 [ 3.19632363]
 [ 3.70305228]
 [ 3.35527635]
 [ 3.29494023]]
DEBUG:root:training time = %d0.22004
INFO:root:frame =5473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:frame =5474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000134944915771
INFO:root:random_action_porb = 0.956806666667
DEBUG:root: dqn, choose action rondomly, need time 0.000280000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =5477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438213348389
INFO:root:frame =5478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000571966171265
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.956775
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 8.11440468]
 [ 3.44386864]
 [ 3.49218941]
 [ 3.70123219]
 [ 3.5041616 ]
 [ 3.22382641]
 [ 3.13423872]
 [ 3.12877083]
 [ 3.54988289]
 [ 3.41929126]
 [ 3.36246324]
 [ 7.90196133]
 [ 3.2809124 ]
 [ 3.96356916]
 [ 3.3840003 ]
 [ 4.12831688]]
DEBUG:root:training time = %d0.198642
INFO:root:frame =5481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =5482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441789627075
DEBUG:root: save sample needs time = 0.000162839889526
INFO:root:random_action_porb = 0.956743333333
DEBUG:root: dqn, choose action rondomly, need time 0.00018399999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000184059143066
INFO:root:frame =5485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =5486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000206232070923
INFO:root:random_action_porb = 0.956711666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282000000027
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.4922893 ]
 [ 4.18532562]
 [ 3.07838202]
 [ 3.18853998]
 [ 7.62352991]
 [ 3.0079906 ]
 [ 3.58566499]
 [ 3.85064864]
 [ 3.23821211]
 [ 2.64423394]
 [ 3.44382596]
 [ 3.12094855]
 [ 3.32159758]
 [ 3.11308217]
 [ 3.45995712]
 [ 3.80809879]]
DEBUG:root:training time = %d0.196068
INFO:root:frame =5489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =5490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:random_action_porb = 0.95668
DEBUG:root: dqn, choose action rondomly, need time 0.00029600000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root:frame =5493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame =5494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446796417236
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.956648333333
DEBUG:root: dqn, choose action rondomly, need time 0.000334000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000387191772461
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.91532421]
 [ 3.63296008]
 [ 3.68980694]
 [ 3.56047058]
 [ 4.1354661 ]
 [ 3.50316191]
 [ 7.97567272]
 [ 3.08884549]
 [ 4.41156387]
 [ 2.94524384]
 [ 3.51777101]
 [ 3.95534086]
 [ 3.80522609]
 [ 3.88893485]
 [ 3.48668838]
 [ 3.83702207]]
DEBUG:root:training time = %d0.223603
INFO:root:frame =5497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:player has been killed for 3 times 
INFO:root:frame =5498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255823135376
INFO:root:frame = 5499 State into memory, numbers recorded 150 action = 1, reward = -1
DEBUG:root: save sample needs time = 0.000632047653198
INFO:root:random_action_porb = 0.956616666667
DEBUG:root: dqn, choose action rondomly, need time 0.000174000000015
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5500current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =5501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000394105911255
INFO:root:frame =5502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.956585
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4.09646082]
 [ 4.21434498]
 [ 3.40577507]
 [ 3.35133648]
 [ 4.13782501]
 [ 3.40577507]
 [ 3.81147933]
 [ 3.64728332]
 [ 4.38124943]
 [ 4.09646082]
 [ 9.0247364 ]
 [ 4.16719294]
 [ 4.23983431]
 [ 3.91072106]
 [ 3.93436885]
 [ 3.74597263]]
DEBUG:root:training time = %d0.203366
INFO:root:frame =5505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =5506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000219106674194
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:random_action_porb = 0.956553333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =5509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000545024871826
INFO:root:frame =5510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000384092330933
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:random_action_porb = 0.956521666667
DEBUG:root: dqn, choose action rondomly, need time 0.000218999999987
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000141859054565
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.16641331]
 [ 3.50646138]
 [ 3.44245291]
 [ 3.29469085]
 [ 3.4012289 ]
 [ 3.63691664]
 [ 3.6548202 ]
 [ 3.16037488]
 [ 3.26381254]
 [ 3.58838153]
 [ 3.6788528 ]
 [ 3.58113003]
 [ 3.36479998]
 [ 3.80391645]
 [ 4.19097805]
 [ 7.96070528]]
DEBUG:root:training time = %d0.183651
INFO:root:frame =5513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =5514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00029993057251
DEBUG:root: save sample needs time = 0.000134229660034
INFO:root:random_action_porb = 0.95649
DEBUG:root: dqn, choose action rondomly, need time 0.000259999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =5517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00036096572876
INFO:root:frame =5518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000323057174683
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:random_action_porb = 0.956458333333
DEBUG:root: dqn, choose action rondomly, need time 0.000273000000021
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.38807178]
 [ 7.89244223]
 [ 3.14552712]
 [ 3.33371949]
 [ 8.67111301]
 [ 2.9714098 ]
 [ 3.44967604]
 [ 3.85135245]
 [ 4.67545938]
 [ 3.06123185]
 [ 3.38807178]
 [ 3.49116302]
 [ 3.39262319]
 [ 3.40707064]
 [ 3.78624463]
 [ 3.36501002]]
DEBUG:root:training time = %d0.18136
INFO:root:frame =5521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =5522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294923782349
DEBUG:root: save sample needs time = 0.000101804733276
INFO:root:random_action_porb = 0.956426666667
INFO:root:dqn select action Tensor("ArgMax_32:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.008342
INFO:root:action choosen by dqn [4]
INFO:root:frame =5524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =5525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =5526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:random_action_porb = 0.956395
DEBUG:root: dqn, choose action rondomly, need time 0.000202999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:training error  = [[ 3.55288792]
 [ 3.14651489]
 [ 4.1672554 ]
 [ 3.51130629]
 [ 3.45055461]
 [ 3.55288792]
 [ 3.15161896]
 [ 4.14777899]
 [ 3.70493174]
 [ 3.53159332]
 [ 3.5871532 ]
 [ 3.60484719]
 [ 3.25137806]
 [ 3.86199021]
 [ 3.09916544]
 [ 3.2120564 ]]
DEBUG:root:training time = %d0.205076
INFO:root:frame =5529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =5530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000184059143066
INFO:root:random_action_porb = 0.956363333333
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root:frame =5533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =5534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446796417236
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:random_action_porb = 0.956331666667
DEBUG:root: dqn, choose action rondomly, need time 0.000247999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.16090369]
 [ 3.47178864]
 [ 0.84950894]
 [ 3.93409634]
 [ 3.55518913]
 [ 4.13537312]
 [ 3.14522934]
 [ 8.63004971]
 [ 3.950032  ]
 [ 3.95792079]
 [ 3.67595601]
 [ 3.67860413]
 [ 4.49407196]
 [ 3.60549903]
 [ 3.91029859]
 [ 3.09743285]]
DEBUG:root:training time = %d0.195987
INFO:root:frame =5537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =5538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000342845916748
DEBUG:root: save sample needs time = 0.0001060962677
INFO:root:random_action_porb = 0.9563
DEBUG:root: dqn, choose action rondomly, need time 0.000157999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000152111053467
INFO:root:frame =5541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000347852706909
INFO:root:frame =5542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000278949737549
DEBUG:root: save sample needs time = 0.0001060962677
INFO:root:random_action_porb = 0.956268333333
DEBUG:root: dqn, choose action rondomly, need time 0.000235000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174045562744
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.90821695]
 [ 3.61383367]
 [ 3.32017922]
 [ 3.21442223]
 [ 4.23041391]
 [ 8.54121017]
 [ 3.90821695]
 [ 4.05996132]
 [ 3.42979527]
 [ 3.64268064]
 [ 3.85855746]
 [ 3.56614494]
 [ 3.20094943]
 [ 3.85129237]
 [ 3.55037165]
 [ 8.11620903]]
DEBUG:root:training time = %d0.181124
INFO:root:frame =5545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =5546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241041183472
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.956236666667
DEBUG:root: dqn, choose action rondomly, need time 0.000191999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:frame =5549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00326299667358
INFO:root:frame =5550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000321865081787
DEBUG:root: save sample needs time = 0.000130891799927
INFO:root:random_action_porb = 0.956205
DEBUG:root: dqn, choose action rondomly, need time 0.000208999999984
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000222206115723
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.41800737]
 [ 3.14958787]
 [ 3.17940521]
 [ 8.25922108]
 [ 3.29492617]
 [ 3.28154802]
 [ 2.90197325]
 [ 4.19121218]
 [ 3.49143386]
 [ 3.50741863]
 [ 3.63875008]
 [ 3.34646392]
 [ 3.63256741]
 [ 3.69313431]
 [ 3.97347856]
 [ 3.46640301]]
DEBUG:root:training time = %d0.177027
INFO:root:frame =5553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =5554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235080718994
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:random_action_porb = 0.956173333333
DEBUG:root: dqn, choose action rondomly, need time 0.000169999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000150918960571
INFO:root:frame =5557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375032424927
INFO:root:frame =5558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000297069549561
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root:random_action_porb = 0.956141666667
INFO:root:dqn select action Tensor("ArgMax_33:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014024
INFO:root:action choosen by dqn [4]
INFO:root:frame =5560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:training error  = [[ 3.83461618]
 [ 3.77181363]
 [ 3.43354058]
 [ 3.4612627 ]
 [ 3.83461618]
 [ 3.81316257]
 [ 3.24248338]
 [ 3.56656265]
 [ 3.34445429]
 [ 3.69829702]
 [ 3.57641053]
 [ 3.4802947 ]
 [ 3.66033578]
 [ 3.40843678]
 [ 3.57749271]
 [ 3.58998585]]
DEBUG:root:training time = %d0.175392
INFO:root:frame =5561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =5562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame = 5563 State into memory, numbers recorded 151 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00147795677185
INFO:root:random_action_porb = 0.95611
DEBUG:root: dqn, choose action rondomly, need time 0.000178000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5564current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:frame =5565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000367879867554
INFO:root:frame =5566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
DEBUG:root: save sample needs time = 0.000173807144165
INFO:root:random_action_porb = 0.956078333333
DEBUG:root: dqn, choose action rondomly, need time 0.000202999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000147819519043
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.72443008]
 [ 3.5809567 ]
 [ 4.06489754]
 [ 3.43043113]
 [ 3.90393472]
 [ 3.67161298]
 [ 3.63441443]
 [ 3.76988769]
 [ 2.925493  ]
 [ 3.05366778]
 [ 3.61247063]
 [ 4.16552687]
 [ 3.33412361]
 [ 4.00231981]
 [ 3.30275559]
 [ 8.67936039]]
DEBUG:root:training time = %d0.178676
INFO:root:frame =5569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =5570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000414848327637
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.956046666667
DEBUG:root: dqn, choose action rondomly, need time 0.000330999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =5573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =5574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000617027282715
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.956015
DEBUG:root: dqn, choose action rondomly, need time 0.000448000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.93117619]
 [ 3.31069112]
 [ 3.67174459]
 [ 3.59556794]
 [ 3.59875131]
 [ 3.29019165]
 [ 9.69183159]
 [ 3.71273375]
 [ 3.8588872 ]
 [ 3.45934677]
 [ 8.77083302]
 [ 4.08351564]
 [ 3.64425349]
 [ 3.89387131]
 [ 3.8081882 ]
 [ 3.8081882 ]]
DEBUG:root:training time = %d0.216302
INFO:root:frame =5577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =5578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.955983333333
INFO:root:dqn select action Tensor("ArgMax_34:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.0113
INFO:root:action choosen by dqn [4]
INFO:root:frame =5580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:frame =5581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000394105911255
INFO:root:frame =5582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.955951666667
DEBUG:root: dqn, choose action rondomly, need time 0.000393000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:training error  = [[ 3.56011081]
 [ 3.31641293]
 [ 3.9212594 ]
 [ 3.75436449]
 [ 3.84969068]
 [ 3.86428452]
 [ 3.46202922]
 [ 2.94740462]
 [ 2.90980268]
 [ 3.24604249]
 [ 3.97927499]
 [ 3.10527945]
 [ 3.31212115]
 [ 3.90122175]
 [ 2.95853543]
 [ 3.31641293]]
DEBUG:root:training time = %d0.202711
INFO:root:frame =5585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =5586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286817550659
DEBUG:root: save sample needs time = 0.000152111053467
INFO:root:random_action_porb = 0.95592
DEBUG:root: dqn, choose action rondomly, need time 0.000280000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:frame =5589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =5590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.955888333333
DEBUG:root: dqn, choose action rondomly, need time 0.000585000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:training error  = [[ 3.55682921]
 [ 3.88137078]
 [ 3.50887632]
 [ 3.74959111]
 [ 3.88869429]
 [ 3.67902851]
 [ 3.76751804]
 [ 4.15567589]
 [ 3.25505233]
 [ 3.88137078]
 [ 3.65003777]
 [ 3.61891174]
 [ 3.87234259]
 [ 3.35768056]
 [ 3.67902851]
 [ 3.65630817]]
DEBUG:root:training time = %d0.216768
INFO:root:frame =5593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000331163406372
INFO:root:frame =5594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000500202178955
DEBUG:root: save sample needs time = 0.000185012817383
INFO:root:random_action_porb = 0.955856666667
DEBUG:root: dqn, choose action rondomly, need time 0.00018399999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174045562744
INFO:root:frame =5597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =5598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047492980957
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:random_action_porb = 0.955825
DEBUG:root: dqn, choose action rondomly, need time 0.00022899999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000188112258911
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.35628271]
 [ 3.92295146]
 [ 7.95084906]
 [ 3.35645032]
 [ 4.13777828]
 [ 3.80713129]
 [ 3.4812057 ]
 [ 3.80713129]
 [ 4.005373  ]
 [ 3.28718925]
 [ 3.4812057 ]
 [ 4.05785561]
 [ 3.48254395]
 [ 3.80722046]
 [ 3.49418592]
 [ 3.80722046]]
DEBUG:root:training time = %d0.202744
INFO:root:frame =5601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =5602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00039005279541
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:random_action_porb = 0.955793333333
DEBUG:root: dqn, choose action rondomly, need time 0.000506000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =5605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =5606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.955761666667
DEBUG:root: dqn, choose action rondomly, need time 0.000477000000018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.78032809]
 [ 3.8067441 ]
 [ 3.38224626]
 [ 0.78032809]
 [ 3.45869422]
 [ 3.21741867]
 [ 3.46675801]
 [ 3.43655252]
 [ 3.64995027]
 [ 3.21741867]
 [ 3.66112399]
 [ 4.90864277]
 [ 4.90864277]
 [ 3.20411682]
 [ 3.7996769 ]
 [ 3.6920054 ]]
DEBUG:root:training time = %d0.211669
INFO:root:frame =5609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =5610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000131845474243
INFO:root:random_action_porb = 0.95573
DEBUG:root: dqn, choose action rondomly, need time 0.000169999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:frame =5613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =5614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.955698333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999977
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:training error  = [[ 3.76514888]
 [ 3.32851171]
 [ 4.05604219]
 [ 3.3751924 ]
 [ 3.42576957]
 [ 3.21319127]
 [ 3.85614514]
 [ 3.96613646]
 [ 3.84521604]
 [ 3.38930774]
 [ 3.01104784]
 [ 3.93928862]
 [ 3.80219054]
 [ 3.80952835]
 [ 3.75776529]
 [ 3.67058969]]
DEBUG:root:training time = %d0.21893
INFO:root:frame =5617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =5618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00029993057251
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:random_action_porb = 0.955666666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313999999975
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =5621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000420093536377
INFO:root:frame =5622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424861907959
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.955635
DEBUG:root: dqn, choose action rondomly, need time 0.000330000000019
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4.02543068]
 [ 3.94965291]
 [ 4.05662584]
 [ 3.18783164]
 [ 4.08837318]
 [ 4.21302938]
 [ 3.42317176]
 [ 3.98888397]
 [ 8.04210854]
 [ 3.68766761]
 [ 3.51551056]
 [ 9.72175789]
 [ 3.29715633]
 [ 8.04210854]
 [ 3.58952332]
 [ 8.03291607]]
DEBUG:root:training time = %d0.216986
INFO:root:frame =5625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =5626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.955603333333
DEBUG:root: dqn, choose action rondomly, need time 0.000811999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =5629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000484943389893
INFO:root:frame =5630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000592947006226
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:random_action_porb = 0.955571666667
DEBUG:root: dqn, choose action rondomly, need time 0.000366999999983
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.05341399]
 [ 4.67702675]
 [ 4.40837574]
 [ 5.33474922]
 [ 3.58325267]
 [ 3.68508935]
 [ 3.15178156]
 [ 4.42044592]
 [ 3.70628309]
 [ 5.09825134]
 [ 4.10636473]
 [ 4.2577939 ]
 [ 4.2577939 ]
 [ 3.64705038]
 [ 4.76391792]
 [ 3.53872275]]
DEBUG:root:training time = %d0.207058
INFO:root:frame =5633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =5634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000225782394409
DEBUG:root: save sample needs time = 0.000115871429443
INFO:root:random_action_porb = 0.95554
DEBUG:root: dqn, choose action rondomly, need time 0.000174000000015
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000173091888428
INFO:root:frame =5637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000418901443481
INFO:root:frame =5638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
DEBUG:root: save sample needs time = 0.000153779983521
INFO:root:random_action_porb = 0.955508333333
DEBUG:root: dqn, choose action rondomly, need time 0.00017600000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.9412725 ]
 [ 3.7226193 ]
 [ 3.29030228]
 [ 9.00936413]
 [ 3.83288336]
 [ 3.51179218]
 [ 3.56438732]
 [ 3.54091883]
 [ 3.55336237]
 [ 3.68985081]
 [ 3.86806488]
 [ 3.83473587]
 [ 8.90603924]
 [ 3.80216074]
 [ 3.67469811]
 [ 3.64885712]]
DEBUG:root:training time = %d0.198119
INFO:root:frame =5641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =5642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031304359436
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.955476666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =5645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =5646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247955322266
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.955445
DEBUG:root: dqn, choose action rondomly, need time 0.000329000000022
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000380039215088
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 8.44959354]
 [ 3.61740255]
 [ 3.92400932]
 [ 3.50436163]
 [ 4.12594557]
 [ 3.34545898]
 [ 9.46503925]
 [ 4.38434839]
 [ 3.55352068]
 [ 3.70855999]
 [ 3.14366007]
 [ 8.52527523]
 [ 3.86211014]
 [ 3.64234567]
 [ 3.50707579]
 [ 3.89959431]]
DEBUG:root:training time = %d0.195941
INFO:root:frame =5649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =5650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000329971313477
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.955413333333
DEBUG:root: dqn, choose action rondomly, need time 0.000442000000021
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =5653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049090385437
INFO:root:frame =5654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000496864318848
DEBUG:root: save sample needs time = 0.000105142593384
INFO:root:random_action_porb = 0.955381666667
DEBUG:root: dqn, choose action rondomly, need time 0.000200000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.68920588]
 [ 3.91512799]
 [ 4.18702745]
 [ 3.99876404]
 [ 3.70388913]
 [ 3.65695   ]
 [ 4.08390093]
 [ 3.96893263]
 [ 1.04658115]
 [ 3.57116055]
 [ 3.92632198]
 [ 3.56930089]
 [ 3.47658086]
 [ 3.96900868]
 [ 4.21785402]
 [ 4.3687706 ]]
DEBUG:root:training time = %d0.214345
INFO:root:frame =5657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275850296021
INFO:root:frame =5658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.000140190124512
INFO:root:random_action_porb = 0.95535
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root:frame =5661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440835952759
INFO:root:frame =5662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449180603027
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.955318333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.82429957]
 [ 3.68343449]
 [ 3.64260769]
 [ 3.41015553]
 [ 3.74244428]
 [ 0.70969492]
 [ 3.30204844]
 [ 4.27973604]
 [ 8.45167828]
 [ 3.75704074]
 [ 3.60589004]
 [ 3.5051043 ]
 [ 3.49673915]
 [ 9.12609482]
 [ 3.95904398]
 [ 3.65620613]]
DEBUG:root:training time = %d0.227664
INFO:root:frame =5665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =5666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000335931777954
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.955286666667
DEBUG:root: dqn, choose action rondomly, need time 0.000247000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000265836715698
INFO:root:frame =5669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =5670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:random_action_porb = 0.955255
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00038480758667
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.5174849 ]
 [ 9.01951122]
 [ 4.02936602]
 [ 3.94360542]
 [ 3.61113667]
 [ 3.75343323]
 [ 3.62777042]
 [ 3.95867968]
 [ 3.47942662]
 [ 4.25294638]
 [ 4.05539656]
 [ 3.49633956]
 [ 3.82640362]
 [ 4.14359999]
 [ 3.52811003]
 [ 3.75343323]]
DEBUG:root:training time = %d0.213465
INFO:root:frame =5673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275850296021
INFO:root:frame =5674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.955223333333
DEBUG:root: dqn, choose action rondomly, need time 0.000333000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =5677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000552892684937
INFO:root:frame =5678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:random_action_porb = 0.955191666667
DEBUG:root: dqn, choose action rondomly, need time 0.000588999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.59067965]
 [ 4.10177469]
 [ 3.36979818]
 [ 3.17385721]
 [ 4.02188063]
 [ 4.45827007]
 [ 4.1246438 ]
 [ 4.25030375]
 [ 4.03655148]
 [ 4.0102911 ]
 [ 3.56706715]
 [ 9.12123203]
 [ 3.98257828]
 [ 8.30480289]
 [ 4.14675331]
 [ 4.52853918]]
DEBUG:root:training time = %d0.209377
INFO:root:frame =5681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =5682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025200843811
DEBUG:root: save sample needs time = 0.000115871429443
INFO:root:random_action_porb = 0.95516
DEBUG:root: dqn, choose action rondomly, need time 0.000189000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:frame =5685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =5686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000419855117798
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.955128333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.65826321]
 [ 4.42765093]
 [ 4.28698349]
 [ 3.80272603]
 [ 3.70731115]
 [ 3.91607904]
 [ 4.31110764]
 [ 3.74898553]
 [ 3.69386744]
 [ 3.40652156]
 [ 9.25114059]
 [ 4.18126869]
 [ 3.49752378]
 [ 3.86176538]
 [ 3.70757556]
 [ 3.81773782]]
DEBUG:root:training time = %d0.217109
INFO:root:frame =5689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =5690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.955096666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =5693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =5694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.955065
DEBUG:root: dqn, choose action rondomly, need time 0.000598999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.57682896]
 [ 8.24298191]
 [ 4.09346581]
 [ 9.10389042]
 [ 3.29743338]
 [ 3.62480664]
 [ 3.73897648]
 [ 3.57958531]
 [ 9.07991886]
 [ 4.57739353]
 [ 3.93535256]
 [ 3.17319131]
 [ 3.54328799]
 [ 4.04606056]
 [ 3.85124755]
 [ 3.83285356]]
DEBUG:root:training time = %d0.205525
INFO:root:frame =5697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000401973724365
INFO:root:frame =5698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.955033333333
DEBUG:root: dqn, choose action rondomly, need time 0.000274000000019
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =5701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =5702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000503063201904
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.955001666667
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325202941895
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.65662909]
 [ 3.94584799]
 [ 3.90153813]
 [ 3.45086622]
 [ 3.89566326]
 [ 4.21605206]
 [ 3.6850307 ]
 [ 3.99065185]
 [ 1.00455999]
 [ 4.17127466]
 [ 3.89566326]
 [ 3.8895669 ]
 [ 3.60503554]
 [ 3.68593884]
 [ 3.8895669 ]
 [ 3.93111587]]
DEBUG:root:training time = %d0.218183
INFO:root:frame =5705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =5706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.95497
DEBUG:root: dqn, choose action rondomly, need time 0.000333999999981
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =5709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =5710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.954938333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.73418355]
 [ 4.25870705]
 [ 4.07074451]
 [ 3.68958712]
 [ 4.55154181]
 [ 4.40281868]
 [ 3.61457348]
 [ 3.81788683]
 [ 4.41305447]
 [ 4.00861073]
 [ 9.60336971]
 [ 3.73418355]
 [ 8.60122776]
 [ 4.41807222]
 [ 8.60122776]
 [ 3.8643744 ]]
DEBUG:root:training time = %d0.225544
INFO:root:frame =5713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =5714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.954906666667
DEBUG:root: dqn, choose action rondomly, need time 0.000226999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =5717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =5718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.954875
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.96445012]
 [ 3.81033254]
 [ 4.56419754]
 [ 3.8306582 ]
 [ 4.00722075]
 [ 4.15754271]
 [ 4.60055256]
 [ 9.25819588]
 [ 4.00722075]
 [ 3.96445012]
 [ 3.40642285]
 [ 3.47241402]
 [ 4.25000477]
 [ 3.81033254]
 [ 4.07696581]
 [ 3.84515619]]
DEBUG:root:training time = %d0.20108
INFO:root:frame =5721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =5722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000385999679565
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.954843333333
DEBUG:root: dqn, choose action rondomly, need time 0.000355999999982
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000451803207397
INFO:root:frame =5725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000383853912354
INFO:root:frame =5726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame = 5727 State into memory, numbers recorded 152 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000505924224854
INFO:root:random_action_porb = 0.954811666667
DEBUG:root: dqn, choose action rondomly, need time 0.000328999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5728current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000777006149292
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.60329723]
 [  3.74408269]
 [  4.16569805]
 [  4.97973967]
 [  4.17404842]
 [  4.00125122]
 [  4.64625597]
 [  4.08490324]
 [  3.74124885]
 [  3.65204954]
 [ 10.12575054]
 [  3.98923445]
 [  4.66306162]
 [  4.78100157]
 [  4.66306162]
 [  4.59078836]]
DEBUG:root:training time = %d0.226785
INFO:root:frame =5729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =5730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:random_action_porb = 0.95478
DEBUG:root: dqn, choose action rondomly, need time 0.000205999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =5733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =5734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.954748333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.52538776]
 [  4.33298016]
 [  4.28952742]
 [ 10.1118679 ]
 [ 10.51608467]
 [  4.4410181 ]
 [  4.32731199]
 [  4.57191086]
 [  4.05762482]
 [  3.9198997 ]
 [  4.17610645]
 [  4.57191086]
 [  4.91533852]
 [  4.42541981]
 [ 10.02341366]
 [ 10.23304844]]
DEBUG:root:training time = %d0.213351
INFO:root:frame =5737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =5738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:random_action_porb = 0.954716666667
DEBUG:root: dqn, choose action rondomly, need time 0.000427999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000392913818359
INFO:root:frame =5741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000388860702515
INFO:root:frame =5742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431776046753
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:random_action_porb = 0.954685
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 8.69723892]
 [ 4.5594883 ]
 [ 3.87472987]
 [ 3.73807669]
 [ 3.67219758]
 [ 3.81587458]
 [ 3.9678688 ]
 [ 3.56551099]
 [ 3.59221244]
 [ 4.08723211]
 [ 3.56551099]
 [ 3.88113022]
 [ 3.62442899]
 [ 4.26062822]
 [ 3.81284976]
 [ 4.0512495 ]]
DEBUG:root:training time = %d0.199418
INFO:root:frame =5745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =5746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.954653333333
DEBUG:root: dqn, choose action rondomly, need time 0.000427000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =5749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame =5750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:random_action_porb = 0.954621666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.7757709 ]
 [ 4.11292267]
 [ 4.23035145]
 [ 3.95808768]
 [ 3.7688508 ]
 [ 3.9939599 ]
 [ 3.62178612]
 [ 3.8706162 ]
 [ 3.60991883]
 [ 3.59101224]
 [ 3.6166625 ]
 [ 3.73181033]
 [ 8.20657349]
 [ 4.15468073]
 [ 4.45943022]
 [ 3.71983767]]
DEBUG:root:training time = %d0.224658
INFO:root:frame =5753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =5754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000251054763794
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.95459
DEBUG:root: dqn, choose action rondomly, need time 0.000351999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =5757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =5758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:random_action_porb = 0.954558333333
DEBUG:root: dqn, choose action rondomly, need time 0.000336000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:training error  = [[ 4.46113825]
 [ 3.53499222]
 [ 3.66546082]
 [ 3.83663344]
 [ 3.76412749]
 [ 3.67949677]
 [ 4.62332678]
 [ 3.84267306]
 [ 3.86985064]
 [ 4.11040115]
 [ 4.25485039]
 [ 3.77210999]
 [ 3.98644638]
 [ 4.11040115]
 [ 4.0479641 ]
 [ 4.34324551]]
DEBUG:root:training time = %d0.232638
INFO:root:frame =5761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000326156616211
INFO:root:frame =5762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.954526666667
DEBUG:root: dqn, choose action rondomly, need time 0.000362999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =5765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =5766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.954495
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999981
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.55214024]
 [  3.79477072]
 [  3.7115283 ]
 [  3.70355153]
 [  4.48574638]
 [  4.34273672]
 [  3.64142847]
 [  4.64466095]
 [  3.9284842 ]
 [  4.51646805]
 [ 10.20697498]
 [  4.64931536]
 [  3.63514185]
 [  4.18328142]
 [  4.38576984]
 [  4.36088037]]
DEBUG:root:training time = %d0.231867
INFO:root:frame =5769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =5770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000578880310059
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.954463333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =5773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454187393188
INFO:root:frame =5774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000574827194214
DEBUG:root: save sample needs time = 0.000346183776855
INFO:root:random_action_porb = 0.954431666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4.07043695]
 [ 4.15628242]
 [ 4.65495968]
 [ 3.75372887]
 [ 4.17581034]
 [ 3.9120338 ]
 [ 3.92824221]
 [ 3.72120619]
 [ 1.20520937]
 [ 8.36369801]
 [ 3.87636709]
 [ 4.15628242]
 [ 3.82512021]
 [ 3.64980459]
 [ 4.24788141]
 [ 3.59011602]]
DEBUG:root:training time = %d0.224536
INFO:root:frame =5777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =5778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9544
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =5781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =5782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame = 5783 State into memory, numbers recorded 153 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000571966171265
INFO:root:random_action_porb = 0.954368333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5784current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000612020492554
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4.15283012]
 [ 4.31338882]
 [ 4.38802338]
 [ 4.36505556]
 [ 4.08087969]
 [ 9.60263634]
 [ 4.27000332]
 [ 3.87171197]
 [ 4.31338882]
 [ 3.98375058]
 [ 4.36991882]
 [ 4.25746346]
 [ 4.31143999]
 [ 9.60561562]
 [ 4.09777355]
 [ 3.86386466]]
DEBUG:root:training time = %d0.224832
INFO:root:frame =5785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =5786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000418901443481
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:random_action_porb = 0.954336666667
DEBUG:root: dqn, choose action rondomly, need time 0.000266000000011
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =5789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =5790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000425100326538
INFO:root:frame = 5791 State into memory, numbers recorded 154 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000547885894775
INFO:root:random_action_porb = 0.954305
DEBUG:root: dqn, choose action rondomly, need time 0.000547999999981
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5792current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 8.89864063]
 [ 3.37040043]
 [ 3.74679947]
 [ 3.9762013 ]
 [ 3.95529532]
 [ 4.1017437 ]
 [ 4.1017437 ]
 [ 4.87595558]
 [ 3.68485498]
 [ 4.08129597]
 [ 3.74679947]
 [ 8.47269535]
 [ 4.07762814]
 [ 3.82734394]
 [ 4.39137983]
 [ 4.31128168]]
DEBUG:root:training time = %d0.198127
INFO:root:frame =5793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =5794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:random_action_porb = 0.954273333333
DEBUG:root: dqn, choose action rondomly, need time 0.000171999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000176906585693
INFO:root:frame =5797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000753879547119
INFO:root:frame =5798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root:frame = 5799 State into memory, numbers recorded 155 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000396966934204
INFO:root:random_action_porb = 0.954241666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5800current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.9679904 ]
 [  3.7717247 ]
 [  3.8323009 ]
 [  3.79298735]
 [  4.4829998 ]
 [  4.64605856]
 [  4.15595579]
 [  4.3799243 ]
 [  8.36261749]
 [  3.80917096]
 [  3.84689188]
 [ 10.09358406]
 [  3.69647789]
 [  4.33507633]
 [  4.32548714]
 [  3.9548552 ]]
DEBUG:root:training time = %d0.215923
INFO:root:frame =5801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =5802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000304937362671
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.95421
DEBUG:root: dqn, choose action rondomly, need time 0.000193999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000176906585693
INFO:root:frame =5805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000482082366943
INFO:root:frame =5806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000499963760376
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:random_action_porb = 0.954178333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:training error  = [[ 3.89396167]
 [ 4.49633646]
 [ 4.80635834]
 [ 3.68844414]
 [ 3.77973032]
 [ 3.19059753]
 [ 4.50569201]
 [ 4.2192955 ]
 [ 4.83522081]
 [ 4.24329138]
 [ 4.11139107]
 [ 4.12577534]
 [ 3.8845129 ]
 [ 4.11768961]
 [ 4.10715342]
 [ 3.89203501]]
DEBUG:root:training time = %d0.221442
INFO:root:frame =5809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =5810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.954146666667
INFO:root:dqn select action Tensor("ArgMax_35:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011242
INFO:root:action choosen by dqn [4]
INFO:root:frame =5812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000420093536377
INFO:root:frame =5813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =5814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.954115
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4.47734785]
 [ 3.79975128]
 [ 3.77212477]
 [ 3.83546782]
 [ 4.16719294]
 [ 3.97016382]
 [ 4.16803408]
 [ 4.76465034]
 [ 3.89790726]
 [ 4.14840031]
 [ 3.77212477]
 [ 8.90490055]
 [ 4.55391884]
 [ 4.83936548]
 [ 4.49764729]
 [ 4.0760417 ]]
DEBUG:root:training time = %d0.225296
INFO:root:frame =5817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000358104705811
INFO:root:frame =5818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.954083333333
DEBUG:root: dqn, choose action rondomly, need time 0.00027
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =5821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000497102737427
INFO:root:frame =5822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485181808472
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.954051666667
INFO:root:dqn select action Tensor("ArgMax_36:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014525
INFO:root:action choosen by dqn [4]
INFO:root:frame =5824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.17481542]
 [ 4.03543282]
 [ 4.17671442]
 [ 4.391716  ]
 [ 4.07932329]
 [ 3.83088207]
 [ 3.99132252]
 [ 4.14826059]
 [ 9.59987068]
 [ 4.45833492]
 [ 3.91432786]
 [ 4.52105761]
 [ 3.64984822]
 [ 4.12633324]
 [ 4.18089437]
 [ 4.00914526]]
DEBUG:root:training time = %d0.21596
INFO:root:frame =5825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =5826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000546932220459
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.95402
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =5829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000542879104614
INFO:root:frame =5830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.953988333333
DEBUG:root: dqn, choose action rondomly, need time 0.000327999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:training error  = [[ 4.9810338 ]
 [ 4.37577391]
 [ 4.1512289 ]
 [ 4.17910051]
 [ 3.9442265 ]
 [ 3.79520178]
 [ 4.29578686]
 [ 4.47395849]
 [ 3.81550193]
 [ 4.03868246]
 [ 4.54757118]
 [ 3.61632872]
 [ 4.96983576]
 [ 3.73324013]
 [ 4.23278379]
 [ 4.29547071]]
DEBUG:root:training time = %d0.201032
INFO:root:frame =5833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =5834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.953956666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =5837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000496864318848
INFO:root:frame =5838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.00015115737915
INFO:root:random_action_porb = 0.953925
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root:training error  = [[ 3.82892632]
 [ 4.54322815]
 [ 3.68539691]
 [ 3.68590951]
 [ 3.90868449]
 [ 4.12921619]
 [ 4.02131414]
 [ 4.07493258]
 [ 4.84211826]
 [ 3.90131211]
 [ 4.27194262]
 [ 5.06881905]
 [ 3.68539691]
 [ 4.47086048]
 [ 4.66602802]
 [ 4.33642673]]
DEBUG:root:training time = %d0.180005
INFO:root:frame =5841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root:frame =5842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.953893333333
DEBUG:root: dqn, choose action rondomly, need time 0.000238999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:frame =5845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000485897064209
INFO:root:frame =5846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504016876221
DEBUG:root: save sample needs time = 0.000134944915771
INFO:root:random_action_porb = 0.953861666667
DEBUG:root: dqn, choose action rondomly, need time 0.000166000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.08980799]
 [  4.13406992]
 [ 10.4126997 ]
 [  4.68944263]
 [  4.38997316]
 [  9.53940392]
 [  3.91173196]
 [  4.4153142 ]
 [  4.08980799]
 [  9.71212578]
 [  4.65087843]
 [  4.94123507]
 [  3.91183758]
 [  4.37194443]
 [  4.11464024]
 [  4.17498398]]
DEBUG:root:training time = %d0.23442
INFO:root:frame =5849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:frame =5850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000566005706787
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:random_action_porb = 0.95383
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =5853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =5854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000125885009766
INFO:root:random_action_porb = 0.953798333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:training error  = [[ 4.63747835]
 [ 4.4973073 ]
 [ 5.06540155]
 [ 3.97607946]
 [ 4.4372406 ]
 [ 4.83995295]
 [ 4.24038458]
 [ 4.14599228]
 [ 4.81182957]
 [ 4.77348089]
 [ 4.38383722]
 [ 4.46065474]
 [ 4.28474092]
 [ 4.94941282]
 [ 4.06362057]
 [ 4.06362057]]
DEBUG:root:training time = %d0.22002
INFO:root:frame =5857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =5858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000337839126587
DEBUG:root: save sample needs time = 0.000183820724487
INFO:root:random_action_porb = 0.953766666667
DEBUG:root: dqn, choose action rondomly, need time 0.000174000000015
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =5861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000532865524292
INFO:root:frame =5862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame = 5863 State into memory, numbers recorded 156 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000571012496948
INFO:root:random_action_porb = 0.953735
DEBUG:root: dqn, choose action rondomly, need time 0.000270999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5864current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.33245611]
 [  4.50200081]
 [  4.02253819]
 [  8.73291492]
 [  4.50389481]
 [  4.03308821]
 [  4.12814665]
 [  3.92207527]
 [  4.22448444]
 [  4.08265209]
 [  3.99231339]
 [  4.2911706 ]
 [ 10.37295341]
 [  4.47863913]
 [  4.47863913]
 [  3.89171886]]
DEBUG:root:training time = %d0.197746
INFO:root:frame =5865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =5866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000519990921021
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.953703333333
DEBUG:root: dqn, choose action rondomly, need time 0.000382999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000395059585571
INFO:root:frame =5869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470876693726
INFO:root:frame =5870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000302791595459
DEBUG:root: save sample needs time = 0.000121831893921
INFO:root:random_action_porb = 0.953671666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4.42904806]
 [ 3.94425678]
 [ 3.82401609]
 [ 4.61502981]
 [ 4.30507421]
 [ 3.94425678]
 [ 4.27902603]
 [ 3.8338244 ]
 [ 9.08316135]
 [ 4.0607605 ]
 [ 4.53877354]
 [ 4.37057257]
 [ 4.05424452]
 [ 5.21003819]
 [ 3.89308858]
 [ 4.0246501 ]]
DEBUG:root:training time = %d0.200129
INFO:root:frame =5873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =5874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494956970215
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.95364
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =5877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =5878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049090385437
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:random_action_porb = 0.953608333333
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.36118317]
 [  3.84077406]
 [  4.13580751]
 [  4.58082199]
 [  4.10587025]
 [  4.06483603]
 [ 10.45955276]
 [  4.2908864 ]
 [  4.87743807]
 [  4.65868044]
 [  4.32340908]
 [  4.87201405]
 [  4.87715149]
 [  3.98365927]
 [  4.36118317]
 [  4.53737593]]
DEBUG:root:training time = %d0.220608
INFO:root:frame =5881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =5882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411033630371
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.953576666667
DEBUG:root: dqn, choose action rondomly, need time 0.00044699999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =5885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000408887863159
INFO:root:frame =5886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000425100326538
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.953545
DEBUG:root: dqn, choose action rondomly, need time 0.000561000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4.06355906]
 [ 4.82464075]
 [ 4.80461884]
 [ 4.74422169]
 [ 4.47494268]
 [ 4.82328367]
 [ 3.98263907]
 [ 4.01382113]
 [ 3.8784554 ]
 [ 3.80631256]
 [ 4.01692438]
 [ 4.2055316 ]
 [ 4.12605429]
 [ 8.75023937]
 [ 4.16356516]
 [ 4.1039381 ]]
DEBUG:root:training time = %d0.210376
INFO:root:frame =5889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =5890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288963317871
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.953513333333
DEBUG:root: dqn, choose action rondomly, need time 0.000175999999982
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:frame =5893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =5894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319004058838
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:random_action_porb = 0.953481666667
DEBUG:root: dqn, choose action rondomly, need time 0.000207000000017
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.98742151]
 [ 3.99469161]
 [ 4.4222908 ]
 [ 4.917521  ]
 [ 4.47445869]
 [ 4.15497589]
 [ 4.34850979]
 [ 4.23214054]
 [ 4.6057086 ]
 [ 3.81972051]
 [ 4.44737101]
 [ 4.48112631]
 [ 9.84328842]
 [ 4.09081125]
 [ 4.44601965]
 [ 4.14412832]]
DEBUG:root:training time = %d0.177754
INFO:root:frame =5897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =5898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000316143035889
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.95345
DEBUG:root: dqn, choose action rondomly, need time 0.000381000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000347852706909
INFO:root:frame =5901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00255513191223
INFO:root:frame =5902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000342130661011
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:random_action_porb = 0.953418333333
DEBUG:root: dqn, choose action rondomly, need time 0.000147999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:training error  = [[ 4.29838085]
 [ 3.82031703]
 [ 4.30216169]
 [ 3.9274559 ]
 [ 4.22958231]
 [ 3.92639756]
 [ 4.57163334]
 [ 4.22395134]
 [ 4.24214411]
 [ 3.99243522]
 [ 4.28401423]
 [ 4.22040844]
 [ 4.41889   ]
 [ 4.13579226]
 [ 4.35505104]
 [ 4.34962368]]
DEBUG:root:training time = %d0.185144
INFO:root:frame =5905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:frame =5906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000369071960449
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:random_action_porb = 0.953386666667
DEBUG:root: dqn, choose action rondomly, need time 0.000226999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000161170959473
INFO:root:frame =5909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =5910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227928161621
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.953355
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.43955517]
 [  5.13890076]
 [  4.26343155]
 [ 10.12880898]
 [  4.31223202]
 [  5.10030127]
 [  4.31979275]
 [  4.75000668]
 [  4.61453819]
 [  4.56211185]
 [  4.21738386]
 [  4.3259635 ]
 [  4.33580732]
 [  4.1922431 ]
 [  4.7437067 ]
 [  3.90619612]]
DEBUG:root:training time = %d0.179997
INFO:root:frame =5913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =5914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 0.000120878219604
INFO:root:random_action_porb = 0.953323333333
INFO:root:dqn select action Tensor("ArgMax_37:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00832
INFO:root:action choosen by dqn [4]
INFO:root:frame =5916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162839889526
INFO:root:frame =5917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:frame =5918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000365018844604
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.953291666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000155210494995
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 9.50726604]
 [ 3.99618626]
 [ 4.21666336]
 [ 3.96855259]
 [ 4.13304615]
 [ 4.22412395]
 [ 4.27989388]
 [ 4.68326569]
 [ 4.12154531]
 [ 4.8713913 ]
 [ 3.9243269 ]
 [ 4.2716589 ]
 [ 4.19585228]
 [ 4.28513575]
 [ 4.35570383]
 [ 4.60091257]]
DEBUG:root:training time = %d0.179688
INFO:root:frame =5921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =5922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239133834839
DEBUG:root: save sample needs time = 0.000110149383545
INFO:root:random_action_porb = 0.95326
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:frame =5925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00027322769165
INFO:root:frame =5926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.953228333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000015
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4.59292984]
 [ 4.34959173]
 [ 4.15802479]
 [ 4.57860136]
 [ 4.25296211]
 [ 4.3834219 ]
 [ 4.06823587]
 [ 3.60691881]
 [ 1.05709743]
 [ 3.86357975]
 [ 4.27722692]
 [ 8.77722931]
 [ 3.94509029]
 [ 4.72537947]
 [ 4.44294739]
 [ 4.03356314]]
DEBUG:root:training time = %d0.183484
INFO:root:frame =5929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:frame =5930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288009643555
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.953196666667
DEBUG:root: dqn, choose action rondomly, need time 0.000194999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142812728882
INFO:root:frame =5933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:frame =5934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298976898193
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.953165
DEBUG:root: dqn, choose action rondomly, need time 0.000254000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.98824406]
 [  4.49685431]
 [  5.09828568]
 [ 10.31707764]
 [  4.09292555]
 [  4.39416218]
 [  4.49685431]
 [  4.15001678]
 [  4.21165133]
 [  4.29428482]
 [  4.24145269]
 [  4.067451  ]
 [  4.96155643]
 [  4.44103384]
 [  4.69253254]
 [  4.60058498]]
DEBUG:root:training time = %d0.182965
INFO:root:frame =5937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =5938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277996063232
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.953133333333
DEBUG:root: dqn, choose action rondomly, need time 0.000162000000017
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:frame =5941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =5942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00055193901062
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:random_action_porb = 0.953101666667
DEBUG:root: dqn, choose action rondomly, need time 0.000329999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 9.36206722]
 [ 4.20216846]
 [ 4.27159548]
 [ 4.34435844]
 [ 4.42594957]
 [ 4.60056877]
 [ 9.17241096]
 [ 4.70866013]
 [ 4.91234493]
 [ 1.40883386]
 [ 4.13455105]
 [ 4.63049841]
 [ 4.21323299]
 [ 4.45199013]
 [ 4.67775249]
 [ 4.68419027]]
DEBUG:root:training time = %d0.181083
INFO:root:frame =5945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame =5946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.95307
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00039005279541
INFO:root:frame =5949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000486135482788
INFO:root:frame =5950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame = 5951 State into memory, numbers recorded 157 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000631093978882
INFO:root:random_action_porb = 0.953038333333
DEBUG:root: dqn, choose action rondomly, need time 0.000384999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5952current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000504970550537
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.39908934]
 [  4.81547832]
 [  5.27554703]
 [ 11.98756981]
 [  4.35059404]
 [  4.25005198]
 [  5.33413267]
 [  6.10277176]
 [  4.89737463]
 [  4.35411167]
 [  5.38620472]
 [  3.98171043]
 [  4.86480904]
 [  4.61321068]
 [  4.90573549]
 [  1.29182601]]
DEBUG:root:training time = %d0.212949
INFO:root:frame =5953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =5954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000256061553955
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.953006666667
DEBUG:root: dqn, choose action rondomly, need time 0.000178000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:frame =5957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =5958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.952975
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.2423954 ]
 [  3.98982882]
 [  4.42136049]
 [  4.06514359]
 [  4.86068726]
 [ 10.0407877 ]
 [  4.41263771]
 [  4.95882082]
 [  4.2423954 ]
 [  4.02860022]
 [  4.68065739]
 [  4.6775713 ]
 [  4.25982475]
 [  1.14220703]
 [  4.14903736]
 [  4.14037037]]
DEBUG:root:training time = %d0.230229
INFO:root:frame =5961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =5962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:frame = 5963 State into memory, numbers recorded 158 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000546932220459
INFO:root:random_action_porb = 0.952943333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5964current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =5965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00044584274292
INFO:root:frame =5966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487089157104
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.952911666667
DEBUG:root: dqn, choose action rondomly, need time 0.000416000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4.65298462]
 [ 4.33024883]
 [ 4.20935011]
 [ 4.22163105]
 [ 4.45058966]
 [ 4.91648865]
 [ 3.90790033]
 [ 4.04457235]
 [ 4.2854991 ]
 [ 4.14707947]
 [ 4.07196093]
 [ 4.66008043]
 [ 4.43986034]
 [ 4.83101082]
 [ 4.00725126]
 [ 1.19331193]]
DEBUG:root:training time = %d0.238221
INFO:root:frame =5969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225782394409
INFO:root:frame =5970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000244140625
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:random_action_porb = 0.95288
DEBUG:root: dqn, choose action rondomly, need time 0.000594000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =5973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000417947769165
INFO:root:frame =5974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000278949737549
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.952848333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999985
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 9.78134346]
 [ 3.49307346]
 [ 3.68299532]
 [ 5.14620209]
 [ 4.75459719]
 [ 4.26524353]
 [ 4.02452803]
 [ 4.97009134]
 [ 4.60402203]
 [ 3.73089647]
 [ 4.05957699]
 [ 4.87764025]
 [ 5.00754642]
 [ 4.20180893]
 [ 3.49307346]
 [ 4.34092426]]
DEBUG:root:training time = %d0.203527
INFO:root:frame =5977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =5978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000546932220459
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.952816666667
DEBUG:root: dqn, choose action rondomly, need time 0.000204999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:frame =5981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =5982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509023666382
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:random_action_porb = 0.952785
DEBUG:root: dqn, choose action rondomly, need time 0.000242000000014
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.1385231 ]
 [  4.41055441]
 [  4.28861094]
 [ 10.61928368]
 [  4.15007877]
 [  4.09676981]
 [  4.36658573]
 [  3.77612686]
 [  9.86292648]
 [  4.2248764 ]
 [  4.28861094]
 [  4.43083048]
 [  4.87824678]
 [  4.09763432]
 [  4.45799637]
 [  4.51551151]]
DEBUG:root:training time = %d0.18882
INFO:root:frame =5985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =5986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000560998916626
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.952753333333
DEBUG:root: dqn, choose action rondomly, need time 0.000326999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00072717666626
INFO:root:frame =5989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000363826751709
INFO:root:frame =5990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000535011291504
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:random_action_porb = 0.952721666667
DEBUG:root: dqn, choose action rondomly, need time 0.000212000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:training error  = [[ 4.89962053]
 [ 4.75369883]
 [ 4.2371645 ]
 [ 4.68423986]
 [ 5.06014872]
 [ 4.50026846]
 [ 5.68992758]
 [ 5.15924263]
 [ 5.0879035 ]
 [ 3.97597313]
 [ 4.68423986]
 [ 3.9069953 ]
 [ 4.44214344]
 [ 5.06014872]
 [ 4.09602833]
 [ 5.049685  ]]
DEBUG:root:training time = %d0.198473
INFO:root:frame =5993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =5994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:random_action_porb = 0.95269
DEBUG:root: dqn, choose action rondomly, need time 0.000323000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =5997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000525951385498
INFO:root:frame =5998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000531911849976
DEBUG:root: save sample needs time = 0.000203132629395
DEBUG:root:one frame running time = 0.00628999999998
DEBUG:root:total training time = 151.130045
INFO:root:frame num = 6000 frame round: 0
INFO:root:random_action_porb = 0.952658333333
DEBUG:root: dqn, choose action rondomly, need time 0.000373999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.28368282]
 [  4.06514359]
 [  4.02965689]
 [  4.66550064]
 [  4.06514359]
 [  4.66744518]
 [  4.36124659]
 [  4.12577534]
 [  4.08366966]
 [  4.26390409]
 [  4.02965689]
 [  4.2381382 ]
 [  4.28368282]
 [ 10.10854435]
 [  4.18846369]
 [  4.30857325]]
DEBUG:root:training time = %d0.213491
INFO:root:frame =6001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000503063201904
INFO:root:frame =6002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.952626666667
DEBUG:root: dqn, choose action rondomly, need time 0.000276999999983
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =6005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000641107559204
INFO:root:frame =6006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424861907959
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.952595
DEBUG:root: dqn, choose action rondomly, need time 0.000289999999978
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.4194355 ]
 [  4.15398073]
 [  4.20388889]
 [  4.01094818]
 [  1.22309875]
 [  5.03519106]
 [  4.03745604]
 [  4.45453358]
 [  4.40531635]
 [  4.21326447]
 [ 10.33897305]
 [  4.22771549]
 [  4.40531635]
 [  4.45221519]
 [  5.08021355]
 [  4.49096727]]
DEBUG:root:training time = %d0.21618
INFO:root:frame =6009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =6010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000673055648804
INFO:root:frame = 6011 State into memory, numbers recorded 159 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000557899475098
INFO:root:random_action_porb = 0.952563333333
DEBUG:root: dqn, choose action rondomly, need time 0.000332999999983
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6012current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =6013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000380039215088
INFO:root:frame =6014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000174999237061
INFO:root:random_action_porb = 0.952531666667
DEBUG:root: dqn, choose action rondomly, need time 0.000325000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.55694723]
 [  4.99486971]
 [  4.43839741]
 [  4.75690985]
 [  4.74900913]
 [  4.82430553]
 [  4.16414118]
 [  4.19791555]
 [  4.73375845]
 [  4.4099617 ]
 [ 10.18458652]
 [  5.0305872 ]
 [  4.41486549]
 [  5.76927614]
 [  4.19211817]
 [  4.48589182]]
DEBUG:root:training time = %d0.223775
INFO:root:frame =6017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:frame =6018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000302076339722
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.9525
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root:frame =6021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =6022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
DEBUG:root: save sample needs time = 0.000385999679565
INFO:root:random_action_porb = 0.952468333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 4.66543436]
 [ 4.6775713 ]
 [ 4.14488935]
 [ 4.89614201]
 [ 4.4194994 ]
 [ 5.11809826]
 [ 5.04322386]
 [ 4.58283091]
 [ 4.26688242]
 [ 3.98800039]
 [ 4.69894743]
 [ 5.00488377]
 [ 4.35970163]
 [ 4.38220787]
 [ 4.63473511]
 [ 4.35970163]]
DEBUG:root:training time = %d0.22828
INFO:root:frame =6025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =6026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000312089920044
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.952436666667
INFO:root:dqn select action Tensor("ArgMax_38:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011792
INFO:root:action choosen by dqn [4]
INFO:root:frame =6028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =6029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame =6030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:random_action_porb = 0.952405
DEBUG:root: dqn, choose action rondomly, need time 0.000276999999983
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4.38482761]
 [ 4.54397631]
 [ 9.22217941]
 [ 4.76849794]
 [ 4.54235029]
 [ 4.24448586]
 [ 4.69038439]
 [ 4.65425205]
 [ 3.87695289]
 [ 4.63690329]
 [ 4.86162949]
 [ 9.43405819]
 [ 4.40131426]
 [ 4.50279379]
 [ 4.70998478]
 [ 4.34529638]]
DEBUG:root:training time = %d0.220251
INFO:root:frame =6033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =6034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000270843505859
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.952373333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =6037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000637769699097
INFO:root:frame =6038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000552177429199
INFO:root:random_action_porb = 0.952341666667
DEBUG:root: dqn, choose action rondomly, need time 0.000529
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.53672886]
 [  4.69914579]
 [  4.70089912]
 [  4.0888052 ]
 [  4.41760731]
 [  4.2487936 ]
 [  5.86052752]
 [  1.58641362]
 [  4.53144598]
 [  4.48270893]
 [  4.10131121]
 [  3.8643744 ]
 [  4.6824069 ]
 [  5.11889267]
 [  4.42594957]
 [  5.65892267]]
DEBUG:root:training time = %d0.232521
INFO:root:frame =6041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =6042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000356197357178
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:random_action_porb = 0.95231
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322818756104
INFO:root:frame =6045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =6046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229835510254
DEBUG:root: save sample needs time = 0.000699996948242
INFO:root:random_action_porb = 0.952278333333
DEBUG:root: dqn, choose action rondomly, need time 0.000317999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:training error  = [[ 4.66149664]
 [ 5.41109324]
 [ 4.63997602]
 [ 5.31387043]
 [ 5.31387043]
 [ 4.52936745]
 [ 4.89789772]
 [ 4.90997791]
 [ 4.40184212]
 [ 4.51040602]
 [ 4.7756815 ]
 [ 4.34299088]
 [ 4.72793388]
 [ 4.96026516]
 [ 4.0788765 ]
 [ 4.16847038]]
DEBUG:root:training time = %d0.216001
INFO:root:frame =6049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =6050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.952246666667
DEBUG:root: dqn, choose action rondomly, need time 0.000332000000014
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000243186950684
INFO:root:frame =6053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00129699707031
INFO:root:frame =6054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.000194072723389
INFO:root:random_action_porb = 0.952215
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.11039639]
 [  4.41542673]
 [  4.49395895]
 [  4.40855169]
 [  4.23860931]
 [  4.48644114]
 [  4.65400505]
 [  4.48644114]
 [  4.59575891]
 [  4.38682461]
 [  5.06950617]
 [  4.23860931]
 [  4.3848753 ]
 [  4.57979345]
 [  4.61109686]
 [  4.78071785]]
DEBUG:root:training time = %d0.206338
INFO:root:frame =6057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =6058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000617980957031
DEBUG:root: save sample needs time = 0.000380039215088
INFO:root:random_action_porb = 0.952183333333
DEBUG:root: dqn, choose action rondomly, need time 0.000197999999983
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:frame =6061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456809997559
INFO:root:frame =6062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:random_action_porb = 0.952151666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4.67011595]
 [ 4.50033331]
 [ 4.60562658]
 [ 4.17060471]
 [ 5.70804977]
 [ 9.81028366]
 [ 4.62411404]
 [ 3.93669963]
 [ 4.86948824]
 [ 4.08841991]
 [ 4.84729052]
 [ 4.49348974]
 [ 4.43298244]
 [ 4.50170946]
 [ 4.69797134]
 [ 4.54074049]]
DEBUG:root:training time = %d0.22421
INFO:root:frame =6065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281810760498
INFO:root:frame =6066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446796417236
INFO:root:frame = 6067 State into memory, numbers recorded 160 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000626087188721
INFO:root:random_action_porb = 0.95212
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6068current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =6069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =6070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.952088333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.98587799]
 [  4.12859583]
 [  4.47842932]
 [  4.63616419]
 [  4.27443457]
 [  4.90293074]
 [  5.50359392]
 [  4.87689877]
 [  5.24226999]
 [  4.49017477]
 [  4.21591139]
 [  9.4031744 ]
 [  5.00968075]
 [  4.4004817 ]
 [  4.36598015]
 [  5.00968075]]
DEBUG:root:training time = %d0.214512
INFO:root:frame =6073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =6074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430822372437
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.952056666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999986
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =6077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =6078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000410795211792
INFO:root:frame = 6079 State into memory, numbers recorded 161 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000670909881592
INFO:root:random_action_porb = 0.952025
DEBUG:root: dqn, choose action rondomly, need time 0.000342999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6080current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000388860702515
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.42620659]
 [  4.83357716]
 [  9.79931831]
 [  4.60916376]
 [  4.43646908]
 [  4.97109461]
 [  4.55815268]
 [  4.89153433]
 [  5.02713108]
 [  4.30364943]
 [ 10.06570435]
 [  4.74870968]
 [  4.59046125]
 [  4.29181862]
 [  4.87661266]
 [  4.43818855]]
DEBUG:root:training time = %d0.19074
INFO:root:frame =6081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000788927078247
INFO:root:frame =6082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00084400177002
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:random_action_porb = 0.951993333333
INFO:root:dqn select action Tensor("ArgMax_39:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013546
INFO:root:action choosen by dqn [4]
INFO:root:frame =6084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =6085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000362157821655
INFO:root:frame =6086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.951961666667
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000413179397583
INFO:root:training error  = [[ 4.38396502]
 [ 5.37326908]
 [ 4.43992472]
 [ 4.56380653]
 [ 4.41395187]
 [ 4.872334  ]
 [ 4.70023727]
 [ 4.311028  ]
 [ 5.79382133]
 [ 4.19996357]
 [ 5.07454062]
 [ 4.46178293]
 [ 4.55323505]
 [ 5.16158247]
 [ 4.65101004]
 [ 5.37905359]]
DEBUG:root:training time = %d0.22182
INFO:root:frame =6089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =6090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.95193
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =6093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =6094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.951898333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.31666183]
 [  4.56312227]
 [  5.33215952]
 [  5.12129211]
 [  4.28978014]
 [ 10.3445673 ]
 [  4.96451378]
 [  4.55113506]
 [  4.80975437]
 [  4.96186209]
 [  4.22715092]
 [  5.19043064]
 [  5.2719202 ]
 [  4.89965391]
 [  9.26476669]
 [  4.63719893]]
DEBUG:root:training time = %d0.23866
INFO:root:frame =6097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =6098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000564098358154
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.951866666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =6101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =6102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.951835
DEBUG:root: dqn, choose action rondomly, need time 0.000327999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.28668356]
 [  5.83554649]
 [ 10.4312706 ]
 [ 10.40851498]
 [  4.88087606]
 [  4.88087606]
 [  4.59490824]
 [  4.87068367]
 [  4.58681679]
 [  5.89619112]
 [  4.61891508]
 [  5.23477888]
 [  4.28144073]
 [  4.88087606]
 [  4.51073027]
 [  4.42752266]]
DEBUG:root:training time = %d0.230747
INFO:root:frame =6105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =6106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000338077545166
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.951803333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =6109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000481128692627
INFO:root:frame =6110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000412940979004
INFO:root:frame = 6111 State into memory, numbers recorded 162 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000657081604004
INFO:root:random_action_porb = 0.951771666667
DEBUG:root: dqn, choose action rondomly, need time 0.000358000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6112current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000518083572388
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.83340931]
 [  5.00307465]
 [ 10.77205944]
 [  4.51398754]
 [  5.29375219]
 [  4.37497568]
 [  4.71197176]
 [  4.63900661]
 [  5.20751333]
 [  4.54257774]
 [  4.6797328 ]
 [  5.00353527]
 [  4.67552519]
 [  5.30248022]
 [  4.2715168 ]
 [  4.39888144]]
DEBUG:root:training time = %d0.206519
INFO:root:frame =6113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =6114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000370025634766
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.95174
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000026
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000481843948364
INFO:root:frame =6117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:frame =6118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000326871871948
DEBUG:root: save sample needs time = 0.000120878219604
INFO:root:random_action_porb = 0.951708333333
DEBUG:root: dqn, choose action rondomly, need time 0.000506999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.78100157]
 [ 10.11281395]
 [  4.17428255]
 [  4.650352  ]
 [  9.7679615 ]
 [  5.79503345]
 [  4.44955969]
 [  5.13592625]
 [ 10.79109859]
 [  4.41810417]
 [  4.47915602]
 [  4.50413752]
 [  4.70758438]
 [  4.63179541]
 [  4.94744444]
 [  4.76090431]]
DEBUG:root:training time = %d0.228792
INFO:root:frame =6121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =6122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000503063201904
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.951676666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =6125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000365972518921
INFO:root:frame =6126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491142272949
INFO:root:frame = 6127 State into memory, numbers recorded 163 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000581979751587
INFO:root:random_action_porb = 0.951645
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6128current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.01817131]
 [  4.82591438]
 [  4.83282232]
 [  5.13782835]
 [  5.21817398]
 [  4.66782427]
 [  4.75980568]
 [  4.80017185]
 [  4.66782427]
 [ 11.07636547]
 [  4.74164629]
 [ 10.73720646]
 [ 11.00254822]
 [  4.40866375]
 [  5.12923717]
 [  4.73448896]]
DEBUG:root:training time = %d0.214818
INFO:root:frame =6129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000555038452148
INFO:root:frame = 6131 State into memory, numbers recorded 164 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000596046447754
INFO:root:random_action_porb = 0.951613333333
DEBUG:root: dqn, choose action rondomly, need time 0.000589999999988
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6132current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000401973724365
INFO:root:frame =6133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00056004524231
INFO:root:frame =6134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000300168991089
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.951581666667
DEBUG:root: dqn, choose action rondomly, need time 0.00027399999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.92410421]
 [ 10.01674747]
 [  5.23209095]
 [  4.46052599]
 [  4.82827806]
 [  4.85808039]
 [  4.76220274]
 [  4.666852  ]
 [  4.98593903]
 [  4.90217066]
 [  4.57104588]
 [  4.73377514]
 [  4.97449732]
 [  4.95005798]
 [  5.03986597]
 [  4.51796007]]
DEBUG:root:training time = %d0.207183
INFO:root:frame =6137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =6138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:random_action_porb = 0.95155
DEBUG:root: dqn, choose action rondomly, need time 0.000235000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000509023666382
INFO:root:frame =6141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000415802001953
DEBUG:root: save sample needs time = 0.000125169754028
INFO:root:random_action_porb = 0.951518333333
DEBUG:root: dqn, choose action rondomly, need time 0.000407000000024
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.21914196]
 [  4.44989729]
 [  4.13624191]
 [  9.58616543]
 [  5.94216871]
 [  4.67329836]
 [  4.88107824]
 [  4.98704624]
 [  6.01499653]
 [  4.7506218 ]
 [  4.6039896 ]
 [  4.39851332]
 [  4.63723183]
 [  5.26720905]
 [  5.42803764]
 [ 11.57127094]]
DEBUG:root:training time = %d0.210082
INFO:root:frame =6145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =6146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494003295898
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.951486666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =6149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =6150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504016876221
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.951455
DEBUG:root: dqn, choose action rondomly, need time 0.000338999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.98374128]
 [  4.49861813]
 [ 10.55374908]
 [ 11.18385315]
 [  4.85976219]
 [  5.43627071]
 [  5.31385279]
 [  5.21031666]
 [  4.48225689]
 [  5.20528507]
 [  4.68417358]
 [  5.11393976]
 [  4.59886694]
 [  4.73775959]
 [  5.01309681]
 [  4.51898146]]
DEBUG:root:training time = %d0.198408
INFO:root:frame =6153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =6154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000501155853271
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:random_action_porb = 0.951423333333
DEBUG:root: dqn, choose action rondomly, need time 0.000327000000027
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =6157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =6158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457763671875
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:random_action_porb = 0.951391666667
DEBUG:root: dqn, choose action rondomly, need time 0.000276999999983
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.32796097]
 [  4.6927309 ]
 [  4.79210138]
 [  5.66907263]
 [  4.76616621]
 [  5.04344654]
 [ 11.32796097]
 [  4.86669397]
 [  4.66180992]
 [  4.64625597]
 [  5.45824385]
 [  4.66934109]
 [  4.56853437]
 [  4.75486326]
 [  5.07225513]
 [  4.75869036]]
DEBUG:root:training time = %d0.201903
INFO:root:frame =6161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =6162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00085186958313
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:random_action_porb = 0.95136
INFO:root:dqn select action Tensor("ArgMax_40:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013884
INFO:root:action choosen by dqn [4]
INFO:root:frame =6164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000165224075317
INFO:root:frame =6165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =6166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00033712387085
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.951328333333
DEBUG:root: dqn, choose action rondomly, need time 0.000205999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000199794769287
INFO:root:training error  = [[ 4.57443953]
 [ 5.34081316]
 [ 4.61783266]
 [ 4.71995783]
 [ 4.91405296]
 [ 5.87048674]
 [ 4.57443953]
 [ 4.49577045]
 [ 5.60632229]
 [ 5.31883144]
 [ 4.47637939]
 [ 6.21906281]
 [ 4.96789742]
 [ 6.22724724]
 [ 4.78210258]
 [ 5.87747669]]
DEBUG:root:training time = %d0.207965
INFO:root:frame =6169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =6170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000342130661011
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:random_action_porb = 0.951296666667
DEBUG:root: dqn, choose action rondomly, need time 0.000360000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root:frame =6173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =6174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000120878219604
INFO:root:random_action_porb = 0.951265
DEBUG:root: dqn, choose action rondomly, need time 0.000515999999976
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000449180603027
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5.09107018]
 [ 9.87105083]
 [ 5.09107018]
 [ 4.66302872]
 [ 4.80604076]
 [ 4.54326057]
 [ 4.92098951]
 [ 4.86586952]
 [ 4.41007376]
 [ 4.93694544]
 [ 4.75309992]
 [ 5.13879681]
 [ 4.53110504]
 [ 5.50917959]
 [ 4.88429832]
 [ 4.75309992]]
DEBUG:root:training time = %d0.209694
INFO:root:frame =6177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =6178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000555992126465
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.951233333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =6181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000412940979004
INFO:root:frame =6182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:random_action_porb = 0.951201666667
DEBUG:root: dqn, choose action rondomly, need time 0.000174000000015
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.78008413]
 [  4.54854727]
 [  4.84049034]
 [  5.01079082]
 [  4.93782711]
 [ 10.75046062]
 [  5.50022936]
 [  1.39788878]
 [  4.74791193]
 [  4.83196688]
 [  5.24898005]
 [  4.97162199]
 [  4.70597887]
 [  5.52265406]
 [  4.54147196]
 [  4.47242546]]
DEBUG:root:training time = %d0.217912
INFO:root:frame =6185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =6186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.95117
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =6189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =6190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame = 6191 State into memory, numbers recorded 165 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000653028488159
INFO:root:random_action_porb = 0.951138333333
DEBUG:root: dqn, choose action rondomly, need time 0.000171999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6192current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000134944915771
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4.72186422]
 [ 4.97041416]
 [ 4.00919104]
 [ 5.51283312]
 [ 5.44520378]
 [ 4.66711569]
 [ 5.77041245]
 [ 1.35856962]
 [ 5.50318241]
 [ 4.61396456]
 [ 4.98173189]
 [ 6.23036957]
 [ 4.85127258]
 [ 4.84762669]
 [ 4.79251909]
 [ 4.6484437 ]]
DEBUG:root:training time = %d0.231482
INFO:root:frame =6193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000356197357178
INFO:root:frame =6194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
DEBUG:root: save sample needs time = 0.000116109848022
INFO:root:random_action_porb = 0.951106666667
DEBUG:root: dqn, choose action rondomly, need time 0.000219999999985
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000391006469727
INFO:root:frame =6197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root:frame =6198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000492095947266
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:random_action_porb = 0.951075
DEBUG:root: dqn, choose action rondomly, need time 0.000240999999988
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.83988571]
 [  4.98874998]
 [  4.83852625]
 [  4.96035004]
 [  4.41316652]
 [  5.63285446]
 [  5.04956484]
 [  1.49033964]
 [  4.67765379]
 [  5.09828568]
 [  5.28285694]
 [  4.92622089]
 [  5.23116589]
 [ 11.59056187]
 [  4.82537842]
 [  4.8111434 ]]
DEBUG:root:training time = %d0.214953
INFO:root:frame =6201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =6202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000313997268677
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.951043333333
DEBUG:root: dqn, choose action rondomly, need time 0.000347000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =6205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00056004524231
INFO:root:frame =6206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235080718994
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:random_action_porb = 0.951011666667
DEBUG:root: dqn, choose action rondomly, need time 0.000349
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.81809044]
 [  5.96398544]
 [  4.47198963]
 [  5.32632971]
 [ 11.50932789]
 [  5.21679735]
 [  4.8546505 ]
 [  5.3722434 ]
 [  4.37044477]
 [  4.76561642]
 [  1.60740232]
 [  4.88932419]
 [  5.8871727 ]
 [  4.71162415]
 [  4.62039089]
 [  5.86001062]]
DEBUG:root:training time = %d0.227528
INFO:root:frame =6209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =6210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame = 6211 State into memory, numbers recorded 166 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000756025314331
INFO:root:random_action_porb = 0.95098
DEBUG:root: dqn, choose action rondomly, need time 0.00018799999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6212current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =6213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =6214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000637054443359
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.950948333333
DEBUG:root: dqn, choose action rondomly, need time 0.000192999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000184059143066
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.07472944]
 [  4.46017122]
 [  4.60351467]
 [  4.60284376]
 [  5.30766392]
 [  5.73575306]
 [  4.82839537]
 [  4.72093582]
 [  4.64836121]
 [  4.98125505]
 [  5.33882093]
 [  5.18834496]
 [  5.15021801]
 [  4.97339153]
 [ 10.4782896 ]
 [  5.10274839]]
DEBUG:root:training time = %d0.215311
INFO:root:frame =6217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:frame =6218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000531911849976
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:random_action_porb = 0.950916666667
DEBUG:root: dqn, choose action rondomly, need time 0.000450000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322818756104
INFO:root:frame =6221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =6222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.950885
DEBUG:root: dqn, choose action rondomly, need time 0.000560000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5.05623627]
 [ 4.44951105]
 [ 4.55535126]
 [ 5.03373623]
 [ 5.96046448]
 [ 5.20747852]
 [ 5.00370598]
 [ 5.59180737]
 [ 4.73850727]
 [ 3.98857927]
 [ 4.86292458]
 [ 4.49211502]
 [ 4.92283487]
 [ 9.87335205]
 [ 4.64359236]
 [ 4.36303139]]
DEBUG:root:training time = %d0.205094
INFO:root:frame =6225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =6226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:random_action_porb = 0.950853333333
DEBUG:root: dqn, choose action rondomly, need time 0.000556999999986
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =6229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =6230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:random_action_porb = 0.950821666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[ 5.10474777]
 [ 6.19744921]
 [ 4.90406275]
 [ 5.18551254]
 [ 5.19980335]
 [ 4.82323313]
 [ 4.9108572 ]
 [ 4.76614952]
 [ 4.65538788]
 [ 4.8069272 ]
 [ 5.05007935]
 [ 4.9108572 ]
 [ 4.58572197]
 [ 4.36164522]
 [ 5.06809759]
 [ 5.60009146]]
DEBUG:root:training time = %d0.209803
INFO:root:frame =6233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =6234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.95079
DEBUG:root: dqn, choose action rondomly, need time 0.000531999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =6237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =6238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.950758333333
DEBUG:root: dqn, choose action rondomly, need time 0.000375999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4.98398018]
 [ 4.59046125]
 [ 2.02265072]
 [ 5.05700827]
 [ 9.9777174 ]
 [ 4.98638201]
 [ 5.03279495]
 [ 6.30735159]
 [ 4.7446537 ]
 [ 5.06813192]
 [ 5.31420469]
 [ 5.46132803]
 [ 6.30990028]
 [ 4.60074854]
 [ 5.62729692]
 [ 5.7234993 ]]
DEBUG:root:training time = %d0.213893
INFO:root:frame =6241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =6242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000280141830444
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.950726666667
DEBUG:root: dqn, choose action rondomly, need time 0.000220000000013
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00017786026001
INFO:root:frame =6245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000518083572388
INFO:root:frame =6246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000429153442383
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:random_action_porb = 0.950695
DEBUG:root: dqn, choose action rondomly, need time 0.000161999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000147104263306
INFO:root:training error  = [[ 6.16198254]
 [ 5.56769466]
 [ 5.14530182]
 [ 4.93948841]
 [ 5.74798346]
 [ 5.23666382]
 [ 5.41480303]
 [ 5.09459972]
 [ 5.61472511]
 [ 5.46906853]
 [ 5.08119392]
 [ 5.15556955]
 [ 5.0646801 ]
 [ 5.91549206]
 [ 5.31960535]
 [ 5.64564514]]
DEBUG:root:training time = %d0.217357
INFO:root:frame =6249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =6250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288963317871
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:random_action_porb = 0.950663333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =6253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =6254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame = 6255 State into memory, numbers recorded 167 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000605821609497
INFO:root:random_action_porb = 0.950631666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6256current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.66668701]
 [  4.81072474]
 [  4.69643402]
 [  4.92872715]
 [  5.1842618 ]
 [  4.59435225]
 [  4.63737965]
 [  4.58495426]
 [  5.18452263]
 [ 11.35943794]
 [  4.7947073 ]
 [ 11.31707573]
 [  4.78163528]
 [  4.86632395]
 [  5.29473543]
 [  5.12901258]]
DEBUG:root:training time = %d0.219982
INFO:root:frame =6257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =6258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:random_action_porb = 0.9506
DEBUG:root: dqn, choose action rondomly, need time 0.000339999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =6261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000509977340698
INFO:root:frame =6262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:random_action_porb = 0.950568333333
DEBUG:root: dqn, choose action rondomly, need time 0.000269000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.7537322 ]
 [  4.39878559]
 [  4.69901323]
 [  9.92707634]
 [  6.60672188]
 [  6.10955858]
 [  5.69566154]
 [  5.54866457]
 [  5.69566154]
 [  5.53248405]
 [ 10.48770046]
 [  4.98542786]
 [  5.28571558]
 [  5.00157309]
 [  4.86285734]
 [ 11.2496748 ]]
DEBUG:root:training time = %d0.208831
INFO:root:frame =6265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =6266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame = 6267 State into memory, numbers recorded 168 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000569820404053
INFO:root:random_action_porb = 0.950536666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6268current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =6269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =6270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000116109848022
INFO:root:random_action_porb = 0.950505
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.46396685]
 [  5.95694447]
 [  5.39839363]
 [  5.46195173]
 [ 10.96045303]
 [  4.82423878]
 [ 10.92237186]
 [  5.20864534]
 [  6.48348331]
 [  6.1706028 ]
 [  4.74561787]
 [  5.04755926]
 [ 12.03188229]
 [  5.06478357]
 [  5.04377174]
 [  6.27711391]]
DEBUG:root:training time = %d0.226026
INFO:root:frame =6273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =6274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000385999679565
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.950473333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =6277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =6278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.950441666667
DEBUG:root: dqn, choose action rondomly, need time 0.000327999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.92577839]
 [  5.92936182]
 [  5.49725962]
 [  5.78864384]
 [  5.92936182]
 [  5.00135136]
 [  4.81912899]
 [ 11.3484869 ]
 [  5.78864384]
 [  5.48965979]
 [  4.757442  ]
 [  5.3171773 ]
 [  5.25754833]
 [  4.94101477]
 [  5.37061691]
 [ 11.14372921]]
DEBUG:root:training time = %d0.228805
INFO:root:frame =6281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =6282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000266075134277
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:random_action_porb = 0.95041
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000199794769287
INFO:root:frame =6285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =6286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.950378333333
DEBUG:root: dqn, choose action rondomly, need time 0.000343000000015
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:training error  = [[ 5.26174736]
 [ 4.99030113]
 [ 5.01776123]
 [ 4.99030113]
 [ 5.16742516]
 [ 5.50219774]
 [ 5.18693733]
 [ 5.38700151]
 [ 4.7908659 ]
 [ 4.89322186]
 [ 5.47210217]
 [ 5.84284687]
 [ 5.25786304]
 [ 4.74432135]
 [ 5.03728008]
 [ 5.70538902]]
DEBUG:root:training time = %d0.20936
INFO:root:frame =6289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =6290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279188156128
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.950346666667
DEBUG:root: dqn, choose action rondomly, need time 0.000232000000011
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =6293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =6294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000675916671753
INFO:root:frame = 6295 State into memory, numbers recorded 169 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000582218170166
INFO:root:random_action_porb = 0.950315
DEBUG:root: dqn, choose action rondomly, need time 0.000258000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6296current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.8548522 ]
 [  5.21718073]
 [  5.09243059]
 [  5.03106642]
 [  4.87433815]
 [  5.26069736]
 [  4.7420783 ]
 [  4.96549988]
 [  4.96881533]
 [  5.06612253]
 [  4.98646688]
 [  5.10548925]
 [  6.30269623]
 [  4.82547855]
 [ 11.04087067]
 [  4.81897831]]
DEBUG:root:training time = %d0.225206
INFO:root:frame =6297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =6298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000261068344116
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.950283333333
DEBUG:root: dqn, choose action rondomly, need time 0.000314999999972
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =6301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =6302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.950251666667
DEBUG:root: dqn, choose action rondomly, need time 0.000336000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.39275837]
 [  5.15399313]
 [  5.21139669]
 [  4.93394566]
 [  5.14563084]
 [  5.22814751]
 [  5.49184084]
 [ 10.5821476 ]
 [  5.33913803]
 [  5.11815023]
 [  5.32631207]
 [  5.39275837]
 [  5.00618076]
 [  5.47883272]
 [  5.22373486]
 [  5.67806816]]
DEBUG:root:training time = %d0.236855
INFO:root:frame =6305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =6306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308990478516
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:random_action_porb = 0.95022
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000370979309082
INFO:root:frame =6309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000411033630371
INFO:root: ememy has been killed for 13 times 
INFO:root:enemies_left [0]
INFO:root:frame =6310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame = 6311 State into memory, numbers recorded 170 action = 4, reward = 1
DEBUG:root: save sample needs time = 0.000546216964722
INFO:root:random_action_porb = 0.950188333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6312current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:training error  = [[ 5.04834795]
 [ 5.54598713]
 [ 5.9848156 ]
 [ 5.10995483]
 [ 5.41989946]
 [ 5.118927  ]
 [ 5.43315792]
 [ 5.67036247]
 [ 5.09508228]
 [ 5.72501421]
 [ 4.79664516]
 [ 4.83215141]
 [ 6.49619436]
 [ 5.16158247]
 [ 5.72501421]
 [ 5.07507324]]
DEBUG:root:training time = %d0.226121
INFO:root:frame =6313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275850296021
INFO:root:frame =6314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000270843505859
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.950156666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame =6318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.950125
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.9066143 ]
 [  5.09787226]
 [ 12.1024332 ]
 [  5.62847328]
 [  5.48965979]
 [  4.74865961]
 [  4.98624563]
 [  4.689641  ]
 [  6.12244558]
 [  5.06222534]
 [  5.21794748]
 [  6.26333952]
 [  5.90853596]
 [  5.48965979]
 [  4.90370798]
 [  6.25312853]]
DEBUG:root:training time = %d0.233161
INFO:root:frame =6321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =6322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000559091567993
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:random_action_porb = 0.950093333333
DEBUG:root: dqn, choose action rondomly, need time 0.000186999999983
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000181198120117
INFO:root:frame =6325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =6326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.950061666667
DEBUG:root: dqn, choose action rondomly, need time 0.000563
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.14341593]
 [  5.08353329]
 [  6.01497793]
 [  4.73214865]
 [ 11.46095085]
 [  6.11210489]
 [  5.68939972]
 [  4.78086805]
 [  5.78737736]
 [  5.81619215]
 [  4.74176264]
 [  5.90043449]
 [  6.32752466]
 [  5.33221197]
 [  5.95549202]
 [  5.30031967]]
DEBUG:root:training time = %d0.211936
INFO:root:frame =6329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =6330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000632047653198
DEBUG:root: save sample needs time = 0.000150203704834
INFO:root:random_action_porb = 0.95003
DEBUG:root: dqn, choose action rondomly, need time 0.000222999999977
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000192165374756
INFO:root:frame =6333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:frame =6334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470876693726
INFO:root:frame = 6335 State into memory, numbers recorded 171 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000722885131836
INFO:root:random_action_porb = 0.949998333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6336current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.43219757]
 [  5.61237526]
 [  5.35125589]
 [ 11.25543308]
 [  5.18488741]
 [  5.47683239]
 [ 10.10641003]
 [  5.57460928]
 [  5.09012365]
 [  5.21244192]
 [ 10.65441799]
 [  5.43219757]
 [  5.12749243]
 [  5.32224512]
 [  5.46664238]
 [ 10.37543488]]
DEBUG:root:training time = %d0.218813
INFO:root:frame =6337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =6338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000467777252197
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.949966666667
DEBUG:root: dqn, choose action rondomly, need time 0.000666999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =6341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000424861907959
INFO:root:frame =6342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame = 6343 State into memory, numbers recorded 172 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000573873519897
INFO:root:random_action_porb = 0.949935
DEBUG:root: dqn, choose action rondomly, need time 0.000427999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6344current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000366926193237
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5.23607063]
 [ 5.03890705]
 [ 4.80729532]
 [ 6.33873749]
 [ 1.57041597]
 [ 5.01808596]
 [ 4.63547421]
 [ 4.9705162 ]
 [ 5.41510487]
 [ 5.40172672]
 [ 4.25028801]
 [ 5.73706865]
 [ 6.45836973]
 [ 5.44872952]
 [ 4.87432146]
 [ 4.54718065]]
DEBUG:root:training time = %d0.209292
INFO:root:frame =6345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =6346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame = 6347 State into memory, numbers recorded 173 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000549077987671
INFO:root:random_action_porb = 0.949903333333
DEBUG:root: dqn, choose action rondomly, need time 0.000173999999987
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6348current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:frame =6349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253200531006
INFO:root:frame =6350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00039005279541
INFO:root: ememy has been killed for 14 times 
INFO:root:enemies_left [0]
INFO:root:frame = 6351 State into memory, numbers recorded 174 action = 2, reward = 1
DEBUG:root: save sample needs time = 0.000428915023804
INFO:root:random_action_porb = 0.949871666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6352current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.68291903]
 [  5.89511681]
 [  5.31714249]
 [  5.3107934 ]
 [  4.68291903]
 [  5.36759377]
 [  4.88578224]
 [  5.36830091]
 [  5.12300158]
 [  5.11478519]
 [ 10.54017067]
 [  5.56675863]
 [  4.96731901]
 [  4.55769682]
 [  5.26106501]
 [  4.86969042]]
DEBUG:root:training time = %d0.197248
INFO:root:frame =6353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00037693977356
INFO:root:frame =6354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000280141830444
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.94984
DEBUG:root: dqn, choose action rondomly, need time 0.000308999999987
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =6357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =6358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000420093536377
INFO:root:frame = 6359 State into memory, numbers recorded 175 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000501155853271
INFO:root:random_action_porb = 0.949808333333
DEBUG:root: dqn, choose action rondomly, need time 0.000317999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6360current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:training error  = [[ 5.80144501]
 [ 4.87969637]
 [ 5.26556349]
 [ 5.67866802]
 [ 5.67866802]
 [ 5.12814856]
 [ 5.97433043]
 [ 5.56186342]
 [ 5.62635565]
 [ 5.49235964]
 [ 6.04099607]
 [ 5.10623026]
 [ 5.31983423]
 [ 5.16829252]
 [ 5.61210442]
 [ 5.53298616]]
DEBUG:root:training time = %d0.216071
INFO:root:frame =6361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:frame =6362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000587940216064
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.949776666667
DEBUG:root: dqn, choose action rondomly, need time 0.000342999999987
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =6365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456809997559
INFO:root:frame =6366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000352144241333
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.949745
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.46794462]
 [  5.01658201]
 [  5.32242155]
 [  5.97634459]
 [  5.31723022]
 [ 11.12501812]
 [  6.14438248]
 [  5.2868557 ]
 [  4.90472174]
 [  1.8126421 ]
 [  5.28413725]
 [  5.22075367]
 [  5.15596771]
 [  5.63535357]
 [  5.30597687]
 [ 11.76121235]]
DEBUG:root:training time = %d0.212621
INFO:root:frame =6369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =6370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000335931777954
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.949713333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =6373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =6374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000572919845581
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.949681666667
DEBUG:root: dqn, choose action rondomly, need time 0.000450999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4.67729044]
 [ 6.48210382]
 [ 5.79619074]
 [ 5.01173019]
 [ 6.25146866]
 [ 4.75025606]
 [ 5.3105998 ]
 [ 4.74433804]
 [ 1.58025992]
 [ 6.15726805]
 [ 6.18689346]
 [ 6.28931475]
 [ 5.23207331]
 [ 5.53221464]
 [ 6.06237316]
 [ 5.68827152]]
DEBUG:root:training time = %d0.220485
INFO:root:frame =6377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =6378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000289916992188
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:random_action_porb = 0.94965
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =6381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000500917434692
INFO:root:frame =6382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000499963760376
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.949618333333
DEBUG:root: dqn, choose action rondomly, need time 0.000181999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000140190124512
INFO:root:training error  = [[ 6.06062651]
 [ 4.93475914]
 [ 5.19987297]
 [ 5.49861908]
 [ 6.63611126]
 [ 5.22614145]
 [ 5.67361498]
 [ 6.14950848]
 [ 5.66099167]
 [ 5.57862711]
 [ 5.50017595]
 [ 4.84556055]
 [ 5.11507845]
 [ 6.15412569]
 [ 7.0624547 ]
 [ 6.94532728]]
DEBUG:root:training time = %d0.2257
INFO:root:frame =6385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =6386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000502109527588
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:random_action_porb = 0.949586666667
DEBUG:root: dqn, choose action rondomly, need time 0.000191000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =6389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =6390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259160995483
DEBUG:root: save sample needs time = 0.000141859054565
INFO:root:random_action_porb = 0.949555
DEBUG:root: dqn, choose action rondomly, need time 0.000243000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.22989225]
 [  5.29533243]
 [ 11.96056175]
 [  5.29329586]
 [  5.40536261]
 [  5.72956038]
 [  5.84767962]
 [  5.31506634]
 [  5.84767962]
 [  5.99446869]
 [  5.61534023]
 [  5.6362772 ]
 [  5.55243921]
 [  6.2179594 ]
 [  5.47311926]
 [  5.95443106]]
DEBUG:root:training time = %d0.184467
INFO:root:frame =6393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =6394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000542163848877
INFO:root: ememy has been killed for 15 times 
INFO:root:enemies_left [0]
INFO:root:frame = 6395 State into memory, numbers recorded 176 action = 0, reward = 1
DEBUG:root: save sample needs time = 0.000456809997559
INFO:root:random_action_porb = 0.949523333333
DEBUG:root: dqn, choose action rondomly, need time 0.000238999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6396current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:frame =6397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =6398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049901008606
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.949491666667
DEBUG:root: dqn, choose action rondomly, need time 0.000325000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.79143429]
 [  5.32890081]
 [  5.84113216]
 [  5.63741827]
 [  6.17276382]
 [  5.86716032]
 [  5.4810648 ]
 [  5.94315434]
 [  5.18745852]
 [  5.05618477]
 [  5.65736198]
 [  6.25738382]
 [  4.85219669]
 [ 11.40703297]
 [  5.52532578]
 [  5.81891584]]
DEBUG:root:training time = %d0.19872
INFO:root:frame =6401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =6402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000300168991089
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.94946
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =6406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.949428333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.27942944]
 [  5.34211779]
 [  5.75303316]
 [  5.62898016]
 [  5.22758913]
 [  5.11350822]
 [  5.24368477]
 [  5.03284597]
 [ 10.65563774]
 [  5.41162586]
 [  1.59762836]
 [  5.25275612]
 [  5.49139404]
 [  5.4830122 ]
 [  6.27743864]
 [  5.00959539]]
DEBUG:root:training time = %d0.215702
INFO:root:frame =6409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =6410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.949396666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =6413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049090385437
INFO:root:frame =6414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000360012054443
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.949365
DEBUG:root: dqn, choose action rondomly, need time 0.000350999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.93917465]
 [  5.83927011]
 [  5.33466148]
 [ 12.05404282]
 [  5.10193825]
 [  5.61492443]
 [  5.0344553 ]
 [  4.91934824]
 [  6.4619956 ]
 [  4.55601931]
 [  5.00385952]
 [  6.28749752]
 [  5.80236387]
 [  5.1297555 ]
 [ 11.31343174]
 [  1.87459826]]
DEBUG:root:training time = %d0.201837
INFO:root:frame =6417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =6418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000282049179077
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.949333333333
DEBUG:root: dqn, choose action rondomly, need time 0.000419000000022
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =6421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =6422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000157117843628
INFO:root:random_action_porb = 0.949301666667
DEBUG:root: dqn, choose action rondomly, need time 0.000320999999985
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000394105911255
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.11246347]
 [  5.27321672]
 [  5.23257923]
 [  5.43545246]
 [  5.30921078]
 [  5.33379793]
 [  5.01858187]
 [  6.74500418]
 [  5.89250517]
 [  5.29250622]
 [  5.53036642]
 [ 12.47837639]
 [  5.28468084]
 [  5.28468084]
 [ 10.75158596]
 [  5.75103855]]
DEBUG:root:training time = %d0.220002
INFO:root:frame =6425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:frame =6426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000134944915771
INFO:root:random_action_porb = 0.94927
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root:frame =6429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =6430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.949238333333
INFO:root:dqn select action Tensor("ArgMax_41:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00829200000001
INFO:root:action choosen by dqn [4]
INFO:root:frame =6432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.39289999]
 [ 10.46947479]
 [  5.70938063]
 [  5.56931496]
 [  5.23154974]
 [  5.36617994]
 [  5.61743736]
 [  5.56674051]
 [  5.69067383]
 [  5.1625185 ]
 [  5.38937473]
 [  5.55786943]
 [  5.9131732 ]
 [  5.23154974]
 [  5.29196215]
 [ 10.46947479]]
DEBUG:root:training time = %d0.208248
INFO:root:frame =6433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =6434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482082366943
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.949206666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000022
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =6437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =6438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame = 6439 State into memory, numbers recorded 177 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000549077987671
INFO:root:random_action_porb = 0.949175
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6440current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.38889647]
 [  5.4717989 ]
 [  5.41956234]
 [ 12.49196339]
 [  6.17532301]
 [  5.43066835]
 [  5.48654985]
 [  5.71576262]
 [  5.08179569]
 [  5.05752325]
 [  5.79483175]
 [  5.10538578]
 [  5.38889647]
 [  5.1341629 ]
 [  5.46485853]
 [  5.35547495]]
DEBUG:root:training time = %d0.219507
INFO:root:frame =6441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =6442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:random_action_porb = 0.949143333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308999999987
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =6445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =6446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.949111666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:training error  = [[ 5.66500425]
 [ 5.28606653]
 [ 5.19394207]
 [ 5.29303265]
 [ 5.65289879]
 [ 5.28606653]
 [ 5.15179396]
 [ 6.56973028]
 [ 4.89131498]
 [ 4.92989588]
 [ 5.12849426]
 [ 5.45047522]
 [ 4.8804884 ]
 [ 5.59823227]
 [ 5.3538332 ]
 [ 5.81197977]]
DEBUG:root:training time = %d0.222025
INFO:root:frame =6449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =6450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.94908
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =6453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame =6454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.949048333333
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000011
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.22957802]
 [  5.13089609]
 [  6.17354059]
 [  5.22014332]
 [  5.12699127]
 [  5.39575291]
 [ 11.11270523]
 [  5.86880493]
 [  5.68265057]
 [  5.44144821]
 [  5.63712835]
 [  5.59877348]
 [  5.63560677]
 [  5.32911205]
 [  5.49833298]
 [  5.63560677]]
DEBUG:root:training time = %d0.216077
INFO:root:frame =6457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268220901489
INFO:root:frame =6458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000305891036987
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.949016666667
DEBUG:root: dqn, choose action rondomly, need time 0.000237999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =6461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =6462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.948985
DEBUG:root: dqn, choose action rondomly, need time 0.000407000000024
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:training error  = [[ 5.15664339]
 [ 5.27008104]
 [ 5.36388254]
 [ 5.0555501 ]
 [ 5.29803658]
 [ 5.80409145]
 [ 5.19114304]
 [ 5.24959183]
 [ 5.40431595]
 [ 5.82232094]
 [ 5.27034378]
 [ 5.5366478 ]
 [ 5.53560686]
 [ 5.24344015]
 [ 5.37937212]
 [ 5.43646622]]
DEBUG:root:training time = %d0.220293
INFO:root:frame =6465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =6466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.948953333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999986
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =6469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =6470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486135482788
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.948921666667
DEBUG:root: dqn, choose action rondomly, need time 0.00027
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.27698421]
 [  5.73747063]
 [  5.75003242]
 [  5.68712521]
 [  5.17965937]
 [  5.40798807]
 [  5.83855104]
 [ 10.3979826 ]
 [ 11.10988235]
 [  7.0509634 ]
 [  1.73486435]
 [  5.55497408]
 [  5.48024321]
 [  5.15260744]
 [  4.99323273]
 [  5.07684374]]
DEBUG:root:training time = %d0.202393
INFO:root:frame =6473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000367879867554
INFO:root:frame =6474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame = 6475 State into memory, numbers recorded 178 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000404119491577
INFO:root:random_action_porb = 0.94889
DEBUG:root: dqn, choose action rondomly, need time 0.000254000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6476current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =6477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =6478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.948858333333
INFO:root:dqn select action Tensor("ArgMax_42:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012095
INFO:root:action choosen by dqn [4]
INFO:root:frame =6480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.02665949]
 [ 11.37186146]
 [  5.93309641]
 [  5.91684675]
 [  5.65620089]
 [  5.86327982]
 [  5.30174255]
 [  6.62709332]
 [  5.42784214]
 [  6.05285311]
 [  5.24352789]
 [ 11.530406  ]
 [  5.90175009]
 [  1.84509087]
 [  5.65620089]
 [  5.49867296]]
DEBUG:root:training time = %d0.220329
INFO:root:frame =6481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =6482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.948826666667
DEBUG:root: dqn, choose action rondomly, need time 0.000193999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000184059143066
INFO:root:frame =6485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000371932983398
INFO:root:frame =6486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000339984893799
DEBUG:root: save sample needs time = 0.000206232070923
INFO:root:random_action_porb = 0.948795
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000373840332031
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.64546394]
 [  5.53108406]
 [  4.9767437 ]
 [  5.9704895 ]
 [  6.28736353]
 [  6.37401438]
 [  2.33100796]
 [  5.46509027]
 [  5.95081997]
 [ 10.645504  ]
 [  5.28985596]
 [  5.66001177]
 [  5.96786165]
 [  5.46525097]
 [  5.46509027]
 [  5.47747564]]
DEBUG:root:training time = %d0.233551
INFO:root:frame =6489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =6490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:random_action_porb = 0.948763333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =6493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =6494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.948731666667
DEBUG:root: dqn, choose action rondomly, need time 0.00027
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.98332214]
 [  6.50088167]
 [  5.29930067]
 [  5.55979443]
 [  5.30363989]
 [  5.35074425]
 [  5.45685339]
 [  5.23722267]
 [ 11.39757824]
 [  5.67881346]
 [  5.99037886]
 [  5.26076746]
 [  5.60634041]
 [  6.07182598]
 [  5.51086283]
 [  5.27151728]]
DEBUG:root:training time = %d0.19679
INFO:root:frame =6497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =6498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298023223877
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.9487
DEBUG:root: dqn, choose action rondomly, need time 0.000257000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =6501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =6502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049090385437
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:random_action_porb = 0.948668333333
INFO:root:dqn select action Tensor("ArgMax_43:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00785200000001
INFO:root:action choosen by dqn [4]
INFO:root:frame =6504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.66952801]
 [  5.95452404]
 [ 11.08883572]
 [  6.20050716]
 [  5.42171144]
 [  5.31830359]
 [  5.34167719]
 [  5.79150772]
 [  6.3008194 ]
 [  4.96589088]
 [  5.80541515]
 [  5.21970749]
 [  5.93586588]
 [  5.18539095]
 [  5.74862385]
 [  5.63709211]]
DEBUG:root:training time = %d0.1931
INFO:root:frame =6505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280857086182
INFO:root:frame =6506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247001647949
DEBUG:root: save sample needs time = 0.000108003616333
INFO:root:random_action_porb = 0.948636666667
DEBUG:root: dqn, choose action rondomly, need time 0.00016500000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:frame =6509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =6510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:random_action_porb = 0.948605
DEBUG:root: dqn, choose action rondomly, need time 0.000443999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.72306108]
 [  6.06197882]
 [  6.37707758]
 [ 11.52550983]
 [  6.40193605]
 [  5.53090477]
 [  5.78956175]
 [  5.20873213]
 [  6.62931252]
 [  6.49498844]
 [  6.37707758]
 [  6.82339859]
 [  6.98757458]
 [  5.48104715]
 [  5.451437  ]
 [  5.79130602]]
DEBUG:root:training time = %d0.229325
INFO:root:frame =6513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000359058380127
INFO:root:frame =6514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411033630371
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.948573333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =6517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =6518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.948541666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.9891324 ]
 [ 6.25954056]
 [ 5.2343421 ]
 [ 5.27209568]
 [ 5.36054325]
 [ 6.13353205]
 [ 6.1875577 ]
 [ 7.05979872]
 [ 6.48653364]
 [ 6.69204521]
 [ 5.47756481]
 [ 6.55618525]
 [ 5.89319038]
 [ 5.22914219]
 [ 5.18518257]
 [ 6.28292608]]
DEBUG:root:training time = %d0.216318
INFO:root:frame =6521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =6522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000383138656616
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.94851
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000360012054443
INFO:root:frame =6525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =6526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000593185424805
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.948478333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000015
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.9878583 ]
 [  6.70450497]
 [  5.28559303]
 [  6.17509556]
 [  5.9878583 ]
 [  5.4093008 ]
 [  5.09701109]
 [  5.44098568]
 [ 12.32132053]
 [  5.09701109]
 [  5.43660831]
 [  6.11859512]
 [  6.19053745]
 [  5.44098568]
 [ 12.32132053]
 [ 12.18692875]]
DEBUG:root:training time = %d0.226931
INFO:root:frame =6529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270843505859
INFO:root:frame =6530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.948446666667
INFO:root:dqn select action Tensor("ArgMax_44:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010085
INFO:root:action choosen by dqn [4]
INFO:root:frame =6532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root:frame =6533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =6534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.948415
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999983
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.45757484]
 [  5.29169893]
 [  6.58548164]
 [  5.97306252]
 [  5.50069475]
 [  6.43313074]
 [  6.15505314]
 [  5.74399662]
 [  6.32577848]
 [  6.02336359]
 [  6.51791334]
 [  5.75455189]
 [  5.29169893]
 [ 12.79375267]
 [  5.79051638]
 [  5.59002161]]
DEBUG:root:training time = %d0.204871
INFO:root:frame =6537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =6538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:random_action_porb = 0.948383333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000358104705811
INFO:root:frame =6541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =6542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root:frame = 6543 State into memory, numbers recorded 179 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:random_action_porb = 0.948351666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6544current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.06808519]
 [  5.810637  ]
 [  5.6664753 ]
 [  5.43534565]
 [ 11.43495655]
 [  5.43534565]
 [  6.01447248]
 [  5.86006594]
 [  5.6129899 ]
 [  6.93590021]
 [  5.41913605]
 [  5.49157286]
 [  6.4854455 ]
 [  5.19526386]
 [  5.47956467]
 [  5.50275278]]
DEBUG:root:training time = %d0.207063
INFO:root:frame =6545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =6546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.94832
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =6549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =6550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.948288333333
DEBUG:root: dqn, choose action rondomly, need time 0.000323999999978
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.28650522]
 [  5.66021156]
 [  5.61118269]
 [  5.4221735 ]
 [  5.66021156]
 [  6.01117992]
 [  5.79881763]
 [  5.87265015]
 [  5.38613415]
 [  6.11593437]
 [  6.26987123]
 [  6.26987123]
 [  5.47324419]
 [  5.41066742]
 [ 11.8202095 ]
 [  5.81326723]]
DEBUG:root:training time = %d0.217111
INFO:root:frame =6553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =6554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000348091125488
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.948256666667
DEBUG:root: dqn, choose action rondomly, need time 0.000184000000019
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185012817383
INFO:root:frame =6557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000550985336304
INFO:root:frame =6558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00420808792114
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.948225
DEBUG:root: dqn, choose action rondomly, need time 0.000571000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 6.27812672]
 [ 5.77897453]
 [ 5.34442806]
 [ 5.598557  ]
 [ 6.1347599 ]
 [ 6.54089832]
 [ 6.10910606]
 [ 6.48301697]
 [ 5.49005318]
 [ 5.91126204]
 [ 5.49005318]
 [ 5.89065313]
 [ 5.95701885]
 [ 5.69416857]
 [ 2.1900034 ]
 [ 6.60313368]]
DEBUG:root:training time = %d0.200782
INFO:root:frame =6561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028920173645
INFO:root:frame =6562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248908996582
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:random_action_porb = 0.948193333333
DEBUG:root: dqn, choose action rondomly, need time 0.000219000000016
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000140190124512
INFO:root:frame =6565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =6566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000223875045776
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:random_action_porb = 0.948161666667
DEBUG:root: dqn, choose action rondomly, need time 0.000174000000015
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180959701538
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.91246796]
 [  5.73310375]
 [ 11.88945389]
 [  6.34796095]
 [  7.26133728]
 [  5.53189182]
 [  5.65955782]
 [  5.72488642]
 [  5.96665001]
 [  5.81954145]
 [  5.44532871]
 [  6.48060846]
 [  5.4097271 ]
 [  6.02692175]
 [  5.79382133]
 [  5.49107218]]
DEBUG:root:training time = %d0.182859
INFO:root:frame =6569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =6570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00029993057251
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:random_action_porb = 0.94813
DEBUG:root: dqn, choose action rondomly, need time 0.000236000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:frame =6573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =6574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000343799591064
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:random_action_porb = 0.948098333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000270843505859
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.35996056]
 [  6.04399681]
 [  6.28323174]
 [  6.79628181]
 [  7.0361619 ]
 [ 13.65959167]
 [  6.77354717]
 [  6.58052921]
 [  6.01821518]
 [  5.37542677]
 [  6.26081944]
 [  5.51365757]
 [  7.5222497 ]
 [  6.47497702]
 [  6.42502499]
 [  5.32757998]]
DEBUG:root:training time = %d0.207657
INFO:root:frame =6577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =6578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.948066666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame =6581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000389814376831
INFO:root:frame =6582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:random_action_porb = 0.948035
DEBUG:root: dqn, choose action rondomly, need time 0.000243000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.03237343]
 [  5.7316246 ]
 [  5.66491365]
 [  5.90367794]
 [  5.5435977 ]
 [  6.42788744]
 [  5.57828474]
 [  6.22012854]
 [  6.2703681 ]
 [  5.94771242]
 [  5.91202259]
 [  6.24788284]
 [  5.95886278]
 [ 10.99202347]
 [  6.86129665]
 [  6.36654329]]
DEBUG:root:training time = %d0.214849
INFO:root:frame =6585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =6586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000300884246826
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:random_action_porb = 0.948003333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =6589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000424146652222
INFO:root:frame =6590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.947971666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.87930775]
 [  6.52576542]
 [  6.1977911 ]
 [  5.86335373]
 [ 11.83382702]
 [  6.19473314]
 [  5.52199078]
 [  6.80742455]
 [  6.71031427]
 [  6.1977911 ]
 [  7.12931824]
 [  6.54308414]
 [  6.61721754]
 [  6.73545694]
 [ 12.24671555]
 [  5.71818876]]
DEBUG:root:training time = %d0.215946
INFO:root:frame =6593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =6594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000253915786743
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.94794
INFO:root:dqn select action Tensor("ArgMax_45:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011496
INFO:root:action choosen by dqn [4]
INFO:root:frame =6596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:frame =6597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243186950684
INFO:root:frame =6598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.947908333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.6325922 ]
 [  6.00510216]
 [  6.07690287]
 [  5.64680576]
 [  5.53654003]
 [  6.02489901]
 [  5.77673721]
 [  5.77396822]
 [  6.25910139]
 [  5.5740509 ]
 [  5.65736198]
 [  5.67495966]
 [  6.68687534]
 [  5.95113611]
 [  6.32739019]
 [  6.23865652]]
DEBUG:root:training time = %d0.222598
INFO:root:frame =6601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =6602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000250101089478
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:random_action_porb = 0.947876666667
DEBUG:root: dqn, choose action rondomly, need time 0.000380000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =6605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =6606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
DEBUG:root: save sample needs time = 0.00018310546875
INFO:root:random_action_porb = 0.947845
DEBUG:root: dqn, choose action rondomly, need time 0.000231000000014
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000411033630371
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.51362133]
 [  6.16705942]
 [  4.9648366 ]
 [ 11.34447765]
 [ 11.53535461]
 [  6.35888386]
 [  5.51362133]
 [  5.50345087]
 [  6.02328873]
 [  5.8751092 ]
 [  6.51627731]
 [ 11.94344425]
 [  5.50481081]
 [ 11.00948334]
 [  5.47419024]
 [ 12.34578323]]
DEBUG:root:training time = %d0.21299
INFO:root:frame =6609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000358104705811
INFO:root:frame =6610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:random_action_porb = 0.947813333333
INFO:root:dqn select action Tensor("ArgMax_46:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014969
INFO:root:action choosen by dqn [4]
INFO:root:frame =6612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =6613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000342845916748
INFO:root:frame =6614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000187873840332
INFO:root:random_action_porb = 0.947781666667
DEBUG:root: dqn, choose action rondomly, need time 0.000278000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.69865894]
 [  6.02268934]
 [  6.13173676]
 [  5.77332687]
 [  5.32645273]
 [  5.25849295]
 [  5.75927496]
 [  6.7781744 ]
 [ 13.09635639]
 [  6.62685728]
 [  6.32082844]
 [  6.30616331]
 [  5.82105064]
 [  5.30544949]
 [  6.30616331]
 [  5.88039923]]
DEBUG:root:training time = %d0.209854
INFO:root:frame =6617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =6618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000406980514526
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.94775
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =6621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =6622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:random_action_porb = 0.947718333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.82244968]
 [ 11.92957878]
 [  6.44801998]
 [  6.11314249]
 [  6.42110014]
 [  5.82653761]
 [  6.06241083]
 [  6.14807081]
 [  6.16687012]
 [  6.07553005]
 [  6.20793772]
 [  2.24543619]
 [  6.17083025]
 [  6.20959139]
 [  5.84432268]
 [  5.92156172]]
DEBUG:root:training time = %d0.216428
INFO:root:frame =6625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000330209732056
INFO:root:frame =6626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.947686666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =6629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =6630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame = 6631 State into memory, numbers recorded 180 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000546932220459
INFO:root:random_action_porb = 0.947655
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6632current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.72371817]
 [  6.81190395]
 [  6.38611698]
 [ 12.42972374]
 [  5.76030016]
 [  5.91636419]
 [  5.87923384]
 [  5.90195417]
 [  5.98067284]
 [  6.17253637]
 [  6.41557217]
 [  5.59159088]
 [  6.17253637]
 [ 11.57093334]
 [  6.05116367]
 [  6.36827612]]
DEBUG:root:training time = %d0.228032
INFO:root:frame =6633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =6634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000420808792114
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.947623333333
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:frame =6637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame =6638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:random_action_porb = 0.947591666667
DEBUG:root: dqn, choose action rondomly, need time 0.000279000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365972518921
INFO:root:training error  = [[ 6.77003288]
 [ 6.83143234]
 [ 6.05341625]
 [ 6.51543999]
 [ 7.13072348]
 [ 6.476336  ]
 [ 5.8501339 ]
 [ 6.01759768]
 [ 5.92436552]
 [ 5.544837  ]
 [ 7.54235077]
 [ 5.77635193]
 [ 6.35178661]
 [ 6.83143234]
 [ 5.73898792]
 [ 6.37892723]]
DEBUG:root:training time = %d0.205402
INFO:root:frame =6641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =6642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.94756
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =6645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =6646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.947528333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000015
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.28818607]
 [  6.00048494]
 [  6.16817713]
 [  6.25915861]
 [  5.79802752]
 [  6.25915861]
 [  5.55330181]
 [  6.23497915]
 [  5.94350767]
 [  5.91823864]
 [  6.31404018]
 [  5.38616943]
 [  7.30915356]
 [  5.68281412]
 [ 11.52810001]
 [  5.67332411]]
DEBUG:root:training time = %d0.213968
INFO:root:frame =6649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000401973724365
INFO:root:frame =6650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:random_action_porb = 0.947496666667
DEBUG:root: dqn, choose action rondomly, need time 0.000272000000024
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =6653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:frame =6654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000591039657593
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:random_action_porb = 0.947465
DEBUG:root: dqn, choose action rondomly, need time 0.000272999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:training error  = [[ 5.78521204]
 [ 6.32675695]
 [ 6.01976871]
 [ 5.5937562 ]
 [ 5.43790722]
 [ 6.03261709]
 [ 6.22418213]
 [ 6.2964344 ]
 [ 5.33596516]
 [ 6.97344446]
 [ 5.97399473]
 [ 5.70644569]
 [ 5.6294508 ]
 [ 6.3862133 ]
 [ 5.66732883]
 [ 5.90931463]]
DEBUG:root:training time = %d0.184229
INFO:root:frame =6657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =6658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
DEBUG:root: save sample needs time = 0.00015115737915
INFO:root:random_action_porb = 0.947433333333
DEBUG:root: dqn, choose action rondomly, need time 0.00017299999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174999237061
INFO:root:frame =6661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000352144241333
INFO:root:frame =6662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.947401666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:training error  = [[ 5.79810095]
 [ 6.81403494]
 [ 6.14296389]
 [ 5.83466196]
 [ 5.59142876]
 [ 6.53260803]
 [ 6.44035053]
 [ 6.32151937]
 [ 6.41159201]
 [ 5.77129221]
 [ 7.10991764]
 [ 5.90823889]
 [ 5.79867077]
 [ 5.97483397]
 [ 6.26114368]
 [ 6.53260803]]
DEBUG:root:training time = %d0.204133
INFO:root:frame =6665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =6666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame = 6667 State into memory, numbers recorded 181 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000539064407349
INFO:root:random_action_porb = 0.94737
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6668current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =6669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =6670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000318050384521
DEBUG:root: save sample needs time = 0.000152111053467
INFO:root:random_action_porb = 0.947338333333
DEBUG:root: dqn, choose action rondomly, need time 0.000243000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:training error  = [[ 6.30944014]
 [ 6.17729473]
 [ 6.45807886]
 [ 5.99374056]
 [ 6.7536459 ]
 [ 6.32412815]
 [ 6.47736502]
 [ 6.6513319 ]
 [ 5.47217369]
 [ 6.47736502]
 [ 6.94528675]
 [ 5.65331602]
 [ 7.40832949]
 [ 6.31267929]
 [ 5.73009014]
 [ 7.711689  ]]
DEBUG:root:training time = %d0.204883
INFO:root:frame =6673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =6674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.947306666667
DEBUG:root: dqn, choose action rondomly, need time 0.000243999999981
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =6677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =6678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000289916992188
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.947275
DEBUG:root: dqn, choose action rondomly, need time 0.000462999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325202941895
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.44364262]
 [  6.09047079]
 [  5.7679019 ]
 [  6.02482414]
 [  6.30942106]
 [  6.40411758]
 [  6.34029341]
 [  6.05200863]
 [  6.04048967]
 [ 11.50096893]
 [  6.26368332]
 [  6.64661074]
 [  6.0524025 ]
 [  5.74346638]
 [  6.53734779]
 [  6.08260298]]
DEBUG:root:training time = %d0.204635
INFO:root:frame =6681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =6682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00020694732666
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.947243333333
DEBUG:root: dqn, choose action rondomly, need time 0.00027
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =6685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000530958175659
INFO:root:frame =6686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000591039657593
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.947211666667
DEBUG:root: dqn, choose action rondomly, need time 0.00027
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 5.33661747]
 [ 5.52683258]
 [ 5.70910692]
 [ 5.70910692]
 [ 5.84913731]
 [ 6.59241438]
 [ 6.28367186]
 [ 5.28634739]
 [ 6.2808032 ]
 [ 5.92598104]
 [ 6.25190735]
 [ 5.93220425]
 [ 6.45338774]
 [ 6.9016242 ]
 [ 6.23168373]
 [ 6.26200294]]
DEBUG:root:training time = %d0.23659
INFO:root:frame =6689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =6690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411033630371
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:random_action_porb = 0.94718
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =6693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =6694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000581979751587
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.947148333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.22079468]
 [ 11.94333839]
 [  7.88333559]
 [  5.79859734]
 [  6.00364399]
 [  5.86741877]
 [ 13.15661526]
 [  5.86411142]
 [  6.51567364]
 [  6.8039217 ]
 [  6.36142349]
 [  5.85823774]
 [ 12.31896305]
 [  6.41346598]
 [  5.88745022]
 [  5.93060637]]
DEBUG:root:training time = %d0.207166
INFO:root:frame =6697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =6698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.947116666667
DEBUG:root: dqn, choose action rondomly, need time 0.000225
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:frame =6701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =6702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root:random_action_porb = 0.947085
INFO:root:dqn select action Tensor("ArgMax_47:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013016
INFO:root:action choosen by dqn [4]
INFO:root:frame =6704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.36101723]
 [ 11.83624172]
 [  5.84544754]
 [ 11.83624172]
 [  6.10571241]
 [  6.22250748]
 [  6.01527739]
 [  6.29519033]
 [  6.12112427]
 [  6.39496946]
 [  6.67315102]
 [  5.84666491]
 [  6.69717789]
 [  6.06158447]
 [  5.65433168]
 [  6.16993952]]
DEBUG:root:training time = %d0.228496
INFO:root:frame =6705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =6706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480175018311
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.947053333333
DEBUG:root: dqn, choose action rondomly, need time 0.00032299999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000187873840332
INFO:root:frame =6709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470876693726
INFO:root:frame =6710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000255823135376
INFO:root:random_action_porb = 0.947021666667
DEBUG:root: dqn, choose action rondomly, need time 0.000261999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.20110226]
 [  6.09742022]
 [  6.71410942]
 [  5.76944113]
 [ 13.53398037]
 [  5.80120611]
 [  6.44664478]
 [  5.75361872]
 [  5.87612629]
 [  6.34509706]
 [  6.65883064]
 [  6.11599112]
 [  2.06470656]
 [  5.09515095]
 [  7.61516953]
 [  5.93051338]]
DEBUG:root:training time = %d0.20132
INFO:root:frame =6713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =6714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.94699
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000011
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =6717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =6718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.946958333333
DEBUG:root: dqn, choose action rondomly, need time 0.000232000000011
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 6.13351297]
 [ 5.87915993]
 [ 6.07607508]
 [ 6.21885395]
 [ 6.15285778]
 [ 6.2798667 ]
 [ 5.82821369]
 [ 5.53194571]
 [ 6.05268431]
 [ 5.86377859]
 [ 6.22606659]
 [ 2.14855099]
 [ 7.0666523 ]
 [ 6.17733288]
 [ 6.17733288]
 [ 5.82821369]]
DEBUG:root:training time = %d0.205373
INFO:root:frame =6721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root:frame =6722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.946926666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =6725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =6726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.946895
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5.95523167]
 [ 5.87943745]
 [ 5.86039829]
 [ 6.89469099]
 [ 5.81908131]
 [ 7.21134233]
 [ 6.40890694]
 [ 5.78875399]
 [ 5.88839436]
 [ 6.09065866]
 [ 5.96467495]
 [ 5.91217136]
 [ 6.411901  ]
 [ 2.08249354]
 [ 5.65360641]
 [ 7.00638342]]
DEBUG:root:training time = %d0.230752
INFO:root:frame =6729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =6730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000320911407471
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.946863333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =6733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =6734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.946831666667
DEBUG:root: dqn, choose action rondomly, need time 0.000197000000014
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000184059143066
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.02549553]
 [  7.40010834]
 [  6.16973114]
 [  5.88067675]
 [  6.32501078]
 [ 11.89437294]
 [  6.60148716]
 [  5.93003035]
 [  7.75730801]
 [  6.33007717]
 [  6.60550642]
 [ 12.21472454]
 [ 13.71618652]
 [  5.98377037]
 [  5.73948097]
 [  6.2419343 ]]
DEBUG:root:training time = %d0.222368
INFO:root:frame =6737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =6738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9468
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =6741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =6742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.946768333333
DEBUG:root: dqn, choose action rondomly, need time 0.000364000000019
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.26616573]
 [  6.39043617]
 [  6.64476156]
 [ 13.33696747]
 [  5.94843769]
 [  6.498528  ]
 [  6.88818169]
 [  6.36475325]
 [  6.91132879]
 [  5.93023491]
 [  6.79345751]
 [  6.17077351]
 [  6.49014807]
 [  5.7723918 ]
 [  5.82379389]
 [ 12.79790115]]
DEBUG:root:training time = %d0.216376
INFO:root:frame =6745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =6746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509977340698
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.946736666667
DEBUG:root: dqn, choose action rondomly, need time 0.000276000000014
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =6749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =6750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000361204147339
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.946705
INFO:root:dqn select action Tensor("ArgMax_48:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010876
INFO:root:action choosen by dqn [4]
INFO:root:frame =6752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.75323391]
 [ 13.5864048 ]
 [  6.54642153]
 [ 12.2177372 ]
 [ 12.18964577]
 [  6.18429375]
 [  6.95170259]
 [  7.04203176]
 [  6.17934275]
 [  6.1426425 ]
 [  7.26037121]
 [  6.2790637 ]
 [  6.18010139]
 [  5.60355854]
 [  6.51292801]
 [  5.81906319]]
DEBUG:root:training time = %d0.227191
INFO:root:frame =6753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =6754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000300168991089
DEBUG:root: save sample needs time = 0.000120162963867
INFO:root:random_action_porb = 0.946673333333
DEBUG:root: dqn, choose action rondomly, need time 0.000187000000011
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016713142395
INFO:root:frame =6757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =6758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:random_action_porb = 0.946641666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.54711866]
 [ 12.59453297]
 [  5.74074221]
 [  6.47684097]
 [  6.26862955]
 [  6.00241041]
 [  6.68225956]
 [  6.22098494]
 [ 12.73800755]
 [  5.79595184]
 [  6.34751892]
 [  6.238904  ]
 [  7.59173346]
 [  6.49625254]
 [ 13.2605114 ]
 [  6.37838793]]
DEBUG:root:training time = %d0.219001
INFO:root:frame =6761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279188156128
INFO:root:frame =6762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000419139862061
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.94661
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999983
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =6765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =6766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000409841537476
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.946578333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999985
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.85957813]
 [  6.02456188]
 [  5.55517197]
 [  6.88968372]
 [  5.89691353]
 [  6.34938335]
 [  5.89176416]
 [  7.27044773]
 [ 12.07929993]
 [  7.08971071]
 [  6.63481426]
 [  6.83745575]
 [  6.39093781]
 [  6.98981333]
 [  6.06072044]
 [ 11.4880352 ]]
DEBUG:root:training time = %d0.227792
INFO:root:frame =6769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =6770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000302076339722
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.946546666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =6773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame =6774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.946515
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.18507147]
 [ 12.29821968]
 [  5.6284008 ]
 [  6.79309988]
 [  6.19630957]
 [  6.86461449]
 [  6.09644079]
 [  6.16770363]
 [  5.84941435]
 [  6.08742094]
 [  7.10802555]
 [  6.30284929]
 [  5.67483234]
 [  5.86501646]
 [  6.45856333]
 [  6.19630957]]
DEBUG:root:training time = %d0.211447
INFO:root:frame =6777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:frame =6778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000367879867554
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.946483333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =6781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464200973511
INFO:root:frame =6782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.946451666667
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.74650478]
 [  6.1758914 ]
 [  6.29936409]
 [ 12.03926754]
 [  6.48284197]
 [  6.38611698]
 [  6.56095266]
 [  6.2595787 ]
 [ 12.33581257]
 [  6.78906393]
 [  5.83466196]
 [  6.61064482]
 [  6.19378376]
 [  6.37247372]
 [  6.47214317]
 [  6.33345604]]
DEBUG:root:training time = %d0.222555
INFO:root:frame =6785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000360012054443
INFO:root:frame =6786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000337839126587
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:random_action_porb = 0.94642
DEBUG:root: dqn, choose action rondomly, need time 0.000279999999975
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =6789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =6790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.946388333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.70077181]
 [ 12.70888901]
 [  6.9133544 ]
 [  6.39454508]
 [ 12.56774235]
 [  6.7579689 ]
 [  6.54970121]
 [  6.27743864]
 [  6.65542507]
 [  6.21023798]
 [  6.96111965]
 [ 13.40752506]
 [  6.23776102]
 [  6.26322508]
 [  6.49691391]
 [  6.09921026]]
DEBUG:root:training time = %d0.231713
INFO:root:frame =6793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =6794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 0.000116109848022
INFO:root:random_action_porb = 0.946356666667
DEBUG:root: dqn, choose action rondomly, need time 0.000329999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =6797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =6798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.946325
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14.27925014]
 [  6.20179939]
 [  7.27011871]
 [ 14.84052849]
 [  7.24890471]
 [  6.59313917]
 [  6.28284931]
 [  6.41655779]
 [  6.13400412]
 [  7.55578756]
 [  6.0633502 ]
 [  6.01443529]
 [  7.95618534]
 [  6.8396306 ]
 [  6.09453821]
 [  6.58358288]]
DEBUG:root:training time = %d0.224628
INFO:root:frame =6801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =6802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000329971313477
DEBUG:root: save sample needs time = 0.000229835510254
INFO:root:random_action_porb = 0.946293333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999974
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =6805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =6806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.946261666667
DEBUG:root: dqn, choose action rondomly, need time 0.000280000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.75202656]
 [  7.1849575 ]
 [  6.62377453]
 [  6.39572191]
 [  6.41477966]
 [  6.35542107]
 [  6.67675829]
 [ 11.9451046 ]
 [  6.21906281]
 [  6.53869343]
 [  5.98856735]
 [  6.30089569]
 [  5.87681055]
 [  6.22587633]
 [  6.00162506]
 [  6.60713387]]
DEBUG:root:training time = %d0.212255
INFO:root:frame =6809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =6810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298023223877
DEBUG:root: save sample needs time = 0.000178098678589
INFO:root:random_action_porb = 0.94623
DEBUG:root: dqn, choose action rondomly, need time 0.000157000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:frame =6813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =6814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.946198333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.88139534]
 [  7.87622499]
 [ 12.72570324]
 [  6.34148455]
 [  7.23970509]
 [  7.17222261]
 [  6.55645895]
 [  6.62192869]
 [ 13.58896446]
 [  6.69131517]
 [  6.41995955]
 [  8.32270908]
 [  6.60082054]
 [  6.27749586]
 [  6.63471603]
 [  6.92144108]]
DEBUG:root:training time = %d0.233787
INFO:root:frame =6817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000341892242432
INFO:root:frame =6818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.946166666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =6821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =6822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000408887863159
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.946135
DEBUG:root: dqn, choose action rondomly, need time 0.000273000000021
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 6.66737795]
 [ 6.46896029]
 [ 6.32710266]
 [ 6.52264738]
 [ 6.76080561]
 [ 2.28573179]
 [ 7.06529331]
 [ 6.66755533]
 [ 6.6494236 ]
 [ 6.64863682]
 [ 7.23389673]
 [ 6.02257681]
 [ 6.56568289]
 [ 7.29259968]
 [ 6.96486425]
 [ 6.65204048]]
DEBUG:root:training time = %d0.226933
INFO:root:frame =6825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =6826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.946103333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =6829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =6830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.946071666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294000000025
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.08350611]
 [  6.57403326]
 [  6.1882596 ]
 [  7.30201864]
 [ 12.8568964 ]
 [  6.64580393]
 [  7.3519125 ]
 [  6.63000011]
 [  6.70821953]
 [  6.92214346]
 [  6.92035723]
 [  6.6537919 ]
 [  6.90763855]
 [  6.62638617]
 [  6.0229888 ]
 [  6.72488785]]
DEBUG:root:training time = %d0.220215
INFO:root:frame =6833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249147415161
INFO:root:frame =6834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000401973724365
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.94604
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root:frame =6837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =6838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:random_action_porb = 0.946008333333
DEBUG:root: dqn, choose action rondomly, need time 0.000317999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.08865452]
 [  7.74110317]
 [  6.72563934]
 [  6.70306301]
 [  6.230865  ]
 [ 12.77383995]
 [  6.18006372]
 [  6.2341218 ]
 [  7.37543154]
 [  6.32879162]
 [ 11.97431278]
 [  6.27627277]
 [  6.86215591]
 [  5.84644365]
 [  6.230865  ]
 [  6.7197051 ]]
DEBUG:root:training time = %d0.219127
INFO:root:frame =6841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =6842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000258922576904
DEBUG:root: save sample needs time = 0.000245809555054
INFO:root:random_action_porb = 0.945976666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =6845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =6846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.945945
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root:training error  = [[ 7.10688686]
 [ 7.09023905]
 [ 6.74118042]
 [ 6.28722954]
 [ 6.35771036]
 [ 6.58855581]
 [ 6.33489656]
 [ 7.16827965]
 [ 6.09378481]
 [ 7.1129694 ]
 [ 6.1171422 ]
 [ 6.08815479]
 [ 6.84505892]
 [ 6.13309717]
 [ 7.14028168]
 [ 6.23288393]]
DEBUG:root:training time = %d0.221479
INFO:root:frame =6849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270843505859
INFO:root:frame =6850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.945913333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =6853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =6854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.945881666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.93019533]
 [  7.97711658]
 [  6.54269361]
 [  6.87635326]
 [  7.10279942]
 [  6.85072851]
 [  6.42440653]
 [  6.16090345]
 [  6.66997862]
 [  6.24563313]
 [  6.9386735 ]
 [ 11.79614258]
 [  6.38492155]
 [  7.36476469]
 [  6.90848064]
 [  6.60156536]]
DEBUG:root:training time = %d0.214078
INFO:root:frame =6857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =6858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000357151031494
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:random_action_porb = 0.94585
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =6861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =6862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000498056411743
INFO:root:frame = 6863 State into memory, numbers recorded 182 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000586032867432
INFO:root:random_action_porb = 0.945818333333
DEBUG:root: dqn, choose action rondomly, need time 0.000235000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6864current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000258207321167
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.62361717]
 [  6.71814251]
 [  6.53606033]
 [  6.15550756]
 [  6.47008562]
 [  6.47125006]
 [  6.52027082]
 [  6.42490911]
 [  6.36452198]
 [  7.39987993]
 [  6.74660921]
 [  6.11074686]
 [  7.43476725]
 [ 14.21865654]
 [  7.53208733]
 [  6.83803415]]
DEBUG:root:training time = %d0.225249
INFO:root:frame =6865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =6866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
DEBUG:root: save sample needs time = 0.000108957290649
INFO:root:random_action_porb = 0.945786666667
DEBUG:root: dqn, choose action rondomly, need time 0.000630000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =6869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00061821937561
INFO:root:frame =6870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000500917434692
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:random_action_porb = 0.945755
INFO:root:dqn select action Tensor("ArgMax_49:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013495
INFO:root:action choosen by dqn [4]
INFO:root:frame =6872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162839889526
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.62538433]
 [  7.23188591]
 [  7.61131716]
 [  7.02501535]
 [  7.61131716]
 [  6.58720446]
 [  7.76893568]
 [  6.56493998]
 [  6.41717625]
 [  6.62925386]
 [ 12.1715126 ]
 [  6.57520676]
 [  7.84136295]
 [  6.3201766 ]
 [  6.80583191]
 [  8.51665688]]
DEBUG:root:training time = %d0.208875
INFO:root:frame =6873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =6874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481843948364
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.945723333333
DEBUG:root: dqn, choose action rondomly, need time 0.000272999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000193119049072
INFO:root:frame =6877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =6878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446796417236
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.945691666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.63070774]
 [  7.08018637]
 [  7.50451565]
 [  6.82740498]
 [  7.33066177]
 [  6.63070774]
 [  6.80613089]
 [ 13.97908211]
 [  6.10329962]
 [ 14.04359531]
 [  7.12153816]
 [  6.66369438]
 [  6.316782  ]
 [  7.51287794]
 [  6.0689311 ]
 [  6.60646725]]
DEBUG:root:training time = %d0.201232
INFO:root:frame =6881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =6882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.94566
DEBUG:root: dqn, choose action rondomly, need time 0.000184999999988
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000172138214111
INFO:root:frame =6885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =6886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487089157104
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.945628333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.44787884]
 [  7.08605433]
 [  7.92155457]
 [ 12.31901741]
 [  7.47084141]
 [  7.41919374]
 [  6.50776958]
 [  7.64942026]
 [  7.50754642]
 [  6.11548138]
 [  7.88519907]
 [  6.30907583]
 [ 12.69890881]
 [  7.226614  ]
 [  7.57687855]
 [  8.0344944 ]]
DEBUG:root:training time = %d0.194687
INFO:root:frame =6889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =6890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000415802001953
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.945596666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =6893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =6894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.945565
INFO:root:dqn select action Tensor("ArgMax_50:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014912
INFO:root:action choosen by dqn [4]
INFO:root:frame =6896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000381946563721
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.88439608]
 [  6.58749819]
 [  6.35322905]
 [  6.64004278]
 [  6.145082  ]
 [  7.49110365]
 [ 12.74770355]
 [  7.05661678]
 [  6.20710135]
 [  7.02871656]
 [  6.31986952]
 [  6.9305768 ]
 [  6.56134367]
 [  6.31986952]
 [  7.07097292]
 [  7.00149727]]
DEBUG:root:training time = %d0.217196
INFO:root:frame =6897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =6898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.945533333333
DEBUG:root: dqn, choose action rondomly, need time 0.00027
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =6901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470876693726
INFO:root:frame =6902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame = 6903 State into memory, numbers recorded 183 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000535011291504
INFO:root:random_action_porb = 0.945501666667
DEBUG:root: dqn, choose action rondomly, need time 0.000279000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6904current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.52920246]
 [  6.89384985]
 [  6.89984035]
 [  6.84991026]
 [  7.10755777]
 [  7.17222261]
 [  6.41688633]
 [  7.1315999 ]
 [  6.84535789]
 [  6.97709131]
 [  6.91006517]
 [  6.66857958]
 [  7.13785601]
 [  2.8704381 ]
 [  6.66857958]
 [  6.56963253]]
DEBUG:root:training time = %d0.214093
INFO:root:frame =6905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000418901443481
INFO:root:frame =6906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000278949737549
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.94547
DEBUG:root: dqn, choose action rondomly, need time 0.000214999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =6909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =6910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476121902466
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.945438333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 7.09741211]
 [ 2.64403558]
 [ 7.3917675 ]
 [ 6.88664007]
 [ 6.40539217]
 [ 6.8567009 ]
 [ 6.27849007]
 [ 6.72027874]
 [ 6.71310091]
 [ 6.70711279]
 [ 6.89651442]
 [ 6.8826766 ]
 [ 7.15815163]
 [ 6.03450966]
 [ 6.39929199]
 [ 6.35615206]]
DEBUG:root:training time = %d0.216097
INFO:root:frame =6913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =6914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
DEBUG:root: save sample needs time = 0.000126838684082
INFO:root:random_action_porb = 0.945406666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =6917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =6918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.945375
DEBUG:root: dqn, choose action rondomly, need time 0.000318000000021
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.76630163]
 [  6.71134186]
 [  6.27055883]
 [  6.30664253]
 [  6.62232161]
 [  6.95528364]
 [  6.51020241]
 [  6.63829279]
 [  6.77235603]
 [  7.28899479]
 [  7.49166727]
 [  6.95528364]
 [  6.59096479]
 [  6.27055883]
 [ 12.45690536]
 [  6.79401445]]
DEBUG:root:training time = %d0.197809
INFO:root:frame =6921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =6922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.945343333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =6925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470161437988
INFO:root:frame =6926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000281095504761
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.945311666667
DEBUG:root: dqn, choose action rondomly, need time 0.000331999999986
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.0201025 ]
 [  6.73432827]
 [  6.67064857]
 [  6.87083244]
 [  6.36579227]
 [  6.57072735]
 [  6.4572258 ]
 [  6.8711524 ]
 [  7.19479752]
 [ 12.63623714]
 [  7.19559574]
 [  7.14831638]
 [  6.69198608]
 [  2.51609325]
 [ 12.55614185]
 [  6.50271034]]
DEBUG:root:training time = %d0.21904
INFO:root:frame =6929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:frame =6930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.94528
DEBUG:root: dqn, choose action rondomly, need time 0.000339999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =6933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root:frame =6934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.945248333333
DEBUG:root: dqn, choose action rondomly, need time 0.000266000000011
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.81234217]
 [  7.07137871]
 [  6.4459281 ]
 [  6.72995329]
 [  6.34980631]
 [  7.26164579]
 [  6.43506575]
 [  7.81568289]
 [  6.68107653]
 [  7.08120155]
 [  6.68713188]
 [  7.0209918 ]
 [  6.71741104]
 [  7.04089832]
 [ 13.09011745]
 [ 13.54066181]]
DEBUG:root:training time = %d0.219799
INFO:root:frame =6937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =6938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.945216666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433206558228
INFO:root:frame =6942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.945185
DEBUG:root: dqn, choose action rondomly, need time 0.000191000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000150918960571
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.92360926]
 [  6.48993444]
 [ 12.79642773]
 [  7.35404348]
 [  7.91270971]
 [  6.47806406]
 [  6.86913252]
 [  2.68480802]
 [  7.37715101]
 [  7.6979661 ]
 [  6.22758961]
 [  6.37607574]
 [  7.36851263]
 [  7.47734928]
 [  7.05343485]
 [  7.38517284]]
DEBUG:root:training time = %d0.220868
INFO:root:frame =6945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =6946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000396013259888
DEBUG:root: save sample needs time = 0.000248193740845
INFO:root:random_action_porb = 0.945153333333
DEBUG:root: dqn, choose action rondomly, need time 0.000383999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00051212310791
INFO:root:frame =6949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =6950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000300884246826
DEBUG:root: save sample needs time = 0.000174045562744
INFO:root:random_action_porb = 0.945121666667
DEBUG:root: dqn, choose action rondomly, need time 0.000421999999986
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.50989103]
 [  7.77153015]
 [  7.1321907 ]
 [  6.47839451]
 [ 12.75173473]
 [  6.77170038]
 [  7.5625    ]
 [  7.22390699]
 [  6.50665998]
 [  6.34928703]
 [  6.86975241]
 [ 14.6463356 ]
 [  7.27489185]
 [  6.40985346]
 [  6.98543692]
 [  7.37582493]]
DEBUG:root:training time = %d0.213422
INFO:root:frame =6953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =6954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:random_action_porb = 0.94509
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999983
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =6957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =6958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.945058333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.74771881]
 [ 14.30924892]
 [ 14.738307  ]
 [  7.5022378 ]
 [  6.6309042 ]
 [  6.9442215 ]
 [  7.31247473]
 [  7.72964478]
 [  7.31247473]
 [  7.04972744]
 [  6.45491886]
 [  7.31255722]
 [  7.0866437 ]
 [  7.74921417]
 [  6.26209831]
 [  6.72949839]]
DEBUG:root:training time = %d0.227798
INFO:root:frame =6961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.945026666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =6965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =6966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.944995
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.11429214]
 [  6.41130209]
 [  6.75757217]
 [  6.41651917]
 [  7.11771107]
 [  6.63349771]
 [  7.37116385]
 [  7.16162252]
 [  7.13104963]
 [  7.07497025]
 [  7.10164022]
 [  7.52794218]
 [ 14.08448124]
 [  7.71418905]
 [  6.41651917]
 [  7.69161701]]
DEBUG:root:training time = %d0.216779
INFO:root:frame =6969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =6970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.944963333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =6973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =6974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.944931666667
DEBUG:root: dqn, choose action rondomly, need time 0.00018399999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.67585182]
 [  6.81343746]
 [  7.76323748]
 [  6.66326141]
 [  8.04321194]
 [  6.41862583]
 [ 12.32209682]
 [  6.63280964]
 [  7.54886866]
 [  6.92587757]
 [  6.84272337]
 [  8.20180988]
 [ 12.74691391]
 [  7.71887302]
 [  7.15760088]
 [ 13.49754524]]
DEBUG:root:training time = %d0.205498
INFO:root:frame =6977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root:frame =6978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000281095504761
DEBUG:root: save sample needs time = 0.000121831893921
INFO:root:random_action_porb = 0.9449
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =6981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =6982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.944868333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.94940948]
 [  6.54238129]
 [ 15.68416119]
 [  7.19946432]
 [  6.90092278]
 [  6.56822443]
 [  7.16568613]
 [  7.36366701]
 [  6.48843765]
 [  6.66028786]
 [  7.17534924]
 [  6.55124378]
 [  6.73502111]
 [  7.26545   ]
 [  7.45787621]
 [  6.59944868]]
DEBUG:root:training time = %d0.230365
INFO:root:frame =6985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229835510254
INFO:root:frame =6986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234127044678
DEBUG:root: save sample needs time = 9.41753387451e-05
INFO:root:random_action_porb = 0.944836666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =6989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =6990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:random_action_porb = 0.944805
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:training error  = [[ 8.66208458]
 [ 7.55884981]
 [ 7.97806454]
 [ 8.00236988]
 [ 8.68250751]
 [ 6.3318243 ]
 [ 6.75428057]
 [ 6.97054338]
 [ 7.4679637 ]
 [ 7.91236639]
 [ 7.367208  ]
 [ 8.26213741]
 [ 7.17177343]
 [ 6.73288298]
 [ 8.00236988]
 [ 7.42987919]]
DEBUG:root:training time = %d0.228749
INFO:root:frame =6993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =6994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000608921051025
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.944773333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999986
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000360012054443
INFO:root:frame =6997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =6998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000418901443481
DEBUG:root: save sample needs time = 0.000281810760498
DEBUG:root:one frame running time = 0.00625500000001
DEBUG:root:total training time = 184.104791
INFO:root:frame num = 7000 frame round: 0
INFO:root:random_action_porb = 0.944741666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.01545429]
 [  7.17240667]
 [  8.12901592]
 [  7.61314821]
 [  6.55485725]
 [  7.13948679]
 [  7.0194149 ]
 [ 14.27927876]
 [ 14.05071545]
 [  8.4237318 ]
 [  7.01062489]
 [  7.20755291]
 [  7.91522121]
 [  7.51442575]
 [  6.87417269]
 [  8.46372604]]
DEBUG:root:training time = %d0.200462
INFO:root:frame =7001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =7002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.94471
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999983
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =7005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000492095947266
INFO:root:frame =7006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.944678333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 7.68802023]
 [ 7.14639902]
 [ 3.04267859]
 [ 8.05461884]
 [ 6.21282387]
 [ 7.45189762]
 [ 7.10068464]
 [ 7.1311717 ]
 [ 3.04267859]
 [ 7.26028919]
 [ 7.23835039]
 [ 7.229424  ]
 [ 7.25656843]
 [ 7.10068464]
 [ 7.27151775]
 [ 7.25811005]]
DEBUG:root:training time = %d0.205329
INFO:root:frame =7009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root:frame =7010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00048303604126
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.944646666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =7013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00050687789917
INFO:root:frame =7014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.944615
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.05072021]
 [  6.75360632]
 [  7.53282022]
 [  6.60133028]
 [ 13.90168667]
 [  7.66622591]
 [  7.09913969]
 [  8.36281586]
 [  2.59932971]
 [  7.26104975]
 [  6.22161293]
 [  7.84285831]
 [  8.36281586]
 [  6.7374568 ]
 [  6.65475607]
 [  7.05035543]]
DEBUG:root:training time = %d0.21193
INFO:root:frame =7017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =7018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.944583333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =7021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:frame =7022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.944551666667
DEBUG:root: dqn, choose action rondomly, need time 0.00031199999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000368118286133
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.02098513]
 [ 6.96766329]
 [ 7.3603549 ]
 [ 7.63261175]
 [ 6.77547312]
 [ 6.81690311]
 [ 8.09980679]
 [ 7.61559057]
 [ 8.14318275]
 [ 7.82884836]
 [ 8.44036961]
 [ 6.47786999]
 [ 7.87733889]
 [ 7.52882147]
 [ 8.09980679]
 [ 6.98007441]]
DEBUG:root:training time = %d0.226742
INFO:root:frame =7025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =7026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.94452
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =7029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =7030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229120254517
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:random_action_porb = 0.944488333333
DEBUG:root: dqn, choose action rondomly, need time 0.000479000000013
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.00295067]
 [  7.67901134]
 [ 14.04079342]
 [  7.31404257]
 [  6.89184666]
 [  7.01016045]
 [  6.87195253]
 [  7.36350155]
 [  6.9663744 ]
 [  7.48064566]
 [  6.8485322 ]
 [  7.15435553]
 [  6.93186235]
 [  7.05329323]
 [  7.69024181]
 [  6.73727846]]
DEBUG:root:training time = %d0.226226
INFO:root:frame =7033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =7034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000419139862061
DEBUG:root: save sample needs time = 0.000115871429443
INFO:root:random_action_porb = 0.944456666667
DEBUG:root: dqn, choose action rondomly, need time 0.000223000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000229835510254
INFO:root:frame =7037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =7038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469207763672
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.944425
DEBUG:root: dqn, choose action rondomly, need time 0.000340999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000504970550537
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.6764822 ]
 [  7.01329184]
 [  6.99213314]
 [  7.4001708 ]
 [  8.14279079]
 [  7.54232979]
 [  7.14825535]
 [  6.65701962]
 [ 13.71237183]
 [  8.23925877]
 [  7.79818153]
 [  7.33049679]
 [  8.57310295]
 [  6.43065405]
 [  7.53020287]
 [  7.10420227]]
DEBUG:root:training time = %d0.203138
INFO:root:frame =7041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =7042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:random_action_porb = 0.944393333333
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =7045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000608921051025
INFO:root:frame =7046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000304937362671
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.944361666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.22597837]
 [  7.1503768 ]
 [  7.40621138]
 [  7.56797695]
 [  7.41852903]
 [ 13.17890167]
 [  6.8167634 ]
 [  7.17833328]
 [  6.95333195]
 [  7.49941683]
 [  2.65403152]
 [  7.39614487]
 [  6.60683966]
 [  7.3923068 ]
 [  7.2671771 ]
 [  6.97991323]]
DEBUG:root:training time = %d0.212879
INFO:root:frame =7049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =7050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.94433
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root:frame =7053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000364065170288
INFO:root:frame =7054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000505924224854
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.944298333333
DEBUG:root: dqn, choose action rondomly, need time 0.000323000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.21914864]
 [  8.54399776]
 [  7.17469549]
 [  7.17469549]
 [  7.43077374]
 [  7.36758041]
 [  6.43193102]
 [  7.41582775]
 [  6.49611664]
 [  6.81150579]
 [  7.3355999 ]
 [  7.71317196]
 [  7.42588711]
 [  7.97606087]
 [  7.57284689]
 [  7.99902487]]
DEBUG:root:training time = %d0.206289
INFO:root:frame =7057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =7058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279188156128
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.944266666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290999999976
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =7061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =7062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.944235
DEBUG:root: dqn, choose action rondomly, need time 0.000630000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.23012161]
 [  3.10536027]
 [  8.11736012]
 [  7.3107419 ]
 [  8.31032181]
 [  6.8698926 ]
 [  7.79228115]
 [  8.31447887]
 [  7.26662207]
 [  7.65283871]
 [  7.46879768]
 [  7.01286745]
 [  6.80537415]
 [ 14.70426273]
 [  7.31668425]
 [  7.24705601]]
DEBUG:root:training time = %d0.215931
INFO:root:frame =7065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =7066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.944203333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root:frame =7069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =7070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000565052032471
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.944171666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:training error  = [[ 7.78932095]
 [ 7.11441422]
 [ 8.48522472]
 [ 7.33694315]
 [ 6.8382535 ]
 [ 7.7055459 ]
 [ 7.33694315]
 [ 7.19420433]
 [ 6.67809916]
 [ 7.8637042 ]
 [ 7.68027973]
 [ 7.51526213]
 [ 7.09826565]
 [ 7.45441818]
 [ 6.75584698]
 [ 7.11765003]]
DEBUG:root:training time = %d0.220477
INFO:root:frame =7073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =7074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.94414
INFO:root:dqn select action Tensor("ArgMax_51:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00884500000001
INFO:root:action choosen by dqn [4]
INFO:root:frame =7076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000182151794434
INFO:root:frame =7077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =7078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame = 7079 State into memory, numbers recorded 184 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00124001502991
INFO:root:random_action_porb = 0.944108333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7080current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.22651148]
 [  6.67246151]
 [  7.27734089]
 [  7.18080711]
 [  7.30282259]
 [  7.03713322]
 [  7.18786192]
 [ 13.96864414]
 [  7.89055586]
 [  6.94882631]
 [  7.51741648]
 [  7.19234228]
 [  7.27046824]
 [  7.81969357]
 [  6.88904285]
 [  6.78570461]]
DEBUG:root:training time = %d0.20813
INFO:root:frame =7081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =7082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000349998474121
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.944076666667
DEBUG:root: dqn, choose action rondomly, need time 0.000344000000013
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000428199768066
INFO:root:frame =7085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:frame =7086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000417947769165
DEBUG:root: save sample needs time = 0.000188112258911
INFO:root:random_action_porb = 0.944045
DEBUG:root: dqn, choose action rondomly, need time 0.000984999999986
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.97169161]
 [  7.13033676]
 [  7.32636595]
 [  6.80306578]
 [  7.72256184]
 [  7.51231337]
 [  7.25917912]
 [  7.79053497]
 [  8.23674107]
 [  7.95646524]
 [  8.3122797 ]
 [  7.52501202]
 [  7.36755991]
 [  7.61182213]
 [  7.68708944]
 [ 13.60688591]]
DEBUG:root:training time = %d0.220915
INFO:root:frame =7089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =7090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:random_action_porb = 0.944013333333
DEBUG:root: dqn, choose action rondomly, need time 0.00027
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root:frame =7093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000560998916626
INFO:root:frame =7094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000623941421509
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:random_action_porb = 0.943981666667
DEBUG:root: dqn, choose action rondomly, need time 0.000170999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000173091888428
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.35480881]
 [  7.94484854]
 [  7.92503357]
 [  3.39745903]
 [  7.52798414]
 [  7.52800512]
 [  8.94789028]
 [  8.06488609]
 [  7.16107082]
 [  7.46944427]
 [  7.45071077]
 [ 14.09590816]
 [  7.91706705]
 [  7.26917267]
 [  7.16680908]
 [  8.38317013]]
DEBUG:root:training time = %d0.215656
INFO:root:frame =7097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:frame =7098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000225782394409
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.94395
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =7101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =7102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.943918333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000370979309082
INFO:root:training error  = [[ 7.40959597]
 [ 7.41156912]
 [ 7.33493853]
 [ 7.1249795 ]
 [ 7.69887638]
 [ 7.20067215]
 [ 7.16311264]
 [ 6.53009319]
 [ 7.24188137]
 [ 7.3162303 ]
 [ 7.74989367]
 [ 7.27382183]
 [ 7.04162693]
 [ 6.86907244]
 [ 9.15335751]
 [ 7.81992817]]
DEBUG:root:training time = %d0.208078
INFO:root:frame =7105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =7106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame = 7107 State into memory, numbers recorded 185 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000373840332031
INFO:root:random_action_porb = 0.943886666667
DEBUG:root: dqn, choose action rondomly, need time 0.000350999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7108current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =7109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000490188598633
INFO:root:frame =7110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:random_action_porb = 0.943855
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.46303749]
 [  7.04913998]
 [  7.15668201]
 [  7.23937654]
 [ 13.8662653 ]
 [  7.56170273]
 [  7.31140184]
 [ 15.52079391]
 [ 13.73436069]
 [  8.21798611]
 [  7.16368437]
 [  7.40052366]
 [  7.46423244]
 [  7.45779276]
 [  7.99660826]
 [  8.17980003]]
DEBUG:root:training time = %d0.206816
INFO:root:frame =7113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000361919403076
INFO:root:frame =7114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.943823333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =7117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046181678772
INFO:root:frame =7118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000206232070923
INFO:root:random_action_porb = 0.943791666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.29002476]
 [  7.16685009]
 [  7.16685009]
 [  6.93332863]
 [  8.97001839]
 [ 14.33399296]
 [  7.73261452]
 [  8.40445614]
 [  7.49390221]
 [  7.74679279]
 [  6.94725752]
 [  7.32244301]
 [  7.03715324]
 [  7.73261452]
 [  7.32244301]
 [  7.61929655]]
DEBUG:root:training time = %d0.220789
INFO:root:frame =7121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =7122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000635147094727
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root:random_action_porb = 0.94376
DEBUG:root: dqn, choose action rondomly, need time 0.00029600000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =7125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456809997559
INFO:root:frame =7126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.943728333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.96836805]
 [  8.52389431]
 [  7.96912432]
 [  7.88303566]
 [  7.26948118]
 [  8.69807148]
 [  8.26601982]
 [  7.91024208]
 [  7.09865189]
 [  8.18914127]
 [  8.24913883]
 [  6.96836805]
 [  6.99348497]
 [  7.20337486]
 [ 13.38551998]
 [  7.30059624]]
DEBUG:root:training time = %d0.226975
INFO:root:frame =7129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000351190567017
INFO:root:frame =7130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000289916992188
DEBUG:root: save sample needs time = 0.000201225280762
INFO:root:random_action_porb = 0.943696666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =7133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =7134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.943665
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00035285949707
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.22003174]
 [  7.00361729]
 [  8.04039955]
 [  7.13516569]
 [  7.18303537]
 [ 13.61994743]
 [  7.47682762]
 [ 14.85202312]
 [  9.04707336]
 [  8.19460106]
 [  8.06551456]
 [  6.51403809]
 [  8.08752155]
 [  8.10302067]
 [  7.20570946]
 [  8.53465652]]
DEBUG:root:training time = %d0.232144
INFO:root:frame =7137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =7138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000266075134277
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.943633333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =7141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =7142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000665903091431
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.943601666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.57858849]
 [  3.16467571]
 [ 14.65678978]
 [  7.98233223]
 [  7.63048315]
 [ 16.43476868]
 [  7.63632202]
 [  7.19608688]
 [  6.60638857]
 [  8.28520203]
 [  7.44819117]
 [  7.42619896]
 [  7.92604303]
 [  8.15816879]
 [  7.65300798]
 [  8.05873394]]
DEBUG:root:training time = %d0.224182
INFO:root:frame =7145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =7146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000201225280762
INFO:root:random_action_porb = 0.94357
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000023
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =7149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =7150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.943538333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.56282997]
 [  7.76591635]
 [  8.07784748]
 [  7.48471546]
 [  7.55012655]
 [  7.33332682]
 [ 14.64902115]
 [  7.62062311]
 [  7.46091843]
 [  8.7418232 ]
 [  7.4568553 ]
 [  7.27649736]
 [  7.54224586]
 [  7.92206955]
 [  7.01110983]
 [  7.9122591 ]]
DEBUG:root:training time = %d0.220304
INFO:root:frame =7153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =7154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.943506666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000023
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =7157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =7158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame = 7159 State into memory, numbers recorded 186 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000531911849976
INFO:root:random_action_porb = 0.943475
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7160current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.57246923]
 [  6.70102835]
 [  7.34632826]
 [  7.98977041]
 [  7.00353622]
 [  8.57468891]
 [  7.745965  ]
 [  7.94749355]
 [  8.00200272]
 [  7.65689182]
 [ 14.93941784]
 [ 14.52474499]
 [  8.19626045]
 [ 13.50884438]
 [  7.14735794]
 [  7.02659273]]
DEBUG:root:training time = %d0.229039
INFO:root:frame =7161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280141830444
INFO:root:frame =7162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.943443333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999983
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root:frame =7165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =7166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00048303604126
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.943411666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.2812717 ]
 [  7.61780119]
 [ 15.0684433 ]
 [  7.99779463]
 [  7.6603756 ]
 [  7.61068535]
 [  7.89900208]
 [  7.93951607]
 [  8.19412041]
 [  7.99145269]
 [  7.77606106]
 [  7.22979355]
 [  7.59091377]
 [  7.24015665]
 [  8.46485806]
 [  9.22394085]]
DEBUG:root:training time = %d0.229322
INFO:root:frame =7169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =7170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000417947769165
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.94338
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =7173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =7174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.943348333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.47457457]
 [  7.72224379]
 [  7.85335302]
 [  7.98149157]
 [  8.13103867]
 [  8.02984619]
 [  3.02450013]
 [ 13.14687634]
 [  8.96960735]
 [  7.97675037]
 [  7.97675037]
 [  7.23603106]
 [  8.02984619]
 [  8.02984619]
 [ 15.14456272]
 [  8.16629887]]
DEBUG:root:training time = %d0.220145
INFO:root:frame =7177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =7178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.943316666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =7181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:frame =7182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.943285
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.05617809]
 [  7.7924304 ]
 [  7.78340292]
 [  3.08302879]
 [  7.19158506]
 [  9.26321125]
 [  7.45293903]
 [  7.39514875]
 [  7.25336266]
 [  7.74982977]
 [  7.6827116 ]
 [  7.87562561]
 [  7.62711143]
 [  8.05617809]
 [ 17.44275665]
 [  7.79351616]]
DEBUG:root:training time = %d0.208155
INFO:root:frame =7185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =7186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.943253333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =7189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =7190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.943221666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root:training error  = [[ 7.42411995]
 [ 7.1822381 ]
 [ 7.06659126]
 [ 8.61739063]
 [ 8.71932507]
 [ 6.90012121]
 [ 7.27347231]
 [ 8.06614304]
 [ 6.89527225]
 [ 7.86933231]
 [ 7.89201355]
 [ 7.41439438]
 [ 8.12631893]
 [ 7.39749336]
 [ 7.51057816]
 [ 7.79179144]]
DEBUG:root:training time = %d0.240843
INFO:root:frame =7193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =7194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame = 7195 State into memory, numbers recorded 187 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000570058822632
INFO:root:random_action_porb = 0.94319
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7196current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000284194946289
INFO:root:frame =7197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =7198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.943158333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999985
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:training error  = [[ 7.37099791]
 [ 7.53537512]
 [ 7.27528286]
 [ 7.53537512]
 [ 8.03570557]
 [ 8.48149204]
 [ 6.69769144]
 [ 8.86607933]
 [ 7.53537512]
 [ 8.03570557]
 [ 7.76950979]
 [ 7.29595852]
 [ 8.02158928]
 [ 7.72111988]
 [ 7.64157248]
 [ 8.35597801]]
DEBUG:root:training time = %d0.210692
INFO:root:frame =7201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =7202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.943126666667
DEBUG:root: dqn, choose action rondomly, need time 0.000151000000017
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =7205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000481128692627
INFO:root:frame =7206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.943095
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.43629169]
 [ 14.44086361]
 [ 14.44086361]
 [  7.45948076]
 [  7.52995205]
 [  8.13169193]
 [  8.35057545]
 [  3.17471361]
 [  7.64849186]
 [  8.28357697]
 [  7.94852591]
 [  7.71181631]
 [  7.97181654]
 [ 15.47631073]
 [  8.325284  ]
 [  7.05023384]]
DEBUG:root:training time = %d0.236206
INFO:root:frame =7209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =7210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274181365967
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.943063333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =7213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =7214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000418901443481
INFO:root:frame = 7215 State into memory, numbers recorded 188 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000576972961426
INFO:root:random_action_porb = 0.943031666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7216current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.97309208]
 [  8.17547989]
 [  8.41883945]
 [  7.56109428]
 [  7.39085484]
 [  7.75399351]
 [  7.91346121]
 [  8.49096012]
 [  7.58692026]
 [  7.62211847]
 [  7.73982954]
 [  7.5525794 ]
 [  7.82741833]
 [ 14.1968298 ]
 [ 14.32076645]
 [  7.56717968]]
DEBUG:root:training time = %d0.233774
INFO:root:frame =7217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000363111495972
INFO:root:frame =7218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.943
DEBUG:root: dqn, choose action rondomly, need time 0.000279000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309228897095
INFO:root:frame =7221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000428199768066
INFO:root:frame =7222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00050687789917
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:random_action_porb = 0.942968333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.66679621]
 [  9.21351624]
 [  7.64986324]
 [  7.97093344]
 [  6.84449959]
 [ 16.0430584 ]
 [  7.68964911]
 [  7.06235313]
 [  7.96949005]
 [  8.17460728]
 [  7.42222834]
 [  7.23225546]
 [  7.83899164]
 [ 13.63400078]
 [  9.21351624]
 [  8.51169205]]
DEBUG:root:training time = %d0.21092
INFO:root:frame =7225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =7226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226020812988
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.942936666667
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =7229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:frame =7230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.942905
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000016
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000361919403076
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.45541811]
 [  7.37008667]
 [  7.95407677]
 [  7.50386763]
 [  7.68618011]
 [  7.95379686]
 [  7.81293154]
 [  8.09993649]
 [  8.06057453]
 [ 14.71889496]
 [  3.54165101]
 [ 13.79841995]
 [  8.60915089]
 [  3.45180178]
 [  7.44248724]
 [  8.61468124]]
DEBUG:root:training time = %d0.234406
INFO:root:frame =7233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280141830444
INFO:root:frame =7234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame = 7235 State into memory, numbers recorded 189 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000577926635742
INFO:root:random_action_porb = 0.942873333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7236current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =7237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =7238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000498056411743
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.942841666667
DEBUG:root: dqn, choose action rondomly, need time 0.000319999999988
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.72519112]
 [ 13.94598389]
 [  7.72493649]
 [  7.38685226]
 [  7.78504181]
 [  7.87633228]
 [  7.59450865]
 [  7.25050688]
 [  8.68855572]
 [  7.77689075]
 [  8.3845396 ]
 [  7.71874571]
 [  8.30095577]
 [  7.24395514]
 [  7.01638317]
 [  8.02022839]]
DEBUG:root:training time = %d0.225417
INFO:root:frame =7241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =7242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame = 7243 State into memory, numbers recorded 190 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000526905059814
INFO:root:random_action_porb = 0.94281
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7244current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =7245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000384092330933
INFO:root:frame =7246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.942778333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.80350876]
 [  7.60189009]
 [  8.6005125 ]
 [  7.58681536]
 [ 14.59207726]
 [  7.30783367]
 [  8.0841589 ]
 [  7.82169914]
 [  7.40552616]
 [  7.1084938 ]
 [  7.76015568]
 [  8.43861866]
 [  6.72999287]
 [  7.30783367]
 [  7.59265852]
 [  8.9825449 ]]
DEBUG:root:training time = %d0.214637
INFO:root:frame =7249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000514984130859
INFO:root:frame =7250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame = 7251 State into memory, numbers recorded 191 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:random_action_porb = 0.942746666667
INFO:root:dqn select action Tensor("ArgMax_52:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014782
INFO:root:action choosen by dqn [4]
INFO:root:frame =7252current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000871896743774
INFO:root:frame =7253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =7254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000281810760498
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.942715
DEBUG:root: dqn, choose action rondomly, need time 0.00027
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:training error  = [[ 8.20076084]
 [ 8.17644024]
 [ 8.3083868 ]
 [ 7.81022358]
 [ 8.02950001]
 [ 8.10519218]
 [ 7.83213615]
 [ 8.4690094 ]
 [ 7.71357489]
 [ 8.1281023 ]
 [ 7.93068314]
 [ 7.97086859]
 [ 8.20076084]
 [ 8.44766426]
 [ 7.93253088]
 [ 8.34570312]]
DEBUG:root:training time = %d0.204332
INFO:root:frame =7257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:frame =7258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000219106674194
DEBUG:root: save sample needs time = 0.000110864639282
INFO:root:random_action_porb = 0.942683333333
DEBUG:root: dqn, choose action rondomly, need time 0.000167000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000131130218506
INFO:root:frame =7261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =7262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000228881835938
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.942651666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:training error  = [[ 8.00098801]
 [ 7.58702564]
 [ 7.68694162]
 [ 8.52950859]
 [ 7.79392099]
 [ 7.66485262]
 [ 8.46077442]
 [ 7.53062201]
 [ 7.48452759]
 [ 8.15487862]
 [ 7.53062201]
 [ 7.65488625]
 [ 7.07683706]
 [ 7.82349157]
 [ 7.98241854]
 [ 9.21692085]]
DEBUG:root:training time = %d0.230857
INFO:root:frame =7265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000346899032593
INFO:root:frame =7266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.94262
DEBUG:root: dqn, choose action rondomly, need time 0.000280000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =7269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =7270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.942588333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.9042778 ]
 [ 13.56776714]
 [  7.83595896]
 [  8.16575336]
 [  8.1139698 ]
 [  8.08281422]
 [  7.5836215 ]
 [  7.61479044]
 [  7.60864401]
 [  7.55813646]
 [  7.769701  ]
 [  8.23012924]
 [  8.06196117]
 [  8.06937122]
 [  8.42937946]
 [  7.56262589]]
DEBUG:root:training time = %d0.227223
INFO:root:frame =7273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000394105911255
INFO:root:frame =7274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.942556666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =7277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =7278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.942525
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.94293451]
 [  8.24149227]
 [  7.32696486]
 [  7.95917702]
 [  7.73609447]
 [  8.17491245]
 [ 15.13850689]
 [  8.17809772]
 [ 15.99597168]
 [  7.95917702]
 [  8.02411747]
 [  8.01182556]
 [  8.42802811]
 [  9.15751266]
 [  7.91648769]
 [  7.70596981]]
DEBUG:root:training time = %d0.233787
INFO:root:frame =7281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =7282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.942493333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =7285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame =7286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.942461666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.96677399]
 [  8.58215237]
 [  9.68708134]
 [ 14.53701782]
 [  3.50504708]
 [  8.42052174]
 [  8.64188766]
 [  7.85380173]
 [  7.59305811]
 [  9.87229729]
 [ 14.7195673 ]
 [  8.5250082 ]
 [  8.86914635]
 [  8.68048477]
 [  8.13112545]
 [  7.28273439]]
DEBUG:root:training time = %d0.221519
INFO:root:frame =7289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =7290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00027322769165
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.94243
DEBUG:root: dqn, choose action rondomly, need time 0.000191999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root:frame =7293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame =7294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.942398333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.08812904]
 [  8.38621902]
 [  8.12366581]
 [  7.44109249]
 [ 14.23814011]
 [ 14.99384403]
 [ 15.27470779]
 [  7.86002493]
 [  7.75186872]
 [ 13.99580288]
 [  8.48291397]
 [  7.39245224]
 [  8.11340523]
 [  8.11340523]
 [  8.10358524]
 [  7.90457821]]
DEBUG:root:training time = %d0.23354
INFO:root:frame =7297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =7298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000355005264282
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.942366666667
DEBUG:root: dqn, choose action rondomly, need time 0.000323000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =7301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =7302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000420093536377
INFO:root:frame = 7303 State into memory, numbers recorded 192 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000541925430298
INFO:root:random_action_porb = 0.942335
INFO:root:dqn select action Tensor("ArgMax_53:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010117
INFO:root:action choosen by dqn [4]
INFO:root:frame =7304current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000399112701416
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.14657307]
 [  8.41784286]
 [  9.07801056]
 [ 14.31421375]
 [  7.73825884]
 [  8.28968239]
 [  7.73732519]
 [  7.95508766]
 [  7.67393827]
 [  8.60621834]
 [  8.23463917]
 [  7.97351837]
 [  9.00485325]
 [  9.23870659]
 [  7.44254923]
 [  7.66299438]]
DEBUG:root:training time = %d0.207236
INFO:root:frame =7305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =7306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:random_action_porb = 0.942303333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =7309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =7310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484228134155
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.942271666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.86438894]
 [  7.94142962]
 [ 14.98341751]
 [ 16.38216782]
 [  7.94706345]
 [  7.91318226]
 [  7.59053516]
 [  8.23310661]
 [  7.70160723]
 [  8.42078686]
 [  7.75868893]
 [  7.93218708]
 [  7.70160723]
 [  7.97560835]
 [  8.23310661]
 [  8.09887314]]
DEBUG:root:training time = %d0.212342
INFO:root:frame =7313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282764434814
INFO:root:frame =7314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 0.000123977661133
INFO:root:random_action_porb = 0.94224
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000023
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =7317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =7318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.942208333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[ 7.77446556]
 [ 8.5275259 ]
 [ 8.38679314]
 [ 7.44571352]
 [ 8.89174557]
 [ 8.32383156]
 [ 7.77446556]
 [ 8.10367203]
 [ 8.16913319]
 [ 8.36886215]
 [ 8.02898121]
 [ 8.26656818]
 [ 8.09622478]
 [ 8.36894989]
 [ 8.36398506]
 [ 7.86177921]]
DEBUG:root:training time = %d0.222778
INFO:root:frame =7321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000420093536377
INFO:root:frame =7322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:random_action_porb = 0.942176666667
INFO:root:dqn select action Tensor("ArgMax_54:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010737
INFO:root:action choosen by dqn [4]
INFO:root:frame =7324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000155925750732
INFO:root:frame =7325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:frame =7326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000256061553955
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:random_action_porb = 0.942145
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000395059585571
INFO:root:training error  = [[ 8.05401325]
 [ 8.64244843]
 [ 9.08559799]
 [ 7.6171484 ]
 [ 7.96023178]
 [ 9.30330944]
 [ 8.97813225]
 [ 8.42300129]
 [ 7.68195009]
 [ 8.22870636]
 [ 8.40131569]
 [ 8.75039673]
 [ 7.10314465]
 [ 8.40131569]
 [ 8.49905396]
 [ 9.49165249]]
DEBUG:root:training time = %d0.225353
INFO:root:frame =7329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285148620605
INFO:root:frame =7330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000245094299316
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.942113333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000022
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =7333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =7334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.942081666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.73329902]
 [  9.62700367]
 [ 15.51006508]
 [  7.83369493]
 [  8.29972458]
 [  7.78976822]
 [  8.57951546]
 [  8.20814705]
 [  9.17885876]
 [ 15.65353775]
 [  8.07678509]
 [  8.7265358 ]
 [  7.74477577]
 [  9.02845001]
 [  9.29881954]
 [  8.47851467]]
DEBUG:root:training time = %d0.222128
INFO:root:frame =7337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =7338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.94205
DEBUG:root: dqn, choose action rondomly, need time 0.000368000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =7341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =7342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.942018333333
DEBUG:root: dqn, choose action rondomly, need time 0.000518
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.14144135]
 [  8.96510696]
 [  9.27666092]
 [ 14.46229744]
 [ 14.83738422]
 [  8.19597626]
 [  8.39390945]
 [  8.57348251]
 [  9.23930931]
 [  8.50259113]
 [  7.83188009]
 [  8.07123566]
 [  7.64233208]
 [ 14.83738422]
 [  7.85393   ]
 [  7.72366428]]
DEBUG:root:training time = %d0.226809
INFO:root:frame =7345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =7346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.941986666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =7349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =7350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.941955
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.81399822]
 [  8.65422726]
 [  8.31782341]
 [ 16.06928825]
 [  7.69957495]
 [  7.58149958]
 [  7.79943848]
 [  8.59986305]
 [  8.04399109]
 [ 15.33846474]
 [  7.85042381]
 [  8.06967449]
 [  8.38661671]
 [  7.77176428]
 [  7.69119406]
 [  7.79202557]]
DEBUG:root:training time = %d0.230378
INFO:root:frame =7353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =7354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308990478516
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.941923333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:frame =7357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000372886657715
INFO:root:frame =7358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.941891666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.14354992]
 [  8.23415661]
 [  8.33133888]
 [  8.41952515]
 [ 15.59340668]
 [  8.48027039]
 [  8.99388981]
 [  9.75906944]
 [  8.75091648]
 [  8.07325172]
 [  8.33133888]
 [  8.22502995]
 [  7.63501501]
 [  7.14790869]
 [  7.53548002]
 [  8.31151009]]
DEBUG:root:training time = %d0.223827
INFO:root:frame =7361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =7362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255823135376
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.94186
DEBUG:root: dqn, choose action rondomly, need time 0.000198000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:frame =7365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000514984130859
INFO:root:frame =7366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:random_action_porb = 0.941828333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000018
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.21317577]
 [  9.35665226]
 [  7.89728689]
 [  8.19431686]
 [  8.48229218]
 [  8.49107075]
 [  8.09826469]
 [ 15.9746809 ]
 [  8.79568291]
 [  8.35033226]
 [  8.33948898]
 [  9.35665226]
 [  8.23917103]
 [  9.45501995]
 [  8.23917103]
 [  7.7520175 ]]
DEBUG:root:training time = %d0.216187
INFO:root:frame =7369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002281665802
INFO:root:frame =7370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:random_action_porb = 0.941796666667
DEBUG:root: dqn, choose action rondomly, need time 0.000353000000018
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =7373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000420093536377
INFO:root:frame =7374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.941765
DEBUG:root: dqn, choose action rondomly, need time 0.000224000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.63805294]
 [  8.19562721]
 [  7.69836807]
 [  7.8569665 ]
 [ 15.23924541]
 [  8.53436661]
 [  7.5778656 ]
 [  8.13132191]
 [  7.93134928]
 [  8.70417023]
 [ 10.3553915 ]
 [  8.5080204 ]
 [  8.09909058]
 [  8.37738323]
 [  8.73952198]
 [  8.26601982]]
DEBUG:root:training time = %d0.217926
INFO:root:frame =7377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286817550659
INFO:root:frame =7378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:random_action_porb = 0.941733333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =7381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =7382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.941701666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999974
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.29037571]
 [  8.60812092]
 [  8.28111839]
 [  8.7679863 ]
 [  9.30293751]
 [  8.75405312]
 [  8.1288414 ]
 [  8.37623501]
 [  9.03110886]
 [  8.96743679]
 [  8.09186172]
 [  8.31648159]
 [  7.76087809]
 [  9.5791502 ]
 [  8.91453362]
 [ 16.0290966 ]]
DEBUG:root:training time = %d0.228412
INFO:root:frame =7385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =7386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:random_action_porb = 0.94167
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =7389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042986869812
INFO:root:frame =7390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:random_action_porb = 0.941638333333
DEBUG:root: dqn, choose action rondomly, need time 0.000323000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000380992889404
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.51754761]
 [  8.65795326]
 [  3.42027879]
 [ 16.00558472]
 [  8.50911045]
 [  9.22275925]
 [  7.73386621]
 [  7.9761467 ]
 [  8.09357643]
 [  8.57797337]
 [  7.9528718 ]
 [ 15.27220345]
 [  7.92859936]
 [  8.49883175]
 [  8.37667751]
 [  9.41347122]]
DEBUG:root:training time = %d0.218752
INFO:root:frame =7393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:frame =7394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.941606666667
DEBUG:root: dqn, choose action rondomly, need time 0.000158999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:frame =7397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =7398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.941575
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 8.46252728]
 [ 8.79276466]
 [ 8.42902565]
 [ 8.60134029]
 [ 8.90836143]
 [ 8.65604496]
 [ 8.49627399]
 [ 8.32517433]
 [ 9.77838421]
 [ 8.37113571]
 [ 8.41604996]
 [ 3.4193759 ]
 [ 8.19036388]
 [ 7.57731962]
 [ 8.58208561]
 [ 8.36921501]]
DEBUG:root:training time = %d0.234957
INFO:root:frame =7401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =7402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.941543333333
DEBUG:root: dqn, choose action rondomly, need time 0.00029600000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =7405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =7406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:random_action_porb = 0.941511666667
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000026
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.86453533]
 [  8.05470562]
 [  7.88659191]
 [  9.322402  ]
 [ 16.17383957]
 [  8.4754715 ]
 [  8.86453533]
 [  8.86453533]
 [  8.04219532]
 [  8.57104778]
 [  8.70844746]
 [  7.57708883]
 [  7.87568998]
 [  8.31326962]
 [  8.20873737]
 [  8.37517548]]
DEBUG:root:training time = %d0.210461
INFO:root:frame =7409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =7410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000313997268677
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.94148
DEBUG:root: dqn, choose action rondomly, need time 0.000331000000017
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =7413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =7414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000609874725342
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.941448333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:training error  = [[  9.20018196]
 [  9.45518398]
 [  9.01032543]
 [  8.94273376]
 [  9.70207119]
 [ 10.21538544]
 [  8.74545479]
 [  7.94831085]
 [  9.70967674]
 [  9.80626965]
 [  8.91651535]
 [  9.81910419]
 [  8.6790905 ]
 [  9.13656139]
 [  9.80626965]
 [  9.2596817 ]]
DEBUG:root:training time = %d0.210557
INFO:root:frame =7417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =7418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.941416666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =7421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =7422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.941385
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.01437378]
 [  8.89964199]
 [  7.96757364]
 [  8.29036331]
 [  8.80745316]
 [  9.16016865]
 [  8.38575459]
 [  8.70385456]
 [  9.08159733]
 [ 10.71848965]
 [  8.28491688]
 [  9.36823177]
 [  8.96828175]
 [  9.33880806]
 [  8.85352135]
 [  4.01700115]]
DEBUG:root:training time = %d0.229748
INFO:root:frame =7425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =7426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.941353333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =7429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =7430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.941321666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:training error  = [[  8.75143528]
 [ 10.12689114]
 [  8.24118614]
 [  8.29374695]
 [  8.84712124]
 [  8.78975582]
 [  9.0667963 ]
 [  8.44207668]
 [ 10.11390591]
 [  7.61828566]
 [  8.42076492]
 [  8.52338219]
 [  8.87032795]
 [  7.7947731 ]
 [  8.6958437 ]
 [  8.45052433]]
DEBUG:root:training time = %d0.222925
INFO:root:frame =7433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =7434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:random_action_porb = 0.94129
DEBUG:root: dqn, choose action rondomly, need time 0.000512000000015
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =7437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =7438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.941258333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999981
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.47311783]
 [  8.04877377]
 [  7.91567183]
 [  8.3260994 ]
 [  9.35249901]
 [  8.93746376]
 [  7.90256214]
 [  9.85523701]
 [  8.70615101]
 [  8.60850143]
 [  8.55896854]
 [ 16.36450958]
 [  9.20258904]
 [  8.54000664]
 [  9.05818367]
 [  7.90256214]]
DEBUG:root:training time = %d0.226716
INFO:root:frame =7441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =7442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000370025634766
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.941226666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =7445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000423908233643
INFO:root:frame =7446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.941195
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.06964588]
 [  8.98462582]
 [  8.38937855]
 [  9.43105888]
 [ 10.1653614 ]
 [  8.74992275]
 [  8.78975582]
 [  7.8180294 ]
 [  8.24666214]
 [  9.46647167]
 [  8.71308613]
 [  9.31583405]
 [  9.43541718]
 [ 15.35609913]
 [  8.37775898]
 [  8.95498943]]
DEBUG:root:training time = %d0.225504
INFO:root:frame =7449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =7450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame = 7451 State into memory, numbers recorded 193 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000533819198608
INFO:root:random_action_porb = 0.941163333333
DEBUG:root: dqn, choose action rondomly, need time 0.000253000000015
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7452current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =7453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =7454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.941131666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.66935253]
 [  7.74643183]
 [  7.8653307 ]
 [  9.19756794]
 [  8.77334213]
 [  8.20895576]
 [  8.84870911]
 [  8.54609394]
 [  7.95678806]
 [  8.48411369]
 [  8.25990105]
 [  9.45168877]
 [ 14.84214497]
 [  8.66064739]
 [  8.23522949]
 [  9.01776981]]
DEBUG:root:training time = %d0.208805
INFO:root:frame =7457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =7458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000258207321167
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9411
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =7461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =7462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00059986114502
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.941068333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999986
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000375032424927
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.41007519]
 [  8.21599579]
 [  7.87104464]
 [  9.04544449]
 [  9.33099937]
 [  8.84609985]
 [  8.84609985]
 [ 15.46088791]
 [  9.0919466 ]
 [  8.2276783 ]
 [  8.09533405]
 [  8.83543777]
 [  9.40015697]
 [  9.1314888 ]
 [  7.81156683]
 [  8.09533405]]
DEBUG:root:training time = %d0.226353
INFO:root:frame =7465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =7466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449180603027
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:random_action_porb = 0.941036666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =7469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049090385437
INFO:root:frame =7470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000179052352905
INFO:root:random_action_porb = 0.941005
DEBUG:root: dqn, choose action rondomly, need time 0.000326000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.55280876]
 [  8.15694809]
 [  8.47833729]
 [ 16.72732162]
 [ 14.55369091]
 [  8.95453262]
 [ 15.37906933]
 [ 16.05620193]
 [  8.74759865]
 [ 15.37906933]
 [  9.81587696]
 [  8.47833729]
 [ 16.3918972 ]
 [  8.58745003]
 [  8.45234299]
 [  8.79271889]]
DEBUG:root:training time = %d0.220435
INFO:root:frame =7473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =7474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264167785645
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.940973333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =7477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =7478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.940941666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332832336426
INFO:root:training error  = [[  8.35917568]
 [  9.43736267]
 [  8.53378677]
 [  9.15504265]
 [  8.49487305]
 [ 10.02264023]
 [  9.11683178]
 [  8.14233398]
 [  8.88469505]
 [  9.49132347]
 [  9.41955853]
 [  7.42869377]
 [  9.14147377]
 [  8.22833443]
 [  9.12547207]
 [  9.41983986]]
DEBUG:root:training time = %d0.226701
INFO:root:frame =7481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =7482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.94091
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =7485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =7486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000304937362671
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:random_action_porb = 0.940878333333
DEBUG:root: dqn, choose action rondomly, need time 0.000334000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.79106712]
 [  9.40446186]
 [  8.52685738]
 [  9.84225941]
 [  8.61094189]
 [  8.44573498]
 [ 16.33884239]
 [  8.60751629]
 [  8.33446693]
 [  8.85726738]
 [  9.17546082]
 [  8.84503365]
 [  8.76398849]
 [  9.29381752]
 [  8.61963081]
 [  9.12667084]]
DEBUG:root:training time = %d0.228018
INFO:root:frame =7489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =7490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame = 7491 State into memory, numbers recorded 194 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000582218170166
INFO:root:random_action_porb = 0.940846666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7492current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =7493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =7494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.940815
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.28656387]
 [  9.53445625]
 [  8.59207916]
 [ 15.45680809]
 [  9.68349648]
 [  8.82319641]
 [  8.41576195]
 [  8.75820732]
 [  9.04340267]
 [ 15.04674244]
 [  8.35322094]
 [  9.19173813]
 [  8.52233505]
 [  9.34736633]
 [  8.57513618]
 [  8.45722389]]
DEBUG:root:training time = %d0.232343
INFO:root:frame =7497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =7498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277996063232
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.940783333333
DEBUG:root: dqn, choose action rondomly, need time 0.000336000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =7501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =7502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.940751666667
DEBUG:root: dqn, choose action rondomly, need time 0.000209999999981
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000351190567017
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.53989506]
 [  9.51455975]
 [ 15.52770805]
 [  7.87314224]
 [  8.04256344]
 [  9.00157928]
 [  9.89162731]
 [  8.19944954]
 [  8.41952515]
 [  9.50023365]
 [  8.47947025]
 [  8.39963531]
 [  8.77772617]
 [  9.48044395]
 [  9.15589714]
 [  8.22518349]]
DEBUG:root:training time = %d0.223363
INFO:root:frame =7505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =7506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000330924987793
DEBUG:root: save sample needs time = 0.000131845474243
INFO:root:random_action_porb = 0.94072
DEBUG:root: dqn, choose action rondomly, need time 0.000184000000019
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =7509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =7510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame = 7511 State into memory, numbers recorded 195 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:random_action_porb = 0.940688333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7512current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000370979309082
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.47442818]
 [  8.9676199 ]
 [  8.53429985]
 [  9.65585709]
 [ 15.74991703]
 [  8.71022606]
 [  9.115242  ]
 [  8.45378494]
 [ 17.07805824]
 [  8.80215549]
 [ 10.02988815]
 [  4.90955544]
 [ 15.70946121]
 [  4.90955544]
 [ 10.4344492 ]
 [  8.08802032]]
DEBUG:root:training time = %d0.201126
INFO:root:frame =7513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =7514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame = 7515 State into memory, numbers recorded 196 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000281810760498
INFO:root:random_action_porb = 0.940656666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7516current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000369071960449
INFO:root:frame =7517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00044584274292
INFO:root:frame =7518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494003295898
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.940625
DEBUG:root: dqn, choose action rondomly, need time 0.000234000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:training error  = [[  9.47029781]
 [  8.7698164 ]
 [ 10.03324699]
 [  8.75051022]
 [  8.42793941]
 [  8.14309597]
 [  8.5885458 ]
 [  9.48615265]
 [  8.79213047]
 [  9.61959553]
 [  8.70892048]
 [  9.58205509]
 [ 10.43412876]
 [  8.59326458]
 [  8.79627132]
 [  9.33943748]]
DEBUG:root:training time = %d0.216792
INFO:root:frame =7521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =7522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000221014022827
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.940593333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000023
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000255823135376
INFO:root:frame =7525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root:frame =7526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
DEBUG:root: save sample needs time = 0.000280141830444
INFO:root:random_action_porb = 0.940561666667
DEBUG:root: dqn, choose action rondomly, need time 0.000326999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root: ememy has been killed for 16 times 
INFO:root:enemies_left [0]
INFO:root:frame =7528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:training error  = [[ 9.23655033]
 [ 8.39906025]
 [ 8.68075371]
 [ 8.99116707]
 [ 8.87660122]
 [ 8.44307423]
 [ 8.71236515]
 [ 8.62449169]
 [ 9.52595329]
 [ 9.73025227]
 [ 8.95188522]
 [ 8.71200466]
 [ 9.28726006]
 [ 8.86492062]
 [ 9.73655987]
 [ 8.49531746]]
DEBUG:root:training time = %d0.205089
INFO:root:frame =7529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240802764893
INFO:root:frame =7530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame = 7531 State into memory, numbers recorded 197 action = 1, reward = 1
DEBUG:root: save sample needs time = 0.000554084777832
INFO:root:random_action_porb = 0.94053
DEBUG:root: dqn, choose action rondomly, need time 0.000450999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7532current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =7533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =7534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449180603027
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.940498333333
DEBUG:root: dqn, choose action rondomly, need time 0.000378999999981
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:training error  = [[  8.7707653 ]
 [  8.16823959]
 [  8.31762505]
 [  8.72389889]
 [  8.98025799]
 [  9.31879139]
 [  8.98025799]
 [  8.5820179 ]
 [ 10.0755825 ]
 [ 10.05735493]
 [  9.40249634]
 [  8.62310314]
 [  8.85583687]
 [  8.93249226]
 [  8.38856125]
 [  8.31989193]]
DEBUG:root:training time = %d0.233849
INFO:root:frame =7537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =7538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.940466666667
DEBUG:root: dqn, choose action rondomly, need time 0.000195999999988
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:frame =7541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =7542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.940435
DEBUG:root: dqn, choose action rondomly, need time 0.00037500000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.37272453]
 [  4.49156523]
 [  8.25520897]
 [  9.11491966]
 [  9.94937229]
 [ 10.0948925 ]
 [  8.31766987]
 [  9.36965561]
 [  8.77686691]
 [ 10.00228977]
 [  4.59317493]
 [ 17.94220924]
 [ 10.076478  ]
 [  8.44318485]
 [  8.94976234]
 [  8.74759865]]
DEBUG:root:training time = %d0.208759
INFO:root:frame =7545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =7546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000337839126587
DEBUG:root: save sample needs time = 0.000182151794434
INFO:root:random_action_porb = 0.940403333333
DEBUG:root: dqn, choose action rondomly, need time 0.000157999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:frame =7549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:frame =7550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:random_action_porb = 0.940371666667
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.45534801]
 [  9.40301132]
 [  8.46290493]
 [  8.60541248]
 [  8.47205162]
 [  8.58964157]
 [  8.85497475]
 [  8.71761322]
 [  8.42537117]
 [  8.47322845]
 [  8.32620907]
 [  8.94186687]
 [  9.17583084]
 [  8.63966751]
 [ 15.42404079]
 [  9.23437023]]
DEBUG:root:training time = %d0.202053
INFO:root:frame =7553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =7554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000307083129883
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:random_action_porb = 0.94034
DEBUG:root: dqn, choose action rondomly, need time 0.000169
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000150203704834
INFO:root:frame =7557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =7558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000245094299316
DEBUG:root: save sample needs time = 0.000304222106934
INFO:root:random_action_porb = 0.940308333333
INFO:root:dqn select action Tensor("ArgMax_55:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014205
INFO:root:action choosen by dqn [4]
INFO:root:frame =7560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.66113567]
 [  8.59652996]
 [  8.7956152 ]
 [ 10.31029129]
 [  9.00281525]
 [  8.39472771]
 [ 15.2395134 ]
 [  8.63273907]
 [  8.42767429]
 [  8.97961807]
 [  9.27521992]
 [  8.75743961]
 [ 15.61281395]
 [  9.38612747]
 [  8.91897583]
 [ 10.31029129]]
DEBUG:root:training time = %d0.194935
INFO:root:frame =7561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:frame =7562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000326871871948
DEBUG:root: save sample needs time = 0.000131130218506
INFO:root:random_action_porb = 0.940276666667
DEBUG:root: dqn, choose action rondomly, need time 0.000157999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:frame =7565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000276803970337
INFO:root:frame =7566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:random_action_porb = 0.940245
DEBUG:root: dqn, choose action rondomly, need time 0.000216999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000829935073853
INFO:root:training error  = [[  8.59621716]
 [  8.52765942]
 [  9.18567848]
 [  9.02331543]
 [  9.49191093]
 [  9.29428291]
 [  9.66799927]
 [  8.65106297]
 [  9.02938938]
 [  8.93281174]
 [ 10.00412369]
 [  8.4440937 ]
 [  8.7514801 ]
 [  8.54136658]
 [  8.84197044]
 [  9.7380352 ]]
DEBUG:root:training time = %d0.186422
INFO:root:frame =7569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =7570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000174045562744
INFO:root:random_action_porb = 0.940213333333
DEBUG:root: dqn, choose action rondomly, need time 0.00022899999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:frame =7573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:frame =7574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229120254517
DEBUG:root: save sample needs time = 0.00011420249939
INFO:root:random_action_porb = 0.940181666667
DEBUG:root: dqn, choose action rondomly, need time 0.000408999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.9961319 ]
 [ 10.15701962]
 [  9.13806057]
 [  8.8352108 ]
 [ 10.69312763]
 [ 10.29224396]
 [  9.29444599]
 [  9.82467461]
 [  4.11146832]
 [ 17.19254112]
 [  9.22565556]
 [  9.47525311]
 [ 16.59602547]
 [  8.62312508]
 [  9.703022  ]
 [  8.69240189]]
DEBUG:root:training time = %d0.200839
INFO:root:frame =7577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =7578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.94015
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =7581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =7582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:random_action_porb = 0.940118333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.89313412]
 [  9.7467041 ]
 [  8.64386082]
 [  9.39171505]
 [  9.74586964]
 [ 10.55127048]
 [  9.42770863]
 [  8.8214283 ]
 [  9.01405907]
 [  8.9316721 ]
 [  9.05522251]
 [  4.31731939]
 [ 10.62109852]
 [ 10.38347244]
 [  8.60480881]
 [  9.06105423]]
DEBUG:root:training time = %d0.210545
INFO:root:frame =7585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:frame =7586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000580072402954
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.940086666667
DEBUG:root: dqn, choose action rondomly, need time 0.000345999999979
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =7589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000480175018311
INFO:root:frame =7590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:random_action_porb = 0.940055
DEBUG:root: dqn, choose action rondomly, need time 0.000540999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000556945800781
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.16615009]
 [ 10.25961876]
 [  9.17684746]
 [  9.41169262]
 [  9.04533005]
 [  8.85474777]
 [  8.54812431]
 [  9.87579727]
 [  9.354949  ]
 [  9.30475235]
 [  8.61674118]
 [  9.34512711]
 [  9.44289494]
 [  4.19780588]
 [  8.87712383]
 [  9.30475235]]
DEBUG:root:training time = %d0.20965
INFO:root:frame =7593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =7594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000329971313477
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.940023333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =7597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =7598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000583171844482
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.939991666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:training error  = [[ 10.39977837]
 [  9.41574192]
 [  9.16931438]
 [ 10.19691086]
 [  9.21865845]
 [  9.65398407]
 [  9.54873753]
 [  9.3690958 ]
 [  9.00721169]
 [  8.61396408]
 [  8.60688972]
 [  8.59248161]
 [  8.14880085]
 [  8.83981514]
 [  9.02766991]
 [  8.27323818]]
DEBUG:root:training time = %d0.225735
INFO:root:frame =7601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =7602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000250101089478
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:random_action_porb = 0.93996
DEBUG:root: dqn, choose action rondomly, need time 0.000173000000018
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root:frame =7605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =7606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame = 7607 State into memory, numbers recorded 198 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00054407119751
INFO:root:random_action_porb = 0.939928333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999986
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7608current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.87253666]
 [  9.98948097]
 [  9.15827465]
 [ 15.39106941]
 [  8.84065437]
 [ 10.68719101]
 [  9.4477253 ]
 [  9.79332542]
 [  9.13296413]
 [  9.45846844]
 [  9.42400837]
 [ 11.7677021 ]
 [ 10.6182642 ]
 [ 10.53464794]
 [ 10.08144379]
 [  9.13296413]]
DEBUG:root:training time = %d0.216869
INFO:root:frame =7609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =7610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000412940979004
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.939896666667
DEBUG:root: dqn, choose action rondomly, need time 0.000280000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =7613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469207763672
INFO:root:frame =7614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000327110290527
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.939865
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000011
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.41828728]
 [  8.94971657]
 [  9.26042461]
 [ 15.67796707]
 [  8.60453987]
 [  8.10773373]
 [ 10.14863205]
 [  9.38991451]
 [  9.86637688]
 [ 10.46194649]
 [  8.9585743 ]
 [  9.86637688]
 [ 10.27528954]
 [ 16.25340652]
 [  8.42603493]
 [ 10.01455021]]
DEBUG:root:training time = %d0.171139
INFO:root:frame =7617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =7618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.00114893913269
INFO:root:random_action_porb = 0.939833333333
DEBUG:root: dqn, choose action rondomly, need time 0.00025500000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =7621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =7622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000364065170288
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:random_action_porb = 0.939801666667
DEBUG:root: dqn, choose action rondomly, need time 0.000189000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174045562744
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.78556728]
 [  9.72825336]
 [ 10.21760464]
 [  9.21655083]
 [ 10.17263603]
 [  8.72027111]
 [  9.36456585]
 [ 15.85980511]
 [ 10.21760464]
 [  9.9017086 ]
 [  9.99712658]
 [  9.3736496 ]
 [  8.76425934]
 [  9.38381386]
 [  9.32466125]
 [  9.19037342]]
DEBUG:root:training time = %d0.215006
INFO:root:frame =7625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:frame =7626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247955322266
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.93977
DEBUG:root: dqn, choose action rondomly, need time 0.000163999999984
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:frame =7629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =7630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:random_action_porb = 0.939738333333
DEBUG:root: dqn, choose action rondomly, need time 0.00034500000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.96114349]
 [  9.94167328]
 [  9.57185555]
 [  9.25480747]
 [  9.12514973]
 [  9.1827879 ]
 [  8.71815395]
 [  9.40593529]
 [  9.80813313]
 [ 15.63657856]
 [  9.76231098]
 [ 10.01800346]
 [ 10.01800346]
 [  9.38640785]
 [ 10.17913342]
 [  9.64024067]]
DEBUG:root:training time = %d0.175345
INFO:root:frame =7633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =7634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248908996582
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.939706666667
DEBUG:root: dqn, choose action rondomly, need time 0.000161999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =7637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000398874282837
INFO:root:frame =7638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000344038009644
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:random_action_porb = 0.939675
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.41133308]
 [  8.27139473]
 [  9.83134842]
 [ 10.25954533]
 [  9.48897266]
 [ 10.3941946 ]
 [  9.31979275]
 [  9.18822193]
 [ 10.19586277]
 [  8.99359226]
 [  8.18429565]
 [  9.48897266]
 [  9.18276501]
 [ 16.50024986]
 [ 10.30059242]
 [ 10.17144299]]
DEBUG:root:training time = %d0.220387
INFO:root:frame =7641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028920173645
INFO:root:frame =7642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000258922576904
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.939643333333
DEBUG:root: dqn, choose action rondomly, need time 0.000325000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =7645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =7646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.939611666667
INFO:root:dqn select action Tensor("ArgMax_56:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012836
INFO:root:action choosen by dqn [4]
INFO:root:frame =7648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000167846679688
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.23627186]
 [  9.46771526]
 [  9.96851349]
 [  8.71459484]
 [  9.24297428]
 [ 10.03522873]
 [  9.46572018]
 [  9.14911079]
 [  9.14357376]
 [  9.69214058]
 [ 10.65733147]
 [ 10.71177197]
 [ 10.56230164]
 [ 16.41287804]
 [  9.55949116]
 [  9.01758671]]
DEBUG:root:training time = %d0.219247
INFO:root:frame =7649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =7650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000281095504761
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.93958
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000011
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =7653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =7654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00058388710022
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.939548333333
DEBUG:root: dqn, choose action rondomly, need time 0.000252000000017
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.08263206]
 [ 10.24315453]
 [  9.65230179]
 [  9.33202457]
 [  9.36995983]
 [  9.21506786]
 [  9.95291042]
 [ 10.24315453]
 [  9.43049717]
 [ 10.19459629]
 [  8.5290184 ]
 [  8.9349556 ]
 [ 17.77375221]
 [  9.53735352]
 [ 10.08611965]
 [ 17.79344177]]
DEBUG:root:training time = %d0.213984
INFO:root:frame =7657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000406980514526
INFO:root:frame =7658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000520944595337
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.939516666667
DEBUG:root: dqn, choose action rondomly, need time 0.000324000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =7661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =7662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000329971313477
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.939485
DEBUG:root: dqn, choose action rondomly, need time 0.000240000000019
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000181913375854
INFO:root:training error  = [[ 10.44975948]
 [ 10.19941998]
 [  9.30265808]
 [ 10.50529957]
 [  8.9662714 ]
 [  9.28521442]
 [  9.66396713]
 [ 10.67876244]
 [ 10.44975948]
 [  9.28244781]
 [  8.84065437]
 [ 10.30820847]
 [  9.6288023 ]
 [  9.76042843]
 [ 10.69968987]
 [ 10.65352154]]
DEBUG:root:training time = %d0.207478
INFO:root:frame =7665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =7666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.939453333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290999999976
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =7669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =7670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042986869812
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.939421666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.90809536]
 [  8.9634161 ]
 [ 10.3071804 ]
 [  9.74491787]
 [ 16.54261017]
 [  8.77616692]
 [  9.40586567]
 [ 10.3071804 ]
 [  9.58836174]
 [  9.42480469]
 [  9.39798164]
 [  9.76514816]
 [  8.9074049 ]
 [ 10.3071804 ]
 [  8.45021439]
 [  4.59310961]]
DEBUG:root:training time = %d0.219197
INFO:root:frame =7673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =7674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame = 7675 State into memory, numbers recorded 199 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000509977340698
INFO:root:random_action_porb = 0.93939
DEBUG:root: dqn, choose action rondomly, need time 0.000405000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7676current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =7677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000409841537476
INFO:root:frame =7678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.939358333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.3846283 ]
 [  9.564044  ]
 [  9.12418175]
 [  9.09146309]
 [ 10.43474579]
 [ 15.86311722]
 [  9.57730865]
 [ 10.21194839]
 [ 10.06754398]
 [  9.36150742]
 [  8.90039349]
 [  9.34328556]
 [  4.05725622]
 [ 10.46337795]
 [  9.022192  ]
 [ 11.039958  ]]
DEBUG:root:training time = %d0.233092
INFO:root:frame =7681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =7682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.939326666667
DEBUG:root: dqn, choose action rondomly, need time 0.000160999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142812728882
INFO:root:frame =7685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =7686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.939295
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.22143841]
 [  9.58042622]
 [ 10.93465424]
 [  9.5147953 ]
 [ 10.2049036 ]
 [  9.29125977]
 [  9.04289722]
 [ 10.2049036 ]
 [  8.9690361 ]
 [  9.30356598]
 [  9.03282833]
 [ 10.51709843]
 [ 16.51360893]
 [ 10.66592598]
 [ 10.41191196]
 [  8.82577991]]
DEBUG:root:training time = %d0.227022
INFO:root:frame =7689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =7690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000429153442383
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.939263333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =7693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =7694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000541925430298
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.939231666667
INFO:root:dqn select action Tensor("ArgMax_57:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00793899999999
INFO:root:action choosen by dqn [4]
INFO:root:frame =7696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.48394585]
 [  9.21990967]
 [  9.89141178]
 [  9.0411768 ]
 [  8.96042442]
 [  9.12044907]
 [  9.56982613]
 [ 10.39249706]
 [ 10.99478054]
 [  9.81974888]
 [  4.25755787]
 [ 10.99478054]
 [  9.82544041]
 [  9.4441843 ]
 [ 10.26360226]
 [ 18.03562927]]
DEBUG:root:training time = %d0.222425
INFO:root:frame =7697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =7698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame = 7699 State into memory, numbers recorded 200 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00128483772278
INFO:root:random_action_porb = 0.9392
DEBUG:root: dqn, choose action rondomly, need time 0.000324000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7700current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =7701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491857528687
INFO:root:frame =7702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:random_action_porb = 0.939168333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.21120071]
 [  9.21238232]
 [ 10.4916544 ]
 [  9.52545929]
 [  9.89253998]
 [  4.61396456]
 [ 10.53388023]
 [  9.40528011]
 [  9.36937618]
 [  9.13642311]
 [ 10.04702663]
 [  9.4753933 ]
 [  9.55677891]
 [ 17.62430954]
 [ 10.57683659]
 [ 17.40810585]]
DEBUG:root:training time = %d0.232872
INFO:root:frame =7705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =7706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269174575806
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root:random_action_porb = 0.939136666667
DEBUG:root: dqn, choose action rondomly, need time 0.000238999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =7709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470161437988
INFO:root:frame =7710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000413179397583
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.939105
DEBUG:root: dqn, choose action rondomly, need time 0.000329999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.87826061]
 [  8.71333313]
 [ 10.04040146]
 [  9.11773014]
 [  8.95170212]
 [  9.63839245]
 [  9.45201683]
 [  9.82548809]
 [ 12.11767292]
 [ 10.12854195]
 [ 10.21953201]
 [  9.72092533]
 [ 16.75572777]
 [  9.80572033]
 [  9.55659008]
 [  9.69893456]]
DEBUG:root:training time = %d0.208602
INFO:root:frame =7713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =7714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:random_action_porb = 0.939073333333
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =7717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =7718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000116109848022
INFO:root:random_action_porb = 0.939041666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.42700863]
 [  9.9371748 ]
 [  4.24468994]
 [ 16.61626625]
 [ 10.14588642]
 [  9.12948322]
 [  9.53634071]
 [  9.87977791]
 [  9.18419838]
 [  9.95319843]
 [ 10.02959824]
 [  9.9371748 ]
 [ 17.38156891]
 [  9.57305908]
 [ 11.1324749 ]
 [  9.54593182]]
DEBUG:root:training time = %d0.20731
INFO:root:frame =7721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000336170196533
INFO:root:frame =7722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000108003616333
INFO:root:random_action_porb = 0.93901
DEBUG:root: dqn, choose action rondomly, need time 0.000187000000011
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180959701538
INFO:root:frame =7725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =7726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.938978333333
DEBUG:root: dqn, choose action rondomly, need time 0.000226999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.96640873]
 [  9.44113636]
 [ 10.41917515]
 [ 10.28930759]
 [ 16.18642235]
 [  9.52077389]
 [  9.377388  ]
 [  9.70508957]
 [  9.16312408]
 [  9.35219574]
 [ 10.03798389]
 [  9.34552383]
 [  9.70435238]
 [  9.16407108]
 [ 16.86323738]
 [  9.70223713]]
DEBUG:root:training time = %d0.24177
INFO:root:frame =7729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =7730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.938946666667
DEBUG:root: dqn, choose action rondomly, need time 0.000279000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =7733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =7734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.938915
DEBUG:root: dqn, choose action rondomly, need time 0.000280000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.40298748]
 [  9.30489254]
 [  9.56331253]
 [  9.77084732]
 [  9.48537731]
 [  9.16395569]
 [ 10.52806187]
 [ 10.52803802]
 [ 17.07834244]
 [  8.8794651 ]
 [ 10.1882391 ]
 [  9.83003235]
 [  4.59791803]
 [  9.37173462]
 [  9.54100609]
 [  9.48065472]]
DEBUG:root:training time = %d0.20362
INFO:root:frame =7737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000868082046509
INFO:root:frame =7738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00048303604126
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:random_action_porb = 0.938883333333
DEBUG:root: dqn, choose action rondomly, need time 0.000378000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =7741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:frame =7742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.938851666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.60939884]
 [  9.83984184]
 [ 17.60327148]
 [  9.23110199]
 [  9.16605759]
 [ 10.48466206]
 [ 10.05094433]
 [ 10.17071342]
 [ 16.76997185]
 [  9.57905579]
 [  9.33218765]
 [  8.89738846]
 [  9.36965561]
 [  4.20855188]
 [  9.81229115]
 [  9.53040409]]
DEBUG:root:training time = %d0.227619
INFO:root:frame =7745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame =7746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427007675171
DEBUG:root: save sample needs time = 0.000134944915771
INFO:root:random_action_porb = 0.93882
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =7749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000808954238892
INFO:root:frame =7750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.938788333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.67001629]
 [ 16.49237823]
 [ 10.11633301]
 [ 10.36897278]
 [  9.24213886]
 [  9.30633545]
 [ 10.88999462]
 [  9.34375191]
 [ 10.33632374]
 [ 10.16708851]
 [  9.32181931]
 [ 10.28005886]
 [  9.00595188]
 [  9.96073437]
 [  9.333004  ]
 [  8.93490982]]
DEBUG:root:training time = %d0.210814
INFO:root:frame =7753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000371932983398
INFO:root:frame =7754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000177145004272
INFO:root:random_action_porb = 0.938756666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =7757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =7758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.938725
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.01793098]
 [  9.77406693]
 [  9.67715836]
 [  9.25007343]
 [ 11.33242893]
 [  9.05919456]
 [ 17.79569435]
 [  9.51510143]
 [  9.0235672 ]
 [  9.41672516]
 [  9.27798557]
 [  9.50747776]
 [  9.16474056]
 [  9.66897202]
 [ 11.24394321]
 [  9.07311535]]
DEBUG:root:training time = %d0.229093
INFO:root:frame =7761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =7762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.938693333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293000000028
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =7765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =7766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.938661666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000396013259888
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.84545612]
 [ 10.44403839]
 [ 11.01485062]
 [ 10.79029655]
 [  8.81603622]
 [ 10.96222115]
 [ 10.44403839]
 [  9.21210384]
 [  9.64071465]
 [ 17.04156685]
 [  9.17137051]
 [ 10.49879742]
 [  9.94013309]
 [ 10.38824272]
 [ 10.08847046]
 [ 19.84493446]]
DEBUG:root:training time = %d0.22279
INFO:root:frame =7769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270843505859
INFO:root:frame =7770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000331163406372
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:random_action_porb = 0.93863
INFO:root:dqn select action Tensor("ArgMax_58:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014176
INFO:root:action choosen by dqn [4]
INFO:root:frame =7772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000158071517944
INFO:root:frame =7773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:frame =7774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000147104263306
INFO:root:random_action_porb = 0.938598333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.11354256]
 [  9.72485065]
 [ 10.00617409]
 [  9.1306591 ]
 [ 10.63383293]
 [  8.96247959]
 [  9.6871767 ]
 [  9.09682465]
 [  9.31187534]
 [ 18.91505432]
 [  9.81578064]
 [ 10.66483021]
 [  9.68128872]
 [  9.54760551]
 [ 11.25307846]
 [  9.68128872]]
DEBUG:root:training time = %d0.210921
INFO:root:frame =7777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =7778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.938566666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =7781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =7782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.938535
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:training error  = [[  9.1012888 ]
 [ 10.13575459]
 [ 10.52556229]
 [  9.82720947]
 [ 10.14612961]
 [ 10.10580349]
 [ 10.43338966]
 [  9.78604412]
 [ 10.12038517]
 [  9.14638805]
 [ 11.4611063 ]
 [  8.97705746]
 [ 10.27081394]
 [  9.1620388 ]
 [ 10.19091797]
 [ 11.04008484]]
DEBUG:root:training time = %d0.200742
INFO:root:frame =7785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =7786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.938503333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =7789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =7790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:random_action_porb = 0.938471666667
INFO:root:dqn select action Tensor("ArgMax_59:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00779300000002
INFO:root:action choosen by dqn [4]
INFO:root:frame =7792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.38984108]
 [ 10.00067234]
 [  9.1822567 ]
 [ 10.3243084 ]
 [ 16.65438461]
 [ 11.65024948]
 [ 10.54175663]
 [ 10.48199368]
 [  9.8208971 ]
 [ 10.3243084 ]
 [  9.33691978]
 [  9.24450493]
 [  9.43049717]
 [ 17.13286781]
 [ 10.12021542]
 [ 11.13525009]]
DEBUG:root:training time = %d0.209381
INFO:root:frame =7793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =7794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.93844
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =7797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =7798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.938408333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283000000024
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.05976582]
 [  8.90009689]
 [ 11.15203381]
 [ 11.15203381]
 [  9.45333099]
 [ 10.38875866]
 [ 10.7178154 ]
 [  9.68815041]
 [  4.69747543]
 [  9.2263279 ]
 [  9.1874361 ]
 [ 10.47673321]
 [  9.83661175]
 [ 10.07570362]
 [ 10.05624199]
 [ 10.35377121]]
DEBUG:root:training time = %d0.212177
INFO:root:frame =7801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =7802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.938376666667
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163793563843
INFO:root:frame =7805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:frame =7806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.938345
DEBUG:root: dqn, choose action rondomly, need time 0.000422000000015
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 19.37787628]
 [ 10.4444828 ]
 [  9.73915482]
 [  9.50990105]
 [  9.67846394]
 [ 10.55702114]
 [  8.80095577]
 [  9.22604942]
 [  9.87862682]
 [ 11.67956352]
 [  9.95370483]
 [  9.84551525]
 [  9.54249096]
 [ 10.73083305]
 [ 10.56202888]
 [ 10.48868942]]
DEBUG:root:training time = %d0.212668
INFO:root:frame =7809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =7810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:random_action_porb = 0.938313333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =7813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =7814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:random_action_porb = 0.938281666667
INFO:root:dqn select action Tensor("ArgMax_60:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012779
INFO:root:action choosen by dqn [4]
INFO:root:frame =7816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:training error  = [[ 10.35438538]
 [ 11.00252342]
 [ 10.12715816]
 [ 10.29792309]
 [ 11.34640503]
 [  9.7533741 ]
 [  9.88932419]
 [ 10.46700573]
 [ 10.10267544]
 [  9.88932419]
 [ 10.46320534]
 [ 10.58450508]
 [  9.67613792]
 [  9.45290852]
 [ 10.6818037 ]
 [ 10.35887814]]
DEBUG:root:training time = %d0.209386
INFO:root:frame =7817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028920173645
INFO:root:frame =7818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:frame = 7819 State into memory, numbers recorded 201 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.000582933425903
INFO:root:random_action_porb = 0.93825
DEBUG:root: dqn, choose action rondomly, need time 0.000346000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7820current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =7821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =7822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.938218333333
DEBUG:root: dqn, choose action rondomly, need time 0.000539000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.91239929]
 [  9.74075031]
 [ 10.45471764]
 [  4.89847183]
 [  9.82371807]
 [ 10.18086243]
 [ 10.71491814]
 [  9.8467598 ]
 [ 10.91506004]
 [ 17.6096096 ]
 [ 10.61155319]
 [  9.40979671]
 [ 10.14666367]
 [ 10.99908161]
 [ 10.71491814]
 [  9.47666168]]
DEBUG:root:training time = %d0.219975
INFO:root:frame =7825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =7826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.938186666667
DEBUG:root: dqn, choose action rondomly, need time 0.000335000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =7829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =7830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.938155
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.73765659]
 [ 10.53437614]
 [ 10.2673912 ]
 [ 10.90447617]
 [ 10.63766479]
 [  9.0235672 ]
 [  9.70501804]
 [ 11.26178169]
 [ 16.70174408]
 [ 10.0588789 ]
 [ 18.38064766]
 [ 10.63435555]
 [  9.65851307]
 [  9.81429863]
 [ 10.63435555]
 [ 10.45096779]]
DEBUG:root:training time = %d0.235496
INFO:root:frame =7833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =7834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000254154205322
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.938123333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =7837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =7838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.938091666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294000000025
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.19632626]
 [ 11.24606705]
 [ 11.14566517]
 [ 10.02341366]
 [ 10.34125519]
 [ 10.13514805]
 [  9.98275471]
 [ 10.0790453 ]
 [  9.87282467]
 [ 18.17632866]
 [ 11.24606705]
 [  9.81845856]
 [  9.54581451]
 [  9.51359463]
 [ 10.25793266]
 [  9.96848869]]
DEBUG:root:training time = %d0.220081
INFO:root:frame =7841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =7842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.93806
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =7845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =7846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.938028333333
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000141859054565
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.68304539]
 [ 11.58980846]
 [ 16.36284256]
 [ 10.67068577]
 [  9.68304539]
 [ 16.36284256]
 [  9.61599922]
 [ 16.37099266]
 [  9.80412006]
 [ 10.13250065]
 [ 10.67068577]
 [ 10.15760326]
 [ 11.17217064]
 [ 11.18283272]
 [  9.54086494]
 [ 10.1941824 ]]
DEBUG:root:training time = %d0.199067
INFO:root:frame =7849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292778015137
INFO:root:frame =7850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:random_action_porb = 0.937996666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root:frame =7853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =7854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485897064209
INFO:root:frame = 7855 State into memory, numbers recorded 202 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000683069229126
INFO:root:random_action_porb = 0.937965
DEBUG:root: dqn, choose action rondomly, need time 0.000191999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7856current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.77277851]
 [ 11.29637241]
 [ 10.13024235]
 [ 17.59955788]
 [ 10.75178623]
 [ 10.63679409]
 [  9.02799129]
 [ 10.02150536]
 [ 10.64199448]
 [ 10.04400349]
 [ 11.40659523]
 [ 10.40898228]
 [ 10.882267  ]
 [ 10.35841179]
 [ 10.78180218]
 [ 10.29650307]]
DEBUG:root:training time = %d0.189835
INFO:root:frame =7857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =7858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.937933333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =7861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =7862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:random_action_porb = 0.937901666667
DEBUG:root: dqn, choose action rondomly, need time 0.000386999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000577926635742
INFO:root:training error  = [[ 12.14812756]
 [ 10.47359753]
 [ 11.07392788]
 [  9.78556728]
 [ 10.22682571]
 [  9.78201103]
 [ 10.75588989]
 [  9.85983562]
 [  9.96764565]
 [ 10.05529881]
 [  9.85983562]
 [ 12.14812756]
 [ 10.45716   ]
 [  9.28277302]
 [ 11.185359  ]
 [ 10.1253376 ]]
DEBUG:root:training time = %d0.215726
INFO:root:frame =7865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =7866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000300884246826
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.93787
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000385999679565
INFO:root:frame =7869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261783599854
INFO:root:frame =7870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000258922576904
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.937838333333
DEBUG:root: dqn, choose action rondomly, need time 0.000217000000021
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:training error  = [[ 10.34392929]
 [  9.54317474]
 [ 10.47014141]
 [ 10.92567444]
 [ 11.00586414]
 [ 10.21994591]
 [ 10.62756443]
 [  9.82496166]
 [  9.67108345]
 [ 10.02766514]
 [ 10.46399498]
 [  9.44746685]
 [ 10.15305614]
 [ 10.58065796]
 [ 10.65770531]
 [  9.89477158]]
DEBUG:root:training time = %d0.206758
INFO:root:frame =7873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =7874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000295162200928
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.937806666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =7877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046181678772
INFO:root:frame =7878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.937775
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:training error  = [[ 11.79946995]
 [  8.99402714]
 [ 10.9500494 ]
 [ 13.25456715]
 [ 10.12970734]
 [ 11.16730022]
 [  9.92327881]
 [ 10.2901144 ]
 [ 10.22255611]
 [ 10.78180218]
 [  9.61370373]
 [ 10.15208435]
 [ 10.8847084 ]
 [ 10.98843193]
 [ 10.2826519 ]
 [  9.77871895]]
DEBUG:root:training time = %d0.208216
INFO:root:frame =7881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =7882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.937743333333
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =7885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488996505737
INFO:root:frame =7886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504016876221
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.937711666667
DEBUG:root: dqn, choose action rondomly, need time 0.000473
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333786010742
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.48960304]
 [ 10.44847679]
 [  9.30596256]
 [ 12.05298328]
 [  9.98101902]
 [ 19.81163979]
 [  9.84386349]
 [ 17.03193092]
 [ 10.4729557 ]
 [ 10.7649498 ]
 [ 11.26859379]
 [ 10.14804935]
 [  9.6336565 ]
 [ 10.22902107]
 [ 10.11800671]
 [  9.97309017]]
DEBUG:root:training time = %d0.223652
INFO:root:frame =7889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root:frame =7890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494956970215
DEBUG:root: save sample needs time = 0.000141859054565
INFO:root:random_action_porb = 0.93768
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:frame =7893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =7894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.937648333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 10.66440678]
 [ 11.31486893]
 [ 10.30865002]
 [  9.43712807]
 [ 10.48308086]
 [  9.57950497]
 [ 10.18918896]
 [  9.57950497]
 [ 10.20716953]
 [ 12.0007019 ]
 [ 11.08037758]
 [ 10.43605137]
 [  9.7244463 ]
 [  9.65846539]
 [ 10.48308086]
 [ 10.10340309]]
DEBUG:root:training time = %d0.231912
INFO:root:frame =7897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286817550659
INFO:root:frame =7898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475168228149
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.937616666667
DEBUG:root: dqn, choose action rondomly, need time 0.000323999999978
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =7901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =7902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000318050384521
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.937585
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.761796  ]
 [ 18.1852417 ]
 [ 10.58805466]
 [  9.71707153]
 [  9.81556606]
 [ 10.62224197]
 [ 10.06633377]
 [ 10.34415054]
 [  9.47074413]
 [ 10.34775734]
 [ 10.24181175]
 [ 10.7951088 ]
 [  9.78611565]
 [  9.78611565]
 [ 12.97606182]
 [ 10.791399  ]]
DEBUG:root:training time = %d0.197725
INFO:root:frame =7905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =7906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
INFO:root:frame = 7907 State into memory, numbers recorded 203 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000561952590942
INFO:root:random_action_porb = 0.937553333333
DEBUG:root: dqn, choose action rondomly, need time 0.000318000000021
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7908current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =7909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =7910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227928161621
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.937521666667
DEBUG:root: dqn, choose action rondomly, need time 0.00046900000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.55666924]
 [ 10.50285244]
 [  9.80488396]
 [ 10.07468605]
 [ 10.9163456 ]
 [  9.4379015 ]
 [  9.826684  ]
 [ 11.01540852]
 [  9.52180958]
 [ 10.06570435]
 [ 10.48537827]
 [ 10.08563519]
 [  9.97933197]
 [  9.60672665]
 [  9.97395802]
 [  8.99867249]]
DEBUG:root:training time = %d0.206082
INFO:root:frame =7913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =7914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000353097915649
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:random_action_porb = 0.93749
DEBUG:root: dqn, choose action rondomly, need time 0.000460000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000377178192139
INFO:root:frame =7917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =7918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000498056411743
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.937458333333
DEBUG:root: dqn, choose action rondomly, need time 0.000372999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.86187172]
 [ 19.07889175]
 [ 10.33904648]
 [ 11.01649666]
 [  9.51333618]
 [  9.92741299]
 [ 10.55449295]
 [  9.99290562]
 [  4.74939156]
 [ 10.69549751]
 [  9.71711922]
 [ 10.14532757]
 [ 10.91039753]
 [  9.8028059 ]
 [  9.66323185]
 [  9.83768845]]
DEBUG:root:training time = %d0.19759
INFO:root:frame =7921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =7922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.937426666667
DEBUG:root: dqn, choose action rondomly, need time 0.000535000000013
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =7925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =7926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:random_action_porb = 0.937395
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326156616211
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.64455795]
 [ 10.47199249]
 [ 11.23754883]
 [ 19.15050697]
 [ 10.16127491]
 [ 10.90873432]
 [  9.85473347]
 [ 11.01908016]
 [ 10.56520271]
 [ 10.56909657]
 [ 10.38900471]
 [ 10.47199249]
 [  9.57962322]
 [  9.71115112]
 [ 10.39343166]
 [  9.83529568]]
DEBUG:root:training time = %d0.222493
INFO:root:frame =7929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:frame =7930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.937363333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999985
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =7933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =7934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.937331666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:training error  = [[ 10.33377361]
 [ 10.90140343]
 [ 10.47130108]
 [ 10.36705685]
 [ 10.1522789 ]
 [ 11.54064178]
 [  9.95057583]
 [ 10.59972572]
 [ 10.27218342]
 [ 11.49807072]
 [ 10.83841801]
 [ 10.73870659]
 [ 10.41026211]
 [ 10.2256546 ]
 [ 11.2168169 ]
 [ 12.03939915]]
DEBUG:root:training time = %d0.210743
INFO:root:frame =7937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =7938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame = 7939 State into memory, numbers recorded 204 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000540018081665
INFO:root:random_action_porb = 0.9373
DEBUG:root: dqn, choose action rondomly, need time 0.000327999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7940current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =7941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =7942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000508069992065
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.937268333333
DEBUG:root: dqn, choose action rondomly, need time 0.000486999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.83799076]
 [ 10.83274269]
 [ 10.94964504]
 [ 10.80716991]
 [ 10.61214924]
 [ 10.38713646]
 [  5.13724041]
 [ 10.2484293 ]
 [ 10.51969719]
 [ 10.26492214]
 [  9.67594814]
 [ 10.18575573]
 [  9.56243992]
 [ 10.26492214]
 [  9.61509991]
 [ 10.60049629]]
DEBUG:root:training time = %d0.221905
INFO:root:frame =7945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280141830444
INFO:root:frame =7946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319004058838
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.937236666667
DEBUG:root: dqn, choose action rondomly, need time 0.000605000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =7949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =7950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame = 7951 State into memory, numbers recorded 205 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000549077987671
INFO:root:random_action_porb = 0.937205
DEBUG:root: dqn, choose action rondomly, need time 0.000530999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7952current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.27303886]
 [ 18.66872597]
 [ 10.62522602]
 [ 10.27450657]
 [ 10.36317539]
 [ 10.2338295 ]
 [ 10.83934784]
 [ 11.4349308 ]
 [ 10.15777302]
 [ 10.47539997]
 [ 11.66991901]
 [ 17.88021469]
 [ 10.98438549]
 [ 10.52675056]
 [ 10.27303886]
 [ 10.27450657]]
DEBUG:root:training time = %d0.199333
INFO:root:frame =7953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =7954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.937173333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =7957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =7958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.937141666667
DEBUG:root: dqn, choose action rondomly, need time 0.000180999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.01336765]
 [ 12.54741096]
 [ 10.50784683]
 [ 10.62520123]
 [ 10.99748802]
 [ 10.00156593]
 [ 10.76892948]
 [  9.9583025 ]
 [ 17.49045753]
 [ 11.68762207]
 [  9.53403187]
 [ 10.41691017]
 [ 10.71247101]
 [ 11.12692642]
 [ 10.85970306]
 [ 11.11150932]]
DEBUG:root:training time = %d0.190605
INFO:root:frame =7961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000315189361572
INFO:root:frame =7962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000310897827148
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.93711
DEBUG:root: dqn, choose action rondomly, need time 0.000267000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =7965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000384092330933
INFO:root:frame =7966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:random_action_porb = 0.937078333333
DEBUG:root: dqn, choose action rondomly, need time 0.000183000000021
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.11989975]
 [ 12.00921345]
 [  9.73196507]
 [ 10.0377903 ]
 [ 10.44800854]
 [ 19.52414513]
 [ 11.4148941 ]
 [ 10.98585224]
 [ 10.72730923]
 [  9.89340305]
 [ 10.92943287]
 [ 10.23229122]
 [ 10.92078304]
 [ 10.901227  ]
 [ 11.36118698]
 [ 10.82536125]]
DEBUG:root:training time = %d0.192509
INFO:root:frame =7969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =7970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045919418335
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.937046666667
DEBUG:root: dqn, choose action rondomly, need time 0.000213000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =7973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =7974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000323057174683
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:random_action_porb = 0.937015
DEBUG:root: dqn, choose action rondomly, need time 0.00027
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000176906585693
INFO:root:training error  = [[ 11.66374207]
 [ 10.07751942]
 [ 10.30600452]
 [ 10.72456074]
 [ 10.12099266]
 [ 10.59803677]
 [ 11.93142414]
 [ 10.92285061]
 [ 10.33127213]
 [ 11.46541977]
 [ 10.30600452]
 [ 12.24121666]
 [ 11.56120396]
 [ 11.20657253]
 [  9.55729771]
 [ 10.1467123 ]]
DEBUG:root:training time = %d0.185949
INFO:root:frame =7977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =7978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275135040283
DEBUG:root: save sample needs time = 0.000108003616333
INFO:root:random_action_porb = 0.936983333333
DEBUG:root: dqn, choose action rondomly, need time 0.00326999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:frame =7981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =7982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.936951666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.1547823 ]
 [ 10.74528313]
 [ 10.38797188]
 [ 12.22045803]
 [ 10.38797188]
 [ 11.26055336]
 [ 10.7198143 ]
 [ 10.91072559]
 [ 11.14497757]
 [ 10.55184078]
 [ 10.2667799 ]
 [ 18.25992012]
 [ 11.29609108]
 [ 10.36013031]
 [ 10.62811184]
 [ 10.2149229 ]]
DEBUG:root:training time = %d0.197121
INFO:root:frame =7985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =7986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000318050384521
DEBUG:root: save sample needs time = 0.000135183334351
INFO:root:random_action_porb = 0.93692
DEBUG:root: dqn, choose action rondomly, need time 0.000193999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000178098678589
INFO:root:frame =7989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =7990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.936888333333
DEBUG:root: dqn, choose action rondomly, need time 0.000181999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000130891799927
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.98685265]
 [ 10.07112694]
 [ 10.88541317]
 [ 10.46722794]
 [ 11.16727448]
 [ 10.43341446]
 [ 10.42168713]
 [ 10.15629005]
 [ 11.25730133]
 [ 18.18904877]
 [ 12.13563251]
 [ 10.55412102]
 [ 10.49986076]
 [ 11.29203987]
 [ 10.13543892]
 [ 10.48476124]]
DEBUG:root:training time = %d0.196156
INFO:root:frame =7993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =7994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.936856666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =7997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000424861907959
INFO:root:frame =7998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488042831421
DEBUG:root: save sample needs time = 0.000239133834839
DEBUG:root:one frame running time = 0.005978
DEBUG:root:total training time = 216.935478
INFO:root:frame num = 8000 frame round: 0
INFO:root:random_action_porb = 0.936825
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000023
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17.54755402]
 [ 11.52918816]
 [ 10.52291393]
 [ 10.89047337]
 [ 10.89442635]
 [ 10.7241106 ]
 [ 18.1645546 ]
 [ 10.50178909]
 [ 10.39517784]
 [ 10.4621191 ]
 [ 11.73472309]
 [ 10.69018364]
 [ 10.75116158]
 [ 17.54755402]
 [ 10.7241106 ]
 [  9.98540592]]
DEBUG:root:training time = %d0.184684
INFO:root:frame =8001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =8002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264883041382
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.936793333333
DEBUG:root: dqn, choose action rondomly, need time 0.000240000000019
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000191926956177
INFO:root:frame =8005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =8006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root:random_action_porb = 0.936761666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365972518921
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.82249928]
 [ 10.38966846]
 [ 10.48387146]
 [ 10.5061655 ]
 [ 11.1640625 ]
 [ 10.85847092]
 [ 11.52584648]
 [ 18.63248253]
 [ 12.48295784]
 [  9.92832661]
 [ 10.27519131]
 [ 12.8847599 ]
 [ 10.99384499]
 [ 11.46870136]
 [ 11.31692123]
 [ 19.36780167]]
DEBUG:root:training time = %d0.187352
INFO:root:frame =8009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =8010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000242948532104
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:random_action_porb = 0.93673
DEBUG:root: dqn, choose action rondomly, need time 0.000190000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =8013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =8014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000611066818237
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:random_action_porb = 0.936698333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.02211952]
 [ 10.94388962]
 [ 10.5041132 ]
 [ 11.03488922]
 [ 10.06572819]
 [ 10.56569862]
 [ 11.24442959]
 [ 10.60906792]
 [ 10.81206131]
 [ 18.5050869 ]
 [ 11.03542137]
 [ 10.8529911 ]
 [ 10.43035889]
 [ 10.45035172]
 [ 10.94388962]
 [ 10.6373415 ]]
DEBUG:root:training time = %d0.173609
INFO:root:frame =8017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:frame =8018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00290203094482
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.936666666667
INFO:root:dqn select action Tensor("ArgMax_61:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00765799999999
INFO:root:action choosen by dqn [4]
INFO:root:frame =8020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000176906585693
INFO:root:frame =8021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =8022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000121831893921
INFO:root:random_action_porb = 0.936635
DEBUG:root: dqn, choose action rondomly, need time 0.000201000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:training error  = [[ 11.75922394]
 [ 12.52015781]
 [ 10.67285442]
 [ 10.80253029]
 [ 10.17871952]
 [ 10.44411278]
 [ 10.62040234]
 [ 10.62040234]
 [ 10.62040234]
 [ 11.62409306]
 [ 10.4454937 ]
 [  9.67915249]
 [ 11.2226429 ]
 [ 11.29262924]
 [ 10.11638165]
 [ 11.01837063]]
DEBUG:root:training time = %d0.175579
INFO:root:frame =8025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235795974731
INFO:root:frame =8026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.000136852264404
INFO:root:random_action_porb = 0.936603333333
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999982
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =8029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000507116317749
INFO:root:frame =8030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.936571666667
DEBUG:root: dqn, choose action rondomly, need time 0.000275999999985
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.25650787]
 [ 11.41290855]
 [ 10.66914082]
 [ 11.41131115]
 [ 13.12818241]
 [ 11.05895329]
 [ 11.47691917]
 [ 11.33810616]
 [ 19.54754829]
 [ 12.40517807]
 [ 11.19589901]
 [ 11.30701637]
 [ 12.71672344]
 [ 12.34377193]
 [ 12.34379959]
 [ 12.29000664]]
DEBUG:root:training time = %d0.189468
INFO:root:frame =8033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:frame =8034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000225067138672
DEBUG:root: save sample needs time = 0.000108957290649
INFO:root:random_action_porb = 0.93654
DEBUG:root: dqn, choose action rondomly, need time 0.000160999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:frame =8037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =8038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:random_action_porb = 0.936508333333
DEBUG:root: dqn, choose action rondomly, need time 0.000165999999979
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.83713722]
 [ 17.83533669]
 [  5.39401627]
 [ 12.21648407]
 [  9.93828106]
 [ 10.70273495]
 [ 11.04901028]
 [ 12.03635502]
 [ 10.6940012 ]
 [ 11.05020237]
 [ 11.18344498]
 [ 11.15570259]
 [ 11.67474079]
 [ 12.15754318]
 [  9.93828106]
 [ 10.31994534]]
DEBUG:root:training time = %d0.178248
INFO:root:frame =8041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =8042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 9.91821289062e-05
INFO:root:random_action_porb = 0.936476666667
DEBUG:root: dqn, choose action rondomly, need time 0.000197999999983
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000161170959473
INFO:root:frame =8045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =8046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000338077545166
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:random_action_porb = 0.936445
DEBUG:root: dqn, choose action rondomly, need time 0.000189000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000217199325562
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.95719528]
 [ 11.39711475]
 [ 11.24199963]
 [ 13.25170612]
 [ 11.10894108]
 [ 10.95719528]
 [ 20.24186325]
 [ 12.81906223]
 [ 10.68941021]
 [ 11.10439014]
 [ 11.2693615 ]
 [ 11.13853455]
 [  9.50322056]
 [ 10.1809597 ]
 [ 12.28326797]
 [ 12.24086952]]
DEBUG:root:training time = %d0.178125
INFO:root:frame =8049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275850296021
INFO:root:frame =8050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:random_action_porb = 0.936413333333
DEBUG:root: dqn, choose action rondomly, need time 0.000237999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =8053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =8054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000307083129883
DEBUG:root: save sample needs time = 0.000120878219604
INFO:root:random_action_porb = 0.936381666667
DEBUG:root: dqn, choose action rondomly, need time 0.000189000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174999237061
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.15575409]
 [ 11.00644588]
 [ 11.49222565]
 [ 10.54007149]
 [ 18.48713875]
 [ 10.37224102]
 [ 18.67136383]
 [ 12.27481937]
 [ 10.77351189]
 [ 10.31791115]
 [ 21.59790039]
 [ 11.87038898]
 [ 11.66991901]
 [ 20.63593102]
 [ 21.59790039]
 [ 11.1816082 ]]
DEBUG:root:training time = %d0.191838
INFO:root:frame =8057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root:frame =8058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000289916992188
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root:random_action_porb = 0.93635
DEBUG:root: dqn, choose action rondomly, need time 0.000224000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =8061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =8062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324964523315
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.936318333333
DEBUG:root: dqn, choose action rondomly, need time 0.000188999999978
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.78616047]
 [ 11.03932476]
 [ 12.3853817 ]
 [ 10.86131191]
 [ 12.15086651]
 [ 10.65984726]
 [ 12.02772808]
 [ 11.11555386]
 [ 12.09479046]
 [ 11.1899519 ]
 [ 11.74625111]
 [ 20.65270805]
 [ 10.82056713]
 [ 11.3734827 ]
 [ 10.45353317]
 [ 10.56746006]]
DEBUG:root:training time = %d0.183945
INFO:root:frame =8065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =8066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00032114982605
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.936286666667
DEBUG:root: dqn, choose action rondomly, need time 0.000228000000021
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =8069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =8070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000391006469727
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root:random_action_porb = 0.936255
DEBUG:root: dqn, choose action rondomly, need time 0.000195999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.4462328 ]
 [ 10.17404652]
 [ 17.97373199]
 [ 12.0640583 ]
 [ 11.51108742]
 [ 11.26785088]
 [ 19.57417107]
 [ 11.99676418]
 [ 11.4817009 ]
 [ 11.72416592]
 [ 12.57315254]
 [ 19.57417107]
 [ 11.4817009 ]
 [ 12.50202274]
 [ 10.8589735 ]
 [ 12.73904228]]
DEBUG:root:training time = %d0.202548
INFO:root:frame =8073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =8074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame = 8075 State into memory, numbers recorded 206 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:random_action_porb = 0.936223333333
DEBUG:root: dqn, choose action rondomly, need time 0.000168000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8076current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:frame =8077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =8078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324964523315
DEBUG:root: save sample needs time = 0.000125169754028
INFO:root:random_action_porb = 0.936191666667
DEBUG:root: dqn, choose action rondomly, need time 0.000234000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000184059143066
INFO:root:training error  = [[ 10.9277935 ]
 [ 13.15376472]
 [ 10.69821739]
 [ 11.77715206]
 [ 11.88235188]
 [ 11.60994625]
 [ 11.04756451]
 [ 10.90150356]
 [ 10.78185272]
 [ 11.20172024]
 [ 11.03826046]
 [ 10.12118626]
 [ 12.28155613]
 [ 11.03653622]
 [ 10.65145493]
 [ 10.82972908]]
DEBUG:root:training time = %d0.220772
INFO:root:frame =8081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:frame =8082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:frame = 8083 State into memory, numbers recorded 207 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:random_action_porb = 0.93616
DEBUG:root: dqn, choose action rondomly, need time 0.000319999999988
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8084current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =8085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =8086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.936128333333
DEBUG:root: dqn, choose action rondomly, need time 0.000330999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.63015079]
 [ 12.00543308]
 [ 11.16072369]
 [ 11.16577053]
 [ 18.57002831]
 [ 11.51582527]
 [ 13.88652897]
 [ 12.25539494]
 [ 11.21081257]
 [ 11.49892521]
 [  5.82639027]
 [ 11.65300941]
 [ 11.42159653]
 [ 12.65403461]
 [ 10.41932297]
 [ 13.2526226 ]]
DEBUG:root:training time = %d0.218109
INFO:root:frame =8089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =8090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000360012054443
DEBUG:root: save sample needs time = 0.000173091888428
INFO:root:random_action_porb = 0.936096666667
DEBUG:root: dqn, choose action rondomly, need time 0.00035299999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000348806381226
INFO:root:frame =8093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000358819961548
INFO:root:frame =8094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000405073165894
DEBUG:root: save sample needs time = 0.000167846679688
INFO:root:random_action_porb = 0.936065
DEBUG:root: dqn, choose action rondomly, need time 0.000395999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.14286327]
 [ 18.97535896]
 [ 18.97535896]
 [  9.85552406]
 [ 11.30606747]
 [ 10.9323082 ]
 [ 11.42902374]
 [ 11.04728603]
 [ 10.88485909]
 [ 11.43663406]
 [ 11.07291222]
 [ 10.91911888]
 [ 10.75969315]
 [ 10.84899521]
 [ 12.23326302]
 [ 10.80373383]]
DEBUG:root:training time = %d0.210701
INFO:root:frame =8097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =8098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000595092773438
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.936033333333
DEBUG:root: dqn, choose action rondomly, need time 0.000360000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =8101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000584125518799
INFO:root:frame =8102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000305891036987
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:random_action_porb = 0.936001666667
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.43039036]
 [ 12.14427185]
 [ 11.36661339]
 [ 12.01624775]
 [ 11.60485172]
 [ 11.76178837]
 [ 10.76792812]
 [ 12.04493332]
 [ 12.15748978]
 [ 12.1309824 ]
 [ 18.46067619]
 [ 11.10713577]
 [ 10.3764677 ]
 [ 11.68326664]
 [ 11.30114269]
 [ 10.3764677 ]]
DEBUG:root:training time = %d0.214248
INFO:root:frame =8105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =8106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000505924224854
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:random_action_porb = 0.93597
DEBUG:root: dqn, choose action rondomly, need time 0.000346999999977
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:frame =8109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000407934188843
INFO:root:frame =8110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:random_action_porb = 0.935938333333
DEBUG:root: dqn, choose action rondomly, need time 0.000558000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000402927398682
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.41176224]
 [ 12.21659088]
 [ 11.06128788]
 [  6.0595932 ]
 [ 12.42872906]
 [ 11.61748695]
 [ 11.31715298]
 [ 12.22480583]
 [ 11.08715916]
 [ 11.5996027 ]
 [ 12.84830761]
 [ 11.85099792]
 [ 10.70440674]
 [ 11.56314945]
 [ 11.27586842]
 [ 20.38384247]]
DEBUG:root:training time = %d0.206015
INFO:root:frame =8113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =8114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:random_action_porb = 0.935906666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =8117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000492095947266
INFO:root:frame =8118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000498056411743
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:random_action_porb = 0.935875
DEBUG:root: dqn, choose action rondomly, need time 0.000164000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.49506474]
 [ 13.01195145]
 [ 10.55223751]
 [ 10.28872013]
 [ 11.54100418]
 [  9.85152435]
 [ 19.48428535]
 [ 11.98107243]
 [ 10.9533062 ]
 [ 11.93941021]
 [ 10.92516994]
 [ 11.17913342]
 [ 10.72548485]
 [ 10.82857418]
 [ 10.5038166 ]
 [ 10.49506474]]
DEBUG:root:training time = %d0.215065
INFO:root:frame =8121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =8122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame = 8123 State into memory, numbers recorded 208 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000525951385498
INFO:root:random_action_porb = 0.935843333333
DEBUG:root: dqn, choose action rondomly, need time 0.00034500000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8124current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =8125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000486135482788
INFO:root:frame =8126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 9.29832458496e-05
INFO:root:random_action_porb = 0.935811666667
INFO:root:dqn select action Tensor("ArgMax_62:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012235
INFO:root:action choosen by dqn [4]
INFO:root:frame =8128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:training error  = [[ 11.3539362 ]
 [ 13.73863029]
 [ 11.37911797]
 [ 12.10776806]
 [ 10.89261341]
 [ 11.880826  ]
 [ 12.10875034]
 [ 11.94977283]
 [ 11.24875355]
 [ 12.01714611]
 [ 12.1528883 ]
 [ 11.2702322 ]
 [ 10.73350716]
 [ 12.85886574]
 [ 11.7190733 ]
 [ 11.17380238]]
DEBUG:root:training time = %d0.224312
INFO:root:frame =8129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =8130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.93578
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =8133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00051212310791
INFO:root:frame =8134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456809997559
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.935748333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.35301113]
 [ 10.33443546]
 [ 10.94666672]
 [ 11.22788334]
 [ 11.54224873]
 [ 10.94005394]
 [ 11.66827679]
 [ 11.10830498]
 [ 10.90578651]
 [ 19.76745033]
 [ 18.34491348]
 [ 11.59326363]
 [ 12.89423752]
 [ 10.16482639]
 [ 11.44703388]
 [ 12.89423752]]
DEBUG:root:training time = %d0.236128
INFO:root:frame =8137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =8138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
DEBUG:root: save sample needs time = 0.000115156173706
INFO:root:random_action_porb = 0.935716666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =8141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =8142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.935685
DEBUG:root: dqn, choose action rondomly, need time 0.000256000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.05081177]
 [ 12.46447372]
 [ 14.00262547]
 [ 10.82014084]
 [ 11.82605934]
 [ 12.23587799]
 [ 11.42053986]
 [ 11.38926029]
 [ 12.59632015]
 [  5.97835922]
 [ 12.46447372]
 [ 11.37857723]
 [ 11.09963608]
 [ 11.41226482]
 [ 11.34918118]
 [ 12.87232971]]
DEBUG:root:training time = %d0.239675
INFO:root:frame =8145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =8146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000499963760376
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.935653333333
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000351905822754
INFO:root:frame =8149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265836715698
INFO:root:frame =8150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000515937805176
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:random_action_porb = 0.935621666667
DEBUG:root: dqn, choose action rondomly, need time 0.000335999999976
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.8935957 ]
 [ 10.6602459 ]
 [ 10.70518112]
 [ 20.71558189]
 [ 11.582407  ]
 [ 11.66538429]
 [ 11.55669022]
 [ 11.90134716]
 [ 11.58386135]
 [ 13.34089661]
 [ 11.3512888 ]
 [ 11.95789719]
 [ 11.17135429]
 [ 11.74010754]
 [ 11.42551613]
 [ 12.81280804]]
DEBUG:root:training time = %d0.214558
INFO:root:frame =8153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =8154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000495910644531
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.93559
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =8157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =8158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.935558333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00041389465332
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.10797501]
 [ 11.10812759]
 [ 20.15220261]
 [  9.68648815]
 [ 11.94381332]
 [ 11.91380024]
 [ 11.52009773]
 [ 12.31446552]
 [ 11.85152245]
 [ 12.12372875]
 [ 13.34950924]
 [ 11.83188438]
 [ 11.92517853]
 [ 11.77398396]
 [ 11.37196445]
 [ 11.9418354 ]]
DEBUG:root:training time = %d0.22049
INFO:root:frame =8161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =8162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259876251221
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.935526666667
DEBUG:root: dqn, choose action rondomly, need time 0.000214999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:frame =8165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =8166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.935495
INFO:root:dqn select action Tensor("ArgMax_63:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011011
INFO:root:action choosen by dqn [4]
INFO:root:frame =8168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000166893005371
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.23064423]
 [ 11.52561378]
 [ 11.31384182]
 [ 12.12997246]
 [ 10.87089443]
 [ 10.85326767]
 [ 13.62577629]
 [ 11.68650055]
 [ 11.64249039]
 [ 11.1024065 ]
 [ 11.29173183]
 [ 13.08208656]
 [ 11.25845337]
 [ 11.26116753]
 [ 12.77334881]
 [ 19.96072769]]
DEBUG:root:training time = %d0.222712
INFO:root:frame =8169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =8170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000383138656616
INFO:root:frame = 8171 State into memory, numbers recorded 209 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00129008293152
INFO:root:random_action_porb = 0.935463333333
INFO:root:dqn select action Tensor("ArgMax_64:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011688
INFO:root:action choosen by dqn [4]
INFO:root:frame =8172current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000958204269409
INFO:root:frame =8173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000549077987671
INFO:root:frame =8174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.935431666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.09140205]
 [ 11.86134815]
 [ 13.28430462]
 [ 11.21150208]
 [ 19.38956642]
 [ 11.30937672]
 [ 11.47019958]
 [ 11.99139977]
 [ 11.57669544]
 [ 11.54027843]
 [ 11.19434166]
 [ 11.32421207]
 [ 11.63036251]
 [ 20.91796303]
 [ 11.52942181]
 [ 11.48273468]]
DEBUG:root:training time = %d0.229415
INFO:root:frame =8177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =8178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9354
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =8181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000429153442383
INFO:root:frame =8182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.935368333333
INFO:root:dqn select action Tensor("ArgMax_65:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.049626
INFO:root:action choosen by dqn [4]
INFO:root:frame =8184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.2542305 ]
 [ 13.11743164]
 [ 11.71176147]
 [ 13.49880695]
 [ 11.00495243]
 [ 12.12189579]
 [ 11.71661758]
 [  6.90372896]
 [ 12.89763451]
 [ 11.51098442]
 [ 13.47367477]
 [ 13.69144535]
 [ 12.6274519 ]
 [ 11.33610249]
 [ 12.54746532]
 [ 13.53325081]]
DEBUG:root:training time = %d0.24145
INFO:root:frame =8185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =8186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:random_action_porb = 0.935336666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =8189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =8190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.935305
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.89305782]
 [ 12.09038639]
 [ 11.90045261]
 [ 21.02204132]
 [ 12.52463913]
 [ 11.79032612]
 [ 10.97932911]
 [ 11.73312855]
 [ 12.65596104]
 [ 12.11708832]
 [ 11.73312855]
 [ 12.50580025]
 [ 10.78571129]
 [ 11.51191616]
 [ 12.31114578]
 [ 13.6438055 ]]
DEBUG:root:training time = %d0.23717
INFO:root:frame =8193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =8194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:random_action_porb = 0.935273333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =8197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =8198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:player has been killed for 4 times 
INFO:root:frame =8200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:training error  = [[ 11.16146278]
 [ 11.81234169]
 [ 11.59518528]
 [ 12.39166546]
 [ 12.14198589]
 [ 12.72132111]
 [ 12.24663544]
 [ 12.3201685 ]
 [ 11.0736742 ]
 [ 11.77194214]
 [ 12.58208084]
 [ 11.70682716]
 [ 11.79244804]
 [ 11.73772812]
 [ 11.33402157]
 [ 11.59526348]]
DEBUG:root:training time = %d0.235771
INFO:root:frame =8201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =8202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame = 8203 State into memory, numbers recorded 210 action = 0, reward = -1
DEBUG:root: save sample needs time = 0.000554084777832
INFO:root:random_action_porb = 0.935241666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8204current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =8205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =8206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.93521
INFO:root:dqn select action Tensor("ArgMax_66:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013484
INFO:root:action choosen by dqn [4]
INFO:root:frame =8208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 19.75581741]
 [ 21.55441666]
 [ 11.72939205]
 [ 11.72939205]
 [ 10.59493256]
 [ 11.40971279]
 [ 11.73770237]
 [ 11.38835907]
 [ 12.55462837]
 [ 11.40726471]
 [ 12.35658836]
 [ 12.51667595]
 [ 11.44533062]
 [ 12.14443207]
 [ 12.19675922]
 [ 11.83356476]]
DEBUG:root:training time = %d0.226526
INFO:root:frame =8209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame =8210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame = 8211 State into memory, numbers recorded 211 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.0012469291687
INFO:root:random_action_porb = 0.935178333333
DEBUG:root: dqn, choose action rondomly, need time 0.000164000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8212current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000342845916748
INFO:root:frame =8213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =8214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.935146666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000275850296021
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.86452961]
 [ 11.95998192]
 [ 13.56203461]
 [ 21.404953  ]
 [ 13.59819126]
 [ 11.19556713]
 [ 11.27743053]
 [ 11.65394783]
 [ 12.51035976]
 [ 11.64043427]
 [ 10.7020359 ]
 [ 10.99414825]
 [ 13.29554081]
 [ 22.52080727]
 [ 11.52584648]
 [ 11.83742237]]
DEBUG:root:training time = %d0.218819
INFO:root:frame =8217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =8218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.935115
INFO:root:dqn select action Tensor("ArgMax_67:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014331
INFO:root:action choosen by dqn [4]
INFO:root:frame =8220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162839889526
INFO:root:frame =8221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =8222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame = 8223 State into memory, numbers recorded 212 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00121998786926
INFO:root:random_action_porb = 0.935083333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999977
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8224current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.57499218]
 [ 12.72817993]
 [ 12.78529453]
 [ 20.51874542]
 [ 13.31493759]
 [ 11.7443161 ]
 [ 11.36334705]
 [ 12.47120857]
 [ 11.98265648]
 [ 11.55881691]
 [ 12.88262367]
 [ 11.08568573]
 [ 13.80499649]
 [ 13.22905254]
 [ 11.54458141]
 [ 12.84483433]]
DEBUG:root:training time = %d0.246115
INFO:root:frame =8225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: ememy has been killed for 17 times 
INFO:root:enemies_left [0]
INFO:root:frame =8226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame = 8227 State into memory, numbers recorded 213 action = 0, reward = 1
DEBUG:root: save sample needs time = 0.000539779663086
INFO:root:random_action_porb = 0.935051666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8228current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =8229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =8230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.93502
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.33345509]
 [ 12.49163914]
 [ 12.85246468]
 [ 12.14943027]
 [ 11.59069157]
 [ 19.93806648]
 [ 12.23227596]
 [ 12.09311867]
 [ 12.99164867]
 [ 11.38462639]
 [ 12.4996767 ]
 [ 10.78150177]
 [ 11.95394039]
 [ 10.78150177]
 [ 11.57550144]
 [ 11.04193592]]
DEBUG:root:training time = %d0.223414
INFO:root:frame =8233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000373125076294
INFO:root:frame =8234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000356912612915
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.934988333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999981
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =8237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000381946563721
INFO:root:frame =8238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.934956666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:training error  = [[  9.99198914]
 [ 12.10365391]
 [ 11.40662098]
 [ 12.66098309]
 [ 13.51515388]
 [ 12.4007988 ]
 [ 11.50743771]
 [ 10.67504787]
 [ 11.96934986]
 [ 11.34694481]
 [ 12.56325245]
 [ 11.55505657]
 [ 12.95916462]
 [ 11.71552086]
 [ 11.47177601]
 [ 12.36624527]]
DEBUG:root:training time = %d0.235659
INFO:root:frame =8241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000333786010742
INFO:root:frame =8242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.934925
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =8245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000540018081665
INFO:root:frame =8246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.934893333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:training error  = [[ 14.30717087]
 [ 12.47112751]
 [ 11.62052917]
 [ 11.47828865]
 [ 11.76840878]
 [ 12.5639286 ]
 [ 10.91818619]
 [ 11.61436653]
 [ 10.43822098]
 [ 12.5639286 ]
 [ 13.15011311]
 [ 11.16811657]
 [ 12.52005005]
 [ 12.76887798]
 [ 11.48894024]
 [ 11.96876907]]
DEBUG:root:training time = %d0.233585
INFO:root:frame =8249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270843505859
INFO:root:frame =8250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame = 8251 State into memory, numbers recorded 214 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:random_action_porb = 0.934861666667
DEBUG:root: dqn, choose action rondomly, need time 0.000177000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8252current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root:frame =8253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268220901489
INFO:root:frame =8254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.93483
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.22872734]
 [ 19.53442764]
 [ 12.1833601 ]
 [ 11.51041508]
 [ 11.01439571]
 [ 19.75714111]
 [ 11.9911623 ]
 [ 20.26188087]
 [ 11.76388168]
 [ 11.0415554 ]
 [ 10.84193516]
 [ 11.92185974]
 [ 13.36333847]
 [ 11.76419544]
 [ 11.16597462]
 [ 12.80368805]]
DEBUG:root:training time = %d0.21725
INFO:root:frame =8257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =8258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.934798333333
DEBUG:root: dqn, choose action rondomly, need time 0.000481999999977
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =8261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =8262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.934766666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999985
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000392913818359
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.94554615]
 [ 11.53807545]
 [ 12.89892197]
 [ 20.01755524]
 [ 12.01989746]
 [ 12.79850197]
 [ 12.62755966]
 [ 11.10105991]
 [ 12.54484367]
 [ 19.22556686]
 [ 11.24657917]
 [ 11.82989025]
 [ 11.4285593 ]
 [ 12.70228004]
 [ 11.44089127]
 [ 11.60742569]]
DEBUG:root:training time = %d0.225688
INFO:root:frame =8265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =8266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000126838684082
INFO:root:random_action_porb = 0.934735
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =8269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000498056411743
INFO:root:frame =8270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000246047973633
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.934703333333
INFO:root:dqn select action Tensor("ArgMax_68:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01459
INFO:root:action choosen by dqn [4]
INFO:root:frame =8272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.02106094]
 [ 11.36381054]
 [ 11.87822342]
 [ 11.35820389]
 [ 11.50270271]
 [ 13.81446552]
 [ 11.72327805]
 [ 11.97972584]
 [ 20.75164223]
 [ 11.46846867]
 [ 19.38298225]
 [ 11.52020073]
 [ 11.51238155]
 [ 12.05801678]
 [ 12.01556015]
 [ 13.33315086]]
DEBUG:root:training time = %d0.228253
INFO:root:frame =8273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =8274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.934671666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =8277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =8278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.93464
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.16597462]
 [ 11.58238125]
 [ 13.46367931]
 [ 13.29367733]
 [ 14.48673725]
 [ 21.73220444]
 [ 12.03958511]
 [ 12.05865288]
 [ 13.29656982]
 [ 12.32434654]
 [ 11.55772781]
 [ 13.16558266]
 [  5.71355581]
 [ 11.16597462]
 [ 13.752491  ]
 [ 20.75053024]]
DEBUG:root:training time = %d0.238154
INFO:root:frame =8281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =8282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000412940979004
INFO:root:frame = 8283 State into memory, numbers recorded 215 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000605821609497
INFO:root:random_action_porb = 0.934608333333
INFO:root:dqn select action Tensor("ArgMax_69:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013508
INFO:root:action choosen by dqn [4]
INFO:root:frame =8284current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000388860702515
INFO:root:frame =8285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =8286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000282049179077
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.934576666667
DEBUG:root: dqn, choose action rondomly, need time 0.000528000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.83618927]
 [ 12.31781197]
 [ 12.00767994]
 [ 13.25842857]
 [ 11.86544704]
 [ 13.89011097]
 [ 12.2830801 ]
 [ 11.91048241]
 [ 13.2022047 ]
 [ 12.0826149 ]
 [ 21.34090042]
 [ 12.8725214 ]
 [ 12.25133514]
 [ 13.4242363 ]
 [ 11.93645763]
 [ 12.2830801 ]]
DEBUG:root:training time = %d0.225812
INFO:root:frame =8289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =8290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000232219696045
INFO:root:random_action_porb = 0.934545
DEBUG:root: dqn, choose action rondomly, need time 0.000354999999985
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =8293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =8294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.934513333333
DEBUG:root: dqn, choose action rondomly, need time 0.000429999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.99698448]
 [ 21.27096176]
 [ 13.38887024]
 [ 12.13560581]
 [ 11.39701176]
 [ 12.6219759 ]
 [ 12.13449001]
 [ 12.85599327]
 [ 12.74647808]
 [ 14.7866745 ]
 [  5.77961636]
 [ 11.96288395]
 [ 11.1136713 ]
 [ 12.71756649]
 [ 11.94768906]
 [ 12.33211517]]
DEBUG:root:training time = %d0.226392
INFO:root:frame =8297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =8298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000284910202026
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.934481666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =8301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488042831421
INFO:root:frame =8302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.93445
DEBUG:root: dqn, choose action rondomly, need time 0.000332000000014
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.19324207]
 [ 12.19223022]
 [ 12.60300922]
 [ 13.23798943]
 [ 13.06809902]
 [ 11.92038441]
 [ 20.09839821]
 [ 12.91843891]
 [ 11.65811539]
 [ 13.40082073]
 [ 12.50331783]
 [ 12.63824368]
 [ 12.54387093]
 [ 12.47640896]
 [ 20.82831192]
 [ 11.97444439]]
DEBUG:root:training time = %d0.24123
INFO:root:frame =8305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023078918457
INFO:root:frame =8306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.934418333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000395059585571
INFO:root:frame =8309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =8310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.934386666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.68845654]
 [ 20.0444622 ]
 [ 12.0401144 ]
 [ 12.86819649]
 [ 11.93197727]
 [ 12.57826614]
 [ 12.53846741]
 [ 12.53846741]
 [ 11.9021101 ]
 [ 11.83272457]
 [ 12.6134119 ]
 [ 13.80142498]
 [ 12.01571846]
 [ 11.83865643]
 [ 11.94220448]
 [ 11.7528677 ]]
DEBUG:root:training time = %d0.212328
INFO:root:frame =8313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root:frame =8314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000307083129883
DEBUG:root: save sample needs time = 0.000168800354004
INFO:root:random_action_porb = 0.934355
DEBUG:root: dqn, choose action rondomly, need time 0.000349
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =8317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =8318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491857528687
INFO:root:frame = 8319 State into memory, numbers recorded 216 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000505924224854
INFO:root:random_action_porb = 0.934323333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8320current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:training error  = [[ 12.82996368]
 [ 13.70228767]
 [ 13.70228767]
 [ 13.56088257]
 [ 11.68016338]
 [ 13.23071766]
 [ 11.87916946]
 [ 10.99531174]
 [ 11.70588684]
 [ 13.82564068]
 [ 11.78726101]
 [ 12.8199091 ]
 [ 12.00001431]
 [ 12.72251892]
 [ 13.66825008]
 [ 11.70588684]]
DEBUG:root:training time = %d0.230175
INFO:root:frame =8321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =8322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233888626099
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.934291666667
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =8325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =8326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000548124313354
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.93426
DEBUG:root: dqn, choose action rondomly, need time 0.000568000000015
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.74915409]
 [ 12.22032452]
 [ 11.39917564]
 [ 13.1048069 ]
 [  5.94136906]
 [ 19.50867462]
 [ 12.60555553]
 [ 12.2812624 ]
 [ 13.50536728]
 [ 12.24006844]
 [ 12.7912426 ]
 [ 11.80083275]
 [ 12.41574097]
 [ 11.47187901]
 [ 12.14661217]
 [ 12.68934059]]
DEBUG:root:training time = %d0.232029
INFO:root:frame =8329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:frame =8330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.934228333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =8333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =8334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.934196666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:training error  = [[ 11.66780758]
 [ 12.88232231]
 [ 11.5480814 ]
 [ 12.32831097]
 [ 12.13938046]
 [ 12.60728931]
 [ 12.37775707]
 [ 12.89530563]
 [ 11.83639908]
 [ 12.65750885]
 [ 12.73498535]
 [ 11.96473122]
 [ 11.39278793]
 [ 12.02069092]
 [ 11.58830261]
 [ 11.67750454]]
DEBUG:root:training time = %d0.231359
INFO:root:frame =8337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00048303604126
INFO:root:frame =8338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.934165
DEBUG:root: dqn, choose action rondomly, need time 0.000331000000017
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root:frame =8341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046181678772
INFO:root:frame =8342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476837158203
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.934133333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.91898727]
 [  7.04108047]
 [ 12.16927719]
 [ 13.63278961]
 [ 12.34589005]
 [ 12.38334084]
 [ 11.87475204]
 [ 12.31374264]
 [ 13.91930008]
 [ 12.51152039]
 [ 12.86141014]
 [ 12.37437534]
 [ 12.36793518]
 [ 11.71716595]
 [ 12.11212254]
 [ 12.99527931]]
DEBUG:root:training time = %d0.222214
INFO:root:frame =8345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =8346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root:random_action_porb = 0.934101666667
INFO:root:dqn select action Tensor("ArgMax_70:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014921
INFO:root:action choosen by dqn [4]
INFO:root:frame =8348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:frame =8349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =8350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480175018311
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.93407
DEBUG:root: dqn, choose action rondomly, need time 0.000336000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.77449417]
 [ 12.68640614]
 [ 12.86387253]
 [ 12.77154922]
 [ 11.91580105]
 [ 11.37868023]
 [ 12.38903332]
 [ 12.51513672]
 [ 12.87799644]
 [ 11.93703747]
 [ 12.95647335]
 [ 12.46374607]
 [ 12.87799644]
 [ 12.38736916]
 [  6.69757271]
 [ 11.54211903]]
DEBUG:root:training time = %d0.217311
INFO:root:frame =8353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =8354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000323057174683
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root:random_action_porb = 0.934038333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =8357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame =8358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000511169433594
INFO:root:frame = 8359 State into memory, numbers recorded 217 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000536918640137
INFO:root:random_action_porb = 0.934006666667
DEBUG:root: dqn, choose action rondomly, need time 0.000321000000014
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8360current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:training error  = [[ 12.75584984]
 [ 12.03799629]
 [ 13.02477932]
 [ 12.3001461 ]
 [ 12.39752102]
 [ 12.48632812]
 [ 11.76767635]
 [ 12.4951725 ]
 [ 12.42504406]
 [ 11.98152161]
 [ 12.48196125]
 [ 12.631464  ]
 [ 12.8629427 ]
 [ 12.94702816]
 [ 12.68069935]
 [ 12.63705063]]
DEBUG:root:training time = %d0.233359
INFO:root:frame =8361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =8362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.933975
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =8365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =8366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.933943333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.7161293 ]
 [ 12.00339794]
 [ 12.48670578]
 [ 12.33586597]
 [ 20.95056725]
 [ 12.00339794]
 [ 13.41803074]
 [ 12.57317924]
 [ 11.58596516]
 [ 12.04710388]
 [ 12.15847397]
 [ 12.03005695]
 [ 11.73226643]
 [ 11.94273186]
 [ 12.44796753]
 [ 12.34701633]]
DEBUG:root:training time = %d0.239224
INFO:root:frame =8369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =8370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000362873077393
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.933911666667
DEBUG:root: dqn, choose action rondomly, need time 0.000325000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =8373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000556945800781
INFO:root:frame =8374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame = 8375 State into memory, numbers recorded 218 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.00058913230896
INFO:root:random_action_porb = 0.93388
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8376current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:training error  = [[ 12.07932663]
 [ 13.93911839]
 [ 12.43026161]
 [ 14.02138901]
 [ 12.25667667]
 [ 11.50870609]
 [ 11.91838264]
 [ 13.64039612]
 [ 13.31293297]
 [ 12.265172  ]
 [ 12.56533527]
 [ 13.54622078]
 [ 12.14379311]
 [ 13.09254646]
 [ 13.62281895]
 [ 11.57282829]]
DEBUG:root:training time = %d0.22037
INFO:root:frame =8377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =8378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000304937362671
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.933848333333
DEBUG:root: dqn, choose action rondomly, need time 0.000175000000013
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000166893005371
INFO:root:frame =8381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame =8382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.933816666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000015
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14.6177063 ]
 [ 12.86496735]
 [ 12.45814419]
 [ 11.88064194]
 [ 13.37430191]
 [ 12.0028162 ]
 [ 12.55165482]
 [ 12.96800995]
 [ 13.4801445 ]
 [ 13.21324062]
 [ 12.71740341]
 [ 11.85309887]
 [ 12.9698782 ]
 [ 12.09927464]
 [ 14.46984196]
 [ 22.3549633 ]]
DEBUG:root:training time = %d0.241911
INFO:root:frame =8385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =8386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:random_action_porb = 0.933785
DEBUG:root: dqn, choose action rondomly, need time 0.000324000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =8389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =8390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:random_action_porb = 0.933753333333
DEBUG:root: dqn, choose action rondomly, need time 0.000326000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root: ememy has been killed for 18 times 
INFO:root:enemies_left [0]
INFO:root:frame =8392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000315189361572
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.6355505 ]
 [ 12.08452415]
 [ 13.0578413 ]
 [ 12.47576237]
 [ 13.0258255 ]
 [ 13.01228142]
 [  7.29760742]
 [ 12.95636368]
 [ 12.81898022]
 [ 12.65636826]
 [ 12.66206932]
 [ 13.84505081]
 [ 13.10558033]
 [ 13.10055351]
 [ 13.29462242]
 [ 12.19787788]]
DEBUG:root:training time = %d0.230526
INFO:root:frame =8393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =8394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
INFO:root:frame = 8395 State into memory, numbers recorded 219 action = 2, reward = 1
DEBUG:root: save sample needs time = 0.000728845596313
INFO:root:random_action_porb = 0.933721666667
DEBUG:root: dqn, choose action rondomly, need time 0.000508999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8396current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000660181045532
INFO:root:frame =8397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000539064407349
INFO:root:frame =8398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000499963760376
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.93369
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 20.94288445]
 [ 13.20741749]
 [ 22.03349495]
 [ 12.26613426]
 [ 13.27810383]
 [ 13.056077  ]
 [ 11.91643333]
 [ 11.91016579]
 [ 12.36326694]
 [ 14.1716013 ]
 [ 13.01828194]
 [ 13.7768898 ]
 [ 14.1716013 ]
 [ 13.05001259]
 [ 13.38507366]
 [ 12.62978363]]
DEBUG:root:training time = %d0.225861
INFO:root:frame =8401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root:frame =8402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.933658333333
DEBUG:root: dqn, choose action rondomly, need time 0.000560999999976
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =8405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427961349487
INFO:root:frame =8406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame = 8407 State into memory, numbers recorded 220 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000572919845581
INFO:root:random_action_porb = 0.933626666667
DEBUG:root: dqn, choose action rondomly, need time 0.000538000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8408current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.49495602]
 [ 13.2490406 ]
 [ 11.70776653]
 [ 13.86458874]
 [ 12.06692028]
 [ 12.4763546 ]
 [ 12.2922802 ]
 [ 20.8656559 ]
 [ 11.16872787]
 [ 12.85112476]
 [ 21.41978073]
 [ 12.34605122]
 [ 13.86458874]
 [ 12.52917576]
 [ 12.16799927]
 [ 12.11366272]]
DEBUG:root:training time = %d0.234749
INFO:root:frame =8409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =8410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.933595
INFO:root:dqn select action Tensor("ArgMax_71:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00828300000001
INFO:root:action choosen by dqn [4]
INFO:root:frame =8412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =8413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:frame =8414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000357151031494
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:random_action_porb = 0.933563333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:training error  = [[ 12.53868389]
 [ 12.01788712]
 [ 12.41552544]
 [ 12.65202618]
 [ 11.99361992]
 [ 14.10063457]
 [ 12.72768974]
 [ 13.48221779]
 [ 11.55544567]
 [ 12.48282337]
 [ 14.1056776 ]
 [ 13.9394598 ]
 [ 13.35193443]
 [ 12.8214941 ]
 [ 12.03640842]
 [ 13.84471035]]
DEBUG:root:training time = %d0.213352
INFO:root:frame =8417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268220901489
INFO:root:frame =8418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000351905822754
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:random_action_porb = 0.933531666667
INFO:root:dqn select action Tensor("ArgMax_72:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015654
INFO:root:action choosen by dqn [4]
INFO:root:frame =8420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000161170959473
INFO:root:frame =8421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =8422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046181678772
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9335
DEBUG:root: dqn, choose action rondomly, need time 0.000550999999973
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:training error  = [[ 13.79348946]
 [ 13.71573448]
 [ 11.78417015]
 [ 13.29846191]
 [ 13.29428864]
 [ 13.57324696]
 [ 13.32574177]
 [ 13.52982712]
 [ 13.78289413]
 [ 12.78966045]
 [ 12.55889988]
 [ 12.29281521]
 [ 12.85675907]
 [ 13.12071991]
 [ 13.29428864]
 [ 12.99065876]]
DEBUG:root:training time = %d0.225465
INFO:root:frame =8425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000347852706909
INFO:root:frame =8426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047779083252
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:random_action_porb = 0.933468333333
DEBUG:root: dqn, choose action rondomly, need time 0.000410000000016
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =8429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =8430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000364065170288
INFO:root:frame = 8431 State into memory, numbers recorded 221 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000593185424805
INFO:root:random_action_porb = 0.933436666667
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8432current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:training error  = [[ 12.01529503]
 [ 13.892272  ]
 [ 13.41965199]
 [ 13.6948328 ]
 [ 13.20397949]
 [ 12.92836761]
 [ 13.04417038]
 [ 13.6948328 ]
 [ 15.05532551]
 [ 12.65446854]
 [ 12.15230274]
 [ 12.1006546 ]
 [ 12.20619297]
 [ 14.81520462]
 [ 12.48799992]
 [ 12.80734634]]
DEBUG:root:training time = %d0.242682
INFO:root:frame =8433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =8434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000577211380005
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:random_action_porb = 0.933405
DEBUG:root: dqn, choose action rondomly, need time 0.000347000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =8437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000406980514526
INFO:root:frame =8438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000115871429443
INFO:root:random_action_porb = 0.933373333333
DEBUG:root: dqn, choose action rondomly, need time 0.000202000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.79475307]
 [ 12.16331577]
 [ 20.57241821]
 [ 12.34894657]
 [ 11.67865086]
 [ 14.54144001]
 [ 24.81646919]
 [ 13.0690918 ]
 [ 13.25615025]
 [ 14.62564087]
 [ 13.63323975]
 [ 13.90524292]
 [ 11.001688  ]
 [ 20.57241821]
 [ 12.86983871]
 [ 13.36671352]]
DEBUG:root:training time = %d0.208571
INFO:root:frame =8441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =8442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504970550537
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:random_action_porb = 0.933341666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =8445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000495910644531
INFO:root:frame =8446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.93331
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.17454529]
 [  6.89635372]
 [ 14.01887512]
 [ 13.20913601]
 [ 12.80696487]
 [ 12.49269104]
 [ 12.65946293]
 [ 11.87491035]
 [ 13.52786255]
 [ 13.09850979]
 [ 11.90021515]
 [ 12.72317219]
 [ 12.09338379]
 [ 13.51938915]
 [ 12.84860802]
 [ 12.09338379]]
DEBUG:root:training time = %d0.211447
INFO:root:frame =8449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:frame =8450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000260829925537
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.933278333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =8453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =8454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.933246666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.54187202]
 [ 11.89505768]
 [ 14.15971375]
 [ 12.80843925]
 [ 12.56782341]
 [ 12.89875793]
 [ 13.30369282]
 [  7.4279871 ]
 [ 14.68785477]
 [ 12.44538307]
 [ 22.18883514]
 [ 14.77646732]
 [ 12.07561398]
 [ 13.3690567 ]
 [ 14.53480721]
 [ 12.34224415]]
DEBUG:root:training time = %d0.230651
INFO:root:frame =8457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =8458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000292062759399
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.933215
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =8461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240802764893
INFO:root:frame =8462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.933183333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000353097915649
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.06458759]
 [ 13.24487495]
 [ 21.71300316]
 [ 13.83086109]
 [ 13.41087723]
 [ 14.26250458]
 [ 13.19959927]
 [ 22.57243156]
 [ 14.07348824]
 [ 15.43686771]
 [ 12.70978642]
 [ 13.13581276]
 [ 13.77201939]
 [ 11.25712299]
 [ 12.86299706]
 [ 14.21431255]]
DEBUG:root:training time = %d0.234953
INFO:root:frame =8465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =8466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000353097915649
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.933151666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =8469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =8470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000305891036987
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:random_action_porb = 0.93312
DEBUG:root: dqn, choose action rondomly, need time 0.000252999999987
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000385046005249
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.64117336]
 [ 14.06272888]
 [ 12.42343044]
 [ 14.18050671]
 [ 12.90588284]
 [ 12.41885948]
 [ 21.35535431]
 [ 12.59353161]
 [ 13.64417267]
 [ 14.06272888]
 [ 12.33141804]
 [ 13.83591175]
 [ 14.45916367]
 [ 13.52696514]
 [ 13.39021015]
 [  6.51154566]]
DEBUG:root:training time = %d0.202845
INFO:root:frame =8473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =8474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000417947769165
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.933088333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308999999987
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =8477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =8478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000401973724365
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.933056666667
DEBUG:root: dqn, choose action rondomly, need time 0.000565999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322818756104
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.21612453]
 [ 14.50614166]
 [ 13.9610033 ]
 [ 13.70742798]
 [ 14.60539913]
 [ 13.92243195]
 [ 23.29900551]
 [ 12.27452564]
 [ 12.54543877]
 [ 20.60288048]
 [ 12.23654556]
 [  6.46312094]
 [ 12.52490902]
 [ 15.22227287]
 [ 12.27452564]
 [ 12.73585701]]
DEBUG:root:training time = %d0.208002
INFO:root:frame =8481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =8482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.933025
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000584125518799
INFO:root:frame =8485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =8486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000343799591064
INFO:root:frame = 8487 State into memory, numbers recorded 222 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000471115112305
INFO:root:random_action_porb = 0.932993333333
DEBUG:root: dqn, choose action rondomly, need time 0.000199000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8488current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.00989771]
 [ 12.38806725]
 [ 13.05315495]
 [ 14.58097553]
 [ 13.21157646]
 [ 13.72862148]
 [ 14.74539566]
 [ 20.83764458]
 [ 12.48018169]
 [ 14.02253151]
 [ 13.97834015]
 [ 13.11209869]
 [ 14.85122871]
 [ 12.2099781 ]
 [ 14.42570496]
 [ 20.83764458]]
DEBUG:root:training time = %d0.209161
INFO:root:frame =8489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000552177429199
INFO:root:frame =8490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000373840332031
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:random_action_porb = 0.932961666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =8493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =8494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.93293
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000019
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.43720913]
 [ 12.09364891]
 [  7.03739643]
 [ 15.18205547]
 [ 20.86684036]
 [ 21.48826599]
 [ 14.03041744]
 [ 12.45432091]
 [ 13.55633163]
 [ 13.54998398]
 [ 12.85265636]
 [ 12.86759472]
 [ 12.80106735]
 [ 12.75067234]
 [ 12.55630398]
 [ 12.60105896]]
DEBUG:root:training time = %d0.207317
INFO:root:frame =8497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:frame =8498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:random_action_porb = 0.932898333333
DEBUG:root: dqn, choose action rondomly, need time 0.000439999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =8501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000487089157104
INFO:root:frame =8502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000591993331909
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:random_action_porb = 0.932866666667
DEBUG:root: dqn, choose action rondomly, need time 0.000263000000018
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000181913375854
INFO:root:training error  = [[ 13.10226536]
 [ 13.39942455]
 [ 12.70586967]
 [ 12.58920002]
 [ 15.63316917]
 [ 13.34178829]
 [ 13.50127411]
 [ 12.87263107]
 [ 14.3413887 ]
 [ 12.43989372]
 [ 12.24914551]
 [ 12.30207253]
 [ 13.45992851]
 [ 13.20891476]
 [ 12.97378063]
 [ 12.75405121]]
DEBUG:root:training time = %d0.252611
INFO:root:frame =8505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:frame =8506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.932835
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000011
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =8509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =8510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000537872314453
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.932803333333
DEBUG:root: dqn, choose action rondomly, need time 0.000369000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000420093536377
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.99703979]
 [ 14.64064217]
 [ 13.38116646]
 [ 13.01178646]
 [ 21.36529732]
 [ 13.06870556]
 [ 13.83023643]
 [ 13.82796669]
 [ 13.86498642]
 [ 11.3395443 ]
 [ 13.53471088]
 [ 12.9042387 ]
 [ 23.55105972]
 [ 13.06870556]
 [ 14.01493263]
 [ 12.88363743]]
DEBUG:root:training time = %d0.205882
INFO:root:frame =8513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =8514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000311851501465
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.932771666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =8517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =8518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.93274
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.17001247]
 [ 12.19073772]
 [ 23.03446388]
 [ 13.80544949]
 [ 13.64490509]
 [ 13.707654  ]
 [ 13.17261505]
 [ 13.11856461]
 [ 14.64858341]
 [ 12.4889698 ]
 [ 12.83953094]
 [ 14.03504753]
 [ 12.1693306 ]
 [ 12.1693306 ]
 [ 13.9918642 ]
 [ 13.88397026]]
DEBUG:root:training time = %d0.220529
INFO:root:frame =8521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =8522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259876251221
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.932708333333
INFO:root:dqn select action Tensor("ArgMax_73:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010223
INFO:root:action choosen by dqn [4]
INFO:root:frame =8524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =8525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =8526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000534057617188
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:random_action_porb = 0.932676666667
DEBUG:root: dqn, choose action rondomly, need time 0.000268000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14.1391077 ]
 [ 21.05945206]
 [ 13.14825916]
 [ 13.09458923]
 [  7.0385704 ]
 [ 13.80828476]
 [ 13.32273388]
 [ 13.84295082]
 [ 13.85175133]
 [ 13.89591217]
 [ 12.45108986]
 [ 13.5799942 ]
 [ 12.57994366]
 [ 13.80176449]
 [ 12.83018303]
 [ 20.35732651]]
DEBUG:root:training time = %d0.217657
INFO:root:frame =8529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =8530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444173812866
DEBUG:root: save sample needs time = 0.000123977661133
INFO:root:random_action_porb = 0.932645
INFO:root:dqn select action Tensor("ArgMax_74:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.009849
INFO:root:action choosen by dqn [4]
INFO:root:frame =8532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000161170959473
INFO:root:frame =8533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000527143478394
INFO:root:frame =8534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00056791305542
DEBUG:root: save sample needs time = 0.000115156173706
INFO:root:random_action_porb = 0.932613333333
DEBUG:root: dqn, choose action rondomly, need time 0.000506999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14.13371468]
 [ 13.94088459]
 [ 14.243783  ]
 [  7.84937668]
 [ 12.43300533]
 [ 12.08033371]
 [ 13.90882778]
 [ 14.45945454]
 [ 13.16414356]
 [ 13.73195744]
 [ 14.15012646]
 [ 12.78142166]
 [ 13.03833008]
 [ 12.75465012]
 [ 14.13446045]
 [ 13.94088459]]
DEBUG:root:training time = %d0.218878
INFO:root:frame =8537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =8538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000543117523193
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.932581666667
DEBUG:root: dqn, choose action rondomly, need time 0.000279000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =8541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =8542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.93255
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999976
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.59979439]
 [ 13.18247509]
 [ 12.41477299]
 [ 15.37936783]
 [ 14.20706558]
 [ 13.49292088]
 [ 14.81455898]
 [ 13.60007572]
 [ 12.33340073]
 [ 13.8042593 ]
 [  7.53788853]
 [ 13.87964916]
 [ 13.48300266]
 [ 13.80896473]
 [ 14.03304672]
 [ 14.27680016]]
DEBUG:root:training time = %d0.229028
INFO:root:frame =8545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =8546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.932518333333
DEBUG:root: dqn, choose action rondomly, need time 0.00018799999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:frame =8549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000602960586548
INFO:root:frame =8550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000560998916626
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.932486666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:training error  = [[ 12.70222569]
 [ 13.10281849]
 [ 14.49202347]
 [ 13.30096626]
 [ 11.5300436 ]
 [ 13.13581276]
 [ 14.37052727]
 [ 13.15307331]
 [ 14.49969196]
 [ 12.4419384 ]
 [ 13.43821621]
 [ 12.98455524]
 [ 14.20890617]
 [ 13.44940567]
 [ 13.82342815]
 [ 14.18613815]]
DEBUG:root:training time = %d0.219731
INFO:root:frame =8553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000386953353882
INFO:root:frame =8554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000542879104614
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:random_action_porb = 0.932455
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =8557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000540971755981
INFO:root:frame =8558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00048303604126
DEBUG:root: save sample needs time = 0.000187873840332
INFO:root:random_action_porb = 0.932423333333
DEBUG:root: dqn, choose action rondomly, need time 0.000432999999987
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:training error  = [[ 12.19521332]
 [ 13.82303047]
 [ 15.40427113]
 [ 13.45600986]
 [ 14.99871922]
 [ 13.13702965]
 [ 13.73371029]
 [ 11.92291355]
 [ 13.96328354]
 [ 15.0473938 ]
 [ 13.01679516]
 [ 12.81275368]
 [ 12.29661369]
 [ 14.44013882]
 [ 12.97273636]
 [ 11.71627808]]
DEBUG:root:training time = %d0.227085
INFO:root:frame =8561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root: ememy has been killed for 19 times 
INFO:root:enemies_left [0]
INFO:root:frame =8562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000176906585693
INFO:root:frame = 8563 State into memory, numbers recorded 223 action = 1, reward = 1
DEBUG:root: save sample needs time = 0.000598907470703
INFO:root:random_action_porb = 0.932391666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8564current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =8565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000684022903442
INFO:root:frame =8566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:random_action_porb = 0.93236
DEBUG:root: dqn, choose action rondomly, need time 0.00056600000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.65245914]
 [ 13.20270443]
 [  7.09129524]
 [ 13.04273796]
 [ 14.77417946]
 [ 13.89682293]
 [ 13.63718414]
 [ 13.8884058 ]
 [ 13.45724106]
 [ 14.28729534]
 [ 13.54167271]
 [ 13.56487274]
 [ 13.15008545]
 [ 16.30133247]
 [ 13.48098564]
 [ 22.60702515]]
DEBUG:root:training time = %d0.231803
INFO:root:frame =8569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =8570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame = 8571 State into memory, numbers recorded 224 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:random_action_porb = 0.932328333333
DEBUG:root: dqn, choose action rondomly, need time 0.000196999999986
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8572current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000192165374756
INFO:root:frame =8573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =8574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000550985336304
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.932296666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 21.5312233 ]
 [ 12.94230747]
 [ 14.94333935]
 [ 13.48440266]
 [ 12.26143169]
 [ 13.04461193]
 [ 13.15307331]
 [ 20.71099854]
 [ 14.94333935]
 [ 12.74811172]
 [ 14.10183811]
 [ 12.81204319]
 [ 15.25056458]
 [ 13.59298611]
 [ 13.45780087]
 [ 15.4227829 ]]
DEBUG:root:training time = %d0.218287
INFO:root:frame =8577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =8578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248908996582
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.932265
INFO:root:dqn select action Tensor("ArgMax_75:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014893
INFO:root:action choosen by dqn [4]
INFO:root:frame =8580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000166893005371
INFO:root:frame =8581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =8582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame = 8583 State into memory, numbers recorded 225 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.0012149810791
INFO:root:random_action_porb = 0.932233333333
INFO:root:dqn select action Tensor("ArgMax_76:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014414
INFO:root:action choosen by dqn [4]
INFO:root:frame =8584current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000500917434692
INFO:root:training error  = [[ 12.52771759]
 [ 13.60362148]
 [ 14.36456966]
 [ 13.08719158]
 [ 13.69116306]
 [ 13.33732986]
 [ 14.19269085]
 [ 14.07640839]
 [ 14.34398842]
 [ 13.02979088]
 [ 14.46757889]
 [ 13.76477242]
 [ 13.16519547]
 [ 12.73961449]
 [ 13.54296398]
 [ 12.95592403]]
DEBUG:root:training time = %d0.204001
INFO:root:frame =8585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =8586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:random_action_porb = 0.932201666667
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =8589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427961349487
INFO:root:frame =8590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.93217
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 22.05405617]
 [ 13.779212  ]
 [ 13.72952652]
 [  8.39015198]
 [ 15.35831165]
 [ 13.77281284]
 [ 14.65798759]
 [ 13.66988564]
 [ 14.14909267]
 [ 13.779212  ]
 [ 22.20184708]
 [ 12.61834431]
 [ 14.88247013]
 [ 13.72952652]
 [ 24.70485497]
 [ 12.51950932]]
DEBUG:root:training time = %d0.254105
INFO:root:frame =8593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:frame =8594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000244140625
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:random_action_porb = 0.932138333333
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =8597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000557899475098
INFO:root:frame =8598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.932106666667
DEBUG:root: dqn, choose action rondomly, need time 0.000519999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:training error  = [[ 14.52334976]
 [ 15.42913532]
 [ 14.1703949 ]
 [ 14.74662685]
 [ 14.97349644]
 [ 14.1502409 ]
 [ 15.47814178]
 [ 14.47175789]
 [ 14.1502409 ]
 [ 13.50632   ]
 [ 14.52323341]
 [ 15.61676407]
 [ 15.34372425]
 [ 12.74914742]
 [ 12.78213024]
 [ 13.8764658 ]]
DEBUG:root:training time = %d0.233862
INFO:root:frame =8601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275850296021
INFO:root:frame =8602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.932075
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000022
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:frame =8605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274181365967
INFO:root:frame =8606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288009643555
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.932043333333
DEBUG:root: dqn, choose action rondomly, need time 0.000225
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000179052352905
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.63380337]
 [ 14.68884945]
 [ 15.01367378]
 [ 15.04905033]
 [ 14.0369339 ]
 [ 13.48328209]
 [ 23.12895775]
 [ 13.38753033]
 [ 13.09464455]
 [ 14.36734581]
 [ 14.62663269]
 [ 13.45763302]
 [ 12.14310265]
 [ 13.59883785]
 [ 15.89592171]
 [ 15.89592171]]
DEBUG:root:training time = %d0.226856
INFO:root:frame =8609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:frame =8610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000306844711304
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.932011666667
DEBUG:root: dqn, choose action rondomly, need time 0.000242000000014
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000286817550659
INFO:root:frame =8613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =8614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.93198
DEBUG:root: dqn, choose action rondomly, need time 0.000329999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14.28608418]
 [ 22.75978279]
 [ 14.70692539]
 [ 14.01796055]
 [ 24.51062775]
 [ 13.5483551 ]
 [ 14.28608418]
 [ 13.00622749]
 [ 12.64144516]
 [ 12.87509441]
 [ 13.80414581]
 [ 14.5690918 ]
 [ 15.51953125]
 [ 12.91394234]
 [ 13.53639507]
 [ 15.07901764]]
DEBUG:root:training time = %d0.232871
INFO:root:frame =8617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =8618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293016433716
DEBUG:root: save sample needs time = 0.000122785568237
INFO:root:random_action_porb = 0.931948333333
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root:frame =8621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =8622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000543117523193
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.931916666667
INFO:root:dqn select action Tensor("ArgMax_77:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011727
INFO:root:action choosen by dqn [4]
INFO:root:frame =8624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000391960144043
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.25959492]
 [ 13.645751  ]
 [ 13.32368088]
 [ 14.65448284]
 [ 13.40758038]
 [ 13.92493629]
 [ 14.27264881]
 [ 13.49236107]
 [ 22.06774521]
 [ 14.50567722]
 [ 13.37971497]
 [ 13.53830338]
 [ 14.75248718]
 [ 14.1976347 ]
 [ 14.00522327]
 [ 14.37399769]]
DEBUG:root:training time = %d0.209742
INFO:root:frame =8625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =8626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.931885
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =8629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000523805618286
INFO:root:frame =8630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000349998474121
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:random_action_porb = 0.931853333333
DEBUG:root: dqn, choose action rondomly, need time 0.000231000000014
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000136852264404
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 25.09912682]
 [ 13.28778076]
 [ 13.64879417]
 [ 13.80403233]
 [ 14.58855057]
 [ 22.89063835]
 [ 14.296525  ]
 [ 13.98644257]
 [ 14.80563259]
 [ 13.390769  ]
 [ 14.62704182]
 [ 13.76726341]
 [ 13.49421024]
 [ 13.64879417]
 [ 22.10359955]
 [ 13.42468357]]
DEBUG:root:training time = %d0.223932
INFO:root:frame =8633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =8634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.931821666667
INFO:root:dqn select action Tensor("ArgMax_78:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00952799999999
INFO:root:action choosen by dqn [4]
INFO:root:frame =8636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:frame =8637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =8638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000363111495972
DEBUG:root: save sample needs time = 0.000107049942017
INFO:root:random_action_porb = 0.93179
INFO:root:dqn select action Tensor("ArgMax_79:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013657
INFO:root:action choosen by dqn [4]
INFO:root:frame =8640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000161170959473
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.29462242]
 [ 13.37145615]
 [ 13.84936619]
 [ 13.29590225]
 [ 13.37145615]
 [ 14.47982693]
 [ 12.77509403]
 [ 15.35693645]
 [ 14.38603306]
 [ 12.9846096 ]
 [ 13.7304306 ]
 [ 13.20974636]
 [ 23.91082573]
 [ 14.39622116]
 [ 14.15609646]
 [ 15.13310432]]
DEBUG:root:training time = %d0.210002
INFO:root:frame =8641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =8642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479221343994
DEBUG:root: save sample needs time = 0.000235795974731
INFO:root:random_action_porb = 0.931758333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =8645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =8646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.931726666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.89488888]
 [ 14.87281799]
 [ 14.64770794]
 [ 14.49562454]
 [ 13.99152184]
 [ 14.51893044]
 [ 14.00773621]
 [ 14.42993546]
 [ 14.43283367]
 [ 13.42731094]
 [ 21.85786438]
 [ 15.35609913]
 [ 14.52899075]
 [ 15.79576111]
 [ 14.16074657]
 [ 13.19272614]]
DEBUG:root:training time = %d0.224305
INFO:root:frame =8649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =8650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.931695
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999977
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =8653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =8654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000598907470703
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.931663333333
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.64777946]
 [ 14.89942837]
 [ 14.04551029]
 [ 13.64676476]
 [ 13.02687168]
 [ 16.0294323 ]
 [ 14.8328886 ]
 [ 22.87261009]
 [ 14.45632076]
 [ 12.96152687]
 [ 14.74123669]
 [ 13.44442558]
 [ 14.27109241]
 [ 14.79653358]
 [ 13.48602772]
 [ 13.76675415]]
DEBUG:root:training time = %d0.225588
INFO:root:frame =8657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =8658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.931631666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =8661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =8662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475883483887
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9316
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 22.98674011]
 [ 13.37519455]
 [ 13.30525112]
 [ 14.3709898 ]
 [ 12.82887077]
 [ 13.97976685]
 [ 23.57379913]
 [ 22.44675446]
 [ 13.34764099]
 [ 13.68105888]
 [ 14.7627449 ]
 [ 14.85887432]
 [ 14.13629627]
 [ 13.72178173]
 [ 14.7627449 ]
 [ 13.94333458]]
DEBUG:root:training time = %d0.232254
INFO:root:frame =8665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =8666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.931568333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =8669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275850296021
INFO:root:frame =8670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486850738525
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.931536666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.56841373]
 [ 22.46649551]
 [ 14.30252552]
 [ 13.48513126]
 [ 14.29098606]
 [ 14.14249325]
 [ 13.49802208]
 [ 22.5930233 ]
 [ 13.42177582]
 [ 13.49706936]
 [ 15.18401718]
 [ 14.43770409]
 [ 16.27829933]
 [ 13.47521496]
 [ 23.86585426]
 [ 13.42177582]]
DEBUG:root:training time = %d0.22667
INFO:root:frame =8673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =8674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.931505
DEBUG:root: dqn, choose action rondomly, need time 0.000329999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =8677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =8678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.931473333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999983
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[ 14.06232834]
 [ 13.9767437 ]
 [ 13.60581589]
 [ 13.39272308]
 [ 13.73930931]
 [ 13.68354225]
 [ 13.09083557]
 [ 14.2553606 ]
 [ 13.83176899]
 [ 14.63795662]
 [ 15.18966675]
 [ 14.86410999]
 [ 15.27202415]
 [ 14.73227406]
 [ 14.24850559]
 [ 14.59910202]]
DEBUG:root:training time = %d0.220628
INFO:root:frame =8681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =8682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000250101089478
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:random_action_porb = 0.931441666667
DEBUG:root: dqn, choose action rondomly, need time 0.000338999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =8685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =8686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000507116317749
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.93141
DEBUG:root: dqn, choose action rondomly, need time 0.000410999999986
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14.30823898]
 [ 14.46316814]
 [ 22.60404968]
 [ 15.07178974]
 [ 13.89693642]
 [ 13.70415211]
 [ 14.52695465]
 [ 14.87487698]
 [ 14.0469408 ]
 [ 13.67829323]
 [ 22.46541023]
 [ 15.09881401]
 [ 13.74468327]
 [ 14.28118229]
 [ 15.4734602 ]
 [ 14.75459671]]
DEBUG:root:training time = %d0.217412
INFO:root:frame =8689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002281665802
INFO:root:frame =8690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049901008606
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.931378333333
DEBUG:root: dqn, choose action rondomly, need time 0.000328999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =8693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =8694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.931346666667
DEBUG:root: dqn, choose action rondomly, need time 0.000162000000017
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.85050201]
 [ 13.88249207]
 [ 13.28505516]
 [ 15.51081657]
 [ 13.5301075 ]
 [ 15.14194965]
 [ 13.3995924 ]
 [ 14.05437565]
 [ 21.99125671]
 [ 14.29398632]
 [ 14.27426338]
 [ 15.17082024]
 [ 15.92635441]
 [ 14.01550388]
 [ 14.63077641]
 [ 13.22489071]]
DEBUG:root:training time = %d0.243024
INFO:root:frame =8697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =8698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000282049179077
DEBUG:root: save sample needs time = 0.000156164169312
INFO:root:random_action_porb = 0.931315
DEBUG:root: dqn, choose action rondomly, need time 0.000153000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:frame =8701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000562906265259
INFO:root:frame =8702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000594854354858
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.931283333333
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14.00693703]
 [ 15.57638931]
 [ 22.55401993]
 [ 14.29992867]
 [ 14.82877445]
 [ 14.98046494]
 [ 14.73221588]
 [ 14.37984085]
 [ 14.41353703]
 [ 13.71731663]
 [ 14.82495594]
 [ 14.72226048]
 [ 15.04999828]
 [ 13.28583336]
 [ 15.60808182]
 [ 13.13586807]]
DEBUG:root:training time = %d0.19723
INFO:root:frame =8705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =8706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:random_action_porb = 0.931251666667
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999982
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =8709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =8710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.93122
DEBUG:root: dqn, choose action rondomly, need time 0.000321000000014
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.67016792]
 [ 14.61898899]
 [ 13.79864693]
 [ 23.12228012]
 [ 14.76028252]
 [ 14.0556345 ]
 [ 14.98991585]
 [ 15.22024918]
 [ 13.72404289]
 [ 13.27004242]
 [ 14.37868404]
 [ 13.27004242]
 [ 14.30823898]
 [ 14.3675766 ]
 [ 14.6940546 ]
 [ 13.07538128]]
DEBUG:root:training time = %d0.204026
INFO:root:frame =8713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286817550659
INFO:root:frame =8714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.931188333333
DEBUG:root: dqn, choose action rondomly, need time 0.000190000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:frame =8717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =8718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000280141830444
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.931156666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 15.45923805]
 [ 16.70960236]
 [ 14.54853916]
 [ 13.81724453]
 [ 14.1798172 ]
 [ 15.64873886]
 [ 15.20287132]
 [ 13.67919636]
 [ 16.00512695]
 [ 14.17292213]
 [ 14.31568527]
 [ 14.91763306]
 [ 14.57613945]
 [ 13.10441971]
 [ 23.95531654]
 [ 13.70403862]]
DEBUG:root:training time = %d0.199466
INFO:root:frame =8721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:frame =8722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000502109527588
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.931125
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000018
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root:frame =8725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000614881515503
INFO:root:frame =8726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:random_action_porb = 0.931093333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14.60085106]
 [ 15.20257378]
 [ 14.44553185]
 [ 14.25103951]
 [ 15.66685295]
 [ 14.87982082]
 [ 13.56554699]
 [  8.45507145]
 [ 14.5558157 ]
 [  8.45507145]
 [ 13.75328255]
 [ 14.17596722]
 [ 14.31187534]
 [ 14.55447674]
 [ 14.36063766]
 [ 13.83681965]]
DEBUG:root:training time = %d0.219706
INFO:root:frame =8729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =8730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.931061666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999983
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =8733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =8734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288009643555
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.93103
DEBUG:root: dqn, choose action rondomly, need time 0.000173999999987
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000166893005371
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14.31834126]
 [ 14.41799831]
 [ 13.7673769 ]
 [ 15.31743622]
 [ 13.78453732]
 [ 13.74044037]
 [ 14.06387329]
 [ 24.36971474]
 [ 14.76708317]
 [ 15.34503937]
 [ 15.31743622]
 [ 14.39483166]
 [ 23.76555061]
 [ 17.07238388]
 [ 14.23623943]
 [ 14.4801178 ]]
DEBUG:root:training time = %d0.223472
INFO:root:frame =8737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =8738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000108957290649
INFO:root:random_action_porb = 0.930998333333
DEBUG:root: dqn, choose action rondomly, need time 0.000350999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =8741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =8742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.930966666667
DEBUG:root: dqn, choose action rondomly, need time 0.000408999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14.44321251]
 [ 15.8237915 ]
 [ 14.44680786]
 [ 13.31310081]
 [ 14.20240688]
 [ 15.0841732 ]
 [ 14.33405018]
 [ 14.41133595]
 [ 14.77171612]
 [ 14.49620533]
 [ 13.71516895]
 [ 14.33116245]
 [ 15.49303341]
 [ 23.67495918]
 [ 14.21845531]
 [ 14.75307274]]
DEBUG:root:training time = %d0.225206
INFO:root:frame =8745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =8746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.930935
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999982
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =8749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root:frame =8750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.930903333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14.1869421 ]
 [ 14.69376183]
 [ 13.4502449 ]
 [ 15.02798557]
 [ 14.34063721]
 [ 15.9504776 ]
 [ 14.77195072]
 [ 14.87581921]
 [ 12.68178654]
 [ 14.05609226]
 [ 23.14870262]
 [ 14.68621731]
 [ 15.81735802]
 [ 12.82034683]
 [ 12.68178654]
 [ 14.16224003]]
DEBUG:root:training time = %d0.232504
INFO:root:frame =8753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =8754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298023223877
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.930871666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000347852706909
INFO:root:frame =8757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000369071960449
INFO:root:frame =8758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame = 8759 State into memory, numbers recorded 226 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000570058822632
INFO:root:random_action_porb = 0.93084
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8760current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 15.63262653]
 [ 23.61374855]
 [ 24.10244179]
 [ 17.5935421 ]
 [ 14.23151875]
 [ 14.64356136]
 [ 13.87652302]
 [ 15.36829948]
 [ 13.74881268]
 [ 14.84358597]
 [ 14.66295338]
 [ 14.8200798 ]
 [ 13.90063381]
 [ 14.69036961]
 [ 15.45917797]
 [ 16.99586678]]
DEBUG:root:training time = %d0.236813
INFO:root:frame =8761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =8762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000243902206421
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:random_action_porb = 0.930808333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =8765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00044584274292
INFO:root:frame =8766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049090385437
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:random_action_porb = 0.930776666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 23.804842  ]
 [ 14.62616634]
 [ 14.65016079]
 [ 14.45620537]
 [ 15.90188408]
 [ 14.91268349]
 [ 14.65898037]
 [ 14.13360023]
 [ 14.73988914]
 [ 15.25104141]
 [ 15.39517021]
 [ 14.22628117]
 [ 15.41157913]
 [ 14.69089603]
 [ 15.53149605]
 [ 15.14242554]]
DEBUG:root:training time = %d0.233309
INFO:root:frame =8769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:frame =8770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000508069992065
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:random_action_porb = 0.930745
DEBUG:root: dqn, choose action rondomly, need time 0.000223000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000194072723389
INFO:root:frame =8773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470161437988
INFO:root:frame =8774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.930713333333
DEBUG:root: dqn, choose action rondomly, need time 0.000207999999986
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000643968582153
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14.29231358]
 [ 14.5386467 ]
 [ 14.5386467 ]
 [ 14.91857624]
 [ 15.40978146]
 [ 15.20418072]
 [ 15.40978146]
 [ 23.12396812]
 [ 15.392416  ]
 [ 15.72658062]
 [ 13.49432278]
 [ 15.17224693]
 [ 15.84176254]
 [ 15.06882763]
 [ 15.21917725]
 [ 14.40901852]]
DEBUG:root:training time = %d0.222538
INFO:root:frame =8777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =8778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.930681666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =8781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000357866287231
INFO:root:frame =8782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.93065
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00035285949707
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14.76667309]
 [ 15.52392006]
 [ 14.19677162]
 [ 14.84664249]
 [ 14.33578396]
 [ 16.35256767]
 [ 14.37590694]
 [ 16.68889999]
 [ 15.94139862]
 [ 16.79103661]
 [ 22.41762924]
 [ 15.23322964]
 [ 16.01220894]
 [ 16.58459091]
 [ 14.06021118]
 [ 16.27263641]]
DEBUG:root:training time = %d0.225898
INFO:root:frame =8785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280857086182
INFO:root:frame =8786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.930618333333
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999983
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =8789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =8790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000613212585449
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.930586666667
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14.34190845]
 [ 14.77764034]
 [ 15.0898037 ]
 [ 14.26100636]
 [ 14.0359621 ]
 [ 14.59414673]
 [ 16.2362175 ]
 [ 14.90826416]
 [ 14.10573483]
 [ 14.32376957]
 [ 13.61031914]
 [ 14.26100636]
 [ 15.7948513 ]
 [ 15.07552242]
 [ 23.70474052]
 [ 15.08399487]]
DEBUG:root:training time = %d0.224194
INFO:root:frame =8793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =8794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509977340698
INFO:root:frame = 8795 State into memory, numbers recorded 227 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000607013702393
INFO:root:random_action_porb = 0.930555
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8796current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =8797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =8798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.930523333333
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:training error  = [[ 16.20358467]
 [ 14.96469975]
 [ 15.44928074]
 [ 14.1369276 ]
 [ 14.60341644]
 [ 14.23877335]
 [ 14.43973351]
 [ 14.60825634]
 [ 14.39176369]
 [ 13.66492176]
 [ 14.68844032]
 [ 16.55409241]
 [ 13.56993103]
 [ 14.6889658 ]
 [ 16.55409241]
 [ 14.4890604 ]]
DEBUG:root:training time = %d0.230032
INFO:root:frame =8801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =8802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame = 8803 State into memory, numbers recorded 228 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000613927841187
INFO:root:random_action_porb = 0.930491666667
DEBUG:root: dqn, choose action rondomly, need time 0.000321000000014
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8804current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =8805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =8806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480175018311
DEBUG:root: save sample needs time = 0.000286817550659
INFO:root:random_action_porb = 0.93046
DEBUG:root: dqn, choose action rondomly, need time 0.000323000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:training error  = [[ 14.89984035]
 [ 13.84249592]
 [ 15.5930748 ]
 [ 15.97535133]
 [ 15.50715065]
 [ 14.40160561]
 [ 16.58260155]
 [ 14.06049728]
 [ 17.72646904]
 [ 15.87177849]
 [ 15.10000038]
 [ 15.83198643]
 [ 15.01651192]
 [ 14.62739182]
 [ 14.42390823]
 [ 14.50230598]]
DEBUG:root:training time = %d0.231041
INFO:root:frame =8809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =8810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000613927841187
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:random_action_porb = 0.930428333333
DEBUG:root: dqn, choose action rondomly, need time 0.000376000000017
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =8813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000406980514526
INFO:root:frame =8814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000538110733032
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.930396666667
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.28828144]
 [ 25.6241169 ]
 [ 26.44179344]
 [ 23.09667969]
 [ 24.2102108 ]
 [ 15.99322605]
 [ 24.52014732]
 [ 14.81590939]
 [ 14.45081043]
 [ 14.39442635]
 [ 14.73695946]
 [ 14.53439999]
 [ 16.18964577]
 [ 15.63570309]
 [ 14.09438992]
 [ 16.14118004]]
DEBUG:root:training time = %d0.229553
INFO:root:frame =8817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =8818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275850296021
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.930365
DEBUG:root: dqn, choose action rondomly, need time 0.000263000000018
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000191926956177
INFO:root:frame =8821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465154647827
INFO:root:frame =8822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame = 8823 State into memory, numbers recorded 229 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000370979309082
INFO:root:random_action_porb = 0.930333333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8824current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 15.46949863]
 [ 14.17591   ]
 [ 14.38609123]
 [ 14.28931332]
 [ 15.00864887]
 [ 15.17218781]
 [ 14.15454578]
 [ 17.44371223]
 [ 14.45748138]
 [ 15.94462776]
 [ 16.00946236]
 [ 23.32464409]
 [ 16.62114906]
 [ 16.11703491]
 [ 16.92209625]
 [ 14.37318802]]
DEBUG:root:training time = %d0.230533
INFO:root:frame =8825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =8826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame = 8827 State into memory, numbers recorded 230 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000482797622681
INFO:root:random_action_porb = 0.930301666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8828current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =8829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =8830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000576019287109
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.93027
DEBUG:root: dqn, choose action rondomly, need time 0.000572000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 15.35813236]
 [ 14.65039444]
 [ 16.70916557]
 [ 15.37153053]
 [ 23.48815918]
 [ 14.42454529]
 [ 15.28061199]
 [ 15.20364475]
 [ 15.27279949]
 [ 14.9446373 ]
 [ 14.90773392]
 [ 15.23859024]
 [ 14.79782486]
 [  8.09390163]
 [ 16.16417694]
 [ 14.00819302]]
DEBUG:root:training time = %d0.227041
INFO:root:frame =8833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =8834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000414848327637
DEBUG:root: save sample needs time = 0.000155210494995
INFO:root:random_action_porb = 0.930238333333
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root:frame =8837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =8838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame = 8839 State into memory, numbers recorded 231 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000571012496948
INFO:root:random_action_porb = 0.930206666667
DEBUG:root: dqn, choose action rondomly, need time 0.000525999999979
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8840current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000428199768066
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14.74158764]
 [ 14.35659027]
 [ 15.81893539]
 [ 15.23841095]
 [ 23.80007935]
 [ 16.34053802]
 [ 14.40658569]
 [ 14.26440716]
 [ 14.60038471]
 [ 14.98028755]
 [ 14.61887264]
 [ 15.61501503]
 [ 16.78984833]
 [ 15.34091568]
 [ 15.93798733]
 [ 25.72973633]]
DEBUG:root:training time = %d0.191571
INFO:root:frame =8841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:frame =8842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000103950500488
INFO:root:random_action_porb = 0.930175
DEBUG:root: dqn, choose action rondomly, need time 0.000205999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root:frame =8845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =8846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000416994094849
DEBUG:root: save sample needs time = 0.000141143798828
INFO:root:random_action_porb = 0.930143333333
DEBUG:root: dqn, choose action rondomly, need time 0.000271000000026
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root:training error  = [[ 15.51760769]
 [ 13.94173908]
 [ 16.57291031]
 [ 14.53591251]
 [ 15.83526516]
 [ 15.78199768]
 [ 15.39726543]
 [ 14.51491833]
 [ 14.35572243]
 [ 16.30607605]
 [ 16.02680588]
 [ 16.25842094]
 [ 15.42475986]
 [ 14.60936451]
 [ 16.53230858]
 [ 16.9266777 ]]
DEBUG:root:training time = %d0.19122
INFO:root:frame =8849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =8850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame = 8851 State into memory, numbers recorded 232 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.00068187713623
INFO:root:random_action_porb = 0.930111666667
DEBUG:root: dqn, choose action rondomly, need time 0.000321000000014
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8852current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =8853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270843505859
INFO:root:frame =8854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000420093536377
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.93008
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.59988022]
 [ 15.42679787]
 [ 14.96511364]
 [ 14.80768776]
 [ 25.35133934]
 [ 13.92488003]
 [ 14.92305565]
 [ 13.92488003]
 [ 15.14278126]
 [ 15.1878233 ]
 [ 15.69525146]
 [ 15.61121655]
 [ 15.93104362]
 [ 15.30794239]
 [ 15.58674908]
 [ 16.05870819]]
DEBUG:root:training time = %d0.217985
INFO:root:frame =8857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:frame =8858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000311136245728
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:random_action_porb = 0.930048333333
DEBUG:root: dqn, choose action rondomly, need time 0.000191999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000146865844727
INFO:root:frame =8861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491857528687
INFO:root:frame =8862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441789627075
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:random_action_porb = 0.930016666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:training error  = [[ 15.05100441]
 [ 17.29522133]
 [ 14.64496326]
 [ 16.29492569]
 [ 15.40594864]
 [ 15.11856461]
 [ 14.53108406]
 [ 16.04642105]
 [ 16.0922966 ]
 [ 15.50654984]
 [ 14.3415041 ]
 [ 15.27035427]
 [ 14.39552593]
 [ 16.04953766]
 [ 15.26767159]
 [ 14.96582127]]
DEBUG:root:training time = %d0.227542
INFO:root:frame =8865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =8866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000327825546265
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.929985
DEBUG:root: dqn, choose action rondomly, need time 0.000289999999978
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =8869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000504016876221
INFO:root:frame =8870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.929953333333
DEBUG:root: dqn, choose action rondomly, need time 0.000321000000014
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 15.8153553 ]
 [ 16.28944397]
 [ 15.40139675]
 [ 16.39313316]
 [ 14.59951019]
 [ 15.96846008]
 [ 14.05683613]
 [ 14.9779253 ]
 [ 15.20435905]
 [  8.4926939 ]
 [ 15.93256664]
 [ 13.89602661]
 [ 13.66368103]
 [ 15.11114979]
 [ 23.82777786]
 [ 14.64747429]]
DEBUG:root:training time = %d0.245298
INFO:root:frame =8873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =8874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000325202941895
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.929921666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =8877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =8878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000492811203003
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.92989
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14.73063469]
 [ 14.74738789]
 [ 15.214118  ]
 [ 18.05692291]
 [ 15.63872051]
 [ 14.60306644]
 [ 24.92627907]
 [ 15.68872356]
 [ 14.40658569]
 [ 14.96045017]
 [ 14.76127911]
 [ 15.83830166]
 [ 16.90653229]
 [ 16.14547157]
 [ 16.39653015]
 [ 14.34502888]]
DEBUG:root:training time = %d0.245136
INFO:root:frame =8881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =8882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:random_action_porb = 0.929858333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999983
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =8885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =8886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476121902466
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.929826666667
DEBUG:root: dqn, choose action rondomly, need time 0.000330999999989
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.79535103]
 [ 15.08121014]
 [ 16.25140762]
 [ 15.24061489]
 [ 14.839118  ]
 [ 24.53737831]
 [ 15.65713024]
 [ 15.81529427]
 [ 23.25711632]
 [ 16.27072716]
 [ 16.27072716]
 [ 15.56223965]
 [ 16.00311279]
 [ 15.40349293]
 [  8.32926941]
 [ 15.06947994]]
DEBUG:root:training time = %d0.219317
INFO:root:frame =8889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: ememy has been killed for 20 times 
INFO:root:enemies_left [0]
INFO:root:frame =8890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00035285949707
INFO:root:frame = 8891 State into memory, numbers recorded 233 action = 3, reward = 1
DEBUG:root: save sample needs time = 0.00059700012207
INFO:root:random_action_porb = 0.929795
DEBUG:root: dqn, choose action rondomly, need time 0.000363000000021
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8892current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =8893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000490188598633
INFO:root:frame =8894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.929763333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 15.0546751 ]
 [ 15.07564068]
 [ 15.5313158 ]
 [ 15.30657005]
 [ 15.72730732]
 [ 15.71351337]
 [ 15.11743736]
 [ 24.58910561]
 [ 14.58656979]
 [ 15.37870979]
 [ 15.00315189]
 [ 14.88977051]
 [ 15.73571968]
 [ 15.3428278 ]
 [ 25.00442505]
 [ 14.55529118]]
DEBUG:root:training time = %d0.236463
INFO:root:frame =8897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =8898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274896621704
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.929731666667
DEBUG:root: dqn, choose action rondomly, need time 0.000182999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root:frame =8901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =8902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.9297
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355958938599
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 15.43980598]
 [ 16.37262726]
 [ 15.02520561]
 [ 24.83000183]
 [ 15.62683582]
 [ 14.31435776]
 [ 16.17442322]
 [ 14.86687469]
 [ 24.51538658]
 [ 15.03153419]
 [ 15.97651005]
 [ 15.55953121]
 [ 14.3926897 ]
 [ 14.31435776]
 [ 16.63794899]
 [ 16.5645256 ]]
DEBUG:root:training time = %d0.233748
INFO:root:frame =8905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =8906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:random_action_porb = 0.929668333333
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =8909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root:frame =8910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000500917434692
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.929636666667
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 15.4700985 ]
 [ 14.76901913]
 [ 24.80294037]
 [ 17.3586731 ]
 [ 17.03218269]
 [ 17.01959038]
 [ 14.91498089]
 [ 14.70745182]
 [ 14.39928913]
 [ 16.83909035]
 [ 14.94245529]
 [ 14.99156952]
 [ 17.03218269]
 [ 17.64619064]
 [ 15.53173637]
 [ 15.9771204 ]]
DEBUG:root:training time = %d0.240085
INFO:root:frame =8913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000367879867554
INFO:root:frame =8914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.929605
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =8917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =8918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.929573333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17.06368446]
 [ 16.41729736]
 [ 15.60976982]
 [ 15.24121094]
 [ 26.96242332]
 [ 14.16792488]
 [ 17.5179081 ]
 [ 16.78397179]
 [ 14.64216042]
 [ 14.76333141]
 [ 15.1159544 ]
 [ 25.04953957]
 [ 14.29548645]
 [ 17.5179081 ]
 [ 15.39942074]
 [ 15.18235302]]
DEBUG:root:training time = %d0.235329
INFO:root:frame =8921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =8922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000338077545166
DEBUG:root: save sample needs time = 0.000121116638184
INFO:root:random_action_porb = 0.929541666667
DEBUG:root: dqn, choose action rondomly, need time 0.000472000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =8925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame =8926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000566005706787
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.92951
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 15.12408352]
 [ 14.7335043 ]
 [ 17.34011459]
 [ 24.80750084]
 [ 14.82272339]
 [ 25.75412178]
 [ 14.24389744]
 [ 15.02899075]
 [ 25.17930603]
 [ 16.07094002]
 [ 15.55513763]
 [ 16.91895676]
 [ 15.27977753]
 [ 16.03560257]
 [ 16.14743233]
 [ 16.83890343]]
DEBUG:root:training time = %d0.219755
INFO:root:frame =8929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =8930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049614906311
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.929478333333
DEBUG:root: dqn, choose action rondomly, need time 0.000194999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000193119049072
INFO:root:frame =8933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =8934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:random_action_porb = 0.929446666667
DEBUG:root: dqn, choose action rondomly, need time 0.000585000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 15.90912628]
 [ 25.65216255]
 [ 14.76368332]
 [ 14.84540844]
 [ 14.62896729]
 [ 15.32549953]
 [ 15.97937679]
 [ 15.46379757]
 [ 24.79162025]
 [ 16.05675125]
 [ 16.05516243]
 [ 15.11921787]
 [ 15.97937679]
 [ 16.14203835]
 [ 16.14203835]
 [ 15.90912628]]
DEBUG:root:training time = %d0.242202
INFO:root:frame =8937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =8938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509977340698
DEBUG:root: save sample needs time = 0.000116109848022
INFO:root:random_action_porb = 0.929415
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =8941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444173812866
INFO:root:frame =8942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.929383333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.05272007]
 [ 15.02224827]
 [ 16.39047623]
 [ 16.92818451]
 [ 26.74576569]
 [ 15.06160259]
 [ 14.69036961]
 [ 15.97352123]
 [ 14.67698002]
 [ 16.24273491]
 [ 15.30985355]
 [ 15.4672184 ]
 [ 14.64963436]
 [ 17.07654572]
 [ 15.7646656 ]
 [ 16.94055557]]
DEBUG:root:training time = %d0.242301
INFO:root:frame =8945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =8946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000235795974731
INFO:root:random_action_porb = 0.929351666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =8949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =8950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame = 8951 State into memory, numbers recorded 234 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000549793243408
INFO:root:random_action_porb = 0.92932
DEBUG:root: dqn, choose action rondomly, need time 0.000280000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8952current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:training error  = [[ 18.29247093]
 [ 16.09658051]
 [ 15.61929607]
 [ 15.47021866]
 [ 15.3537674 ]
 [ 15.27924061]
 [ 15.44154453]
 [ 16.41383553]
 [ 15.70425987]
 [ 15.65356827]
 [ 16.38182831]
 [ 15.40774536]
 [ 15.57717228]
 [ 15.38427544]
 [ 14.58336449]
 [ 15.33989906]]
DEBUG:root:training time = %d0.230062
INFO:root:frame =8953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =8954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.929288333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =8957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =8958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.929256666667
DEBUG:root: dqn, choose action rondomly, need time 0.000421000000017
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 15.47099876]
 [ 16.1362133 ]
 [ 13.98963833]
 [ 15.34701157]
 [ 17.67196846]
 [ 15.35281086]
 [  9.38016796]
 [ 15.0965023 ]
 [ 16.95217514]
 [ 14.92069817]
 [ 15.62345791]
 [ 16.76366234]
 [ 16.4318924 ]
 [ 24.52150726]
 [ 16.22711945]
 [ 15.76611996]]
DEBUG:root:training time = %d0.214693
INFO:root:frame =8961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000363826751709
INFO:root:frame =8962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.929225
DEBUG:root: dqn, choose action rondomly, need time 0.000166000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:frame =8965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000500917434692
INFO:root:frame =8966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:random_action_porb = 0.929193333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000353097915649
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 15.0492878 ]
 [ 23.66471481]
 [ 16.82519341]
 [ 13.89022541]
 [ 17.43268967]
 [ 14.86169815]
 [ 17.44460487]
 [ 16.82519341]
 [ 15.40049839]
 [ 14.94510937]
 [ 16.53119278]
 [ 15.03425598]
 [ 16.08764458]
 [ 15.7613945 ]
 [ 17.58355904]
 [ 15.74788857]]
DEBUG:root:training time = %d0.230065
INFO:root:frame =8969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:frame =8970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000589847564697
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.929161666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =8973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =8974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.92913
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 15.14480019]
 [ 15.76951313]
 [  8.48073673]
 [ 15.68830109]
 [ 15.19608974]
 [ 15.97077751]
 [ 24.97688866]
 [ 15.52121449]
 [ 16.61965561]
 [ 15.74867535]
 [ 16.24790192]
 [ 15.81547642]
 [ 15.7533989 ]
 [ 16.16442108]
 [ 15.43213177]
 [ 15.99835205]]
DEBUG:root:training time = %d0.222663
INFO:root:frame =8977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271797180176
INFO:root:frame =8978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.929098333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =8981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =8982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.929066666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.43325233]
 [ 17.0524025 ]
 [ 24.65111351]
 [ 16.48252678]
 [ 25.78913498]
 [ 14.52445412]
 [ 16.93710136]
 [ 15.98785591]
 [ 16.28082275]
 [ 15.87250805]
 [ 25.56899643]
 [ 16.98945045]
 [ 17.07320213]
 [ 24.41108704]
 [ 15.07421875]
 [ 15.95358562]]
DEBUG:root:training time = %d0.232076
INFO:root:frame =8985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000366926193237
INFO:root:frame =8986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.929035
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000341892242432
INFO:root:frame =8989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =8990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.929003333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336170196533
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.3852253 ]
 [ 16.28107071]
 [ 16.29597282]
 [ 15.68008232]
 [ 17.0914917 ]
 [  8.92421722]
 [ 15.5092535 ]
 [ 15.78351307]
 [ 14.78632259]
 [ 15.39481068]
 [ 15.4882288 ]
 [ 17.13252068]
 [ 18.2694416 ]
 [ 16.47156334]
 [ 16.68721771]
 [ 14.03401852]]
DEBUG:root:training time = %d0.24251
INFO:root:frame =8993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =8994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame = 8995 State into memory, numbers recorded 235 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000572919845581
INFO:root:random_action_porb = 0.928971666667
DEBUG:root: dqn, choose action rondomly, need time 0.000270999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8996current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =8997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =8998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000123977661133
DEBUG:root:one frame running time = 0.00369799999999
DEBUG:root:total training time = 250.916972
INFO:root:frame num = 9000 frame round: 0
INFO:root:random_action_porb = 0.92894
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 15.77975464]
 [ 15.33583546]
 [ 15.6926527 ]
 [ 16.88922119]
 [ 17.69782829]
 [ 15.47327995]
 [ 16.52170181]
 [ 16.84647942]
 [ 16.92046356]
 [ 15.63497925]
 [ 17.69333458]
 [  9.07674694]
 [ 16.6885891 ]
 [ 15.91716099]
 [ 15.50078201]
 [ 15.08909225]]
DEBUG:root:training time = %d0.229242
INFO:root:frame =9001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =9002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.928908333333
DEBUG:root: dqn, choose action rondomly, need time 0.000332999999983
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =9005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame =9006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000391006469727
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.928876666667
DEBUG:root: dqn, choose action rondomly, need time 0.000376000000017
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.56750679]
 [  8.76733208]
 [ 15.11998844]
 [ 16.36194801]
 [ 16.81080055]
 [ 14.7289362 ]
 [ 14.65500832]
 [ 16.64180756]
 [ 17.64305115]
 [ 17.07862663]
 [ 16.44475937]
 [ 16.73031616]
 [ 16.05925941]
 [ 15.47454071]
 [ 15.1246767 ]
 [ 24.15768433]]
DEBUG:root:training time = %d0.225728
INFO:root:frame =9009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046181678772
INFO:root:frame =9010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000495910644531
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.928845
DEBUG:root: dqn, choose action rondomly, need time 0.000180999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000179052352905
INFO:root:frame =9013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =9014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049614906311
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.928813333333
DEBUG:root: dqn, choose action rondomly, need time 0.000334000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 15.19377041]
 [ 15.51159763]
 [ 16.58645439]
 [ 24.55423546]
 [ 16.40672684]
 [ 16.73893166]
 [ 26.26406097]
 [ 26.26406097]
 [ 15.66039085]
 [ 24.8346405 ]
 [ 15.04585457]
 [ 17.19890022]
 [ 17.70533943]
 [ 15.78945446]
 [ 17.68775177]
 [ 16.97115326]]
DEBUG:root:training time = %d0.23029
INFO:root:frame =9017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:frame =9018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame = 9019 State into memory, numbers recorded 236 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000651121139526
INFO:root:random_action_porb = 0.928781666667
INFO:root:dqn select action Tensor("ArgMax_80:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015156
INFO:root:action choosen by dqn [4]
INFO:root:frame =9020current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.00115299224854
INFO:root:frame =9021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000407934188843
INFO:root:frame =9022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.92875
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.78328514]
 [ 16.13045311]
 [ 15.97992611]
 [ 25.16238785]
 [ 16.25356102]
 [ 16.87599182]
 [ 16.02002525]
 [ 16.61716843]
 [ 16.02002525]
 [ 15.80055237]
 [ 16.82062531]
 [ 15.81128979]
 [ 26.02562904]
 [ 16.35676384]
 [ 14.68756294]
 [ 16.19388199]]
DEBUG:root:training time = %d0.220543
INFO:root:frame =9025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000401020050049
INFO:root:frame =9026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002601146698
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.928718333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =9029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444173812866
INFO:root:frame =9030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame = 9031 State into memory, numbers recorded 237 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000540018081665
INFO:root:random_action_porb = 0.928686666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9032current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.4690876 ]
 [ 15.49153233]
 [ 16.33387756]
 [ 15.87196159]
 [ 14.9057312 ]
 [ 17.0202198 ]
 [ 16.4035759 ]
 [ 16.46178055]
 [ 15.55598068]
 [ 14.59898472]
 [ 16.68478584]
 [ 16.43665504]
 [ 16.40400696]
 [ 24.65421867]
 [ 16.04965973]
 [ 15.20703697]]
DEBUG:root:training time = %d0.228263
INFO:root:frame =9033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =9034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000499963760376
INFO:root:frame = 9035 State into memory, numbers recorded 238 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000545024871826
INFO:root:random_action_porb = 0.928655
INFO:root:dqn select action Tensor("ArgMax_81:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011858
INFO:root:action choosen by dqn [4]
INFO:root:frame =9036current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.00090217590332
INFO:root:frame =9037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000506162643433
INFO:root:frame =9038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:random_action_porb = 0.928623333333
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000016
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:training error  = [[ 15.10628605]
 [ 15.31540585]
 [ 15.92952156]
 [ 15.8024931 ]
 [ 17.30207634]
 [ 17.15564346]
 [ 16.91500282]
 [ 16.6907711 ]
 [ 15.4616375 ]
 [ 15.87457561]
 [ 16.73306274]
 [ 15.9815731 ]
 [ 16.46103859]
 [ 15.75230885]
 [ 15.90249252]
 [ 17.47023392]]
DEBUG:root:training time = %d0.225697
INFO:root:frame =9041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =9042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.928591666667
INFO:root:dqn select action Tensor("ArgMax_82:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012089
INFO:root:action choosen by dqn [4]
INFO:root:frame =9044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016713142395
INFO:root:frame =9045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =9046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.92856
DEBUG:root: dqn, choose action rondomly, need time 0.000341999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14.89713097]
 [ 17.05511284]
 [ 16.16773415]
 [ 16.16773415]
 [ 16.07620049]
 [ 16.20794678]
 [ 16.31624413]
 [ 15.7510376 ]
 [ 16.20794678]
 [ 18.40358353]
 [ 15.62629223]
 [  9.31434345]
 [ 16.94645882]
 [ 17.09187126]
 [ 16.89053726]
 [ 15.73039341]]
DEBUG:root:training time = %d0.226365
INFO:root:frame =9049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =9050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.928528333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =9053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =9054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.928496666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 24.62642097]
 [ 16.29960823]
 [ 25.87700462]
 [ 16.25208473]
 [ 15.75806236]
 [ 17.23473549]
 [ 16.37052917]
 [ 15.97742462]
 [ 15.29057503]
 [ 16.08378792]
 [ 16.54862976]
 [ 15.76533222]
 [ 15.78854465]
 [ 14.79348183]
 [ 16.53317833]
 [ 10.52672577]]
DEBUG:root:training time = %d0.213921
INFO:root:frame =9057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =9058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000260829925537
DEBUG:root: save sample needs time = 0.000116109848022
INFO:root:random_action_porb = 0.928465
DEBUG:root: dqn, choose action rondomly, need time 0.00017200000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000157833099365
INFO:root:frame =9061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =9062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.928433333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335216522217
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.96964455]
 [ 14.87852669]
 [ 16.39992905]
 [ 26.35524178]
 [ 15.54713535]
 [ 16.32394981]
 [ 17.05378914]
 [ 16.35583878]
 [  9.74351215]
 [ 17.44103622]
 [ 24.96964455]
 [ 16.76091385]
 [ 15.97858429]
 [ 15.93043423]
 [ 16.72757149]
 [ 17.0802021 ]]
DEBUG:root:training time = %d0.225448
INFO:root:frame =9065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =9066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000246047973633
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.928401666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =9069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =9070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000658988952637
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.92837
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999986
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.48878479]
 [ 18.09870529]
 [ 24.07667923]
 [ 25.38192558]
 [ 16.14859772]
 [ 16.39288521]
 [ 16.97486305]
 [ 18.17746735]
 [ 18.27283287]
 [ 16.73125267]
 [ 26.79116058]
 [ 16.98762703]
 [ 24.78144073]
 [ 15.30644989]
 [ 27.00443268]
 [  9.66603088]]
DEBUG:root:training time = %d0.217556
INFO:root:frame =9073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285148620605
INFO:root:frame =9074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248908996582
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.928338333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000015
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =9077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049090385437
INFO:root:frame =9078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.928306666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 19.5504818 ]
 [ 15.89762497]
 [ 16.08788872]
 [ 19.00980568]
 [ 17.23562241]
 [ 15.16737366]
 [ 16.13308716]
 [ 16.32160759]
 [ 19.00980568]
 [ 16.91337204]
 [ 16.44438934]
 [ 15.31498814]
 [ 26.91158104]
 [ 16.48996162]
 [  9.19458294]
 [ 25.32745171]]
DEBUG:root:training time = %d0.221926
INFO:root:frame =9081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =9082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255107879639
DEBUG:root: save sample needs time = 0.00011682510376
INFO:root:random_action_porb = 0.928275
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root:frame =9085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000481843948364
INFO:root:frame =9086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486135482788
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.928243333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000023
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 27.68399811]
 [ 17.02204514]
 [ 15.47327995]
 [ 17.1033535 ]
 [ 16.50117874]
 [ 16.46778679]
 [ 16.57812881]
 [ 17.08947372]
 [ 24.85799026]
 [ 16.81198883]
 [ 17.88802338]
 [ 16.24119759]
 [ 17.19238281]
 [ 17.06822205]
 [ 16.52021408]
 [ 16.66378975]]
DEBUG:root:training time = %d0.226626
INFO:root:frame =9089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =9090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464200973511
DEBUG:root: save sample needs time = 0.0002281665802
INFO:root:random_action_porb = 0.928211666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000018
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =9093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =9094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.92818
DEBUG:root: dqn, choose action rondomly, need time 0.000340999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17.54429436]
 [ 17.30194855]
 [ 16.84497643]
 [ 18.29129601]
 [ 26.74734497]
 [ 18.29129601]
 [ 16.07565117]
 [ 20.59713173]
 [ 18.35994911]
 [ 15.95236683]
 [ 26.88261795]
 [ 17.12210083]
 [ 15.84637928]
 [ 15.44910049]
 [ 17.37247276]
 [ 16.15147972]]
DEBUG:root:training time = %d0.239274
INFO:root:frame =9097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =9098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000503063201904
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.928148333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =9101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =9102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.928116666667
DEBUG:root: dqn, choose action rondomly, need time 0.000173999999987
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000134944915771
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 15.58982086]
 [ 15.9283638 ]
 [ 16.43801689]
 [ 16.25091553]
 [ 17.14540672]
 [ 19.55749893]
 [ 17.43319893]
 [ 26.35343933]
 [ 18.70936012]
 [ 17.14540672]
 [ 26.5268383 ]
 [ 17.23017502]
 [ 15.70607471]
 [ 15.5018034 ]
 [ 16.77315903]
 [ 16.68142128]]
DEBUG:root:training time = %d0.224484
INFO:root:frame =9105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =9106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.928085
DEBUG:root: dqn, choose action rondomly, need time 0.000325000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =9109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =9110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000407934188843
DEBUG:root: save sample needs time = 0.000279188156128
INFO:root:random_action_porb = 0.928053333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.53963089]
 [ 17.65696144]
 [ 16.61542511]
 [ 16.24248886]
 [ 16.0625    ]
 [ 17.12481689]
 [ 15.13607216]
 [ 17.8482914 ]
 [ 16.92316246]
 [ 27.27693558]
 [ 19.46112251]
 [ 16.86953545]
 [ 16.05840302]
 [ 16.33128738]
 [ 25.57254601]
 [ 18.09539413]]
DEBUG:root:training time = %d0.239082
INFO:root:frame =9113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270128250122
INFO:root:frame =9114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000295877456665
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.928021666667
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =9117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000400066375732
INFO:root:frame =9118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.92799
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17.26135254]
 [ 18.99769783]
 [ 17.27105331]
 [ 18.75499535]
 [ 15.84285641]
 [ 17.86757088]
 [ 17.20712852]
 [ 17.46800232]
 [ 16.92008781]
 [ 17.03048325]
 [ 25.70458794]
 [ 18.53171349]
 [ 15.32197571]
 [ 17.65529442]
 [ 16.41037369]
 [ 16.73986816]]
DEBUG:root:training time = %d0.218138
INFO:root:frame =9121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0003821849823
INFO:root:frame =9122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame = 9123 State into memory, numbers recorded 239 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000562906265259
INFO:root:random_action_porb = 0.927958333333
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9124current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =9125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =9126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000235795974731
INFO:root:random_action_porb = 0.927926666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17.71362305]
 [ 15.18128204]
 [ 16.92215729]
 [ 17.71362305]
 [ 26.43543816]
 [ 16.41785431]
 [ 17.12475204]
 [ 17.52078247]
 [ 17.30264664]
 [ 15.36201954]
 [ 18.55293655]
 [ 17.35797501]
 [ 17.30531311]
 [ 18.22954941]
 [ 18.1320858 ]
 [ 17.93548775]]
DEBUG:root:training time = %d0.227587
INFO:root:frame =9129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =9130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274181365967
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.927895
DEBUG:root: dqn, choose action rondomly, need time 0.000377000000015
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304222106934
INFO:root:frame =9133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000509977340698
INFO:root:frame =9134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475883483887
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.927863333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 25.72400856]
 [ 18.29142761]
 [ 16.42310905]
 [ 16.71471786]
 [ 16.79954147]
 [ 16.45849991]
 [ 16.45020485]
 [ 16.46970558]
 [ 15.99639893]
 [ 25.57470703]
 [ 18.48451424]
 [ 10.4126749 ]
 [ 28.42535019]
 [ 18.11383247]
 [ 16.91343498]
 [ 16.3975811 ]]
DEBUG:root:training time = %d0.228866
INFO:root:frame =9137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259160995483
INFO:root:frame =9138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000511884689331
DEBUG:root: save sample needs time = 0.000155925750732
INFO:root:random_action_porb = 0.927831666667
DEBUG:root: dqn, choose action rondomly, need time 0.000337999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =9141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000425100326538
INFO:root:frame =9142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
DEBUG:root: save sample needs time = 0.000192880630493
INFO:root:random_action_porb = 0.9278
DEBUG:root: dqn, choose action rondomly, need time 0.00027399999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.01544571]
 [ 17.52097511]
 [ 16.12769508]
 [ 16.34824944]
 [ 16.93427467]
 [ 16.76297379]
 [ 15.77799702]
 [ 17.86396027]
 [ 16.24507141]
 [ 18.03449631]
 [ 16.66565704]
 [ 17.02890778]
 [ 17.9630928 ]
 [ 26.73732185]
 [ 16.09107208]
 [ 17.06645775]]
DEBUG:root:training time = %d0.210603
INFO:root:frame =9145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =9146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.927768333333
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:frame =9149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =9150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame = 9151 State into memory, numbers recorded 240 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:random_action_porb = 0.927736666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999965
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9152current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:training error  = [[ 16.71134949]
 [ 17.72916794]
 [ 16.20119095]
 [ 17.32334518]
 [ 18.02736855]
 [ 16.47757149]
 [ 15.74982643]
 [ 16.40678978]
 [ 17.53292084]
 [ 17.37240791]
 [ 16.66540909]
 [ 16.24580956]
 [ 16.96185112]
 [ 16.30940437]
 [ 16.98586655]
 [ 17.60173607]]
DEBUG:root:training time = %d0.226473
INFO:root:player has been killed for 5 times 
INFO:root:frame =9153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:frame =9154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame = 9155 State into memory, numbers recorded 241 action = 1, reward = -1
DEBUG:root: save sample needs time = 0.000568866729736
INFO:root:random_action_porb = 0.927705
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9156current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =9157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame =9158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.927673333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.45955276]
 [ 15.2521143 ]
 [ 16.85907173]
 [ 16.90966988]
 [ 17.7073288 ]
 [ 16.23166847]
 [ 25.75907898]
 [ 17.5251255 ]
 [ 16.83270454]
 [ 16.19369888]
 [ 10.53251839]
 [ 16.08825684]
 [ 15.88308811]
 [ 16.84128189]
 [ 16.55583191]
 [ 17.0068779 ]]
DEBUG:root:training time = %d0.225309
INFO:root:frame =9161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =9162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.927641666667
DEBUG:root: dqn, choose action rondomly, need time 0.000184999999988
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root:frame =9165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =9166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.92761
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17.14319611]
 [ 17.52659607]
 [ 17.61364365]
 [ 16.36904716]
 [ 16.97109032]
 [ 16.96555901]
 [ 25.58381271]
 [ 16.07149124]
 [ 15.94060707]
 [ 16.36904716]
 [ 16.10772514]
 [ 17.33687592]
 [ 16.30508995]
 [ 18.30317688]
 [ 16.38108826]
 [ 17.76362228]]
DEBUG:root:training time = %d0.229008
INFO:root:frame =9169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =9170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame = 9171 State into memory, numbers recorded 242 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000573873519897
INFO:root:random_action_porb = 0.927578333333
DEBUG:root: dqn, choose action rondomly, need time 0.000344999999982
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9172current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000396966934204
INFO:root:frame =9173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =9174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.927546666667
DEBUG:root: dqn, choose action rondomly, need time 0.000276999999983
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.99530029]
 [ 17.20598984]
 [ 18.72507286]
 [ 15.82561207]
 [ 17.48547935]
 [ 18.34863853]
 [ 16.2883358 ]
 [ 16.19161034]
 [ 18.57713127]
 [ 16.2883358 ]
 [ 17.6316433 ]
 [ 19.05507088]
 [ 10.98635769]
 [ 16.4695816 ]
 [ 18.34863853]
 [ 16.57775497]]
DEBUG:root:training time = %d0.235915
INFO:root:frame =9177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =9178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240087509155
DEBUG:root: save sample needs time = 9.58442687988e-05
INFO:root:random_action_porb = 0.927515
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =9181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =9182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000653028488159
DEBUG:root: save sample needs time = 0.000108003616333
INFO:root:random_action_porb = 0.927483333333
DEBUG:root: dqn, choose action rondomly, need time 0.000354000000016
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17.9889698 ]
 [ 16.23793793]
 [ 18.84490776]
 [ 16.59397507]
 [ 19.36068535]
 [ 19.36068535]
 [ 29.10779953]
 [ 17.74465561]
 [ 18.97994614]
 [  9.75713921]
 [ 18.61694145]
 [ 19.52121162]
 [ 20.77389145]
 [ 17.83907318]
 [ 19.41073608]
 [ 19.21345901]]
DEBUG:root:training time = %d0.205742
INFO:root:frame =9185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =9186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.927451666667
DEBUG:root: dqn, choose action rondomly, need time 0.00033099999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000428915023804
INFO:root:frame =9189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =9190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.92742
DEBUG:root: dqn, choose action rondomly, need time 0.000343999999984
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.98863411]
 [ 16.94941139]
 [ 17.45308113]
 [ 16.93546867]
 [ 18.56305885]
 [ 26.70056725]
 [ 16.94941139]
 [ 17.45952034]
 [ 17.97072411]
 [ 16.60186958]
 [ 17.72389984]
 [ 18.15671921]
 [ 16.73605919]
 [ 19.12841034]
 [ 27.02949524]
 [ 16.90170097]]
DEBUG:root:training time = %d0.198877
INFO:root:frame =9193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =9194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.927388333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =9197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =9198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000199794769287
INFO:root:random_action_porb = 0.927356666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320196151733
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17.86608696]
 [ 18.26428986]
 [ 19.36216164]
 [ 17.73874283]
 [ 15.78060341]
 [ 17.50060463]
 [ 17.43205261]
 [ 17.63568115]
 [ 17.54276085]
 [ 27.01394844]
 [ 18.34798622]
 [ 27.58076859]
 [ 16.75522804]
 [ 17.25463295]
 [ 16.28507233]
 [ 18.74382782]]
DEBUG:root:training time = %d0.210359
INFO:root:frame =9201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =9202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.927325
INFO:root:dqn select action Tensor("ArgMax_83:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00831399999998
INFO:root:action choosen by dqn [4]
INFO:root:frame =9204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000346899032593
INFO:root:frame =9205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000584840774536
INFO:root:frame =9206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.927293333333
DEBUG:root: dqn, choose action rondomly, need time 0.000173000000018
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.28316307]
 [ 16.51903534]
 [ 17.26629639]
 [ 26.80032158]
 [ 27.46533394]
 [ 17.84661484]
 [ 17.31210518]
 [  9.92496109]
 [ 10.86978722]
 [ 17.26376152]
 [ 17.38290405]
 [ 17.16253471]
 [ 17.99045944]
 [ 18.14599228]
 [ 18.24649048]
 [ 17.81034279]]
DEBUG:root:training time = %d0.232395
INFO:root:frame =9209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285148620605
INFO:root:frame =9210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame = 9211 State into memory, numbers recorded 243 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000577926635742
INFO:root:random_action_porb = 0.927261666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000031
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9212current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000389099121094
INFO:root:frame =9213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =9214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:random_action_porb = 0.92723
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000033
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 16.65251732]
 [ 18.09123993]
 [ 17.19592667]
 [ 17.92489243]
 [ 17.69314194]
 [ 19.05420494]
 [ 18.49914742]
 [ 18.6949749 ]
 [ 17.83134079]
 [ 17.37005615]
 [ 19.43871307]
 [ 17.25095749]
 [ 16.52499008]
 [ 17.64664078]
 [ 16.80886078]
 [ 16.80798531]]
DEBUG:root:training time = %d0.21909
INFO:root:frame =9217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =9218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509977340698
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:random_action_porb = 0.927198333333
DEBUG:root: dqn, choose action rondomly, need time 0.000337000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:frame =9221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =9222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.927166666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330209732056
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 18.87379837]
 [ 17.38354111]
 [ 16.82744598]
 [ 17.33414268]
 [ 17.10518456]
 [ 17.33414268]
 [ 29.12385559]
 [ 17.65375519]
 [ 18.90569687]
 [ 17.11275673]
 [ 17.62760735]
 [ 18.01279449]
 [ 18.82047272]
 [ 26.43292809]
 [ 18.63511658]
 [ 17.46596146]]
DEBUG:root:training time = %d0.206002
INFO:root:frame =9225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =9226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame = 9227 State into memory, numbers recorded 244 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.00058388710022
INFO:root:random_action_porb = 0.927135
DEBUG:root: dqn, choose action rondomly, need time 0.000189000000034
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9228current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000180006027222
INFO:root:frame =9229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469207763672
INFO:root:frame =9230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000378847122192
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:random_action_porb = 0.927103333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17.40836143]
 [ 18.25079346]
 [ 19.73829079]
 [ 17.45461273]
 [ 16.3163681 ]
 [ 28.06310844]
 [ 19.43642616]
 [ 17.21795273]
 [ 16.08103561]
 [ 16.36941719]
 [ 10.26792908]
 [ 17.90454865]
 [ 17.54397583]
 [ 17.49007416]
 [ 17.68877792]
 [ 17.2240963 ]]
DEBUG:root:training time = %d0.216504
INFO:root:frame =9233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:frame =9234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000285863876343
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.927071666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =9237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =9238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.92704
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:training error  = [[ 16.08954048]
 [ 17.66183472]
 [ 18.63570976]
 [ 17.10064125]
 [ 17.08556366]
 [ 17.5187397 ]
 [ 16.50440216]
 [ 18.56338882]
 [ 18.00683784]
 [ 17.59802246]
 [ 17.61633492]
 [ 17.79205894]
 [ 18.85855484]
 [ 17.0996933 ]
 [ 17.44734573]
 [ 16.38763428]]
DEBUG:root:training time = %d0.230467
INFO:root:frame =9241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =9242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.927008333333
DEBUG:root: dqn, choose action rondomly, need time 0.000377999999955
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =9245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000585079193115
INFO:root:frame =9246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:random_action_porb = 0.926976666667
DEBUG:root: dqn, choose action rondomly, need time 0.000342000000046
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17.56954956]
 [ 17.50092506]
 [ 16.60678101]
 [ 18.56970024]
 [ 18.70711708]
 [ 17.09439468]
 [ 28.95028114]
 [ 16.83333015]
 [ 17.03640175]
 [ 17.70296288]
 [ 17.56954956]
 [ 17.78285599]
 [ 17.10897064]
 [ 17.75275421]
 [ 16.69843864]
 [ 17.16436768]]
DEBUG:root:training time = %d0.221903
INFO:root:frame =9249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =9250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.926945
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =9253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =9254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487804412842
DEBUG:root: save sample needs time = 0.000123977661133
INFO:root:random_action_porb = 0.926913333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17.75777054]
 [ 17.62075424]
 [ 18.93775558]
 [ 16.66565704]
 [ 26.51434326]
 [ 18.51614952]
 [ 18.17577553]
 [ 18.17577553]
 [ 17.47807884]
 [ 18.01700401]
 [ 17.02513123]
 [ 20.01769066]
 [ 17.5538826 ]
 [ 16.13039207]
 [ 16.62805367]
 [ 20.37633324]]
DEBUG:root:training time = %d0.238493
INFO:root:frame =9257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =9258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000297069549561
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.926881666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283000000024
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =9261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =9262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.92685
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000022
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.53538036]
 [ 19.09165573]
 [ 10.43361187]
 [ 18.24701309]
 [ 17.62145805]
 [ 16.9981308 ]
 [  9.97535515]
 [ 17.93303299]
 [ 17.31109047]
 [ 17.18978882]
 [ 16.99272156]
 [ 19.62138748]
 [ 19.50584412]
 [ 26.87700081]
 [ 17.18978882]
 [ 19.53544044]]
DEBUG:root:training time = %d0.228198
INFO:root:frame =9265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000327825546265
INFO:root:frame =9266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000312805175781
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.926818333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =9269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =9270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.926786666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17.62389183]
 [ 19.18571281]
 [ 17.45091438]
 [ 16.78878593]
 [ 16.72345161]
 [ 17.27365303]
 [ 26.81904602]
 [ 17.23511696]
 [ 17.05895615]
 [ 17.86163712]
 [ 17.15981483]
 [ 26.75097466]
 [ 17.19795227]
 [ 17.30309105]
 [ 18.48333359]
 [ 18.17798615]]
DEBUG:root:training time = %d0.233906
INFO:root:frame =9273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =9274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293016433716
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.926755
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000033
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =9277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =9278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.926723333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:training error  = [[ 20.29596329]
 [ 17.07812119]
 [ 18.57081795]
 [ 17.79823875]
 [ 18.85365105]
 [ 18.61345291]
 [ 17.73148155]
 [ 17.35937309]
 [ 17.05410385]
 [ 15.46733856]
 [ 18.09526443]
 [ 18.38048363]
 [ 17.41033363]
 [ 18.64381218]
 [ 17.95061302]
 [ 17.61031532]]
DEBUG:root:training time = %d0.225018
INFO:root:frame =9281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =9282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000362873077393
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.926691666667
DEBUG:root: dqn, choose action rondomly, need time 0.000317999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =9285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =9286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487089157104
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.92666
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 18.67591286]
 [ 17.77931786]
 [ 19.90969849]
 [ 19.261446  ]
 [ 16.67525101]
 [ 17.69564629]
 [ 18.81477928]
 [ 17.68383789]
 [ 20.43009377]
 [ 10.97331333]
 [ 18.62365723]
 [ 18.95954323]
 [ 18.1560688 ]
 [ 16.66833687]
 [ 17.66715813]
 [ 18.2448616 ]]
DEBUG:root:training time = %d0.240044
INFO:root:frame =9289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =9290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000297069549561
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.926628333333
INFO:root:dqn select action Tensor("ArgMax_84:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012344
INFO:root:action choosen by dqn [4]
INFO:root:frame =9292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:frame =9293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000481128692627
INFO:root:frame =9294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.926596666667
INFO:root:dqn select action Tensor("ArgMax_85:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.008826
INFO:root:action choosen by dqn [4]
INFO:root:frame =9296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17.07522011]
 [ 18.7508316 ]
 [ 18.52054787]
 [ 18.13533401]
 [ 20.68545151]
 [ 28.26725769]
 [ 17.55100632]
 [ 18.56963539]
 [ 28.01769829]
 [ 17.58483887]
 [ 18.66622162]
 [ 17.16057396]
 [ 17.25133705]
 [ 18.35308456]
 [ 19.48650742]
 [ 17.28773499]]
DEBUG:root:training time = %d0.232923
INFO:root:frame =9297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =9298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456809997559
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.926565
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =9301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =9302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.926533333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000031
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17.26794624]
 [ 19.22650337]
 [ 20.25878906]
 [ 10.98666191]
 [ 17.722229  ]
 [ 18.50013161]
 [ 18.43233109]
 [ 27.90868759]
 [ 17.76947403]
 [ 18.67545128]
 [ 19.22650337]
 [ 18.31251144]
 [ 19.49425507]
 [ 17.60211945]
 [ 19.07292557]
 [ 18.10396194]]
DEBUG:root:training time = %d0.218347
INFO:root:frame =9305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =9306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476121902466
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:random_action_porb = 0.926501666667
INFO:root:dqn select action Tensor("ArgMax_86:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010767
INFO:root:action choosen by dqn [4]
INFO:root:frame =9308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162124633789
INFO:root:frame =9309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:frame =9310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000223159790039
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.92647
DEBUG:root: dqn, choose action rondomly, need time 0.000171999999964
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17.47667694]
 [ 19.17107773]
 [ 18.66193581]
 [ 17.65824318]
 [ 18.28222656]
 [ 10.31717587]
 [ 19.15190887]
 [ 17.97091866]
 [ 18.10240555]
 [ 18.35726738]
 [ 17.96787834]
 [ 17.70180893]
 [ 17.35892868]
 [ 18.10344315]
 [ 19.18912125]
 [ 18.03300476]]
DEBUG:root:training time = %d0.235343
INFO:root:frame =9313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =9314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.926438333333
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =9317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =9318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000495910644531
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.926406666667
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000026
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 26.97216988]
 [ 19.17909622]
 [ 18.3904953 ]
 [ 19.92944717]
 [ 17.39919472]
 [ 17.45894814]
 [ 18.86557961]
 [ 18.36916924]
 [ 18.47572517]
 [ 30.38316536]
 [ 18.11987305]
 [ 17.10549927]
 [ 17.68255424]
 [ 16.64243126]
 [ 18.17479897]
 [ 17.10549927]]
DEBUG:root:training time = %d0.232411
INFO:root:frame =9321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =9322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000416994094849
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.926375
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =9325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000425815582275
INFO:root:frame =9326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.926343333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17.42071342]
 [ 18.55688095]
 [ 18.38355827]
 [ 18.28698921]
 [ 19.36766815]
 [ 19.22336006]
 [ 18.38355827]
 [ 18.8009491 ]
 [ 17.38805771]
 [ 17.30886841]
 [ 17.81497955]
 [ 27.73861885]
 [ 19.46670914]
 [ 19.42445374]
 [ 19.22336006]
 [ 17.45091438]]
DEBUG:root:training time = %d0.236291
INFO:root:frame =9329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =9330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.926311666667
DEBUG:root: dqn, choose action rondomly, need time 0.000184000000047
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000182867050171
INFO:root:frame =9333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =9334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504016876221
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.92628
INFO:root:dqn select action Tensor("ArgMax_87:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011879
INFO:root:action choosen by dqn [4]
INFO:root:frame =9336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:training error  = [[ 19.13108063]
 [ 17.49990273]
 [ 17.14553452]
 [ 17.81278992]
 [ 17.01713562]
 [ 18.34667778]
 [ 18.95681763]
 [ 17.01669502]
 [ 17.48458672]
 [ 19.22422981]
 [ 18.25255394]
 [ 17.08896828]
 [ 18.12604332]
 [ 18.77621269]
 [ 19.17094421]
 [ 19.57903099]]
DEBUG:root:training time = %d0.221448
INFO:root:frame =9337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:frame =9338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.926248333333
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309228897095
INFO:root:frame =9341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000424146652222
INFO:root:frame =9342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486135482788
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.926216666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 20.81550217]
 [ 17.85441589]
 [ 18.25548744]
 [ 17.52863884]
 [ 20.56743431]
 [ 19.76975822]
 [ 17.24069214]
 [ 27.5438385 ]
 [ 19.48179245]
 [ 17.09407806]
 [ 17.08461761]
 [ 19.71267319]
 [ 18.61114883]
 [ 17.85441589]
 [ 17.6743412 ]
 [ 19.27732086]]
DEBUG:root:training time = %d0.230363
INFO:root:frame =9345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =9346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000316143035889
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.926185
DEBUG:root: dqn, choose action rondomly, need time 0.000201000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =9349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000493049621582
INFO:root:frame =9350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 9.58442687988e-05
INFO:root:random_action_porb = 0.926153333333
DEBUG:root: dqn, choose action rondomly, need time 0.000330000000019
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17.1052475 ]
 [ 18.66496849]
 [ 19.3202877 ]
 [ 29.04058075]
 [ 16.81643105]
 [ 18.59917068]
 [ 18.81822205]
 [ 16.99045753]
 [ 17.66747856]
 [ 18.93735695]
 [ 19.62321281]
 [ 19.20483208]
 [ 18.71133995]
 [ 21.1868782 ]
 [ 19.89533424]
 [ 19.73449326]]
DEBUG:root:training time = %d0.213736
INFO:root:frame =9353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =9354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000260829925537
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:random_action_porb = 0.926121666667
DEBUG:root: dqn, choose action rondomly, need time 0.000280999999973
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:frame =9357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =9358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.92609
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 19.65120697]
 [ 17.09698105]
 [ 21.14426613]
 [ 18.2079258 ]
 [ 18.39566422]
 [ 18.74508476]
 [ 18.60068321]
 [ 17.55196571]
 [ 18.5308609 ]
 [ 20.39955139]
 [ 19.16847229]
 [ 11.01925755]
 [ 18.48136711]
 [ 18.72923279]
 [ 19.06439781]
 [ 19.4556694 ]]
DEBUG:root:training time = %d0.214157
INFO:root:frame =9361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =9362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.926058333333
DEBUG:root: dqn, choose action rondomly, need time 0.000475999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =9365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000530004501343
INFO:root:frame =9366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476121902466
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.926026666667
DEBUG:root: dqn, choose action rondomly, need time 0.00028100000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17.59923935]
 [ 16.38201332]
 [ 18.52796936]
 [ 18.58219528]
 [ 18.46831512]
 [ 18.90616226]
 [ 18.42873001]
 [ 17.93684578]
 [ 30.96721458]
 [ 18.11409187]
 [ 18.67525291]
 [ 18.81253052]
 [ 17.68601799]
 [ 19.86002731]
 [ 18.93516731]
 [ 18.76801491]]
DEBUG:root:training time = %d0.23432
INFO:root:frame =9369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root:frame =9370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.925995
DEBUG:root: dqn, choose action rondomly, need time 0.000448000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =9373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =9374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.925963333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:training error  = [[ 19.36021423]
 [ 19.08885574]
 [ 19.82081032]
 [ 19.51743698]
 [ 17.81285286]
 [ 19.4987011 ]
 [ 20.2488327 ]
 [ 19.89969063]
 [ 18.83629608]
 [ 20.25109863]
 [ 18.24544907]
 [ 18.18638039]
 [ 18.46103668]
 [ 18.39075661]
 [ 17.0385437 ]
 [ 18.70190239]]
DEBUG:root:training time = %d0.244384
INFO:root:frame =9377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =9378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000261068344116
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:random_action_porb = 0.925931666667
DEBUG:root: dqn, choose action rondomly, need time 0.000207999999986
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:frame =9381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =9382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9259
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 18.57680321]
 [ 28.66699219]
 [ 19.36444473]
 [ 19.66622543]
 [ 18.47165871]
 [ 18.08968163]
 [ 17.77275467]
 [ 17.90002823]
 [ 18.80147934]
 [ 18.45028687]
 [ 18.47165871]
 [ 20.23476028]
 [ 19.53422546]
 [ 18.80147934]
 [ 18.67802238]
 [ 28.40729332]]
DEBUG:root:training time = %d0.219866
INFO:root:frame =9385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =9386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025486946106
DEBUG:root: save sample needs time = 9.41753387451e-05
INFO:root:random_action_porb = 0.925868333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =9389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456809997559
INFO:root:frame =9390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00077486038208
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:random_action_porb = 0.925836666667
INFO:root:dqn select action Tensor("ArgMax_88:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011738
INFO:root:action choosen by dqn [4]
INFO:root:frame =9392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000187873840332
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 19.72656441]
 [ 29.80567551]
 [ 19.25548553]
 [ 32.44962311]
 [ 17.36299706]
 [ 18.9548912 ]
 [ 17.45072365]
 [ 18.80147934]
 [ 18.64928246]
 [ 18.57357979]
 [ 20.91677666]
 [ 20.36545181]
 [ 18.40450096]
 [ 20.32415771]
 [ 18.72857094]
 [ 18.37714767]]
DEBUG:root:training time = %d0.222087
INFO:root:frame =9393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256776809692
INFO:root:frame =9394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.925805
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =9397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =9398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.925773333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 19.80627632]
 [ 28.45195961]
 [ 18.79618645]
 [ 18.46339798]
 [ 17.43574715]
 [ 19.15157509]
 [ 19.19259644]
 [ 19.24892426]
 [ 17.0245018 ]
 [ 20.26050758]
 [ 18.55004501]
 [ 19.03888893]
 [ 18.02808189]
 [ 18.43017006]
 [ 18.61575699]
 [ 18.89727211]]
DEBUG:root:training time = %d0.22699
INFO:root:frame =9401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =9402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.925741666667
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =9405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =9406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame = 9407 State into memory, numbers recorded 245 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000602006912231
INFO:root:random_action_porb = 0.92571
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999976
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9408current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000346183776855
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17.97486496]
 [ 19.40387917]
 [ 17.63882065]
 [ 19.54535484]
 [ 17.81935883]
 [ 18.82517242]
 [ 17.44218254]
 [ 20.69857025]
 [ 20.69857025]
 [ 29.67669296]
 [ 21.09798241]
 [ 17.9716301 ]
 [ 20.59207726]
 [ 18.79182053]
 [ 17.97486496]
 [ 21.10190773]]
DEBUG:root:training time = %d0.23349
INFO:root:frame =9409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000260829925537
INFO:root:frame =9410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249862670898
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.925678333333
DEBUG:root: dqn, choose action rondomly, need time 0.000324999999975
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =9413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =9414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:random_action_porb = 0.925646666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000356912612915
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 18.20564651]
 [ 18.68455315]
 [ 18.42591286]
 [ 18.78963661]
 [ 19.32297134]
 [ 19.94709396]
 [ 19.69221878]
 [ 18.68455315]
 [ 18.55635452]
 [ 29.63580894]
 [ 19.81102943]
 [ 20.62227821]
 [ 18.71754456]
 [ 18.69761467]
 [ 17.43746758]
 [ 17.8869915 ]]
DEBUG:root:training time = %d0.225519
INFO:root:frame =9417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =9418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00040602684021
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:random_action_porb = 0.925615
INFO:root:dqn select action Tensor("ArgMax_89:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00858500000004
INFO:root:action choosen by dqn [4]
INFO:root:frame =9420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:frame =9421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =9422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488996505737
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.925583333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 19.64538956]
 [ 18.45848083]
 [ 11.05869961]
 [ 17.83082581]
 [ 19.57660103]
 [ 19.38781929]
 [ 18.20108986]
 [ 19.91786957]
 [ 19.08498955]
 [ 18.1560688 ]
 [ 18.61654663]
 [ 19.91786957]
 [ 18.49055099]
 [ 19.98213959]
 [ 28.84659958]
 [ 16.88627243]]
DEBUG:root:training time = %d0.23423
INFO:root:frame =9425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =9426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:random_action_porb = 0.925551666667
INFO:root:dqn select action Tensor("ArgMax_90:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011803
INFO:root:action choosen by dqn [4]
INFO:root:frame =9428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =9429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000372886657715
INFO:root:frame =9430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:random_action_porb = 0.92552
DEBUG:root: dqn, choose action rondomly, need time 0.000546999999983
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 19.22697258]
 [ 18.07644463]
 [ 17.68903542]
 [ 20.72989082]
 [ 19.63125801]
 [ 21.72288704]
 [ 28.83242226]
 [ 19.24946022]
 [ 20.21108627]
 [ 19.74662971]
 [ 18.88215256]
 [ 19.19199562]
 [ 17.31204224]
 [ 20.23661232]
 [ 18.87273788]
 [ 19.13221359]]
DEBUG:root:training time = %d0.226926
INFO:root:frame =9433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =9434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265836715698
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.925488333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =9437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000451803207397
INFO:root:frame =9438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000235795974731
INFO:root:random_action_porb = 0.925456666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365972518921
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17.98353386]
 [ 19.4465847 ]
 [ 18.24375343]
 [ 19.57228088]
 [ 19.12680817]
 [ 21.84809303]
 [ 19.94416428]
 [ 10.82460785]
 [ 29.63572693]
 [ 18.56963539]
 [ 19.3463192 ]
 [ 18.64302254]
 [ 17.51094818]
 [ 20.98899841]
 [ 17.64740944]
 [ 17.54832077]]
DEBUG:root:training time = %d0.233147
INFO:root:frame =9441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0003662109375
INFO:root:frame =9442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488996505737
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.925425
INFO:root:dqn select action Tensor("ArgMax_91:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014496
INFO:root:action choosen by dqn [4]
INFO:root:frame =9444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =9445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:frame =9446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471830368042
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.925393333333
DEBUG:root: dqn, choose action rondomly, need time 0.000544999999988
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:training error  = [[ 18.61707306]
 [ 20.18962097]
 [ 20.25089264]
 [ 18.64427376]
 [ 21.35612869]
 [ 17.84912872]
 [ 19.37861443]
 [ 18.70500374]
 [ 19.28770638]
 [ 20.3561573 ]
 [ 19.16707039]
 [ 19.95425034]
 [ 20.08820724]
 [ 18.50472641]
 [ 19.12527466]
 [ 18.40181732]]
DEBUG:root:training time = %d0.223757
INFO:root:frame =9449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =9450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:random_action_porb = 0.925361666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000046
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =9453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000475883483887
INFO:root:frame =9454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:random_action_porb = 0.92533
DEBUG:root: dqn, choose action rondomly, need time 0.000307999999961
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 19.14216042]
 [ 20.70926285]
 [ 18.01052856]
 [ 19.76589012]
 [ 18.7196579 ]
 [ 18.1880722 ]
 [ 18.79664993]
 [ 19.54306221]
 [ 18.07417488]
 [ 29.0622921 ]
 [ 18.09085083]
 [ 19.12000275]
 [ 19.64498329]
 [ 18.73326111]
 [ 10.94351101]
 [ 11.05905533]]
DEBUG:root:training time = %d0.217066
INFO:root:frame =9457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =9458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000331163406372
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.925298333333
DEBUG:root: dqn, choose action rondomly, need time 0.000332000000014
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =9461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491857528687
INFO:root:frame =9462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000220775604248
INFO:root:random_action_porb = 0.925266666667
DEBUG:root: dqn, choose action rondomly, need time 0.00032699999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 20.85123062]
 [ 17.81130791]
 [ 28.83463478]
 [ 11.52615738]
 [ 20.86112595]
 [ 28.84299278]
 [ 19.68416214]
 [ 19.0068779 ]
 [ 18.36184502]
 [ 19.40475273]
 [ 19.0068779 ]
 [ 19.07525826]
 [ 18.69543648]
 [ 19.10559273]
 [ 18.64163971]
 [ 18.64163971]]
DEBUG:root:training time = %d0.221747
INFO:root:frame =9465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:player has been killed for 6 times 
INFO:root:frame =9466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root:frame = 9467 State into memory, numbers recorded 246 action = 1, reward = -1
DEBUG:root: save sample needs time = 0.000562906265259
INFO:root:random_action_porb = 0.925235
INFO:root:dqn select action Tensor("ArgMax_92:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011627
INFO:root:action choosen by dqn [4]
INFO:root:frame =9468current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.00039005279541
INFO:root:frame =9469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =9470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241041183472
DEBUG:root: save sample needs time = 0.000108957290649
INFO:root:random_action_porb = 0.925203333333
DEBUG:root: dqn, choose action rondomly, need time 0.000170999999966
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000134944915771
INFO:root:training error  = [[ 18.22459793]
 [ 18.97928047]
 [ 18.73061943]
 [ 19.13408279]
 [ 21.03166199]
 [ 19.9437561 ]
 [ 19.078125  ]
 [ 20.40244675]
 [ 18.38061523]
 [ 19.79704094]
 [ 18.02613831]
 [ 20.96775246]
 [ 19.13408279]
 [ 20.48592758]
 [ 19.39252281]
 [ 19.46744919]]
DEBUG:root:training time = %d0.237591
INFO:root:frame =9473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00036096572876
INFO:root:frame =9474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000410079956055
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.925171666667
DEBUG:root: dqn, choose action rondomly, need time 0.000512999999955
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =9477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000401020050049
INFO:root:frame =9478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000560998916626
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.92514
DEBUG:root: dqn, choose action rondomly, need time 0.000494000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 21.26265907]
 [ 20.83200455]
 [ 21.07731247]
 [ 20.23359299]
 [ 30.51948738]
 [ 20.08109474]
 [ 28.949049  ]
 [ 19.75307083]
 [ 18.558918  ]
 [ 20.18824959]
 [ 19.92406654]
 [ 12.4338131 ]
 [ 18.48103905]
 [ 18.18241119]
 [ 18.77918816]
 [ 19.05547142]]
DEBUG:root:training time = %d0.241593
INFO:root:frame =9481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =9482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000564813613892
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.925108333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =9485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =9486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000527858734131
INFO:root:frame = 9487 State into memory, numbers recorded 247 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:random_action_porb = 0.925076666667
DEBUG:root: dqn, choose action rondomly, need time 0.000173999999959
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9488current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000176191329956
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 18.59996033]
 [ 20.28386497]
 [ 20.10024643]
 [ 29.65608215]
 [ 18.5009861 ]
 [ 19.16399765]
 [ 20.01407242]
 [ 19.73523903]
 [ 30.00911713]
 [ 19.44779587]
 [ 18.75248337]
 [ 20.65860367]
 [ 18.20727348]
 [ 20.16206741]
 [ 20.16206741]
 [ 20.13261604]]
DEBUG:root:training time = %d0.230008
INFO:root:frame =9489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =9490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000360012054443
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.925045
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999976
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =9493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000500917434692
INFO:root:frame =9494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.925013333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000018
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 19.40045166]
 [ 18.18241119]
 [ 18.77323723]
 [ 18.83285332]
 [ 20.36125183]
 [ 19.60712814]
 [ 18.74944496]
 [ 17.97738838]
 [ 19.29400444]
 [ 18.63406372]
 [ 22.39819908]
 [ 18.61759949]
 [ 19.41483688]
 [ 18.41700554]
 [ 29.39019394]
 [ 17.97738838]]
DEBUG:root:training time = %d0.233409
INFO:root:frame =9497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =9498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.924981666667
INFO:root:dqn select action Tensor("ArgMax_93:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00926999999996
INFO:root:action choosen by dqn [4]
INFO:root:frame =9500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000353097915649
INFO:root:frame =9501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000410079956055
INFO:root:frame =9502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.92495
DEBUG:root: dqn, choose action rondomly, need time 0.000343999999984
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 29.36711884]
 [ 20.01305008]
 [ 11.67719173]
 [ 18.743433  ]
 [ 17.92683029]
 [ 19.22777557]
 [ 19.7298851 ]
 [ 20.56812668]
 [ 20.62782097]
 [ 19.30412674]
 [ 19.34564781]
 [ 19.13381577]
 [ 18.81967735]
 [ 19.15638351]
 [ 18.26233292]
 [ 21.05826187]]
DEBUG:root:training time = %d0.219017
INFO:root:frame =9505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =9506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000511884689331
DEBUG:root: save sample needs time = 0.000151872634888
INFO:root:random_action_porb = 0.924918333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000383853912354
INFO:root:frame =9509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000494956970215
INFO:root:frame =9510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000249147415161
INFO:root:random_action_porb = 0.924886666667
INFO:root:dqn select action Tensor("ArgMax_94:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00839400000001
INFO:root:action choosen by dqn [4]
INFO:root:frame =9512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 29.05464363]
 [ 18.07333183]
 [ 18.67927551]
 [ 19.93796349]
 [ 19.61240005]
 [ 29.22654915]
 [ 18.81530952]
 [ 18.77277565]
 [ 17.9388485 ]
 [ 21.5031929 ]
 [ 20.37578201]
 [ 19.70745659]
 [ 20.1432991 ]
 [ 18.88301468]
 [ 19.45627594]
 [ 20.58626175]]
DEBUG:root:training time = %d0.222671
INFO:root:frame =9513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =9514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294923782349
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.924855
DEBUG:root: dqn, choose action rondomly, need time 0.000340999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00062894821167
INFO:root:frame =9517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:frame =9518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.924823333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 18.10279465]
 [ 11.44336891]
 [ 21.00186348]
 [ 19.95704651]
 [ 19.56202126]
 [ 19.58321762]
 [ 18.98300362]
 [ 11.69810963]
 [ 18.40273285]
 [ 18.9333744 ]
 [ 19.15244293]
 [ 17.62952995]
 [ 18.55300331]
 [ 18.12000275]
 [ 33.58624649]
 [ 19.98050117]]
DEBUG:root:training time = %d0.224183
INFO:root:frame =9521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =9522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000383853912354
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.924791666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =9525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =9526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.92476
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000048
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:training error  = [[ 19.83256531]
 [ 18.66239738]
 [ 19.64640427]
 [ 19.46448708]
 [ 20.49518394]
 [ 19.23513603]
 [ 21.91225815]
 [ 21.44182014]
 [ 20.29238892]
 [ 19.86179543]
 [ 20.00622368]
 [ 19.10212517]
 [ 20.04986   ]
 [ 21.31595421]
 [ 19.41288757]
 [ 19.20703888]]
DEBUG:root:training time = %d0.223024
INFO:root:frame =9529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =9530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.924728333333
DEBUG:root: dqn, choose action rondomly, need time 0.000246000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000498056411743
INFO:root:frame =9533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000425100326538
INFO:root:frame =9534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509023666382
INFO:root: ememy has been killed for 21 times 
INFO:root:enemies_left [0]
INFO:root:frame = 9535 State into memory, numbers recorded 248 action = 4, reward = 1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:random_action_porb = 0.924696666667
DEBUG:root: dqn, choose action rondomly, need time 0.000246000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9536current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 19.92597389]
 [ 18.9475193 ]
 [ 19.38398933]
 [ 20.49387169]
 [ 19.34779549]
 [ 12.03905582]
 [ 18.65086365]
 [ 19.37196541]
 [ 20.4962883 ]
 [ 20.04050064]
 [ 19.38398933]
 [ 19.56539536]
 [ 20.74246788]
 [ 20.1219368 ]
 [ 19.60280418]
 [ 21.27300262]]
DEBUG:root:training time = %d0.209829
INFO:root:frame =9537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243186950684
INFO:root:frame =9538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000671148300171
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.924665
DEBUG:root: dqn, choose action rondomly, need time 0.000234999999975
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:frame =9541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000540018081665
INFO:root:frame =9542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000524997711182
INFO:root:frame = 9543 State into memory, numbers recorded 249 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:random_action_porb = 0.924633333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9544current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 21.64203072]
 [ 18.67960548]
 [ 21.73056984]
 [ 21.10702515]
 [ 21.33420563]
 [ 18.64513016]
 [ 29.05579376]
 [ 19.21359253]
 [ 19.7286644 ]
 [ 19.54859352]
 [ 21.53256798]
 [ 21.65431213]
 [ 19.55156136]
 [ 21.12722015]
 [ 31.03025055]
 [ 19.69926071]]
DEBUG:root:training time = %d0.220638
INFO:root:frame =9545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000396966934204
INFO:root:frame =9546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.924601666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999963
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =9549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root:frame =9550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:random_action_porb = 0.92457
INFO:root:dqn select action Tensor("ArgMax_95:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013979
INFO:root:action choosen by dqn [4]
INFO:root:frame =9552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 19.96352196]
 [ 21.10520363]
 [ 18.99350929]
 [ 19.85445213]
 [ 19.3726368 ]
 [ 18.76140594]
 [ 19.5046978 ]
 [ 11.57500839]
 [ 18.99716568]
 [ 18.79949379]
 [ 18.99723244]
 [ 19.61571121]
 [ 18.99350929]
 [ 11.49488926]
 [ 19.48751831]
 [ 19.23908424]]
DEBUG:root:training time = %d0.224827
INFO:root:frame =9553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =9554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.924538333333
DEBUG:root: dqn, choose action rondomly, need time 0.000179000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174045562744
INFO:root:frame =9557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =9558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:random_action_porb = 0.924506666667
DEBUG:root: dqn, choose action rondomly, need time 0.00032699999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000362873077393
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 21.66766357]
 [ 18.92885971]
 [ 18.81471443]
 [ 19.23828125]
 [ 20.18735695]
 [ 22.09384346]
 [ 12.75721169]
 [ 22.06380272]
 [ 20.62248611]
 [ 19.39084244]
 [ 21.37136269]
 [ 22.41235542]
 [ 20.61521149]
 [ 18.28712082]
 [ 18.75955391]
 [ 21.23888397]]
DEBUG:root:training time = %d0.226294
INFO:root:frame =9561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =9562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.924475
DEBUG:root: dqn, choose action rondomly, need time 0.000193000000024
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =9565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =9566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000297069549561
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:random_action_porb = 0.924443333333
DEBUG:root: dqn, choose action rondomly, need time 0.00018799999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 19.10039139]
 [ 19.31358147]
 [ 20.19346046]
 [ 20.31143188]
 [ 19.65201759]
 [ 19.36343765]
 [ 19.24986076]
 [ 22.33166695]
 [ 19.87485313]
 [ 20.14001274]
 [ 20.59131622]
 [ 31.56539536]
 [ 19.9736824 ]
 [ 20.05177307]
 [ 20.33764267]
 [ 20.47929764]]
DEBUG:root:training time = %d0.184554
INFO:root:frame =9569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =9570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame = 9571 State into memory, numbers recorded 250 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:random_action_porb = 0.924411666667
DEBUG:root: dqn, choose action rondomly, need time 0.000261000000023
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9572current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =9573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =9574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000292062759399
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:random_action_porb = 0.92438
DEBUG:root: dqn, choose action rondomly, need time 0.000225999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 20.9171257 ]
 [ 20.66332054]
 [ 11.31735802]
 [ 19.46287155]
 [ 19.4056282 ]
 [ 21.6903286 ]
 [ 19.66074562]
 [ 22.13876534]
 [ 19.62726784]
 [ 20.66332054]
 [ 18.58002472]
 [ 19.19660759]
 [ 23.19960594]
 [ 19.9415741 ]
 [ 22.81528664]
 [ 12.70978642]]
DEBUG:root:training time = %d0.219769
INFO:root:frame =9577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253200531006
INFO:root:frame =9578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481128692627
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:random_action_porb = 0.924348333333
DEBUG:root: dqn, choose action rondomly, need time 0.000269000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =9581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =9582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.924316666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 18.8103466 ]
 [ 20.6583252 ]
 [ 20.31232643]
 [ 21.83818054]
 [ 19.46024704]
 [ 21.2652626 ]
 [ 19.72771645]
 [ 21.60832596]
 [ 18.86511612]
 [ 18.15984154]
 [ 19.19660759]
 [ 19.95956802]
 [ 30.07159042]
 [ 19.92154694]
 [ 21.58074188]
 [ 18.23782349]]
DEBUG:root:training time = %d0.221318
INFO:root:frame =9585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000357151031494
INFO:root:frame =9586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000323057174683
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.924285
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:frame =9589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =9590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.924253333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999952
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 21.35909081]
 [ 21.09980583]
 [ 20.00438118]
 [ 12.70075798]
 [ 20.8003273 ]
 [ 20.69815445]
 [ 21.55579948]
 [ 21.60563087]
 [ 18.13000679]
 [ 20.58370018]
 [ 22.26242638]
 [ 20.094841  ]
 [ 18.82590103]
 [ 23.23997307]
 [ 20.5302906 ]
 [ 20.01584816]]
DEBUG:root:training time = %d0.208263
INFO:root:frame =9593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:frame =9594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264167785645
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.924221666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame =9597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000610113143921
INFO:root:frame =9598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:random_action_porb = 0.92419
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 20.45817375]
 [ 19.78251457]
 [ 19.70610237]
 [ 30.16747665]
 [ 19.44712257]
 [ 19.95609093]
 [ 21.5019207 ]
 [ 20.12529182]
 [ 20.04555511]
 [ 18.47926712]
 [ 19.95609093]
 [ 19.69648552]
 [ 20.12857819]
 [ 20.72162437]
 [ 19.79473305]
 [ 11.91537952]]
DEBUG:root:training time = %d0.204098
INFO:root:frame =9601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =9602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:random_action_porb = 0.924158333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000038
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320196151733
INFO:root:frame =9605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =9606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488996505737
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:random_action_porb = 0.924126666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 20.61597252]
 [ 21.00892639]
 [ 31.30608749]
 [ 21.76016998]
 [ 18.58278847]
 [ 29.96575165]
 [ 19.66893196]
 [ 22.71256256]
 [ 29.97159767]
 [ 18.58278847]
 [ 19.77667809]
 [ 23.59684563]
 [ 22.18164825]
 [ 22.18164825]
 [ 20.20381546]
 [ 19.12200356]]
DEBUG:root:training time = %d0.216719
INFO:root:frame =9609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =9610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000514030456543
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.924095
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999974
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root:frame =9613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =9614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.924063333333
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 20.3482399 ]
 [ 19.93019676]
 [ 21.39104843]
 [ 20.84210396]
 [ 19.82570267]
 [ 20.49946594]
 [ 19.48435211]
 [ 19.67272186]
 [ 19.59895515]
 [ 19.32458115]
 [ 29.71286201]
 [ 18.71510315]
 [ 21.22749329]
 [ 21.23635101]
 [ 19.87118149]
 [ 19.03156662]]
DEBUG:root:training time = %d0.208399
INFO:root:frame =9617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =9618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.924031666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283000000024
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =9621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =9622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487089157104
DEBUG:root: save sample needs time = 0.00338292121887
INFO:root:random_action_porb = 0.924
DEBUG:root: dqn, choose action rondomly, need time 0.000304000000028
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:training error  = [[ 22.30737305]
 [ 21.24570465]
 [ 21.89055061]
 [ 22.15255165]
 [ 20.90945053]
 [ 20.38480568]
 [ 20.23441696]
 [ 18.27961731]
 [ 20.95545578]
 [ 20.85784912]
 [ 19.57201004]
 [ 19.29628372]
 [ 20.85157776]
 [ 19.75056267]
 [ 19.2997036 ]
 [ 19.46152496]]
DEBUG:root:training time = %d0.218608
INFO:root:frame =9625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280141830444
INFO:root:frame =9626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000515937805176
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.923968333333
DEBUG:root: dqn, choose action rondomly, need time 0.00036399999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =9629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =9630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000519037246704
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.923936666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999956
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 20.79768372]
 [ 18.85066986]
 [ 21.56444168]
 [ 20.32106209]
 [ 19.9486618 ]
 [ 20.58695412]
 [ 19.4003849 ]
 [ 18.89455223]
 [ 29.58516121]
 [ 20.99165535]
 [ 20.48060989]
 [ 21.25351334]
 [ 20.03974915]
 [ 20.9126606 ]
 [ 19.29903221]
 [ 20.29554939]]
DEBUG:root:training time = %d0.232331
INFO:root:frame =9633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:frame =9634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229835510254
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.923905
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000031
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000391006469727
INFO:root:frame =9637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =9638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.923873333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 21.26216507]
 [ 31.80692482]
 [ 20.81139374]
 [ 19.45116043]
 [ 21.33180809]
 [ 21.90811539]
 [ 30.43297768]
 [ 20.04712677]
 [ 29.98220825]
 [ 18.87320137]
 [ 22.52439117]
 [ 19.68869781]
 [ 20.07596779]
 [ 21.77803802]
 [ 29.98220825]
 [ 21.24591637]]
DEBUG:root:training time = %d0.22785
INFO:root:frame =9641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =9642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000281810760498
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:random_action_porb = 0.923841666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =9645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =9646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.92381
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999968
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 20.55449677]
 [ 20.94365311]
 [ 21.70589447]
 [ 20.37915802]
 [ 21.28630638]
 [ 20.53402519]
 [ 20.84098816]
 [ 21.21800232]
 [ 21.70589447]
 [ 21.73818016]
 [ 23.20129776]
 [ 21.69686699]
 [ 18.52514648]
 [ 20.20847893]
 [ 20.34748268]
 [ 32.04522705]]
DEBUG:root:training time = %d0.240709
INFO:root:frame =9649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =9650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame = 9651 State into memory, numbers recorded 251 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000585079193115
INFO:root:random_action_porb = 0.923778333333
DEBUG:root: dqn, choose action rondomly, need time 0.000212000000033
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9652current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000184059143066
INFO:root:frame =9653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000519037246704
INFO:root:frame =9654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.923746666667
DEBUG:root: dqn, choose action rondomly, need time 0.000184999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000176906585693
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 19.9053421 ]
 [ 22.28582954]
 [ 19.66446686]
 [ 19.30975914]
 [ 20.30270004]
 [ 20.28269768]
 [ 19.80118179]
 [ 19.19346619]
 [ 21.45418739]
 [ 21.34886742]
 [ 23.65098572]
 [ 21.19137192]
 [ 22.83139801]
 [ 29.51963043]
 [ 19.4253273 ]
 [ 21.90483093]]
DEBUG:root:training time = %d0.222753
INFO:root:frame =9657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =9658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000385046005249
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.923715
DEBUG:root: dqn, choose action rondomly, need time 0.000537000000008
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =9661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =9662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000525951385498
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.923683333333
DEBUG:root: dqn, choose action rondomly, need time 0.000325999999973
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 20.926548  ]
 [ 21.35027695]
 [ 30.21727943]
 [ 20.06427765]
 [ 19.70237732]
 [ 19.24510956]
 [ 18.80478668]
 [ 23.75305557]
 [ 22.63191605]
 [ 20.48067856]
 [ 19.80403519]
 [ 19.85105133]
 [ 20.85255432]
 [ 20.32305527]
 [ 21.37369156]
 [ 19.29608345]]
DEBUG:root:training time = %d0.223969
INFO:root:frame =9665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =9666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000289916992188
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.923651666667
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =9669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =9670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.92362
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:training error  = [[ 20.68510437]
 [ 19.16099167]
 [ 20.01147842]
 [ 20.77556038]
 [ 20.32525826]
 [ 19.5474453 ]
 [ 20.79044724]
 [ 19.29239655]
 [ 23.30010986]
 [ 22.92518234]
 [ 19.27028656]
 [ 21.24563408]
 [ 21.26835823]
 [ 21.13507652]
 [ 20.15665627]
 [ 20.24855804]]
DEBUG:root:training time = %d0.228295
INFO:root:frame =9673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =9674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255823135376
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.923588333333
DEBUG:root: dqn, choose action rondomly, need time 0.000180999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:frame =9677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =9678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.923556666667
INFO:root:dqn select action Tensor("ArgMax_96:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012294
INFO:root:action choosen by dqn [4]
INFO:root:frame =9680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 21.28961563]
 [ 22.45456314]
 [ 21.43016434]
 [ 21.69096756]
 [ 21.85679436]
 [ 22.20522499]
 [ 21.59350395]
 [ 21.97051048]
 [ 21.08354759]
 [ 20.8329792 ]
 [ 19.98432159]
 [ 20.30854416]
 [ 21.95013237]
 [ 29.96950912]
 [ 21.55615234]
 [ 32.09102631]]
DEBUG:root:training time = %d0.223378
INFO:root:frame =9681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =9682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031590461731
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.923525
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =9685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =9686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.923493333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326156616211
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 23.371315  ]
 [ 21.99905777]
 [ 22.24133682]
 [ 22.61732674]
 [ 21.04104042]
 [ 20.23633766]
 [ 21.76486778]
 [ 22.73758507]
 [ 21.94569969]
 [ 22.27682686]
 [ 21.07626152]
 [ 30.86252022]
 [ 21.99905777]
 [ 20.84161568]
 [ 21.73184967]
 [ 20.96656418]]
DEBUG:root:training time = %d0.236452
INFO:root:frame =9689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =9690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.923461666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =9693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491857528687
INFO:root:frame =9694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.92343
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 22.91349411]
 [ 20.0965519 ]
 [ 19.98357201]
 [ 33.30272293]
 [ 19.95643234]
 [ 30.51181793]
 [ 21.78743935]
 [ 22.16964722]
 [ 20.46604347]
 [ 20.40375519]
 [ 22.40585518]
 [ 20.22748375]
 [ 21.91283035]
 [ 13.48339462]
 [ 22.40585518]
 [ 20.61943626]]
DEBUG:root:training time = %d0.216479
INFO:root:frame =9697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =9698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.923398333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =9701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root:frame =9702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475168228149
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.923366666667
DEBUG:root: dqn, choose action rondomly, need time 0.000170000000026
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000178098678589
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 22.15836906]
 [ 21.24345398]
 [ 21.88612366]
 [ 19.83637047]
 [ 22.09384346]
 [ 21.4122963 ]
 [ 20.00622368]
 [ 31.24183273]
 [ 20.18927765]
 [ 20.28510284]
 [ 21.59619904]
 [ 20.89549828]
 [ 21.04972076]
 [ 20.32113075]
 [ 19.55925369]
 [ 21.0066185 ]]
DEBUG:root:training time = %d0.243716
INFO:root:frame =9705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =9706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235080718994
DEBUG:root: save sample needs time = 0.000156164169312
INFO:root:random_action_porb = 0.923335
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =9709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =9710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.923303333333
INFO:root:dqn select action Tensor("ArgMax_97:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013204
INFO:root:action choosen by dqn [4]
INFO:root:frame =9712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000359058380127
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 33.32315445]
 [ 22.068964  ]
 [ 21.62875938]
 [ 21.89390564]
 [ 22.12261391]
 [ 22.56605148]
 [ 13.79541683]
 [ 24.66232681]
 [ 19.90214157]
 [ 21.52739906]
 [ 22.10159111]
 [ 22.66662788]
 [ 20.35099411]
 [ 21.59307861]
 [ 31.17278671]
 [ 22.86772156]]
DEBUG:root:training time = %d0.216013
INFO:root:frame =9713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =9714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:random_action_porb = 0.923271666667
DEBUG:root: dqn, choose action rondomly, need time 0.000181999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:frame =9717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =9718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:random_action_porb = 0.92324
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:training error  = [[ 19.22242355]
 [ 21.09791374]
 [ 21.18526268]
 [ 20.41547585]
 [ 20.77569962]
 [ 21.40714264]
 [ 20.40389442]
 [ 20.70731926]
 [ 20.90121841]
 [ 21.78850746]
 [ 20.70926285]
 [ 21.09791374]
 [ 21.60385704]
 [ 20.80993271]
 [ 21.18526268]
 [ 20.67032623]]
DEBUG:root:training time = %d0.216485
INFO:root:frame =9721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =9722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.923208333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =9725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440835952759
INFO:root:frame =9726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.923176666667
INFO:root:dqn select action Tensor("ArgMax_98:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013348
INFO:root:action choosen by dqn [4]
INFO:root:frame =9728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:training error  = [[ 21.66908455]
 [ 20.76651955]
 [ 21.49173164]
 [ 21.93483543]
 [ 20.48820686]
 [ 21.16209221]
 [ 20.46997833]
 [ 20.18276405]
 [ 20.38260078]
 [ 22.41784668]
 [ 20.3660717 ]
 [ 22.22205353]
 [ 21.10765648]
 [ 21.56706429]
 [ 21.74693298]
 [ 20.47736549]]
DEBUG:root:training time = %d0.218902
INFO:root:frame =9729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =9730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.923145
INFO:root:dqn select action Tensor("ArgMax_99:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.0116630000001
INFO:root:action choosen by dqn [4]
INFO:root:frame =9732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =9733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00044584274292
INFO:root:frame =9734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485897064209
INFO:root:frame = 9735 State into memory, numbers recorded 252 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00128889083862
INFO:root:random_action_porb = 0.923113333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9736current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 22.56445694]
 [ 22.04151726]
 [ 21.16602325]
 [ 22.5520649 ]
 [ 20.77152634]
 [ 20.51010704]
 [ 22.17165947]
 [ 30.65738297]
 [ 23.21967506]
 [ 21.2689209 ]
 [ 31.64259911]
 [ 22.85918427]
 [ 20.97236443]
 [ 21.07479095]
 [ 20.45113564]
 [ 23.21967506]]
DEBUG:root:training time = %d0.219338
INFO:root:frame =9737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =9738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame = 9739 State into memory, numbers recorded 253 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:random_action_porb = 0.923081666667
DEBUG:root: dqn, choose action rondomly, need time 0.00018399999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9740current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:frame =9741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =9742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.92305
DEBUG:root: dqn, choose action rondomly, need time 0.000215000000026
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180006027222
INFO:root:training error  = [[ 20.67698669]
 [ 21.03782082]
 [ 23.27455902]
 [ 21.63791466]
 [ 21.42486572]
 [ 24.18379021]
 [ 20.48288918]
 [ 20.98648071]
 [ 20.94504929]
 [ 20.48240662]
 [ 24.12747002]
 [ 20.98648071]
 [ 23.39123535]
 [ 24.56505013]
 [ 20.44768524]
 [ 19.40119171]]
DEBUG:root:training time = %d0.246749
INFO:root:frame =9745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =9746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277996063232
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.923018333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304000000028
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =9749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049901008606
INFO:root:frame =9750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042200088501
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.922986666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999968
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 22.730093  ]
 [ 22.18538475]
 [ 23.29244995]
 [ 20.98829842]
 [ 22.39162827]
 [ 31.02047729]
 [ 22.90327072]
 [ 21.47016335]
 [ 21.59243965]
 [ 19.9696579 ]
 [ 20.59020805]
 [ 24.2867775 ]
 [ 21.47157669]
 [ 23.29244995]
 [ 20.2804985 ]
 [ 21.47016335]]
DEBUG:root:training time = %d0.224129
INFO:root:frame =9753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259160995483
INFO:root:frame =9754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259876251221
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.922955
DEBUG:root: dqn, choose action rondomly, need time 0.000357000000008
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =9757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =9758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00033712387085
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.922923333333
DEBUG:root: dqn, choose action rondomly, need time 0.000237000000027
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 22.42261505]
 [ 23.11193657]
 [ 22.02404213]
 [ 32.1434288 ]
 [ 24.88660431]
 [ 20.932621  ]
 [ 20.26002693]
 [ 22.51867104]
 [ 21.69132233]
 [ 21.49993896]
 [ 23.64994621]
 [ 22.05713654]
 [ 20.90910149]
 [ 20.57767677]
 [ 24.50601959]
 [ 21.12160873]]
DEBUG:root:training time = %d0.222148
INFO:root:frame =9761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275850296021
INFO:root:frame =9762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.922891666667
DEBUG:root: dqn, choose action rondomly, need time 0.000329000000022
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =9765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =9766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.92286
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 21.62322426]
 [ 23.85728264]
 [ 21.61974716]
 [ 31.4673996 ]
 [ 20.82510948]
 [ 30.70302391]
 [ 21.4271965 ]
 [ 22.22565079]
 [ 23.12206078]
 [ 31.7350235 ]
 [ 22.22565079]
 [ 23.54898643]
 [ 20.37867546]
 [ 20.88524628]
 [ 21.75454712]
 [ 20.80526924]]
DEBUG:root:training time = %d0.234782
INFO:root:frame =9769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =9770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:random_action_porb = 0.922828333333
INFO:root:dqn select action Tensor("ArgMax_100:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00826899999998
INFO:root:action choosen by dqn [4]
INFO:root:frame =9772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root:frame =9773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:frame =9774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227928161621
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.922796666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000041
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 21.55211449]
 [ 21.45807457]
 [ 21.42006302]
 [ 35.01224136]
 [ 22.18782806]
 [ 22.61856079]
 [ 31.28414917]
 [ 20.14775085]
 [ 21.10716629]
 [ 23.89754677]
 [ 21.6973629 ]
 [ 32.23025513]
 [ 22.73176575]
 [ 20.78035927]
 [ 22.38188171]
 [ 22.93080902]]
DEBUG:root:training time = %d0.233071
INFO:root:frame =9777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =9778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.922765
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =9781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame =9782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000498056411743
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.922733333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000041
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:training error  = [[ 21.92325974]
 [ 21.89361954]
 [ 22.81412125]
 [ 21.29700851]
 [ 20.99389267]
 [ 21.70546722]
 [ 21.32173157]
 [ 21.66148567]
 [ 20.70356941]
 [ 21.01599121]
 [ 22.35200691]
 [ 21.94941711]
 [ 23.11648369]
 [ 20.65464973]
 [ 21.08852196]
 [ 21.32384491]]
DEBUG:root:training time = %d0.234493
INFO:root:frame =9785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =9786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000316143035889
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.922701666667
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =9789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =9790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047779083252
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.92267
DEBUG:root: dqn, choose action rondomly, need time 0.000338999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 21.01508141]
 [ 24.18514061]
 [ 23.98669243]
 [ 23.56187248]
 [ 31.65513229]
 [ 21.85658073]
 [ 20.84335709]
 [ 22.74151421]
 [ 20.55034637]
 [ 21.03362274]
 [ 33.06364059]
 [ 21.58053017]
 [ 21.73867798]
 [ 20.70641518]
 [ 20.6269207 ]
 [ 20.67663956]]
DEBUG:root:training time = %d0.242078
INFO:root:frame =9793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000404119491577
INFO:root:frame =9794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.922638333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =9797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =9798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.922606666667
DEBUG:root: dqn, choose action rondomly, need time 0.000329999999963
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 22.81608772]
 [ 21.42041588]
 [ 21.44634247]
 [ 21.66404152]
 [ 22.2859745 ]
 [ 20.87213898]
 [ 22.30766106]
 [ 23.77358437]
 [ 22.94052696]
 [ 21.84944725]
 [ 32.05110168]
 [ 21.34223938]
 [ 21.46026611]
 [ 22.17611504]
 [ 21.23381996]
 [ 22.43041992]]
DEBUG:root:training time = %d0.225125
INFO:root:frame =9801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =9802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:random_action_porb = 0.922575
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999976
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =9805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =9806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.922543333333
DEBUG:root: dqn, choose action rondomly, need time 0.000319999999988
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 21.37961769]
 [ 22.65703964]
 [ 21.65040779]
 [ 21.31997108]
 [ 21.92868996]
 [ 22.30715752]
 [ 23.12183952]
 [ 21.06407356]
 [ 13.32473946]
 [ 23.14488411]
 [ 22.43576813]
 [ 21.87377548]
 [ 22.54177475]
 [ 21.981884  ]
 [ 21.95899773]
 [ 21.47610283]]
DEBUG:root:training time = %d0.217579
INFO:root:frame =9809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290155410767
INFO:root:frame =9810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:random_action_porb = 0.922511666667
INFO:root:dqn select action Tensor("ArgMax_101:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015822
INFO:root:action choosen by dqn [4]
INFO:root:frame =9812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:frame =9813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =9814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:random_action_porb = 0.92248
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 30.82769012]
 [ 23.31123352]
 [ 21.11592865]
 [ 21.56302452]
 [ 33.19485474]
 [ 22.91963005]
 [ 21.74799919]
 [ 19.63680077]
 [ 22.7675724 ]
 [ 24.59387207]
 [ 22.11048698]
 [ 21.66936874]
 [ 31.566082  ]
 [ 22.20889282]
 [ 20.93317986]
 [ 21.87606049]]
DEBUG:root:training time = %d0.241503
INFO:root:frame =9817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =9818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.922448333333
INFO:root:dqn select action Tensor("ArgMax_102:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00929500000001
INFO:root:action choosen by dqn [4]
INFO:root:frame =9820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =9821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000518083572388
INFO:root:frame =9822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000425100326538
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.922416666667
INFO:root:dqn select action Tensor("ArgMax_103:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00902200000002
INFO:root:action choosen by dqn [4]
INFO:root:frame =9824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 22.32553864]
 [ 21.37721825]
 [ 21.45489311]
 [ 20.56093025]
 [ 21.89119339]
 [ 20.93995285]
 [ 21.54460716]
 [ 22.18128777]
 [ 21.69352531]
 [ 20.56093025]
 [ 21.45856857]
 [ 20.28826332]
 [ 20.80213737]
 [ 31.56085205]
 [ 19.91575813]
 [ 21.74977875]]
DEBUG:root:training time = %d0.224674
INFO:root:frame =9825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:frame =9826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.922385
DEBUG:root: dqn, choose action rondomly, need time 0.000534999999957
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =9829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =9830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462770462036
INFO:root:frame = 9831 State into memory, numbers recorded 254 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000613927841187
INFO:root:random_action_porb = 0.922353333333
INFO:root:dqn select action Tensor("ArgMax_104:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011058
INFO:root:action choosen by dqn [4]
INFO:root:frame =9832current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 24.3244648 ]
 [ 21.6236496 ]
 [ 21.33335876]
 [ 33.95183563]
 [ 21.6244297 ]
 [ 21.26272964]
 [ 23.16830826]
 [ 21.76202011]
 [ 21.56656837]
 [ 20.79274368]
 [ 21.61527824]
 [ 23.54298973]
 [ 22.77318001]
 [ 21.58839989]
 [ 22.46417999]
 [ 23.54298973]]
DEBUG:root:training time = %d0.229385
INFO:root:frame =9833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =9834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000244140625
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.922321666667
DEBUG:root: dqn, choose action rondomly, need time 0.000159999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:frame =9837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =9838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241041183472
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.92229
DEBUG:root: dqn, choose action rondomly, need time 0.000174999999956
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 21.33638954]
 [ 22.95617104]
 [ 33.91823578]
 [ 23.24240112]
 [ 21.41109657]
 [ 22.19350815]
 [ 21.46083069]
 [ 21.79634285]
 [ 21.61229897]
 [ 21.02368546]
 [ 22.11558151]
 [ 23.50235939]
 [ 32.79369354]
 [ 15.1926403 ]
 [ 22.55554199]
 [ 22.37329292]]
DEBUG:root:training time = %d0.22745
INFO:root:frame =9841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =9842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485897064209
INFO:root:frame = 9843 State into memory, numbers recorded 255 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000571966171265
INFO:root:random_action_porb = 0.922258333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000046
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9844current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =9845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:frame =9846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.922226666667
DEBUG:root: dqn, choose action rondomly, need time 0.000351000000023
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root:training error  = [[ 21.59435463]
 [ 22.76582527]
 [ 21.68485641]
 [ 22.86845016]
 [ 23.96569824]
 [ 21.96150017]
 [ 21.14770508]
 [ 23.2926712 ]
 [ 23.26852226]
 [ 22.18869209]
 [ 22.35575676]
 [ 21.43906403]
 [ 21.18778992]
 [ 22.66510201]
 [ 23.00803375]
 [ 22.30182457]]
DEBUG:root:training time = %d0.238904
INFO:root:frame =9849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =9850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269174575806
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.922195
DEBUG:root: dqn, choose action rondomly, need time 0.000180999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000166893005371
INFO:root:frame =9853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame =9854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
DEBUG:root: save sample needs time = 0.000157117843628
INFO:root:random_action_porb = 0.922163333333
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000021
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 21.70418739]
 [ 22.64048195]
 [ 23.39994431]
 [ 24.64331055]
 [ 21.53568459]
 [ 24.10476494]
 [ 21.67611694]
 [ 22.81244469]
 [ 23.55439186]
 [ 21.40488243]
 [ 34.30125809]
 [ 31.88175201]
 [ 21.16532135]
 [ 23.36017609]
 [ 24.02983284]
 [ 21.72359848]]
DEBUG:root:training time = %d0.220138
INFO:root:frame =9857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =9858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.922131666667
DEBUG:root: dqn, choose action rondomly, need time 0.00032299999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =9861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =9862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.9221
DEBUG:root: dqn, choose action rondomly, need time 0.000633999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 22.73314857]
 [ 22.63460159]
 [ 23.57113075]
 [ 33.92179108]
 [ 21.16012573]
 [ 21.44019508]
 [ 22.53301048]
 [ 24.12776947]
 [ 14.03401852]
 [ 20.58847618]
 [ 32.47726822]
 [ 21.77625847]
 [ 22.86064339]
 [ 22.53279305]
 [ 22.98549652]
 [ 21.63777161]]
DEBUG:root:training time = %d0.214329
INFO:root:frame =9865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =9866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411987304688
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.922068333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =9869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000646829605103
INFO:root:frame =9870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481128692627
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.922036666667
DEBUG:root: dqn, choose action rondomly, need time 0.000343999999984
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 22.71220016]
 [ 21.88012886]
 [ 22.08086395]
 [ 21.55296516]
 [ 21.09377861]
 [ 22.88085747]
 [ 23.90455818]
 [ 23.54928207]
 [ 22.5901947 ]
 [ 21.73896408]
 [ 23.92485428]
 [ 21.50432587]
 [ 33.95281219]
 [ 23.47167206]
 [ 24.33854103]
 [ 23.3755188 ]]
DEBUG:root:training time = %d0.230136
INFO:root:frame =9873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =9874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031590461731
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:random_action_porb = 0.922005
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999976
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =9877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =9878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame = 9879 State into memory, numbers recorded 256 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.00110697746277
INFO:root:random_action_porb = 0.921973333333
DEBUG:root: dqn, choose action rondomly, need time 0.000241000000017
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9880current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000554084777832
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 21.93605042]
 [ 32.51301956]
 [ 21.90047455]
 [ 22.8637085 ]
 [ 22.68704605]
 [ 22.19897079]
 [ 21.79199791]
 [ 21.34358025]
 [ 21.57230759]
 [ 33.13834763]
 [ 22.43345451]
 [ 21.47065735]
 [ 22.52526093]
 [ 32.51301956]
 [ 35.00862885]
 [ 24.67801476]]
DEBUG:root:training time = %d0.221859
INFO:root:frame =9881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000410079956055
INFO:root:frame =9882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00051212310791
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:random_action_porb = 0.921941666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =9885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =9886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.92191
DEBUG:root: dqn, choose action rondomly, need time 0.000450999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000427961349487
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 23.60344315]
 [ 23.02465057]
 [ 22.46606064]
 [ 23.10775566]
 [ 22.68370247]
 [ 22.57569313]
 [ 21.93326378]
 [ 34.15119934]
 [ 22.80428314]
 [ 33.64251328]
 [ 21.39973068]
 [ 20.07562637]
 [ 22.1899128 ]
 [ 23.6829052 ]
 [ 34.11375427]
 [ 21.31045914]]
DEBUG:root:training time = %d0.196406
INFO:root:frame =9889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame =9890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000365018844604
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:random_action_porb = 0.921878333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =9893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000511884689331
INFO:root:frame =9894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319957733154
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.921846666667
DEBUG:root: dqn, choose action rondomly, need time 0.000352000000021
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 33.96792984]
 [ 21.60215569]
 [ 25.10264397]
 [ 20.32615089]
 [ 21.57379723]
 [ 33.32201004]
 [ 22.54706383]
 [ 24.72397232]
 [ 24.50541496]
 [ 22.49442101]
 [ 23.43162155]
 [ 21.47143555]
 [ 22.61725426]
 [ 32.90537262]
 [ 23.7879467 ]
 [ 22.72689056]]
DEBUG:root:training time = %d0.213073
INFO:root:frame =9897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000383138656616
INFO:root:frame =9898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475168228149
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.921815
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000033
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000363111495972
INFO:root:frame =9901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000418901443481
INFO:root:frame =9902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00074291229248
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root:random_action_porb = 0.921783333333
INFO:root:dqn select action Tensor("ArgMax_105:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00938500000001
INFO:root:action choosen by dqn [4]
INFO:root:frame =9904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162124633789
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 22.52055359]
 [ 22.17769623]
 [ 23.9702549 ]
 [ 23.74554443]
 [ 22.59933472]
 [ 21.39055443]
 [ 22.03521347]
 [ 22.95258713]
 [ 32.78652954]
 [ 23.02018547]
 [ 21.903759  ]
 [ 22.85269165]
 [ 21.90940094]
 [ 25.05282402]
 [ 22.85269165]
 [ 25.05282402]]
DEBUG:root:training time = %d0.216936
INFO:root:frame =9905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000494956970215
INFO:root:frame =9906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.921751666667
DEBUG:root: dqn, choose action rondomly, need time 0.000564999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =9909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000774145126343
INFO:root:frame =9910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame = 9911 State into memory, numbers recorded 257 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000491142272949
INFO:root:random_action_porb = 0.92172
DEBUG:root: dqn, choose action rondomly, need time 0.000490000000013
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9912current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 23.39942741]
 [ 22.55242729]
 [ 22.74326134]
 [ 34.78373337]
 [ 21.26821709]
 [ 22.34919357]
 [ 21.93354988]
 [ 23.45408058]
 [ 23.99035454]
 [ 22.148386  ]
 [ 21.98510361]
 [ 22.58591652]
 [ 25.56066513]
 [ 23.92194366]
 [ 13.98547268]
 [ 24.95172882]]
DEBUG:root:training time = %d0.219884
INFO:root:frame =9913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =9914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000361919403076
DEBUG:root: save sample needs time = 0.000156879425049
INFO:root:random_action_porb = 0.921688333333
DEBUG:root: dqn, choose action rondomly, need time 0.000202999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:frame =9917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =9918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000602960586548
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.921656666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 23.10738754]
 [ 32.42085648]
 [ 21.60541725]
 [ 23.28420258]
 [ 24.91546249]
 [ 22.53721237]
 [ 23.10738754]
 [ 23.93142319]
 [ 33.51854324]
 [ 21.77348137]
 [ 22.16584015]
 [ 21.59371758]
 [ 20.95922852]
 [ 21.74565125]
 [ 21.86585617]
 [ 22.92956543]]
DEBUG:root:training time = %d0.235199
INFO:root:frame =9921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258207321167
INFO:root:frame =9922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319957733154
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:random_action_porb = 0.921625
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =9925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444173812866
INFO:root:frame =9926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame = 9927 State into memory, numbers recorded 258 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000582933425903
INFO:root:random_action_porb = 0.921593333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9928current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 24.43951797]
 [ 32.2685585 ]
 [ 24.6605072 ]
 [ 24.29918671]
 [ 20.95126534]
 [ 22.0024929 ]
 [ 24.69021988]
 [ 32.3343811 ]
 [ 24.67399788]
 [ 22.89742851]
 [ 24.23003578]
 [ 22.2089653 ]
 [ 24.03783607]
 [ 15.80777073]
 [ 22.35510826]
 [ 20.35684586]]
DEBUG:root:training time = %d0.217412
INFO:root:frame =9929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =9930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.921561666667
DEBUG:root: dqn, choose action rondomly, need time 0.000419000000022
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000465154647827
INFO:root:frame =9933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =9934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.92153
DEBUG:root: dqn, choose action rondomly, need time 0.000290999999947
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 24.11263084]
 [ 34.74154282]
 [ 34.38701248]
 [ 23.77484894]
 [ 22.88757133]
 [ 22.72434616]
 [ 23.71068573]
 [ 21.93383408]
 [ 21.2125206 ]
 [ 22.04130363]
 [ 22.4975338 ]
 [ 25.1751709 ]
 [ 21.74806976]
 [ 23.70615387]
 [ 24.19932556]
 [ 22.77725792]]
DEBUG:root:training time = %d0.232774
INFO:root:frame =9937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root:frame =9938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000365018844604
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.921498333333
INFO:root:dqn select action Tensor("ArgMax_106:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01145
INFO:root:action choosen by dqn [4]
INFO:root:frame =9940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000187158584595
INFO:root:frame =9941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =9942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255107879639
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:random_action_porb = 0.921466666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:training error  = [[ 23.02933693]
 [ 21.78359413]
 [ 23.69879913]
 [ 24.50473595]
 [ 22.389534  ]
 [ 24.04284859]
 [ 22.04595947]
 [ 22.23831367]
 [ 23.25233269]
 [ 23.33230782]
 [ 22.3383007 ]
 [ 23.77864456]
 [ 23.45718384]
 [ 23.03263283]
 [ 21.67064667]
 [ 23.92978096]]
DEBUG:root:training time = %d0.216476
INFO:root:frame =9945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =9946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.921435
DEBUG:root: dqn, choose action rondomly, need time 0.000349000000028
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000346899032593
INFO:root:frame =9949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000494956970215
INFO:root:frame =9950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487089157104
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.921403333333
INFO:root:dqn select action Tensor("ArgMax_107:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014461
INFO:root:action choosen by dqn [4]
INFO:root:frame =9952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14.29179382]
 [ 21.49420929]
 [ 23.58283806]
 [ 32.78871155]
 [ 23.28361511]
 [ 22.62451172]
 [ 22.66314125]
 [ 23.15303421]
 [ 24.69552803]
 [ 23.12675667]
 [ 22.91656303]
 [ 23.08722115]
 [ 21.28623581]
 [ 22.43352699]
 [ 24.88401604]
 [ 22.6210289 ]]
DEBUG:root:training time = %d0.217794
INFO:root:frame =9953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =9954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00034499168396
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.921371666667
DEBUG:root: dqn, choose action rondomly, need time 0.000351999999964
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =9957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =9958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000498056411743
DEBUG:root: save sample needs time = 0.000260829925537
INFO:root:random_action_porb = 0.92134
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000279188156128
INFO:root:training error  = [[ 23.71402931]
 [ 22.17151642]
 [ 21.59215736]
 [ 24.48215675]
 [ 21.0858593 ]
 [ 21.0858593 ]
 [ 21.98145485]
 [ 24.27587509]
 [ 21.92997551]
 [ 22.15600014]
 [ 24.49975014]
 [ 24.74294281]
 [ 22.41430664]
 [ 22.13682747]
 [ 22.47220802]
 [ 22.41430664]]
DEBUG:root:training time = %d0.22162
INFO:root:frame =9961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =9962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000334978103638
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:random_action_porb = 0.921308333333
DEBUG:root: dqn, choose action rondomly, need time 0.000325000000032
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =9965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000480175018311
INFO:root:frame =9966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.921276666667
DEBUG:root: dqn, choose action rondomly, need time 0.000337000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 23.57253838]
 [ 23.76964188]
 [ 24.39194107]
 [ 22.71016312]
 [ 23.47470284]
 [ 24.67513466]
 [ 22.33584976]
 [ 23.45245361]
 [ 23.62687302]
 [ 24.9739151 ]
 [ 23.04303169]
 [ 23.53528976]
 [ 14.39888382]
 [ 24.49151993]
 [ 23.88964081]
 [ 23.3882103 ]]
DEBUG:root:training time = %d0.207701
INFO:root:frame =9969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =9970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.921245
DEBUG:root: dqn, choose action rondomly, need time 0.000617999999974
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =9972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =9973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =9974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:random_action_porb = 0.921213333333
DEBUG:root: dqn, choose action rondomly, need time 0.000540000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =9976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 22.41748619]
 [ 23.30239296]
 [ 38.09430313]
 [ 21.64444351]
 [ 24.16113472]
 [ 24.62649727]
 [ 23.55757713]
 [ 22.21227264]
 [ 22.09671402]
 [ 21.82106972]
 [ 22.73482132]
 [ 23.92045212]
 [ 23.60114479]
 [ 24.31137276]
 [ 24.83304405]
 [ 22.95317268]]
DEBUG:root:training time = %d0.213937
INFO:root:frame =9977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =9978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298976898193
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.921181666667
DEBUG:root: dqn, choose action rondomly, need time 0.000389999999982
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =9981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000496864318848
INFO:root:frame =9982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.92115
DEBUG:root: dqn, choose action rondomly, need time 0.000332999999955
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 34.41413116]
 [ 35.52977371]
 [ 23.70370102]
 [ 13.89921188]
 [ 23.66805649]
 [ 22.81783867]
 [ 23.39891052]
 [ 22.92708206]
 [ 22.83278275]
 [ 24.80552483]
 [ 23.66805649]
 [ 22.30550003]
 [ 22.80632401]
 [ 22.41141701]
 [ 23.53543854]
 [ 25.02136612]]
DEBUG:root:training time = %d0.228707
INFO:root:frame =9985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =9986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.921118333333
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =9988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root:frame =9989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000504016876221
INFO:root:frame =9990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.921086666667
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =9992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 22.76240349]
 [ 23.7157383 ]
 [ 22.28237343]
 [ 23.60373878]
 [ 22.28237343]
 [ 23.90120125]
 [ 22.78184509]
 [ 23.21393967]
 [ 23.79702568]
 [ 22.20910835]
 [ 34.12971115]
 [ 23.06464577]
 [ 34.271595  ]
 [ 33.36447906]
 [ 22.37394142]
 [ 23.27728271]]
DEBUG:root:training time = %d0.230641
INFO:root:frame =9993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =9994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240087509155
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.921055
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =9996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =9997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =9998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000202894210815
DEBUG:root:one frame running time = 0.00622700000002
DEBUG:root:total training time = 285.531022
INFO:root:frame num = 10000 frame round: 0
INFO:root:random_action_porb = 0.921023333333
DEBUG:root: dqn, choose action rondomly, need time 0.000217999999961
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 23.01689148]
 [ 24.29008484]
 [ 24.79861069]
 [ 24.84619904]
 [ 22.2677536 ]
 [ 23.26889038]
 [ 23.73625183]
 [ 25.45339203]
 [ 23.15685272]
 [ 25.51293373]
 [ 23.22026253]
 [ 23.89001274]
 [ 33.56962585]
 [ 25.57493782]
 [ 33.16057587]
 [ 22.90012932]]
DEBUG:root:training time = %d0.22731
INFO:root:frame =10001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224828720093
INFO:root:frame =10002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:frame = 10003 State into memory, numbers recorded 259 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:random_action_porb = 0.920991666667
DEBUG:root: dqn, choose action rondomly, need time 0.000253999999984
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10004current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =10005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =10006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.92096
INFO:root:dqn select action Tensor("ArgMax_108:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00856000000005
INFO:root:action choosen by dqn [4]
INFO:root:frame =10008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162124633789
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 22.45261002]
 [ 23.64311981]
 [ 34.75224304]
 [ 25.49251366]
 [ 26.11787605]
 [ 22.87326622]
 [ 24.51727676]
 [ 21.82962418]
 [ 22.25385857]
 [ 21.82962418]
 [ 23.83269501]
 [ 24.51871109]
 [ 23.74331474]
 [ 23.50716782]
 [ 25.49251366]
 [ 23.35906982]]
DEBUG:root:training time = %d0.231722
INFO:root:frame =10009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =10010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.920928333333
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =10013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =10014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:random_action_porb = 0.920896666667
DEBUG:root: dqn, choose action rondomly, need time 0.000211999999976
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 22.27084923]
 [ 25.04106331]
 [ 22.69765854]
 [ 24.2192955 ]
 [ 24.96461296]
 [ 22.95368385]
 [ 24.67293739]
 [ 22.32099724]
 [ 23.49903107]
 [ 24.09292984]
 [ 35.80863571]
 [ 23.49548149]
 [ 33.92969894]
 [ 22.87947083]
 [ 23.44410515]
 [ 24.79192352]]
DEBUG:root:training time = %d0.221634
INFO:root:frame =10017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame =10018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000669002532959
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:random_action_porb = 0.920865
DEBUG:root: dqn, choose action rondomly, need time 0.000335000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =10021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000494956970215
INFO:root:frame =10022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000364065170288
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.920833333333
INFO:root:dqn select action Tensor("ArgMax_109:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00938600000001
INFO:root:action choosen by dqn [4]
INFO:root:frame =10024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 23.96465302]
 [ 23.41470909]
 [ 23.51604652]
 [ 23.22276306]
 [ 24.92665863]
 [ 22.80457497]
 [ 22.61195755]
 [ 22.99464226]
 [ 23.13688469]
 [ 23.74457741]
 [ 24.328228  ]
 [ 25.04885101]
 [ 37.39189148]
 [ 23.67741013]
 [ 21.85964775]
 [ 23.39964867]]
DEBUG:root:training time = %d0.220473
INFO:root:frame =10025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =10026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000244855880737
DEBUG:root: save sample needs time = 0.00011682510376
INFO:root:random_action_porb = 0.920801666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root:frame =10029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491857528687
INFO:root:frame =10030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.92077
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000046
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:training error  = [[ 23.90291786]
 [ 25.66004562]
 [ 24.16240883]
 [ 23.96487617]
 [ 23.6342907 ]
 [ 23.73773766]
 [ 25.97762108]
 [ 25.23147583]
 [ 24.62233353]
 [ 25.00740051]
 [ 23.96487617]
 [ 26.88261795]
 [ 25.55449295]
 [ 25.00740051]
 [ 25.18252182]
 [ 26.86988068]]
DEBUG:root:training time = %d0.23114
INFO:root:frame =10033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =10034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000280141830444
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root:random_action_porb = 0.920738333333
DEBUG:root: dqn, choose action rondomly, need time 0.000339999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =10037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000588893890381
INFO:root:frame =10038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000492095947266
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.920706666667
DEBUG:root: dqn, choose action rondomly, need time 0.000337000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 23.70793533]
 [ 24.41402817]
 [ 25.05503845]
 [ 24.21418953]
 [ 23.36423302]
 [ 25.67434883]
 [ 24.65565872]
 [ 22.18854713]
 [ 22.10941124]
 [ 23.43996811]
 [ 23.01623154]
 [ 23.81541634]
 [ 24.21418953]
 [ 33.56980133]
 [ 25.08437538]
 [ 14.89041805]]
DEBUG:root:training time = %d0.220163
INFO:root:frame =10041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000374794006348
INFO:root:frame =10042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000282049179077
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.920675
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root:frame =10045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =10046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.920643333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 24.14913559]
 [ 23.88591194]
 [ 25.37316322]
 [ 24.50043106]
 [ 23.65595627]
 [ 24.26880836]
 [ 24.2598629 ]
 [ 24.42926025]
 [ 24.40023232]
 [ 24.06814575]
 [ 22.91488266]
 [ 25.49336243]
 [ 24.64353752]
 [ 16.04244804]
 [ 22.92087173]
 [ 23.07153511]]
DEBUG:root:training time = %d0.225165
INFO:root:frame =10049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =10050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.920611666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =10053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =10054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
INFO:root:frame = 10055 State into memory, numbers recorded 260 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000560998916626
INFO:root:random_action_porb = 0.92058
INFO:root:dqn select action Tensor("ArgMax_110:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013722
INFO:root:action choosen by dqn [4]
INFO:root:frame =10056current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 22.3227272 ]
 [ 24.40053368]
 [ 25.07948494]
 [ 25.24044418]
 [ 23.33120155]
 [ 25.25117683]
 [ 15.96711922]
 [ 25.12895012]
 [ 26.23865318]
 [ 24.09015846]
 [ 23.75551033]
 [ 22.22658539]
 [ 24.1089592 ]
 [ 23.95120811]
 [ 25.42145348]
 [ 23.9079895 ]]
DEBUG:root:training time = %d0.224536
INFO:root:frame =10057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =10058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000566959381104
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:random_action_porb = 0.920548333333
DEBUG:root: dqn, choose action rondomly, need time 0.000275999999985
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =10061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =10062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:random_action_porb = 0.920516666667
DEBUG:root: dqn, choose action rondomly, need time 0.00037199999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000563859939575
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 22.77368927]
 [ 15.26773071]
 [ 24.50284767]
 [ 23.40725327]
 [ 21.97337151]
 [ 23.94067955]
 [ 23.38525772]
 [ 24.98009109]
 [ 22.64679909]
 [ 25.06397438]
 [ 23.69894791]
 [ 25.27894211]
 [ 22.39523888]
 [ 24.08783722]
 [ 24.74461365]
 [ 25.33643532]]
DEBUG:root:training time = %d0.201741
INFO:root:frame =10065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:frame =10066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.920485
DEBUG:root: dqn, choose action rondomly, need time 0.000325999999973
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000396013259888
INFO:root:frame =10069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =10070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.920453333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000043
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 23.20563316]
 [ 24.2933197 ]
 [ 22.8044281 ]
 [ 25.20212746]
 [ 24.61135483]
 [ 23.59121132]
 [ 24.23717117]
 [ 25.53814316]
 [ 34.83090591]
 [ 24.36135483]
 [ 24.04247475]
 [ 23.59121132]
 [ 25.20856285]
 [ 24.17868805]
 [ 34.28642654]
 [ 23.55935478]]
DEBUG:root:training time = %d0.217985
INFO:root:frame =10073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000378847122192
INFO:root:frame =10074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000101804733276
INFO:root:random_action_porb = 0.920421666667
DEBUG:root: dqn, choose action rondomly, need time 0.000275999999985
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =10077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =10078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000574111938477
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root:random_action_porb = 0.92039
DEBUG:root: dqn, choose action rondomly, need time 0.000452999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 15.64988613]
 [ 24.9388504 ]
 [ 28.0796814 ]
 [ 24.76875687]
 [ 24.9388504 ]
 [ 25.79146004]
 [ 23.48645782]
 [ 27.1358242 ]
 [ 24.73429108]
 [ 15.64988613]
 [ 23.28420258]
 [ 23.64764595]
 [ 23.42829704]
 [ 24.76875687]
 [ 23.64838791]
 [ 23.65744209]]
DEBUG:root:training time = %d0.21605
INFO:root:frame =10081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =10082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000357151031494
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.920358333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =10085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =10086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.920326666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326156616211
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 35.07574081]
 [ 28.55566406]
 [ 24.43423653]
 [ 23.41101837]
 [ 25.47002411]
 [ 36.33963394]
 [ 23.3910141 ]
 [ 26.21888161]
 [ 24.26775551]
 [ 23.76041794]
 [ 25.08429909]
 [ 24.32010078]
 [ 26.2104435 ]
 [ 23.56194687]
 [ 25.39538002]
 [ 24.32868004]]
DEBUG:root:training time = %d0.225969
INFO:root:frame =10089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:frame =10090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
DEBUG:root: save sample needs time = 9.51290130615e-05
INFO:root:random_action_porb = 0.920295
INFO:root:dqn select action Tensor("ArgMax_111:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.006822
INFO:root:action choosen by dqn [4]
INFO:root:frame =10092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000379085540771
INFO:root:frame =10093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000516891479492
INFO:root:frame =10094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234127044678
DEBUG:root: save sample needs time = 0.000126123428345
INFO:root:random_action_porb = 0.920263333333
DEBUG:root: dqn, choose action rondomly, need time 0.000235999999973
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 24.42322731]
 [ 24.93001175]
 [ 25.07291412]
 [ 35.85128784]
 [ 16.30583   ]
 [ 26.25733566]
 [ 24.70834541]
 [ 24.7858448 ]
 [ 25.29712677]
 [ 23.6722126 ]
 [ 25.73647118]
 [ 22.81288147]
 [ 27.4914093 ]
 [ 16.97756577]
 [ 25.83479691]
 [ 22.60354233]]
DEBUG:root:training time = %d0.198924
INFO:root:frame =10097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root:frame =10098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.920231666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =10101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =10102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488042831421
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9202
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:training error  = [[ 24.39088631]
 [ 23.28206825]
 [ 23.28331947]
 [ 23.8522892 ]
 [ 23.32294846]
 [ 24.40377426]
 [ 23.68543053]
 [ 27.95780182]
 [ 24.63043404]
 [ 23.27058411]
 [ 27.3551693 ]
 [ 24.84452629]
 [ 25.34649849]
 [ 22.86918068]
 [ 24.48283577]
 [ 23.8522892 ]]
DEBUG:root:training time = %d0.239716
INFO:root:frame =10105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =10106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002601146698
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.920168333333
DEBUG:root: dqn, choose action rondomly, need time 0.000188000000037
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root:frame =10109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275850296021
INFO:root:frame =10110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000334978103638
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.920136666667
DEBUG:root: dqn, choose action rondomly, need time 0.000168000000031
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 36.04075241]
 [ 26.29096794]
 [ 25.24527359]
 [ 26.80498314]
 [ 23.27558899]
 [ 25.06527328]
 [ 25.70806885]
 [ 23.75335312]
 [ 26.16070557]
 [ 35.84288406]
 [ 23.56772423]
 [ 23.97981834]
 [ 24.70766258]
 [ 37.28336334]
 [ 26.06090355]
 [ 25.04701996]]
DEBUG:root:training time = %d0.217037
INFO:root:frame =10113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =10114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000385999679565
DEBUG:root: save sample needs time = 0.000152826309204
INFO:root:random_action_porb = 0.920105
DEBUG:root: dqn, choose action rondomly, need time 0.000359000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =10117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame =10118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 9.51290130615e-05
INFO:root:random_action_porb = 0.920073333333
INFO:root:dqn select action Tensor("ArgMax_112:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.0121
INFO:root:action choosen by dqn [4]
INFO:root:frame =10120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 27.09251976]
 [ 24.90563774]
 [ 22.87895966]
 [ 23.5668354 ]
 [ 24.67460442]
 [ 27.69186592]
 [ 23.49518585]
 [ 25.37493134]
 [ 24.33267021]
 [ 23.72844696]
 [ 25.93253326]
 [ 23.27978516]
 [ 35.37604904]
 [ 23.87517357]
 [ 25.13109207]
 [ 27.86243629]]
DEBUG:root:training time = %d0.226535
INFO:root:frame =10121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =10122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000514030456543
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.920041666667
DEBUG:root: dqn, choose action rondomly, need time 0.000323999999978
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =10125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000511169433594
INFO:root:frame =10126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:random_action_porb = 0.92001
DEBUG:root: dqn, choose action rondomly, need time 0.00032600000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:training error  = [[ 26.2883873 ]
 [ 25.9969902 ]
 [ 24.67627144]
 [ 24.51455688]
 [ 23.80863953]
 [ 24.94890976]
 [ 23.76807976]
 [ 24.32115364]
 [ 24.4595108 ]
 [ 26.76115608]
 [ 25.26428986]
 [ 24.06604958]
 [ 26.56024933]
 [ 25.32176781]
 [ 26.6051712 ]
 [ 28.39013481]]
DEBUG:root:training time = %d0.210092
INFO:root:frame =10129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =10130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.919978333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000041
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =10133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255823135376
INFO:root:frame =10134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.919946666667
DEBUG:root: dqn, choose action rondomly, need time 0.00032600000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 25.76674652]
 [ 26.12739182]
 [ 23.72718239]
 [ 24.02669144]
 [ 23.76688957]
 [ 26.06074715]
 [ 24.07503319]
 [ 23.67406845]
 [ 23.4680481 ]
 [ 23.96502495]
 [ 24.43114471]
 [ 38.28203964]
 [ 37.74954605]
 [ 23.86168098]
 [ 21.96493149]
 [ 24.36655235]]
DEBUG:root:training time = %d0.215261
INFO:root:frame =10137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =10138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265836715698
INFO:root:frame = 10139 State into memory, numbers recorded 261 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:random_action_porb = 0.919915
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10140current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =10141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =10142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000624895095825
DEBUG:root: save sample needs time = 0.000199794769287
INFO:root:random_action_porb = 0.919883333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000048
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 24.9962616 ]
 [ 26.34999275]
 [ 36.57152557]
 [ 23.13879204]
 [ 25.484272  ]
 [ 34.69119263]
 [ 24.93031502]
 [ 25.01365852]
 [ 27.79916573]
 [ 27.39908028]
 [ 25.96961212]
 [ 36.74789429]
 [ 24.02684021]
 [ 28.50456238]
 [ 23.53306961]
 [ 27.79916573]]
DEBUG:root:training time = %d0.229446
INFO:root:frame =10145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =10146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.919851666667
INFO:root:dqn select action Tensor("ArgMax_113:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010669
INFO:root:action choosen by dqn [4]
INFO:root:frame =10148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000411033630371
INFO:root:frame =10149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000385046005249
INFO:root:frame =10150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.91982
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 27.1622982 ]
 [ 24.47166252]
 [ 17.19750786]
 [ 23.69285583]
 [ 35.71857071]
 [ 25.89066887]
 [ 25.12160683]
 [ 26.17826843]
 [ 34.73965073]
 [ 25.34864998]
 [ 40.92594528]
 [ 26.22028732]
 [ 26.44289207]
 [ 24.28249168]
 [ 25.50823402]
 [ 26.14728355]]
DEBUG:root:training time = %d0.222877
INFO:root:frame =10153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290155410767
INFO:root:frame =10154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274896621704
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.919788333333
DEBUG:root: dqn, choose action rondomly, need time 0.00027
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =10157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =10158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044322013855
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.919756666667
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000026
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 27.47181129]
 [ 23.96480179]
 [ 25.00968933]
 [ 24.6568718 ]
 [ 24.83889961]
 [ 24.89018059]
 [ 26.27563477]
 [ 24.88074303]
 [ 25.88818359]
 [ 24.65308189]
 [ 24.28594971]
 [ 24.55423546]
 [ 34.43463135]
 [ 25.44815826]
 [ 24.32695007]
 [ 17.38812065]]
DEBUG:root:training time = %d0.226747
INFO:root:frame =10161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =10162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.919725
INFO:root:dqn select action Tensor("ArgMax_114:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00908399999997
INFO:root:action choosen by dqn [4]
INFO:root:frame =10164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000380992889404
INFO:root:frame =10165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =10166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.919693333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 27.50317192]
 [ 26.36346817]
 [ 24.6978035 ]
 [ 35.44060516]
 [ 26.91736031]
 [ 27.09117126]
 [ 24.27407074]
 [ 24.29798317]
 [ 23.90366364]
 [ 26.31514931]
 [ 25.87995529]
 [ 38.72648239]
 [ 24.12881851]
 [ 40.04700089]
 [ 27.03647804]
 [ 25.42183876]]
DEBUG:root:training time = %d0.227793
INFO:root:frame =10169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:frame =10170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 9.20295715332e-05
INFO:root:random_action_porb = 0.919661666667
DEBUG:root: dqn, choose action rondomly, need time 0.00017200000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000131845474243
INFO:root:frame =10173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =10174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.91963
DEBUG:root: dqn, choose action rondomly, need time 0.000589999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 27.01402855]
 [ 23.97481155]
 [ 24.10776138]
 [ 25.80889893]
 [ 25.45547104]
 [ 25.80975151]
 [ 25.18864822]
 [ 36.718853  ]
 [ 25.82983398]
 [ 35.93896103]
 [ 24.96949196]
 [ 25.07520676]
 [ 25.15993881]
 [ 24.55030441]
 [ 23.29127312]
 [ 27.33881187]]
DEBUG:root:training time = %d0.209409
INFO:root:frame =10177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =10178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.919598333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =10181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000481843948364
INFO:root:frame =10182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000505924224854
INFO:root:frame = 10183 State into memory, numbers recorded 262 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:random_action_porb = 0.919566666667
DEBUG:root: dqn, choose action rondomly, need time 0.000331000000017
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10184current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 36.25928497]
 [ 24.9726944 ]
 [ 24.02482224]
 [ 24.81608963]
 [ 23.7795372 ]
 [ 24.69803047]
 [ 37.4024353 ]
 [ 24.75607491]
 [ 25.31263161]
 [ 22.50954819]
 [ 25.17831039]
 [ 34.7722168 ]
 [ 24.77900887]
 [ 26.09004402]
 [ 23.33179283]
 [ 23.98863602]]
DEBUG:root:training time = %d0.228168
INFO:root:frame =10185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =10186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:random_action_porb = 0.919535
DEBUG:root: dqn, choose action rondomly, need time 0.000333000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =10189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =10190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.919503333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 25.52511406]
 [ 24.53223801]
 [ 26.08794022]
 [ 23.19975281]
 [ 24.53730202]
 [ 26.81138229]
 [ 23.95225334]
 [ 24.13234138]
 [ 25.85403442]
 [ 24.97970963]
 [ 23.87114716]
 [ 25.19285965]
 [ 24.92383957]
 [ 24.67035866]
 [ 24.59939575]
 [ 36.87843323]]
DEBUG:root:training time = %d0.21862
INFO:root:frame =10193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =10194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277996063232
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.919471666667
DEBUG:root: dqn, choose action rondomly, need time 0.000342000000046
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =10197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =10198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.91944
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 37.25122833]
 [ 25.22772026]
 [ 24.74347496]
 [ 27.18663788]
 [ 26.79289818]
 [ 26.66612244]
 [ 26.44681549]
 [ 26.00897217]
 [ 25.00068665]
 [ 24.13016701]
 [ 24.98520088]
 [ 25.72230721]
 [ 16.54118347]
 [ 25.05603027]
 [ 24.03843498]
 [ 25.00801086]]
DEBUG:root:training time = %d0.218277
INFO:root:frame =10201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000351905822754
INFO:root:frame =10202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.919408333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =10205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000429153442383
INFO:root:frame =10206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame = 10207 State into memory, numbers recorded 263 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000554084777832
INFO:root:random_action_porb = 0.919376666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10208current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 35.95295715]
 [ 26.57857513]
 [ 36.49718857]
 [ 25.05885696]
 [ 25.21515274]
 [ 24.19219589]
 [ 23.93642426]
 [ 25.2094059 ]
 [ 25.78061295]
 [ 26.53461838]
 [ 25.80417061]
 [ 24.26151657]
 [ 26.33448792]
 [ 27.95973778]
 [ 23.26285553]
 [ 26.4539566 ]]
DEBUG:root:training time = %d0.222467
INFO:root:frame =10209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =10210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000201225280762
INFO:root:random_action_porb = 0.919345
DEBUG:root: dqn, choose action rondomly, need time 0.000317999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331163406372
INFO:root:frame =10213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290155410767
INFO:root:frame =10214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.919313333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 25.23086166]
 [ 23.27161407]
 [ 28.68840027]
 [ 27.8679142 ]
 [ 25.80804634]
 [ 24.76579475]
 [ 24.89368248]
 [ 24.27685165]
 [ 25.10860825]
 [ 26.84117699]
 [ 37.46293259]
 [ 25.08812141]
 [ 22.6288681 ]
 [ 27.8679142 ]
 [ 25.28538704]
 [ 25.24028969]]
DEBUG:root:training time = %d0.218623
INFO:root:frame =10217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =10218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.919281666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =10221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000514984130859
INFO:root:frame =10222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.91925
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000033
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 24.63566017]
 [ 24.77202225]
 [ 24.75964355]
 [ 25.03579521]
 [ 26.793293  ]
 [ 36.75085449]
 [ 24.27279282]
 [ 24.79336739]
 [ 26.28783798]
 [ 24.94105911]
 [ 26.03216743]
 [ 26.35312653]
 [ 26.82971573]
 [ 23.84468842]
 [ 27.17573929]
 [ 24.15190887]]
DEBUG:root:training time = %d0.236138
INFO:root:frame =10225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =10226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame = 10227 State into memory, numbers recorded 264 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:random_action_porb = 0.919218333333
DEBUG:root: dqn, choose action rondomly, need time 0.000216000000023
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10228current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:frame =10229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =10230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000548839569092
DEBUG:root: save sample needs time = 0.000104904174805
INFO:root:random_action_porb = 0.919186666667
DEBUG:root: dqn, choose action rondomly, need time 0.000185999999985
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000348806381226
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 24.55605125]
 [ 26.06503296]
 [ 25.5396862 ]
 [ 28.2130909 ]
 [ 27.65406036]
 [ 36.05541229]
 [ 24.21982193]
 [ 26.8686161 ]
 [ 25.08919144]
 [ 25.18160248]
 [ 25.20388985]
 [ 27.18178558]
 [ 25.74250793]
 [ 24.90091705]
 [ 23.65246964]
 [ 26.91514397]]
DEBUG:root:training time = %d0.186486
INFO:root:frame =10233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =10234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000182151794434
INFO:root:random_action_porb = 0.919155
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000038
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:frame =10237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000397920608521
INFO:root:frame =10238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000580072402954
DEBUG:root: save sample needs time = 0.000131130218506
INFO:root:random_action_porb = 0.919123333333
DEBUG:root: dqn, choose action rondomly, need time 0.000368000000037
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 26.63162231]
 [ 24.47468185]
 [ 27.41345978]
 [ 26.80553627]
 [ 25.80355072]
 [ 25.08598137]
 [ 16.90232849]
 [ 25.37208748]
 [ 27.76755714]
 [ 25.75141335]
 [ 27.87830734]
 [ 25.94900894]
 [ 24.89406395]
 [ 25.24956703]
 [ 27.47397041]
 [ 24.82072639]]
DEBUG:root:training time = %d0.219527
INFO:root:frame =10241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000400066375732
INFO:root:frame =10242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000401973724365
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:random_action_porb = 0.919091666667
DEBUG:root: dqn, choose action rondomly, need time 0.000214999999969
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =10245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000405788421631
INFO:root:frame =10246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame = 10247 State into memory, numbers recorded 265 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000687122344971
INFO:root:random_action_porb = 0.91906
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10248current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 26.80047989]
 [ 37.24834061]
 [ 25.9063549 ]
 [ 24.71289635]
 [ 26.55537415]
 [ 24.71289635]
 [ 25.31224823]
 [ 23.82688522]
 [ 24.01958656]
 [ 26.71310616]
 [ 26.60493469]
 [ 37.91500854]
 [ 26.84868813]
 [ 36.69897842]
 [ 25.60002327]
 [ 23.58254242]]
DEBUG:root:training time = %d0.21941
INFO:root:frame =10249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =10250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000543117523193
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.919028333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000046
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =10253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =10254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271797180176
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:random_action_porb = 0.918996666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 37.85011292]
 [ 16.94928551]
 [ 26.32845879]
 [ 29.24073982]
 [ 27.33123207]
 [ 25.12535477]
 [ 26.53328323]
 [ 27.26912498]
 [ 23.74264526]
 [ 24.42058754]
 [ 26.17998695]
 [ 24.56557846]
 [ 25.9291153 ]
 [ 24.30708504]
 [ 23.84878731]
 [ 28.04532814]]
DEBUG:root:training time = %d0.236821
INFO:root:frame =10257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =10258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000513076782227
DEBUG:root: save sample needs time = 0.000141143798828
INFO:root:random_action_porb = 0.918965
DEBUG:root: dqn, choose action rondomly, need time 0.000193999999965
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =10261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00036096572876
INFO:root:frame =10262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.918933333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283000000024
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000384092330933
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 26.62209511]
 [ 25.95413971]
 [ 26.9390564 ]
 [ 25.6052742 ]
 [ 25.56892014]
 [ 26.29190636]
 [ 27.76546669]
 [ 27.16261673]
 [ 24.41184044]
 [ 24.87922096]
 [ 25.2635994 ]
 [ 27.33051491]
 [ 41.29576492]
 [ 24.52067566]
 [ 38.52041626]
 [ 24.86225128]]
DEBUG:root:training time = %d0.219999
INFO:root:frame =10265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431776046753
INFO:root:frame =10266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000415802001953
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.918901666667
DEBUG:root: dqn, choose action rondomly, need time 0.000307999999961
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =10269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000516891479492
INFO:root:frame =10270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000310182571411
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.91887
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 38.2457962 ]
 [ 38.15959549]
 [ 23.83694077]
 [ 38.39381027]
 [ 29.89471054]
 [ 40.97564697]
 [ 26.58494759]
 [ 24.90342903]
 [ 26.61335564]
 [ 25.64567184]
 [ 24.32950783]
 [ 26.00321388]
 [ 25.37308502]
 [ 27.52582169]
 [ 36.5336113 ]
 [ 25.46486473]]
DEBUG:root:training time = %d0.227771
INFO:root:frame =10273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270128250122
INFO:root:frame =10274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000368118286133
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.918838333333
INFO:root:dqn select action Tensor("ArgMax_115:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.0128
INFO:root:action choosen by dqn [4]
INFO:root:frame =10276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000466823577881
INFO:root:frame =10277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =10278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.918806666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:training error  = [[ 28.72559929]
 [ 24.90015411]
 [ 26.47687912]
 [ 24.87602425]
 [ 25.04839325]
 [ 27.58782005]
 [ 24.27895737]
 [ 27.02798843]
 [ 25.97777748]
 [ 28.72052956]
 [ 27.33290863]
 [ 25.3737011 ]
 [ 25.33328819]
 [ 25.27004242]
 [ 26.06690216]
 [ 26.03660583]]
DEBUG:root:training time = %d0.215567
INFO:root:frame =10281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =10282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000237226486206
INFO:root:random_action_porb = 0.918775
DEBUG:root: dqn, choose action rondomly, need time 0.000220000000013
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000290155410767
INFO:root:frame =10285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =10286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.918743333333
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 27.4126606 ]
 [ 38.52439499]
 [ 25.24711418]
 [ 26.140028  ]
 [ 27.1844902 ]
 [ 24.52868652]
 [ 26.08115959]
 [ 25.76914787]
 [ 17.24740791]
 [ 24.52868652]
 [ 25.20005989]
 [ 24.52868652]
 [ 26.4502697 ]
 [ 26.45913696]
 [ 25.87436676]
 [ 25.8560524 ]]
DEBUG:root:training time = %d0.220225
INFO:root:frame =10289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00036883354187
INFO:root:frame =10290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:frame = 10291 State into memory, numbers recorded 266 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:random_action_porb = 0.918711666667
DEBUG:root: dqn, choose action rondomly, need time 0.000175000000013
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10292current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:frame =10293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =10294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000131845474243
INFO:root:random_action_porb = 0.91868
DEBUG:root: dqn, choose action rondomly, need time 0.000423000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000720977783203
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 28.33357811]
 [ 28.21341515]
 [ 25.86660576]
 [ 26.77686691]
 [ 27.09387016]
 [ 25.1452446 ]
 [ 37.14810944]
 [ 26.11857796]
 [ 24.46977615]
 [ 24.41493225]
 [ 29.42602348]
 [ 27.24172211]
 [ 27.95392799]
 [ 24.01853943]
 [ 24.1756115 ]
 [ 25.97178841]]
DEBUG:root:training time = %d0.184083
INFO:root:frame =10297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =10298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame = 10299 State into memory, numbers recorded 267 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000497102737427
INFO:root:random_action_porb = 0.918648333333
DEBUG:root: dqn, choose action rondomly, need time 0.000206999999989
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10300current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =10301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:frame =10302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.918616666667
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000405073165894
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 37.94395447]
 [ 28.29176331]
 [ 37.35131454]
 [ 37.35131454]
 [ 28.83348846]
 [ 26.23068047]
 [ 27.75332832]
 [ 24.15430832]
 [ 25.07772827]
 [ 25.10738373]
 [ 25.38730621]
 [ 25.8045578 ]
 [ 25.55426216]
 [ 25.93331146]
 [ 27.75332832]
 [ 25.94877625]]
DEBUG:root:training time = %d0.209156
INFO:root:frame =10305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =10306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000385999679565
DEBUG:root: save sample needs time = 0.000131130218506
INFO:root:random_action_porb = 0.918585
DEBUG:root: dqn, choose action rondomly, need time 0.000206000000048
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:frame =10309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =10310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000320911407471
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:random_action_porb = 0.918553333333
INFO:root:dqn select action Tensor("ArgMax_116:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013482
INFO:root:action choosen by dqn [4]
INFO:root:frame =10312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 25.55464745]
 [ 24.21133614]
 [ 28.94059372]
 [ 24.87351227]
 [ 36.94703674]
 [ 26.96717834]
 [ 26.96717834]
 [ 26.61367226]
 [ 38.76361847]
 [ 25.48411751]
 [ 25.56814766]
 [ 28.22606087]
 [ 19.00055885]
 [ 25.04808807]
 [ 27.56786728]
 [ 28.79802132]]
DEBUG:root:training time = %d0.225738
INFO:root:frame =10313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =10314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000354051589966
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:random_action_porb = 0.918521666667
DEBUG:root: dqn, choose action rondomly, need time 0.000581000000011
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =10317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =10318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.91849
DEBUG:root: dqn, choose action rondomly, need time 0.00036399999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000360012054443
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 24.30761147]
 [ 26.60808182]
 [ 27.7622509 ]
 [ 27.1319294 ]
 [ 26.35148239]
 [ 26.41135979]
 [ 25.57246971]
 [ 27.07417679]
 [ 25.75954437]
 [ 27.18043327]
 [ 25.30933189]
 [ 17.09944153]
 [ 25.95483971]
 [ 25.53413391]
 [ 26.77607727]
 [ 27.14774704]]
DEBUG:root:training time = %d0.205524
INFO:root:frame =10321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =10322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000347852706909
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:random_action_porb = 0.918458333333
DEBUG:root: dqn, choose action rondomly, need time 0.000336000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root:frame =10325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000517845153809
INFO:root:frame =10326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame = 10327 State into memory, numbers recorded 268 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000615835189819
INFO:root:random_action_porb = 0.918426666667
DEBUG:root: dqn, choose action rondomly, need time 0.000417000000027
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10328current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000634908676147
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 25.5164032 ]
 [ 28.57637787]
 [ 26.26499939]
 [ 28.54734802]
 [ 26.62225151]
 [ 26.62225151]
 [ 25.20886993]
 [ 26.00064659]
 [ 24.87472916]
 [ 25.91885948]
 [ 27.99153709]
 [ 24.92536354]
 [ 26.92654419]
 [ 25.83743286]
 [ 27.20366669]
 [ 38.57991409]]
DEBUG:root:training time = %d0.231513
INFO:root:frame =10329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =10330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.918395
DEBUG:root: dqn, choose action rondomly, need time 0.000194000000022
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000173091888428
INFO:root:frame =10333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame =10334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame = 10335 State into memory, numbers recorded 269 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:random_action_porb = 0.918363333333
DEBUG:root: dqn, choose action rondomly, need time 0.00018300000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10336current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 26.31812477]
 [ 26.47099113]
 [ 26.84505081]
 [ 38.29507065]
 [ 26.01045227]
 [ 41.13256454]
 [ 25.07749748]
 [ 27.40411377]
 [ 24.4208889 ]
 [ 25.07749748]
 [ 28.20304298]
 [ 36.89112854]
 [ 27.87137794]
 [ 26.47161865]
 [ 27.00419426]
 [ 25.93261147]]
DEBUG:root:training time = %d0.186963
INFO:root:frame =10337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:frame =10338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.918331666667
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999983
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =10341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000378847122192
INFO:root:frame =10342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000150918960571
INFO:root:random_action_porb = 0.9183
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000031
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 23.42578697]
 [ 25.38907623]
 [ 28.85750008]
 [ 29.71993256]
 [ 26.59494019]
 [ 27.30595016]
 [ 24.69423866]
 [ 25.39107513]
 [ 17.62030602]
 [ 29.94145012]
 [ 27.87806511]
 [ 27.72078133]
 [ 26.88008499]
 [ 37.45471191]
 [ 26.23802757]
 [ 28.05316734]]
DEBUG:root:training time = %d0.217413
INFO:root:frame =10345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =10346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000573873519897
DEBUG:root: save sample needs time = 0.000104188919067
INFO:root:random_action_porb = 0.918268333333
INFO:root:dqn select action Tensor("ArgMax_117:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015883
INFO:root:action choosen by dqn [4]
INFO:root:frame =10348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016713142395
INFO:root:frame =10349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =10350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423192977905
DEBUG:root: save sample needs time = 0.000351905822754
INFO:root:random_action_porb = 0.918236666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 28.23627663]
 [ 26.62366867]
 [ 16.81067657]
 [ 38.26693726]
 [ 28.18424606]
 [ 24.81487274]
 [ 28.48778152]
 [ 27.16627502]
 [ 26.32501411]
 [ 26.29347229]
 [ 26.88222122]
 [ 26.26867485]
 [ 26.06705856]
 [ 27.92448997]
 [ 25.40522385]
 [ 28.51091576]]
DEBUG:root:training time = %d0.23419
INFO:root:frame =10353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000260829925537
INFO:root:frame =10354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.918205
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999976
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =10357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000497102737427
INFO:root:frame =10358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.918173333333
INFO:root:dqn select action Tensor("ArgMax_118:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014055
INFO:root:action choosen by dqn [4]
INFO:root:frame =10360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00038480758667
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 39.55077362]
 [ 25.59631729]
 [ 26.07430267]
 [ 25.331213  ]
 [ 26.30810547]
 [ 29.06237411]
 [ 26.35437965]
 [ 38.25013733]
 [ 26.36221313]
 [ 29.13744354]
 [ 28.22808838]
 [ 26.07983589]
 [ 26.95909691]
 [ 26.28557014]
 [ 26.92266464]
 [ 27.69981575]]
DEBUG:root:training time = %d0.21048
INFO:root:frame =10361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =10362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249862670898
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.918141666667
DEBUG:root: dqn, choose action rondomly, need time 0.000565000000051
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =10365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =10366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:random_action_porb = 0.91811
DEBUG:root: dqn, choose action rondomly, need time 0.000344999999982
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 25.99387741]
 [ 27.35700607]
 [ 25.71603775]
 [ 26.82900429]
 [ 27.64419174]
 [ 39.56372833]
 [ 25.54400444]
 [ 25.90068436]
 [ 26.37984467]
 [ 29.14666939]
 [ 24.98909187]
 [ 27.87548637]
 [ 29.14666939]
 [ 27.49860954]
 [ 27.36267281]
 [ 26.13292885]]
DEBUG:root:training time = %d0.214955
INFO:root:frame =10369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =10370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.918078333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =10373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =10374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000500917434692
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.918046666667
DEBUG:root: dqn, choose action rondomly, need time 0.000334000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 27.38207054]
 [ 29.12319565]
 [ 28.72192001]
 [ 27.09633255]
 [ 27.71363068]
 [ 26.05132294]
 [ 30.10808372]
 [ 29.75845909]
 [ 25.7632618 ]
 [ 41.14303589]
 [ 28.2242775 ]
 [ 26.20919418]
 [ 29.71028519]
 [ 25.46871376]
 [ 26.92884064]
 [ 27.11460495]]
DEBUG:root:training time = %d0.215384
INFO:root:frame =10377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =10378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.918015
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999976
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =10381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245809555054
INFO:root:frame =10382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.917983333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000038
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[ 27.16707039]
 [ 27.91828156]
 [ 27.32221985]
 [ 28.55753899]
 [ 28.9585743 ]
 [ 29.57818985]
 [ 29.04469109]
 [ 27.95352554]
 [ 27.73765373]
 [ 28.14027596]
 [ 29.11874962]
 [ 26.63492966]
 [ 28.03660202]
 [ 27.86847878]
 [ 26.79558372]
 [ 27.99791527]]
DEBUG:root:training time = %d0.230052
INFO:root:frame =10385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032377243042
INFO:root:frame =10386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.917951666667
INFO:root:dqn select action Tensor("ArgMax_119:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014639
INFO:root:action choosen by dqn [4]
INFO:root:frame =10388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000196218490601
INFO:root:frame =10389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:frame =10390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.91792
INFO:root:dqn select action Tensor("ArgMax_120:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00878699999998
INFO:root:action choosen by dqn [4]
INFO:root:frame =10392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 29.16463089]
 [ 29.41195297]
 [ 27.911026  ]
 [ 40.22554779]
 [ 28.64951134]
 [ 27.04925156]
 [ 25.80936432]
 [ 26.57715797]
 [ 24.42639351]
 [ 25.81727219]
 [ 25.63578224]
 [ 28.28421593]
 [ 26.05116653]
 [ 26.05116653]
 [ 28.42665291]
 [ 28.12586975]]
DEBUG:root:training time = %d0.20607
INFO:root:frame =10393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274181365967
INFO:root:frame =10394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:random_action_porb = 0.917888333333
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =10397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =10398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000156879425049
INFO:root:random_action_porb = 0.917856666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 27.78878975]
 [ 27.44718361]
 [ 26.72359657]
 [ 28.32829857]
 [ 27.52182007]
 [ 27.71676445]
 [ 26.76368141]
 [ 30.8716774 ]
 [ 26.22146034]
 [ 27.59134674]
 [ 27.01720047]
 [ 27.37887764]
 [ 29.37960625]
 [ 29.54624748]
 [ 26.9842968 ]
 [ 38.75297928]]
DEBUG:root:training time = %d0.223065
INFO:root:frame =10401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =10402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.917825
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =10405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000493049621582
INFO:root:frame =10406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.917793333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000033
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:training error  = [[ 27.57628059]
 [ 27.60216713]
 [ 26.91989326]
 [ 26.3890152 ]
 [ 28.09294319]
 [ 26.41716194]
 [ 29.44266319]
 [ 27.08386421]
 [ 26.68669319]
 [ 26.79787445]
 [ 26.67061424]
 [ 30.42464447]
 [ 26.1938858 ]
 [ 27.23893547]
 [ 28.24098015]
 [ 29.19059372]]
DEBUG:root:training time = %d0.208439
INFO:root:frame =10409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =10410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000375032424927
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.917761666667
DEBUG:root: dqn, choose action rondomly, need time 0.000345999999979
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =10413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000525951385498
INFO:root:frame =10414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000146865844727
INFO:root:random_action_porb = 0.91773
DEBUG:root: dqn, choose action rondomly, need time 0.000421000000017
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000386953353882
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 28.0357933 ]
 [ 29.40103149]
 [ 27.28315163]
 [ 26.6739254 ]
 [ 27.95110512]
 [ 25.46440125]
 [ 27.32748413]
 [ 28.55908966]
 [ 38.89883041]
 [ 26.43292809]
 [ 25.98843193]
 [ 25.42391586]
 [ 27.14679337]
 [ 25.41137695]
 [ 29.3966465 ]
 [ 28.1622963 ]]
DEBUG:root:training time = %d0.191699
INFO:root:frame =10417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =10418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000330209732056
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:random_action_porb = 0.917698333333
DEBUG:root: dqn, choose action rondomly, need time 0.000262999999961
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =10421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000416994094849
INFO:root:frame =10422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000368118286133
INFO:root:random_action_porb = 0.917666666667
DEBUG:root: dqn, choose action rondomly, need time 0.000338999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000269174575806
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 25.57061768]
 [ 25.2860775 ]
 [ 27.29048538]
 [ 26.80577278]
 [ 25.99496651]
 [ 28.21471214]
 [ 25.55480194]
 [ 37.13834381]
 [ 26.30113983]
 [ 27.02449799]
 [ 26.61398697]
 [ 27.17041016]
 [ 37.19499588]
 [ 25.57061768]
 [ 27.39213181]
 [ 27.2578125 ]]
DEBUG:root:training time = %d0.205875
INFO:root:frame =10425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =10426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000401973724365
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.917635
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =10429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275850296021
INFO:root:frame =10430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298976898193
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.917603333333
DEBUG:root: dqn, choose action rondomly, need time 0.000378000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:training error  = [[ 26.81462288]
 [ 26.16296959]
 [ 29.25864792]
 [ 26.20560074]
 [ 28.69036293]
 [ 26.65123367]
 [ 28.22127914]
 [ 27.5560112 ]
 [ 27.37855721]
 [ 25.53274536]
 [ 28.40769958]
 [ 27.8880558 ]
 [ 27.31081581]
 [ 28.971632  ]
 [ 26.45254517]
 [ 26.26359177]]
DEBUG:root:training time = %d0.195044
INFO:root:frame =10433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame =10434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00035285949707
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:random_action_porb = 0.917571666667
DEBUG:root: dqn, choose action rondomly, need time 0.000344999999982
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root:frame =10437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =10438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000569105148315
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.91754
INFO:root:dqn select action Tensor("ArgMax_121:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010366
INFO:root:action choosen by dqn [4]
INFO:root:frame =10440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:training error  = [[ 25.79704094]
 [ 28.00300026]
 [ 28.36266136]
 [ 30.23649025]
 [ 27.13860512]
 [ 26.34349251]
 [ 26.885149  ]
 [ 26.83904266]
 [ 28.21406364]
 [ 32.97955322]
 [ 29.23290062]
 [ 27.09553909]
 [ 28.86889458]
 [ 26.40681076]
 [ 30.35987091]
 [ 28.52729607]]
DEBUG:root:training time = %d0.234943
INFO:root:frame =10441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =10442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00034499168396
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.917508333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =10445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =10446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.917476666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 30.23506355]
 [ 38.50460434]
 [ 28.71284294]
 [ 28.7958107 ]
 [ 27.90909195]
 [ 28.61897278]
 [ 25.99162292]
 [ 18.8097496 ]
 [ 27.07258987]
 [ 19.08345604]
 [ 27.66633797]
 [ 27.28793335]
 [ 27.44286728]
 [ 27.47701073]
 [ 27.47701073]
 [ 28.22995186]]
DEBUG:root:training time = %d0.227913
INFO:root:frame =10449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =10450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045919418335
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.917445
DEBUG:root: dqn, choose action rondomly, need time 0.000202000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000379085540771
INFO:root:frame =10453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =10454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
INFO:root:frame = 10455 State into memory, numbers recorded 270 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000569105148315
INFO:root:random_action_porb = 0.917413333333
DEBUG:root: dqn, choose action rondomly, need time 0.000268000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10456current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 28.4793129 ]
 [ 26.69654655]
 [ 27.88660622]
 [ 41.14499283]
 [ 29.5800972 ]
 [ 27.83465767]
 [ 28.85069656]
 [ 26.56567574]
 [ 27.59254837]
 [ 39.71224594]
 [ 26.72446442]
 [ 28.67115784]
 [ 26.33761978]
 [ 28.05235863]
 [ 27.75549889]
 [ 30.12156677]]
DEBUG:root:training time = %d0.210241
INFO:root:frame =10457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =10458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271797180176
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.917381666667
DEBUG:root: dqn, choose action rondomly, need time 0.000190999999973
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:frame =10461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =10462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.0002281665802
INFO:root:random_action_porb = 0.91735
DEBUG:root: dqn, choose action rondomly, need time 0.00018300000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000161170959473
INFO:root:training error  = [[ 28.33991241]
 [ 25.88220596]
 [ 28.48403549]
 [ 27.91836166]
 [ 27.42041016]
 [ 27.89587212]
 [ 27.31831169]
 [ 25.8285141 ]
 [ 29.43107224]
 [ 28.60509872]
 [ 27.28227425]
 [ 29.31075096]
 [ 26.77363014]
 [ 25.68973541]
 [ 27.76988983]
 [ 27.9805584 ]]
DEBUG:root:training time = %d0.206872
INFO:root:frame =10465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000322818756104
INFO:root:frame =10466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000331163406372
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:random_action_porb = 0.917318333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000033
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =10469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =10470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00055980682373
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:random_action_porb = 0.917286666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000022
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 26.59352303]
 [ 26.11460114]
 [ 27.46805191]
 [ 42.17009735]
 [ 26.27086449]
 [ 29.49169731]
 [ 38.83652115]
 [ 30.64572525]
 [ 28.63922119]
 [ 26.44516754]
 [ 27.68327522]
 [ 26.98905182]
 [ 31.97426605]
 [ 30.52471542]
 [ 28.23100662]
 [ 27.36283112]]
DEBUG:root:training time = %d0.23518
INFO:root:frame =10473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =10474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00029993057251
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.917255
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =10477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root:frame =10478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000266790390015
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.917223333333
DEBUG:root: dqn, choose action rondomly, need time 0.000186999999983
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 27.3391304 ]
 [ 25.82929039]
 [ 27.64844322]
 [ 28.26255226]
 [ 29.70388031]
 [ 29.63423157]
 [ 19.28093719]
 [ 25.90720749]
 [ 26.79739952]
 [ 26.27039528]
 [ 27.57571983]
 [ 27.5116539 ]
 [ 27.08124352]
 [ 27.18663788]
 [ 29.39060593]
 [ 28.47499657]]
DEBUG:root:training time = %d0.209525
INFO:root:frame =10481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =10482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000109910964966
INFO:root:random_action_porb = 0.917191666667
INFO:root:dqn select action Tensor("ArgMax_122:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013657
INFO:root:action choosen by dqn [4]
INFO:root:frame =10484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =10485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =10486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000194072723389
INFO:root:random_action_porb = 0.91716
DEBUG:root: dqn, choose action rondomly, need time 0.000256999999976
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 27.46733284]
 [ 43.48770142]
 [ 27.58453369]
 [ 28.06270409]
 [ 39.20998001]
 [ 25.43807411]
 [ 26.44344139]
 [ 27.4668541 ]
 [ 28.24495316]
 [ 29.19669533]
 [ 28.52134705]
 [ 29.00654793]
 [ 27.84101677]
 [ 39.72686386]
 [ 29.18919182]
 [ 18.46398735]]
DEBUG:root:training time = %d0.217948
INFO:root:frame =10489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =10490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.917128333333
DEBUG:root: dqn, choose action rondomly, need time 0.000272000000052
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =10493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =10494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:random_action_porb = 0.917096666667
DEBUG:root: dqn, choose action rondomly, need time 0.000256000000036
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 27.96167374]
 [ 27.00340271]
 [ 30.64428902]
 [ 27.69042206]
 [ 30.8598938 ]
 [ 40.29893875]
 [ 18.3249855 ]
 [ 26.78831673]
 [ 27.99282837]
 [ 28.37574768]
 [ 28.65065384]
 [ 27.59679794]
 [ 31.06204987]
 [ 30.93648338]
 [ 28.47988319]
 [ 28.01228714]]
DEBUG:root:training time = %d0.228542
INFO:root:frame =10497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =10498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.917065
DEBUG:root: dqn, choose action rondomly, need time 0.000193000000024
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000175952911377
INFO:root:frame =10501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =10502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame = 10503 State into memory, numbers recorded 271 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000776052474976
INFO:root:random_action_porb = 0.917033333333
DEBUG:root: dqn, choose action rondomly, need time 0.000473999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10504current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 28.26060677]
 [ 27.94610405]
 [ 26.93881798]
 [ 28.01543808]
 [ 25.50507355]
 [ 30.49462509]
 [ 32.04039001]
 [ 27.42352676]
 [ 28.51947212]
 [ 27.42240906]
 [ 30.31952858]
 [ 30.17040825]
 [ 30.32019997]
 [ 28.9721241 ]
 [ 40.30194092]
 [ 28.03999519]]
DEBUG:root:training time = %d0.205312
INFO:root:frame =10505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =10506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000677108764648
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root:random_action_porb = 0.917001666667
DEBUG:root: dqn, choose action rondomly, need time 0.000263000000018
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =10509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =10510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288963317871
DEBUG:root: save sample needs time = 0.000158786773682
INFO:root:random_action_porb = 0.91697
DEBUG:root: dqn, choose action rondomly, need time 0.000231999999983
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000206232070923
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 28.06925201]
 [ 19.70346069]
 [ 30.49049759]
 [ 27.65454102]
 [ 28.54571724]
 [ 31.06204987]
 [ 31.20474434]
 [ 28.13258743]
 [ 27.9397316 ]
 [ 29.26153564]
 [ 30.16060448]
 [ 30.05477524]
 [ 30.17191696]
 [ 27.9239254 ]
 [ 28.62052536]
 [ 28.97056389]]
DEBUG:root:training time = %d0.202888
INFO:root:frame =10513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =10514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000360012054443
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.916938333333
DEBUG:root: dqn, choose action rondomly, need time 0.000404000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =10517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =10518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509023666382
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:random_action_porb = 0.916906666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 28.03805542]
 [ 29.51573372]
 [ 28.08889961]
 [ 29.78318787]
 [ 39.57121277]
 [ 27.70744705]
 [ 27.41098213]
 [ 27.59206772]
 [ 28.85643387]
 [ 28.16893768]
 [ 27.59206772]
 [ 26.94364929]
 [ 28.8539753 ]
 [ 40.28266907]
 [ 28.45627213]
 [ 30.35054016]]
DEBUG:root:training time = %d0.21924
INFO:root:frame =10521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =10522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000243902206421
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.916875
DEBUG:root: dqn, choose action rondomly, need time 0.000724999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000266790390015
INFO:root:frame =10525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000451803207397
INFO:root:frame =10526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480890274048
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:random_action_porb = 0.916843333333
DEBUG:root: dqn, choose action rondomly, need time 0.000511000000017
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 27.60200691]
 [ 30.63710976]
 [ 27.72399521]
 [ 28.61815643]
 [ 31.00883484]
 [ 28.04371262]
 [ 30.08062935]
 [ 42.15860367]
 [ 29.4072361 ]
 [ 27.10205269]
 [ 26.07321167]
 [ 33.21234894]
 [ 28.84250259]
 [ 26.58242989]
 [ 27.04306221]
 [ 26.51332283]]
DEBUG:root:training time = %d0.217648
INFO:root:frame =10529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =10530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000499963760376
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.916811666667
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =10533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =10534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.91678
DEBUG:root: dqn, choose action rondomly, need time 0.000366999999983
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000581026077271
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 28.44382095]
 [ 27.40986443]
 [ 28.67295647]
 [ 28.43657875]
 [ 29.72259521]
 [ 30.2586441 ]
 [ 27.93271446]
 [ 27.87717819]
 [ 40.85988617]
 [ 27.48868942]
 [ 28.90235519]
 [ 18.87432861]
 [ 40.88017654]
 [ 26.56614685]
 [ 28.83537292]
 [ 30.80803871]]
DEBUG:root:training time = %d0.229681
INFO:root:frame =10537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032377243042
INFO:root:frame =10538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000627040863037
DEBUG:root: save sample needs time = 0.000146150588989
INFO:root:random_action_porb = 0.916748333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =10541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =10542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame = 10543 State into memory, numbers recorded 272 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000711917877197
INFO:root:random_action_porb = 0.916716666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303999999971
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10544current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000346899032593
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 30.10867119]
 [ 28.64975548]
 [ 27.65157318]
 [ 28.99463272]
 [ 28.38346863]
 [ 27.32373428]
 [ 28.52509499]
 [ 30.62334442]
 [ 29.77569199]
 [ 28.64975548]
 [ 38.47279739]
 [ 27.82950401]
 [ 29.72367668]
 [ 28.42185211]
 [ 39.80220413]
 [ 41.02743149]]
DEBUG:root:training time = %d0.226689
INFO:root:frame =10545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =10546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.916685
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000033
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =10549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =10550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449180603027
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.916653333333
DEBUG:root: dqn, choose action rondomly, need time 0.000485000000026
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 28.08429146]
 [ 33.20927429]
 [ 27.45597839]
 [ 28.7213459 ]
 [ 31.39742088]
 [ 40.78822708]
 [ 26.61115265]
 [ 29.23620224]
 [ 31.13650513]
 [ 27.7548542 ]
 [ 32.99190903]
 [ 29.16331291]
 [ 31.69996262]
 [ 30.26854897]
 [ 29.37547112]
 [ 28.08930397]]
DEBUG:root:training time = %d0.215869
INFO:root:frame =10553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:frame =10554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.916621666667
INFO:root:dqn select action Tensor("ArgMax_123:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014512
INFO:root:action choosen by dqn [4]
INFO:root:frame =10556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:frame =10557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =10558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000281095504761
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.91659
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000173091888428
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 31.30181885]
 [ 28.83455276]
 [ 29.30926323]
 [ 30.99991417]
 [ 29.21846581]
 [ 28.179142  ]
 [ 29.78901672]
 [ 42.03781891]
 [ 41.98688507]
 [ 30.19145012]
 [ 40.670784  ]
 [ 32.04799271]
 [ 29.66347694]
 [ 28.78197479]
 [ 28.78197479]
 [ 27.89692116]]
DEBUG:root:training time = %d0.23335
INFO:root:frame =10561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =10562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame = 10563 State into memory, numbers recorded 273 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:random_action_porb = 0.916558333333
DEBUG:root: dqn, choose action rondomly, need time 0.000337000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10564current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000342845916748
INFO:root:frame =10565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000496864318848
INFO:root:frame =10566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:random_action_porb = 0.916526666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999964
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 28.91039467]
 [ 27.40315437]
 [ 28.17954826]
 [ 28.00154686]
 [ 28.22419739]
 [ 29.20015717]
 [ 30.83836746]
 [ 32.58239746]
 [ 28.27886009]
 [ 30.48931694]
 [ 29.84625816]
 [ 28.55851746]
 [ 25.66831779]
 [ 40.60969925]
 [ 30.14284134]
 [ 27.05036354]]
DEBUG:root:training time = %d0.20056
INFO:root:frame =10569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =10570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229120254517
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:random_action_porb = 0.916495
DEBUG:root: dqn, choose action rondomly, need time 0.000188000000037
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000146865844727
INFO:root:frame =10573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488996505737
INFO:root:frame =10574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000512838363647
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.916463333333
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 28.63962936]
 [ 40.2738533 ]
 [ 30.5500946 ]
 [ 29.88061333]
 [ 30.13253784]
 [ 30.65856552]
 [ 27.96086693]
 [ 30.65011787]
 [ 26.77978706]
 [ 28.17501259]
 [ 26.3929348 ]
 [ 30.49184418]
 [ 30.49774361]
 [ 30.50035477]
 [ 32.05343628]
 [ 31.64053917]]
DEBUG:root:training time = %d0.212589
INFO:root:frame =10577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =10578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.916431666667
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999966
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =10581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =10582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000492095947266
INFO:root:frame = 10583 State into memory, numbers recorded 274 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000545024871826
INFO:root:random_action_porb = 0.9164
DEBUG:root: dqn, choose action rondomly, need time 0.000303999999971
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10584current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 33.36236191]
 [ 27.93569946]
 [ 29.37150002]
 [ 29.18803787]
 [ 27.93569946]
 [ 18.66813278]
 [ 31.53437042]
 [ 31.02200699]
 [ 29.02002716]
 [ 28.77567101]
 [ 27.75075531]
 [ 26.95798683]
 [ 32.6232605 ]
 [ 31.2497654 ]
 [ 32.20410156]
 [ 27.75654221]]
DEBUG:root:training time = %d0.229905
INFO:root:frame =10585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =10586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494003295898
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.916368333333
INFO:root:dqn select action Tensor("ArgMax_124:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01102
INFO:root:action choosen by dqn [4]
INFO:root:frame =10588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =10589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000372171401978
INFO:root:frame =10590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.916336666667
DEBUG:root: dqn, choose action rondomly, need time 0.000497999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 30.39241791]
 [ 29.07915878]
 [ 27.90731812]
 [ 30.1818924 ]
 [ 28.57099533]
 [ 30.34843826]
 [ 29.14716339]
 [ 27.87097549]
 [ 27.25805092]
 [ 27.86743164]
 [ 30.18239594]
 [ 41.68960571]
 [ 29.39176559]
 [ 28.79351807]
 [ 30.70615196]
 [ 29.29629517]]
DEBUG:root:training time = %d0.2239
INFO:root:frame =10593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root:frame =10594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame = 10595 State into memory, numbers recorded 275 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000389099121094
INFO:root:random_action_porb = 0.916305
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10596current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000187158584595
INFO:root:frame =10597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000497817993164
INFO:root:frame =10598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045919418335
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:random_action_porb = 0.916273333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:training error  = [[ 30.12876892]
 [ 26.86719131]
 [ 28.86586189]
 [ 30.77366257]
 [ 33.54346085]
 [ 30.55566216]
 [ 30.32566261]
 [ 27.89256859]
 [ 29.39920998]
 [ 28.759058  ]
 [ 27.96546745]
 [ 31.00637054]
 [ 29.41534615]
 [ 30.78974724]
 [ 29.4059124 ]
 [ 29.12558365]]
DEBUG:root:training time = %d0.207924
INFO:root:frame =10601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =10602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000306129455566
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.916241666667
DEBUG:root: dqn, choose action rondomly, need time 0.00022800000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000168800354004
INFO:root:frame =10605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =10606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.91621
INFO:root:dqn select action Tensor("ArgMax_125:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01461
INFO:root:action choosen by dqn [4]
INFO:root:frame =10608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000201225280762
INFO:root:training error  = [[ 27.55144691]
 [ 33.5705986 ]
 [ 29.4998188 ]
 [ 30.93987846]
 [ 29.41236687]
 [ 28.08348274]
 [ 28.58290482]
 [ 30.68205833]
 [ 31.83808517]
 [ 26.99856567]
 [ 31.51012611]
 [ 28.61864662]
 [ 28.43039513]
 [ 29.01706696]
 [ 29.26566315]
 [ 30.79110146]]
DEBUG:root:training time = %d0.210742
INFO:root:frame =10609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =10610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame = 10611 State into memory, numbers recorded 276 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00060510635376
INFO:root:random_action_porb = 0.916178333333
DEBUG:root: dqn, choose action rondomly, need time 0.000222000000008
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10612current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.00013279914856
INFO:root:frame =10613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =10614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.916146666667
DEBUG:root: dqn, choose action rondomly, need time 0.000308999999959
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 29.47496223]
 [ 30.03737831]
 [ 31.57799911]
 [ 27.25446701]
 [ 30.60384178]
 [ 32.33108139]
 [ 31.39451408]
 [ 28.4035511 ]
 [ 28.55770302]
 [ 41.88639069]
 [ 30.74996567]
 [ 29.40086555]
 [ 29.49774742]
 [ 44.53152847]
 [ 31.41452408]
 [ 27.91497612]]
DEBUG:root:training time = %d0.216256
INFO:root:frame =10617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =10618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.916115
DEBUG:root: dqn, choose action rondomly, need time 0.000342000000046
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =10621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =10622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488042831421
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.916083333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 29.05447769]
 [ 27.59134674]
 [ 29.91507149]
 [ 35.75113297]
 [ 43.73246002]
 [ 30.96016693]
 [ 30.08481407]
 [ 29.38415527]
 [ 30.37366104]
 [ 20.57456207]
 [ 31.53796959]
 [ 30.99014473]
 [ 29.90597534]
 [ 41.2835083 ]
 [ 31.16333199]
 [ 31.40135384]]
DEBUG:root:training time = %d0.227533
INFO:root:frame =10625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285148620605
INFO:root:frame =10626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000371932983398
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.916051666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =10629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =10630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.91602
DEBUG:root: dqn, choose action rondomly, need time 0.000563
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[ 31.58280182]
 [ 31.35229301]
 [ 28.50439835]
 [ 29.67178917]
 [ 29.21186829]
 [ 29.82842255]
 [ 30.33557892]
 [ 30.1116848 ]
 [ 30.67014313]
 [ 29.00284958]
 [ 29.14123344]
 [ 30.41117859]
 [ 29.67087364]
 [ 28.02408028]
 [ 29.71336174]
 [ 29.76495361]]
DEBUG:root:training time = %d0.230125
INFO:root:frame =10633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =10634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000650882720947
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.915988333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =10637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00040602684021
INFO:root:frame =10638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482082366943
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:random_action_porb = 0.915956666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 29.9432869 ]
 [ 29.45847893]
 [ 42.40108871]
 [ 30.1888504 ]
 [ 28.39281845]
 [ 27.36195374]
 [ 30.91739082]
 [ 30.85896111]
 [ 30.3280983 ]
 [ 28.39281845]
 [ 31.38605118]
 [ 28.99364662]
 [ 28.68962669]
 [ 27.53238678]
 [ 41.45800781]
 [ 28.76994133]]
DEBUG:root:training time = %d0.209446
INFO:root:frame =10641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =10642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame = 10643 State into memory, numbers recorded 277 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:random_action_porb = 0.915925
DEBUG:root: dqn, choose action rondomly, need time 0.000502999999981
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10644current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =10645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00048303604126
INFO:root:frame =10646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482082366943
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.915893333333
DEBUG:root: dqn, choose action rondomly, need time 0.00051000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 30.21518135]
 [ 30.79618263]
 [ 32.36692429]
 [ 32.00792313]
 [ 30.12072945]
 [ 29.99231911]
 [ 28.7936821 ]
 [ 29.5207901 ]
 [ 28.7936821 ]
 [ 32.00792313]
 [ 28.59057426]
 [ 29.03548241]
 [ 28.48419952]
 [ 20.03442001]
 [ 31.61556816]
 [ 30.09309959]]
DEBUG:root:training time = %d0.232747
INFO:root:frame =10649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =10650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264883041382
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:random_action_porb = 0.915861666667
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999966
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =10653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =10654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000381946563721
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:random_action_porb = 0.91583
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999974
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000341892242432
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 43.58989716]
 [ 28.53397942]
 [ 43.43498993]
 [ 29.9317646 ]
 [ 41.74795151]
 [ 26.45952988]
 [ 30.5639286 ]
 [ 20.46687126]
 [ 30.314991  ]
 [ 30.68112946]
 [ 29.12113762]
 [ 29.01813698]
 [ 28.96908569]
 [ 28.20231247]
 [ 42.08343887]
 [ 42.72432327]]
DEBUG:root:training time = %d0.248062
INFO:root:frame =10657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =10658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.915798333333
DEBUG:root: dqn, choose action rondomly, need time 0.000406999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000193119049072
INFO:root:frame =10661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =10662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.915766666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 31.00951576]
 [ 29.2351284 ]
 [ 30.49437332]
 [ 41.07993317]
 [ 29.92992783]
 [ 28.79572868]
 [ 34.91299438]
 [ 20.0270462 ]
 [ 31.63272858]
 [ 30.33852005]
 [ 33.94125748]
 [ 29.88086319]
 [ 27.98104286]
 [ 30.33683968]
 [ 34.52799606]
 [ 29.20444489]]
DEBUG:root:training time = %d0.231089
INFO:root:frame =10665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =10666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000261783599854
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.915735
DEBUG:root: dqn, choose action rondomly, need time 0.000307999999961
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =10669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =10670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:random_action_porb = 0.915703333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 31.78730774]
 [ 33.82836151]
 [ 30.27551842]
 [ 42.64676285]
 [ 28.4321022 ]
 [ 30.57616043]
 [ 31.02702141]
 [ 29.60109711]
 [ 29.50727844]
 [ 29.6056633 ]
 [ 30.28357887]
 [ 30.06347466]
 [ 40.1063118 ]
 [ 29.94888115]
 [ 30.35499573]
 [ 30.6806221 ]]
DEBUG:root:training time = %d0.230501
INFO:root:frame =10673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =10674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.915671666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =10677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =10678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000360012054443
DEBUG:root: save sample needs time = 0.00018310546875
INFO:root:random_action_porb = 0.91564
DEBUG:root: dqn, choose action rondomly, need time 0.000361000000055
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 30.44754219]
 [ 30.4994278 ]
 [ 30.16638565]
 [ 28.84397697]
 [ 28.65571785]
 [ 28.66061974]
 [ 32.16981888]
 [ 28.84996033]
 [ 27.61050606]
 [ 31.38220406]
 [ 43.77021027]
 [ 32.01034164]
 [ 32.57107544]
 [ 27.82926369]
 [ 30.28878593]
 [ 29.04641914]]
DEBUG:root:training time = %d0.216155
INFO:root:frame =10681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000370979309082
INFO:root:frame =10682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.915608333333
DEBUG:root: dqn, choose action rondomly, need time 0.000339999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =10685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000391006469727
INFO:root:frame =10686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247001647949
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:random_action_porb = 0.915576666667
DEBUG:root: dqn, choose action rondomly, need time 0.000225
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:training error  = [[ 32.03054428]
 [ 31.54156876]
 [ 28.53357124]
 [ 31.42324638]
 [ 29.63938141]
 [ 30.45730972]
 [ 30.10038185]
 [ 29.62750435]
 [ 31.51278114]
 [ 31.44634628]
 [ 30.77323914]
 [ 29.79559517]
 [ 30.57953644]
 [ 30.92273521]
 [ 28.75954819]
 [ 30.4101696 ]]
DEBUG:root:training time = %d0.201744
INFO:root:frame =10689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =10690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000338792800903
INFO:root:player has been killed for 7 times 
INFO:root:frame = 10691 State into memory, numbers recorded 278 action = -1, reward = -1
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root:random_action_porb = 0.915545
DEBUG:root: dqn, choose action rondomly, need time 0.000170999999966
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10692current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:frame =10693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000481843948364
INFO:root:frame =10694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.915513333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:training error  = [[ 31.80064392]
 [ 31.29294205]
 [ 31.1944313 ]
 [ 34.55508041]
 [ 28.3416996 ]
 [ 31.572855  ]
 [ 31.52640152]
 [ 30.2197113 ]
 [ 30.89872742]
 [ 29.48548317]
 [ 29.29902077]
 [ 30.96806335]
 [ 30.71012497]
 [ 29.01542473]
 [ 30.47095299]
 [ 30.49538422]]
DEBUG:root:training time = %d0.203297
INFO:root:frame =10697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000378131866455
INFO:root:frame =10698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000365972518921
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.915481666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:frame =10701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =10702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000933170318604
INFO:root:frame = 10703 State into memory, numbers recorded 279 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:random_action_porb = 0.91545
DEBUG:root: dqn, choose action rondomly, need time 0.00027
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10704current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000419855117798
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 28.96226883]
 [ 30.30608749]
 [ 31.49214172]
 [ 33.67066193]
 [ 30.92731857]
 [ 41.97877502]
 [ 32.94766235]
 [ 32.39054108]
 [ 31.17730331]
 [ 43.92884445]
 [ 30.70513725]
 [ 30.39889526]
 [ 32.8980217 ]
 [ 32.04557419]
 [ 29.12163162]
 [ 32.144207  ]]
DEBUG:root:training time = %d0.20978
INFO:root:frame =10705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000531911849976
INFO:root:frame =10706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000675916671753
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:random_action_porb = 0.915418333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =10709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =10710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame = 10711 State into memory, numbers recorded 280 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:random_action_porb = 0.915386666667
DEBUG:root: dqn, choose action rondomly, need time 0.000385000000051
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10712current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000280141830444
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 32.80487823]
 [ 30.70530701]
 [ 30.59498024]
 [ 42.39125443]
 [ 33.20127106]
 [ 32.35381699]
 [ 33.45470428]
 [ 32.74390411]
 [ 30.43247223]
 [ 29.17105865]
 [ 34.48085022]
 [ 32.01310349]
 [ 33.70706558]
 [ 32.43580246]
 [ 31.2467804 ]
 [ 30.07828522]]
DEBUG:root:training time = %d0.213712
INFO:root:frame =10713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000370979309082
INFO:root:frame =10714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.915355
DEBUG:root: dqn, choose action rondomly, need time 0.000224000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =10717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000550985336304
INFO:root:frame =10718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000667810440063
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.915323333333
INFO:root:dqn select action Tensor("ArgMax_126:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014264
INFO:root:action choosen by dqn [4]
INFO:root:frame =10720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 29.60881805]
 [ 41.07161713]
 [ 31.99860191]
 [ 29.02882195]
 [ 30.95159149]
 [ 29.54641342]
 [ 30.11922073]
 [ 28.46473885]
 [ 27.05330086]
 [ 28.55166817]
 [ 29.19009972]
 [ 30.71629906]
 [ 30.71097183]
 [ 30.78915405]
 [ 31.53025818]
 [ 30.67521286]]
DEBUG:root:training time = %d0.202781
INFO:root:frame =10721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0003821849823
INFO:root:frame =10722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475168228149
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:random_action_porb = 0.915291666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =10725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466823577881
INFO:root:frame =10726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.91526
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 30.69769669]
 [ 30.16160965]
 [ 34.07544327]
 [ 33.84975433]
 [ 32.19587708]
 [ 40.83570099]
 [ 30.47398567]
 [ 29.08582306]
 [ 29.8341713 ]
 [ 31.64525986]
 [ 33.27921677]
 [ 31.69935989]
 [ 32.44301605]
 [ 30.40184021]
 [ 30.09778786]
 [ 31.7904911 ]]
DEBUG:root:training time = %d0.224479
INFO:root:frame =10729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =10730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
DEBUG:root: save sample needs time = 0.000115871429443
INFO:root:random_action_porb = 0.915228333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000038
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =10733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000336170196533
INFO:root:frame =10734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.915196666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 31.95019722]
 [ 28.57858086]
 [ 31.07378578]
 [ 30.8076992 ]
 [ 31.13344002]
 [ 28.92237473]
 [ 34.79426575]
 [ 30.21543312]
 [ 30.93555069]
 [ 31.44720078]
 [ 32.1384964 ]
 [ 29.01147842]
 [ 32.78678894]
 [ 29.89888191]
 [ 32.1384964 ]
 [ 45.89506531]]
DEBUG:root:training time = %d0.240126
INFO:root:frame =10737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame =10738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264167785645
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:random_action_porb = 0.915165
DEBUG:root: dqn, choose action rondomly, need time 0.000260000000026
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =10741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =10742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319004058838
DEBUG:root: save sample needs time = 0.000105857849121
INFO:root:random_action_porb = 0.915133333333
INFO:root:dqn select action Tensor("ArgMax_127:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.016265
INFO:root:action choosen by dqn [4]
INFO:root:frame =10744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000182151794434
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 34.36053467]
 [ 44.27733231]
 [ 31.79530907]
 [ 31.64843559]
 [ 30.46059227]
 [ 31.69918823]
 [ 33.06451797]
 [ 44.25510025]
 [ 29.66846466]
 [ 43.09875488]
 [ 20.32023621]
 [ 30.464468  ]
 [ 42.50040817]
 [ 30.55861473]
 [ 30.49993515]
 [ 29.74181366]]
DEBUG:root:training time = %d0.216294
INFO:root:frame =10745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =10746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.915101666667
DEBUG:root: dqn, choose action rondomly, need time 0.000583000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: ememy has been killed for 22 times 
INFO:root:enemies_left [0]
INFO:root:frame =10749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000507831573486
INFO:root:frame =10750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000591993331909
INFO:root:frame = 10751 State into memory, numbers recorded 281 action = 1, reward = 1
DEBUG:root: save sample needs time = 0.000730037689209
INFO:root:random_action_porb = 0.91507
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10752current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:training error  = [[ 31.79599762]
 [ 31.32017708]
 [ 30.31389999]
 [ 30.01597214]
 [ 29.74006653]
 [ 32.28719711]
 [ 31.12722588]
 [ 30.56401253]
 [ 31.54310989]
 [ 30.52555847]
 [ 28.76773262]
 [ 31.10679817]
 [ 29.3576088 ]
 [ 30.04431915]
 [ 32.80252075]
 [ 33.50873947]]
DEBUG:root:training time = %d0.207437
INFO:root:frame =10753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =10754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319957733154
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.915038333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root:frame =10757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =10758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000341892242432
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:random_action_porb = 0.915006666667
DEBUG:root: dqn, choose action rondomly, need time 0.000207999999986
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000151872634888
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 29.64037895]
 [ 32.13711548]
 [ 29.64386749]
 [ 31.93734741]
 [ 29.32752419]
 [ 31.92174149]
 [ 30.18314934]
 [ 29.17987823]
 [ 30.02307892]
 [ 43.1744194 ]
 [ 31.6626873 ]
 [ 30.85667229]
 [ 30.27056503]
 [ 30.52926636]
 [ 32.28554916]
 [ 47.11332321]]
DEBUG:root:training time = %d0.222265
INFO:root:frame =10761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =10762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000258922576904
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.914975
INFO:root:dqn select action Tensor("ArgMax_128:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01253
INFO:root:action choosen by dqn [4]
INFO:root:frame =10764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000193119049072
INFO:root:frame =10765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =10766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.914943333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000031
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 30.79889297]
 [ 30.75445175]
 [ 30.68205833]
 [ 29.7512188 ]
 [ 32.11315918]
 [ 32.48613739]
 [ 29.80858994]
 [ 30.60882378]
 [ 31.21198845]
 [ 44.25550461]
 [ 29.60533142]
 [ 31.39169312]
 [ 29.76337051]
 [ 29.95815086]
 [ 30.45882416]
 [ 31.23321915]]
DEBUG:root:training time = %d0.226842
INFO:root:frame =10769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =10770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324010848999
DEBUG:root: save sample needs time = 0.000256776809692
INFO:root:random_action_porb = 0.914911666667
DEBUG:root: dqn, choose action rondomly, need time 0.000250999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000351905822754
INFO:root:frame =10773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =10774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000517845153809
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:random_action_porb = 0.91488
DEBUG:root: dqn, choose action rondomly, need time 0.000229999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:training error  = [[ 30.50077629]
 [ 31.98013306]
 [ 30.07242775]
 [ 29.17518044]
 [ 28.53471184]
 [ 33.07065964]
 [ 31.48640442]
 [ 29.83675575]
 [ 31.463377  ]
 [ 33.25809479]
 [ 28.12044907]
 [ 32.32466125]
 [ 33.09733963]
 [ 31.63204193]
 [ 34.06618118]
 [ 29.52136993]]
DEBUG:root:training time = %d0.224533
INFO:root:frame =10777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =10778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264167785645
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.914848333333
DEBUG:root: dqn, choose action rondomly, need time 0.000535000000013
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =10781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000527143478394
INFO:root:frame =10782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.914816666667
DEBUG:root: dqn, choose action rondomly, need time 0.000501999999983
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 33.09716415]
 [ 50.22499847]
 [ 32.83302689]
 [ 32.46874619]
 [ 36.29411697]
 [ 30.94989395]
 [ 30.2761898 ]
 [ 34.12462997]
 [ 30.42262459]
 [ 32.77962494]
 [ 31.26025772]
 [ 45.81942749]
 [ 33.82357025]
 [ 33.93361282]
 [ 31.43299866]
 [ 29.14601135]]
DEBUG:root:training time = %d0.210164
INFO:root:frame =10785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =10786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:random_action_porb = 0.914785
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000018
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312805175781
INFO:root:frame =10789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =10790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.914753333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999969
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000424861907959
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 35.17974472]
 [ 35.00763702]
 [ 33.41120911]
 [ 31.18309593]
 [ 30.39990425]
 [ 32.19604874]
 [ 20.12077332]
 [ 31.23859215]
 [ 44.39264679]
 [ 30.41715431]
 [ 29.67153931]
 [ 33.95183563]
 [ 47.4768219 ]
 [ 30.27551842]
 [ 29.8980484 ]
 [ 31.90725899]]
DEBUG:root:training time = %d0.233867
INFO:root:frame =10793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =10794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.914721666667
DEBUG:root: dqn, choose action rondomly, need time 0.00018799999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root:frame =10797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =10798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.91469
INFO:root:dqn select action Tensor("ArgMax_129:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00981100000001
INFO:root:action choosen by dqn [4]
INFO:root:frame =10800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000188112258911
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 32.27557755]
 [ 30.66853714]
 [ 31.16358757]
 [ 30.98853111]
 [ 30.49723816]
 [ 30.66127014]
 [ 35.44115067]
 [ 30.56612206]
 [ 29.7136116 ]
 [ 28.71684837]
 [ 32.99120712]
 [ 30.04515457]
 [ 31.91398239]
 [ 31.98798561]
 [ 22.89640617]
 [ 29.51324654]]
DEBUG:root:training time = %d0.206745
INFO:root:frame =10801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =10802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000391006469727
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:random_action_porb = 0.914658333333
DEBUG:root: dqn, choose action rondomly, need time 0.000361999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000367879867554
INFO:root:frame =10805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame =10806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464200973511
DEBUG:root: save sample needs time = 0.000108957290649
INFO:root:random_action_porb = 0.914626666667
DEBUG:root: dqn, choose action rondomly, need time 0.000486000000024
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000531911849976
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 33.08478928]
 [ 35.15820694]
 [ 32.6950264 ]
 [ 45.36732483]
 [ 32.32431412]
 [ 32.55914688]
 [ 32.70497513]
 [ 32.0925827 ]
 [ 30.22566795]
 [ 31.60124016]
 [ 29.86660194]
 [ 32.86039734]
 [ 29.17658043]
 [ 33.57413483]
 [ 30.75089645]
 [ 31.93010521]]
DEBUG:root:training time = %d0.200624
INFO:root:frame =10809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =10810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226020812988
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.914595
INFO:root:dqn select action Tensor("ArgMax_130:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012911
INFO:root:action choosen by dqn [4]
INFO:root:frame =10812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =10813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:frame =10814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame = 10815 State into memory, numbers recorded 282 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00126910209656
INFO:root:random_action_porb = 0.914563333333
DEBUG:root: dqn, choose action rondomly, need time 0.000509000000022
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10816current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 32.84229279]
 [ 32.69136429]
 [ 32.54399872]
 [ 33.97104263]
 [ 34.37144852]
 [ 43.08413315]
 [ 30.10331154]
 [ 30.18029976]
 [ 31.8603878 ]
 [ 32.02856064]
 [ 43.50269699]
 [ 31.13088608]
 [ 32.32561493]
 [ 31.73768806]
 [ 30.18029976]
 [ 31.99040222]]
DEBUG:root:training time = %d0.203487
INFO:root:frame =10817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =10818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488996505737
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:random_action_porb = 0.914531666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000393152236938
INFO:root:frame =10821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =10822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9145
DEBUG:root: dqn, choose action rondomly, need time 0.000331999999958
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 33.42549896]
 [ 31.84652328]
 [ 33.33416748]
 [ 33.48577881]
 [ 35.08803558]
 [ 32.58771133]
 [ 31.33349991]
 [ 30.92918587]
 [ 20.30049896]
 [ 31.499506  ]
 [ 34.56638336]
 [ 46.16577911]
 [ 32.50884247]
 [ 29.68159676]
 [ 32.61079788]
 [ 43.0681076 ]]
DEBUG:root:training time = %d0.224554
INFO:root:frame =10825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =10826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:random_action_porb = 0.914468333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =10829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =10830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame = 10831 State into memory, numbers recorded 283 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000562906265259
INFO:root:random_action_porb = 0.914436666667
DEBUG:root: dqn, choose action rondomly, need time 0.000445000000013
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10832current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 32.98971939]
 [ 32.90694809]
 [ 32.00896072]
 [ 21.88305473]
 [ 30.20536995]
 [ 22.19163895]
 [ 33.05741119]
 [ 34.70638275]
 [ 32.79823685]
 [ 34.5534668 ]
 [ 29.66771507]
 [ 33.50732803]
 [ 33.05197144]
 [ 33.39771652]
 [ 31.00229263]
 [ 33.72248077]]
DEBUG:root:training time = %d0.217626
INFO:root:frame =10833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:frame =10834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000270128250122
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.914405
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =10837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =10838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.914373333333
INFO:root:dqn select action Tensor("ArgMax_131:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011859
INFO:root:action choosen by dqn [4]
INFO:root:frame =10840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000388860702515
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 33.18421555]
 [ 33.24023056]
 [ 33.27226257]
 [ 44.58428955]
 [ 31.25078773]
 [ 32.37421799]
 [ 44.58428955]
 [ 31.92777634]
 [ 28.55191422]
 [ 32.87833023]
 [ 33.27481461]
 [ 31.27868843]
 [ 32.37421799]
 [ 32.15986633]
 [ 33.08426285]
 [ 32.43302155]]
DEBUG:root:training time = %d0.216607
INFO:root:frame =10841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =10842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000316143035889
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.914341666667
INFO:root:dqn select action Tensor("ArgMax_132:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01539
INFO:root:action choosen by dqn [4]
INFO:root:frame =10844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:frame =10845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =10846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.91431
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000043
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 33.02180099]
 [ 33.50503159]
 [ 32.07616043]
 [ 31.63650513]
 [ 33.55238724]
 [ 32.04972076]
 [ 21.74991989]
 [ 31.04912376]
 [ 35.21224213]
 [ 32.05222702]
 [ 29.96549988]
 [ 33.20285416]
 [ 35.50304031]
 [ 32.38298798]
 [ 34.69748688]
 [ 43.87202835]]
DEBUG:root:training time = %d0.196612
INFO:root:frame =10849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =10850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000284910202026
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:random_action_porb = 0.914278333333
DEBUG:root: dqn, choose action rondomly, need time 0.000546999999983
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000476837158203
INFO:root:frame =10853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =10854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:random_action_porb = 0.914246666667
DEBUG:root: dqn, choose action rondomly, need time 0.000272999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000484943389893
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 33.28423309]
 [ 34.09334946]
 [ 31.29592896]
 [ 31.39570999]
 [ 30.72416496]
 [ 33.0442543 ]
 [ 32.69642258]
 [ 33.25061417]
 [ 47.05562973]
 [ 34.51813507]
 [ 31.01554871]
 [ 33.68164444]
 [ 32.53346634]
 [ 48.87969589]
 [ 21.88605309]
 [ 32.09612656]]
DEBUG:root:training time = %d0.222928
INFO:root:frame =10857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =10858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277996063232
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.914215
INFO:root:dqn select action Tensor("ArgMax_133:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010187
INFO:root:action choosen by dqn [4]
INFO:root:frame =10860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00018310546875
INFO:root:frame =10861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =10862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:random_action_porb = 0.914183333333
DEBUG:root: dqn, choose action rondomly, need time 0.000252999999987
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00023078918457
INFO:root:training error  = [[ 29.62534332]
 [ 30.24530029]
 [ 30.96449661]
 [ 33.40468216]
 [ 33.04644775]
 [ 33.62216187]
 [ 32.55165863]
 [ 31.8587513 ]
 [ 33.04644775]
 [ 32.83241272]
 [ 31.08314323]
 [ 32.67077637]
 [ 33.56600189]
 [ 31.5288868 ]
 [ 33.20980072]
 [ 32.80015945]]
DEBUG:root:training time = %d0.22411
INFO:root:frame =10865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =10866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.914151666667
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365972518921
INFO:root:frame =10869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472784042358
INFO:root:frame =10870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000556945800781
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.91412
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000018
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 31.6671524 ]
 [ 33.46538544]
 [ 33.46538544]
 [ 33.18553543]
 [ 32.06285095]
 [ 31.02634239]
 [ 32.85838699]
 [ 33.25008774]
 [ 32.65490341]
 [ 32.24030685]
 [ 31.25471306]
 [ 33.00146103]
 [ 44.74868011]
 [ 32.68769836]
 [ 32.31373215]
 [ 34.97252655]]
DEBUG:root:training time = %d0.235063
INFO:root:frame =10873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =10874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:random_action_porb = 0.914088333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =10877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000428915023804
INFO:root:frame =10878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.914056666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 34.08969879]
 [ 46.17075729]
 [ 31.59978294]
 [ 33.64853287]
 [ 33.57333755]
 [ 31.85702896]
 [ 35.96668243]
 [ 32.6628418 ]
 [ 30.75978279]
 [ 33.06785202]
 [ 33.2052269 ]
 [ 33.80023575]
 [ 32.27583694]
 [ 33.2052269 ]
 [ 31.6674099 ]
 [ 35.2634201 ]]
DEBUG:root:training time = %d0.240189
INFO:root:frame =10881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =10882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000292062759399
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.914025
DEBUG:root: dqn, choose action rondomly, need time 0.000192000000027
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =10885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000379085540771
INFO:root:frame =10886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.913993333333
DEBUG:root: dqn, choose action rondomly, need time 0.000442999999962
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 32.62892532]
 [ 33.01504898]
 [ 36.46631241]
 [ 33.25395584]
 [ 35.47258759]
 [ 34.57463837]
 [ 47.52435684]
 [ 33.69607925]
 [ 36.75288773]
 [ 32.66353607]
 [ 24.20360374]
 [ 49.14012909]
 [ 33.53780746]
 [ 34.56988144]
 [ 30.45057297]
 [ 31.86667633]]
DEBUG:root:training time = %d0.21834
INFO:root:frame =10889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =10890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.000109195709229
INFO:root:random_action_porb = 0.913961666667
DEBUG:root: dqn, choose action rondomly, need time 0.00022899999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =10893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =10894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002281665802
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:random_action_porb = 0.91393
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999958
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000416994094849
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 34.74163055]
 [ 31.88907623]
 [ 36.1264534 ]
 [ 33.76777649]
 [ 33.26979828]
 [ 34.34049988]
 [ 34.25033951]
 [ 33.8164711 ]
 [ 30.44796181]
 [ 34.74019241]
 [ 34.35060501]
 [ 33.47571182]
 [ 45.85093307]
 [ 31.47510338]
 [ 34.19329834]
 [ 33.29391861]]
DEBUG:root:training time = %d0.215912
INFO:root:frame =10897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =10898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482082366943
INFO:root:frame = 10899 State into memory, numbers recorded 284 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000592947006226
INFO:root:random_action_porb = 0.913898333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10900current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =10901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000520944595337
INFO:root:frame =10902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.913866666667
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 34.81496811]
 [ 32.38220596]
 [ 31.98090935]
 [ 35.16978836]
 [ 32.2550354 ]
 [ 32.84911728]
 [ 33.18166733]
 [ 49.16954803]
 [ 31.35101128]
 [ 33.4899292 ]
 [ 34.73884201]
 [ 32.84911728]
 [ 33.5392189 ]
 [ 32.41903305]
 [ 30.52876091]
 [ 33.46255875]]
DEBUG:root:training time = %d0.216985
INFO:root:frame =10905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =10906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00029993057251
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root:random_action_porb = 0.913835
DEBUG:root: dqn, choose action rondomly, need time 0.000398999999959
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =10909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =10910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000412940979004
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.913803333333
DEBUG:root: dqn, choose action rondomly, need time 0.000342999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 44.64941788]
 [ 33.59579849]
 [ 34.07847214]
 [ 32.53868866]
 [ 34.48076248]
 [ 34.64681244]
 [ 37.2205925 ]
 [ 34.93797302]
 [ 36.0694313 ]
 [ 32.75691605]
 [ 30.45840454]
 [ 31.1120739 ]
 [ 31.07285118]
 [ 32.98997879]
 [ 33.01180649]
 [ 35.64483261]]
DEBUG:root:training time = %d0.19476
INFO:root:frame =10913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =10914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000409841537476
DEBUG:root: save sample needs time = 0.000105857849121
INFO:root:random_action_porb = 0.913771666667
DEBUG:root: dqn, choose action rondomly, need time 0.000166999999976
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000147104263306
INFO:root:frame =10917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000487089157104
INFO:root:frame =10918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000519990921021
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.91374
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000046
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root:training error  = [[ 33.30210495]
 [ 33.69430923]
 [ 31.16435432]
 [ 33.33258057]
 [ 35.29623032]
 [ 35.36270905]
 [ 32.62378311]
 [ 32.38550568]
 [ 33.6044693 ]
 [ 34.02745056]
 [ 32.8482399 ]
 [ 33.81309891]
 [ 32.85987473]
 [ 31.54576683]
 [ 32.68891907]
 [ 33.41182709]]
DEBUG:root:training time = %d0.225345
INFO:root:frame =10921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000403165817261
INFO:root:frame =10922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.913708333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =10925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =10926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.913676666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 31.66946983]
 [ 47.89355469]
 [ 36.44678116]
 [ 32.96684647]
 [ 35.65002441]
 [ 31.23432732]
 [ 33.26108551]
 [ 31.80176163]
 [ 32.34244919]
 [ 34.26158905]
 [ 45.3012619 ]
 [ 32.10771179]
 [ 35.27166748]
 [ 32.60652924]
 [ 50.09780121]
 [ 32.85926056]]
DEBUG:root:training time = %d0.235549
INFO:root:frame =10929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =10930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame = 10931 State into memory, numbers recorded 285 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000549077987671
INFO:root:random_action_porb = 0.913645
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10932current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =10933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =10934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.913613333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000343799591064
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 31.29166031]
 [ 33.25827026]
 [ 33.06890488]
 [ 31.58837509]
 [ 31.69068336]
 [ 33.26592636]
 [ 32.95239258]
 [ 44.86297226]
 [ 31.52271843]
 [ 34.6219368 ]
 [ 45.02716064]
 [ 34.22185898]
 [ 32.62038422]
 [ 32.44162369]
 [ 31.86891556]
 [ 34.10662842]]
DEBUG:root:training time = %d0.229205
INFO:root:frame =10937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =10938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:random_action_porb = 0.913581666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =10941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =10942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046181678772
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.91355
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000038
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 35.10783005]
 [ 33.55017853]
 [ 37.61625671]
 [ 32.56454468]
 [ 32.00473022]
 [ 32.31069565]
 [ 34.67744446]
 [ 32.47692108]
 [ 33.12596512]
 [ 46.08618927]
 [ 34.31913376]
 [ 31.39092255]
 [ 31.39092255]
 [ 32.67592239]
 [ 33.93752289]
 [ 33.49858093]]
DEBUG:root:training time = %d0.213961
INFO:root:frame =10945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =10946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00055193901062
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:random_action_porb = 0.913518333333
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =10949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =10950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.913486666667
DEBUG:root: dqn, choose action rondomly, need time 0.000411000000042
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 49.28849411]
 [ 33.65171814]
 [ 22.26112938]
 [ 35.17304611]
 [ 32.02433014]
 [ 32.23926544]
 [ 22.26112938]
 [ 23.14958382]
 [ 35.51985931]
 [ 32.1491394 ]
 [ 35.83311081]
 [ 34.16091919]
 [ 35.75204468]
 [ 32.63363266]
 [ 34.54440689]
 [ 31.86857033]]
DEBUG:root:training time = %d0.237521
INFO:root:frame =10953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =10954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000130891799927
INFO:root:random_action_porb = 0.913455
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =10957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =10958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame = 10959 State into memory, numbers recorded 286 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000801801681519
INFO:root:random_action_porb = 0.913423333333
DEBUG:root: dqn, choose action rondomly, need time 0.000171000000023
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10960current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 32.81038284]
 [ 32.64670944]
 [ 33.40997314]
 [ 47.11709213]
 [ 33.13931656]
 [ 22.92737389]
 [ 34.13773346]
 [ 46.99211884]
 [ 33.59004974]
 [ 35.56898499]
 [ 30.70809555]
 [ 34.07615662]
 [ 32.38064194]
 [ 45.79061508]
 [ 32.58152771]
 [ 36.49829483]]
DEBUG:root:training time = %d0.200668
INFO:root:frame =10961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =10962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame = 10963 State into memory, numbers recorded 287 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000577926635742
INFO:root:random_action_porb = 0.913391666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10964current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =10965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000550031661987
INFO:root:frame =10966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:random_action_porb = 0.91336
INFO:root:dqn select action Tensor("ArgMax_134:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01134
INFO:root:action choosen by dqn [4]
INFO:root:frame =10968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 32.65882874]
 [ 33.66287231]
 [ 29.71294594]
 [ 34.9922905 ]
 [ 34.42156219]
 [ 35.74538422]
 [ 46.56485748]
 [ 50.22586441]
 [ 32.87395859]
 [ 23.89463806]
 [ 34.03626251]
 [ 35.86663818]
 [ 35.08911896]
 [ 32.21483994]
 [ 50.81869507]
 [ 34.15530014]]
DEBUG:root:training time = %d0.209749
INFO:root:frame =10969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =10970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.913328333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000022
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =10973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =10974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000517845153809
DEBUG:root: save sample needs time = 0.000206232070923
INFO:root:random_action_porb = 0.913296666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000043
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =10976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 32.25572968]
 [ 35.95378113]
 [ 32.15433121]
 [ 33.94525528]
 [ 35.98370361]
 [ 36.3583107 ]
 [ 34.44421387]
 [ 32.98840332]
 [ 34.66612244]
 [ 35.02018738]
 [ 32.71832657]
 [ 31.30113602]
 [ 47.02852631]
 [ 31.71413803]
 [ 35.38621521]
 [ 34.44421387]]
DEBUG:root:training time = %d0.22468
INFO:root:frame =10977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =10978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.913265
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000022
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =10980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =10981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000514030456543
INFO:root:frame =10982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.913233333333
DEBUG:root: dqn, choose action rondomly, need time 0.00032200000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =10984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 33.09944916]
 [ 24.2728672 ]
 [ 37.48170853]
 [ 48.91949844]
 [ 33.75190353]
 [ 33.45302963]
 [ 35.84864044]
 [ 34.12462997]
 [ 34.53902817]
 [ 34.25676727]
 [ 33.43255615]
 [ 36.10664749]
 [ 36.38066864]
 [ 52.56825256]
 [ 36.71802139]
 [ 33.11463547]]
DEBUG:root:training time = %d0.228158
INFO:root:frame =10985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =10986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000387907028198
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root:random_action_porb = 0.913201666667
INFO:root:dqn select action Tensor("ArgMax_135:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011404
INFO:root:action choosen by dqn [4]
INFO:root:frame =10988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root:frame =10989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =10990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000684022903442
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:random_action_porb = 0.91317
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =10992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 34.80524826]
 [ 32.94249725]
 [ 33.15249252]
 [ 34.78832626]
 [ 34.9517746 ]
 [ 34.86225128]
 [ 31.35348892]
 [ 31.35348892]
 [ 34.19365692]
 [ 39.10475922]
 [ 33.81167984]
 [ 33.93503189]
 [ 35.027771  ]
 [ 35.39574432]
 [ 34.70063019]
 [ 45.6903038 ]]
DEBUG:root:training time = %d0.223707
INFO:root:frame =10993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000338792800903
INFO:root:frame =10994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000302076339722
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.913138333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =10996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root:frame =10997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000513076782227
INFO:root:frame =10998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000203132629395
DEBUG:root:one frame running time = 0.00667499999997
DEBUG:root:total training time = 319.484895
INFO:root:frame num = 11000 frame round: 0
INFO:root:random_action_porb = 0.913106666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000038
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 36.46603775]
 [ 35.56361771]
 [ 34.65175247]
 [ 37.1386261 ]
 [ 34.56737137]
 [ 45.9823494 ]
 [ 34.77563477]
 [ 34.49796677]
 [ 34.6035347 ]
 [ 33.78613281]
 [ 32.72172928]
 [ 24.93435478]
 [ 34.67681503]
 [ 35.40219116]
 [ 35.31526947]
 [ 24.46804047]]
DEBUG:root:training time = %d0.229676
INFO:root:frame =11001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =11002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471830368042
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:random_action_porb = 0.913075
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304222106934
INFO:root:frame =11005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =11006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.913043333333
DEBUG:root: dqn, choose action rondomly, need time 0.000500999999986
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 32.14957047]
 [ 33.51845551]
 [ 34.16992569]
 [ 46.57975006]
 [ 33.93894577]
 [ 34.64878845]
 [ 32.11851883]
 [ 35.19829941]
 [ 33.26126099]
 [ 34.00484848]
 [ 47.20343781]
 [ 32.69206238]
 [ 33.07434464]
 [ 33.59871674]
 [ 33.68589401]
 [ 37.18653107]]
DEBUG:root:training time = %d0.232217
INFO:root:frame =11009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =11010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000280857086182
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.913011666667
DEBUG:root: dqn, choose action rondomly, need time 0.000324999999975
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =11013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000602006912231
INFO:root:frame =11014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000369787216187
INFO:root:frame = 11015 State into memory, numbers recorded 288 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000882863998413
INFO:root:random_action_porb = 0.91298
DEBUG:root: dqn, choose action rondomly, need time 0.00022100000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11016current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 33.79996872]
 [ 35.19341278]
 [ 46.33876801]
 [ 47.67552948]
 [ 33.2756958 ]
 [ 44.68123627]
 [ 34.42353058]
 [ 35.64437485]
 [ 33.4355545 ]
 [ 34.56010437]
 [ 34.32369232]
 [ 34.6121521 ]
 [ 35.09797668]
 [ 34.52745819]
 [ 32.3156395 ]
 [ 33.318573  ]]
DEBUG:root:training time = %d0.198377
INFO:root:frame =11017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =11018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000612020492554
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.912948333333
DEBUG:root: dqn, choose action rondomly, need time 0.000227999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:frame =11021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =11022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000496864318848
INFO:root:frame = 11023 State into memory, numbers recorded 289 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000422954559326
INFO:root:random_action_porb = 0.912916666667
DEBUG:root: dqn, choose action rondomly, need time 0.000253999999984
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11024current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000224828720093
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 34.96404266]
 [ 33.98838806]
 [ 34.42362213]
 [ 34.36106873]
 [ 48.99775696]
 [ 33.21876907]
 [ 34.67906189]
 [ 35.25617218]
 [ 32.89548111]
 [ 35.97080231]
 [ 35.25617218]
 [ 34.14754105]
 [ 31.76889992]
 [ 52.35240936]
 [ 34.26230621]
 [ 32.78198624]]
DEBUG:root:training time = %d0.202066
INFO:root:frame =11025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:frame =11026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235080718994
DEBUG:root: save sample needs time = 0.000176906585693
INFO:root:random_action_porb = 0.912885
DEBUG:root: dqn, choose action rondomly, need time 0.000323999999978
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000521898269653
INFO:root:frame =11029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =11030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293016433716
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.912853333333
DEBUG:root: dqn, choose action rondomly, need time 0.000379000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 34.41744232]
 [ 34.04445267]
 [ 33.70600128]
 [ 35.11307526]
 [ 34.62911987]
 [ 34.85801697]
 [ 47.27328491]
 [ 34.10314941]
 [ 34.15271378]
 [ 35.83146667]
 [ 33.12903976]
 [ 34.85801697]
 [ 34.84703064]
 [ 32.93400192]
 [ 33.47076797]
 [ 33.18658829]]
DEBUG:root:training time = %d0.216038
INFO:root:frame =11033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =11034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000312805175781
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.912821666667
DEBUG:root: dqn, choose action rondomly, need time 0.000175000000013
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:frame =11037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =11038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411033630371
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:random_action_porb = 0.91279
INFO:root:dqn select action Tensor("ArgMax_136:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.016395
INFO:root:action choosen by dqn [4]
INFO:root:frame =11040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000172138214111
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 35.0387001 ]
 [ 33.91237259]
 [ 33.69572449]
 [ 46.63360596]
 [ 33.42011642]
 [ 34.81451797]
 [ 33.34095001]
 [ 50.47380829]
 [ 32.8311882 ]
 [ 36.64843369]
 [ 34.26534271]
 [ 35.76345062]
 [ 35.10909653]
 [ 35.46431732]
 [ 32.94091797]
 [ 32.88008118]]
DEBUG:root:training time = %d0.205826
INFO:root:frame =11041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =11042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000333070755005
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:random_action_porb = 0.912758333333
DEBUG:root: dqn, choose action rondomly, need time 0.000391000000036
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =11045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00039005279541
INFO:root:frame =11046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame = 11047 State into memory, numbers recorded 290 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000574111938477
INFO:root:random_action_porb = 0.912726666667
DEBUG:root: dqn, choose action rondomly, need time 0.000218999999959
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11048current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:training error  = [[ 35.2637825 ]
 [ 34.36930084]
 [ 33.19256592]
 [ 35.9901123 ]
 [ 36.09472656]
 [ 37.0301857 ]
 [ 34.70692444]
 [ 34.42469406]
 [ 36.24752426]
 [ 34.37556076]
 [ 33.65065765]
 [ 35.05179977]
 [ 33.51059341]
 [ 33.47474289]
 [ 32.2831192 ]
 [ 33.46503067]]
DEBUG:root:training time = %d0.221717
INFO:root:frame =11049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =11050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.912695
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =11053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =11054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:random_action_porb = 0.912663333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:training error  = [[ 33.74702835]
 [ 32.22167969]
 [ 35.3103714 ]
 [ 33.64180374]
 [ 34.89775848]
 [ 34.97333908]
 [ 35.10927582]
 [ 33.45161438]
 [ 34.35972977]
 [ 34.34738541]
 [ 36.53831482]
 [ 33.25175858]
 [ 34.57382965]
 [ 33.25175858]
 [ 33.45161438]
 [ 33.94703293]]
DEBUG:root:training time = %d0.217834
INFO:root:frame =11057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:frame =11058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000120162963867
INFO:root:random_action_porb = 0.912631666667
DEBUG:root: dqn, choose action rondomly, need time 0.000319999999988
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =11061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000543117523193
INFO:root:frame =11062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00059700012207
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:random_action_porb = 0.9126
DEBUG:root: dqn, choose action rondomly, need time 0.000283000000024
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:training error  = [[ 33.60314178]
 [ 34.75107574]
 [ 35.23189545]
 [ 34.30957031]
 [ 32.25416946]
 [ 33.00505829]
 [ 35.05577469]
 [ 34.1310463 ]
 [ 34.84162521]
 [ 37.69293976]
 [ 35.90283585]
 [ 37.5128212 ]
 [ 34.73884201]
 [ 34.30957031]
 [ 34.48058319]
 [ 36.63217545]]
DEBUG:root:training time = %d0.242755
INFO:root:frame =11065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =11066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000384092330933
INFO:root:frame = 11067 State into memory, numbers recorded 291 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:random_action_porb = 0.912568333333
DEBUG:root: dqn, choose action rondomly, need time 0.000350000000026
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11068current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000396013259888
INFO:root:frame =11069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =11070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481843948364
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.912536666667
DEBUG:root: dqn, choose action rondomly, need time 0.000459999999975
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029182434082
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 37.1788063 ]
 [ 34.76195908]
 [ 36.71996307]
 [ 35.12392426]
 [ 34.87225342]
 [ 34.72301483]
 [ 35.14762497]
 [ 36.04450989]
 [ 34.27588272]
 [ 30.66769218]
 [ 38.74253082]
 [ 34.77554703]
 [ 23.15861511]
 [ 33.99443817]
 [ 34.31940079]
 [ 39.82348251]]
DEBUG:root:training time = %d0.21052
INFO:root:frame =11073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =11074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame = 11075 State into memory, numbers recorded 292 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000566005706787
INFO:root:random_action_porb = 0.912505
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11076current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =11077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000393152236938
INFO:root:frame =11078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:random_action_porb = 0.912473333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 37.12402725]
 [ 36.17223358]
 [ 36.40543365]
 [ 35.53368378]
 [ 51.07725525]
 [ 35.42770767]
 [ 39.45534897]
 [ 33.11384583]
 [ 36.94963074]
 [ 36.89844894]
 [ 36.64556885]
 [ 33.22299194]
 [ 34.31797028]
 [ 35.42770767]
 [ 37.12402725]
 [ 35.67262268]]
DEBUG:root:training time = %d0.212529
INFO:root:frame =11081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =11082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame = 11083 State into memory, numbers recorded 293 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000404119491577
INFO:root:random_action_porb = 0.912441666667
DEBUG:root: dqn, choose action rondomly, need time 0.000328999999965
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11084current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =11085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000509977340698
INFO:root:frame =11086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000625848770142
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.91241
DEBUG:root: dqn, choose action rondomly, need time 0.00027399999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000378847122192
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 36.03727341]
 [ 38.89511871]
 [ 33.26108551]
 [ 35.58018112]
 [ 47.9122467 ]
 [ 36.89075851]
 [ 33.75944138]
 [ 39.122509  ]
 [ 34.01232147]
 [ 35.85010147]
 [ 35.65066147]
 [ 33.78799438]
 [ 32.80715179]
 [ 36.23365402]
 [ 24.88645172]
 [ 34.2113266 ]]
DEBUG:root:training time = %d0.210473
INFO:root:frame =11089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =11090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000305891036987
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.912378333333
DEBUG:root: dqn, choose action rondomly, need time 0.000242000000014
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:frame =11093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =11094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.912346666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355958938599
INFO:root:training error  = [[ 35.14219666]
 [ 35.44705582]
 [ 35.97317886]
 [ 38.03066254]
 [ 34.30769348]
 [ 34.81343842]
 [ 38.27656555]
 [ 36.82276154]
 [ 35.55779266]
 [ 35.97711563]
 [ 35.25934219]
 [ 35.69532013]
 [ 33.50697327]
 [ 36.81174469]
 [ 34.49276733]
 [ 34.95511246]]
DEBUG:root:training time = %d0.230329
INFO:root:frame =11097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:frame =11098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame = 11099 State into memory, numbers recorded 294 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000368118286133
INFO:root:random_action_porb = 0.912315
INFO:root:dqn select action Tensor("ArgMax_137:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014485
INFO:root:action choosen by dqn [4]
INFO:root:frame =11100current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =11101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =11102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.912283333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 34.69469833]
 [ 31.20508385]
 [ 36.60281372]
 [ 35.10466766]
 [ 35.27882385]
 [ 35.30973816]
 [ 37.53945923]
 [ 48.16839981]
 [ 35.85777664]
 [ 35.65111923]
 [ 48.68903351]
 [ 35.60066223]
 [ 36.31563187]
 [ 35.13423538]
 [ 35.55670166]
 [ 25.47756958]]
DEBUG:root:training time = %d0.216421
INFO:root:frame =11105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028920173645
INFO:root:frame =11106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.912251666667
DEBUG:root: dqn, choose action rondomly, need time 0.000271999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =11109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =11110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000593900680542
INFO:root:frame = 11111 State into memory, numbers recorded 295 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00056004524231
INFO:root:random_action_porb = 0.91222
DEBUG:root: dqn, choose action rondomly, need time 0.000379000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11112current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 36.12186813]
 [ 38.84365463]
 [ 34.77185822]
 [ 38.56892014]
 [ 38.348629  ]
 [ 38.58218765]
 [ 34.46974182]
 [ 33.41288376]
 [ 46.22489548]
 [ 33.70617676]
 [ 32.44823074]
 [ 36.12186813]
 [ 34.28329849]
 [ 34.20927048]
 [ 38.348629  ]
 [ 34.42702103]]
DEBUG:root:training time = %d0.224267
INFO:root:frame =11113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =11114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000538110733032
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.912188333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000031
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =11117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =11118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame = 11119 State into memory, numbers recorded 296 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:random_action_porb = 0.912156666667
DEBUG:root: dqn, choose action rondomly, need time 0.000202000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11120current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 37.93549347]
 [ 40.25168228]
 [ 34.54440689]
 [ 38.26721954]
 [ 33.56361389]
 [ 49.3755188 ]
 [ 33.51527786]
 [ 34.66675186]
 [ 37.32679367]
 [ 34.49285889]
 [ 36.36548615]
 [ 34.47144318]
 [ 35.30012512]
 [ 51.35418701]
 [ 40.59841919]
 [ 34.41171646]]
DEBUG:root:training time = %d0.235256
INFO:root:frame =11121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =11122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame = 11123 State into memory, numbers recorded 297 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000625133514404
INFO:root:random_action_porb = 0.912125
DEBUG:root: dqn, choose action rondomly, need time 0.000263000000018
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11124current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =11125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:frame =11126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411987304688
DEBUG:root: save sample needs time = 0.000256776809692
INFO:root:random_action_porb = 0.912093333333
DEBUG:root: dqn, choose action rondomly, need time 0.000263000000018
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 36.95018768]
 [ 36.48492813]
 [ 24.98344612]
 [ 32.56219482]
 [ 35.14798355]
 [ 35.63135147]
 [ 34.94428635]
 [ 35.35581207]
 [ 25.2585392 ]
 [ 38.29327774]
 [ 36.81322861]
 [ 47.72443008]
 [ 49.84604263]
 [ 47.90622711]
 [ 34.61924362]
 [ 38.38284302]]
DEBUG:root:training time = %d0.227551
INFO:root:frame =11129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =11130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:random_action_porb = 0.912061666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999976
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =11133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280857086182
INFO:root:frame =11134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000389099121094
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.91203
DEBUG:root: dqn, choose action rondomly, need time 0.000359000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 38.02087784]
 [ 35.72394943]
 [ 34.9295845 ]
 [ 34.9295845 ]
 [ 46.90199661]
 [ 37.50254059]
 [ 37.569664  ]
 [ 36.26158142]
 [ 36.19068146]
 [ 35.33150101]
 [ 35.33150101]
 [ 32.81938934]
 [ 46.97716141]
 [ 35.89268875]
 [ 35.08179855]
 [ 35.9916687 ]]
DEBUG:root:training time = %d0.218952
INFO:root:frame =11137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =11138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.911998333333
DEBUG:root: dqn, choose action rondomly, need time 0.000317999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =11141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =11142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000569105148315
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:random_action_porb = 0.911966666667
DEBUG:root: dqn, choose action rondomly, need time 0.000334000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 36.45672989]
 [ 38.75222015]
 [ 46.74621201]
 [ 35.43261337]
 [ 36.20895004]
 [ 34.42603683]
 [ 25.97124481]
 [ 36.14718246]
 [ 34.43292999]
 [ 36.81924438]
 [ 36.39862061]
 [ 37.41615677]
 [ 36.79711914]
 [ 34.54019165]
 [ 37.33397293]
 [ 36.08712006]]
DEBUG:root:training time = %d0.209576
INFO:root:frame =11145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000396013259888
INFO:root:frame =11146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.911935
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =11149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000495195388794
INFO:root:frame =11150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00065803527832
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.911903333333
DEBUG:root: dqn, choose action rondomly, need time 0.000466999999958
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000556945800781
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 35.33095932]
 [ 35.67608643]
 [ 36.04377365]
 [ 37.04560089]
 [ 34.30554962]
 [ 39.28750992]
 [ 27.43535423]
 [ 36.08061218]
 [ 35.35236359]
 [ 36.96605301]
 [ 35.06245804]
 [ 35.18010712]
 [ 34.81388855]
 [ 40.64879608]
 [ 38.84593582]
 [ 49.53884125]]
DEBUG:root:training time = %d0.223776
INFO:root:frame =11153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000346899032593
INFO:root:frame =11154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.911871666667
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999966
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =11157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =11158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.91184
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 38.89445114]
 [ 36.80841446]
 [ 34.88513947]
 [ 35.32306671]
 [ 35.80434418]
 [ 35.57217026]
 [ 35.50167465]
 [ 25.07092667]
 [ 35.55706406]
 [ 36.85045242]
 [ 35.38394547]
 [ 38.42596054]
 [ 34.21587753]
 [ 37.34973145]
 [ 34.05326843]
 [ 52.50941467]]
DEBUG:root:training time = %d0.234496
INFO:root:frame =11161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250816345215
INFO:root:frame =11162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000503063201904
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.911808333333
DEBUG:root: dqn, choose action rondomly, need time 0.000491000000011
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =11165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =11166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000508069992065
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.911776666667
DEBUG:root: dqn, choose action rondomly, need time 0.000327000000027
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:training error  = [[ 38.05494308]
 [ 33.26944733]
 [ 35.99560547]
 [ 38.19334793]
 [ 35.06797028]
 [ 36.54218674]
 [ 38.19778061]
 [ 36.96883392]
 [ 35.07221985]
 [ 36.80480194]
 [ 35.38793945]
 [ 36.80637741]
 [ 35.26423645]
 [ 35.16390991]
 [ 36.49562073]
 [ 34.82658386]]
DEBUG:root:training time = %d0.22722
INFO:root:frame =11169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =11170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.911745
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999968
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =11173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =11174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046181678772
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.911713333333
DEBUG:root: dqn, choose action rondomly, need time 0.000276999999983
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 37.1470871 ]
 [ 33.62525558]
 [ 51.31701279]
 [ 36.6137085 ]
 [ 37.66858673]
 [ 37.32865906]
 [ 37.52544022]
 [ 37.68797684]
 [ 37.6108284 ]
 [ 37.01078033]
 [ 34.73263931]
 [ 35.48649216]
 [ 35.44169617]
 [ 36.07181168]
 [ 35.80653381]
 [ 35.61568451]]
DEBUG:root:training time = %d0.22265
INFO:root:frame =11177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =11178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042986869812
INFO:root:frame = 11179 State into memory, numbers recorded 298 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000582933425903
INFO:root:random_action_porb = 0.911681666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11180current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =11181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =11182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049090385437
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:random_action_porb = 0.91165
DEBUG:root: dqn, choose action rondomly, need time 0.00018300000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000145196914673
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 34.96837616]
 [ 38.03950882]
 [ 38.66270065]
 [ 25.8106041 ]
 [ 36.86453629]
 [ 38.11549377]
 [ 49.77389145]
 [ 34.48031235]
 [ 38.29450226]
 [ 38.50431824]
 [ 35.63262558]
 [ 34.96657181]
 [ 36.1001358 ]
 [ 24.42956161]
 [ 37.20244217]
 [ 35.78608704]]
DEBUG:root:training time = %d0.226348
INFO:root:frame =11185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =11186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000539779663086
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.911618333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000031
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326156616211
INFO:root:frame =11189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000521898269653
INFO:root:frame =11190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00056004524231
INFO:root:frame = 11191 State into memory, numbers recorded 299 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000573873519897
INFO:root:random_action_porb = 0.911586666667
DEBUG:root: dqn, choose action rondomly, need time 0.00037500000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11192current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000446796417236
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 50.51490402]
 [ 37.80093765]
 [ 52.8945694 ]
 [ 39.61566925]
 [ 37.39945221]
 [ 33.99443817]
 [ 36.07309723]
 [ 51.43841934]
 [ 40.07191849]
 [ 37.05442429]
 [ 39.57659149]
 [ 37.25681305]
 [ 34.89045715]
 [ 39.48017502]
 [ 40.21209717]
 [ 39.61566925]]
DEBUG:root:training time = %d0.2301
INFO:root:frame =11193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =11194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.911555
DEBUG:root: dqn, choose action rondomly, need time 0.000324999999975
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =11197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =11198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000503063201904
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.911523333333
DEBUG:root: dqn, choose action rondomly, need time 0.000405000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 39.88792801]
 [ 36.28078842]
 [ 36.68677902]
 [ 38.07047653]
 [ 35.6660614 ]
 [ 40.7325058 ]
 [ 35.95542908]
 [ 34.49321747]
 [ 49.64092255]
 [ 36.38370895]
 [ 36.37542343]
 [ 49.31999588]
 [ 39.86162567]
 [ 36.97106171]
 [ 50.98765564]
 [ 35.50222015]]
DEBUG:root:training time = %d0.228701
INFO:root:frame =11201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =11202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.911491666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =11205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =11206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.91146
DEBUG:root: dqn, choose action rondomly, need time 0.00028599999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 35.76290512]
 [ 40.14951706]
 [ 35.91947937]
 [ 38.14564514]
 [ 36.06906509]
 [ 37.16568756]
 [ 36.91448593]
 [ 35.51868057]
 [ 36.40018463]
 [ 39.01978683]
 [ 37.6452713 ]
 [ 35.4787674 ]
 [ 35.99578857]
 [ 41.51697922]
 [ 38.71527863]
 [ 53.40271759]]
DEBUG:root:training time = %d0.228011
INFO:root:frame =11209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =11210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000607967376709
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.911428333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =11213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =11214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.911396666667
DEBUG:root: dqn, choose action rondomly, need time 0.000522999999987
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 35.93877792]
 [ 38.38142395]
 [ 36.79721069]
 [ 37.57948685]
 [ 50.6537056 ]
 [ 38.38142395]
 [ 36.75603485]
 [ 49.22006607]
 [ 38.01034164]
 [ 36.90364075]
 [ 36.8886261 ]
 [ 37.22720337]
 [ 49.26782227]
 [ 32.58866882]
 [ 36.79054642]
 [ 34.08176804]]
DEBUG:root:training time = %d0.225931
INFO:root:frame =11217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:frame =11218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:random_action_porb = 0.911365
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =11221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =11222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000380992889404
DEBUG:root: save sample needs time = 0.000134944915771
INFO:root:random_action_porb = 0.911333333333
DEBUG:root: dqn, choose action rondomly, need time 0.000230999999985
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 35.89387894]
 [ 34.90235519]
 [ 38.22654724]
 [ 36.86759186]
 [ 35.66970825]
 [ 39.05000687]
 [ 34.94591141]
 [ 39.20902634]
 [ 50.68542099]
 [ 26.65816498]
 [ 49.66436005]
 [ 40.02904129]
 [ 39.61605072]
 [ 33.4229393 ]
 [ 36.5207901 ]
 [ 36.89344406]]
DEBUG:root:training time = %d0.187477
INFO:root:frame =11225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =11226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000416994094849
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:random_action_porb = 0.911301666667
DEBUG:root: dqn, choose action rondomly, need time 0.000362999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =11229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000485897064209
INFO:root:frame =11230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494003295898
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.91127
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999966
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 36.94416046]
 [ 36.30404663]
 [ 43.08453369]
 [ 36.85054779]
 [ 41.33705521]
 [ 37.30973434]
 [ 36.64584732]
 [ 38.180336  ]
 [ 36.78240204]
 [ 49.44770432]
 [ 37.008461  ]
 [ 36.71155167]
 [ 36.57309341]
 [ 39.65034485]
 [ 37.70080948]
 [ 36.35315704]]
DEBUG:root:training time = %d0.200116
INFO:root:frame =11233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =11234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237226486206
DEBUG:root: save sample needs time = 0.000123977661133
INFO:root:random_action_porb = 0.911238333333
DEBUG:root: dqn, choose action rondomly, need time 0.000175999999954
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000158071517944
INFO:root:frame =11237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =11238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240087509155
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.911206666667
DEBUG:root: dqn, choose action rondomly, need time 0.000184000000047
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 48.47409058]
 [ 35.72340393]
 [ 51.09492493]
 [ 34.766819  ]
 [ 38.19297028]
 [ 35.49376678]
 [ 36.61666107]
 [ 38.52041626]
 [ 35.14129257]
 [ 36.31783676]
 [ 37.66924286]
 [ 36.28639603]
 [ 48.00101089]
 [ 34.766819  ]
 [ 36.99565125]
 [ 35.95222473]]
DEBUG:root:training time = %d0.191498
INFO:root:frame =11241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:frame =11242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
INFO:root:frame = 11243 State into memory, numbers recorded 300 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.00105381011963
INFO:root:random_action_porb = 0.911175
DEBUG:root: dqn, choose action rondomly, need time 0.000194999999962
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11244current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:frame =11245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =11246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000331878662109
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.911143333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 36.99500275]
 [ 36.67624283]
 [ 37.21770859]
 [ 37.96491623]
 [ 38.3770752 ]
 [ 50.06918335]
 [ 37.19332123]
 [ 36.23503113]
 [ 34.8224411 ]
 [ 37.47376633]
 [ 35.60803604]
 [ 36.16672516]
 [ 37.19229889]
 [ 38.03941345]
 [ 37.4468689 ]
 [ 37.53132629]]
DEBUG:root:training time = %d0.200012
INFO:root:frame =11249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =11250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.000109910964966
INFO:root:random_action_porb = 0.911111666667
DEBUG:root: dqn, choose action rondomly, need time 0.000536000000011
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =11253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root:frame =11254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000496864318848
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.91108
DEBUG:root: dqn, choose action rondomly, need time 0.000488000000018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 38.10748672]
 [ 36.34220886]
 [ 36.26544189]
 [ 54.19824982]
 [ 37.55264282]
 [ 36.65157318]
 [ 39.85497665]
 [ 34.11420059]
 [ 37.37379456]
 [ 49.57686615]
 [ 37.32707214]
 [ 37.91435242]
 [ 40.17350006]
 [ 35.47813034]
 [ 39.66139603]
 [ 56.85748291]]
DEBUG:root:training time = %d0.215627
INFO:root:frame =11257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:frame =11258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226020812988
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:random_action_porb = 0.911048333333
DEBUG:root: dqn, choose action rondomly, need time 0.000349000000028
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =11261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame =11262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.911016666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000022
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 37.27805328]
 [ 37.39217377]
 [ 39.29315186]
 [ 38.40856171]
 [ 39.56612778]
 [ 35.0435791 ]
 [ 28.14229965]
 [ 37.65707016]
 [ 38.865242  ]
 [ 40.49232101]
 [ 39.67340851]
 [ 35.93850327]
 [ 37.58781052]
 [ 40.35843658]
 [ 38.38813782]
 [ 35.02524567]]
DEBUG:root:training time = %d0.220368
INFO:root:frame =11265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =11266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.910985
DEBUG:root: dqn, choose action rondomly, need time 0.000538000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =11269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000574111938477
INFO:root:frame =11270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000451803207397
INFO:root:frame = 11271 State into memory, numbers recorded 301 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000579833984375
INFO:root:random_action_porb = 0.910953333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304000000028
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11272current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 52.36488724]
 [ 38.47005081]
 [ 39.58791733]
 [ 37.41027451]
 [ 38.94014359]
 [ 35.47322464]
 [ 38.33492661]
 [ 37.76961136]
 [ 36.45912552]
 [ 38.29270935]
 [ 51.74727249]
 [ 39.01654816]
 [ 36.41031265]
 [ 39.55326843]
 [ 35.07646561]
 [ 54.34573364]]
DEBUG:root:training time = %d0.215953
INFO:root:frame =11273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =11274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000501871109009
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.910921666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =11277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =11278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.91089
DEBUG:root: dqn, choose action rondomly, need time 0.000344000000041
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 37.99547958]
 [ 36.33411407]
 [ 26.04330254]
 [ 37.32847214]
 [ 39.69715118]
 [ 36.13415909]
 [ 37.9228096 ]
 [ 49.77916718]
 [ 37.92788315]
 [ 39.64304352]
 [ 38.04459   ]
 [ 56.21693039]
 [ 37.12690735]
 [ 36.92514801]
 [ 34.55768204]
 [ 35.00312424]]
DEBUG:root:training time = %d0.229563
INFO:root:frame =11281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =11282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494003295898
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.910858333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =11285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =11286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487804412842
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.910826666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 38.36497879]
 [ 37.62205887]
 [ 38.24428558]
 [ 36.82683563]
 [ 35.69650269]
 [ 38.32075882]
 [ 41.59881973]
 [ 57.70409393]
 [ 38.37660217]
 [ 36.86481094]
 [ 36.36401367]
 [ 40.2631073 ]
 [ 35.69650269]
 [ 41.62943268]
 [ 26.885149  ]
 [ 36.73790359]]
DEBUG:root:training time = %d0.22436
INFO:root:frame =11289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:frame =11290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.910795
DEBUG:root: dqn, choose action rondomly, need time 0.000238000000024
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331163406372
INFO:root:frame =11293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000540971755981
INFO:root:frame =11294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000285148620605
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.910763333333
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 38.11050034]
 [ 40.6325531 ]
 [ 38.11351776]
 [ 38.43996048]
 [ 50.94070435]
 [ 49.63199997]
 [ 38.17137909]
 [ 41.0776825 ]
 [ 36.25726318]
 [ 36.26930237]
 [ 38.72999573]
 [ 40.05308533]
 [ 37.4899292 ]
 [ 40.12921524]
 [ 40.50183487]
 [ 26.93074036]]
DEBUG:root:training time = %d0.22016
INFO:root:frame =11297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253200531006
INFO:root:frame =11298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000258207321167
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root:random_action_porb = 0.910731666667
DEBUG:root: dqn, choose action rondomly, need time 0.000179000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:frame =11301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000342845916748
INFO:root:frame =11302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9107
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:training error  = [[ 37.1363945 ]
 [ 38.62845612]
 [ 37.92647171]
 [ 34.52423096]
 [ 37.81914139]
 [ 35.62287903]
 [ 38.04581451]
 [ 38.89245605]
 [ 37.04067993]
 [ 35.79840851]
 [ 36.64224243]
 [ 39.56641388]
 [ 37.87846756]
 [ 37.87537003]
 [ 36.51525879]
 [ 40.06795883]]
DEBUG:root:training time = %d0.237323
INFO:root:frame =11305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =11306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.910668333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282000000027
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000346183776855
INFO:root:frame =11309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469207763672
INFO:root:frame =11310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000387907028198
DEBUG:root: save sample needs time = 0.000209808349609
INFO:root:random_action_porb = 0.910636666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 51.86160278]
 [ 39.89631271]
 [ 39.2151413 ]
 [ 38.87218857]
 [ 40.71108246]
 [ 40.38112259]
 [ 40.76980972]
 [ 35.27628708]
 [ 35.0839653 ]
 [ 38.80743027]
 [ 40.2151947 ]
 [ 35.72312927]
 [ 25.52573013]
 [ 52.59303665]
 [ 40.02441025]
 [ 39.51805496]]
DEBUG:root:training time = %d0.234868
INFO:root:frame =11313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:frame =11314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308036804199
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.910605
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =11317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =11318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000526905059814
DEBUG:root: save sample needs time = 0.000171184539795
INFO:root:random_action_porb = 0.910573333333
INFO:root:dqn select action Tensor("ArgMax_138:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012129
INFO:root:action choosen by dqn [4]
INFO:root:frame =11320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000356912612915
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 38.51662827]
 [ 42.17406082]
 [ 37.41578293]
 [ 37.41578293]
 [ 38.96233368]
 [ 37.4829216 ]
 [ 38.71024704]
 [ 38.31915283]
 [ 37.68048096]
 [ 38.3436203 ]
 [ 50.15462494]
 [ 39.02464676]
 [ 38.55992126]
 [ 38.74718475]
 [ 39.87366867]
 [ 39.02464676]]
DEBUG:root:training time = %d0.228989
INFO:root:frame =11321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284194946289
INFO:root:frame =11322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000317096710205
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.910541666667
DEBUG:root: dqn, choose action rondomly, need time 0.000320999999985
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =11325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =11326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:random_action_porb = 0.91051
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 39.83263016]
 [ 36.54947281]
 [ 37.6916275 ]
 [ 28.28835487]
 [ 41.62755966]
 [ 28.28835487]
 [ 39.09579086]
 [ 36.47626495]
 [ 38.75402451]
 [ 38.60493851]
 [ 39.04714584]
 [ 40.75909424]
 [ 37.35243607]
 [ 42.27083206]
 [ 37.71008682]
 [ 41.63228607]]
DEBUG:root:training time = %d0.197793
INFO:root:frame =11329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =11330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000339031219482
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:random_action_porb = 0.910478333333
DEBUG:root: dqn, choose action rondomly, need time 0.000226999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000192880630493
INFO:root:frame =11333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000524997711182
INFO:root:frame =11334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240802764893
DEBUG:root: save sample needs time = 0.000194072723389
INFO:root:random_action_porb = 0.910446666667
INFO:root:dqn select action Tensor("ArgMax_139:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010229
INFO:root:action choosen by dqn [4]
INFO:root:frame =11336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000176906585693
INFO:root:training error  = [[ 39.26159286]
 [ 39.49925613]
 [ 35.95195007]
 [ 37.7026825 ]
 [ 37.95786667]
 [ 38.25051498]
 [ 38.34475327]
 [ 39.64016342]
 [ 36.61564636]
 [ 36.44060898]
 [ 39.32414627]
 [ 37.10850143]
 [ 37.67055511]
 [ 39.24496078]
 [ 40.97437668]
 [ 39.7729454 ]]
DEBUG:root:training time = %d0.190906
INFO:root:frame =11337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =11338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000278949737549
DEBUG:root: save sample needs time = 0.000104188919067
INFO:root:random_action_porb = 0.910415
DEBUG:root: dqn, choose action rondomly, need time 0.000163999999984
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:frame =11341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:frame =11342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00023889541626
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.910383333333
DEBUG:root: dqn, choose action rondomly, need time 0.000370999999973
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000341892242432
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 40.13762665]
 [ 38.4540596 ]
 [ 39.97538376]
 [ 39.60529709]
 [ 37.5400238 ]
 [ 38.85373306]
 [ 37.14569092]
 [ 39.61499786]
 [ 41.22519302]
 [ 41.27968216]
 [ 52.9901619 ]
 [ 40.95650482]
 [ 39.17778778]
 [ 38.04374313]
 [ 37.69303513]
 [ 38.54144669]]
DEBUG:root:training time = %d0.217172
INFO:root:frame =11345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =11346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255823135376
DEBUG:root: save sample needs time = 0.000280857086182
INFO:root:random_action_porb = 0.910351666667
DEBUG:root: dqn, choose action rondomly, need time 0.000408999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =11349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =11350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.91032
DEBUG:root: dqn, choose action rondomly, need time 0.000179000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 37.82627106]
 [ 42.15483856]
 [ 42.01101303]
 [ 51.44552994]
 [ 52.84996796]
 [ 40.18317032]
 [ 39.55029297]
 [ 37.45489883]
 [ 38.22739792]
 [ 36.35453796]
 [ 36.31848145]
 [ 39.85391617]
 [ 37.481987  ]
 [ 38.03207397]
 [ 37.81669998]
 [ 37.89236832]]
DEBUG:root:training time = %d0.215563
INFO:root:frame =11353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000353813171387
INFO:root:frame =11354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.910288333333
INFO:root:dqn select action Tensor("ArgMax_140:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013894
INFO:root:action choosen by dqn [4]
INFO:root:frame =11356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000224828720093
INFO:root:frame =11357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =11358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.910256666667
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 52.25276184]
 [ 52.25276184]
 [ 39.13491821]
 [ 52.80471802]
 [ 42.2840271 ]
 [ 37.59894562]
 [ 39.09846115]
 [ 41.94803619]
 [ 37.59894562]
 [ 40.95845795]
 [ 38.7420578 ]
 [ 39.09426498]
 [ 41.0992012 ]
 [ 38.51246262]
 [ 37.31830978]
 [ 40.51795578]]
DEBUG:root:training time = %d0.228738
INFO:root:frame =11361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =11362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:random_action_porb = 0.910225
DEBUG:root: dqn, choose action rondomly, need time 0.000439000000028
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =11365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000492095947266
INFO:root:frame =11366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.910193333333
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 38.55082321]
 [ 42.92153168]
 [ 51.97220612]
 [ 40.19323349]
 [ 59.02788162]
 [ 42.00666046]
 [ 36.90790558]
 [ 36.50834274]
 [ 41.02176285]
 [ 39.64563751]
 [ 37.7520752 ]
 [ 37.90984344]
 [ 39.35075378]
 [ 42.63899231]
 [ 37.47909164]
 [ 39.67629242]]
DEBUG:root:training time = %d0.22408
INFO:root:frame =11369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =11370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame = 11371 State into memory, numbers recorded 302 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.00055980682373
INFO:root:random_action_porb = 0.910161666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11372current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =11373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame =11374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000513076782227
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:random_action_porb = 0.91013
INFO:root:dqn select action Tensor("ArgMax_141:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014214
INFO:root:action choosen by dqn [4]
INFO:root:frame =11376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 38.6014328 ]
 [ 38.28638458]
 [ 38.28638458]
 [ 40.46911621]
 [ 35.91316986]
 [ 38.91282272]
 [ 37.69968796]
 [ 36.8479538 ]
 [ 40.2530365 ]
 [ 35.67554092]
 [ 40.46911621]
 [ 39.53071976]
 [ 39.58561325]
 [ 40.22303391]
 [ 56.33666611]
 [ 54.91392136]]
DEBUG:root:training time = %d0.224803
INFO:root:frame =11377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =11378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229120254517
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.910098333333
INFO:root:dqn select action Tensor("ArgMax_142:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010566
INFO:root:action choosen by dqn [4]
INFO:root:frame =11380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =11381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =11382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031590461731
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:random_action_porb = 0.910066666667
DEBUG:root: dqn, choose action rondomly, need time 0.000245000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 37.80591202]
 [ 37.01904297]
 [ 37.95166016]
 [ 39.55931091]
 [ 38.25712204]
 [ 43.61740112]
 [ 41.12375641]
 [ 27.68006516]
 [ 43.28869247]
 [ 38.50214386]
 [ 45.08420944]
 [ 39.14599228]
 [ 54.31592941]
 [ 41.11299515]
 [ 42.01417923]
 [ 37.95166016]]
DEBUG:root:training time = %d0.202437
INFO:root:frame =11385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =11386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.910035
DEBUG:root: dqn, choose action rondomly, need time 0.000253999999984
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:frame =11389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000357151031494
INFO:root:frame =11390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000287055969238
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.910003333333
DEBUG:root: dqn, choose action rondomly, need time 0.00022100000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000155925750732
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 38.7256279 ]
 [ 27.98402977]
 [ 37.41587448]
 [ 39.24859238]
 [ 40.71059418]
 [ 38.09138107]
 [ 39.65707397]
 [ 38.75431061]
 [ 39.28291702]
 [ 37.94573975]
 [ 37.781147  ]
 [ 38.94042969]
 [ 38.12152481]
 [ 39.20386505]
 [ 37.781147  ]
 [ 39.1030426 ]]
DEBUG:root:training time = %d0.199188
INFO:root:frame =11393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =11394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424861907959
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:random_action_porb = 0.909971666667
DEBUG:root: dqn, choose action rondomly, need time 0.000224000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:frame =11397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =11398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000748872756958
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.90994
DEBUG:root: dqn, choose action rondomly, need time 0.000175000000013
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 41.29085922]
 [ 41.19218445]
 [ 55.29983902]
 [ 42.06968307]
 [ 38.19231033]
 [ 38.67740631]
 [ 37.96068573]
 [ 36.8284111 ]
 [ 41.24047852]
 [ 38.03866196]
 [ 37.60932922]
 [ 42.96852875]
 [ 41.46950531]
 [ 41.62234497]
 [ 52.34677887]
 [ 41.29085922]]
DEBUG:root:training time = %d0.186183
INFO:root:frame =11401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000355958938599
INFO:root:frame =11402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.909908333333
DEBUG:root: dqn, choose action rondomly, need time 0.000171999999964
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:frame =11405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:frame =11406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000316143035889
DEBUG:root: save sample needs time = 0.000108003616333
INFO:root:random_action_porb = 0.909876666667
DEBUG:root: dqn, choose action rondomly, need time 0.000209000000041
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 42.11621094]
 [ 44.11381149]
 [ 42.76841736]
 [ 43.77293396]
 [ 43.05649185]
 [ 40.36667633]
 [ 42.14879608]
 [ 37.94282532]
 [ 41.59133911]
 [ 46.57902145]
 [ 39.85709763]
 [ 38.60911179]
 [ 53.89481354]
 [ 40.46348572]
 [ 36.57992172]
 [ 40.46960068]]
DEBUG:root:training time = %d0.194512
INFO:root:frame =11409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000342845916748
INFO:root:frame =11410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000561952590942
INFO:root:frame = 11411 State into memory, numbers recorded 303 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000638008117676
INFO:root:random_action_porb = 0.909845
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11412current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =11413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =11414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.909813333333
DEBUG:root: dqn, choose action rondomly, need time 0.000316000000055
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 29.43620491]
 [ 37.06241226]
 [ 38.41328812]
 [ 41.76067352]
 [ 39.085392  ]
 [ 52.42839432]
 [ 39.06850815]
 [ 39.49283218]
 [ 37.82073593]
 [ 39.63679886]
 [ 43.93481064]
 [ 36.98841095]
 [ 39.92176056]
 [ 42.08037186]
 [ 38.36015701]
 [ 42.80414963]]
DEBUG:root:training time = %d0.231558
INFO:root:frame =11417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =11418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488042831421
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:random_action_porb = 0.909781666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000022
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =11421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464200973511
INFO:root:frame =11422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00040602684021
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.90975
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 43.03697205]
 [ 55.32400894]
 [ 41.38671112]
 [ 40.04854584]
 [ 39.54261398]
 [ 37.27516556]
 [ 52.40022659]
 [ 39.14198303]
 [ 41.88826752]
 [ 39.88898849]
 [ 38.64552689]
 [ 40.42292404]
 [ 38.75345612]
 [ 41.56939697]
 [ 41.3073349 ]
 [ 38.85401917]]
DEBUG:root:training time = %d0.213038
INFO:root:frame =11425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002281665802
INFO:root:frame =11426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000699996948242
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.909718333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =11429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00055193901062
INFO:root:frame =11430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000240802764893
INFO:root:random_action_porb = 0.909686666667
DEBUG:root: dqn, choose action rondomly, need time 0.000252999999987
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 38.50110245]
 [ 40.79758453]
 [ 40.96812439]
 [ 40.33943939]
 [ 42.38638687]
 [ 38.64458084]
 [ 42.7076683 ]
 [ 40.88944626]
 [ 42.04603195]
 [ 53.08584213]
 [ 41.52032089]
 [ 39.0394249 ]
 [ 39.91520691]
 [ 40.18404388]
 [ 42.06572342]
 [ 37.61522675]]
DEBUG:root:training time = %d0.237783
INFO:root:frame =11433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =11434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.909655
DEBUG:root: dqn, choose action rondomly, need time 0.000220000000013
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =11437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root:frame =11438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000642061233521
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.909623333333
DEBUG:root: dqn, choose action rondomly, need time 0.000201000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 38.12755203]
 [ 40.69277954]
 [ 37.47330093]
 [ 38.53206635]
 [ 41.6064949 ]
 [ 54.976017  ]
 [ 40.45640182]
 [ 39.56987   ]
 [ 37.75873184]
 [ 38.26901245]
 [ 39.31400681]
 [ 57.64627075]
 [ 53.12998581]
 [ 55.45415115]
 [ 39.66082001]
 [ 39.05363083]]
DEBUG:root:training time = %d0.193683
INFO:root:frame =11441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000191926956177
INFO:root:frame =11442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:random_action_porb = 0.909591666667
DEBUG:root: dqn, choose action rondomly, need time 0.000216000000023
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:frame =11445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =11446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000507116317749
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.90956
DEBUG:root: dqn, choose action rondomly, need time 0.000351000000023
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 37.429039  ]
 [ 38.28647995]
 [ 41.05812454]
 [ 27.2715168 ]
 [ 43.85969543]
 [ 37.429039  ]
 [ 39.37324905]
 [ 37.9986763 ]
 [ 37.00149918]
 [ 42.58978271]
 [ 41.16486359]
 [ 42.64327621]
 [ 39.1133461 ]
 [ 53.05794144]
 [ 40.17998123]
 [ 38.17015076]]
DEBUG:root:training time = %d0.195713
INFO:root:frame =11449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =11450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000410079956055
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:random_action_porb = 0.909528333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =11453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:frame =11454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.909496666667
DEBUG:root: dqn, choose action rondomly, need time 0.000180999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00015115737915
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 40.08428192]
 [ 36.42826843]
 [ 40.57071304]
 [ 39.24562836]
 [ 39.39977646]
 [ 30.12332535]
 [ 40.8336525 ]
 [ 39.59031677]
 [ 42.46530151]
 [ 41.20256424]
 [ 42.31270599]
 [ 39.81298828]
 [ 40.15348053]
 [ 40.44601822]
 [ 39.75476074]
 [ 39.4921608 ]]
DEBUG:root:training time = %d0.18836
INFO:root:frame =11457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root:frame =11458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.909465
DEBUG:root: dqn, choose action rondomly, need time 0.000160000000051
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:frame =11461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =11462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:random_action_porb = 0.909433333333
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000176906585693
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 43.10857391]
 [ 41.55434799]
 [ 51.36993408]
 [ 39.25222397]
 [ 54.75245667]
 [ 39.70984268]
 [ 42.73868561]
 [ 40.60551453]
 [ 41.14352417]
 [ 39.36233521]
 [ 42.8765564 ]
 [ 45.02521515]
 [ 40.50368118]
 [ 43.71601486]
 [ 40.2045517 ]
 [ 41.65473938]]
DEBUG:root:training time = %d0.193721
INFO:root:frame =11465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =11466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000551223754883
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:random_action_porb = 0.909401666667
INFO:root:dqn select action Tensor("ArgMax_143:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011225
INFO:root:action choosen by dqn [4]
INFO:root:frame =11468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =11469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =11470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269174575806
DEBUG:root: save sample needs time = 0.00015115737915
INFO:root:random_action_porb = 0.90937
INFO:root:dqn select action Tensor("ArgMax_144:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00971300000003
INFO:root:action choosen by dqn [4]
INFO:root:frame =11472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 36.50198364]
 [ 39.14656448]
 [ 40.73201752]
 [ 53.34018326]
 [ 38.36318207]
 [ 37.92496872]
 [ 38.61404037]
 [ 40.06138992]
 [ 54.85412216]
 [ 41.37640381]
 [ 42.43776321]
 [ 39.60049438]
 [ 38.56920624]
 [ 40.73201752]
 [ 41.33156204]
 [ 40.39877319]]
DEBUG:root:training time = %d0.188059
INFO:root:frame =11473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =11474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000381946563721
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:random_action_porb = 0.909338333333
DEBUG:root: dqn, choose action rondomly, need time 0.00022899999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =11477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:frame =11478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000258922576904
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:random_action_porb = 0.909306666667
DEBUG:root: dqn, choose action rondomly, need time 0.000404000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 41.84650421]
 [ 40.83530807]
 [ 39.81828308]
 [ 39.81693649]
 [ 39.08558273]
 [ 40.65200806]
 [ 39.13520432]
 [ 54.0514183 ]
 [ 39.88889313]
 [ 41.00720215]
 [ 55.03610992]
 [ 39.80990601]
 [ 40.20019913]
 [ 46.7467308 ]
 [ 40.76299286]
 [ 39.16804886]]
DEBUG:root:training time = %d0.204622
INFO:root:frame =11481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =11482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000300884246826
DEBUG:root: save sample needs time = 0.000180959701538
INFO:root:random_action_porb = 0.909275
DEBUG:root: dqn, choose action rondomly, need time 0.00018399999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000152826309204
INFO:root:frame =11485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =11486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000333070755005
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:random_action_porb = 0.909243333333
DEBUG:root: dqn, choose action rondomly, need time 0.000177000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000152826309204
INFO:root:training error  = [[ 41.48817444]
 [ 40.73211288]
 [ 41.26076508]
 [ 39.69167328]
 [ 39.54347992]
 [ 40.43097687]
 [ 41.96849442]
 [ 41.25939178]
 [ 40.67555237]
 [ 41.67384338]
 [ 38.64742661]
 [ 39.54347992]
 [ 38.54684448]
 [ 40.89256668]
 [ 39.4210434 ]
 [ 40.67555237]]
DEBUG:root:training time = %d0.189502
INFO:root:frame =11489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =11490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000333070755005
DEBUG:root: save sample needs time = 0.000136137008667
INFO:root:random_action_porb = 0.909211666667
DEBUG:root: dqn, choose action rondomly, need time 0.000263000000018
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:frame =11493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =11494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298976898193
DEBUG:root: save sample needs time = 0.000136137008667
INFO:root:random_action_porb = 0.90918
DEBUG:root: dqn, choose action rondomly, need time 0.00022100000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000175952911377
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 40.30833435]
 [ 40.62749481]
 [ 41.14626694]
 [ 40.7325058 ]
 [ 53.99343491]
 [ 44.17200089]
 [ 36.4465065 ]
 [ 37.32175827]
 [ 38.51208496]
 [ 38.98090744]
 [ 39.29965591]
 [ 38.62115479]
 [ 41.79065323]
 [ 40.07336807]
 [ 38.65027237]
 [ 42.63619995]]
DEBUG:root:training time = %d0.193997
INFO:root:frame =11497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:frame =11498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000317811965942
DEBUG:root: save sample needs time = 0.000134944915771
INFO:root:random_action_porb = 0.909148333333
DEBUG:root: dqn, choose action rondomly, need time 0.00024099999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:frame =11501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:frame =11502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000365972518921
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:random_action_porb = 0.909116666667
DEBUG:root: dqn, choose action rondomly, need time 0.00019599999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 40.03483582]
 [ 39.65005875]
 [ 40.47096252]
 [ 42.19596481]
 [ 37.43557358]
 [ 39.05687332]
 [ 39.63334274]
 [ 54.01989746]
 [ 40.45077133]
 [ 41.18121719]
 [ 42.28739929]
 [ 39.69849777]
 [ 40.84915543]
 [ 40.0687294 ]
 [ 44.37770462]
 [ 41.57195663]]
DEBUG:root:training time = %d0.190517
INFO:root:frame =11505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root:frame =11506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000266075134277
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.909085
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =11509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =11510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:random_action_porb = 0.909053333333
DEBUG:root: dqn, choose action rondomly, need time 0.000327999999968
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00015115737915
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 40.81737137]
 [ 43.09705353]
 [ 42.5175209 ]
 [ 55.01154709]
 [ 39.9882164 ]
 [ 55.2682991 ]
 [ 42.27817154]
 [ 42.40864182]
 [ 40.03937149]
 [ 40.68849945]
 [ 40.10418701]
 [ 40.75042343]
 [ 39.74966049]
 [ 41.73730469]
 [ 39.23846054]
 [ 54.41932297]]
DEBUG:root:training time = %d0.187526
INFO:root:frame =11513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =11514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000251054763794
DEBUG:root: save sample needs time = 0.000107049942017
INFO:root:random_action_porb = 0.909021666667
DEBUG:root: dqn, choose action rondomly, need time 0.000200000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =11517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root:frame =11518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324964523315
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root:random_action_porb = 0.90899
DEBUG:root: dqn, choose action rondomly, need time 0.000245000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 40.31763458]
 [ 40.18056107]
 [ 42.0961113 ]
 [ 28.83070183]
 [ 39.71176529]
 [ 43.86636734]
 [ 43.98823166]
 [ 41.19884491]
 [ 41.55739594]
 [ 40.46921158]
 [ 43.67728424]
 [ 41.70852661]
 [ 42.28759766]
 [ 42.06136703]
 [ 40.9450798 ]
 [ 43.27082443]]
DEBUG:root:training time = %d0.186558
INFO:root:frame =11521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000227212905884
INFO:root:frame =11522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.908958333333
INFO:root:dqn select action Tensor("ArgMax_145:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00788399999999
INFO:root:action choosen by dqn [4]
INFO:root:frame =11524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180959701538
INFO:root:frame =11525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =11526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240802764893
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.908926666667
DEBUG:root: dqn, choose action rondomly, need time 0.000164999999981
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:training error  = [[ 43.70431137]
 [ 44.90212631]
 [ 39.94470978]
 [ 39.76120758]
 [ 40.50290298]
 [ 42.82202148]
 [ 39.77371597]
 [ 46.47764587]
 [ 42.07878876]
 [ 42.62743378]
 [ 45.56332397]
 [ 41.28889847]
 [ 41.91226959]
 [ 44.63239288]
 [ 42.83869934]
 [ 41.0957756 ]]
DEBUG:root:training time = %d0.184672
INFO:root:frame =11529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =11530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000392913818359
INFO:root:frame = 11531 State into memory, numbers recorded 304 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000366926193237
INFO:root:random_action_porb = 0.908895
DEBUG:root: dqn, choose action rondomly, need time 0.000238000000024
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11532current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:frame =11533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =11534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240087509155
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.908863333333
DEBUG:root: dqn, choose action rondomly, need time 0.000172999999961
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 42.04751587]
 [ 41.186306  ]
 [ 41.03993988]
 [ 41.66921616]
 [ 40.37869644]
 [ 31.53882599]
 [ 41.5514946 ]
 [ 39.59924698]
 [ 40.19942474]
 [ 42.60711288]
 [ 44.82414627]
 [ 44.82618713]
 [ 43.82181168]
 [ 44.39895248]
 [ 45.90602112]
 [ 39.09044647]]
DEBUG:root:training time = %d0.187841
INFO:root:frame =11537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000353097915649
INFO:root:frame =11538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000292062759399
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:random_action_porb = 0.908831666667
DEBUG:root: dqn, choose action rondomly, need time 0.000200000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000229835510254
INFO:root:frame =11541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =11542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000315189361572
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.9088
DEBUG:root: dqn, choose action rondomly, need time 0.000179000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:training error  = [[ 42.5187149 ]
 [ 43.61598969]
 [ 41.36560822]
 [ 41.18914795]
 [ 41.79844666]
 [ 39.36779404]
 [ 44.60253143]
 [ 39.19383621]
 [ 44.40739059]
 [ 40.19535828]
 [ 41.02596283]
 [ 41.18914795]
 [ 43.84838104]
 [ 40.58062744]
 [ 40.33023071]
 [ 42.356987  ]]
DEBUG:root:training time = %d0.180882
INFO:root:frame =11545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =11546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00023889541626
DEBUG:root: save sample needs time = 0.0001060962677
INFO:root:random_action_porb = 0.908768333333
DEBUG:root: dqn, choose action rondomly, need time 0.000179000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162124633789
INFO:root:frame =11549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =11550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049090385437
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:random_action_porb = 0.908736666667
DEBUG:root: dqn, choose action rondomly, need time 0.000191000000029
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 42.15850449]
 [ 40.20368195]
 [ 40.68849945]
 [ 54.86067581]
 [ 42.08027267]
 [ 40.30659103]
 [ 45.02920532]
 [ 42.64487076]
 [ 39.31352615]
 [ 45.16723633]
 [ 41.89962387]
 [ 40.91608429]
 [ 43.22055435]
 [ 41.16153717]
 [ 40.7647438 ]
 [ 42.35351181]]
DEBUG:root:training time = %d0.185924
INFO:root:frame =11553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =11554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame = 11555 State into memory, numbers recorded 305 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000462770462036
INFO:root:random_action_porb = 0.908705
DEBUG:root: dqn, choose action rondomly, need time 0.000182999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11556current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:frame =11557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259160995483
INFO:root:frame =11558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234127044678
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.908673333333
DEBUG:root: dqn, choose action rondomly, need time 0.000317999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180959701538
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 40.7976799 ]
 [ 58.19927979]
 [ 41.21647263]
 [ 41.13647842]
 [ 42.27708054]
 [ 42.94352722]
 [ 42.05859756]
 [ 39.68792343]
 [ 38.91976929]
 [ 43.40744019]
 [ 40.93531799]
 [ 46.37294769]
 [ 40.93531799]
 [ 40.88173676]
 [ 62.62055206]
 [ 44.5298996 ]]
DEBUG:root:training time = %d0.186422
INFO:root:frame =11561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =11562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.908641666667
INFO:root:dqn select action Tensor("ArgMax_146:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00763699999999
INFO:root:action choosen by dqn [4]
INFO:root:frame =11564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000176191329956
INFO:root:frame =11565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =11566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame = 11567 State into memory, numbers recorded 306 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.000648975372314
INFO:root:random_action_porb = 0.90861
DEBUG:root: dqn, choose action rondomly, need time 0.000162999999986
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11568current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.00015115737915
INFO:root:training error  = [[ 39.85863876]
 [ 40.9961586 ]
 [ 43.37236023]
 [ 40.6820755 ]
 [ 44.11624146]
 [ 39.3721962 ]
 [ 42.16127777]
 [ 42.58152008]
 [ 41.0173645 ]
 [ 42.87985611]
 [ 44.93086243]
 [ 41.22568512]
 [ 40.19226456]
 [ 42.44501877]
 [ 41.61889648]
 [ 43.37236023]]
DEBUG:root:training time = %d0.185134
INFO:root:frame =11569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =11570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000329971313477
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.908578333333
DEBUG:root: dqn, choose action rondomly, need time 0.000275000000045
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =11573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =11574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame = 11575 State into memory, numbers recorded 307 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root:random_action_porb = 0.908546666667
DEBUG:root: dqn, choose action rondomly, need time 0.000245000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11576current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 41.46498489]
 [ 43.18705368]
 [ 42.1905098 ]
 [ 54.92443848]
 [ 43.47945023]
 [ 40.77098083]
 [ 44.53417587]
 [ 43.24683762]
 [ 43.97001648]
 [ 44.65696335]
 [ 29.18490601]
 [ 40.20677567]
 [ 42.94222641]
 [ 40.25177765]
 [ 44.9158287 ]
 [ 43.37195969]]
DEBUG:root:training time = %d0.201813
INFO:root:frame =11577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =11578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
DEBUG:root: save sample needs time = 0.000131130218506
INFO:root:random_action_porb = 0.908515
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999965
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =11581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =11582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000292062759399
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:random_action_porb = 0.908483333333
DEBUG:root: dqn, choose action rondomly, need time 0.000253999999984
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 43.80363083]
 [ 43.08893967]
 [ 43.18725586]
 [ 40.42030334]
 [ 42.26527405]
 [ 47.74751663]
 [ 41.32145691]
 [ 41.3962326 ]
 [ 57.79372787]
 [ 41.55474091]
 [ 40.61154556]
 [ 43.81888199]
 [ 40.80469894]
 [ 40.77828979]
 [ 56.28662872]
 [ 41.88214493]]
DEBUG:root:training time = %d0.198835
INFO:root:frame =11585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000370025634766
INFO:root:frame =11586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000349998474121
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:random_action_porb = 0.908451666667
DEBUG:root: dqn, choose action rondomly, need time 0.000263000000018
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =11589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =11590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248908996582
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root:random_action_porb = 0.90842
DEBUG:root: dqn, choose action rondomly, need time 0.000178000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 43.62637329]
 [ 42.17059326]
 [ 40.26949692]
 [ 41.92195129]
 [ 45.56847382]
 [ 39.67196655]
 [ 46.68426132]
 [ 40.89744568]
 [ 56.54472733]
 [ 57.04506302]
 [ 44.16439819]
 [ 57.4892807 ]
 [ 43.23790741]
 [ 43.74477386]
 [ 43.18083572]
 [ 42.31975555]]
DEBUG:root:training time = %d0.189961
INFO:root:frame =11593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =11594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000130891799927
INFO:root:random_action_porb = 0.908388333333
DEBUG:root: dqn, choose action rondomly, need time 0.000230000000045
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =11597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000497817993164
INFO:root:frame =11598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000250816345215
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:random_action_porb = 0.908356666667
DEBUG:root: dqn, choose action rondomly, need time 0.000208999999984
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 39.77650833]
 [ 42.76133347]
 [ 42.58231735]
 [ 41.64163971]
 [ 41.78404617]
 [ 42.66469955]
 [ 42.073246  ]
 [ 43.53027725]
 [ 43.84282303]
 [ 57.97773361]
 [ 43.83272171]
 [ 42.66141129]
 [ 41.4370842 ]
 [ 41.31733704]
 [ 42.01852798]
 [ 41.99024582]]
DEBUG:root:training time = %d0.20626
INFO:root:frame =11601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000599145889282
INFO:root:frame =11602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031590461731
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.908325
DEBUG:root: dqn, choose action rondomly, need time 0.000256000000036
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:frame =11605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000475168228149
INFO:root:frame =11606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame = 11607 State into memory, numbers recorded 308 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000552892684937
INFO:root:random_action_porb = 0.908293333333
DEBUG:root: dqn, choose action rondomly, need time 0.000586999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11608current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000429153442383
INFO:root:training error  = [[ 43.35035706]
 [ 42.59506226]
 [ 40.27733994]
 [ 42.71883774]
 [ 42.53712082]
 [ 41.24645615]
 [ 42.88485336]
 [ 42.35241699]
 [ 44.46811676]
 [ 39.36185837]
 [ 41.72793961]
 [ 42.30665207]
 [ 41.76511002]
 [ 41.42991257]
 [ 40.95132828]
 [ 43.45218658]]
DEBUG:root:training time = %d0.230223
INFO:root:frame =11609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root:frame =11610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000325918197632
DEBUG:root: save sample needs time = 0.000136852264404
INFO:root:random_action_porb = 0.908261666667
DEBUG:root: dqn, choose action rondomly, need time 0.000197999999955
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:frame =11613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000269174575806
INFO:root:frame =11614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000309944152832
DEBUG:root: save sample needs time = 0.000103950500488
INFO:root:random_action_porb = 0.90823
DEBUG:root: dqn, choose action rondomly, need time 0.000366999999983
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000188112258911
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 40.21529007]
 [ 44.27865219]
 [ 47.15732193]
 [ 40.98355865]
 [ 58.77013397]
 [ 41.9841156 ]
 [ 40.45717621]
 [ 43.87516022]
 [ 45.84907532]
 [ 63.01081085]
 [ 44.32120514]
 [ 58.21336365]
 [ 44.54008484]
 [ 32.91482544]
 [ 40.99987411]
 [ 40.45999146]]
DEBUG:root:training time = %d0.205698
INFO:root:frame =11617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame =11618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000380992889404
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.908198333333
DEBUG:root: dqn, choose action rondomly, need time 0.000177000000008
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000131130218506
INFO:root:frame =11621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000653028488159
INFO:root:frame =11622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045919418335
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.908166666667
DEBUG:root: dqn, choose action rondomly, need time 0.000279000000035
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:training error  = [[ 45.84318542]
 [ 45.05849457]
 [ 44.53713226]
 [ 41.50154495]
 [ 41.50233078]
 [ 48.1776123 ]
 [ 41.08942032]
 [ 41.50233078]
 [ 42.68782806]
 [ 41.83821106]
 [ 45.23894501]
 [ 46.14888   ]
 [ 46.30657578]
 [ 40.55555344]
 [ 39.61038589]
 [ 41.47539902]]
DEBUG:root:training time = %d0.229384
INFO:root:frame =11625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =11626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.908135
DEBUG:root: dqn, choose action rondomly, need time 0.00032699999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000315189361572
INFO:root:frame =11629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =11630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248908996582
DEBUG:root: save sample needs time = 0.000182151794434
INFO:root:random_action_porb = 0.908103333333
DEBUG:root: dqn, choose action rondomly, need time 0.000160999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000146150588989
INFO:root:training error  = [[ 46.87023163]
 [ 44.19948959]
 [ 44.11532974]
 [ 46.35456085]
 [ 42.1883316 ]
 [ 44.08908463]
 [ 40.70796585]
 [ 42.14720917]
 [ 41.82212448]
 [ 45.68257141]
 [ 42.55065918]
 [ 42.92133331]
 [ 41.36688614]
 [ 43.76536179]
 [ 46.40184021]
 [ 42.62504196]]
DEBUG:root:training time = %d0.202631
INFO:root:frame =11633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame =11634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000515937805176
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:random_action_porb = 0.908071666667
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000047
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =11637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =11638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.90804
DEBUG:root: dqn, choose action rondomly, need time 0.000279999999975
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 43.1064682 ]
 [ 43.45782089]
 [ 44.47829056]
 [ 44.67124176]
 [ 46.49501801]
 [ 41.76234818]
 [ 56.11652756]
 [ 56.30632019]
 [ 55.89773178]
 [ 42.57355499]
 [ 39.83031845]
 [ 44.23388672]
 [ 55.89773178]
 [ 42.99333954]
 [ 45.79598236]
 [ 42.41758347]]
DEBUG:root:training time = %d0.230331
INFO:root:frame =11641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =11642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:random_action_porb = 0.908008333333
DEBUG:root: dqn, choose action rondomly, need time 0.000356000000011
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =11645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame =11646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464200973511
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.907976666667
DEBUG:root: dqn, choose action rondomly, need time 0.00032299999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:training error  = [[ 40.62768936]
 [ 44.51065826]
 [ 45.15410995]
 [ 45.14754868]
 [ 41.51579666]
 [ 41.20462036]
 [ 43.26289749]
 [ 45.06105804]
 [ 43.356987  ]
 [ 42.01852798]
 [ 42.11294174]
 [ 44.05828857]
 [ 42.01675034]
 [ 45.14754868]
 [ 42.35023499]
 [ 42.74567032]]
DEBUG:root:training time = %d0.22013
INFO:root:frame =11649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =11650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:random_action_porb = 0.907945
DEBUG:root: dqn, choose action rondomly, need time 0.000319999999988
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =11653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000520944595337
INFO:root:frame =11654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.907913333333
DEBUG:root: dqn, choose action rondomly, need time 0.00064500000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:training error  = [[ 41.8616066 ]
 [ 41.17631912]
 [ 43.31861496]
 [ 42.47902298]
 [ 47.57970428]
 [ 42.98433304]
 [ 42.06216049]
 [ 44.40261078]
 [ 46.72701645]
 [ 43.46949005]
 [ 41.14802933]
 [ 43.2726326 ]
 [ 42.57116318]
 [ 42.82142258]
 [ 44.13104248]
 [ 44.0028038 ]]
DEBUG:root:training time = %d0.207563
INFO:root:frame =11657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =11658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000329971313477
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:random_action_porb = 0.907881666667
DEBUG:root: dqn, choose action rondomly, need time 0.000381000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =11661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000557899475098
INFO:root:frame =11662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.90785
DEBUG:root: dqn, choose action rondomly, need time 0.000674000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000410079956055
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 59.81914139]
 [ 48.68296432]
 [ 43.39336777]
 [ 42.15939713]
 [ 42.72801208]
 [ 43.1583786 ]
 [ 45.53778458]
 [ 42.93202972]
 [ 43.46496201]
 [ 42.74177933]
 [ 43.85494614]
 [ 43.08132935]
 [ 43.0170517 ]
 [ 41.04297256]
 [ 48.12985992]
 [ 44.35717392]]
DEBUG:root:training time = %d0.229945
INFO:root:frame =11665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =11666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000368118286133
DEBUG:root: save sample needs time = 0.000126838684082
INFO:root:random_action_porb = 0.907818333333
DEBUG:root: dqn, choose action rondomly, need time 0.00023699999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root:frame =11669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000683069229126
INFO:root:frame =11670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000312089920044
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:random_action_porb = 0.907786666667
DEBUG:root: dqn, choose action rondomly, need time 0.000279999999975
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:training error  = [[ 43.44102478]
 [ 46.92572021]
 [ 45.35417175]
 [ 45.10798264]
 [ 45.47026062]
 [ 41.68064117]
 [ 45.47026062]
 [ 43.5766983 ]
 [ 47.0672493 ]
 [ 44.05920029]
 [ 41.68064117]
 [ 46.14255905]
 [ 43.46828461]
 [ 44.29672623]
 [ 41.68064117]
 [ 48.63506699]]
DEBUG:root:training time = %d0.200404
INFO:root:frame =11673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =11674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
DEBUG:root: save sample needs time = 0.000110864639282
INFO:root:random_action_porb = 0.907755
DEBUG:root: dqn, choose action rondomly, need time 0.00027799999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00019383430481
INFO:root:frame =11677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000487089157104
INFO:root:frame =11678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000246047973633
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.907723333333
DEBUG:root: dqn, choose action rondomly, need time 0.000199000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:training error  = [[ 45.0372963 ]
 [ 42.34338379]
 [ 41.54549408]
 [ 43.46808243]
 [ 43.44263458]
 [ 41.2782135 ]
 [ 42.73000717]
 [ 43.42201996]
 [ 41.1889534 ]
 [ 43.13893509]
 [ 42.93422699]
 [ 46.78648758]
 [ 44.93536377]
 [ 44.89619446]
 [ 41.09078598]
 [ 43.14695358]]
DEBUG:root:training time = %d0.19228
INFO:root:frame =11681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000365972518921
INFO:root:frame =11682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000300884246826
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.907691666667
DEBUG:root: dqn, choose action rondomly, need time 0.00019599999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:frame =11685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =11686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000220060348511
DEBUG:root: save sample needs time = 0.000173091888428
INFO:root:random_action_porb = 0.90766
DEBUG:root: dqn, choose action rondomly, need time 0.000192999999967
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142812728882
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 44.42254257]
 [ 47.00749588]
 [ 42.21569061]
 [ 44.23429108]
 [ 42.71105957]
 [ 44.23429108]
 [ 42.87056351]
 [ 44.31663513]
 [ 42.77380753]
 [ 57.16429138]
 [ 57.6414032 ]
 [ 39.9895668 ]
 [ 44.15172195]
 [ 58.97103882]
 [ 46.13333511]
 [ 58.17320633]]
DEBUG:root:training time = %d0.188156
INFO:root:frame =11689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =11690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000104188919067
INFO:root:random_action_porb = 0.907628333333
DEBUG:root: dqn, choose action rondomly, need time 0.000199000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:frame =11693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =11694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.907596666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 43.25115585]
 [ 31.76038551]
 [ 43.8356514 ]
 [ 43.48981476]
 [ 42.85787582]
 [ 44.0282135 ]
 [ 42.25019836]
 [ 45.90922546]
 [ 42.75744247]
 [ 42.8474884 ]
 [ 42.64716339]
 [ 42.33285904]
 [ 43.31218719]
 [ 46.41639328]
 [ 56.62139893]
 [ 44.0282135 ]]
DEBUG:root:training time = %d0.211979
INFO:root:frame =11697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =11698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000350952148438
DEBUG:root: save sample needs time = 0.000131130218506
INFO:root:random_action_porb = 0.907565
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000357151031494
INFO:root:frame =11701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =11702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.907533333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:training error  = [[ 43.36512756]
 [ 47.22398758]
 [ 44.58214951]
 [ 43.67335129]
 [ 43.09745407]
 [ 43.21343231]
 [ 44.08705902]
 [ 42.16217041]
 [ 44.49569321]
 [ 43.02095795]
 [ 42.83979797]
 [ 42.78887939]
 [ 42.12829208]
 [ 43.32645035]
 [ 43.41558456]
 [ 43.95028687]]
DEBUG:root:training time = %d0.220284
INFO:root:frame =11705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =11706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame = 11707 State into memory, numbers recorded 309 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000409126281738
INFO:root:random_action_porb = 0.907501666667
INFO:root:dqn select action Tensor("ArgMax_147:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011736
INFO:root:action choosen by dqn [4]
INFO:root:frame =11708current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =11709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =11710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486135482788
INFO:root:frame = 11711 State into memory, numbers recorded 310 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00124406814575
INFO:root:random_action_porb = 0.90747
DEBUG:root: dqn, choose action rondomly, need time 0.000263000000018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11712current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000396013259888
INFO:root:training error  = [[ 44.19908524]
 [ 42.42553711]
 [ 44.39142609]
 [ 42.19080734]
 [ 43.54366684]
 [ 44.31389236]
 [ 44.65196991]
 [ 42.47484589]
 [ 44.55556488]
 [ 40.05231094]
 [ 45.21893311]
 [ 43.98549652]
 [ 42.19080734]
 [ 43.07151413]
 [ 45.84576797]
 [ 44.42396545]]
DEBUG:root:training time = %d0.212142
INFO:root:frame =11713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:frame =11714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:random_action_porb = 0.907438333333
DEBUG:root: dqn, choose action rondomly, need time 0.000253999999984
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =11717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =11718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000492095947266
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.907406666667
DEBUG:root: dqn, choose action rondomly, need time 0.000336000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:training error  = [[ 48.4501915 ]
 [ 46.44696045]
 [ 42.33514023]
 [ 42.52249527]
 [ 44.34609604]
 [ 43.01755524]
 [ 41.74933243]
 [ 42.90563965]
 [ 47.10871506]
 [ 47.04694366]
 [ 44.96431351]
 [ 43.18424606]
 [ 42.18268204]
 [ 45.27353668]
 [ 40.89520264]
 [ 44.28636932]]
DEBUG:root:training time = %d0.234221
INFO:root:frame =11721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =11722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229120254517
DEBUG:root: save sample needs time = 9.41753387451e-05
INFO:root:random_action_porb = 0.907375
DEBUG:root: dqn, choose action rondomly, need time 0.000168000000031
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000137805938721
INFO:root:frame =11725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =11726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.907343333333
DEBUG:root: dqn, choose action rondomly, need time 0.000280999999973
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 44.89292526]
 [ 63.65123367]
 [ 61.60295486]
 [ 41.08628845]
 [ 44.09556961]
 [ 42.24771881]
 [ 45.31030273]
 [ 43.75224304]
 [ 43.2605896 ]
 [ 43.2726326 ]
 [ 44.71663666]
 [ 46.3321228 ]
 [ 45.784832  ]
 [ 45.78080368]
 [ 62.4993782 ]
 [ 44.81127167]]
DEBUG:root:training time = %d0.233502
INFO:root:frame =11729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =11730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000302791595459
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:random_action_porb = 0.907311666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000280857086182
INFO:root:frame =11733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =11734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000548124313354
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:random_action_porb = 0.90728
DEBUG:root: dqn, choose action rondomly, need time 0.000251999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 43.60903931]
 [ 47.72169113]
 [ 43.48760223]
 [ 43.76647568]
 [ 43.56088638]
 [ 45.78328323]
 [ 43.66508102]
 [ 42.89634323]
 [ 48.5694313 ]
 [ 43.07641983]
 [ 46.52228165]
 [ 32.52494049]
 [ 42.68394089]
 [ 41.82439423]
 [ 42.48210526]
 [ 41.10027695]]
DEBUG:root:training time = %d0.229685
INFO:root:frame =11737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =11738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000253915786743
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.907248333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304000000028
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000391960144043
INFO:root:frame =11741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =11742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.907216666667
DEBUG:root: dqn, choose action rondomly, need time 0.000330000000019
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:training error  = [[ 43.6978569 ]
 [ 43.56441116]
 [ 48.35348129]
 [ 45.16313171]
 [ 44.48826599]
 [ 44.06203842]
 [ 47.30979919]
 [ 44.04431534]
 [ 42.36701584]
 [ 46.97558975]
 [ 41.75702286]
 [ 43.56441116]
 [ 50.0430603 ]
 [ 46.39113617]
 [ 45.07068634]
 [ 48.07831955]]
DEBUG:root:training time = %d0.242947
INFO:root:frame =11745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =11746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
DEBUG:root: save sample needs time = 0.000158071517944
INFO:root:random_action_porb = 0.907185
DEBUG:root: dqn, choose action rondomly, need time 0.000185999999985
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174045562744
INFO:root:frame =11749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279188156128
INFO:root:frame =11750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.907153333333
INFO:root:dqn select action Tensor("ArgMax_148:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012261
INFO:root:action choosen by dqn [4]
INFO:root:frame =11752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:training error  = [[ 42.27093124]
 [ 44.74827194]
 [ 46.08142471]
 [ 49.12376404]
 [ 45.23001862]
 [ 47.1307106 ]
 [ 45.89857864]
 [ 42.32183838]
 [ 46.06930542]
 [ 44.06629181]
 [ 41.32234192]
 [ 44.14868164]
 [ 44.97935486]
 [ 49.72922516]
 [ 46.0514946 ]
 [ 46.0057373 ]]
DEBUG:root:training time = %d0.209964
INFO:root:frame =11753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =11754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000663042068481
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root:random_action_porb = 0.907121666667
DEBUG:root: dqn, choose action rondomly, need time 0.000567000000046
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =11757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =11758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000344038009644
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.90709
DEBUG:root: dqn, choose action rondomly, need time 0.000391000000036
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 46.80820084]
 [ 50.        ]
 [ 44.705616  ]
 [ 48.52254486]
 [ 46.80820084]
 [ 42.85377884]
 [ 61.73536301]
 [ 45.2802124 ]
 [ 46.97433853]
 [ 49.72621155]
 [ 60.74047089]
 [ 46.60620499]
 [ 47.17985153]
 [ 46.98510742]
 [ 47.67668915]
 [ 47.2115097 ]]
DEBUG:root:training time = %d0.195128
INFO:root:frame =11761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =11762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.907058333333
DEBUG:root: dqn, choose action rondomly, need time 0.00018300000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174999237061
INFO:root:frame =11765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000327825546265
INFO:root:frame =11766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031304359436
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:random_action_porb = 0.907026666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000041
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 41.47952652]
 [ 46.02561188]
 [ 60.25931931]
 [ 47.11196136]
 [ 43.64985657]
 [ 45.19790268]
 [ 45.34790039]
 [ 46.39560318]
 [ 43.78040695]
 [ 45.86540222]
 [ 44.43810272]
 [ 49.55688477]
 [ 43.13623047]
 [ 47.7245369 ]
 [ 44.1828537 ]
 [ 45.04354477]]
DEBUG:root:training time = %d0.235188
INFO:root:frame =11769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =11770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.906995
DEBUG:root: dqn, choose action rondomly, need time 0.000403000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000392913818359
INFO:root:frame =11773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =11774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000355005264282
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.906963333333
DEBUG:root: dqn, choose action rondomly, need time 0.000384999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 45.48590088]
 [ 47.50868607]
 [ 45.51132584]
 [ 45.16661835]
 [ 45.19749069]
 [ 47.36743546]
 [ 44.63657379]
 [ 43.7854538 ]
 [ 34.14700699]
 [ 49.23258972]
 [ 44.74980545]
 [ 43.64884949]
 [ 45.10726547]
 [ 44.69398499]
 [ 44.16480255]
 [ 45.77006912]]
DEBUG:root:training time = %d0.223895
INFO:root:frame =11777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =11778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000393152236938
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:random_action_porb = 0.906931666667
DEBUG:root: dqn, choose action rondomly, need time 0.000325999999973
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000358819961548
INFO:root:frame =11781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000597953796387
INFO:root:frame =11782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000259160995483
INFO:root:random_action_porb = 0.9069
DEBUG:root: dqn, choose action rondomly, need time 0.000210999999979
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 43.63050461]
 [ 48.07979965]
 [ 45.41317368]
 [ 43.57881546]
 [ 60.48980713]
 [ 45.42458725]
 [ 45.76862335]
 [ 45.83460999]
 [ 44.80871964]
 [ 42.97122955]
 [ 41.64636612]
 [ 42.67526627]
 [ 43.74830627]
 [ 41.67207336]
 [ 45.64947128]
 [ 46.27335358]]
DEBUG:root:training time = %d0.213801
INFO:root:frame =11785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:frame =11786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:random_action_porb = 0.906868333333
DEBUG:root: dqn, choose action rondomly, need time 0.000333999999953
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =11789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00044584274292
INFO:root:frame =11790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.906836666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999963
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:training error  = [[ 46.00387573]
 [ 45.58372116]
 [ 43.27845383]
 [ 43.83140564]
 [ 45.81023407]
 [ 45.00023651]
 [ 42.89194489]
 [ 47.44055557]
 [ 47.16465759]
 [ 46.7187767 ]
 [ 44.56707382]
 [ 48.59197998]
 [ 45.12622452]
 [ 42.80325317]
 [ 44.90232849]
 [ 45.01988983]]
DEBUG:root:training time = %d0.220308
INFO:root:frame =11793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000406980514526
INFO:root:frame =11794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000401973724365
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.906805
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =11797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =11798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.906773333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 43.89790344]
 [ 47.75637436]
 [ 44.20030212]
 [ 45.08205795]
 [ 45.81064606]
 [ 44.96656418]
 [ 44.23449326]
 [ 61.81907272]
 [ 48.19339371]
 [ 45.67658997]
 [ 45.42664719]
 [ 44.26464081]
 [ 46.746418  ]
 [ 40.81415176]
 [ 45.41440964]
 [ 46.01743317]]
DEBUG:root:training time = %d0.217597
INFO:root:frame =11801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274181365967
INFO:root:frame =11802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.906741666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =11805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =11806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436782836914
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.90671
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 46.42876434]
 [ 46.47972488]
 [ 34.55804062]
 [ 44.81832123]
 [ 44.71847153]
 [ 43.47794342]
 [ 46.14566803]
 [ 47.32008743]
 [ 46.93397903]
 [ 44.23459625]
 [ 42.70188522]
 [ 44.21876526]
 [ 45.73631668]
 [ 46.62433243]
 [ 48.85580444]
 [ 45.48909378]]
DEBUG:root:training time = %d0.200477
INFO:root:frame =11809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =11810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504016876221
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.906678333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000048
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =11813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =11814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.906646666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 32.53355408]
 [ 32.53355408]
 [ 42.24761963]
 [ 61.84223175]
 [ 45.30023575]
 [ 47.4911232 ]
 [ 43.94047546]
 [ 48.71554947]
 [ 43.28759003]
 [ 44.87278366]
 [ 45.25701141]
 [ 46.90711594]
 [ 45.41389465]
 [ 47.59696579]
 [ 45.22837448]
 [ 48.67157364]]
DEBUG:root:training time = %d0.222594
INFO:root:frame =11817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =11818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame = 11819 State into memory, numbers recorded 311 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000574827194214
INFO:root:random_action_porb = 0.906615
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11820current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =11821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000423192977905
INFO:root:frame =11822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame = 11823 State into memory, numbers recorded 312 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000545978546143
INFO:root:random_action_porb = 0.906583333333
DEBUG:root: dqn, choose action rondomly, need time 0.000168999999971
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11824current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000150918960571
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 49.68974304]
 [ 45.49104691]
 [ 48.9711647 ]
 [ 41.55533218]
 [ 47.81090546]
 [ 44.09567261]
 [ 58.55859756]
 [ 44.34955215]
 [ 53.06705475]
 [ 47.81544495]
 [ 44.47554398]
 [ 45.91832352]
 [ 45.92990494]
 [ 43.78222275]
 [ 45.55158234]
 [ 49.47700119]]
DEBUG:root:training time = %d0.240241
INFO:root:frame =11825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =11826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame = 11827 State into memory, numbers recorded 313 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000545978546143
INFO:root:random_action_porb = 0.906551666667
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11828current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =11829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =11830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488996505737
INFO:root:frame = 11831 State into memory, numbers recorded 314 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000564813613892
INFO:root:random_action_porb = 0.90652
DEBUG:root: dqn, choose action rondomly, need time 0.000473999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11832current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:training error  = [[ 45.44320297]
 [ 46.62537384]
 [ 44.49477768]
 [ 45.22909164]
 [ 45.92700958]
 [ 50.01435089]
 [ 51.65478134]
 [ 46.63475418]
 [ 46.27688217]
 [ 43.9479599 ]
 [ 47.92914963]
 [ 44.85612488]
 [ 43.9479599 ]
 [ 46.3731575 ]
 [ 50.4793396 ]
 [ 48.66869736]]
DEBUG:root:training time = %d0.218897
INFO:root:frame =11833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:frame =11834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.906488333333
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =11837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =11838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.906456666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 45.07191467]
 [ 48.91469574]
 [ 46.08007812]
 [ 43.42754745]
 [ 47.87138367]
 [ 48.60261536]
 [ 50.53778839]
 [ 45.40309906]
 [ 46.92707825]
 [ 60.60319519]
 [ 47.53287888]
 [ 48.0969429 ]
 [ 45.07191467]
 [ 45.10501099]
 [ 47.45117188]
 [ 36.48354721]]
DEBUG:root:training time = %d0.220261
INFO:root:frame =11841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =11842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.906425
DEBUG:root: dqn, choose action rondomly, need time 0.000177000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:frame =11845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270843505859
INFO:root:frame =11846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame = 11847 State into memory, numbers recorded 315 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:random_action_porb = 0.906393333333
DEBUG:root: dqn, choose action rondomly, need time 0.000181999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11848current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000172853469849
INFO:root:training error  = [[ 47.55791855]
 [ 45.03012848]
 [ 51.63712692]
 [ 42.766922  ]
 [ 47.59570312]
 [ 49.86403656]
 [ 47.36428452]
 [ 46.09820557]
 [ 43.52846527]
 [ 47.87275314]
 [ 46.01226044]
 [ 47.30423737]
 [ 46.5053215 ]
 [ 45.35756302]
 [ 46.29660797]
 [ 45.45256424]]
DEBUG:root:training time = %d0.222715
INFO:root:frame =11849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274181365967
INFO:root:frame =11850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000296115875244
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:random_action_porb = 0.906361666667
DEBUG:root: dqn, choose action rondomly, need time 0.000201000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root:frame =11853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =11854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00057315826416
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.90633
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 45.1636467 ]
 [ 48.16479874]
 [ 48.15283203]
 [ 46.88893509]
 [ 49.2596817 ]
 [ 46.20819092]
 [ 32.99760437]
 [ 63.08702087]
 [ 46.15862656]
 [ 50.6247139 ]
 [ 47.21371078]
 [ 45.05255508]
 [ 47.13228226]
 [ 45.66287231]
 [ 49.7881012 ]
 [ 46.20819092]]
DEBUG:root:training time = %d0.237536
INFO:root:frame =11857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471830368042
INFO:root:frame =11858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.906298333333
DEBUG:root: dqn, choose action rondomly, need time 0.000357000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000361919403076
INFO:root:frame =11861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =11862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:random_action_porb = 0.906266666667
DEBUG:root: dqn, choose action rondomly, need time 0.000179000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 44.1318512 ]
 [ 49.27146149]
 [ 45.5370636 ]
 [ 46.1205864 ]
 [ 47.5095253 ]
 [ 44.33888245]
 [ 61.11051941]
 [ 47.19085693]
 [ 45.90478134]
 [ 47.35525513]
 [ 47.24758148]
 [ 46.76457214]
 [ 61.29029083]
 [ 44.19076538]
 [ 45.66297913]
 [ 44.48551559]]
DEBUG:root:training time = %d0.208065
INFO:root:frame =11865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =11866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.906235
DEBUG:root: dqn, choose action rondomly, need time 0.000243000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00015115737915
INFO:root:frame =11869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000549077987671
INFO:root:frame =11870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.906203333333
DEBUG:root: dqn, choose action rondomly, need time 0.000171999999964
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:training error  = [[ 46.29473877]
 [ 47.54876328]
 [ 44.31368637]
 [ 50.20791626]
 [ 47.58475494]
 [ 45.88824081]
 [ 44.55067444]
 [ 49.48698425]
 [ 43.78525162]
 [ 47.02820969]
 [ 44.65696335]
 [ 46.15074921]
 [ 44.39671326]
 [ 45.58753204]
 [ 46.42678833]
 [ 46.83336258]]
DEBUG:root:training time = %d0.220033
INFO:root:frame =11873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =11874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.906171666667
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999949
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =11877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =11878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000307083129883
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.90614
DEBUG:root: dqn, choose action rondomly, need time 0.000323000000037
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 44.55678558]
 [ 45.13483429]
 [ 48.38128281]
 [ 64.03943634]
 [ 45.25978088]
 [ 48.65507507]
 [ 43.16940689]
 [ 45.52553177]
 [ 44.83916473]
 [ 46.33472061]
 [ 48.7035141 ]
 [ 47.08934021]
 [ 44.86297226]
 [ 46.0619545 ]
 [ 46.46984482]
 [ 48.20843887]]
DEBUG:root:training time = %d0.231012
INFO:root:frame =11881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000358104705811
INFO:root:frame =11882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000334024429321
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.906108333333
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000045
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =11885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =11886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000352144241333
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.906076666667
INFO:root:dqn select action Tensor("ArgMax_149:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00974000000002
INFO:root:action choosen by dqn [4]
INFO:root:frame =11888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 49.23398209]
 [ 48.97041702]
 [ 51.07278442]
 [ 47.22597885]
 [ 34.5116806 ]
 [ 48.68690491]
 [ 50.52737427]
 [ 48.88876724]
 [ 48.26937485]
 [ 44.84539795]
 [ 46.56142426]
 [ 44.36926651]
 [ 45.69360733]
 [ 46.17614746]
 [ 44.53549957]
 [ 46.04714584]]
DEBUG:root:training time = %d0.226698
INFO:root:frame =11889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =11890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249862670898
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.906045
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999976
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =11893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465154647827
INFO:root:frame =11894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.906013333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 45.04200745]
 [ 52.05573273]
 [ 48.97287369]
 [ 63.09235382]
 [ 45.19123459]
 [ 47.27422714]
 [ 44.84376144]
 [ 63.35806274]
 [ 51.05370331]
 [ 43.88920975]
 [ 47.72769928]
 [ 47.72769928]
 [ 45.31214905]
 [ 49.25475693]
 [ 44.36296463]
 [ 47.44539261]]
DEBUG:root:training time = %d0.225448
INFO:root:frame =11897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:frame =11898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000329971313477
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.905981666667
DEBUG:root: dqn, choose action rondomly, need time 0.00032200000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =11901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =11902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.90595
DEBUG:root: dqn, choose action rondomly, need time 0.000217000000021
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000189065933228
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 46.6068306 ]
 [ 46.39061737]
 [ 51.78240204]
 [ 52.60012054]
 [ 50.26848221]
 [ 45.43775177]
 [ 46.97862625]
 [ 51.21300507]
 [ 61.2711792 ]
 [ 46.94118881]
 [ 46.84318161]
 [ 46.42221451]
 [ 45.67215347]
 [ 49.09938431]
 [ 44.90529633]
 [ 60.41731644]]
DEBUG:root:training time = %d0.218823
INFO:root:frame =11905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =11906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.905918333333
INFO:root:dqn select action Tensor("ArgMax_150:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012831
INFO:root:action choosen by dqn [4]
INFO:root:frame =11908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:frame =11909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:frame =11910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.905886666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[ 51.06460571]
 [ 51.39902878]
 [ 46.23796463]
 [ 44.71081924]
 [ 47.16056824]
 [ 47.40672302]
 [ 46.67144012]
 [ 47.09289932]
 [ 51.22698593]
 [ 47.36050415]
 [ 48.43086243]
 [ 46.14318085]
 [ 42.25416565]
 [ 49.93798065]
 [ 50.92295456]
 [ 48.69797516]]
DEBUG:root:training time = %d0.234623
INFO:root:frame =11913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =11914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:random_action_porb = 0.905855
DEBUG:root: dqn, choose action rondomly, need time 0.000360000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =11917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =11918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.905823333333
DEBUG:root: dqn, choose action rondomly, need time 0.000335000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 44.26768494]
 [ 47.48407745]
 [ 48.33639908]
 [ 47.33677673]
 [ 68.5710144 ]
 [ 50.45668411]
 [ 52.73743439]
 [ 49.00448608]
 [ 50.46253586]
 [ 47.80278397]
 [ 49.09275436]
 [ 45.8139534 ]
 [ 47.80278397]
 [ 51.86786652]
 [ 61.88471603]
 [ 47.63329315]]
DEBUG:root:training time = %d0.229694
INFO:root:frame =11921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000377893447876
INFO:root:frame =11922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.905791666667
DEBUG:root: dqn, choose action rondomly, need time 0.000562000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =11924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =11925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =11926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.90576
DEBUG:root: dqn, choose action rondomly, need time 0.000537000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 47.48765182]
 [ 46.90795135]
 [ 46.13136673]
 [ 42.49593353]
 [ 52.73433304]
 [ 47.06442261]
 [ 52.0341568 ]
 [ 35.99121094]
 [ 46.7820015 ]
 [ 44.57461166]
 [ 48.23015976]
 [ 47.64361191]
 [ 49.22284698]
 [ 46.88935089]
 [ 45.73281097]
 [ 47.70809174]]
DEBUG:root:training time = %d0.223985
INFO:root:frame =11929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:frame =11930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame = 11931 State into memory, numbers recorded 316 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000562191009521
INFO:root:random_action_porb = 0.905728333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11932current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =11933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =11934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047779083252
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.905696666667
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 54.13614655]
 [ 50.50677109]
 [ 47.93284607]
 [ 48.06816483]
 [ 46.4209671 ]
 [ 50.50677109]
 [ 62.34313965]
 [ 50.30765152]
 [ 48.34276581]
 [ 48.16024399]
 [ 61.09262848]
 [ 49.52176666]
 [ 46.80913925]
 [ 45.24890137]
 [ 48.36844254]
 [ 51.98067474]]
DEBUG:root:training time = %d0.245714
INFO:root:frame =11937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270128250122
INFO:root:frame =11938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275850296021
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root:random_action_porb = 0.905665
DEBUG:root: dqn, choose action rondomly, need time 0.000254999999981
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =11941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =11942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.905633333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 47.06295776]
 [ 46.28882217]
 [ 45.18877411]
 [ 50.07976532]
 [ 49.55806732]
 [ 46.62245941]
 [ 49.41466141]
 [ 45.18877411]
 [ 48.61453247]
 [ 47.14590073]
 [ 49.54668427]
 [ 44.92411041]
 [ 49.13467407]
 [ 46.78784561]
 [ 49.13467407]
 [ 60.07385254]]
DEBUG:root:training time = %d0.232376
INFO:root:frame =11945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:frame =11946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000372886657715
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.905601666667
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000021
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:frame =11949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =11950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.90557
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:training error  = [[ 50.9260025 ]
 [ 47.70240021]
 [ 46.64162827]
 [ 45.32036972]
 [ 52.38410187]
 [ 44.62026215]
 [ 47.94235229]
 [ 47.23541641]
 [ 48.073452  ]
 [ 48.1998558 ]
 [ 52.57112885]
 [ 47.32040024]
 [ 45.84494019]
 [ 48.16384506]
 [ 50.81716919]
 [ 45.34379196]]
DEBUG:root:training time = %d0.242639
INFO:root:frame =11953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =11954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000408887863159
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:random_action_porb = 0.905538333333
INFO:root:dqn select action Tensor("ArgMax_151:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011202
INFO:root:action choosen by dqn [4]
INFO:root:frame =11956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000269174575806
INFO:root:frame =11957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:frame =11958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.905506666667
INFO:root:dqn select action Tensor("ArgMax_152:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010844
INFO:root:action choosen by dqn [4]
INFO:root:frame =11960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000192880630493
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 46.7970314 ]
 [ 49.91835785]
 [ 47.14904404]
 [ 50.63763428]
 [ 47.07007599]
 [ 51.02230835]
 [ 50.47966385]
 [ 47.73275757]
 [ 50.23429871]
 [ 47.21863937]
 [ 63.99414062]
 [ 49.66382217]
 [ 48.61304092]
 [ 47.96412277]
 [ 66.29288483]
 [ 47.45674515]]
DEBUG:root:training time = %d0.235383
INFO:root:frame =11961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =11962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:random_action_porb = 0.905475
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000043
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =11965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =11966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.905443333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000031
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:training error  = [[ 45.88131714]
 [ 51.22239685]
 [ 44.2104454 ]
 [ 47.19054413]
 [ 52.62446976]
 [ 48.9047699 ]
 [ 48.27467728]
 [ 49.43204117]
 [ 47.67500305]
 [ 53.46038437]
 [ 46.41202927]
 [ 45.43096542]
 [ 44.21673584]
 [ 47.33026886]
 [ 52.10815048]
 [ 52.70043182]]
DEBUG:root:training time = %d0.231356
INFO:root:frame =11969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =11970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000329971313477
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.905411666667
DEBUG:root: dqn, choose action rondomly, need time 0.000193000000024
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000170230865479
INFO:root:frame =11973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =11974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame = 11975 State into memory, numbers recorded 317 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000858068466187
INFO:root:random_action_porb = 0.90538
DEBUG:root: dqn, choose action rondomly, need time 0.000308999999959
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =11976current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 49.6109314 ]
 [ 51.89797974]
 [ 45.5921669 ]
 [ 50.68542099]
 [ 49.92935181]
 [ 64.63217163]
 [ 51.16846466]
 [ 53.57804108]
 [ 53.78374481]
 [ 48.25050735]
 [ 48.36738205]
 [ 48.95920563]
 [ 51.74485779]
 [ 35.4033699 ]
 [ 44.796772  ]
 [ 45.43981171]]
DEBUG:root:training time = %d0.223064
INFO:root:frame =11977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270843505859
INFO:root:frame =11978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.905348333333
DEBUG:root: dqn, choose action rondomly, need time 0.000267000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =11980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =11981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =11982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:random_action_porb = 0.905316666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 45.52954865]
 [ 49.95652771]
 [ 48.6202774 ]
 [ 51.12001419]
 [ 47.25828171]
 [ 47.66109848]
 [ 50.20466995]
 [ 47.56423187]
 [ 46.03627396]
 [ 50.54343033]
 [ 49.61007309]
 [ 47.80974579]
 [ 49.98715973]
 [ 46.1510582 ]
 [ 68.48082733]
 [ 49.18153381]]
DEBUG:root:training time = %d0.232266
INFO:root:frame =11985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =11986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480890274048
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.905285
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999964
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =11988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =11989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =11990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.905253333333
INFO:root:dqn select action Tensor("ArgMax_153:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010396
INFO:root:action choosen by dqn [4]
INFO:root:frame =11992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000380039215088
INFO:root:training error  = [[ 47.29332352]
 [ 48.82562637]
 [ 43.67193985]
 [ 49.28752899]
 [ 48.63708878]
 [ 47.18656158]
 [ 48.71757126]
 [ 49.93948746]
 [ 46.31976318]
 [ 46.76655579]
 [ 45.02296066]
 [ 49.40028763]
 [ 47.72579956]
 [ 45.34625626]
 [ 51.40471649]
 [ 48.41238785]]
DEBUG:root:training time = %d0.228206
INFO:root:frame =11993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =11994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.905221666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =11996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =11997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000516891479492
INFO:root:frame =11998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000201940536499
DEBUG:root:one frame running time = 0.00566899999995
DEBUG:root:total training time = 352.387641
INFO:root:frame num = 12000 frame round: 0
INFO:root:random_action_porb = 0.90519
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 49.18431473]
 [ 48.73269653]
 [ 47.90538406]
 [ 44.20821381]
 [ 49.94940948]
 [ 66.3291626 ]
 [ 47.88531876]
 [ 50.23667908]
 [ 49.14922333]
 [ 50.86765289]
 [ 49.12226868]
 [ 49.33039093]
 [ 48.52902985]
 [ 65.55498505]
 [ 49.98112106]
 [ 49.18431473]]
DEBUG:root:training time = %d0.240294
INFO:root:frame =12001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =12002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504016876221
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.905158333333
INFO:root:dqn select action Tensor("ArgMax_154:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012127
INFO:root:action choosen by dqn [4]
INFO:root:frame =12004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =12005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =12006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000109910964966
INFO:root:random_action_porb = 0.905126666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 47.77936554]
 [ 52.53528976]
 [ 46.44384384]
 [ 49.34217834]
 [ 50.82391357]
 [ 48.22380066]
 [ 46.09281921]
 [ 51.98947906]
 [ 46.62079239]
 [ 49.50673676]
 [ 47.21633148]
 [ 46.19750977]
 [ 47.35756683]
 [ 48.77488708]
 [ 37.0815506 ]
 [ 54.07217407]]
DEBUG:root:training time = %d0.225591
INFO:root:frame =12009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =12010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000329971313477
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:random_action_porb = 0.905095
DEBUG:root: dqn, choose action rondomly, need time 0.000337999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =12013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =12014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000187873840332
INFO:root:random_action_porb = 0.905063333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999955
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 50.84893799]
 [ 62.93101501]
 [ 48.53689575]
 [ 48.33979416]
 [ 48.65262604]
 [ 47.51015854]
 [ 51.36293411]
 [ 47.31767273]
 [ 48.18926239]
 [ 47.1926384 ]
 [ 46.83127594]
 [ 49.89205551]
 [ 49.00448608]
 [ 48.65262604]
 [ 47.04349136]
 [ 50.65240479]]
DEBUG:root:training time = %d0.248877
INFO:root:frame =12017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =12018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.905031666667
INFO:root:dqn select action Tensor("ArgMax_155:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011078
INFO:root:action choosen by dqn [4]
INFO:root:frame =12020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000270128250122
INFO:root:frame =12021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =12022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000333786010742
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:random_action_porb = 0.905
INFO:root:dqn select action Tensor("ArgMax_156:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012119
INFO:root:action choosen by dqn [4]
INFO:root:frame =12024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000385046005249
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 49.01153564]
 [ 50.44736099]
 [ 50.86678314]
 [ 49.9509201 ]
 [ 50.99419022]
 [ 47.73591995]
 [ 46.34074402]
 [ 49.52692032]
 [ 47.74583054]
 [ 36.53001404]
 [ 47.6341362 ]
 [ 51.1835289 ]
 [ 36.53001404]
 [ 50.65631104]
 [ 47.95059586]
 [ 46.5045929 ]]
DEBUG:root:training time = %d0.208494
INFO:root:frame =12025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:frame =12026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:random_action_porb = 0.904968333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000043
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =12029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root:frame =12030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.904936666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999952
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 49.63243103]
 [ 48.22083282]
 [ 47.8671608 ]
 [ 49.44942093]
 [ 50.07048035]
 [ 47.87877274]
 [ 48.42746353]
 [ 46.72253036]
 [ 65.96653748]
 [ 51.02056503]
 [ 50.25701523]
 [ 53.73183441]
 [ 49.3434639 ]
 [ 47.69713211]
 [ 49.19287872]
 [ 65.0216217 ]]
DEBUG:root:training time = %d0.222834
INFO:root:frame =12033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =12034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.904905
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =12037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =12038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.904873333333
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000026
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 49.71609879]
 [ 48.3835144 ]
 [ 52.61871338]
 [ 51.84830475]
 [ 37.18494797]
 [ 49.49471283]
 [ 48.47908401]
 [ 49.62791443]
 [ 48.95664597]
 [ 49.51038742]
 [ 46.78554916]
 [ 49.10922241]
 [ 45.92121887]
 [ 50.14090347]
 [ 49.51038742]
 [ 51.85358047]]
DEBUG:root:training time = %d0.250147
INFO:root:frame =12041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =12042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.904841666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290999999947
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000379085540771
INFO:root:frame =12045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =12046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000592947006226
INFO:root:frame = 12047 State into memory, numbers recorded 318 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.00056791305542
INFO:root:random_action_porb = 0.90481
DEBUG:root: dqn, choose action rondomly, need time 0.000567999999987
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12048current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:training error  = [[ 51.34915543]
 [ 50.3215065 ]
 [ 48.67625809]
 [ 49.9772377 ]
 [ 53.28380585]
 [ 51.76769257]
 [ 51.23616028]
 [ 49.29867172]
 [ 48.39922333]
 [ 51.57486725]
 [ 51.20623779]
 [ 50.4040184 ]
 [ 50.07436752]
 [ 48.97565079]
 [ 51.9536171 ]
 [ 50.96869659]]
DEBUG:root:training time = %d0.214273
INFO:root:frame =12049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =12050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame = 12051 State into memory, numbers recorded 319 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000575065612793
INFO:root:random_action_porb = 0.904778333333
DEBUG:root: dqn, choose action rondomly, need time 0.000370999999973
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12052current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =12053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =12054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.904746666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 48.49332047]
 [ 49.64554596]
 [ 48.28209686]
 [ 48.20155334]
 [ 50.11194992]
 [ 50.20207596]
 [ 47.89799118]
 [ 51.26434326]
 [ 36.65332794]
 [ 52.15794754]
 [ 48.5252037 ]
 [ 49.77292252]
 [ 49.76861572]
 [ 51.66761398]
 [ 50.80281448]
 [ 48.72353745]]
DEBUG:root:training time = %d0.228639
INFO:root:frame =12057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =12058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000282049179077
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.904715
DEBUG:root: dqn, choose action rondomly, need time 0.000477999999987
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =12061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =12062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:random_action_porb = 0.904683333333
DEBUG:root: dqn, choose action rondomly, need time 0.000520999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 48.78682327]
 [ 63.45818329]
 [ 51.16627884]
 [ 53.21989059]
 [ 54.5606842 ]
 [ 50.05925369]
 [ 51.88874817]
 [ 49.21878052]
 [ 47.48113251]
 [ 65.0226059 ]
 [ 49.44405746]
 [ 49.46401596]
 [ 49.07094955]
 [ 50.47901154]
 [ 49.54453278]
 [ 48.55156708]]
DEBUG:root:training time = %d0.228701
INFO:root:frame =12065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:frame =12066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235795974731
DEBUG:root: save sample needs time = 0.000108957290649
INFO:root:random_action_porb = 0.904651666667
DEBUG:root: dqn, choose action rondomly, need time 0.000246000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:frame =12069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =12070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00022292137146
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.90462
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[ 49.84313583]
 [ 48.35167694]
 [ 55.76285553]
 [ 50.4707756 ]
 [ 48.67923737]
 [ 52.08854294]
 [ 48.20176315]
 [ 50.22110748]
 [ 49.23783493]
 [ 49.81900787]
 [ 49.56924057]
 [ 49.76753998]
 [ 52.05793381]
 [ 47.03490829]
 [ 52.33110428]
 [ 49.84313583]]
DEBUG:root:training time = %d0.233234
INFO:root:frame =12073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =12074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000146865844727
INFO:root:random_action_porb = 0.904588333333
DEBUG:root: dqn, choose action rondomly, need time 0.000194000000022
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000181913375854
INFO:root:frame =12077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =12078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000354051589966
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.904556666667
DEBUG:root: dqn, choose action rondomly, need time 0.00032699999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:training error  = [[ 49.72190857]
 [ 53.37495804]
 [ 50.11497498]
 [ 50.43912506]
 [ 45.60041046]
 [ 50.43349075]
 [ 48.90327835]
 [ 49.8564949 ]
 [ 54.22038269]
 [ 52.6928978 ]
 [ 49.46229935]
 [ 48.74249649]
 [ 51.08750534]
 [ 53.00060272]
 [ 50.03010559]
 [ 47.33950806]]
DEBUG:root:training time = %d0.252452
INFO:root:frame =12081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =12082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000116109848022
INFO:root:random_action_porb = 0.904525
DEBUG:root: dqn, choose action rondomly, need time 0.000344000000041
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =12085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440835952759
INFO:root:frame =12086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.904493333333
DEBUG:root: dqn, choose action rondomly, need time 0.000528000000031
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:training error  = [[ 50.86134338]
 [ 52.94218826]
 [ 52.7846489 ]
 [ 51.42944336]
 [ 50.63068771]
 [ 53.33394241]
 [ 51.62309265]
 [ 51.36206055]
 [ 50.52477264]
 [ 53.7879982 ]
 [ 47.12494659]
 [ 49.11200333]
 [ 49.50845337]
 [ 47.23709488]
 [ 49.45135117]
 [ 51.95955658]]
DEBUG:root:training time = %d0.249613
INFO:root:frame =12089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =12090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000261068344116
DEBUG:root: save sample needs time = 0.000120878219604
INFO:root:random_action_porb = 0.904461666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:frame =12093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =12094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:random_action_porb = 0.90443
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999983
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000379085540771
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 49.27189255]
 [ 56.74731064]
 [ 55.2007103 ]
 [ 36.50806808]
 [ 50.79998779]
 [ 49.94919205]
 [ 46.94474411]
 [ 55.20297623]
 [ 52.03173447]
 [ 50.51045609]
 [ 56.36083221]
 [ 46.94474411]
 [ 38.10127258]
 [ 53.63389969]
 [ 51.03495026]
 [ 51.32269669]]
DEBUG:root:training time = %d0.220136
INFO:root:frame =12097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =12098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000343084335327
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:random_action_porb = 0.904398333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =12101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000562906265259
INFO:root:frame =12102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.904366666667
INFO:root:dqn select action Tensor("ArgMax_157:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012285
INFO:root:action choosen by dqn [4]
INFO:root:frame =12104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:training error  = [[ 48.65326309]
 [ 53.90736008]
 [ 55.27623749]
 [ 52.86139297]
 [ 50.83392334]
 [ 47.9379158 ]
 [ 54.60487366]
 [ 50.81716919]
 [ 49.17853928]
 [ 49.84119415]
 [ 54.60509872]
 [ 52.61384201]
 [ 47.65688324]
 [ 49.61651993]
 [ 53.40639877]
 [ 50.18153763]]
DEBUG:root:training time = %d0.22352
INFO:root:frame =12105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:frame =12106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000503063201904
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.904335
DEBUG:root: dqn, choose action rondomly, need time 0.000357000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =12109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000492811203003
INFO:root:frame =12110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294923782349
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.904303333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000031
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 69.24385071]
 [ 52.41016769]
 [ 53.5085907 ]
 [ 51.30192947]
 [ 53.55793762]
 [ 49.95609665]
 [ 50.80433655]
 [ 52.87093353]
 [ 51.76351929]
 [ 54.35776901]
 [ 49.2014389 ]
 [ 51.23069763]
 [ 50.10330963]
 [ 51.50366211]
 [ 53.03393555]
 [ 53.89234924]]
DEBUG:root:training time = %d0.22467
INFO:root:frame =12113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =12114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000385046005249
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.904271666667
DEBUG:root: dqn, choose action rondomly, need time 0.000504000000035
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =12117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000619888305664
INFO:root:frame =12118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000615119934082
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:random_action_porb = 0.90424
DEBUG:root: dqn, choose action rondomly, need time 0.000237000000027
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 50.61092758]
 [ 51.0373497 ]
 [ 53.13154602]
 [ 50.00744629]
 [ 50.05860519]
 [ 49.61695099]
 [ 48.96561432]
 [ 54.42078781]
 [ 51.93909836]
 [ 50.95671463]
 [ 50.76584244]
 [ 51.53695679]
 [ 65.63902283]
 [ 50.69367981]
 [ 51.06765747]
 [ 65.61380768]]
DEBUG:root:training time = %d0.221331
INFO:root:frame =12121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029182434082
INFO:root:frame =12122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.904208333333
INFO:root:dqn select action Tensor("ArgMax_158:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010993
INFO:root:action choosen by dqn [4]
INFO:root:frame =12124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029182434082
INFO:root:frame =12125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000377178192139
INFO:root:frame =12126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000590085983276
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.904176666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325202941895
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 50.31414413]
 [ 50.05709457]
 [ 52.62004089]
 [ 50.43955994]
 [ 52.72879028]
 [ 72.27386475]
 [ 51.2807312 ]
 [ 54.79875946]
 [ 52.71970749]
 [ 50.03269958]
 [ 52.66521072]
 [ 50.90096283]
 [ 50.05709457]
 [ 49.9724884 ]
 [ 54.78294754]
 [ 50.43955994]]
DEBUG:root:training time = %d0.200684
INFO:root:frame =12129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =12130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.904145
DEBUG:root: dqn, choose action rondomly, need time 0.000433999999984
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:frame =12133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =12134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.904113333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999964
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 48.62559509]
 [ 51.5943718 ]
 [ 53.56754303]
 [ 46.90251923]
 [ 53.59613419]
 [ 55.01358414]
 [ 52.84564209]
 [ 66.09152222]
 [ 64.61475372]
 [ 51.25057602]
 [ 48.72140503]
 [ 51.24423981]
 [ 54.44420242]
 [ 50.92578506]
 [ 56.58695984]
 [ 50.63915634]]
DEBUG:root:training time = %d0.225938
INFO:root:frame =12137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =12138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.904081666667
DEBUG:root: dqn, choose action rondomly, need time 0.000457999999981
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =12141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =12142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:random_action_porb = 0.90405
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[ 51.43447876]
 [ 49.99061203]
 [ 50.53475189]
 [ 52.56648254]
 [ 50.12405014]
 [ 52.53705978]
 [ 47.66657639]
 [ 54.14558029]
 [ 49.48719788]
 [ 50.38257217]
 [ 51.87841415]
 [ 59.2093811 ]
 [ 54.7192688 ]
 [ 51.06591415]
 [ 50.20207596]
 [ 51.74749374]]
DEBUG:root:training time = %d0.212652
INFO:root:frame =12145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:frame =12146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.904018333333
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999966
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =12149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =12150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.903986666667
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000352144241333
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 66.9000473 ]
 [ 53.02659988]
 [ 56.37182999]
 [ 50.52585602]
 [ 55.18234634]
 [ 53.67882919]
 [ 53.41621017]
 [ 52.92731094]
 [ 53.67681885]
 [ 54.11190033]
 [ 50.46665573]
 [ 46.92572021]
 [ 54.02842331]
 [ 51.37124634]
 [ 51.62265396]
 [ 51.71083832]]
DEBUG:root:training time = %d0.221414
INFO:root:frame =12153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =12154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.903955
DEBUG:root: dqn, choose action rondomly, need time 0.000174000000015
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:frame =12157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =12158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000276803970337
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.903923333333
DEBUG:root: dqn, choose action rondomly, need time 0.00017600000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000130891799927
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 53.75263977]
 [ 51.39005661]
 [ 51.25953293]
 [ 51.91139221]
 [ 52.1317215 ]
 [ 51.9489975 ]
 [ 50.46470261]
 [ 37.34366989]
 [ 52.95573425]
 [ 57.25327301]
 [ 54.74206924]
 [ 52.49658585]
 [ 55.64009094]
 [ 53.07416916]
 [ 57.2992363 ]
 [ 68.43688965]]
DEBUG:root:training time = %d0.238597
INFO:root:frame =12161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =12162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000306129455566
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.903891666667
DEBUG:root: dqn, choose action rondomly, need time 0.000344000000041
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =12165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =12166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.90386
DEBUG:root: dqn, choose action rondomly, need time 0.000515000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:training error  = [[ 51.10561371]
 [ 56.24679565]
 [ 57.40369797]
 [ 55.43949509]
 [ 52.73854446]
 [ 51.30914307]
 [ 54.09573746]
 [ 48.90028763]
 [ 52.33573914]
 [ 54.3913002 ]
 [ 48.90028763]
 [ 50.7460556 ]
 [ 55.16307831]
 [ 57.12680435]
 [ 55.18756104]
 [ 53.56374359]]
DEBUG:root:training time = %d0.235677
INFO:root:frame =12169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =12170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.903828333333
DEBUG:root: dqn, choose action rondomly, need time 0.000372999999968
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =12173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =12174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.903796666667
DEBUG:root: dqn, choose action rondomly, need time 0.000521999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 50.26891327]
 [ 48.85569763]
 [ 52.06145859]
 [ 52.2803421 ]
 [ 49.32503128]
 [ 50.64567184]
 [ 56.2424469 ]
 [ 52.54922485]
 [ 52.29269791]
 [ 68.95339203]
 [ 52.03371429]
 [ 53.33460999]
 [ 53.66340637]
 [ 52.44176483]
 [ 53.23124695]
 [ 37.2666893 ]]
DEBUG:root:training time = %d0.196447
INFO:root:frame =12177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =12178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274896621704
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.903765
DEBUG:root: dqn, choose action rondomly, need time 0.000501999999983
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =12181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:frame =12182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000565052032471
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.903733333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 54.86655426]
 [ 58.93214035]
 [ 53.42000198]
 [ 56.60280228]
 [ 69.92635345]
 [ 52.88957596]
 [ 54.10426712]
 [ 52.79950714]
 [ 70.10791016]
 [ 69.04388428]
 [ 55.39883041]
 [ 52.6634407 ]
 [ 49.47603607]
 [ 49.64769363]
 [ 49.58514023]
 [ 56.1392746 ]]
DEBUG:root:training time = %d0.232264
INFO:root:frame =12185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =12186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.903701666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000041
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =12189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000429153442383
INFO:root:frame =12190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504970550537
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.90367
DEBUG:root: dqn, choose action rondomly, need time 0.000652000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 71.80892181]
 [ 55.77014542]
 [ 55.40382767]
 [ 54.3667717 ]
 [ 54.1538887 ]
 [ 51.44126129]
 [ 52.73721313]
 [ 52.55010986]
 [ 53.18249512]
 [ 54.39400101]
 [ 53.45391083]
 [ 50.17267609]
 [ 55.42676926]
 [ 56.3099823 ]
 [ 58.38195038]
 [ 55.42676926]]
DEBUG:root:training time = %d0.228509
INFO:root:frame =12193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =12194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485897064209
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.903638333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =12197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000393867492676
INFO:root:frame =12198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000540971755981
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.903606666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999964
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 46.34115982]
 [ 54.66510391]
 [ 52.25188065]
 [ 52.57997894]
 [ 49.36190414]
 [ 55.76832199]
 [ 66.71172333]
 [ 68.6114502 ]
 [ 53.8220253 ]
 [ 51.00291061]
 [ 68.2481842 ]
 [ 49.72018814]
 [ 48.35613251]
 [ 69.50337219]
 [ 52.86449814]
 [ 66.01141357]]
DEBUG:root:training time = %d0.231569
INFO:root:frame =12201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =12202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319957733154
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.903575
DEBUG:root: dqn, choose action rondomly, need time 0.000329000000022
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332832336426
INFO:root:frame =12205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =12206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame = 12207 State into memory, numbers recorded 320 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000539064407349
INFO:root:random_action_porb = 0.903543333333
DEBUG:root: dqn, choose action rondomly, need time 0.000328999999965
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12208current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:training error  = [[ 56.41170502]
 [ 51.95207596]
 [ 53.48716354]
 [ 54.68292999]
 [ 47.75110245]
 [ 56.21773148]
 [ 53.70231247]
 [ 52.08656311]
 [ 52.4377861 ]
 [ 54.10920715]
 [ 58.72779846]
 [ 54.18622971]
 [ 50.86069107]
 [ 53.12842941]
 [ 53.64730835]
 [ 53.23881912]]
DEBUG:root:training time = %d0.227397
INFO:root:frame =12209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame =12210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428199768066
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.903511666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =12213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =12214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049090385437
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.90348
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 50.83240128]
 [ 72.42883301]
 [ 52.74031448]
 [ 51.67200089]
 [ 55.27079391]
 [ 51.31832504]
 [ 53.90713501]
 [ 68.63142395]
 [ 52.29336166]
 [ 54.02057266]
 [ 55.78382111]
 [ 54.58593369]
 [ 68.82269287]
 [ 50.51262665]
 [ 53.28826141]
 [ 41.28223419]]
DEBUG:root:training time = %d0.225896
INFO:root:frame =12217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =12218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.903448333333
DEBUG:root: dqn, choose action rondomly, need time 0.000321000000042
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =12221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =12222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame = 12223 State into memory, numbers recorded 321 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000333786010742
INFO:root:random_action_porb = 0.903416666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303999999971
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12224current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[ 60.47639465]
 [ 51.26477814]
 [ 55.41745758]
 [ 56.74363327]
 [ 56.48622513]
 [ 57.76728439]
 [ 56.15962982]
 [ 53.94187164]
 [ 55.18121338]
 [ 47.39411545]
 [ 53.64865112]
 [ 53.81105423]
 [ 49.08912277]
 [ 50.64197922]
 [ 52.55674744]
 [ 53.53739166]]
DEBUG:root:training time = %d0.217625
INFO:root:frame =12225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =12226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.903385
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =12229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =12230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000189065933228
INFO:root:random_action_porb = 0.903353333333
DEBUG:root: dqn, choose action rondomly, need time 0.000524999999982
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 51.64304733]
 [ 69.48607635]
 [ 53.45993805]
 [ 52.24217224]
 [ 51.96219635]
 [ 49.99644089]
 [ 53.52019882]
 [ 53.71908569]
 [ 51.88786697]
 [ 55.03463745]
 [ 51.9397583 ]
 [ 53.23881912]
 [ 54.86270905]
 [ 52.4908371 ]
 [ 53.55347061]
 [ 49.92180634]]
DEBUG:root:training time = %d0.200431
INFO:root:frame =12233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028920173645
INFO:root:frame =12234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480890274048
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.903321666667
DEBUG:root: dqn, choose action rondomly, need time 0.000163999999984
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00015115737915
INFO:root:frame =12237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000496864318848
INFO:root:frame =12238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000515937805176
DEBUG:root: save sample needs time = 0.000188112258911
INFO:root:random_action_porb = 0.90329
DEBUG:root: dqn, choose action rondomly, need time 0.000185999999985
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 52.82168579]
 [ 52.7024231 ]
 [ 55.73095322]
 [ 50.93144608]
 [ 68.79711914]
 [ 55.06996155]
 [ 52.99949265]
 [ 53.24060059]
 [ 54.10987854]
 [ 59.93792343]
 [ 52.7024231 ]
 [ 48.61133957]
 [ 48.58389664]
 [ 53.67033386]
 [ 53.55548096]
 [ 52.32867432]]
DEBUG:root:training time = %d0.208327
INFO:root:frame =12241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =12242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494003295898
DEBUG:root: save sample needs time = 0.000240802764893
INFO:root:random_action_porb = 0.903258333333
INFO:root:dqn select action Tensor("ArgMax_159:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014798
INFO:root:action choosen by dqn [4]
INFO:root:frame =12244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =12245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002281665802
INFO:root:frame =12246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042986869812
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:random_action_porb = 0.903226666667
DEBUG:root: dqn, choose action rondomly, need time 0.000433000000044
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 57.19648361]
 [ 52.48707962]
 [ 49.80672836]
 [ 57.22810745]
 [ 55.33797073]
 [ 51.71127701]
 [ 52.36952591]
 [ 53.63680267]
 [ 50.60245895]
 [ 51.41106033]
 [ 66.6780777 ]
 [ 54.11773682]
 [ 53.28358459]
 [ 51.17654037]
 [ 55.21295547]
 [ 52.92220688]]
DEBUG:root:training time = %d0.218742
INFO:root:frame =12249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =12250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042986869812
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.903195
DEBUG:root: dqn, choose action rondomly, need time 0.000256999999976
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =12253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =12254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00061297416687
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.903163333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283000000024
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000380039215088
INFO:root:training error  = [[ 51.71017838]
 [ 52.41127396]
 [ 55.88187408]
 [ 50.60593414]
 [ 50.85742569]
 [ 54.50862503]
 [ 55.34909439]
 [ 51.47935486]
 [ 60.07385254]
 [ 57.72669983]
 [ 53.23614502]
 [ 54.75652313]
 [ 53.27868271]
 [ 55.41041183]
 [ 51.54068375]
 [ 57.61175156]]
DEBUG:root:training time = %d0.218376
INFO:root:frame =12257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =12258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame = 12259 State into memory, numbers recorded 322 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000566005706787
INFO:root:random_action_porb = 0.903131666667
DEBUG:root: dqn, choose action rondomly, need time 0.000279999999975
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12260current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =12261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =12262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00061297416687
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.9031
DEBUG:root: dqn, choose action rondomly, need time 0.000505999999973
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:training error  = [[ 53.41130447]
 [ 57.2853775 ]
 [ 52.53772354]
 [ 53.54074097]
 [ 53.4657402 ]
 [ 51.63559341]
 [ 53.52220917]
 [ 54.8337822 ]
 [ 52.06586075]
 [ 53.11864471]
 [ 53.57804108]
 [ 50.24792862]
 [ 53.19451523]
 [ 54.26331329]
 [ 52.83277512]
 [ 54.26331329]]
DEBUG:root:training time = %d0.221579
INFO:root:frame =12265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =12266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464200973511
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.903068333333
DEBUG:root: dqn, choose action rondomly, need time 0.000447000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =12269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =12270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.903036666667
DEBUG:root: dqn, choose action rondomly, need time 0.000425999999948
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 48.1723175 ]
 [ 48.9372139 ]
 [ 51.46249771]
 [ 53.38053131]
 [ 49.72599792]
 [ 52.25606918]
 [ 52.61605835]
 [ 52.62823105]
 [ 53.88293839]
 [ 49.28688812]
 [ 54.51470947]
 [ 55.70954132]
 [ 57.2161026 ]
 [ 54.0656662 ]
 [ 53.91004944]
 [ 51.38196182]]
DEBUG:root:training time = %d0.234371
INFO:root:frame =12273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =12274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.903005
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999969
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =12277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =12278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000495910644531
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.902973333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 51.19881058]
 [ 54.99660873]
 [ 54.80395508]
 [ 53.0326004 ]
 [ 56.32097626]
 [ 53.70857239]
 [ 71.30062103]
 [ 55.36952972]
 [ 57.16463852]
 [ 53.52980042]
 [ 58.26332092]
 [ 53.5327034 ]
 [ 60.02679062]
 [ 55.68835831]
 [ 59.50304031]
 [ 53.79471207]]
DEBUG:root:training time = %d0.237383
INFO:root:frame =12281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =12282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame = 12283 State into memory, numbers recorded 323 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.00056791305542
INFO:root:random_action_porb = 0.902941666667
INFO:root:dqn select action Tensor("ArgMax_160:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011963
INFO:root:action choosen by dqn [4]
INFO:root:frame =12284current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000466823577881
INFO:root:frame =12285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =12286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000333070755005
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.90291
INFO:root:dqn select action Tensor("ArgMax_161:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015115
INFO:root:action choosen by dqn [4]
INFO:root:frame =12288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000385046005249
INFO:root:training error  = [[ 55.24130249]
 [ 55.04188156]
 [ 53.22078323]
 [ 54.12491989]
 [ 48.83351517]
 [ 52.91243744]
 [ 55.12795258]
 [ 57.89515686]
 [ 51.56851196]
 [ 54.50502014]
 [ 49.91188812]
 [ 54.72581482]
 [ 55.46472168]
 [ 59.14951324]
 [ 53.1104126 ]
 [ 53.48381424]]
DEBUG:root:training time = %d0.232976
INFO:root:frame =12289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =12290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.902878333333
DEBUG:root: dqn, choose action rondomly, need time 0.000247000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =12293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:frame =12294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame = 12295 State into memory, numbers recorded 324 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000568151473999
INFO:root:random_action_porb = 0.902846666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12296current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 51.64063644]
 [ 56.08395386]
 [ 44.16743851]
 [ 55.89100266]
 [ 44.16743851]
 [ 76.01261139]
 [ 54.40390396]
 [ 52.28850555]
 [ 51.44345093]
 [ 55.78587341]
 [ 60.91433716]
 [ 55.89100266]
 [ 44.1424942 ]
 [ 51.43382263]
 [ 57.47493362]
 [ 54.17297745]]
DEBUG:root:training time = %d0.225317
INFO:root:frame =12297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =12298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.902815
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000377178192139
INFO:root:frame =12301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488042831421
INFO:root:frame =12302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame = 12303 State into memory, numbers recorded 325 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000622034072876
INFO:root:random_action_porb = 0.902783333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12304current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 57.76171494]
 [ 54.73258591]
 [ 53.66720581]
 [ 53.1560173 ]
 [ 54.46784973]
 [ 53.3974762 ]
 [ 53.44855881]
 [ 53.16291428]
 [ 69.68718719]
 [ 58.65485382]
 [ 53.83142853]
 [ 53.07105637]
 [ 57.55223465]
 [ 55.4654007 ]
 [ 55.19662857]
 [ 53.24571991]]
DEBUG:root:training time = %d0.228279
INFO:root:frame =12305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =12306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324964523315
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.902751666667
DEBUG:root: dqn, choose action rondomly, need time 0.000192000000027
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:frame =12309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =12310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482082366943
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.90272
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 52.28762054]
 [ 50.39838791]
 [ 55.80570602]
 [ 55.78792572]
 [ 56.27380753]
 [ 55.47040176]
 [ 57.89724731]
 [ 57.28583908]
 [ 57.16302109]
 [ 55.89100266]
 [ 70.94416809]
 [ 57.81971359]
 [ 57.01222229]
 [ 55.45653915]
 [ 55.45653915]
 [ 57.73945236]]
DEBUG:root:training time = %d0.221025
INFO:root:frame =12313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =12314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.902688333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000375032424927
INFO:root:frame =12317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame =12318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000259160995483
INFO:root:random_action_porb = 0.902656666667
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 55.26444244]
 [ 71.96649933]
 [ 54.36137009]
 [ 55.96175003]
 [ 55.55566788]
 [ 54.55121613]
 [ 52.21394348]
 [ 53.58630371]
 [ 54.29748535]
 [ 61.04350281]
 [ 52.57334137]
 [ 55.90605927]
 [ 56.80732727]
 [ 61.43946457]
 [ 53.37049866]
 [ 56.3021965 ]]
DEBUG:root:training time = %d0.223756
INFO:root:frame =12321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =12322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.902625
INFO:root:dqn select action Tensor("ArgMax_162:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011662
INFO:root:action choosen by dqn [4]
INFO:root:frame =12324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:frame =12325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280857086182
INFO:root:frame =12326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.902593333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 56.30402756]
 [ 55.06090164]
 [ 54.04771423]
 [ 57.50108337]
 [ 55.23200226]
 [ 51.60489655]
 [ 70.80877686]
 [ 55.57614136]
 [ 55.8894043 ]
 [ 52.2909317 ]
 [ 55.78063202]
 [ 53.87308121]
 [ 52.01412582]
 [ 56.41789627]
 [ 57.87867355]
 [ 56.06224442]]
DEBUG:root:training time = %d0.232877
INFO:root:frame =12329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =12330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000261068344116
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.902561666667
DEBUG:root: dqn, choose action rondomly, need time 0.000193999999965
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:frame =12333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root:frame =12334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235080718994
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:random_action_porb = 0.90253
INFO:root:dqn select action Tensor("ArgMax_163:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010324
INFO:root:action choosen by dqn [4]
INFO:root:frame =12336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 55.04006958]
 [ 53.73004532]
 [ 53.83590698]
 [ 53.81038284]
 [ 69.41461182]
 [ 69.41461182]
 [ 56.15299606]
 [ 57.6543808 ]
 [ 58.22838593]
 [ 57.97738647]
 [ 55.87366486]
 [ 54.70843124]
 [ 53.10752106]
 [ 55.55498505]
 [ 57.5483017 ]
 [ 57.62541962]]
DEBUG:root:training time = %d0.193771
INFO:root:frame =12337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270843505859
INFO:root:frame =12338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446796417236
INFO:root: ememy has been killed for 23 times 
INFO:root:enemies_left [0]
INFO:root:frame = 12339 State into memory, numbers recorded 326 action = [4], reward = 1
DEBUG:root: save sample needs time = 0.00107717514038
INFO:root:random_action_porb = 0.902498333333
DEBUG:root: dqn, choose action rondomly, need time 0.000448000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12340current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =12341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =12342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame = 12343 State into memory, numbers recorded 327 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:random_action_porb = 0.902466666667
DEBUG:root: dqn, choose action rondomly, need time 0.000342999999987
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12344current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000784158706665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 53.01504517]
 [ 56.67285156]
 [ 56.67285156]
 [ 52.25938034]
 [ 39.14112091]
 [ 53.97616959]
 [ 53.20742416]
 [ 57.75475693]
 [ 52.29578781]
 [ 56.84321594]
 [ 42.75674438]
 [ 58.51213455]
 [ 51.82655334]
 [ 57.45851135]
 [ 56.49058151]
 [ 69.55731964]]
DEBUG:root:training time = %d0.19344
INFO:root:frame =12345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =12346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486850738525
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:random_action_porb = 0.902435
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =12349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =12350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.902403333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000038
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000414848327637
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 57.91048431]
 [ 56.07435608]
 [ 59.86423111]
 [ 54.12334824]
 [ 55.08785248]
 [ 71.07558441]
 [ 53.86703491]
 [ 57.20040894]
 [ 56.30975342]
 [ 57.20040894]
 [ 70.76409912]
 [ 55.55794144]
 [ 52.59746552]
 [ 56.34159088]
 [ 56.15093613]
 [ 55.8355751 ]]
DEBUG:root:training time = %d0.237252
INFO:root:frame =12353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:frame =12354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000420093536377
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.902371666667
DEBUG:root: dqn, choose action rondomly, need time 0.000323999999978
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =12357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =12358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.90234
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 55.16012955]
 [ 55.48949432]
 [ 57.16786957]
 [ 55.46994781]
 [ 57.70676041]
 [ 55.73733521]
 [ 57.75823593]
 [ 55.2456131 ]
 [ 53.92438889]
 [ 52.03151321]
 [ 54.26286316]
 [ 56.98987579]
 [ 55.35477066]
 [ 71.11238098]
 [ 55.22270584]
 [ 58.2388649 ]]
DEBUG:root:training time = %d0.238757
INFO:root:frame =12361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00027322769165
INFO:root:frame =12362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.902308333333
DEBUG:root: dqn, choose action rondomly, need time 0.000280999999973
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =12365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =12366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.902276666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 53.62473679]
 [ 46.21431351]
 [ 61.49736786]
 [ 54.44758224]
 [ 55.27215576]
 [ 58.01805878]
 [ 58.04990768]
 [ 56.57089233]
 [ 51.11455917]
 [ 54.49037552]
 [ 53.89929199]
 [ 56.42110443]
 [ 53.6269722 ]
 [ 56.15070724]
 [ 72.7233963 ]
 [ 53.27667999]]
DEBUG:root:training time = %d0.236899
INFO:root:frame =12369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:frame =12370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000316858291626
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.902245
DEBUG:root: dqn, choose action rondomly, need time 0.000336000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root:frame =12373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =12374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.902213333333
DEBUG:root: dqn, choose action rondomly, need time 0.000445000000013
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 56.155056  ]
 [ 59.3188591 ]
 [ 57.88888931]
 [ 59.00596237]
 [ 53.00993729]
 [ 56.13287354]
 [ 57.63028336]
 [ 59.81866837]
 [ 58.985569  ]
 [ 59.00596237]
 [ 55.62256241]
 [ 55.52928543]
 [ 57.14848709]
 [ 56.5304985 ]
 [ 53.45748138]
 [ 56.21018219]]
DEBUG:root:training time = %d0.21772
INFO:root:frame =12377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =12378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000404119491577
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.902181666667
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00039005279541
INFO:root:frame =12381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =12382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444173812866
DEBUG:root: save sample needs time = 0.000177145004272
INFO:root:random_action_porb = 0.90215
DEBUG:root: dqn, choose action rondomly, need time 0.000490000000013
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:training error  = [[ 57.33620071]
 [ 59.84982681]
 [ 54.37802124]
 [ 61.74243546]
 [ 54.59111786]
 [ 54.36362076]
 [ 55.84857178]
 [ 55.84857178]
 [ 52.82079697]
 [ 58.89325714]
 [ 56.50732803]
 [ 54.82112503]
 [ 54.88554382]
 [ 57.5800209 ]
 [ 59.30898666]
 [ 53.79023743]]
DEBUG:root:training time = %d0.242214
INFO:root:frame =12385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000411033630371
INFO:root:frame =12386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000317811965942
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:random_action_porb = 0.902118333333
DEBUG:root: dqn, choose action rondomly, need time 0.000324999999975
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =12389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =12390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000292062759399
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.902086666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 56.26235962]
 [ 73.58265686]
 [ 62.0598526 ]
 [ 58.10758591]
 [ 61.07164001]
 [ 53.55592728]
 [ 57.68473816]
 [ 60.30493164]
 [ 57.17709732]
 [ 56.10795593]
 [ 70.63912964]
 [ 55.7352829 ]
 [ 58.51773834]
 [ 55.82622528]
 [ 58.96236801]
 [ 52.90955353]]
DEBUG:root:training time = %d0.229502
INFO:root:frame =12393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =12394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000258922576904
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.902055
DEBUG:root: dqn, choose action rondomly, need time 0.000329000000022
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =12397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471115112305
INFO:root:frame =12398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000157117843628
INFO:root:random_action_porb = 0.902023333333
DEBUG:root: dqn, choose action rondomly, need time 0.000508999999965
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 61.47583008]
 [ 56.45709991]
 [ 54.4800148 ]
 [ 61.92937851]
 [ 55.18846512]
 [ 61.54164886]
 [ 72.20928192]
 [ 55.8980751 ]
 [ 61.56056595]
 [ 59.08827209]
 [ 48.69755173]
 [ 56.26281738]
 [ 54.12020493]
 [ 52.62292099]
 [ 58.79516983]
 [ 56.01267242]]
DEBUG:root:training time = %d0.223226
INFO:root:frame =12401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =12402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000395059585571
DEBUG:root: save sample needs time = 0.000180006027222
INFO:root:random_action_porb = 0.901991666667
DEBUG:root: dqn, choose action rondomly, need time 0.000357000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =12405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =12406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame = 12407 State into memory, numbers recorded 328 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000560998916626
INFO:root:random_action_porb = 0.90196
DEBUG:root: dqn, choose action rondomly, need time 0.000203999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12408current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 59.09953308]
 [ 57.48789215]
 [ 54.37014771]
 [ 59.07982635]
 [ 58.06455994]
 [ 58.0959549 ]
 [ 59.3555336 ]
 [ 61.2687912 ]
 [ 64.41718292]
 [ 56.41101837]
 [ 54.83694458]
 [ 53.07283401]
 [ 57.4464798 ]
 [ 56.81054688]
 [ 76.26318359]
 [ 58.02875137]]
DEBUG:root:training time = %d0.20835
INFO:root:frame =12409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =12410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.901928333333
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000409841537476
INFO:root:frame =12413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =12414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.901896666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 59.86611938]
 [ 55.82326126]
 [ 62.89470673]
 [ 53.23993301]
 [ 56.90903854]
 [ 56.08212662]
 [ 74.79995728]
 [ 57.2140274 ]
 [ 59.04511642]
 [ 53.23993301]
 [ 72.12735748]
 [ 44.57318497]
 [ 61.30701828]
 [ 57.22856903]
 [ 57.23549652]
 [ 59.37693024]]
DEBUG:root:training time = %d0.21761
INFO:root:frame =12417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =12418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000515937805176
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.901865
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =12421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000540018081665
INFO:root:frame =12422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.901833333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 57.79767227]
 [ 76.28957367]
 [ 52.99660492]
 [ 58.54225159]
 [ 58.57985306]
 [ 56.57433319]
 [ 55.78633118]
 [ 55.73619461]
 [ 60.67710114]
 [ 61.30199814]
 [ 59.09695435]
 [ 56.98434448]
 [ 58.86000824]
 [ 55.33978653]
 [ 76.15369415]
 [ 59.61349869]]
DEBUG:root:training time = %d0.230543
INFO:root:frame =12425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =12426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.901801666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =12429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471115112305
INFO:root:frame =12430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.90177
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:training error  = [[ 55.03463745]
 [ 57.26759338]
 [ 55.28440857]
 [ 56.48484802]
 [ 57.82598114]
 [ 58.58335495]
 [ 58.08037186]
 [ 57.23226166]
 [ 55.12726974]
 [ 58.30991745]
 [ 51.68209457]
 [ 63.68252182]
 [ 52.59768677]
 [ 54.78768921]
 [ 56.47521591]
 [ 58.32296753]]
DEBUG:root:training time = %d0.220041
INFO:root:frame =12433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =12434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000378131866455
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.901738333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999976
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =12437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =12438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.901706666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 74.89923096]
 [ 57.78815842]
 [ 58.14411545]
 [ 43.45218658]
 [ 59.33813477]
 [ 61.83623123]
 [ 55.8709259 ]
 [ 57.93370819]
 [ 61.2652092 ]
 [ 55.67469788]
 [ 61.65542221]
 [ 60.76199722]
 [ 57.2248764 ]
 [ 56.00193787]
 [ 58.15691376]
 [ 56.20583344]]
DEBUG:root:training time = %d0.223033
INFO:root:frame =12441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280141830444
INFO:root:frame =12442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000378847122192
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:random_action_porb = 0.901675
DEBUG:root: dqn, choose action rondomly, need time 0.000224000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:frame =12445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000475168228149
INFO:root:frame =12446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00065803527832
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:random_action_porb = 0.901643333333
DEBUG:root: dqn, choose action rondomly, need time 0.000335000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 60.18057632]
 [ 44.53285217]
 [ 60.09325027]
 [ 62.68069839]
 [ 58.55299377]
 [ 58.88787079]
 [ 57.39976883]
 [ 54.99027252]
 [ 53.93268204]
 [ 55.1059761 ]
 [ 59.7653389 ]
 [ 59.78751755]
 [ 72.55901337]
 [ 56.98342514]
 [ 56.84712601]
 [ 54.99027252]]
DEBUG:root:training time = %d0.229232
INFO:root:frame =12449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280141830444
INFO:root:frame =12450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.901611666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =12453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =12454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:random_action_porb = 0.90158
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999949
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 60.93935013]
 [ 57.02581787]
 [ 59.34142685]
 [ 79.00061798]
 [ 60.10176849]
 [ 55.48449326]
 [ 44.9451828 ]
 [ 54.49105072]
 [ 46.46693039]
 [ 57.78444672]
 [ 58.09223557]
 [ 59.84699631]
 [ 55.77493286]
 [ 58.38871002]
 [ 53.94007874]
 [ 56.62805939]]
DEBUG:root:training time = %d0.228794
INFO:root:frame =12457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =12458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.901548333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =12461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =12462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000364065170288
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.901516666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:training error  = [[ 56.44838715]
 [ 51.59919739]
 [ 66.5042572 ]
 [ 54.42191315]
 [ 59.20397949]
 [ 61.77193451]
 [ 56.60073471]
 [ 62.88454056]
 [ 58.54108429]
 [ 60.10744476]
 [ 57.63005066]
 [ 62.40218735]
 [ 59.86848068]
 [ 58.46009064]
 [ 55.41927338]
 [ 60.8102951 ]]
DEBUG:root:training time = %d0.203253
INFO:root:frame =12465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =12466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000182867050171
INFO:root:random_action_porb = 0.901485
DEBUG:root: dqn, choose action rondomly, need time 0.000388999999984
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =12469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =12470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000582933425903
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.901453333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 60.33052826]
 [ 61.11242676]
 [ 59.21807098]
 [ 52.98994064]
 [ 57.22210693]
 [ 58.62213516]
 [ 57.28583908]
 [ 58.65158081]
 [ 55.85336304]
 [ 56.10383987]
 [ 62.02403641]
 [ 74.88391113]
 [ 56.9601593 ]
 [ 60.68019104]
 [ 56.16191483]
 [ 58.15668106]]
DEBUG:root:training time = %d0.219223
INFO:root:frame =12473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =12474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.901421666667
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =12477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000392913818359
INFO:root:frame =12478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:random_action_porb = 0.90139
DEBUG:root: dqn, choose action rondomly, need time 0.000270999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 55.81254578]
 [ 59.0230751 ]
 [ 59.76510239]
 [ 58.61933136]
 [ 58.42416   ]
 [ 58.93471909]
 [ 75.41778564]
 [ 57.34128571]
 [ 57.49599075]
 [ 56.93229294]
 [ 56.30013657]
 [ 59.07255554]
 [ 59.37834167]
 [ 56.06178665]
 [ 57.20479202]
 [ 55.80365372]]
DEBUG:root:training time = %d0.217141
INFO:root:frame =12481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =12482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame = 12483 State into memory, numbers recorded 329 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000341176986694
INFO:root:random_action_porb = 0.901358333333
DEBUG:root: dqn, choose action rondomly, need time 0.000534000000016
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12484current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =12485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =12486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.901326666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 57.58974838]
 [ 61.1584816 ]
 [ 58.15458679]
 [ 59.42561722]
 [ 56.18364334]
 [ 60.16305923]
 [ 57.67824936]
 [ 56.46581268]
 [ 60.11265182]
 [ 72.05558014]
 [ 56.06795883]
 [ 61.59960175]
 [ 56.18364334]
 [ 55.71842575]
 [ 53.85650635]
 [ 57.67824936]]
DEBUG:root:training time = %d0.233077
INFO:root:frame =12489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000373125076294
INFO:root:frame =12490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.901295
DEBUG:root: dqn, choose action rondomly, need time 0.000330000000019
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =12493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =12494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288009643555
DEBUG:root: save sample needs time = 0.000134944915771
INFO:root:random_action_porb = 0.901263333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 57.47354507]
 [ 59.18050003]
 [ 62.01081848]
 [ 62.08341599]
 [ 58.11363602]
 [ 56.57020187]
 [ 60.102005  ]
 [ 57.29392242]
 [ 76.58706665]
 [ 75.77997589]
 [ 62.57346725]
 [ 61.34668732]
 [ 58.21790695]
 [ 77.62493134]
 [ 62.01081848]
 [ 63.91775131]]
DEBUG:root:training time = %d0.22032
INFO:root:frame =12497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =12498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000300884246826
DEBUG:root: save sample needs time = 0.000206232070923
INFO:root:random_action_porb = 0.901231666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000038
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000315189361572
INFO:root:frame =12501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =12502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466823577881
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9012
DEBUG:root: dqn, choose action rondomly, need time 0.000236000000029
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000197172164917
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 58.68758011]
 [ 61.00178146]
 [ 55.99280167]
 [ 55.84811783]
 [ 60.18033981]
 [ 54.79175568]
 [ 57.51473618]
 [ 56.58787918]
 [ 73.24352264]
 [ 58.62891388]
 [ 60.20827866]
 [ 55.22610855]
 [ 60.6509552 ]
 [ 56.8202095 ]
 [ 63.5437851 ]
 [ 59.06035995]]
DEBUG:root:training time = %d0.196753
INFO:root:frame =12505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000347852706909
INFO:root:frame =12506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000602006912231
DEBUG:root: save sample needs time = 0.000131130218506
INFO:root:random_action_porb = 0.901168333333
DEBUG:root: dqn, choose action rondomly, need time 0.000360999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000357866287231
INFO:root:frame =12509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000357866287231
INFO:root:frame =12510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308036804199
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:random_action_porb = 0.901136666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 61.19643402]
 [ 60.79578018]
 [ 59.93910599]
 [ 59.09695435]
 [ 59.71038055]
 [ 55.28100204]
 [ 57.22579956]
 [ 73.51356506]
 [ 56.4614563 ]
 [ 57.30963135]
 [ 58.30362701]
 [ 59.95209885]
 [ 57.13049316]
 [ 58.13178253]
 [ 55.08400345]
 [ 59.89894485]]
DEBUG:root:training time = %d0.199911
INFO:root:frame =12513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:frame =12514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:random_action_porb = 0.901105
INFO:root:dqn select action Tensor("ArgMax_164:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.016523
INFO:root:action choosen by dqn [4]
INFO:root:frame =12516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =12517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000327825546265
INFO:root:frame =12518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame = 12519 State into memory, numbers recorded 330 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00121808052063
INFO:root:random_action_porb = 0.901073333333
INFO:root:dqn select action Tensor("ArgMax_165:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.009997
INFO:root:action choosen by dqn [4]
INFO:root:frame =12520current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:training error  = [[ 61.12364197]
 [ 61.26903152]
 [ 61.88399506]
 [ 56.55482483]
 [ 58.41180038]
 [ 58.52380753]
 [ 56.57157898]
 [ 60.22177887]
 [ 62.21405411]
 [ 58.52941132]
 [ 61.47678757]
 [ 58.40083694]
 [ 54.85977173]
 [ 58.55836487]
 [ 62.39929581]
 [ 57.70977402]]
DEBUG:root:training time = %d0.215948
INFO:root:frame =12521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =12522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264167785645
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.901041666667
DEBUG:root: dqn, choose action rondomly, need time 0.00028100000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =12525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:frame =12526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239849090576
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.90101
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000021
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root:training error  = [[ 60.60010529]
 [ 58.18693924]
 [ 64.13556671]
 [ 58.03340149]
 [ 60.17678833]
 [ 63.05381775]
 [ 57.33990097]
 [ 56.21063995]
 [ 57.94625473]
 [ 59.00314713]
 [ 56.25915527]
 [ 57.70397949]
 [ 55.84264374]
 [ 57.38288879]
 [ 59.00291443]
 [ 58.26867676]]
DEBUG:root:training time = %d0.233866
INFO:root:frame =12529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =12530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:random_action_porb = 0.900978333333
DEBUG:root: dqn, choose action rondomly, need time 0.000319999999988
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =12533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =12534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.900946666667
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 56.96430588]
 [ 74.83638763]
 [ 56.5860405 ]
 [ 60.76723099]
 [ 54.19499207]
 [ 64.59512329]
 [ 62.72516251]
 [ 59.65261841]
 [ 55.40473557]
 [ 59.42632294]
 [ 59.184021  ]
 [ 59.43055725]
 [ 54.19499207]
 [ 54.6017189 ]
 [ 60.82886124]
 [ 62.66934204]]
DEBUG:root:training time = %d0.22502
INFO:root:frame =12537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =12538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319004058838
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.900915
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00036096572876
INFO:root:frame =12541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000511884689331
INFO:root:frame =12542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root:random_action_porb = 0.900883333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 59.61231995]
 [ 58.47549057]
 [ 58.10618973]
 [ 63.98779297]
 [ 59.79105759]
 [ 57.28860855]
 [ 58.40340424]
 [ 55.68881607]
 [ 62.43473816]
 [ 61.77936935]
 [ 55.83443451]
 [ 76.33782959]
 [ 60.21751404]
 [ 60.93863678]
 [ 60.21775055]
 [ 58.96681976]]
DEBUG:root:training time = %d0.227308
INFO:root:frame =12545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274181365967
INFO:root:frame =12546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000515937805176
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.900851666667
DEBUG:root: dqn, choose action rondomly, need time 0.000398999999959
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =12549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =12550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.90082
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 45.18220901]
 [ 60.05445862]
 [ 59.79247284]
 [ 76.14596558]
 [ 58.66116333]
 [ 62.71066284]
 [ 59.96533203]
 [ 61.73620224]
 [ 76.14596558]
 [ 59.85785675]
 [ 58.44235611]
 [ 62.16471481]
 [ 57.6606369 ]
 [ 60.35162735]
 [ 58.97408295]
 [ 60.37581253]]
DEBUG:root:training time = %d0.248602
INFO:root:frame =12553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =12554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.900788333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000033
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =12557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000416994094849
INFO:root:frame =12558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494956970215
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.900756666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999974
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:training error  = [[ 64.25904846]
 [ 59.53623962]
 [ 57.54019547]
 [ 60.41850281]
 [ 56.72041702]
 [ 58.08293152]
 [ 60.19075775]
 [ 60.49372101]
 [ 59.63352966]
 [ 61.08594894]
 [ 58.14504623]
 [ 58.11154175]
 [ 60.80315781]
 [ 60.43415833]
 [ 60.35826492]
 [ 58.71797562]]
DEBUG:root:training time = %d0.217487
INFO:root:frame =12561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:frame =12562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000228881835938
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.900725
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =12565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =12566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.900693333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000031
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 58.80921173]
 [ 59.66888428]
 [ 80.81060028]
 [ 62.23692322]
 [ 56.72179413]
 [ 59.08287811]
 [ 75.82727051]
 [ 58.20835876]
 [ 59.89445877]
 [ 61.66308975]
 [ 62.46801758]
 [ 63.57444   ]
 [ 62.63190079]
 [ 60.74225235]
 [ 57.07952881]
 [ 62.18444824]]
DEBUG:root:training time = %d0.224801
INFO:root:frame =12569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =12570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504016876221
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.900661666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =12573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =12574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000348091125488
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:random_action_porb = 0.90063
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 63.05018234]
 [ 65.03614044]
 [ 60.8029213 ]
 [ 57.10904312]
 [ 76.7575531 ]
 [ 77.7753067 ]
 [ 66.54383087]
 [ 59.68467712]
 [ 58.67144775]
 [ 73.3299942 ]
 [ 59.14552689]
 [ 58.17436981]
 [ 61.16898346]
 [ 58.19276047]
 [ 58.85438919]
 [ 54.81186295]]
DEBUG:root:training time = %d0.236474
INFO:root:frame =12577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =12578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428915023804
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.900598333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =12581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =12582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249862670898
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.900566666667
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000021
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:training error  = [[ 57.13302994]
 [ 61.58187866]
 [ 63.46353149]
 [ 57.07791519]
 [ 59.24249649]
 [ 57.269207  ]
 [ 60.92124557]
 [ 64.01538086]
 [ 63.26773071]
 [ 59.81017303]
 [ 64.50489807]
 [ 61.33999634]
 [ 64.64321136]
 [ 60.85885239]
 [ 59.98471451]
 [ 66.14611053]]
DEBUG:root:training time = %d0.219624
INFO:root:frame =12585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =12586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.900535
DEBUG:root: dqn, choose action rondomly, need time 0.000323999999978
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000181913375854
INFO:root:frame =12589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =12590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.900503333333
INFO:root:dqn select action Tensor("ArgMax_166:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.009524
INFO:root:action choosen by dqn [4]
INFO:root:frame =12592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000279188156128
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 59.06903839]
 [ 60.62244034]
 [ 63.61922073]
 [ 62.48852158]
 [ 59.08967972]
 [ 61.45286179]
 [ 61.52944183]
 [ 63.68788147]
 [ 61.45286179]
 [ 64.94093323]
 [ 56.25411987]
 [ 61.52944183]
 [ 76.24160004]
 [ 63.33183289]
 [ 62.70510483]
 [ 58.16622543]]
DEBUG:root:training time = %d0.213922
INFO:root:frame =12593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =12594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000356912612915
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:random_action_porb = 0.900471666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =12597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =12598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame = 12599 State into memory, numbers recorded 331 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000556945800781
INFO:root:random_action_porb = 0.90044
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12600current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 60.21917343]
 [ 61.73164368]
 [ 61.57397461]
 [ 61.9793396 ]
 [ 77.06694794]
 [ 64.61328125]
 [ 64.80132294]
 [ 59.45479202]
 [ 60.5955925 ]
 [ 61.57397461]
 [ 76.77654266]
 [ 58.70417786]
 [ 57.81229019]
 [ 62.21934891]
 [ 62.4118309 ]
 [ 60.53123093]]
DEBUG:root:training time = %d0.2364
INFO:root:frame =12601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =12602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000326871871948
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.900408333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =12605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =12606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000569105148315
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.900376666667
DEBUG:root: dqn, choose action rondomly, need time 0.000369000000035
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:training error  = [[ 56.98319244]
 [ 64.63658142]
 [ 58.50303268]
 [ 64.48872375]
 [ 58.70651627]
 [ 62.73966599]
 [ 62.45547867]
 [ 58.47012329]
 [ 58.15249252]
 [ 61.57517242]
 [ 66.54009247]
 [ 62.56791687]
 [ 60.10697174]
 [ 58.93987274]
 [ 61.03658676]
 [ 58.87593079]]
DEBUG:root:training time = %d0.199153
INFO:root:frame =12609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =12610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000270843505859
DEBUG:root: save sample needs time = 0.000206232070923
INFO:root:random_action_porb = 0.900345
DEBUG:root: dqn, choose action rondomly, need time 0.000406999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =12613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =12614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000306129455566
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:random_action_porb = 0.900313333333
DEBUG:root: dqn, choose action rondomly, need time 0.000349999999969
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:training error  = [[ 64.71487427]
 [ 59.45243835]
 [ 60.5129509 ]
 [ 63.81263733]
 [ 66.3639679 ]
 [ 62.76504898]
 [ 61.31872559]
 [ 63.5627594 ]
 [ 56.06018829]
 [ 64.48553467]
 [ 62.64083862]
 [ 60.5129509 ]
 [ 64.08816528]
 [ 60.77864838]
 [ 60.8060112 ]
 [ 60.88409424]]
DEBUG:root:training time = %d0.215428
INFO:root:frame =12617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =12618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000103950500488
INFO:root:random_action_porb = 0.900281666667
DEBUG:root: dqn, choose action rondomly, need time 0.000336000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =12621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000620126724243
INFO:root:frame =12622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame = 12623 State into memory, numbers recorded 332 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000584840774536
INFO:root:random_action_porb = 0.90025
DEBUG:root: dqn, choose action rondomly, need time 0.00033499999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12624current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 56.68732452]
 [ 58.95721054]
 [ 67.98774719]
 [ 58.87429047]
 [ 59.53529739]
 [ 59.63282013]
 [ 64.02612305]
 [ 65.06469727]
 [ 60.95674133]
 [ 63.85993958]
 [ 60.46666718]
 [ 56.11161041]
 [ 59.75920486]
 [ 74.54125977]
 [ 63.00681305]
 [ 62.00048447]]
DEBUG:root:training time = %d0.212156
INFO:root:frame =12625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =12626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.000104904174805
INFO:root:random_action_porb = 0.900218333333
DEBUG:root: dqn, choose action rondomly, need time 0.000202000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:frame =12629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =12630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324010848999
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:random_action_porb = 0.900186666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00037693977356
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 47.15281677]
 [ 60.60865784]
 [ 82.99989319]
 [ 59.57156372]
 [ 77.09078979]
 [ 65.87758636]
 [ 80.29785156]
 [ 62.53798676]
 [ 62.25233078]
 [ 61.20526886]
 [ 65.82310486]
 [ 60.95817184]
 [ 78.10157013]
 [ 74.92405701]
 [ 60.76342392]
 [ 59.63305664]]
DEBUG:root:training time = %d0.187041
INFO:root:frame =12633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =12634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame = 12635 State into memory, numbers recorded 333 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:random_action_porb = 0.900155
DEBUG:root: dqn, choose action rondomly, need time 0.000194000000022
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12636current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =12637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000524997711182
INFO:root:frame =12638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000161170959473
INFO:root:random_action_porb = 0.900123333333
DEBUG:root: dqn, choose action rondomly, need time 0.000263999999959
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:training error  = [[ 69.11693573]
 [ 65.14767456]
 [ 64.89225006]
 [ 58.79329681]
 [ 65.2336731 ]
 [ 61.76353836]
 [ 59.44844055]
 [ 60.27009964]
 [ 65.21370697]
 [ 66.07241821]
 [ 62.10025024]
 [ 60.66426468]
 [ 62.47043228]
 [ 62.10025024]
 [ 62.37856674]
 [ 60.22580338]]
DEBUG:root:training time = %d0.188868
INFO:root:frame =12641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =12642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame = 12643 State into memory, numbers recorded 334 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000499963760376
INFO:root:random_action_porb = 0.900091666667
DEBUG:root: dqn, choose action rondomly, need time 0.000190999999973
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12644current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =12645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259160995483
INFO:root:frame =12646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame = 12647 State into memory, numbers recorded 335 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000419855117798
INFO:root:random_action_porb = 0.90006
DEBUG:root: dqn, choose action rondomly, need time 0.000520000000051
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12648current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000381946563721
INFO:root:training error  = [[ 65.76592255]
 [ 57.13141632]
 [ 59.60831451]
 [ 60.68399429]
 [ 62.59881973]
 [ 57.42636108]
 [ 61.51555634]
 [ 61.83959198]
 [ 59.33155441]
 [ 61.53973389]
 [ 60.67139816]
 [ 64.32414246]
 [ 62.31157684]
 [ 63.70566177]
 [ 66.32369232]
 [ 65.3660965 ]]
DEBUG:root:training time = %d0.185367
INFO:root:frame =12649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =12650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 0.00010085105896
INFO:root:random_action_porb = 0.900028333333
DEBUG:root: dqn, choose action rondomly, need time 0.000175000000013
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:frame =12653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =12654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame = 12655 State into memory, numbers recorded 336 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000411033630371
INFO:root:random_action_porb = 0.899996666667
DEBUG:root: dqn, choose action rondomly, need time 0.000204999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12656current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.00016713142395
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 61.82639313]
 [ 67.88938904]
 [ 60.58514023]
 [ 63.78387451]
 [ 64.48749542]
 [ 69.34877014]
 [ 59.97454834]
 [ 60.58514023]
 [ 60.5195961 ]
 [ 61.98246384]
 [ 64.40444183]
 [ 69.1174469 ]
 [ 60.25849152]
 [ 60.69207764]
 [ 61.94498825]
 [ 81.33102417]]
DEBUG:root:training time = %d0.189076
INFO:root:frame =12657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000381946563721
INFO:root:frame =12658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000253915786743
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:random_action_porb = 0.899965
DEBUG:root: dqn, choose action rondomly, need time 0.000174999999956
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000181913375854
INFO:root:frame =12661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:frame =12662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000103950500488
INFO:root:random_action_porb = 0.899933333333
DEBUG:root: dqn, choose action rondomly, need time 0.000159999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000166893005371
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 62.32844162]
 [ 59.55955124]
 [ 76.07168579]
 [ 56.17403793]
 [ 59.74740982]
 [ 62.86735916]
 [ 61.8554306 ]
 [ 61.48923111]
 [ 61.87583542]
 [ 64.92470551]
 [ 58.45985794]
 [ 63.85384369]
 [ 60.12046051]
 [ 62.82091141]
 [ 59.94760895]
 [ 66.10839081]]
DEBUG:root:training time = %d0.192005
INFO:root:frame =12665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =12666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000419855117798
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:random_action_porb = 0.899901666667
DEBUG:root: dqn, choose action rondomly, need time 0.000163999999984
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root:frame =12669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000514984130859
INFO:root:frame =12670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000334978103638
DEBUG:root: save sample needs time = 0.000147819519043
INFO:root:random_action_porb = 0.89987
DEBUG:root: dqn, choose action rondomly, need time 0.000198999999952
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 64.9552002 ]
 [ 80.41056061]
 [ 63.7456131 ]
 [ 62.61403275]
 [ 62.76867676]
 [ 79.04972839]
 [ 59.74929428]
 [ 59.806633  ]
 [ 61.07092285]
 [ 60.4638176 ]
 [ 64.32242584]
 [ 64.63805389]
 [ 80.76177216]
 [ 63.2386055 ]
 [ 64.08938599]
 [ 61.10551071]]
DEBUG:root:training time = %d0.183454
INFO:root:frame =12673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:frame =12674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239849090576
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.899838333333
DEBUG:root: dqn, choose action rondomly, need time 0.000192000000027
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root:frame =12677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000370979309082
INFO:root:frame =12678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000418186187744
DEBUG:root: save sample needs time = 0.000115871429443
INFO:root:random_action_porb = 0.899806666667
DEBUG:root: dqn, choose action rondomly, need time 0.000176999999951
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 62.29206848]
 [ 62.74377441]
 [ 62.62151718]
 [ 62.04807281]
 [ 62.27304077]
 [ 66.43110657]
 [ 65.78844452]
 [ 79.3805542 ]
 [ 64.17956543]
 [ 62.90705109]
 [ 61.39904785]
 [ 59.64507675]
 [ 69.32081604]
 [ 69.05960846]
 [ 63.15660477]
 [ 65.35351562]]
DEBUG:root:training time = %d0.193557
INFO:root:frame =12681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =12682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000340938568115
DEBUG:root: save sample needs time = 0.000103950500488
INFO:root:random_action_porb = 0.899775
DEBUG:root: dqn, choose action rondomly, need time 0.000154000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:frame =12685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =12686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.899743333333
DEBUG:root: dqn, choose action rondomly, need time 0.000159000000053
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 60.32128525]
 [ 62.32410431]
 [ 60.27080917]
 [ 64.69204712]
 [ 60.59392929]
 [ 65.396698  ]
 [ 61.8045578 ]
 [ 60.59891891]
 [ 71.21252441]
 [ 64.01733398]
 [ 82.03324127]
 [ 80.60908508]
 [ 62.11756516]
 [ 66.40424347]
 [ 47.49459457]
 [ 70.80877686]]
DEBUG:root:training time = %d0.191499
INFO:root:frame =12689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240802764893
INFO:root:frame =12690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239133834839
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.899711666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:frame =12693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =12694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235080718994
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.89968
DEBUG:root: dqn, choose action rondomly, need time 0.000158999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root:training error  = [[ 63.72173691]
 [ 61.21171188]
 [ 62.84171295]
 [ 63.33887482]
 [ 62.64107895]
 [ 59.85714722]
 [ 62.82405472]
 [ 63.72173691]
 [ 62.61161804]
 [ 61.60367203]
 [ 62.51530457]
 [ 60.6003418 ]
 [ 58.55018997]
 [ 66.01042175]
 [ 64.81459045]
 [ 62.58554077]]
DEBUG:root:training time = %d0.189987
INFO:root:frame =12697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =12698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00040602684021
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:random_action_porb = 0.899648333333
DEBUG:root: dqn, choose action rondomly, need time 0.000331000000017
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185012817383
INFO:root:frame =12701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =12702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame = 12703 State into memory, numbers recorded 337 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000408172607422
INFO:root:random_action_porb = 0.899616666667
DEBUG:root: dqn, choose action rondomly, need time 0.00022899999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12704current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000255823135376
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 78.77754211]
 [ 63.33984756]
 [ 65.64767456]
 [ 61.88879776]
 [ 62.24895859]
 [ 62.83203888]
 [ 81.89923859]
 [ 61.11600876]
 [ 61.10527039]
 [ 76.35409546]
 [ 47.31620407]
 [ 62.41135025]
 [ 63.17261505]
 [ 67.88360596]
 [ 63.28787994]
 [ 63.99682617]]
DEBUG:root:training time = %d0.187952
INFO:root:frame =12705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =12706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255107879639
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:random_action_porb = 0.899585
DEBUG:root: dqn, choose action rondomly, need time 0.000167999999974
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root:frame =12709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =12710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000405073165894
DEBUG:root: save sample needs time = 0.000155925750732
INFO:root:random_action_porb = 0.899553333333
DEBUG:root: dqn, choose action rondomly, need time 0.000258999999971
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 81.8837738 ]
 [ 56.82365799]
 [ 61.24586105]
 [ 61.18736267]
 [ 63.10568619]
 [ 67.98069763]
 [ 81.12007141]
 [ 62.9508667 ]
 [ 61.87679291]
 [ 59.99724197]
 [ 62.82042694]
 [ 61.27094269]
 [ 65.62963104]
 [ 68.83813477]
 [ 60.91267014]
 [ 52.17712402]]
DEBUG:root:training time = %d0.192558
INFO:root:frame =12713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280857086182
INFO:root:frame =12714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00023889541626
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.899521666667
DEBUG:root: dqn, choose action rondomly, need time 0.000165999999979
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root:frame =12717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000360012054443
INFO:root:frame =12718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293016433716
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.89949
INFO:root:dqn select action Tensor("ArgMax_167:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00809099999998
INFO:root:action choosen by dqn [4]
INFO:root:frame =12720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 62.39254761]
 [ 63.17673874]
 [ 63.41030121]
 [ 63.0499382 ]
 [ 62.21814346]
 [ 60.85099792]
 [ 63.16267014]
 [ 63.39863586]
 [ 63.42852783]
 [ 59.08451843]
 [ 60.54571533]
 [ 65.0592804 ]
 [ 66.0719223 ]
 [ 81.43784332]
 [ 67.4132309 ]
 [ 63.17431259]]
DEBUG:root:training time = %d0.185247
INFO:root:frame =12721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =12722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:random_action_porb = 0.899458333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =12725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =12726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000381946563721
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:random_action_porb = 0.899426666667
DEBUG:root: dqn, choose action rondomly, need time 0.000550000000032
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 63.30997467]
 [ 60.38861847]
 [ 58.16366577]
 [ 61.94643021]
 [ 85.45469666]
 [ 64.54412079]
 [ 66.38161469]
 [ 60.97961807]
 [ 65.05139923]
 [ 80.68774414]
 [ 66.09871674]
 [ 64.78658295]
 [ 66.64494324]
 [ 66.55553436]
 [ 80.11719513]
 [ 63.93605042]]
DEBUG:root:training time = %d0.186214
INFO:root:frame =12729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =12730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000295877456665
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.899395
DEBUG:root: dqn, choose action rondomly, need time 0.000373999999965
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =12733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =12734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000307083129883
DEBUG:root: save sample needs time = 0.000140190124512
INFO:root:random_action_porb = 0.899363333333
DEBUG:root: dqn, choose action rondomly, need time 0.000173000000018
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 61.75035095]
 [ 66.59188843]
 [ 66.57171631]
 [ 67.15013885]
 [ 63.05842209]
 [ 62.51916504]
 [ 71.64170074]
 [ 63.95508575]
 [ 65.68402863]
 [ 59.92894363]
 [ 64.65768433]
 [ 60.61103439]
 [ 62.10818481]
 [ 65.32514954]
 [ 65.33451843]
 [ 81.62963867]]
DEBUG:root:training time = %d0.187504
INFO:root:frame =12737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000370979309082
INFO:root:frame =12738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00029993057251
DEBUG:root: save sample needs time = 0.000123977661133
INFO:root:random_action_porb = 0.899331666667
DEBUG:root: dqn, choose action rondomly, need time 0.000197000000014
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =12741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =12742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame = 12743 State into memory, numbers recorded 338 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000370979309082
INFO:root:random_action_porb = 0.8993
DEBUG:root: dqn, choose action rondomly, need time 0.000222000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12744current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 51.88434982]
 [ 79.87126923]
 [ 60.92910767]
 [ 66.28269196]
 [ 63.33086014]
 [ 62.25064468]
 [ 65.13806915]
 [ 61.37131119]
 [ 61.77793121]
 [ 64.76300049]
 [ 64.62824249]
 [ 63.51119232]
 [ 45.98286819]
 [ 64.01416016]
 [ 62.06538391]
 [ 64.5061264 ]]
DEBUG:root:training time = %d0.207644
INFO:root:frame =12745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:frame =12746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000281810760498
DEBUG:root: save sample needs time = 0.00011682510376
INFO:root:random_action_porb = 0.899268333333
DEBUG:root: dqn, choose action rondomly, need time 0.00018399999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180959701538
INFO:root:frame =12749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312805175781
INFO:root:frame =12750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274181365967
DEBUG:root: save sample needs time = 0.000126123428345
INFO:root:random_action_porb = 0.899236666667
DEBUG:root: dqn, choose action rondomly, need time 0.000222000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180006027222
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 67.76850128]
 [ 65.06641388]
 [ 61.06448364]
 [ 67.50823212]
 [ 50.03464127]
 [ 63.37919998]
 [ 63.30803299]
 [ 64.19888306]
 [ 63.12508011]
 [ 63.49124908]
 [ 63.82726669]
 [ 65.51348114]
 [ 63.32478714]
 [ 62.47694397]
 [ 61.30343246]
 [ 63.9716835 ]]
DEBUG:root:training time = %d0.195426
INFO:root:frame =12753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =12754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:random_action_porb = 0.899205
DEBUG:root: dqn, choose action rondomly, need time 0.000244000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000193119049072
INFO:root:frame =12757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =12758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.899173333333
DEBUG:root: dqn, choose action rondomly, need time 0.000178000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000151872634888
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 67.71123505]
 [ 62.57829666]
 [ 66.42339325]
 [ 62.37639618]
 [ 61.95051193]
 [ 63.73051071]
 [ 61.81511688]
 [ 70.14266968]
 [ 70.86270905]
 [ 66.59039307]
 [ 67.11113739]
 [ 65.19497681]
 [ 66.77380371]
 [ 65.98215485]
 [ 79.17186737]
 [ 65.68551636]]
DEBUG:root:training time = %d0.19305
INFO:root:frame =12761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =12762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000306844711304
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.899141666667
DEBUG:root: dqn, choose action rondomly, need time 0.000166999999976
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:frame =12765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000351905822754
INFO:root:frame =12766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031304359436
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:random_action_porb = 0.89911
DEBUG:root: dqn, choose action rondomly, need time 0.000205999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 79.82327271]
 [ 69.98710632]
 [ 63.91140747]
 [ 81.69361877]
 [ 68.4838562 ]
 [ 65.85059357]
 [ 63.5340538 ]
 [ 70.54734039]
 [ 66.51893616]
 [ 73.51565552]
 [ 61.50143814]
 [ 63.10398865]
 [ 66.10119629]
 [ 63.72758484]
 [ 82.80122375]
 [ 65.91226959]]
DEBUG:root:training time = %d0.188625
INFO:root:frame =12769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =12770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000321865081787
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:random_action_porb = 0.899078333333
DEBUG:root: dqn, choose action rondomly, need time 0.000252999999987
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =12773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =12774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame = 12775 State into memory, numbers recorded 339 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000384092330933
INFO:root:random_action_porb = 0.899046666667
DEBUG:root: dqn, choose action rondomly, need time 0.000245000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12776current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 61.14583206]
 [ 64.64738464]
 [ 66.40001678]
 [ 65.7020874 ]
 [ 66.00818634]
 [ 64.72543335]
 [ 62.49310684]
 [ 82.86177063]
 [ 65.92787933]
 [ 62.24607086]
 [ 60.59464264]
 [ 65.11812592]
 [ 65.59329224]
 [ 65.45964813]
 [ 68.08666992]
 [ 63.24515915]]
DEBUG:root:training time = %d0.193115
INFO:root:frame =12777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275850296021
INFO:root:frame =12778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000520944595337
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.899015
INFO:root:dqn select action Tensor("ArgMax_168:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00740999999999
INFO:root:action choosen by dqn [4]
INFO:root:frame =12780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000168085098267
INFO:root:frame =12781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =12782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.898983333333
DEBUG:root: dqn, choose action rondomly, need time 0.000173000000018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 63.57273865]
 [ 64.14363861]
 [ 64.01855469]
 [ 63.03104019]
 [ 65.94571686]
 [ 81.38056946]
 [ 63.50024796]
 [ 65.04278564]
 [ 80.95963287]
 [ 62.02788162]
 [ 62.84534454]
 [ 63.57857513]
 [ 60.78959274]
 [ 65.61231995]
 [ 72.68670654]
 [ 62.41810226]]
DEBUG:root:training time = %d0.186406
INFO:root:frame =12785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000745058059692
INFO:root:frame =12786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000333786010742
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:random_action_porb = 0.898951666667
DEBUG:root: dqn, choose action rondomly, need time 0.00022100000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =12789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =12790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000343084335327
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.89892
DEBUG:root: dqn, choose action rondomly, need time 0.000167000000033
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:training error  = [[ 65.12304688]
 [ 64.61131287]
 [ 61.93201828]
 [ 65.58340454]
 [ 64.86250305]
 [ 62.55391693]
 [ 68.57632446]
 [ 67.83734894]
 [ 66.76507568]
 [ 66.65490723]
 [ 63.97192764]
 [ 66.15157318]
 [ 67.6783371 ]
 [ 66.26704407]
 [ 68.20633698]
 [ 64.02685547]]
DEBUG:root:training time = %d0.190003
INFO:root:frame =12793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00065803527832
INFO:root:frame =12794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:random_action_porb = 0.898888333333
DEBUG:root: dqn, choose action rondomly, need time 0.000256999999976
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =12797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =12798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000321865081787
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.898856666667
DEBUG:root: dqn, choose action rondomly, need time 0.000251999999989
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000188112258911
INFO:root:training error  = [[ 62.62103271]
 [ 63.60145187]
 [ 64.45833588]
 [ 72.62792206]
 [ 68.18592072]
 [ 67.6969223 ]
 [ 61.9951973 ]
 [ 60.30895996]
 [ 64.93208313]
 [ 62.48804092]
 [ 63.62335968]
 [ 63.81239319]
 [ 66.23251343]
 [ 68.43411255]
 [ 67.10663605]
 [ 66.89555359]]
DEBUG:root:training time = %d0.192593
INFO:root:frame =12801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =12802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000291109085083
DEBUG:root: save sample needs time = 0.000134944915771
INFO:root:random_action_porb = 0.898825
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355958938599
INFO:root:frame =12805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000417947769165
INFO:root:frame =12806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000358819961548
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:random_action_porb = 0.898793333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:training error  = [[ 63.41661835]
 [ 62.5585022 ]
 [ 65.69911957]
 [ 67.4074707 ]
 [ 62.82091141]
 [ 66.80797577]
 [ 66.90953064]
 [ 65.79760742]
 [ 63.97485733]
 [ 62.7590065 ]
 [ 62.51675034]
 [ 64.75170898]
 [ 66.86211395]
 [ 66.39653778]
 [ 68.62965393]
 [ 68.44244385]]
DEBUG:root:training time = %d0.234532
INFO:root:frame =12809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =12810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.898761666667
DEBUG:root: dqn, choose action rondomly, need time 0.000255000000038
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =12813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =12814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000349998474121
DEBUG:root: save sample needs time = 0.000179052352905
INFO:root:random_action_porb = 0.89873
DEBUG:root: dqn, choose action rondomly, need time 0.000182999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 64.10820007]
 [ 79.95420074]
 [ 65.96282196]
 [ 64.59340668]
 [ 69.26366425]
 [ 63.44384003]
 [ 66.1396637 ]
 [ 63.55327225]
 [ 69.8449707 ]
 [ 82.89872742]
 [ 66.88232422]
 [ 65.56858063]
 [ 79.95420074]
 [ 69.93426514]
 [ 66.87882996]
 [ 68.9977417 ]]
DEBUG:root:training time = %d0.204858
INFO:root:frame =12817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =12818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308036804199
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.898698333333
DEBUG:root: dqn, choose action rondomly, need time 0.000243000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000175952911377
INFO:root:frame =12821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =12822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.898666666667
DEBUG:root: dqn, choose action rondomly, need time 0.000261999999964
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 62.07091141]
 [ 59.7941246 ]
 [ 62.89494705]
 [ 68.95059967]
 [ 71.48370361]
 [ 63.92140961]
 [ 66.32245636]
 [ 61.05208588]
 [ 83.51086426]
 [ 64.3608551 ]
 [ 70.91333008]
 [ 87.2135849 ]
 [ 66.75086212]
 [ 66.92900848]
 [ 70.37903595]
 [ 82.70294952]]
DEBUG:root:training time = %d0.243335
INFO:root:frame =12825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =12826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.898635
DEBUG:root: dqn, choose action rondomly, need time 0.000333000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000292778015137
INFO:root:frame =12829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =12830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464200973511
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.898603333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:training error  = [[ 64.69327545]
 [ 64.92617798]
 [ 68.31248474]
 [ 65.69367981]
 [ 62.283638  ]
 [ 69.91282654]
 [ 67.27599335]
 [ 68.98912811]
 [ 65.69367981]
 [ 66.16075897]
 [ 67.09938812]
 [ 64.69327545]
 [ 68.38640594]
 [ 69.55579376]
 [ 65.70876312]
 [ 66.46692657]]
DEBUG:root:training time = %d0.230737
INFO:root:frame =12833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:frame =12834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.898571666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =12837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440835952759
INFO:root:frame =12838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456809997559
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.89854
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 64.40248871]
 [ 66.22928619]
 [ 70.03842926]
 [ 65.40879059]
 [ 65.49668884]
 [ 86.58970642]
 [ 85.28354645]
 [ 64.06983948]
 [ 66.19055176]
 [ 69.05250549]
 [ 85.28354645]
 [ 68.06451416]
 [ 62.56598663]
 [ 63.45113373]
 [ 63.63723373]
 [ 64.00830078]]
DEBUG:root:training time = %d0.236823
INFO:root:frame =12841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:frame =12842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:random_action_porb = 0.898508333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999968
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000361919403076
INFO:root:frame =12845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =12846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.898476666667
DEBUG:root: dqn, choose action rondomly, need time 0.000257999999974
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 65.6496582 ]
 [ 67.04465485]
 [ 67.05239868]
 [ 70.09053802]
 [ 62.07980728]
 [ 80.25547028]
 [ 67.70219421]
 [ 66.42662811]
 [ 64.45392609]
 [ 68.02902222]
 [ 64.09525299]
 [ 55.0975914 ]
 [ 72.05325317]
 [ 67.58322144]
 [ 65.4581604 ]
 [ 69.39757538]]
DEBUG:root:training time = %d0.206654
INFO:root:frame =12849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =12850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00037693977356
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.898445
DEBUG:root: dqn, choose action rondomly, need time 0.000368999999978
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:frame =12853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =12854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000612020492554
DEBUG:root: save sample needs time = 0.00016713142395
INFO:root:random_action_porb = 0.898413333333
INFO:root:dqn select action Tensor("ArgMax_169:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012187
INFO:root:action choosen by dqn [4]
INFO:root:frame =12856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 69.21186066]
 [ 63.07999039]
 [ 67.127388  ]
 [ 64.60665894]
 [ 65.14102936]
 [ 87.78222656]
 [ 64.00585938]
 [ 83.15260315]
 [ 70.13321686]
 [ 62.54281235]
 [ 64.99259186]
 [ 52.93241882]
 [ 70.10842133]
 [ 62.85187531]
 [ 51.18745804]
 [ 64.66062927]]
DEBUG:root:training time = %d0.212333
INFO:root:frame =12857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =12858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
DEBUG:root: save sample needs time = 0.00011420249939
INFO:root:random_action_porb = 0.898381666667
DEBUG:root: dqn, choose action rondomly, need time 0.000187000000039
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:frame =12861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =12862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000617980957031
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:random_action_porb = 0.89835
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:training error  = [[ 61.7738533 ]
 [ 67.08139038]
 [ 66.12229156]
 [ 63.15102768]
 [ 72.13876343]
 [ 66.86585999]
 [ 63.76413345]
 [ 61.7738533 ]
 [ 65.63704681]
 [ 62.76867676]
 [ 73.56407166]
 [ 69.83731842]
 [ 64.16441345]
 [ 67.97994232]
 [ 69.66247559]
 [ 67.00267792]]
DEBUG:root:training time = %d0.236997
INFO:root:frame =12865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =12866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227928161621
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.898318333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000048
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000341176986694
INFO:root:frame =12869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =12870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.898286666667
INFO:root:dqn select action Tensor("ArgMax_170:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011693
INFO:root:action choosen by dqn [4]
INFO:root:frame =12872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000380039215088
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 68.88954163]
 [ 66.25810242]
 [ 64.98889923]
 [ 66.79125977]
 [ 64.60297394]
 [ 66.88182831]
 [ 66.32170868]
 [ 67.32255554]
 [ 65.11171722]
 [ 66.43260193]
 [ 67.26597595]
 [ 82.6102829 ]
 [ 65.73474121]
 [ 69.63446045]
 [ 65.42607117]
 [ 68.6574707 ]]
DEBUG:root:training time = %d0.220468
INFO:root:frame =12873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =12874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000111103057861
INFO:root:random_action_porb = 0.898255
DEBUG:root: dqn, choose action rondomly, need time 0.00018300000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root:frame =12877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =12878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:random_action_porb = 0.898223333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000046
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 61.57756805]
 [ 65.90483856]
 [ 67.75744629]
 [ 61.11147308]
 [ 66.72418976]
 [ 65.5557251 ]
 [ 63.42560959]
 [ 64.76398468]
 [ 64.04517365]
 [ 66.29362488]
 [ 66.2148819 ]
 [ 64.08034515]
 [ 70.30045319]
 [ 70.78360748]
 [ 84.39810181]
 [ 68.01869965]]
DEBUG:root:training time = %d0.228353
INFO:root:frame =12881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268220901489
INFO:root:frame =12882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000313997268677
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.898191666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000041
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =12885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000494003295898
INFO:root:frame =12886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.89816
DEBUG:root: dqn, choose action rondomly, need time 0.000518
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 65.63011932]
 [ 67.10638428]
 [ 51.24598694]
 [ 60.63645935]
 [ 68.12419891]
 [ 65.86569977]
 [ 67.84740448]
 [ 63.71223831]
 [ 68.71640015]
 [ 67.06789398]
 [ 66.31524658]
 [ 66.23723602]
 [ 87.47626495]
 [ 70.35112762]
 [ 64.88634491]
 [ 65.9308548 ]]
DEBUG:root:training time = %d0.208625
INFO:root:frame =12889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274181365967
INFO:root:frame =12890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504970550537
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.898128333333
DEBUG:root: dqn, choose action rondomly, need time 0.000256000000036
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =12893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =12894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000496864318848
INFO:root:frame = 12895 State into memory, numbers recorded 340 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000540971755981
INFO:root:random_action_porb = 0.898096666667
DEBUG:root: dqn, choose action rondomly, need time 0.000328000000025
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12896current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:training error  = [[ 72.85384369]
 [ 67.27098083]
 [ 61.41148376]
 [ 64.21746826]
 [ 67.71625519]
 [ 72.12528229]
 [ 65.454216  ]
 [ 66.33538055]
 [ 68.21944427]
 [ 67.21918488]
 [ 66.17614746]
 [ 68.19902802]
 [ 71.5327301 ]
 [ 75.3187027 ]
 [ 65.39472198]
 [ 72.12528229]]
DEBUG:root:training time = %d0.216829
INFO:root:frame =12897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:frame =12898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:random_action_porb = 0.898065
DEBUG:root: dqn, choose action rondomly, need time 0.000210000000038
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =12901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =12902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509023666382
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.898033333333
DEBUG:root: dqn, choose action rondomly, need time 0.000462000000027
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000386953353882
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 64.60640717]
 [ 69.65891266]
 [ 67.9059906 ]
 [ 64.6076355 ]
 [ 84.12245178]
 [ 69.57870483]
 [ 83.16623688]
 [ 66.07787323]
 [ 66.81246185]
 [ 69.60135651]
 [ 66.70150757]
 [ 70.35266113]
 [ 70.30889893]
 [ 66.26232147]
 [ 67.20141602]
 [ 54.00554276]]
DEBUG:root:training time = %d0.203568
INFO:root:frame =12905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =12906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480175018311
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:random_action_porb = 0.898001666667
DEBUG:root: dqn, choose action rondomly, need time 0.000254999999981
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =12909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =12910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.89797
DEBUG:root: dqn, choose action rondomly, need time 0.000188000000037
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000168085098267
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 83.8735199 ]
 [ 87.05747986]
 [ 71.55080414]
 [ 67.5588913 ]
 [ 67.84967041]
 [ 65.80874634]
 [ 68.95237732]
 [ 89.33676147]
 [ 84.258255  ]
 [ 68.0700531 ]
 [ 87.05747986]
 [ 68.02625275]
 [ 69.75114441]
 [ 84.258255  ]
 [ 64.95839691]
 [ 70.7789917 ]]
DEBUG:root:training time = %d0.218661
INFO:root:frame =12913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250816345215
INFO:root:frame =12914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:frame = 12915 State into memory, numbers recorded 341 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:random_action_porb = 0.897938333333
DEBUG:root: dqn, choose action rondomly, need time 0.000339999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12916current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =12917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =12918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
DEBUG:root: save sample needs time = 0.0001060962677
INFO:root:random_action_porb = 0.897906666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 66.38137054]
 [ 68.68199921]
 [ 66.70075989]
 [ 73.49106598]
 [ 67.01791382]
 [ 66.97669983]
 [ 68.3551178 ]
 [ 73.1865921 ]
 [ 69.01776886]
 [ 86.48210907]
 [ 68.22120667]
 [ 65.93531036]
 [ 76.88246918]
 [ 76.13265228]
 [ 75.68171692]
 [ 78.29640961]]
DEBUG:root:training time = %d0.210878
INFO:root:frame =12921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =12922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002601146698
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.897875
DEBUG:root: dqn, choose action rondomly, need time 0.000186999999983
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =12924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000179052352905
INFO:root:frame =12925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =12926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.897843333333
DEBUG:root: dqn, choose action rondomly, need time 0.000185999999985
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 69.77127838]
 [ 67.00817108]
 [ 88.15002441]
 [ 71.62593842]
 [ 67.85821533]
 [ 70.73046875]
 [ 84.53553009]
 [ 63.62189865]
 [ 70.2966156 ]
 [ 69.72693634]
 [ 70.83856201]
 [ 68.04915619]
 [ 68.56394196]
 [ 70.35675812]
 [ 69.31878662]
 [ 70.35675812]]
DEBUG:root:training time = %d0.188958
INFO:root:frame =12929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =12930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298023223877
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:random_action_porb = 0.897811666667
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:frame =12933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =12934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.89778
DEBUG:root: dqn, choose action rondomly, need time 0.000239000000022
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 72.35224152]
 [ 66.66113281]
 [ 67.8562088 ]
 [ 68.55079651]
 [ 70.91384125]
 [ 85.11594391]
 [ 84.0365448 ]
 [ 64.27617645]
 [ 69.0251236 ]
 [ 64.74212646]
 [ 66.88282776]
 [ 66.62401581]
 [ 84.52515411]
 [ 64.1160202 ]
 [ 84.52515411]
 [ 65.4581604 ]]
DEBUG:root:training time = %d0.190517
INFO:root:frame =12937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =12938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame = 12939 State into memory, numbers recorded 342 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root:random_action_porb = 0.897748333333
DEBUG:root: dqn, choose action rondomly, need time 0.00017600000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12940current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000176906585693
INFO:root:frame =12941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:frame =12942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237226486206
DEBUG:root: save sample needs time = 0.000107049942017
INFO:root:random_action_porb = 0.897716666667
DEBUG:root: dqn, choose action rondomly, need time 0.000182999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00015115737915
INFO:root:training error  = [[ 69.27280426]
 [ 66.29387665]
 [ 74.87651825]
 [ 70.97090912]
 [ 68.78775787]
 [ 66.23524475]
 [ 62.92108917]
 [ 66.51694489]
 [ 67.93063354]
 [ 69.34368896]
 [ 71.91757202]
 [ 69.60746765]
 [ 66.82044983]
 [ 65.30738831]
 [ 70.1843338 ]
 [ 66.59587097]]
DEBUG:root:training time = %d0.186638
INFO:root:frame =12945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00070595741272
INFO:root:frame =12946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000243902206421
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.897685
DEBUG:root: dqn, choose action rondomly, need time 0.000166999999976
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:frame =12949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =12950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame = 12951 State into memory, numbers recorded 343 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:random_action_porb = 0.897653333333
DEBUG:root: dqn, choose action rondomly, need time 0.000170999999966
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12952current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 53.37339783]
 [ 67.79890442]
 [ 67.65876007]
 [ 69.63420868]
 [ 68.6782074 ]
 [ 65.21173859]
 [ 69.08674622]
 [ 71.86349487]
 [ 68.36042023]
 [ 67.36963654]
 [ 84.39810181]
 [ 68.45885468]
 [ 66.6531601 ]
 [ 65.8191452 ]
 [ 72.12839508]
 [ 69.56877136]]
DEBUG:root:training time = %d0.191569
INFO:root:frame =12953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =12954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247001647949
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:random_action_porb = 0.897621666667
DEBUG:root: dqn, choose action rondomly, need time 0.000171000000023
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142812728882
INFO:root:frame =12957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:frame =12958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239133834839
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:random_action_porb = 0.89759
DEBUG:root: dqn, choose action rondomly, need time 0.000201000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:training error  = [[ 64.31263733]
 [ 73.20800781]
 [ 61.84606934]
 [ 72.03874207]
 [ 66.57595062]
 [ 71.91602325]
 [ 66.1446228 ]
 [ 69.73381805]
 [ 69.6367569 ]
 [ 67.74162292]
 [ 70.43305969]
 [ 66.51545715]
 [ 74.51622772]
 [ 78.33287048]
 [ 68.44976807]
 [ 66.05753326]]
DEBUG:root:training time = %d0.188448
INFO:root:frame =12961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =12962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000120878219604
INFO:root:random_action_porb = 0.897558333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000509023666382
INFO:root:frame =12965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =12966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274181365967
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:random_action_porb = 0.897526666667
DEBUG:root: dqn, choose action rondomly, need time 0.000182999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 70.2104187 ]
 [ 70.6552887 ]
 [ 67.72679901]
 [ 67.64218903]
 [ 87.39009094]
 [ 54.59766006]
 [ 66.07142639]
 [ 72.01776123]
 [ 70.50222778]
 [ 68.66960907]
 [ 65.26226807]
 [ 73.55700684]
 [ 69.67368317]
 [ 67.67457581]
 [ 66.67783356]
 [ 73.47563171]]
DEBUG:root:training time = %d0.191905
INFO:root:frame =12969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =12970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239133834839
DEBUG:root: save sample needs time = 0.000127792358398
INFO:root:random_action_porb = 0.897495
DEBUG:root: dqn, choose action rondomly, need time 0.00023299999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:frame =12973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =12974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000348091125488
DEBUG:root: save sample needs time = 0.000130176544189
INFO:root:random_action_porb = 0.897463333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:training error  = [[ 69.54485321]
 [ 71.12601471]
 [ 73.49237061]
 [ 68.63800049]
 [ 67.69616699]
 [ 75.10326385]
 [ 70.97399139]
 [ 68.05821991]
 [ 69.05783844]
 [ 69.78759766]
 [ 67.40972137]
 [ 75.12416077]
 [ 66.90603638]
 [ 71.20479584]
 [ 67.5528717 ]
 [ 66.60633087]]
DEBUG:root:training time = %d0.194297
INFO:root:frame =12977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =12978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264167785645
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.897431666667
DEBUG:root: dqn, choose action rondomly, need time 0.000188999999978
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =12980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:frame =12981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =12982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000326871871948
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root:random_action_porb = 0.8974
DEBUG:root: dqn, choose action rondomly, need time 0.000254999999981
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =12984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 70.05732727]
 [ 64.56668091]
 [ 71.66520691]
 [ 67.56616211]
 [ 68.57328796]
 [ 69.8908844 ]
 [ 67.44004059]
 [ 65.61801147]
 [ 88.71768188]
 [ 69.80926514]
 [ 69.01117706]
 [ 72.46234131]
 [ 68.49168396]
 [ 72.28762054]
 [ 71.46744537]
 [ 66.33836365]]
DEBUG:root:training time = %d0.18898
INFO:root:frame =12985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =12986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000353097915649
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:random_action_porb = 0.897368333333
DEBUG:root: dqn, choose action rondomly, need time 0.000253000000043
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:frame =12989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000358104705811
INFO:root:frame =12990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239133834839
DEBUG:root: save sample needs time = 0.000106811523438
INFO:root:random_action_porb = 0.897336666667
DEBUG:root: dqn, choose action rondomly, need time 0.000185999999985
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =12992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 84.66690063]
 [ 76.24213409]
 [ 68.70121765]
 [ 74.56655884]
 [ 66.2131424 ]
 [ 85.50463867]
 [ 92.84870148]
 [ 68.98709869]
 [ 68.97315979]
 [ 90.44638062]
 [ 70.86142731]
 [ 79.14716339]
 [ 70.48711395]
 [ 68.70121765]
 [ 67.68185425]
 [ 65.22135162]]
DEBUG:root:training time = %d0.18826
INFO:root:frame =12993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame =12994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:frame = 12995 State into memory, numbers recorded 344 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000381946563721
INFO:root:random_action_porb = 0.897305
DEBUG:root: dqn, choose action rondomly, need time 0.000240000000019
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =12996current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =12997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame =12998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000320911407471
DEBUG:root: save sample needs time = 0.000109910964966
DEBUG:root:one frame running time = 0.00331299999999
DEBUG:root:total training time = 385.242864
INFO:root:frame num = 13000 frame round: 0
INFO:root:random_action_porb = 0.897273333333
DEBUG:root: dqn, choose action rondomly, need time 0.000204999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000274181365967
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 68.10581207]
 [ 67.4641037 ]
 [ 66.86585999]
 [ 72.82675171]
 [ 70.19456482]
 [ 71.08072662]
 [ 74.640625  ]
 [ 67.68963623]
 [ 73.44241333]
 [ 75.86395264]
 [ 72.87390137]
 [ 66.37664795]
 [ 68.60766602]
 [ 73.09968567]
 [ 65.49668884]
 [ 92.46740723]]
DEBUG:root:training time = %d0.192468
INFO:root:frame =13001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =13002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000334978103638
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:random_action_porb = 0.897241666667
INFO:root:dqn select action Tensor("ArgMax_171:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011598
INFO:root:action choosen by dqn [4]
INFO:root:frame =13004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =13005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =13006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239133834839
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.89721
DEBUG:root: dqn, choose action rondomly, need time 0.000265000000013
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:training error  = [[ 70.38261414]
 [ 67.96710968]
 [ 70.23138428]
 [ 68.86092377]
 [ 66.48484039]
 [ 77.77261353]
 [ 71.03313446]
 [ 70.18612671]
 [ 71.07275391]
 [ 70.13935089]
 [ 67.76197052]
 [ 71.09796906]
 [ 66.47364807]
 [ 71.09050751]
 [ 71.24240112]
 [ 75.28453827]]
DEBUG:root:training time = %d0.190528
INFO:root:frame =13009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =13010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240087509155
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.897178333333
DEBUG:root: dqn, choose action rondomly, need time 0.000204999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:frame =13013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =13014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000370025634766
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.897146666667
DEBUG:root: dqn, choose action rondomly, need time 0.000161999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root:training error  = [[ 71.19810486]
 [ 70.20249176]
 [ 71.19810486]
 [ 71.19810486]
 [ 76.87524414]
 [ 74.32247162]
 [ 68.50482178]
 [ 73.14196014]
 [ 68.6299057 ]
 [ 70.20249176]
 [ 68.99622345]
 [ 72.40078735]
 [ 72.6086731 ]
 [ 67.79186249]
 [ 74.15312958]
 [ 70.19507599]]
DEBUG:root:training time = %d0.186987
INFO:root:frame =13017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =13018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:random_action_porb = 0.897115
DEBUG:root: dqn, choose action rondomly, need time 0.000230999999985
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:frame =13021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =13022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00036096572876
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:random_action_porb = 0.897083333333
DEBUG:root: dqn, choose action rondomly, need time 0.000225999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 77.6932373 ]
 [ 69.74273682]
 [ 68.21768188]
 [ 68.64356232]
 [ 70.43050385]
 [ 75.11463928]
 [ 68.95339203]
 [ 67.64646149]
 [ 74.04122162]
 [ 74.04122162]
 [ 70.65862274]
 [ 72.36547852]
 [ 70.17155457]
 [ 68.91969299]
 [ 94.05797577]
 [ 69.03374481]]
DEBUG:root:training time = %d0.186098
INFO:root:frame =13025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =13026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000336170196533
INFO:root:frame = 13027 State into memory, numbers recorded 345 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000411033630371
INFO:root:random_action_porb = 0.897051666667
DEBUG:root: dqn, choose action rondomly, need time 0.000240000000019
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13028current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:frame =13029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =13030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000300884246826
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:random_action_porb = 0.89702
DEBUG:root: dqn, choose action rondomly, need time 0.000256999999976
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 71.21741486]
 [ 93.50650024]
 [ 74.79045868]
 [ 63.44043732]
 [ 73.60202789]
 [ 66.36794281]
 [ 73.99108124]
 [ 72.35301971]
 [ 70.81545258]
 [ 72.34030151]
 [ 71.69569397]
 [ 73.91077423]
 [ 71.46460724]
 [ 66.48633575]
 [ 99.13396454]
 [ 67.91227722]]
DEBUG:root:training time = %d0.1896
INFO:root:frame =13033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =13034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000313997268677
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:random_action_porb = 0.896988333333
DEBUG:root: dqn, choose action rondomly, need time 0.00019599999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000181913375854
INFO:root:frame =13037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =13038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000326871871948
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:random_action_porb = 0.896956666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 77.55826569]
 [ 78.48176575]
 [ 69.02968597]
 [ 87.86230469]
 [ 76.60656738]
 [ 63.6791153 ]
 [ 70.82983398]
 [ 70.29277802]
 [ 72.19165039]
 [ 68.51719666]
 [ 66.16770935]
 [ 68.52073669]
 [ 76.60656738]
 [ 71.75074005]
 [ 66.76158905]
 [ 71.71946716]]
DEBUG:root:training time = %d0.189404
INFO:root:frame =13041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =13042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248908996582
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.896925
DEBUG:root: dqn, choose action rondomly, need time 0.000225
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:frame =13045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =13046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame = 13047 State into memory, numbers recorded 346 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:random_action_porb = 0.896893333333
DEBUG:root: dqn, choose action rondomly, need time 0.000181999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13048current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:training error  = [[ 74.32562256]
 [ 70.39490509]
 [ 69.41410065]
 [ 74.56839752]
 [ 73.27381897]
 [ 71.70835876]
 [ 71.81925964]
 [ 72.17064667]
 [ 71.40090179]
 [ 72.17064667]
 [ 71.59339905]
 [ 71.06786346]
 [ 68.34048462]
 [ 72.7400589 ]
 [ 69.05276489]
 [ 69.74732208]]
DEBUG:root:training time = %d0.186413
INFO:root:frame =13049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280141830444
INFO:root:frame =13050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247955322266
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.896861666667
DEBUG:root: dqn, choose action rondomly, need time 0.000259999999969
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:frame =13053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =13054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root:frame = 13055 State into memory, numbers recorded 347 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:random_action_porb = 0.89683
DEBUG:root: dqn, choose action rondomly, need time 0.000170999999966
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13056current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000155925750732
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 69.21871185]
 [ 88.04375458]
 [ 78.63973236]
 [ 69.71419525]
 [ 68.88143921]
 [ 73.11090088]
 [ 69.38562775]
 [ 74.48751831]
 [ 67.06589508]
 [ 71.66107178]
 [ 80.86711884]
 [ 69.95391846]
 [ 71.63214111]
 [ 73.03603363]
 [ 71.76522064]
 [ 73.92835236]]
DEBUG:root:training time = %d0.191227
INFO:root:frame =13057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =13058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:frame = 13059 State into memory, numbers recorded 348 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000353813171387
INFO:root:random_action_porb = 0.896798333333
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000026
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13060current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =13061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000475168228149
INFO:root:frame =13062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509977340698
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.896766666667
DEBUG:root: dqn, choose action rondomly, need time 0.000202000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000145196914673
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 74.47356415]
 [ 72.73744965]
 [ 67.67482758]
 [ 68.18113708]
 [ 56.21292877]
 [ 70.05886078]
 [ 70.56681824]
 [ 70.51274109]
 [ 88.3346405 ]
 [ 68.17030334]
 [ 72.49819946]
 [ 72.6071167 ]
 [ 68.7308197 ]
 [ 71.86297607]
 [ 71.32330322]
 [ 75.28083038]]
DEBUG:root:training time = %d0.186968
INFO:root:frame =13065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =13066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265836715698
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.896735
DEBUG:root: dqn, choose action rondomly, need time 0.000243000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000181913375854
INFO:root:frame =13069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =13070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000108957290649
INFO:root:random_action_porb = 0.896703333333
DEBUG:root: dqn, choose action rondomly, need time 0.000160999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 74.63218689]
 [ 89.81015015]
 [ 79.94956207]
 [ 74.29484558]
 [ 71.19861603]
 [ 69.02436066]
 [ 68.26103973]
 [ 87.50880432]
 [ 87.50880432]
 [ 81.12117004]
 [ 77.78283691]
 [ 88.63549042]
 [ 77.15538025]
 [ 71.65332031]
 [ 73.40920258]
 [ 75.79592133]]
DEBUG:root:training time = %d0.205327
INFO:root:frame =13073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229835510254
INFO:root:frame =13074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000141859054565
INFO:root:random_action_porb = 0.896671666667
DEBUG:root: dqn, choose action rondomly, need time 0.000246000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root:frame =13077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =13078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000266075134277
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.89664
DEBUG:root: dqn, choose action rondomly, need time 0.000190999999973
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000189065933228
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 70.34472656]
 [ 71.98617554]
 [ 71.74790192]
 [ 72.22872925]
 [ 70.70814514]
 [ 69.91001892]
 [ 79.54595184]
 [ 70.95317078]
 [ 71.69646454]
 [ 70.69608307]
 [ 88.5217514 ]
 [ 71.94940948]
 [ 69.18418884]
 [ 72.22872925]
 [ 68.74625397]
 [ 76.96169281]]
DEBUG:root:training time = %d0.187121
INFO:root:frame =13081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:frame =13082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.896608333333
DEBUG:root: dqn, choose action rondomly, need time 0.000160999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:frame =13085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =13086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247001647949
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.896576666667
DEBUG:root: dqn, choose action rondomly, need time 0.000188000000037
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 73.38540649]
 [ 76.64556885]
 [ 92.13814545]
 [ 70.72251892]
 [ 89.34542084]
 [ 74.12738037]
 [ 69.14459229]
 [ 74.12738037]
 [ 88.83441925]
 [ 74.55917358]
 [ 72.79290009]
 [ 76.55502319]
 [ 67.73182678]
 [ 55.33070755]
 [ 70.97013855]
 [ 75.53231812]]
DEBUG:root:training time = %d0.193082
INFO:root:frame =13089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000360012054443
INFO:root:frame =13090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436782836914
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:random_action_porb = 0.896545
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000018
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =13093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =13094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424146652222
DEBUG:root: save sample needs time = 0.000276803970337
INFO:root:random_action_porb = 0.896513333333
DEBUG:root: dqn, choose action rondomly, need time 0.000167999999974
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000151872634888
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 69.14459229]
 [ 56.81998062]
 [ 70.62477112]
 [ 69.33885956]
 [ 76.57104492]
 [ 71.97840881]
 [ 74.02835846]
 [ 75.77493286]
 [ 69.32666016]
 [ 70.37493896]
 [ 68.98075867]
 [ 71.41095734]
 [ 71.13090515]
 [ 70.62477112]
 [ 80.80264282]
 [ 70.96216583]]
DEBUG:root:training time = %d0.209933
INFO:root:frame =13097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =13098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.896481666667
DEBUG:root: dqn, choose action rondomly, need time 0.000307999999961
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332832336426
INFO:root:frame =13101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =13102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509023666382
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.89645
DEBUG:root: dqn, choose action rondomly, need time 0.000272999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000485897064209
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 69.95570374]
 [ 57.54922485]
 [ 71.05165863]
 [ 80.31398773]
 [ 71.05165863]
 [ 67.77377319]
 [ 91.6396637 ]
 [ 71.28774261]
 [ 69.11820221]
 [ 72.65393066]
 [ 70.76204681]
 [ 71.83503723]
 [ 71.75669098]
 [ 72.64326477]
 [ 75.50341034]
 [ 71.58617401]]
DEBUG:root:training time = %d0.191339
INFO:root:frame =13105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:frame =13106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255823135376
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.896418333333
DEBUG:root: dqn, choose action rondomly, need time 0.00041299999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =13109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000269174575806
INFO:root:frame =13110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000414133071899
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:random_action_porb = 0.896386666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 72.13694763]
 [ 71.73316956]
 [ 73.71858215]
 [ 72.62635803]
 [ 69.38536835]
 [ 71.15922546]
 [ 90.32104492]
 [ 70.92900848]
 [ 72.76738739]
 [ 76.84340668]
 [ 71.52111816]
 [ 72.59358978]
 [ 73.20513153]
 [ 89.46112823]
 [ 69.54637909]
 [ 90.38428497]]
DEBUG:root:training time = %d0.212403
INFO:root:frame =13113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000341176986694
INFO:root:frame =13114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000304937362671
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.896355
DEBUG:root: dqn, choose action rondomly, need time 0.000603000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =13117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491857528687
INFO:root:frame =13118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000517845153809
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.896323333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000346899032593
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 73.84126282]
 [ 74.2538147 ]
 [ 75.92190552]
 [ 73.38749695]
 [ 75.5851059 ]
 [ 71.09307861]
 [ 73.92467499]
 [ 74.44011688]
 [ 72.07501221]
 [ 77.27069092]
 [ 73.23490143]
 [ 70.78001404]
 [ 93.71702576]
 [ 74.27643585]
 [ 73.75946808]
 [ 88.72831726]]
DEBUG:root:training time = %d0.225227
INFO:root:frame =13121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:frame =13122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000251054763794
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.896291666667
DEBUG:root: dqn, choose action rondomly, need time 0.000269000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =13125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000492811203003
INFO:root:frame =13126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:random_action_porb = 0.89626
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000041
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root:training error  = [[ 70.76358032]
 [ 76.20030212]
 [ 69.10906982]
 [ 79.50458527]
 [ 66.76332855]
 [ 68.78927612]
 [ 74.35903931]
 [ 71.56655121]
 [ 74.46618652]
 [ 70.74638367]
 [ 74.97795868]
 [ 74.46618652]
 [ 70.89431   ]
 [ 76.39916229]
 [ 73.26702881]
 [ 73.26702881]]
DEBUG:root:training time = %d0.208383
INFO:root:frame =13129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =13130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000518798828125
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.896228333333
INFO:root:dqn select action Tensor("ArgMax_172:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010319
INFO:root:action choosen by dqn [4]
INFO:root:frame =13132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root:frame =13133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000346899032593
INFO:root:frame =13134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000361919403076
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:random_action_porb = 0.896196666667
INFO:root:dqn select action Tensor("ArgMax_173:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011208
INFO:root:action choosen by dqn [4]
INFO:root:frame =13136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 72.33744049]
 [ 75.20829773]
 [ 76.44612122]
 [ 71.26944733]
 [ 73.3637085 ]
 [ 77.65934753]
 [ 72.01725006]
 [ 75.00227356]
 [ 74.90609741]
 [ 76.3458252 ]
 [ 73.37730408]
 [ 81.8868103 ]
 [ 77.58110809]
 [ 76.07568359]
 [ 58.12922287]
 [ 67.0381546 ]]
DEBUG:root:training time = %d0.200258
INFO:root:frame =13137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:frame =13138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:random_action_porb = 0.896165
INFO:root:dqn select action Tensor("ArgMax_174:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01389
INFO:root:action choosen by dqn [4]
INFO:root:frame =13140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =13141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame =13142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.00016713142395
INFO:root:random_action_porb = 0.896133333333
DEBUG:root: dqn, choose action rondomly, need time 0.000237999999968
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000364065170288
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 72.26478577]
 [ 72.17401886]
 [ 72.44676208]
 [ 70.98633575]
 [ 74.61795044]
 [ 70.7048111 ]
 [ 73.30987549]
 [ 71.49918365]
 [ 74.29458618]
 [ 72.47975159]
 [ 71.34778595]
 [ 72.33562469]
 [ 71.65229034]
 [ 77.05435181]
 [ 88.60704803]
 [ 74.28143311]]
DEBUG:root:training time = %d0.210208
INFO:root:frame =13145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =13146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame = 13147 State into memory, numbers recorded 349 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.00061297416687
INFO:root:random_action_porb = 0.896101666667
DEBUG:root: dqn, choose action rondomly, need time 0.000201000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13148current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =13149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =13150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:random_action_porb = 0.89607
DEBUG:root: dqn, choose action rondomly, need time 0.000255999999979
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000270128250122
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 74.92405701]
 [ 71.47879791]
 [ 81.09203339]
 [ 73.25553131]
 [ 76.99436188]
 [ 71.07378387]
 [ 77.37937164]
 [ 75.34757233]
 [ 70.98427582]
 [ 77.25379181]
 [ 76.60870361]
 [ 74.25933838]
 [ 75.61933899]
 [ 74.10189819]
 [ 80.79550934]
 [ 60.54500198]]
DEBUG:root:training time = %d0.197746
INFO:root:frame =13153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =13154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000420093536377
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.896038333333
DEBUG:root: dqn, choose action rondomly, need time 0.000168999999971
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143766403198
INFO:root:frame =13157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000597953796387
INFO:root:frame =13158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000328063964844
DEBUG:root: save sample needs time = 0.000179052352905
INFO:root:random_action_porb = 0.896006666667
DEBUG:root: dqn, choose action rondomly, need time 0.00018799999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180959701538
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 73.70155334]
 [ 75.93280792]
 [ 76.48455048]
 [ 74.11030579]
 [ 73.79747772]
 [ 72.69425201]
 [ 70.49915314]
 [ 75.42308807]
 [ 81.34175873]
 [ 74.57788849]
 [ 75.38943481]
 [ 75.31260681]
 [ 70.32988739]
 [ 91.14660645]
 [ 75.08792877]
 [ 74.93779755]]
DEBUG:root:training time = %d0.190304
INFO:root:frame =13161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =13162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000338077545166
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.895975
DEBUG:root: dqn, choose action rondomly, need time 0.000261000000023
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =13165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =13166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.895943333333
DEBUG:root: dqn, choose action rondomly, need time 0.000239999999962
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174045562744
INFO:root:training error  = [[ 74.11083221]
 [ 74.10346985]
 [ 78.08296204]
 [ 74.2135849 ]
 [ 77.52091217]
 [ 73.84965515]
 [ 77.58272552]
 [ 75.50182343]
 [ 71.50408936]
 [ 74.54125977]
 [ 76.77841187]
 [ 71.77711487]
 [ 81.55961609]
 [ 67.56465912]
 [ 74.75008392]
 [ 69.73330688]]
DEBUG:root:training time = %d0.198385
INFO:root:frame =13169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000394821166992
INFO:root:frame =13170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000496864318848
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.895911666667
DEBUG:root: dqn, choose action rondomly, need time 0.000192999999967
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:frame =13173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000586032867432
INFO:root:frame =13174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0003821849823
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:random_action_porb = 0.89588
INFO:root:dqn select action Tensor("ArgMax_175:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011182
INFO:root:action choosen by dqn [4]
INFO:root:frame =13176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 91.43907166]
 [ 76.96356964]
 [ 90.43738556]
 [ 73.66906738]
 [ 69.7121582 ]
 [ 70.07827759]
 [ 94.54606628]
 [ 75.61960602]
 [ 80.35365295]
 [ 91.17836761]
 [ 76.15795135]
 [ 75.46152496]
 [ 71.45480347]
 [ 77.36031342]
 [ 74.84879303]
 [ 72.22950745]]
DEBUG:root:training time = %d0.196771
INFO:root:frame =13177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =13178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480890274048
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:random_action_porb = 0.895848333333
DEBUG:root: dqn, choose action rondomly, need time 0.00050600000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =13181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =13182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.895816666667
DEBUG:root: dqn, choose action rondomly, need time 0.000451000000055
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 73.45758057]
 [ 81.82938385]
 [ 92.41869354]
 [ 68.06098938]
 [ 73.20121765]
 [ 73.57820892]
 [ 75.83418274]
 [ 74.59686279]
 [ 73.57035828]
 [ 73.02142334]
 [ 72.19113159]
 [ 91.75626373]
 [ 78.12773132]
 [ 70.80415344]
 [ 76.025383  ]
 [ 76.49362183]]
DEBUG:root:training time = %d0.209624
INFO:root:frame =13185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000384092330933
INFO:root:frame =13186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000301837921143
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:random_action_porb = 0.895785
DEBUG:root: dqn, choose action rondomly, need time 0.000193000000024
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:frame =13189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000586032867432
INFO:root:frame =13190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000336885452271
DEBUG:root: save sample needs time = 0.000173091888428
INFO:root:random_action_porb = 0.895753333333
DEBUG:root: dqn, choose action rondomly, need time 0.000225
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162839889526
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 74.58843231]
 [ 75.28983307]
 [ 81.25673676]
 [ 90.81593323]
 [ 72.48832703]
 [ 78.83389282]
 [ 70.97425079]
 [ 73.03186035]
 [ 72.69139099]
 [ 77.97081757]
 [ 70.46533966]
 [ 74.8421936 ]
 [ 73.70233917]
 [ 76.74205017]
 [ 72.31304932]
 [ 76.20563507]]
DEBUG:root:training time = %d0.189684
INFO:root:frame =13193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =13194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000261783599854
DEBUG:root: save sample needs time = 0.000103950500488
INFO:root:random_action_porb = 0.895721666667
DEBUG:root: dqn, choose action rondomly, need time 0.00022100000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:frame =13197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =13198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000302076339722
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.89569
DEBUG:root: dqn, choose action rondomly, need time 0.00018399999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:training error  = [[ 78.93498993]
 [ 75.52516174]
 [ 75.33353424]
 [ 72.20565033]
 [ 72.63285828]
 [ 80.47624969]
 [ 77.62116241]
 [ 73.11220551]
 [ 72.86946869]
 [ 76.26212311]
 [ 79.98531342]
 [ 75.91100311]
 [ 73.77990723]
 [ 71.90747833]
 [ 74.90900421]
 [ 72.1885376 ]]
DEBUG:root:training time = %d0.221559
INFO:root:frame =13201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =13202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame = 13203 State into memory, numbers recorded 350 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000614166259766
INFO:root:random_action_porb = 0.895658333333
DEBUG:root: dqn, choose action rondomly, need time 0.000350999999966
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13204current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =13205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000420093536377
INFO:root:frame =13206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:random_action_porb = 0.895626666667
INFO:root:dqn select action Tensor("ArgMax_176:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010626
INFO:root:action choosen by dqn [4]
INFO:root:frame =13208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 74.63166046]
 [ 80.6734848 ]
 [ 84.14148712]
 [ 78.92577362]
 [ 74.52571869]
 [ 80.6734848 ]
 [ 64.88585663]
 [ 74.50016022]
 [ 75.23767853]
 [ 74.13578796]
 [ 77.31388092]
 [ 78.92577362]
 [ 72.08537292]
 [ 75.64455414]
 [ 76.97454071]
 [ 76.00196838]]
DEBUG:root:training time = %d0.227681
INFO:root:frame =13209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000327825546265
INFO:root:frame =13210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame = 13211 State into memory, numbers recorded 351 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.0012378692627
INFO:root:random_action_porb = 0.895595
DEBUG:root: dqn, choose action rondomly, need time 0.000247999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13212current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =13213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =13214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000579833984375
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.895563333333
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000045
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000370979309082
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 56.69743347]
 [ 79.68373871]
 [ 79.75757599]
 [ 69.38639069]
 [ 75.33087921]
 [ 73.47667694]
 [ 73.45444489]
 [ 78.93444824]
 [ 80.4442215 ]
 [ 82.62692261]
 [ 74.07089996]
 [ 75.33353424]
 [ 76.06663513]
 [ 76.17739868]
 [ 76.85597992]
 [ 80.56607056]]
DEBUG:root:training time = %d0.228731
INFO:root:frame =13217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root: ememy has been killed for 24 times 
INFO:root:enemies_left [0]
INFO:root:frame =13218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000189781188965
INFO:root:frame = 13219 State into memory, numbers recorded 352 action = 2, reward = 1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:random_action_porb = 0.895531666667
DEBUG:root: dqn, choose action rondomly, need time 0.000467000000015
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13220current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =13221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =13222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509977340698
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.8955
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 58.96611786]
 [ 72.076828  ]
 [ 74.75905609]
 [ 92.7361145 ]
 [ 74.22147369]
 [ 77.6120224 ]
 [ 78.80138397]
 [ 80.23141479]
 [ 78.2086792 ]
 [ 75.59492493]
 [ 78.13744354]
 [ 74.75905609]
 [ 75.35313416]
 [ 76.51764679]
 [ 73.537117  ]
 [ 71.48292542]]
DEBUG:root:training time = %d0.23377
INFO:root:frame =13225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =13226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.895468333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =13229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000415086746216
INFO:root:frame =13230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488042831421
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.895436666667
DEBUG:root: dqn, choose action rondomly, need time 0.000253999999984
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000184059143066
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 77.52333069]
 [ 81.14343262]
 [ 76.96972656]
 [ 76.38076019]
 [ 73.52822113]
 [ 78.92414856]
 [ 79.50159454]
 [ 75.61138153]
 [ 76.66106415]
 [ 75.77918243]
 [ 76.88487244]
 [ 74.25013733]
 [ 73.24352264]
 [ 77.64133453]
 [ 72.10455322]
 [ 93.95056915]]
DEBUG:root:training time = %d0.223219
INFO:root:frame =13233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =13234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000358104705811
INFO:root:frame = 13235 State into memory, numbers recorded 353 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000576972961426
INFO:root:random_action_porb = 0.895405
DEBUG:root: dqn, choose action rondomly, need time 0.00027
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13236current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:frame =13237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =13238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:random_action_porb = 0.895373333333
DEBUG:root: dqn, choose action rondomly, need time 0.000361999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000402927398682
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 76.92555237]
 [ 83.5942688 ]
 [ 86.40096283]
 [ 74.19045258]
 [ 63.15806198]
 [ 78.58453369]
 [ 79.13874817]
 [ 77.05167389]
 [ 75.21411896]
 [ 80.74668884]
 [ 79.13874817]
 [ 75.75553894]
 [ 76.72013092]
 [ 74.03833771]
 [ 77.37749481]
 [ 85.86029053]]
DEBUG:root:training time = %d0.24063
INFO:root:frame =13241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =13242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259876251221
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.895341666667
DEBUG:root: dqn, choose action rondomly, need time 0.000262000000021
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =13245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440835952759
INFO:root:frame =13246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.89531
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 75.95009613]
 [ 71.32562256]
 [ 75.58670044]
 [ 77.74112701]
 [ 82.78816986]
 [ 74.29379272]
 [ 79.01011658]
 [ 60.62386322]
 [ 72.19631195]
 [ 92.48031616]
 [ 74.95576477]
 [ 74.79652405]
 [ 73.82421875]
 [ 75.06729889]
 [ 73.52586365]
 [ 74.95576477]]
DEBUG:root:training time = %d0.224753
INFO:root:frame =13249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =13250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.895278333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =13253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =13254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000520944595337
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.895246666667
INFO:root:dqn select action Tensor("ArgMax_177:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012748
INFO:root:action choosen by dqn [4]
INFO:root:frame =13256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 74.96606445]
 [ 76.33329773]
 [ 75.99185944]
 [ 78.96563721]
 [ 74.31668091]
 [ 61.18592834]
 [ 76.38022614]
 [ 76.83003235]
 [ 74.67253113]
 [ 74.4185257 ]
 [ 76.19044495]
 [ 62.81075287]
 [ 72.02709198]
 [ 74.44643402]
 [ 93.90117645]
 [ 81.53922272]]
DEBUG:root:training time = %d0.24171
INFO:root:frame =13257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =13258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319957733154
DEBUG:root: save sample needs time = 0.000108957290649
INFO:root:random_action_porb = 0.895215
DEBUG:root: dqn, choose action rondomly, need time 0.000225999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root:frame =13261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =13262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame = 13263 State into memory, numbers recorded 354 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000560998916626
INFO:root:random_action_porb = 0.895183333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13264current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 95.03899384]
 [ 84.05948639]
 [ 79.55466461]
 [ 76.08074188]
 [ 74.77752686]
 [ 95.74271393]
 [ 72.8900528 ]
 [ 75.92669678]
 [ 82.5171051 ]
 [ 76.03309631]
 [ 79.95774841]
 [ 79.16806793]
 [ 78.56478882]
 [ 81.73995972]
 [ 76.61484528]
 [ 73.09316254]]
DEBUG:root:training time = %d0.218141
INFO:root:frame =13265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =13266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000492095947266
INFO:root:frame = 13267 State into memory, numbers recorded 355 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000583171844482
INFO:root:random_action_porb = 0.895151666667
DEBUG:root: dqn, choose action rondomly, need time 0.000360999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13268current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:frame =13269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284194946289
INFO:root:frame =13270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.89512
INFO:root:dqn select action Tensor("ArgMax_178:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010523
INFO:root:action choosen by dqn [4]
INFO:root:frame =13272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 76.1204071 ]
 [ 75.55884552]
 [ 72.00352478]
 [ 79.99432373]
 [ 82.13831329]
 [ 73.53423309]
 [ 80.8583374 ]
 [ 77.35709381]
 [ 73.59732056]
 [ 76.7575531 ]
 [ 80.75683594]
 [ 98.54294586]
 [ 80.88166809]
 [ 75.42546844]
 [ 76.19417572]
 [ 78.88321686]]
DEBUG:root:training time = %d0.22253
INFO:root:frame =13273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =13274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308036804199
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.895088333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000500917434692
INFO:root:frame =13277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =13278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241041183472
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.895056666667
DEBUG:root: dqn, choose action rondomly, need time 0.000171000000023
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 76.71318054]
 [ 78.93390656]
 [ 78.95316315]
 [ 73.61721802]
 [ 75.09745026]
 [ 96.54255676]
 [ 74.46328735]
 [ 78.90354156]
 [ 78.47176361]
 [ 81.4282074 ]
 [ 77.30395508]
 [ 78.00154114]
 [ 75.06227875]
 [ 84.50354767]
 [ 78.20840454]
 [ 75.53603363]]
DEBUG:root:training time = %d0.22083
INFO:root:frame =13281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255823135376
INFO:root:frame =13282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000282049179077
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.895025
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999964
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =13285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =13286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000519037246704
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:random_action_porb = 0.894993333333
DEBUG:root: dqn, choose action rondomly, need time 0.000338999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000407934188843
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 80.35201263]
 [ 85.9046936 ]
 [ 75.36054993]
 [ 66.34929657]
 [ 95.83829498]
 [ 77.15296936]
 [ 75.95648193]
 [ 79.01852417]
 [ 82.50102997]
 [ 75.95568085]
 [ 80.4907608 ]
 [ 81.75431061]
 [ 94.9390564 ]
 [ 82.74097443]
 [ 79.70743561]
 [ 78.71904755]]
DEBUG:root:training time = %d0.21963
INFO:root: ememy has been killed for 25 times 
INFO:root:enemies_left [0]
INFO:root:frame =13289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000166893005371
INFO:root:frame =13290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame = 13291 State into memory, numbers recorded 356 action = 0, reward = 1
DEBUG:root: save sample needs time = 0.000592947006226
INFO:root:random_action_porb = 0.894961666667
DEBUG:root: dqn, choose action rondomly, need time 0.000535000000013
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13292current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:frame =13293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000479221343994
INFO:root:frame =13294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 9.41753387451e-05
INFO:root:random_action_porb = 0.89493
DEBUG:root: dqn, choose action rondomly, need time 0.000174000000015
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 82.54815674]
 [ 80.43573761]
 [ 74.64537048]
 [ 79.26721191]
 [ 79.55683899]
 [ 85.29537964]
 [ 75.01469421]
 [ 81.10852814]
 [ 85.38813782]
 [ 86.73573303]
 [ 78.43500519]
 [ 82.21355438]
 [ 77.69458008]
 [ 74.86780548]
 [ 87.62075043]
 [ 94.68825531]]
DEBUG:root:training time = %d0.22903
INFO:root:frame =13297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =13298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000336170196533
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.894898333333
DEBUG:root: dqn, choose action rondomly, need time 0.000193999999965
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root:frame =13301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000499963760376
INFO:root:frame =13302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.894866666667
DEBUG:root: dqn, choose action rondomly, need time 0.000399000000016
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  77.0098877 ]
 [ 105.41188049]
 [  75.25012207]
 [  76.33009338]
 [  76.43357849]
 [  82.72099304]
 [  82.2545166 ]
 [  75.25779724]
 [  79.16752625]
 [  77.80302429]
 [  79.21559143]
 [  77.40299988]
 [  80.38127899]
 [  84.9670639 ]
 [  76.25093079]
 [  74.87519836]]
DEBUG:root:training time = %d0.250198
INFO:root:frame =13305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270128250122
INFO:root:frame =13306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000533103942871
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.894835
DEBUG:root: dqn, choose action rondomly, need time 0.000353999999959
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =13309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =13310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509977340698
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.894803333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 81.0376358 ]
 [ 90.83018494]
 [ 71.04085541]
 [ 81.94316101]
 [ 78.49041748]
 [ 79.54187012]
 [ 84.40062714]
 [ 78.62024689]
 [ 61.28097534]
 [ 74.50253296]
 [ 80.05547333]
 [ 78.8238678 ]
 [ 80.24153137]
 [ 72.92783356]
 [ 85.79921722]
 [ 77.88353729]]
DEBUG:root:training time = %d0.222249
INFO:root:frame =13313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =13314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000343084335327
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.894771666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000031
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =13317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =13318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.89474
DEBUG:root: dqn, choose action rondomly, need time 0.000261000000023
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 78.85502625]
 [ 82.57478333]
 [ 77.75673676]
 [ 88.06752777]
 [ 79.3082428 ]
 [ 86.25125122]
 [ 80.48090363]
 [ 74.64694977]
 [ 74.26591492]
 [ 97.63137817]
 [ 75.71888733]
 [ 77.24600983]
 [ 92.77402496]
 [ 74.55864716]
 [ 78.23485565]
 [ 81.65224457]]
DEBUG:root:training time = %d0.22241
INFO:root:frame =13321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00035285949707
INFO:root:frame =13322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.894708333333
DEBUG:root: dqn, choose action rondomly, need time 0.00051099999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =13325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =13326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234127044678
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.894676666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328779220581
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 78.21002197]
 [ 79.82709503]
 [ 71.44758606]
 [ 82.97988129]
 [ 81.4552002 ]
 [ 99.1886673 ]
 [ 83.48855591]
 [ 75.38254547]
 [ 77.55934143]
 [ 78.68547821]
 [ 77.43710327]
 [ 77.55934143]
 [ 81.48963165]
 [ 75.58272552]
 [ 83.67520142]
 [ 81.9821167 ]]
DEBUG:root:training time = %d0.222441
INFO:root:frame =13329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:frame =13330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000519037246704
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.894645
DEBUG:root: dqn, choose action rondomly, need time 0.000268000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =13333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =13334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000451803207397
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:random_action_porb = 0.894613333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 80.27105713]
 [ 79.06491852]
 [ 78.72581482]
 [ 80.06093597]
 [ 76.32209778]
 [ 74.44091034]
 [ 79.44146729]
 [ 77.205513  ]
 [ 76.55261993]
 [ 80.86684418]
 [ 78.52800751]
 [ 75.89186096]
 [ 97.32225037]
 [ 83.31018829]
 [ 73.64994812]
 [ 82.66825867]]
DEBUG:root:training time = %d0.207017
INFO:root:frame =13337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000398874282837
INFO:root:frame =13338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.894581666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =13341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000419139862061
INFO:root:frame =13342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000278949737549
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.89455
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  75.92722321]
 [  77.78875732]
 [  81.30185699]
 [  75.34518433]
 [  76.27758026]
 [  80.21091461]
 [  78.49069214]
 [  74.93541718]
 [  75.35525513]
 [  84.3227005 ]
 [  83.29821014]
 [  79.44664001]
 [  63.35296249]
 [ 102.88396454]
 [  85.72376251]
 [  79.77993011]]
DEBUG:root:training time = %d0.233077
INFO:root:frame =13345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:frame =13346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.894518333333
DEBUG:root: dqn, choose action rondomly, need time 0.000335000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root:frame =13349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame =13350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame = 13351 State into memory, numbers recorded 357 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000591039657593
INFO:root:random_action_porb = 0.894486666667
DEBUG:root: dqn, choose action rondomly, need time 0.000383999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13352current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  77.55315399]
 [  75.02896881]
 [  78.917099  ]
 [  76.78295898]
 [  86.47473145]
 [  81.31066132]
 [  83.56720734]
 [  81.74658203]
 [  81.51938629]
 [ 102.72244263]
 [  82.9968338 ]
 [  80.45736694]
 [  94.52944946]
 [  82.54982758]
 [  77.66311646]
 [  84.23696899]]
DEBUG:root:training time = %d0.223884
INFO:root:frame =13353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =13354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000326871871948
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.894455
DEBUG:root: dqn, choose action rondomly, need time 0.000206999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000182867050171
INFO:root:frame =13357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =13358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00040602684021
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.894423333333
INFO:root:dqn select action Tensor("ArgMax_179:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00842599999999
INFO:root:action choosen by dqn [4]
INFO:root:frame =13360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 76.12839508]
 [ 77.31790924]
 [ 79.67338562]
 [ 83.83970642]
 [ 79.22618866]
 [ 84.00717163]
 [ 75.94477844]
 [ 79.38109589]
 [ 65.47223663]
 [ 83.49356842]
 [ 77.72875214]
 [ 82.884552  ]
 [ 84.42669678]
 [ 83.72602081]
 [ 76.68992615]
 [ 83.65621948]]
DEBUG:root:training time = %d0.230623
INFO:root:frame =13361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame =13362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000418186187744
INFO:root:frame = 13363 State into memory, numbers recorded 358 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00120902061462
INFO:root:random_action_porb = 0.894391666667
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13364current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =13365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =13366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000406980514526
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.89436
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:training error  = [[ 77.18755341]
 [ 77.26129913]
 [ 83.02464294]
 [ 78.25186157]
 [ 78.8319931 ]
 [ 84.73514557]
 [ 75.83524323]
 [ 71.49298859]
 [ 86.34338379]
 [ 81.67375946]
 [ 76.32369232]
 [ 79.73223114]
 [ 71.49298859]
 [ 75.87006378]
 [ 81.7140274 ]
 [ 79.2886734 ]]
DEBUG:root:training time = %d0.211184
INFO:root:frame =13369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =13370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000292062759399
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.894328333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =13373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =13374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame = 13375 State into memory, numbers recorded 359 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000554084777832
INFO:root:random_action_porb = 0.894296666667
DEBUG:root: dqn, choose action rondomly, need time 0.000189000000034
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13376current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 82.33811951]
 [ 67.98195648]
 [ 98.13802338]
 [ 79.45941925]
 [ 79.97303009]
 [ 78.35691071]
 [ 79.52417755]
 [ 83.22052002]
 [ 75.87724304]
 [ 97.69169617]
 [ 76.45252228]
 [ 73.25736237]
 [ 80.70775604]
 [ 80.70227051]
 [ 97.048172  ]
 [ 80.73983002]]
DEBUG:root:training time = %d0.214847
INFO:root:frame =13377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =13378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.894265
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =13381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =13382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470876693726
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.894233333333
DEBUG:root: dqn, choose action rondomly, need time 0.000499999999988
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:training error  = [[ 75.99425507]
 [ 85.83908081]
 [ 81.01593018]
 [ 81.15718079]
 [ 80.72721863]
 [ 81.81751251]
 [ 75.92696381]
 [ 77.90050507]
 [ 81.16652679]
 [ 79.76821136]
 [ 77.71879578]
 [ 80.1029892 ]
 [ 84.59025574]
 [ 85.86057281]
 [ 75.23609161]
 [ 77.67306519]]
DEBUG:root:training time = %d0.217893
INFO:root:frame =13385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312805175781
INFO:root:frame =13386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.894201666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000031
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =13389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =13390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root: ememy has been killed for 26 times 
INFO:root:enemies_left [0]
INFO:root:frame = 13391 State into memory, numbers recorded 360 action = 2, reward = 1
DEBUG:root: save sample needs time = 0.000504970550537
INFO:root:random_action_porb = 0.89417
DEBUG:root: dqn, choose action rondomly, need time 0.000278999999978
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13392current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:training error  = [[ 78.01124573]
 [ 76.73028564]
 [ 80.93629456]
 [ 83.4863205 ]
 [ 80.7881012 ]
 [ 84.29608154]
 [ 77.64025879]
 [ 82.26946259]
 [ 78.04575348]
 [ 82.83094025]
 [ 82.7934494 ]
 [ 75.15061188]
 [ 80.23825073]
 [ 82.28884125]
 [ 77.61686707]
 [ 85.76332092]]
DEBUG:root:training time = %d0.231101
INFO:root:frame =13393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =13394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288009643555
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:random_action_porb = 0.894138333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999968
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =13397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =13398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.894106666667
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 84.98141479]
 [ 82.60057068]
 [ 77.24359894]
 [ 81.60951233]
 [ 84.85935974]
 [ 80.38346863]
 [ 80.28390503]
 [ 81.84511566]
 [ 80.57648468]
 [ 82.21273041]
 [ 98.39970398]
 [ 77.68382263]
 [ 81.66217804]
 [ 99.43804932]
 [ 75.47610474]
 [ 81.07527161]]
DEBUG:root:training time = %d0.236145
INFO:root:frame =13401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =13402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000329971313477
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:random_action_porb = 0.894075
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =13405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame =13406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.894043333333
DEBUG:root: dqn, choose action rondomly, need time 0.000323000000037
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 80.41192627]
 [ 83.06552124]
 [ 77.18460083]
 [ 87.2768631 ]
 [ 81.11732483]
 [ 85.45639038]
 [ 96.65983582]
 [ 81.66465759]
 [ 80.1524353 ]
 [ 82.49077606]
 [ 98.20152283]
 [ 75.19532776]
 [ 82.7667923 ]
 [ 79.79573822]
 [ 79.13141632]
 [ 86.62406921]]
DEBUG:root:training time = %d0.23644
INFO:root:frame =13409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =13410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000304222106934
INFO:root:frame = 13411 State into memory, numbers recorded 361 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:random_action_porb = 0.894011666667
DEBUG:root: dqn, choose action rondomly, need time 0.000161999999989
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13412current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:frame =13413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =13414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247001647949
DEBUG:root: save sample needs time = 0.000379085540771
INFO:root:random_action_porb = 0.89398
DEBUG:root: dqn, choose action rondomly, need time 0.00022100000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  76.63781738]
 [  82.76179504]
 [  77.58003235]
 [  78.13879395]
 [  81.37809753]
 [  85.46683502]
 [  78.94095612]
 [  81.03653717]
 [  75.75049591]
 [  85.54528046]
 [  77.12937927]
 [  98.9562912 ]
 [ 103.0567627 ]
 [  84.32718658]
 [  82.111763  ]
 [  80.0169754 ]]
DEBUG:root:training time = %d0.183705
INFO:root:frame =13417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000412940979004
INFO:root:frame =13418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000281095504761
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.893948333333
INFO:root:dqn select action Tensor("ArgMax_180:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015986
INFO:root:action choosen by dqn [4]
INFO:root:frame =13420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:frame =13421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =13422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509977340698
INFO:root:frame = 13423 State into memory, numbers recorded 362 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.000611066818237
INFO:root:random_action_porb = 0.893916666667
DEBUG:root: dqn, choose action rondomly, need time 0.000173000000018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13424current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  84.85710907]
 [  82.45668793]
 [ 102.35192871]
 [  88.22281647]
 [  81.70354462]
 [  78.35475159]
 [  95.89476776]
 [  81.50423431]
 [  78.75045776]
 [  82.62276459]
 [  98.23206329]
 [  80.92668152]
 [  80.66416931]
 [  85.30101776]
 [  86.06485748]
 [  78.86965942]]
DEBUG:root:training time = %d0.229946
INFO:root:frame =13425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =13426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.893885
INFO:root:dqn select action Tensor("ArgMax_181:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012816
INFO:root:action choosen by dqn [4]
INFO:root:frame =13428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =13429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =13430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:random_action_porb = 0.893853333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  79.75921631]
 [  79.14363098]
 [  99.69657898]
 [  82.38298798]
 [  78.77185822]
 [  82.59668732]
 [  79.19223785]
 [  80.97912598]
 [ 100.68170166]
 [  84.96762848]
 [  83.83663177]
 [  77.72013855]
 [  78.45662689]
 [  80.28609467]
 [  79.19223785]
 [  80.03472137]]
DEBUG:root:training time = %d0.216305
INFO:root:frame =13433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =13434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00040602684021
INFO:root:frame = 13435 State into memory, numbers recorded 363 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:random_action_porb = 0.893821666667
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13436current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =13437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =13438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000498056411743
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:random_action_porb = 0.89379
DEBUG:root: dqn, choose action rondomly, need time 0.000178999999946
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  82.95847321]
 [  80.91378021]
 [  86.754776  ]
 [  79.26829529]
 [  77.71852875]
 [  81.25618744]
 [  83.72992706]
 [  80.43738556]
 [  78.59156799]
 [  82.60611725]
 [  81.96636963]
 [  85.1832428 ]
 [  80.12593842]
 [ 105.05467987]
 [ 101.11545563]
 [  83.68804932]]
DEBUG:root:training time = %d0.218321
INFO:root:frame =13441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =13442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.893758333333
INFO:root:dqn select action Tensor("ArgMax_182:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.008331
INFO:root:action choosen by dqn [4]
INFO:root:frame =13444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:frame =13445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =13446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame = 13447 State into memory, numbers recorded 364 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.000617980957031
INFO:root:random_action_porb = 0.893726666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13448current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 83.03047943]
 [ 87.18366241]
 [ 81.92686462]
 [ 83.7134552 ]
 [ 85.0827179 ]
 [ 79.04837036]
 [ 80.05329132]
 [ 68.87612152]
 [ 79.76139069]
 [ 89.32493591]
 [ 80.83885956]
 [ 88.52950287]
 [ 82.47857666]
 [ 99.91487122]
 [ 78.91249084]
 [ 90.94510651]]
DEBUG:root:training time = %d0.245475
INFO:root:frame =13449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =13450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000355958938599
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.893695
DEBUG:root: dqn, choose action rondomly, need time 0.00019199999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:frame =13453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =13454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.893663333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  87.3193512 ]
 [  81.82441711]
 [  82.48107147]
 [  80.59319305]
 [ 102.10292053]
 [  78.17197418]
 [  90.18449402]
 [ 109.01340485]
 [  80.00551605]
 [  79.2729187 ]
 [  82.04512787]
 [  89.14015198]
 [  81.81254578]
 [  81.78245544]
 [  84.94174957]
 [  84.74329376]]
DEBUG:root:training time = %d0.240376
INFO:root:frame =13457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =13458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.893631666667
DEBUG:root: dqn, choose action rondomly, need time 0.000317999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326156616211
INFO:root:frame =13461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000481128692627
INFO:root:frame =13462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.8936
DEBUG:root: dqn, choose action rondomly, need time 0.000324000000035
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000391960144043
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 74.60187531]
 [ 81.13573456]
 [ 83.49998474]
 [ 80.5567627 ]
 [ 84.9394989 ]
 [ 79.80228424]
 [ 82.04098511]
 [ 82.47442627]
 [ 83.42080688]
 [ 80.79605865]
 [ 98.5056839 ]
 [ 81.25398254]
 [ 81.66327667]
 [ 79.73332214]
 [ 79.26123047]
 [ 98.96661377]]
DEBUG:root:training time = %d0.217772
INFO:root:frame =13465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =13466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.893568333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root:frame =13469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame =13470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000242948532104
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.893536666667
DEBUG:root: dqn, choose action rondomly, need time 0.000203999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185012817383
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 86.55392456]
 [ 79.59740448]
 [ 83.54321289]
 [ 84.69694519]
 [ 99.83313751]
 [ 80.35912323]
 [ 84.38996887]
 [ 79.48690033]
 [ 81.88653564]
 [ 82.69129181]
 [ 86.14839935]
 [ 85.28185272]
 [ 85.59693909]
 [ 80.1502533 ]
 [ 78.87400055]
 [ 86.64678955]]
DEBUG:root:training time = %d0.209295
INFO:root:frame =13473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000423192977905
INFO:root:frame =13474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000369071960449
DEBUG:root: save sample needs time = 0.000105142593384
INFO:root:random_action_porb = 0.893505
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =13477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =13478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.893473333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999952
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:training error  = [[ 85.06752014]
 [ 80.22868347]
 [ 83.20214844]
 [ 83.81176758]
 [ 82.93929291]
 [ 84.45502472]
 [ 82.48911285]
 [ 85.32582092]
 [ 78.278862  ]
 [ 83.5289917 ]
 [ 82.93790436]
 [ 83.50835419]
 [ 79.27074432]
 [ 76.42931366]
 [ 85.97909546]
 [ 78.79027557]]
DEBUG:root:training time = %d0.22289
INFO:root:frame =13481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =13482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000266075134277
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.893441666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000038
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =13485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =13486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485897064209
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.89341
DEBUG:root: dqn, choose action rondomly, need time 0.000307999999961
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  82.9376297 ]
 [  80.75408936]
 [  90.32539368]
 [  82.52597809]
 [  81.03158569]
 [  81.77748871]
 [  78.18681335]
 [  84.36530304]
 [  85.23226166]
 [  83.22580719]
 [  80.84461975]
 [  84.70930481]
 [  88.54386139]
 [ 107.60485077]
 [  90.11929321]
 [ 104.78772736]]
DEBUG:root:training time = %d0.219561
INFO:root:frame =13489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =13490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame = 13491 State into memory, numbers recorded 365 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000571966171265
INFO:root:random_action_porb = 0.893378333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13492current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =13493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =13494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456809997559
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.893346666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  85.37911224]
 [  81.68093109]
 [  89.00765991]
 [ 101.2569809 ]
 [  61.26091003]
 [  85.92392731]
 [  86.037117  ]
 [  75.05857849]
 [  83.36646271]
 [  79.37212372]
 [  90.27377319]
 [  75.40665436]
 [  84.81326294]
 [ 104.90615845]
 [  71.18883514]
 [ 113.61486053]]
DEBUG:root:training time = %d0.220041
INFO:root:frame =13497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =13498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.893315
DEBUG:root: dqn, choose action rondomly, need time 0.000293000000056
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =13501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000618934631348
INFO:root:frame =13502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000507831573486
DEBUG:root: save sample needs time = 0.000105142593384
INFO:root:random_action_porb = 0.893283333333
DEBUG:root: dqn, choose action rondomly, need time 0.000207999999986
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142812728882
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 103.15158081]
 [  81.56072235]
 [  82.22904968]
 [  80.23715973]
 [  83.28289032]
 [  83.62859344]
 [  91.25823212]
 [  82.69406891]
 [  79.68618774]
 [  85.38729095]
 [  83.28289032]
 [  85.15592194]
 [ 104.93616486]
 [  82.88344574]
 [  78.83605957]
 [  79.3082428 ]]
DEBUG:root:training time = %d0.210221
INFO:root:frame =13505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:frame =13506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.893251666667
DEBUG:root: dqn, choose action rondomly, need time 0.000162999999986
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:frame =13509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =13510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.89322
DEBUG:root: dqn, choose action rondomly, need time 0.000266000000011
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  79.81782532]
 [  79.04837036]
 [  79.81782532]
 [ 111.69280243]
 [  83.36980438]
 [  81.45491791]
 [  79.0253067 ]
 [  81.92327118]
 [  84.01500702]
 [  82.56036377]
 [  84.03794098]
 [  91.03476715]
 [  86.2518158 ]
 [  79.76521301]
 [  70.10485077]
 [  84.81466675]]
DEBUG:root:training time = %d0.211905
INFO:root:frame =13513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =13514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000157117843628
INFO:root:random_action_porb = 0.893188333333
INFO:root:dqn select action Tensor("ArgMax_183:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010933
INFO:root:action choosen by dqn [4]
INFO:root:frame =13516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =13517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =13518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.893156666667
DEBUG:root: dqn, choose action rondomly, need time 0.00032699999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 81.59049225]
 [ 84.53188324]
 [ 85.29679108]
 [ 80.31371307]
 [ 86.68258667]
 [ 79.69980621]
 [ 85.02642822]
 [ 82.82843781]
 [ 81.70217133]
 [ 84.66718292]
 [ 66.01984406]
 [ 82.17427063]
 [ 85.93637085]
 [ 80.54306793]
 [ 81.78356171]
 [ 86.77609253]]
DEBUG:root:training time = %d0.235673
INFO:root:frame =13521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =13522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000352144241333
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:random_action_porb = 0.893125
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999976
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =13525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =13526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488042831421
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.893093333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999974
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  83.64003754]
 [  91.29234314]
 [  71.29573059]
 [  84.2599411 ]
 [  71.29573059]
 [  83.15705872]
 [  83.36980438]
 [  81.57312012]
 [  81.09863281]
 [  79.52581024]
 [  84.96144104]
 [  84.01052856]
 [  85.00195312]
 [  89.09290314]
 [  85.00195312]
 [ 105.18734741]]
DEBUG:root:training time = %d0.226075
INFO:root:frame =13529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =13530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000392913818359
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.893061666667
INFO:root:dqn select action Tensor("ArgMax_184:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013999
INFO:root:action choosen by dqn [4]
INFO:root:frame =13532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:frame =13533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =13534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root: ememy has been killed for 27 times 
INFO:root:enemies_left [0]
INFO:root:frame = 13535 State into memory, numbers recorded 366 action = [4], reward = 1
DEBUG:root: save sample needs time = 0.00109601020813
INFO:root:random_action_porb = 0.89303
DEBUG:root: dqn, choose action rondomly, need time 0.000159999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13536current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000151872634888
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 83.42276001]
 [ 95.92853546]
 [ 92.00022888]
 [ 84.66184235]
 [ 85.83342743]
 [ 84.1837616 ]
 [ 80.82349396]
 [ 88.39833069]
 [ 80.80510712]
 [ 87.14320374]
 [ 83.83076477]
 [ 86.4384079 ]
 [ 81.49320984]
 [ 87.15232086]
 [ 70.52017212]
 [ 84.64920807]]
DEBUG:root:training time = %d0.203829
INFO:root:frame =13537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =13538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 9.58442687988e-05
INFO:root:random_action_porb = 0.892998333333
DEBUG:root: dqn, choose action rondomly, need time 0.000340999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =13541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =13542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.892966666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  82.52237701]
 [  81.76838684]
 [  82.85288239]
 [  81.89344025]
 [  85.10608673]
 [  89.70057678]
 [  81.41857147]
 [ 109.98931885]
 [  88.6995697 ]
 [ 103.47883606]
 [  86.93820953]
 [  83.4949646 ]
 [  79.2310791 ]
 [  86.70674133]
 [  78.82928467]
 [  79.61755371]]
DEBUG:root:training time = %d0.226333
INFO:root:frame =13545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =13546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.892935
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000022
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =13549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000495195388794
INFO:root:frame =13550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.892903333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999956
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  82.45502472]
 [  88.9204483 ]
 [  86.83210754]
 [ 110.32147217]
 [  82.17813873]
 [  85.23986816]
 [  82.60112762]
 [  81.91912842]
 [  85.74240875]
 [  82.30683136]
 [  85.95448303]
 [  82.58753967]
 [  84.3490448 ]
 [  82.12199402]
 [  87.20874023]
 [  86.41344452]]
DEBUG:root:training time = %d0.234687
INFO:root:frame =13553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =13554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.892871666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =13557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =13558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470161437988
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.89284
DEBUG:root: dqn, choose action rondomly, need time 0.000262000000021
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  89.51136017]
 [  89.97536469]
 [  82.82372284]
 [  91.44169617]
 [  79.32047272]
 [  85.36501312]
 [  88.20103455]
 [  80.49651337]
 [ 106.40494537]
 [ 100.8293457 ]
 [  86.50623322]
 [  85.14437866]
 [  87.4528656 ]
 [  87.06943512]
 [  91.01525879]
 [  87.50452423]]
DEBUG:root:training time = %d0.215297
INFO:root:frame =13561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =13562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000282049179077
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.892808333333
INFO:root:dqn select action Tensor("ArgMax_185:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00908200000003
INFO:root:action choosen by dqn [4]
INFO:root:frame =13564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:frame =13565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =13566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.892776666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  79.78156281]
 [ 105.64857483]
 [  80.87974548]
 [  86.27874756]
 [  86.08779144]
 [ 108.42218781]
 [  87.90607452]
 [  83.22135162]
 [  85.5018158 ]
 [  84.43062592]
 [  81.78052521]
 [  77.20819855]
 [  84.1652832 ]
 [  84.21792603]
 [  83.50751495]
 [  86.82414246]]
DEBUG:root:training time = %d0.227539
INFO:root:frame =13569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =13570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000256061553955
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.892745
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999976
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =13573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =13574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:random_action_porb = 0.892713333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000550985336304
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  86.50254822]
 [  85.77603912]
 [  90.0295105 ]
 [  81.29745483]
 [  86.03739929]
 [  87.89920807]
 [  81.95669556]
 [  85.25085449]
 [  86.33629608]
 [  89.41783905]
 [  84.81748199]
 [  85.6412735 ]
 [ 103.22567749]
 [  84.40370941]
 [  80.59785461]
 [  88.86520386]]
DEBUG:root:training time = %d0.230514
INFO:root:frame =13577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:frame =13578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274896621704
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.892681666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000406980514526
INFO:root:frame =13581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =13582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482082366943
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:random_action_porb = 0.89265
INFO:root:dqn select action Tensor("ArgMax_186:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012012
INFO:root:action choosen by dqn [4]
INFO:root:frame =13584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000363111495972
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 82.22489929]
 [ 82.67464447]
 [ 70.94468689]
 [ 88.34583282]
 [ 85.44792938]
 [ 87.26860046]
 [ 88.11334991]
 [ 84.41408539]
 [ 83.55632782]
 [ 85.93637085]
 [ 83.26200867]
 [ 85.13198853]
 [ 88.47122192]
 [ 71.67424774]
 [ 86.32041931]
 [ 91.04233551]]
DEBUG:root:training time = %d0.226013
INFO:root:frame =13585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =13586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428915023804
DEBUG:root: save sample needs time = 0.000179052352905
INFO:root:random_action_porb = 0.892618333333
DEBUG:root: dqn, choose action rondomly, need time 0.000397000000021
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =13589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =13590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.892586666667
DEBUG:root: dqn, choose action rondomly, need time 0.000530000000026
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  86.92057037]
 [  88.56253052]
 [  78.96482086]
 [  86.00626373]
 [  88.70187378]
 [  96.00058746]
 [ 109.00384521]
 [  85.7689743 ]
 [  83.73355865]
 [  82.27804565]
 [  87.1252594 ]
 [  82.02467346]
 [  88.38283539]
 [  90.69963837]
 [  89.92327118]
 [  83.77824402]]
DEBUG:root:training time = %d0.207594
INFO:root:frame =13593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =13594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:random_action_porb = 0.892555
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999954
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =13597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =13598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277996063232
DEBUG:root: save sample needs time = 0.000115871429443
INFO:root:random_action_porb = 0.892523333333
DEBUG:root: dqn, choose action rondomly, need time 0.000173000000018
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  84.33278656]
 [  88.13512421]
 [  81.76120758]
 [ 107.63492584]
 [  84.56218719]
 [  87.15317535]
 [ 106.38259125]
 [  94.90843201]
 [  92.01515198]
 [  88.24488831]
 [  85.92392731]
 [  88.43534851]
 [  83.89169312]
 [  91.77497101]
 [  79.1678009 ]
 [  92.90782166]]
DEBUG:root:training time = %d0.225892
INFO:root:frame =13601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =13602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031304359436
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.892491666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =13605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =13606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000498056411743
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.89246
DEBUG:root: dqn, choose action rondomly, need time 0.000320999999985
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  90.80371857]
 [  90.71940613]
 [  86.19911194]
 [  91.95222473]
 [ 105.15792847]
 [  80.7324295 ]
 [  83.4442215 ]
 [ 105.56640625]
 [  82.31984711]
 [  82.92984772]
 [  86.78604126]
 [  89.4262085 ]
 [  88.64813232]
 [ 108.93567657]
 [  87.04153442]
 [ 108.93567657]]
DEBUG:root:training time = %d0.226373
INFO:root:frame =13609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290155410767
INFO:root:frame =13610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045919418335
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.892428333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =13613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000856161117554
INFO:root:frame =13614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.892396666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  87.44915009]
 [  87.68074799]
 [  88.03344727]
 [  86.84319305]
 [  87.6818924 ]
 [  89.3924408 ]
 [  89.56622314]
 [  83.01379395]
 [  79.12979126]
 [  91.76912689]
 [  85.42338562]
 [ 105.51655579]
 [ 110.34391022]
 [  90.320755  ]
 [  88.03344727]
 [  88.37193298]]
DEBUG:root:training time = %d0.221623
INFO:root:frame =13617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:frame =13618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000243186950684
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.892365
DEBUG:root: dqn, choose action rondomly, need time 0.000323999999978
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =13621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =13622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.892333333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308999999959
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  82.93595886]
 [  90.7002182 ]
 [  85.47501373]
 [  88.89454651]
 [  83.97360992]
 [  74.14524841]
 [  88.39316559]
 [  85.12438965]
 [  91.76298523]
 [  82.17869568]
 [ 111.67215729]
 [  92.65707397]
 [  91.18041229]
 [  91.46417236]
 [  91.18041229]
 [  84.3753891 ]]
DEBUG:root:training time = %d0.217379
INFO:root:frame =13625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =13626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root:random_action_porb = 0.892301666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999969
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root: ememy has been killed for 28 times 
INFO:root:enemies_left [0]
INFO:root:frame =13628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =13629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =13630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame = 13631 State into memory, numbers recorded 367 action = 3, reward = 1
DEBUG:root: save sample needs time = 0.000570058822632
INFO:root:random_action_porb = 0.89227
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999965
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13632current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000346899032593
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  92.2509613 ]
 [  90.65692139]
 [  83.74556732]
 [  85.86312103]
 [  83.55715942]
 [  83.76847076]
 [  82.18810272]
 [ 104.61534882]
 [  88.0786972 ]
 [  91.62155151]
 [  90.54189301]
 [  89.14879608]
 [  84.35044861]
 [  88.51198578]
 [  82.71266174]
 [  88.4407959 ]]
DEBUG:root:training time = %d0.246996
INFO:root:frame =13633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =13634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.892238333333
DEBUG:root: dqn, choose action rondomly, need time 0.000351999999964
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =13637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =13638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.892206666667
INFO:root:dqn select action Tensor("ArgMax_187:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010643
INFO:root:action choosen by dqn [4]
INFO:root:frame =13640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  88.25550079]
 [  85.99947357]
 [  92.53961182]
 [  85.31257629]
 [ 113.90324402]
 [  86.39358521]
 [  85.99947357]
 [  85.70342255]
 [  84.43567657]
 [  86.43926239]
 [  90.08366394]
 [  88.92591095]
 [  85.14437866]
 [ 108.46191406]
 [  88.5269165 ]
 [  91.94490814]]
DEBUG:root:training time = %d0.221839
INFO:root:frame =13641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =13642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000285863876343
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:random_action_porb = 0.892175
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =13645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000494003295898
INFO:root:frame =13646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.892143333333
INFO:root:dqn select action Tensor("ArgMax_188:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012082
INFO:root:action choosen by dqn [4]
INFO:root:frame =13648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000184059143066
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  88.99845123]
 [  90.81185913]
 [  87.95701599]
 [  82.76040649]
 [  85.42818451]
 [  90.23347473]
 [  84.11685181]
 [  86.34990692]
 [ 110.66053772]
 [  90.56715393]
 [  88.3392334 ]
 [  88.26123047]
 [  88.12281036]
 [  89.10010529]
 [  89.52146149]
 [  97.06861877]]
DEBUG:root:training time = %d0.223243
INFO:root:frame =13649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =13650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.892111666667
DEBUG:root: dqn, choose action rondomly, need time 0.000355000000013
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =13653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =13654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.89208
INFO:root:dqn select action Tensor("ArgMax_189:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014637
INFO:root:action choosen by dqn [4]
INFO:root:frame =13656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000414133071899
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  89.69884491]
 [  85.25930786]
 [  85.31201172]
 [  93.23933411]
 [  95.0154953 ]
 [  89.85266876]
 [  88.29506683]
 [  82.16320038]
 [  84.74947357]
 [ 107.02284241]
 [  85.06526947]
 [  87.21016693]
 [  86.84888458]
 [  90.27087402]
 [  96.0484314 ]
 [  85.40843964]]
DEBUG:root:training time = %d0.242666
INFO:root:frame =13657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =13658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275850296021
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.892048333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =13661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000572919845581
INFO:root:frame =13662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509977340698
INFO:root:frame = 13663 State into memory, numbers recorded 368 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000606060028076
INFO:root:random_action_porb = 0.892016666667
DEBUG:root: dqn, choose action rondomly, need time 0.000320999999985
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13664current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[ 88.4098053 ]
 [ 86.51758575]
 [ 86.08779144]
 [ 86.24700165]
 [ 93.32923126]
 [ 91.76883698]
 [ 88.9538269 ]
 [ 91.76883698]
 [ 87.75963593]
 [ 87.21586609]
 [ 94.07158661]
 [ 87.46770477]
 [ 87.98506165]
 [ 83.71485138]
 [ 95.46252441]
 [ 88.6587677 ]]
DEBUG:root:training time = %d0.230151
INFO:root:frame =13665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259160995483
INFO:root:frame =13666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486135482788
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.891985
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000031
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =13669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =13670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046181678772
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.891953333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  82.76512909]
 [  91.56167603]
 [  85.81674957]
 [  89.77458191]
 [  88.66192627]
 [  88.51514435]
 [  84.84333801]
 [  87.03498077]
 [  93.17775726]
 [  92.5425415 ]
 [  92.75257111]
 [  87.01363373]
 [ 115.94862366]
 [  86.5022583 ]
 [ 109.28632355]
 [  87.27544403]]
DEBUG:root:training time = %d0.25559
INFO:root:frame =13673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root:frame =13674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000292778015137
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.891921666667
DEBUG:root: dqn, choose action rondomly, need time 0.00027799999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =13677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =13678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.89189
DEBUG:root: dqn, choose action rondomly, need time 0.000331000000017
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  89.77053833]
 [  94.55941772]
 [  86.60873413]
 [ 108.48384857]
 [ 110.83203125]
 [  94.50601196]
 [  86.63201904]
 [  87.36726379]
 [  94.51016235]
 [ 111.23045349]
 [  89.41264343]
 [  85.72460938]
 [  86.20477295]
 [ 105.9203949 ]
 [  84.99970245]
 [  87.77764893]]
DEBUG:root:training time = %d0.207962
INFO:root:frame =13681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =13682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:random_action_porb = 0.891858333333
DEBUG:root: dqn, choose action rondomly, need time 0.000174000000015
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:frame =13685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =13686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.891826666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000363826751709
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  87.50395203]
 [  89.7988739 ]
 [  82.8892746 ]
 [  88.9564209 ]
 [  91.54211426]
 [  87.89148712]
 [  90.4190979 ]
 [  86.95272064]
 [  87.55877686]
 [  92.79666138]
 [  93.38732147]
 [  86.54768372]
 [ 108.83058929]
 [  86.3785553 ]
 [  96.34505463]
 [  87.55877686]]
DEBUG:root:training time = %d0.215089
INFO:root:frame =13689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =13690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
DEBUG:root: save sample needs time = 0.000157117843628
INFO:root:random_action_porb = 0.891795
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999956
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =13693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000482082366943
INFO:root:frame =13694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000497817993164
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:random_action_porb = 0.891763333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  90.03761292]
 [  92.59275055]
 [  90.53637695]
 [ 110.99047852]
 [  86.89439392]
 [  86.60929871]
 [  87.23125458]
 [  89.39763641]
 [  85.81731415]
 [  85.36247253]
 [  90.18507385]
 [  90.21839905]
 [  85.17563629]
 [  90.21839905]
 [  87.24921417]
 [  84.94484711]]
DEBUG:root:training time = %d0.225242
INFO:root:frame =13697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =13698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000110864639282
INFO:root:random_action_porb = 0.891731666667
DEBUG:root: dqn, choose action rondomly, need time 0.000173000000018
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:frame =13701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00050687789917
INFO:root:frame =13702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000619888305664
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.8917
INFO:root:dqn select action Tensor("ArgMax_190:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012422
INFO:root:action choosen by dqn [4]
INFO:root:frame =13704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  91.83520508]
 [  90.3155365 ]
 [  94.64401245]
 [  95.55467987]
 [  93.46018219]
 [  96.77388763]
 [  91.55583954]
 [ 112.42386627]
 [ 109.47303772]
 [  87.99536896]
 [  95.23455811]
 [  93.87042236]
 [ 116.86759186]
 [  93.11325073]
 [  87.48939514]
 [  82.89788818]]
DEBUG:root:training time = %d0.239733
INFO:root:frame =13705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250816345215
INFO:root:frame =13706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.891668333333
INFO:root:dqn select action Tensor("ArgMax_191:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01089
INFO:root:action choosen by dqn [4]
INFO:root:frame =13708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame =13709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000514984130859
INFO:root:frame =13710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame = 13711 State into memory, numbers recorded 369 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00129413604736
INFO:root:random_action_porb = 0.891636666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13712current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  91.53043365]
 [ 107.39633179]
 [  89.47902679]
 [  85.29763794]
 [  73.46359253]
 [  86.7533493 ]
 [  89.37080383]
 [  94.57455444]
 [  93.88195038]
 [  81.66796875]
 [  89.59481812]
 [  91.81795502]
 [  88.18269348]
 [  94.11066437]
 [  92.71524811]
 [  89.33647919]]
DEBUG:root:training time = %d0.217971
INFO:root:frame =13713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =13714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.891605
DEBUG:root: dqn, choose action rondomly, need time 0.000259000000028
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root:frame =13717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =13718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487089157104
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.891573333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  84.67223358]
 [  91.13699341]
 [ 117.18848419]
 [  91.1171875 ]
 [  86.29064941]
 [  85.0647049 ]
 [  92.73140717]
 [  88.28044128]
 [  89.84023285]
 [  97.55390167]
 [  89.84023285]
 [  84.90378571]
 [  88.45572662]
 [  74.92432404]
 [  93.01315308]
 [  95.26881409]]
DEBUG:root:training time = %d0.222761
INFO:root:frame =13721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =13722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000320196151733
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:random_action_porb = 0.891541666667
DEBUG:root: dqn, choose action rondomly, need time 0.000212999999974
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =13725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =13726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame = 13727 State into memory, numbers recorded 370 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000560998916626
INFO:root:random_action_porb = 0.89151
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13728current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:training error  = [[ 93.44837952]
 [ 90.64297485]
 [ 86.90975952]
 [ 92.51289368]
 [ 90.24420166]
 [ 95.32273102]
 [ 90.99225616]
 [ 90.64297485]
 [ 84.48587799]
 [ 88.58493042]
 [ 90.32423401]
 [ 94.84898376]
 [ 94.40190887]
 [ 92.0256958 ]
 [ 97.515625  ]
 [ 90.2363739 ]]
DEBUG:root:training time = %d0.232042
INFO:root:frame =13729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:frame =13730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:random_action_porb = 0.891478333333
INFO:root:dqn select action Tensor("ArgMax_192:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010142
INFO:root:action choosen by dqn [4]
INFO:root:frame =13732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root:frame =13733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:frame =13734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.891446666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  93.29975128]
 [  96.79159546]
 [ 116.07945251]
 [  99.66336823]
 [  96.44722748]
 [ 109.96403503]
 [  93.58354187]
 [  87.58704376]
 [  87.03412628]
 [  87.10845184]
 [  94.69538879]
 [  96.72375488]
 [  91.95339966]
 [  88.15116882]
 [  90.66389465]
 [  90.62757874]]
DEBUG:root:training time = %d0.220939
INFO:root:frame =13737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =13738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:random_action_porb = 0.891415
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999952
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =13741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000493049621582
INFO:root:frame =13742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049901008606
DEBUG:root: save sample needs time = 0.000174999237061
INFO:root:random_action_porb = 0.891383333333
DEBUG:root: dqn, choose action rondomly, need time 0.000279999999975
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163793563843
INFO:root:training error  = [[ 88.65962982]
 [ 84.94174957]
 [ 94.92032623]
 [ 91.99934387]
 [ 90.82233429]
 [ 91.25648499]
 [ 91.27689362]
 [ 88.91670227]
 [ 87.72447968]
 [ 90.32829285]
 [ 86.6050415 ]
 [ 98.36670685]
 [ 87.11927795]
 [ 94.02186584]
 [ 92.21989441]
 [ 90.74382019]]
DEBUG:root:training time = %d0.22583
INFO:root:frame =13745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000322818756104
INFO:root:frame =13746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.891351666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =13749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =13750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.89132
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000400066375732
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  90.34714508]
 [  95.84127808]
 [  84.79611969]
 [  90.40226746]
 [  89.88796997]
 [  90.12798309]
 [  91.40435028]
 [  90.23695374]
 [  94.96166229]
 [  89.30648041]
 [  89.6364212 ]
 [  87.31735229]
 [  92.97754669]
 [ 113.48510742]
 [  95.97248077]
 [ 111.83669281]]
DEBUG:root:training time = %d0.229161
INFO:root:frame =13753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =13754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264883041382
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:random_action_porb = 0.891288333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =13757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =13758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.891256666667
DEBUG:root: dqn, choose action rondomly, need time 0.000214000000028
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  94.07662201]
 [  89.12631989]
 [  96.84024048]
 [ 110.02484894]
 [  90.71242523]
 [  89.83531952]
 [  89.83531952]
 [  91.32646179]
 [  91.54678345]
 [  94.89743042]
 [  88.79243469]
 [  89.7722702 ]
 [  89.49403381]
 [  92.7734375 ]
 [  90.98003387]
 [  89.41581726]]
DEBUG:root:training time = %d0.229397
INFO:root:frame =13761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000276803970337
INFO:root:frame =13762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000503063201904
INFO:root:frame = 13763 State into memory, numbers recorded 371 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000388145446777
INFO:root:random_action_porb = 0.891225
DEBUG:root: dqn, choose action rondomly, need time 0.000280999999973
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13764current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =13765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000510931015015
INFO:root:frame =13766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000490188598633
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.891193333333
DEBUG:root: dqn, choose action rondomly, need time 0.000460999999973
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  91.33375549]
 [  94.78984833]
 [  95.17619324]
 [ 124.66899872]
 [  89.52377319]
 [ 109.59728241]
 [  94.08194733]
 [  91.59642792]
 [  99.37597656]
 [ 111.6918335 ]
 [  90.47366333]
 [  93.50650024]
 [  94.08194733]
 [  93.04524231]
 [  99.98718262]
 [  90.42577362]]
DEBUG:root:training time = %d0.223873
INFO:root:frame =13769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =13770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:random_action_porb = 0.891161666667
DEBUG:root: dqn, choose action rondomly, need time 0.000540000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =13773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000634908676147
INFO:root:frame =13774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:random_action_porb = 0.89113
INFO:root:dqn select action Tensor("ArgMax_193:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012855
INFO:root:action choosen by dqn [4]
INFO:root:frame =13776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000182867050171
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 89.85064697]
 [ 90.95529175]
 [ 92.50144958]
 [ 94.80915833]
 [ 85.36895752]
 [ 90.59968567]
 [ 92.59657288]
 [ 90.81564331]
 [ 72.90802765]
 [ 82.5670166 ]
 [ 90.91222382]
 [ 96.94177246]
 [ 93.24552155]
 [ 88.4838562 ]
 [ 90.1914444 ]
 [ 88.76741791]]
DEBUG:root:training time = %d0.240061
INFO:root:frame =13777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000397920608521
INFO:root:frame =13778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.891098333333
INFO:root:dqn select action Tensor("ArgMax_194:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00985700000001
INFO:root:action choosen by dqn [4]
INFO:root:frame =13780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000181913375854
INFO:root:frame =13781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00027322769165
INFO:root:frame =13782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:random_action_porb = 0.891066666667
DEBUG:root: dqn, choose action rondomly, need time 0.000280000000032
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  92.89369965]
 [  95.02619934]
 [ 110.00276184]
 [  93.16096497]
 [  89.80436707]
 [  92.44862366]
 [  91.8188324 ]
 [  96.45532227]
 [  89.29811859]
 [  85.37882996]
 [  94.90397644]
 [ 113.54981232]
 [  92.20611572]
 [  94.45380402]
 [ 110.88922882]
 [  91.51583862]]
DEBUG:root:training time = %d0.227412
INFO:root:frame =13785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =13786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249862670898
DEBUG:root: save sample needs time = 0.000115871429443
INFO:root:random_action_porb = 0.891035
DEBUG:root: dqn, choose action rondomly, need time 0.000182999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:frame =13789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root:frame =13790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045919418335
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.891003333333
INFO:root:dqn select action Tensor("ArgMax_195:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.0112590000001
INFO:root:action choosen by dqn [4]
INFO:root:frame =13792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000193119049072
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  90.84123993]
 [  97.03374481]
 [  89.58441925]
 [  93.42507172]
 [  89.0560379 ]
 [  91.9516449 ]
 [  88.70560455]
 [  94.34083557]
 [  91.63002014]
 [  96.38549805]
 [  91.19177246]
 [  92.26268768]
 [  89.66098022]
 [  91.15680695]
 [ 113.17095184]
 [ 117.6021347 ]]
DEBUG:root:training time = %d0.237741
INFO:root:frame =13793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =13794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:random_action_porb = 0.890971666667
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000018
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =13797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =13798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame = 13799 State into memory, numbers recorded 372 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000537872314453
INFO:root:random_action_porb = 0.89094
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13800current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 123.75883484]
 [  97.37192535]
 [  94.7749939 ]
 [  93.72441864]
 [  90.47163391]
 [  94.5178833 ]
 [  69.26950073]
 [  87.1480484 ]
 [  91.46504211]
 [  96.39538574]
 [ 102.27352142]
 [  88.44281006]
 [  96.82072449]
 [  92.27529144]
 [ 110.39809418]
 [  93.9925766 ]]
DEBUG:root:training time = %d0.237623
INFO:root:frame =13801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =13802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000357151031494
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:random_action_porb = 0.890908333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =13805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =13806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.890876666667
DEBUG:root: dqn, choose action rondomly, need time 0.000464999999963
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:training error  = [[ 91.96100616]
 [ 92.14575958]
 [ 89.22286224]
 [ 90.115242  ]
 [ 94.53687286]
 [ 88.24259949]
 [ 88.3398056 ]
 [ 92.87576294]
 [ 92.87576294]
 [ 92.33451843]
 [ 93.12944794]
 [ 89.55958557]
 [ 89.54860687]
 [ 90.90174866]
 [ 94.50244904]
 [ 92.97136688]]
DEBUG:root:training time = %d0.22234
INFO:root:frame =13809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000387191772461
INFO:root:frame =13810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000311136245728
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.890845
DEBUG:root: dqn, choose action rondomly, need time 0.000332000000014
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000418901443481
INFO:root:frame =13813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000502109527588
INFO:root:frame =13814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.890813333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304222106934
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 111.89059448]
 [  92.21344757]
 [ 100.46409607]
 [  93.39203644]
 [  90.2653656 ]
 [ 100.49285126]
 [  95.72450256]
 [  97.33518982]
 [  85.24606323]
 [  97.7580719 ]
 [ 102.19576263]
 [  90.66941833]
 [  89.27245331]
 [  89.56015778]
 [  92.74492645]
 [  92.23923492]]
DEBUG:root:training time = %d0.246648
INFO:root:frame =13817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =13818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.890781666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =13821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =13822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000525951385498
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.89075
INFO:root:dqn select action Tensor("ArgMax_196:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010134
INFO:root:action choosen by dqn [4]
INFO:root:frame =13824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000384092330933
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  97.91805267]
 [  99.89687347]
 [  72.85592651]
 [  89.034729  ]
 [  90.59532928]
 [  95.79647064]
 [  88.02972412]
 [ 100.57424927]
 [  80.46913147]
 [  96.9559021 ]
 [  91.87030792]
 [  90.98352814]
 [  90.02256012]
 [  95.08660126]
 [ 100.01861572]
 [  93.96624756]]
DEBUG:root:training time = %d0.231576
INFO:root:frame =13825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =13826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00032114982605
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.890718333333
INFO:root:dqn select action Tensor("ArgMax_197:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012369
INFO:root:action choosen by dqn [4]
INFO:root:frame =13828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016713142395
INFO:root:frame =13829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =13830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.890686666667
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  93.15330505]
 [ 110.62169647]
 [  97.48548889]
 [  91.74983215]
 [  95.65255737]
 [  95.91359711]
 [  95.4959259 ]
 [  97.52707672]
 [  98.25686646]
 [  97.18711853]
 [  96.77718353]
 [  98.66537476]
 [  97.59037781]
 [  92.20553589]
 [  98.07998657]
 [  92.44568634]]
DEBUG:root:training time = %d0.20807
INFO:root:frame =13833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000222206115723
INFO:root:frame =13834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233888626099
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.890655
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =13837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000386953353882
INFO:root:frame =13838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049090385437
INFO:root:frame = 13839 State into memory, numbers recorded 373 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000564098358154
INFO:root:random_action_porb = 0.890623333333
DEBUG:root: dqn, choose action rondomly, need time 0.00028599999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13840current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  94.30319977]
 [  90.82989502]
 [  98.56930542]
 [  89.60435486]
 [  98.18669891]
 [  89.58413696]
 [  94.44164276]
 [  94.35861969]
 [  91.35475159]
 [  92.68645477]
 [  91.27747345]
 [ 117.23937225]
 [  92.31428528]
 [  93.65913391]
 [  90.97974396]
 [  94.78092957]]
DEBUG:root:training time = %d0.22916
INFO:root:frame =13841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =13842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000379800796509
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:random_action_porb = 0.890591666667
DEBUG:root: dqn, choose action rondomly, need time 0.000411999999983
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355958938599
INFO:root:frame =13845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:frame =13846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000513076782227
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.89056
DEBUG:root: dqn, choose action rondomly, need time 0.000364999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  88.02027893]
 [ 104.40444946]
 [ 114.4549942 ]
 [  93.92601776]
 [  93.49175262]
 [  98.88071442]
 [ 124.38225555]
 [  91.81210327]
 [  95.72270966]
 [  99.26952362]
 [  93.06201935]
 [  92.38378906]
 [  90.90756226]
 [  95.86966705]
 [  91.30255127]
 [  91.05194092]]
DEBUG:root:training time = %d0.230979
INFO:root:frame =13849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023078918457
INFO:root:frame =13850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
INFO:root:frame = 13851 State into memory, numbers recorded 374 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000542879104614
INFO:root:random_action_porb = 0.890528333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13852current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =13853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430822372437
INFO:root:frame =13854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.890496666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  92.60038757]
 [  92.65354919]
 [ 115.47164154]
 [ 119.4410553 ]
 [  99.7386322 ]
 [  96.36662292]
 [  89.24650574]
 [  95.50785065]
 [  91.45016479]
 [ 100.65843201]
 [  92.95930481]
 [  95.23843384]
 [  94.74142456]
 [  97.14139557]
 [  87.89577484]
 [  94.10237122]]
DEBUG:root:training time = %d0.227571
INFO:root:frame =13857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =13858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.890465
DEBUG:root: dqn, choose action rondomly, need time 0.000335000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =13861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =13862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 9.29832458496e-05
INFO:root:random_action_porb = 0.890433333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000346183776855
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  93.46549225]
 [ 100.00091553]
 [  93.12208557]
 [  94.84511566]
 [  93.30918884]
 [  93.12208557]
 [  94.08757019]
 [  94.41347504]
 [  90.111763  ]
 [ 115.63993835]
 [ 113.93321228]
 [  96.56745148]
 [  92.61830139]
 [  92.70996094]
 [  90.93375397]
 [  92.81253815]]
DEBUG:root:training time = %d0.240421
INFO:root:frame =13865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =13866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.890401666667
DEBUG:root: dqn, choose action rondomly, need time 0.000354999999956
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame =13869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470876693726
INFO:root:frame =13870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000343799591064
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.89037
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000031
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  91.98617554]
 [  97.72698975]
 [  99.75265503]
 [  91.39588928]
 [  95.77287292]
 [  97.76139069]
 [ 107.90104675]
 [  96.64693451]
 [  96.84864807]
 [  94.41999817]
 [  92.84017944]
 [  89.23929596]
 [  89.19029236]
 [  98.87252045]
 [  91.53043365]
 [  79.66221619]]
DEBUG:root:training time = %d0.215032
INFO:root:frame =13873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:frame =13874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame = 13875 State into memory, numbers recorded 375 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000573873519897
INFO:root:random_action_porb = 0.890338333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13876current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000351905822754
INFO:root:frame =13877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000509977340698
INFO:root:frame =13878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.890306666667
INFO:root:dqn select action Tensor("ArgMax_198:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00935400000003
INFO:root:action choosen by dqn [4]
INFO:root:frame =13880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  99.96520996]
 [  94.68261719]
 [  92.76197815]
 [ 100.07966614]
 [  98.89983368]
 [  94.53390503]
 [  87.57647705]
 [ 114.23635864]
 [ 103.17327881]
 [  98.44178772]
 [ 100.84344482]
 [  98.66082764]
 [  76.36902618]
 [  92.54812622]
 [  86.57437134]
 [  95.5215683 ]]
DEBUG:root:training time = %d0.221096
INFO:root:frame =13881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000358104705811
INFO:root:frame =13882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000339031219482
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.890275
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =13885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =13886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.890243333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  99.14642334]
 [  93.23667908]
 [  95.80155182]
 [  79.93619537]
 [  96.90692139]
 [ 103.56578064]
 [  94.26644897]
 [  97.66123962]
 [  93.93282318]
 [  93.30594635]
 [  97.9911499 ]
 [  97.34332275]
 [  96.91894531]
 [  95.50486755]
 [  97.9105072 ]
 [  96.73576355]]
DEBUG:root:training time = %d0.232348
INFO:root:frame =13889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259160995483
INFO:root:frame =13890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root:random_action_porb = 0.890211666667
DEBUG:root: dqn, choose action rondomly, need time 0.000319999999988
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =13893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =13894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049090385437
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:random_action_porb = 0.89018
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000362873077393
INFO:root:training error  = [[  92.1580658 ]
 [  93.99760437]
 [  91.7246933 ]
 [  97.54727173]
 [  95.25242615]
 [  98.67658997]
 [  88.29994202]
 [  92.03535461]
 [  91.7246933 ]
 [  95.16607666]
 [  95.68180847]
 [ 104.8895874 ]
 [ 101.0697403 ]
 [  98.72479248]
 [  94.62887573]
 [  92.48735809]]
DEBUG:root:training time = %d0.231177
INFO:root:frame =13897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =13898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000345945358276
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.890148333333
DEBUG:root: dqn, choose action rondomly, need time 0.00037199999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =13901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =13902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000715970993042
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.890116666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:training error  = [[  95.39633942]
 [ 105.18484497]
 [  97.25482178]
 [  91.34658813]
 [  92.94871521]
 [  94.09378815]
 [ 101.05931091]
 [ 103.26846313]
 [  98.67992401]
 [  97.63047791]
 [  93.19955444]
 [  94.43749237]
 [  97.63047791]
 [  92.82224274]
 [  98.85340118]
 [  98.01954651]]
DEBUG:root:training time = %d0.217581
INFO:root:frame =13905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =13906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485181808472
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.890085
DEBUG:root: dqn, choose action rondomly, need time 0.000351000000023
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =13909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000659942626953
INFO:root:frame =13910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.890053333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304000000028
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  95.26016998]
 [  96.17738342]
 [ 100.11814117]
 [ 101.28891754]
 [ 122.18587494]
 [  98.75511932]
 [  96.4888916 ]
 [  98.32826996]
 [  97.53039551]
 [ 101.14737701]
 [ 104.23021698]
 [ 108.6526947 ]
 [ 103.67978668]
 [  96.09210205]
 [ 121.21359253]
 [ 102.58361053]]
DEBUG:root:training time = %d0.216972
INFO:root:frame =13913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =13914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428915023804
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:random_action_porb = 0.890021666667
DEBUG:root: dqn, choose action rondomly, need time 0.000551999999971
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =13917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame =13918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.88999
DEBUG:root: dqn, choose action rondomly, need time 0.000260999999966
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  99.40487671]
 [  98.35853577]
 [  90.88865662]
 [  95.12558746]
 [  98.752388  ]
 [  94.44698334]
 [  98.31375122]
 [  95.9697876 ]
 [  93.95677948]
 [  96.87358093]
 [ 105.05843353]
 [  94.44283295]
 [ 116.05610657]
 [  93.28884888]
 [  96.55635071]
 [  98.25384521]]
DEBUG:root:training time = %d0.227703
INFO:root:frame =13921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =13922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000285863876343
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.889958333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =13925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =13926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.889926666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:training error  = [[  95.46550751]
 [  97.14259338]
 [  93.05259705]
 [  92.17359161]
 [ 100.34851074]
 [  94.94024658]
 [  97.88001251]
 [  96.63853455]
 [  92.7978363 ]
 [ 103.65213776]
 [  96.81141663]
 [  99.14824677]
 [  96.36452484]
 [ 104.4468689 ]
 [ 100.99520111]
 [  89.92298126]]
DEBUG:root:training time = %d0.217265
INFO:root:frame =13929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =13930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000175952911377
INFO:root:random_action_porb = 0.889895
DEBUG:root: dqn, choose action rondomly, need time 0.00032600000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =13933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000592947006226
INFO:root:frame =13934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000289916992188
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.889863333333
DEBUG:root: dqn, choose action rondomly, need time 0.00041600000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:training error  = [[ 108.08435059]
 [ 100.59169006]
 [  92.60596466]
 [  96.85946655]
 [ 105.06406403]
 [  95.58481598]
 [ 102.06407166]
 [ 106.09949493]
 [  94.27622986]
 [ 103.09735107]
 [ 102.2710495 ]
 [  92.97225189]
 [  96.74206543]
 [  96.39718628]
 [  99.80630493]
 [ 103.12927246]]
DEBUG:root:training time = %d0.250317
INFO:root:frame =13937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =13938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000587940216064
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.889831666667
DEBUG:root: dqn, choose action rondomly, need time 0.000274999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =13941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =13942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.8898
DEBUG:root: dqn, choose action rondomly, need time 0.000174000000015
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  98.21966553]
 [  95.41124725]
 [  94.83679962]
 [  98.24446869]
 [  93.19690704]
 [ 105.8927536 ]
 [ 100.7297821 ]
 [  98.24446869]
 [ 100.83823395]
 [  99.69109344]
 [ 114.37763214]
 [  98.38093567]
 [  96.08133698]
 [ 103.22350311]
 [  93.02404785]
 [ 106.42697906]]
DEBUG:root:training time = %d0.233578
INFO:root:frame =13945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =13946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000258922576904
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.889768333333
DEBUG:root: dqn, choose action rondomly, need time 0.00022800000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =13948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000380992889404
INFO:root:frame =13949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000498056411743
INFO:root:frame =13950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.889736666667
DEBUG:root: dqn, choose action rondomly, need time 0.000501999999983
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  96.24383545]
 [  97.9095993 ]
 [  97.60243988]
 [  92.99491119]
 [  93.42802429]
 [  98.57142639]
 [ 102.37230682]
 [ 104.41723633]
 [ 102.37230682]
 [  98.78726959]
 [ 100.94429779]
 [  95.0746994 ]
 [ 126.89024353]
 [  94.69657135]
 [  98.28016663]
 [  92.95783234]]
DEBUG:root:training time = %d0.220974
INFO:root:frame =13953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =13954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000125885009766
INFO:root:random_action_porb = 0.889705
INFO:root:dqn select action Tensor("ArgMax_199:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014783
INFO:root:action choosen by dqn [4]
INFO:root:frame =13956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000197172164917
INFO:root:frame =13957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =13958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00023889541626
DEBUG:root: save sample needs time = 0.00010085105896
INFO:root:random_action_porb = 0.889673333333
DEBUG:root: dqn, choose action rondomly, need time 0.000165999999979
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  99.56041718]
 [  94.81450653]
 [  96.40617371]
 [ 116.26726532]
 [  96.18935394]
 [ 111.25105286]
 [  96.56624603]
 [  97.80545044]
 [  98.96296692]
 [  93.4460144 ]
 [  93.15831757]
 [  99.99084473]
 [ 100.64281464]
 [  98.80303955]
 [  95.91269684]
 [  97.43186188]]
DEBUG:root:training time = %d0.222484
INFO:root:frame =13961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =13962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.889641666667
DEBUG:root: dqn, choose action rondomly, need time 0.000266000000011
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =13965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049614906311
INFO:root:frame =13966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000613927841187
INFO:root:frame = 13967 State into memory, numbers recorded 376 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.00059986114502
INFO:root:random_action_porb = 0.88961
INFO:root:dqn select action Tensor("ArgMax_200:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010148
INFO:root:action choosen by dqn [4]
INFO:root:frame =13968current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000485181808472
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 102.43406677]
 [ 103.48628998]
 [ 101.20631409]
 [ 100.75030518]
 [ 101.20631409]
 [ 100.8937149 ]
 [  97.15011597]
 [  94.19950104]
 [ 101.86715698]
 [ 110.99465942]
 [ 124.5514679 ]
 [ 101.25390625]
 [ 101.25390625]
 [  97.45114136]
 [ 101.68951416]
 [  97.95792389]]
DEBUG:root:training time = %d0.214973
INFO:root:frame =13969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =13970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:random_action_porb = 0.889578333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =13973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000403881072998
INFO:root:frame =13974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444173812866
DEBUG:root: save sample needs time = 0.000245809555054
INFO:root:random_action_porb = 0.889546666667
DEBUG:root: dqn, choose action rondomly, need time 0.000227999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 100.12119293]
 [ 101.27693939]
 [ 103.61236572]
 [  95.60002899]
 [ 103.96742249]
 [ 103.96742249]
 [ 115.05358124]
 [ 105.48834229]
 [ 108.46509552]
 [ 103.09703827]
 [  92.52933502]
 [  92.23659515]
 [ 101.27693939]
 [ 121.29727173]
 [ 104.8345871 ]
 [ 104.8345871 ]]
DEBUG:root:training time = %d0.242906
INFO:root:frame =13977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =13978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.889515
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =13980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =13981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =13982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame = 13983 State into memory, numbers recorded 377 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000837087631226
INFO:root:random_action_porb = 0.889483333333
DEBUG:root: dqn, choose action rondomly, need time 0.00032699999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13984current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:training error  = [[ 100.24337006]
 [  94.81569672]
 [ 101.69320679]
 [ 107.69730377]
 [  98.42028809]
 [ 100.91946411]
 [ 104.77960205]
 [ 100.8839035 ]
 [  96.95980835]
 [  99.46391296]
 [ 110.44972229]
 [ 104.33804321]
 [  97.22984314]
 [  96.61544037]
 [ 100.24795532]
 [ 100.08424377]]
DEBUG:root:training time = %d0.213854
INFO:root:frame =13985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =13986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000326871871948
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.889451666667
DEBUG:root: dqn, choose action rondomly, need time 0.000340999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =13988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =13989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000595092773438
INFO:root:frame =13990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 9.91821289062e-05
INFO:root:random_action_porb = 0.88942
DEBUG:root: dqn, choose action rondomly, need time 0.000163999999984
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =13992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  99.58203888]
 [ 101.93154144]
 [  99.11238861]
 [  99.1917038 ]
 [  99.66306305]
 [  98.84854889]
 [  94.98545074]
 [ 103.72920227]
 [  98.68780518]
 [  95.96141815]
 [ 103.06450653]
 [  96.00746155]
 [ 101.77693176]
 [  98.70387268]
 [ 120.72086334]
 [ 101.77693176]]
DEBUG:root:training time = %d0.211524
INFO:root:frame =13993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =13994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423192977905
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.889388333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =13996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =13997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =13998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000201940536499
DEBUG:root:one frame running time = 0.00606499999998
DEBUG:root:total training time = 419.577102
INFO:root:frame num = 14000 frame round: 0
INFO:root:random_action_porb = 0.889356666667
INFO:root:dqn select action Tensor("ArgMax_201:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01326
INFO:root:action choosen by dqn [4]
INFO:root:frame =14000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  97.80665588]
 [  99.51535797]
 [  96.98835754]
 [  92.6849823 ]
 [ 106.15388489]
 [  96.96611786]
 [  99.75905609]
 [ 100.25406647]
 [  97.54154205]
 [  99.60549164]
 [ 100.81157684]
 [  98.04613495]
 [ 119.12875366]
 [ 129.150177  ]
 [  99.37932587]
 [ 101.00133514]]
DEBUG:root:training time = %d0.233494
INFO:root:frame =14001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =14002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000340938568115
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.889325
DEBUG:root: dqn, choose action rondomly, need time 0.000208000000043
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:frame =14005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =14006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.889293333333
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999983
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  96.53446198]
 [  97.33278656]
 [ 100.08180237]
 [  99.77642822]
 [ 104.81147003]
 [  95.38591003]
 [ 100.1529541 ]
 [ 100.69303131]
 [ 124.61448669]
 [  98.30860138]
 [  97.24217987]
 [ 117.57996368]
 [  98.11474609]
 [ 100.66792297]
 [ 101.69720459]
 [ 103.39317322]]
DEBUG:root:training time = %d0.225102
INFO:root:frame =14009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000385046005249
INFO:root:frame =14010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000530958175659
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.889261666667
DEBUG:root: dqn, choose action rondomly, need time 0.000362999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00037693977356
INFO:root:frame =14013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =14014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485897064209
INFO:root:frame = 14015 State into memory, numbers recorded 378 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root:random_action_porb = 0.88923
DEBUG:root: dqn, choose action rondomly, need time 0.000495000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14016current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  97.9778595 ]
 [ 106.16519928]
 [  97.06981659]
 [ 102.70048523]
 [ 103.83552551]
 [  96.3543396 ]
 [  96.39238739]
 [  97.8824234 ]
 [ 101.7252121 ]
 [ 101.0577774 ]
 [  98.43906403]
 [ 102.92204285]
 [  97.58525085]
 [  99.92951965]
 [ 124.05675507]
 [  98.66840363]]
DEBUG:root:training time = %d0.237504
INFO:root:frame =14017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =14018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000600099563599
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.889198333333
DEBUG:root: dqn, choose action rondomly, need time 0.000185999999985
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000369071960449
INFO:root:frame =14021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =14022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000187873840332
INFO:root:random_action_porb = 0.889166666667
INFO:root:dqn select action Tensor("ArgMax_202:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012292
INFO:root:action choosen by dqn [4]
INFO:root:frame =14024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000370979309082
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  93.6978302 ]
 [  96.58784485]
 [ 100.1868515 ]
 [ 125.05979919]
 [  96.93035889]
 [ 129.48576355]
 [ 100.24795532]
 [ 102.85889435]
 [ 117.16899872]
 [ 121.69252014]
 [  97.59671021]
 [  95.60331726]
 [  93.6978302 ]
 [  92.11500549]
 [ 103.14476776]
 [ 125.19702911]]
DEBUG:root:training time = %d0.227991
INFO:root:frame =14025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =14026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:random_action_porb = 0.889135
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =14029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000607013702393
INFO:root:frame =14030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:random_action_porb = 0.889103333333
INFO:root:dqn select action Tensor("ArgMax_203:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010777
INFO:root:action choosen by dqn [4]
INFO:root:frame =14032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  99.17589569]
 [ 100.38581085]
 [  97.07523346]
 [ 101.69997406]
 [ 100.36165619]
 [ 117.93828583]
 [  96.41216278]
 [  96.87958527]
 [  97.92681122]
 [  99.55646515]
 [ 102.18095398]
 [ 100.63332367]
 [  99.22392273]
 [ 114.20439148]
 [  97.92469788]
 [ 103.46517944]]
DEBUG:root:training time = %d0.224907
INFO:root:frame =14033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =14034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487089157104
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:random_action_porb = 0.889071666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =14037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =14038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:random_action_porb = 0.88904
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  99.29264069]
 [ 100.14470673]
 [  98.77483368]
 [  98.11444092]
 [  99.29264069]
 [  99.30966949]
 [ 102.69399261]
 [ 120.53919983]
 [  98.90408325]
 [ 100.1202774 ]
 [ 122.09649658]
 [ 100.14470673]
 [  98.61293793]
 [ 101.34144592]
 [ 102.85826874]
 [ 102.44889069]]
DEBUG:root:training time = %d0.238977
INFO:root:frame =14041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =14042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000402927398682
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.889008333333
DEBUG:root: dqn, choose action rondomly, need time 0.000437999999974
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =14045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =14046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.888976666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  98.40787506]
 [  98.57566833]
 [ 106.42099762]
 [ 102.17416382]
 [  99.87644196]
 [  95.08243561]
 [ 101.46682739]
 [ 125.2953949 ]
 [  97.89087677]
 [  99.44261169]
 [ 106.99285126]
 [  96.80541229]
 [  97.74117279]
 [  98.84945679]
 [ 102.95238495]
 [  99.99938965]]
DEBUG:root:training time = %d0.216065
INFO:root:frame =14049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270843505859
INFO:root:frame =14050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486850738525
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.888945
DEBUG:root: dqn, choose action rondomly, need time 0.000256999999976
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:frame =14053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =14054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494003295898
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.888913333333
INFO:root:dqn select action Tensor("ArgMax_204:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012262
INFO:root:action choosen by dqn [4]
INFO:root:frame =14056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 105.14134216]
 [ 100.4980545 ]
 [ 120.12442017]
 [ 120.22444916]
 [ 101.95835114]
 [ 102.48133087]
 [  98.43209839]
 [ 104.03869629]
 [ 102.3698349 ]
 [ 103.36369324]
 [ 102.50635529]
 [  98.06668854]
 [  97.08786011]
 [ 101.30826569]
 [  99.51566315]
 [ 102.72554016]]
DEBUG:root:training time = %d0.227358
INFO:root:frame =14057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =14058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319957733154
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.888881666667
DEBUG:root: dqn, choose action rondomly, need time 0.000320999999985
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =14061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471830368042
INFO:root:frame =14062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.88885
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999963
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[ 100.67312622]
 [  99.22088623]
 [ 102.26889038]
 [  96.28036499]
 [ 100.42036438]
 [  98.04069519]
 [ 106.35584259]
 [  98.7745285 ]
 [  99.02490997]
 [ 106.55641174]
 [ 102.83227539]
 [ 100.70773315]
 [ 109.06471252]
 [ 100.41883087]
 [  98.68235016]
 [  94.56535339]]
DEBUG:root:training time = %d0.221389
INFO:root:frame =14065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =14066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.888818333333
DEBUG:root: dqn, choose action rondomly, need time 0.000324999999975
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326156616211
INFO:root:frame =14069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000411033630371
INFO:root:frame =14070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.888786666667
DEBUG:root: dqn, choose action rondomly, need time 0.000164999999981
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000134944915771
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 105.3025589 ]
 [ 103.5508728 ]
 [ 101.60059357]
 [ 128.87736511]
 [ 100.6902771 ]
 [ 101.24315643]
 [  99.32183075]
 [ 101.0712738 ]
 [ 103.7776947 ]
 [  99.06713104]
 [ 102.65348053]
 [ 106.82245636]
 [ 102.6683197 ]
 [ 100.71263123]
 [ 100.00579834]
 [  99.34738159]]
DEBUG:root:training time = %d0.227339
INFO:root:frame =14073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =14074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000261068344116
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.888755
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =14077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =14078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.888723333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303999999971
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 107.92893982]
 [ 107.54280853]
 [ 129.12451172]
 [  95.11130524]
 [ 100.67067719]
 [ 102.88860321]
 [  99.65575409]
 [ 107.54280853]
 [ 105.43914032]
 [ 100.21984863]
 [ 102.38496399]
 [ 102.47329712]
 [ 106.11804199]
 [  99.56864166]
 [ 102.32784271]
 [  96.29953003]]
DEBUG:root:training time = %d0.223905
INFO:root:frame =14081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =14082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000543832778931
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.888691666667
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000021
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =14085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000486850738525
INFO:root:frame =14086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000535011291504
DEBUG:root: save sample needs time = 0.000123977661133
INFO:root:random_action_porb = 0.88866
DEBUG:root: dqn, choose action rondomly, need time 0.000180999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 100.48918152]
 [ 109.20658112]
 [ 100.53538513]
 [  99.14672852]
 [ 105.54665375]
 [ 100.777565  ]
 [ 104.20124054]
 [ 101.84806061]
 [ 124.69557953]
 [  98.62475586]
 [ 100.25101471]
 [ 105.62504578]
 [ 104.52516174]
 [  99.08383179]
 [  98.81365967]
 [ 103.86320496]]
DEBUG:root:training time = %d0.207199
INFO:root:frame =14089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =14090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.888628333333
INFO:root:dqn select action Tensor("ArgMax_205:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01436
INFO:root:action choosen by dqn [4]
INFO:root:frame =14092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:frame =14093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000189065933228
INFO:root:frame =14094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234127044678
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.888596666667
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 100.52467346]
 [ 103.32150269]
 [ 103.6891098 ]
 [ 103.60584259]
 [ 106.15105438]
 [ 100.73131561]
 [ 132.18508911]
 [ 111.97422028]
 [ 127.30619812]
 [  98.12351227]
 [ 100.07569885]
 [ 108.47557831]
 [ 101.97653198]
 [  96.63763428]
 [ 102.29759216]
 [ 102.05975342]]
DEBUG:root:training time = %d0.23192
INFO:root:frame =14097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =14098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000111103057861
INFO:root:random_action_porb = 0.888565
DEBUG:root: dqn, choose action rondomly, need time 0.00036700000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =14101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =14102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411987304688
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.888533333333
DEBUG:root: dqn, choose action rondomly, need time 0.000264000000016
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root:training error  = [[ 112.690979  ]
 [ 101.07587433]
 [ 107.09230804]
 [  99.54550171]
 [ 106.76442719]
 [  93.35812378]
 [ 111.98197174]
 [ 102.07485962]
 [ 109.4292984 ]
 [ 107.20160675]
 [ 103.95279694]
 [ 100.3161087 ]
 [ 100.65873718]
 [ 104.00165558]
 [  99.44535065]
 [ 110.15196991]]
DEBUG:root:training time = %d0.230285
INFO:root:frame =14105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304222106934
INFO:root:frame =14106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475168228149
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.888501666667
INFO:root:dqn select action Tensor("ArgMax_206:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011041
INFO:root:action choosen by dqn [4]
INFO:root:frame =14108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000384092330933
INFO:root:frame =14109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =14110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.88847
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999955
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 103.19528961]
 [ 105.13633728]
 [  94.77469635]
 [ 128.73918152]
 [ 104.81021881]
 [ 122.41874695]
 [ 103.78298187]
 [ 111.19312286]
 [ 123.5630188 ]
 [ 131.56898499]
 [ 103.64654541]
 [ 106.20262146]
 [ 108.87038422]
 [  97.75656128]
 [ 104.42815399]
 [ 107.34953308]]
DEBUG:root:training time = %d0.244643
INFO:root:frame =14113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =14114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.888438333333
DEBUG:root: dqn, choose action rondomly, need time 0.00017600000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:frame =14117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =14118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.888406666667
INFO:root:dqn select action Tensor("ArgMax_207:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.016934
INFO:root:action choosen by dqn [4]
INFO:root:frame =14120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 100.93356323]
 [ 108.31322479]
 [ 100.12119293]
 [ 107.57003021]
 [ 112.74411011]
 [ 102.56074524]
 [ 106.16771698]
 [ 105.57392883]
 [ 107.00958252]
 [ 123.73574829]
 [  98.1386261 ]
 [ 102.87653351]
 [ 111.85831451]
 [ 123.82164764]
 [ 103.97395325]
 [  97.52014923]]
DEBUG:root:training time = %d0.216899
INFO:root:frame =14121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000366926193237
INFO:root:frame =14122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000519037246704
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.888375
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =14125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =14126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.888343333333
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000021
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 114.23570251]
 [ 106.95623779]
 [ 104.0302887 ]
 [ 110.54756165]
 [ 121.04834747]
 [ 124.95675659]
 [ 112.00489807]
 [ 132.23561096]
 [ 101.96697235]
 [ 101.89580536]
 [ 101.47420502]
 [ 100.1450119 ]
 [ 109.54425812]
 [ 106.53058624]
 [ 124.95675659]
 [ 108.52739716]]
DEBUG:root:training time = %d0.225886
INFO:root:frame =14129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00037407875061
INFO:root:frame =14130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.888311666667
INFO:root:dqn select action Tensor("ArgMax_208:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013132
INFO:root:action choosen by dqn [4]
INFO:root:frame =14132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000199794769287
INFO:root:frame =14133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =14134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.88828
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000048
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:training error  = [[ 109.93235779]
 [  96.00656891]
 [ 108.28337097]
 [ 103.84268188]
 [ 111.3830719 ]
 [ 102.76729584]
 [ 110.92811584]
 [ 109.5286026 ]
 [ 106.14067841]
 [ 102.83320618]
 [ 107.31064606]
 [ 101.02832794]
 [  98.40636444]
 [ 103.34011841]
 [ 102.29882812]
 [ 103.38169098]]
DEBUG:root:training time = %d0.236698
INFO:root:frame =14137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =14138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.888248333333
DEBUG:root: dqn, choose action rondomly, need time 0.000349000000028
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =14141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =14142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.888216666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 112.59963989]
 [ 105.65328217]
 [ 102.50852203]
 [ 102.21674347]
 [ 104.51424408]
 [ 107.2477417 ]
 [ 102.15936279]
 [ 110.141716  ]
 [  98.1129303 ]
 [ 101.56522369]
 [ 101.73752594]
 [ 132.72068787]
 [  89.18280029]
 [ 126.76514435]
 [ 104.23706818]
 [ 102.71873474]]
DEBUG:root:training time = %d0.235246
INFO:root:frame =14145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =14146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000297069549561
DEBUG:root: save sample needs time = 0.000120162963867
INFO:root:random_action_porb = 0.888185
DEBUG:root: dqn, choose action rondomly, need time 0.000180999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000172138214111
INFO:root:frame =14149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame =14150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.888153333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000424146652222
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 103.00131226]
 [ 102.6946106 ]
 [  87.24693298]
 [ 100.55649567]
 [ 101.07802582]
 [ 110.41604614]
 [  99.71486664]
 [ 102.52149963]
 [ 110.45934296]
 [ 112.24790955]
 [ 114.50397491]
 [ 105.78663635]
 [ 101.92691803]
 [  97.7692337 ]
 [ 110.19168854]
 [ 103.764328  ]]
DEBUG:root:training time = %d0.233665
INFO:root:frame =14153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000406980514526
INFO:root:frame =14154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000266075134277
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.888121666667
DEBUG:root: dqn, choose action rondomly, need time 0.000349000000028
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:frame =14157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =14158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.88809
INFO:root:dqn select action Tensor("ArgMax_209:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013629
INFO:root:action choosen by dqn [4]
INFO:root:frame =14160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 132.19104004]
 [ 112.51512909]
 [ 106.78649902]
 [ 102.92049408]
 [ 106.93603516]
 [ 104.68341064]
 [  99.15189362]
 [ 108.26432037]
 [ 103.21916199]
 [ 105.98007202]
 [ 116.31103516]
 [ 104.10531616]
 [ 104.59288025]
 [ 133.30178833]
 [ 108.11893463]
 [ 106.75370789]]
DEBUG:root:training time = %d0.23852
INFO:root:frame =14161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000377893447876
INFO:root:frame =14162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.888058333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =14165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000656127929688
INFO:root:frame =14166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484228134155
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.888026666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 103.20490265]
 [ 102.68718719]
 [ 112.78753662]
 [  98.44814301]
 [ 108.43934631]
 [  86.00937653]
 [ 113.77495575]
 [ 100.99949646]
 [ 110.39905548]
 [ 110.47377777]
 [ 125.37636566]
 [ 103.23187256]
 [ 106.60146332]
 [ 104.11870575]
 [ 115.69376373]
 [ 106.15796661]]
DEBUG:root:training time = %d0.23302
INFO:root:frame =14169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =14170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.887995
DEBUG:root: dqn, choose action rondomly, need time 0.00058800000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00036096572876
INFO:root:frame =14173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =14174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame = 14175 State into memory, numbers recorded 379 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.00056791305542
INFO:root:random_action_porb = 0.887963333333
INFO:root:dqn select action Tensor("ArgMax_210:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013771
INFO:root:action choosen by dqn [4]
INFO:root:frame =14176current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.00102496147156
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 103.41334534]
 [ 104.01721191]
 [ 115.48049927]
 [ 103.95622253]
 [ 122.86283112]
 [ 109.96595764]
 [ 111.6363678 ]
 [ 103.15127563]
 [ 109.82295227]
 [ 106.37693024]
 [ 105.05092621]
 [ 108.70264435]
 [ 107.46054077]
 [ 114.37045288]
 [ 101.48988342]
 [ 100.64006042]]
DEBUG:root:training time = %d0.237862
INFO:root:frame =14177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =14178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000285863876343
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.887931666667
INFO:root:dqn select action Tensor("ArgMax_211:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012471
INFO:root:action choosen by dqn [4]
INFO:root:frame =14180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000353097915649
INFO:root:frame =14181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =14182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.8879
DEBUG:root: dqn, choose action rondomly, need time 0.000397000000021
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 102.85115051]
 [  99.85478973]
 [ 102.86539459]
 [ 104.03651428]
 [ 104.91053009]
 [ 104.96617889]
 [ 106.33192444]
 [ 104.24454498]
 [ 109.51869965]
 [ 111.09403229]
 [ 104.02281952]
 [ 110.71287537]
 [  99.9575882 ]
 [ 106.68624115]
 [ 106.97327423]
 [  89.63729095]]
DEBUG:root:training time = %d0.214959
INFO:root:frame =14185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =14186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000474214553833
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.887868333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000041
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =14189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =14190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456809997559
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.887836666667
DEBUG:root: dqn, choose action rondomly, need time 0.000202000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000187158584595
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 107.38937378]
 [ 104.99713135]
 [ 104.2492218 ]
 [ 105.88396454]
 [ 112.0326767 ]
 [ 106.19381714]
 [ 110.31633759]
 [ 100.46868896]
 [ 102.9957428 ]
 [ 106.14539337]
 [ 111.33347321]
 [ 105.91630554]
 [ 125.77511597]
 [ 108.50959015]
 [  98.85947418]
 [  99.65666962]]
DEBUG:root:training time = %d0.205064
INFO:root:frame =14193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =14194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000381946563721
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:random_action_porb = 0.887805
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =14197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =14198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.887773333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 108.9289856 ]
 [ 105.50589752]
 [ 131.80291748]
 [ 103.87284851]
 [ 108.0418396 ]
 [ 128.6076355 ]
 [ 103.63131714]
 [ 103.96088409]
 [  96.99827576]
 [ 101.64827728]
 [ 102.79050446]
 [ 108.74050903]
 [ 103.90332794]
 [ 105.7919693 ]
 [ 111.53707886]
 [  96.99827576]]
DEBUG:root:training time = %d0.225591
INFO:root:frame =14201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:frame =14202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000581026077271
DEBUG:root: save sample needs time = 0.000147819519043
INFO:root:random_action_porb = 0.887741666667
DEBUG:root: dqn, choose action rondomly, need time 0.000409999999988
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =14205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =14206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000339984893799
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.88771
DEBUG:root: dqn, choose action rondomly, need time 0.000317999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000363826751709
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 106.51641083]
 [ 112.42030334]
 [ 106.02468872]
 [ 106.02468872]
 [ 109.69474792]
 [ 104.09130859]
 [ 106.72438812]
 [ 101.15628052]
 [ 104.72962952]
 [ 131.11186218]
 [ 111.74892426]
 [ 103.35810852]
 [ 103.38231659]
 [ 114.79218292]
 [ 105.87359619]
 [ 113.16316223]]
DEBUG:root:training time = %d0.211453
INFO:root:frame =14209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =14210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000312089920044
DEBUG:root: save sample needs time = 0.000175952911377
INFO:root:random_action_porb = 0.887678333333
DEBUG:root: dqn, choose action rondomly, need time 0.000210999999979
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =14213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000813007354736
INFO:root:frame =14214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame = 14215 State into memory, numbers recorded 380 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000382900238037
INFO:root:random_action_porb = 0.887646666667
DEBUG:root: dqn, choose action rondomly, need time 0.000248999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14216current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 110.89212036]
 [ 104.45404053]
 [ 103.14476776]
 [ 101.25237274]
 [ 101.99501801]
 [ 113.09564209]
 [ 109.41174316]
 [  92.03652954]
 [ 109.83222961]
 [ 101.61689758]
 [ 106.97296143]
 [ 107.1292572 ]
 [ 110.01428986]
 [ 104.84677887]
 [ 107.32803345]
 [ 108.12813568]]
DEBUG:root:training time = %d0.191451
INFO:root:frame =14217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:frame =14218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:random_action_porb = 0.887615
DEBUG:root: dqn, choose action rondomly, need time 0.000324999999975
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =14221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454187393188
INFO:root:frame =14222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.887583333333
DEBUG:root: dqn, choose action rondomly, need time 0.000347999999974
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 104.33960724]
 [ 133.27043152]
 [ 113.59859467]
 [ 109.595047  ]
 [ 135.91334534]
 [ 110.70773315]
 [ 116.65753174]
 [ 108.92611694]
 [ 103.87937927]
 [ 110.7854538 ]
 [ 110.88922882]
 [ 110.71447754]
 [ 109.94611359]
 [ 107.16843414]
 [ 116.32485962]
 [ 107.29515076]]
DEBUG:root:training time = %d0.189283
INFO:root:frame =14225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000550985336304
INFO:root:frame =14226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494956970215
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.887551666667
INFO:root:dqn select action Tensor("ArgMax_212:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00984400000004
INFO:root:action choosen by dqn [4]
INFO:root:frame =14228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:frame =14229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:frame =14230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:random_action_porb = 0.88752
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 108.12813568]
 [ 111.25782013]
 [ 105.94551849]
 [ 103.10231018]
 [ 108.62883759]
 [ 107.10620117]
 [ 130.30903625]
 [ 100.24765015]
 [ 106.7067337 ]
 [ 106.51766968]
 [ 105.8607254 ]
 [ 111.30964661]
 [ 109.06726074]
 [ 108.55378723]
 [ 108.67241669]
 [ 105.07313538]]
DEBUG:root:training time = %d0.22901
INFO:root:frame =14233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =14234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000316143035889
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:random_action_porb = 0.887488333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000033
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =14237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =14238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000474214553833
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.887456666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 116.34428406]
 [ 109.788414  ]
 [ 110.32082367]
 [ 104.10157776]
 [ 106.21488953]
 [ 110.10264587]
 [ 109.75196838]
 [ 105.10003662]
 [ 102.33772278]
 [ 113.76714325]
 [  99.16830444]
 [  97.65731812]
 [ 111.25588226]
 [ 107.70585632]
 [ 133.4744873 ]
 [ 103.28583527]]
DEBUG:root:training time = %d0.233699
INFO:root:frame =14241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame =14242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000328063964844
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.887425
DEBUG:root: dqn, choose action rondomly, need time 0.000335000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =14245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249147415161
INFO:root:frame =14246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.887393333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 106.42446136]
 [ 106.47232056]
 [ 111.49969482]
 [ 117.45755768]
 [ 107.28472137]
 [ 103.77986908]
 [ 137.50439453]
 [ 117.45755768]
 [ 115.56381226]
 [ 106.82434845]
 [ 105.16950989]
 [ 108.61134338]
 [ 111.30449677]
 [ 104.65749359]
 [ 107.84811401]
 [ 114.30225372]]
DEBUG:root:training time = %d0.231463
INFO:root:frame =14249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =14250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame = 14251 State into memory, numbers recorded 381 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000274181365967
INFO:root:random_action_porb = 0.887361666667
DEBUG:root: dqn, choose action rondomly, need time 0.000166000000036
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14252current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000146150588989
INFO:root:frame =14253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =14254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233888626099
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.88733
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 107.13083649]
 [ 109.90772247]
 [ 105.9109726 ]
 [ 106.87797546]
 [ 112.41609955]
 [ 112.68870544]
 [ 109.75804138]
 [ 129.3989563 ]
 [ 112.73633575]
 [ 111.34796906]
 [ 110.39039612]
 [ 108.83599854]
 [ 106.74771881]
 [ 111.99133301]
 [  98.46237946]
 [ 114.8608551 ]]
DEBUG:root:training time = %d0.221582
INFO:root:frame =14257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =14258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.887298333333
INFO:root:dqn select action Tensor("ArgMax_213:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013085
INFO:root:action choosen by dqn [4]
INFO:root:frame =14260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000407934188843
INFO:root:frame =14261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000402927398682
INFO:root:frame =14262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame = 14263 State into memory, numbers recorded 382 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00131297111511
INFO:root:random_action_porb = 0.887266666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14264current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 105.16199493]
 [ 115.39131165]
 [ 105.17920685]
 [ 111.79764557]
 [ 107.40107727]
 [ 107.46623993]
 [ 104.25981903]
 [ 105.80703735]
 [ 111.73118591]
 [ 104.82990265]
 [ 110.1160965 ]
 [ 112.0297699 ]
 [ 114.7800827 ]
 [ 132.347229  ]
 [ 112.3025589 ]
 [ 107.95969391]]
DEBUG:root:training time = %d0.226871
INFO:root:frame =14265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270843505859
INFO:root:frame =14266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000290155410767
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.887235
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =14269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =14270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.887203333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:training error  = [[ 113.07974243]
 [ 106.61564636]
 [ 108.41678619]
 [ 108.55155945]
 [ 120.11305237]
 [ 105.39183044]
 [ 108.91624451]
 [ 111.53127289]
 [ 109.47367859]
 [ 104.21619415]
 [ 112.73536682]
 [ 112.4018631 ]
 [ 117.05439758]
 [ 106.12055206]
 [ 110.7494812 ]
 [ 107.41436005]]
DEBUG:root:training time = %d0.228169
INFO:root:frame =14273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =14274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000384092330933
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.887171666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000031
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =14277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =14278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.88714
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999983
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 120.43769836]
 [ 116.61502075]
 [ 105.62410736]
 [ 127.73800659]
 [ 109.79065704]
 [ 115.59629059]
 [ 111.30900574]
 [ 110.50040436]
 [ 108.89968109]
 [ 111.7047348 ]
 [ 110.18015289]
 [ 115.25531006]
 [ 113.80555725]
 [ 111.79667664]
 [ 106.05422974]
 [ 109.3380127 ]]
DEBUG:root:training time = %d0.237254
INFO:root:frame =14281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =14282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000375032424927
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.887108333333
DEBUG:root: dqn, choose action rondomly, need time 0.00028599999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =14285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488996505737
INFO:root:frame =14286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00034499168396
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.887076666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303999999971
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000183820724487
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  94.24481964]
 [ 104.7746048 ]
 [ 113.14498138]
 [ 103.39845276]
 [ 112.88446808]
 [ 113.94103241]
 [ 103.02144623]
 [ 108.10688019]
 [ 114.4203949 ]
 [ 109.78298187]
 [ 108.18812561]
 [ 111.71376801]
 [  94.24481964]
 [ 109.06661987]
 [ 141.13088989]
 [ 108.96720886]]
DEBUG:root:training time = %d0.221792
INFO:root:frame =14289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root:frame =14290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.887045
DEBUG:root: dqn, choose action rondomly, need time 0.000179000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:frame =14293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =14294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.887013333333
INFO:root:dqn select action Tensor("ArgMax_214:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014787
INFO:root:action choosen by dqn [4]
INFO:root:frame =14296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000387191772461
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 110.15293121]
 [ 103.25761414]
 [ 117.04185486]
 [ 113.23589325]
 [ 140.86346436]
 [ 105.64386749]
 [ 136.54450989]
 [ 108.67209625]
 [ 109.02870178]
 [ 132.40235901]
 [ 107.87220001]
 [ 113.3586731 ]
 [ 109.04686737]
 [ 113.51599121]
 [ 109.66086578]
 [ 106.93477631]]
DEBUG:root:training time = %d0.197747
INFO:root:frame =14297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000377178192139
INFO:root:frame =14298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000314950942993
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.886981666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =14301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444173812866
INFO:root:frame =14302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.88695
DEBUG:root: dqn, choose action rondomly, need time 0.00023200000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 111.59090424]
 [ 131.78889465]
 [ 109.90164185]
 [ 132.06616211]
 [ 115.85203552]
 [ 124.61891937]
 [ 113.3768692 ]
 [ 111.5080719 ]
 [ 129.8238678 ]
 [ 117.59088898]
 [ 110.17567444]
 [ 107.90833282]
 [ 110.68975067]
 [ 105.56765747]
 [ 109.24740601]
 [ 109.74365234]]
DEBUG:root:training time = %d0.191127
INFO:root:frame =14305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =14306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000250101089478
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.886918333333
INFO:root:dqn select action Tensor("ArgMax_215:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00775900000002
INFO:root:action choosen by dqn [4]
INFO:root:frame =14308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000172138214111
INFO:root:frame =14309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =14310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000261068344116
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:random_action_porb = 0.886886666667
DEBUG:root: dqn, choose action rondomly, need time 0.000202999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:training error  = [[ 113.98599243]
 [ 107.12136078]
 [ 108.89682007]
 [ 112.31937408]
 [ 110.94740295]
 [ 113.54070282]
 [ 109.595047  ]
 [ 118.22215271]
 [ 110.16766357]
 [ 115.67932129]
 [ 109.34311676]
 [ 109.13834381]
 [ 118.48709106]
 [ 108.5789032 ]
 [ 106.45815277]
 [ 107.91625977]]
DEBUG:root:training time = %d0.198696
INFO:root:frame =14313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =14314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453233718872
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.886855
INFO:root:dqn select action Tensor("ArgMax_216:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015355
INFO:root:action choosen by dqn [4]
INFO:root:frame =14316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:frame =14317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:frame =14318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.886823333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 112.94186401]
 [ 122.53053284]
 [ 107.30020905]
 [ 110.69007111]
 [ 112.43486786]
 [ 112.32389832]
 [ 113.81272125]
 [ 111.43621826]
 [ 117.88460541]
 [ 115.31428528]
 [  87.61503601]
 [ 110.077034  ]
 [ 105.78694916]
 [ 110.1987381 ]
 [ 127.03741455]
 [ 106.1711731 ]]
DEBUG:root:training time = %d0.225901
INFO:root:frame =14321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =14322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000115156173706
INFO:root:random_action_porb = 0.886791666667
DEBUG:root: dqn, choose action rondomly, need time 0.000190999999973
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root:frame =14325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000556945800781
INFO:root:frame =14326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000474214553833
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:random_action_porb = 0.88676
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 105.45700073]
 [ 109.9800415 ]
 [ 137.13104248]
 [ 103.17142487]
 [  99.98199463]
 [ 110.46575928]
 [ 105.05499268]
 [ 107.34194183]
 [ 110.44138336]
 [ 109.85334015]
 [ 110.40065765]
 [ 108.71950531]
 [ 110.12378693]
 [ 114.27125549]
 [ 111.60347748]
 [ 115.64813995]]
DEBUG:root:training time = %d0.219747
INFO:root:frame =14329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =14330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324964523315
DEBUG:root: save sample needs time = 0.000121831893921
INFO:root:random_action_porb = 0.886728333333
DEBUG:root: dqn, choose action rondomly, need time 0.000193000000024
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174045562744
INFO:root:frame =14333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049901008606
INFO:root:frame =14334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308036804199
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:random_action_porb = 0.886696666667
DEBUG:root: dqn, choose action rondomly, need time 0.000329000000022
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 128.6574707 ]
 [ 111.24075317]
 [ 109.1628952 ]
 [ 110.59056091]
 [ 118.02082825]
 [ 112.51383972]
 [ 115.68260193]
 [ 107.02188873]
 [  98.43058014]
 [ 114.25756073]
 [ 110.99787903]
 [ 112.77198029]
 [ 113.77300262]
 [ 108.00314331]
 [ 109.59792328]
 [ 109.69570923]]
DEBUG:root:training time = %d0.217821
INFO:root:frame =14337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =14338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298976898193
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.886665
DEBUG:root: dqn, choose action rondomly, need time 0.000186999999983
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000192165374756
INFO:root:frame =14341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000601053237915
INFO:root:frame =14342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:random_action_porb = 0.886633333333
DEBUG:root: dqn, choose action rondomly, need time 0.000582000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 118.57746124]
 [ 114.0615921 ]
 [ 116.29457855]
 [ 108.03644562]
 [ 130.33482361]
 [ 113.042099  ]
 [ 124.97620392]
 [ 122.33637238]
 [ 116.02783203]
 [ 117.8170166 ]
 [ 107.05535889]
 [ 116.70368195]
 [ 119.39936829]
 [ 111.117836  ]
 [ 111.92094421]
 [ 118.57281494]]
DEBUG:root:training time = %d0.222378
INFO:root:frame =14345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =14346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000369787216187
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.886601666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =14349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =14350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:random_action_porb = 0.88657
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 104.60817719]
 [ 112.09664154]
 [ 113.06578827]
 [ 105.41094208]
 [ 108.66668701]
 [ 112.59542847]
 [ 121.76760101]
 [ 112.31775665]
 [ 106.47893524]
 [ 110.55654907]
 [ 112.01361847]
 [ 135.95852661]
 [ 115.68128967]
 [ 114.93740082]
 [ 112.1092453 ]
 [ 120.6078949 ]]
DEBUG:root:training time = %d0.228905
INFO:root:frame =14353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =14354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.886538333333
DEBUG:root: dqn, choose action rondomly, need time 0.000255000000038
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:frame =14357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =14358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000399112701416
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:random_action_porb = 0.886506666667
DEBUG:root: dqn, choose action rondomly, need time 0.000552000000027
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 108.11702728]
 [ 112.05787659]
 [ 117.09468079]
 [ 111.07762909]
 [ 115.83429718]
 [ 131.96307373]
 [ 108.37230682]
 [ 109.77946472]
 [ 111.48583221]
 [ 120.11003876]
 [ 113.34405518]
 [ 122.05401611]
 [ 112.42742157]
 [ 110.08824158]
 [ 114.22167969]
 [ 118.61069489]]
DEBUG:root:training time = %d0.198856
INFO:root:frame =14361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =14362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.886475
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =14365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =14366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.886443333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:training error  = [[ 113.04924011]
 [ 116.51320648]
 [ 112.09632111]
 [ 119.34335327]
 [ 109.12176514]
 [ 116.57118988]
 [ 110.81790161]
 [ 112.84523773]
 [ 109.16481018]
 [ 117.67826843]
 [ 115.74169159]
 [ 110.75911713]
 [ 110.46992493]
 [ 110.46992493]
 [ 116.82998657]
 [ 102.94433594]]
DEBUG:root:training time = %d0.221509
INFO:root:frame =14369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =14370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000115156173706
INFO:root:random_action_porb = 0.886411666667
DEBUG:root: dqn, choose action rondomly, need time 0.000188999999978
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000179052352905
INFO:root:frame =14373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =14374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000191211700439
INFO:root:random_action_porb = 0.88638
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000021
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 113.52574921]
 [ 118.62000275]
 [ 118.41268921]
 [ 112.19876862]
 [ 111.14582825]
 [ 118.29217529]
 [ 118.2224884 ]
 [ 106.45279694]
 [ 133.23765564]
 [ 109.37599182]
 [ 119.51878357]
 [ 117.90945435]
 [ 102.69306183]
 [ 111.95355225]
 [ 112.60935211]
 [ 114.03747559]]
DEBUG:root:training time = %d0.247938
INFO:root:frame =14377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =14378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475168228149
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.886348333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =14381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427961349487
INFO:root:frame =14382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.886316666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 116.12220001]
 [ 119.20337677]
 [ 124.73818207]
 [ 135.9037323 ]
 [ 115.53133392]
 [ 115.57332611]
 [ 115.91576385]
 [  93.260849  ]
 [ 108.74209595]
 [ 114.0417099 ]
 [ 122.26212311]
 [ 116.09951019]
 [ 111.08181   ]
 [ 117.54091644]
 [ 110.97151184]
 [ 115.57332611]]
DEBUG:root:training time = %d0.231012
INFO:root:frame =14385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =14386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000305891036987
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.886285
INFO:root:dqn select action Tensor("ArgMax_217:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00795299999999
INFO:root:action choosen by dqn [4]
INFO:root:frame =14388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:frame =14389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =14390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308990478516
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:random_action_porb = 0.886253333333
DEBUG:root: dqn, choose action rondomly, need time 0.000334000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000346899032593
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 113.72483063]
 [ 115.59563446]
 [ 113.70302582]
 [ 118.84313202]
 [ 114.77779388]
 [ 140.47291565]
 [ 115.87601471]
 [ 118.48144531]
 [ 122.97109985]
 [ 108.25383759]
 [ 112.10827637]
 [ 115.35722351]
 [ 108.64919281]
 [ 108.60307312]
 [ 110.56777954]
 [ 114.33586121]]
DEBUG:root:training time = %d0.221498
INFO:root:frame =14393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =14394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000540971755981
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.886221666667
DEBUG:root: dqn, choose action rondomly, need time 0.000361999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =14397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000498056411743
INFO:root:frame =14398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame = 14399 State into memory, numbers recorded 383 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000644207000732
INFO:root:random_action_porb = 0.88619
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000041
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14400current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 107.41278076]
 [ 115.18160248]
 [ 115.1190567 ]
 [ 131.43179321]
 [ 114.55002594]
 [ 111.72215271]
 [ 110.93004608]
 [ 121.55318451]
 [ 116.93424225]
 [ 133.95794678]
 [ 117.64946747]
 [ 116.0058136 ]
 [ 114.42333221]
 [ 111.88381958]
 [ 110.62747192]
 [ 117.47839355]]
DEBUG:root:training time = %d0.213523
INFO:root:frame =14401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000341176986694
INFO:root:frame =14402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame = 14403 State into memory, numbers recorded 384 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000561952590942
INFO:root:random_action_porb = 0.886158333333
DEBUG:root: dqn, choose action rondomly, need time 0.000218000000018
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14404current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =14405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049614906311
INFO:root:frame =14406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471830368042
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:random_action_porb = 0.886126666667
DEBUG:root: dqn, choose action rondomly, need time 0.000341999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 114.15319824]
 [ 110.80023193]
 [ 121.39139557]
 [ 111.45458221]
 [ 110.83171082]
 [ 118.96392822]
 [ 123.73609161]
 [ 117.1052475 ]
 [ 115.48607635]
 [ 126.16352844]
 [ 113.66886139]
 [ 116.69247437]
 [ 119.87637329]
 [ 108.70996094]
 [ 116.52902222]
 [ 140.4989624 ]]
DEBUG:root:training time = %d0.219882
INFO:root:frame =14409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000363111495972
INFO:root:frame =14410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480175018311
INFO:root:frame = 14411 State into memory, numbers recorded 385 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000607967376709
INFO:root:random_action_porb = 0.886095
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14412current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =14413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =14414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00023889541626
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.886063333333
DEBUG:root: dqn, choose action rondomly, need time 0.000202999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:training error  = [[ 114.96390533]
 [ 127.27004242]
 [ 123.66413116]
 [ 118.32537079]
 [ 116.56328583]
 [ 117.16767883]
 [ 113.87165833]
 [ 112.62975311]
 [ 114.81801605]
 [ 121.05371857]
 [ 114.36457825]
 [ 123.66413116]
 [ 115.07485962]
 [ 120.677948  ]
 [ 113.10180664]
 [ 125.486763  ]]
DEBUG:root:training time = %d0.217011
INFO:root:frame =14417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame =14418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046181678772
INFO:root:frame = 14419 State into memory, numbers recorded 386 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000561952590942
INFO:root:random_action_porb = 0.886031666667
DEBUG:root: dqn, choose action rondomly, need time 0.00028199999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14420current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =14421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =14422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.886
INFO:root:dqn select action Tensor("ArgMax_218:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012192
INFO:root:action choosen by dqn [4]
INFO:root:frame =14424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 119.21603394]
 [ 113.30410004]
 [ 116.21133423]
 [ 141.89326477]
 [ 136.33099365]
 [ 118.30014038]
 [ 111.26554108]
 [ 114.81997681]
 [ 116.69841003]
 [ 121.39745331]
 [ 118.95860291]
 [ 117.66304016]
 [ 122.91864777]
 [ 115.53494263]
 [ 120.29941559]
 [ 111.83475494]]
DEBUG:root:training time = %d0.203477
INFO:root:frame =14425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =14426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root: ememy has been killed for 29 times 
INFO:root:enemies_left [0]
INFO:root:frame = 14427 State into memory, numbers recorded 387 action = [4], reward = 1
DEBUG:root: save sample needs time = 0.000510931015015
INFO:root:random_action_porb = 0.885968333333
DEBUG:root: dqn, choose action rondomly, need time 0.000246000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14428current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =14429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000380039215088
INFO:root:frame =14430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame = 14431 State into memory, numbers recorded 388 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000545978546143
INFO:root:random_action_porb = 0.885936666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000022
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14432current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000365972518921
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 145.7709198 ]
 [ 115.69901276]
 [ 122.55148315]
 [ 113.48542786]
 [ 110.39231873]
 [ 122.05738068]
 [ 111.33154297]
 [ 112.38277435]
 [ 120.08395386]
 [ 117.20698547]
 [ 103.41706848]
 [ 118.14120483]
 [ 120.08395386]
 [ 107.77301025]
 [ 115.74793243]
 [ 127.22219086]]
DEBUG:root:training time = %d0.223847
INFO:root:frame =14433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =14434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446796417236
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.885905
DEBUG:root: dqn, choose action rondomly, need time 0.000275999999985
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =14437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame =14438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000507116317749
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.885873333333
DEBUG:root: dqn, choose action rondomly, need time 0.000398000000018
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000405073165894
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 120.59482574]
 [ 121.70530701]
 [ 118.07719421]
 [ 111.39048004]
 [ 108.67655182]
 [ 105.99389648]
 [ 135.64842224]
 [ 117.75740051]
 [ 115.14263153]
 [ 114.89749146]
 [ 125.77477264]
 [ 113.09597015]
 [ 118.53359985]
 [ 110.61752319]
 [ 141.9234314 ]
 [ 146.02709961]]
DEBUG:root:training time = %d0.220425
INFO:root:frame =14441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =14442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000607013702393
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:random_action_porb = 0.885841666667
DEBUG:root: dqn, choose action rondomly, need time 0.000550999999973
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =14445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000492095947266
INFO:root:frame =14446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000651836395264
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.88581
DEBUG:root: dqn, choose action rondomly, need time 0.000524000000041
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 118.88372803]
 [ 135.79275513]
 [ 118.33599091]
 [ 115.04277802]
 [ 116.47499847]
 [ 117.27737427]
 [ 111.52869415]
 [ 115.58513641]
 [ 116.94876862]
 [ 122.77455902]
 [ 112.4827652 ]
 [ 118.41734314]
 [ 118.88372803]
 [ 117.74250031]
 [ 114.36588287]
 [ 110.98855591]]
DEBUG:root:training time = %d0.246174
INFO:root:frame =14449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =14450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000278234481812
INFO:root:random_action_porb = 0.885778333333
DEBUG:root: dqn, choose action rondomly, need time 0.000165000000038
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:frame =14453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =14454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247001647949
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:random_action_porb = 0.885746666667
DEBUG:root: dqn, choose action rondomly, need time 0.000164999999981
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 149.43621826]
 [ 113.16088867]
 [ 145.9463501 ]
 [ 114.11602783]
 [ 109.81368256]
 [ 124.1516037 ]
 [ 117.83325195]
 [ 128.19161987]
 [ 119.86935425]
 [  98.29196167]
 [ 119.04815674]
 [ 120.0458374 ]
 [ 124.34243774]
 [ 110.79059601]
 [ 117.30645752]
 [ 124.93253326]]
DEBUG:root:training time = %d0.179732
INFO:root:frame =14457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =14458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000333786010742
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:random_action_porb = 0.885715
DEBUG:root: dqn, choose action rondomly, need time 0.000269000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =14461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =14462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:frame = 14463 State into memory, numbers recorded 389 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:random_action_porb = 0.885683333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14464current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 110.12378693]
 [ 118.97325134]
 [ 116.00712585]
 [ 108.23287964]
 [ 110.90208435]
 [ 123.39482117]
 [ 124.13630676]
 [ 114.76766205]
 [ 114.36784363]
 [ 114.64836121]
 [ 137.88505554]
 [ 143.49397278]
 [ 138.74572754]
 [ 123.32059479]
 [ 116.98540497]
 [ 120.43401337]]
DEBUG:root:training time = %d0.173838
INFO:root:frame =14465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =14466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031304359436
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:random_action_porb = 0.885651666667
DEBUG:root: dqn, choose action rondomly, need time 0.000247999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180006027222
INFO:root:frame =14469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000413179397583
INFO:root:frame =14470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234842300415
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.88562
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000147104263306
INFO:root:training error  = [[ 114.18906403]
 [ 112.95970154]
 [ 121.72786713]
 [ 130.20211792]
 [ 114.20569611]
 [ 119.58551788]
 [ 120.53617859]
 [ 118.37284851]
 [ 126.33361053]
 [ 115.10825348]
 [ 114.27745819]
 [ 126.33361053]
 [ 117.86605072]
 [ 129.02119446]
 [ 112.82448578]
 [ 120.78625488]]
DEBUG:root:training time = %d0.193823
INFO:root:frame =14473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =14474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000403881072998
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.885588333333
DEBUG:root: dqn, choose action rondomly, need time 0.000351000000023
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:frame =14477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =14478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235795974731
DEBUG:root: save sample needs time = 0.000141143798828
INFO:root:random_action_porb = 0.885556666667
DEBUG:root: dqn, choose action rondomly, need time 0.000321000000042
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  96.98595428]
 [ 143.37263489]
 [ 113.56769562]
 [ 118.60005951]
 [ 113.95211029]
 [ 118.85511017]
 [ 115.09548187]
 [ 114.50626373]
 [ 119.75544739]
 [ 115.87141418]
 [ 117.06265259]
 [ 118.67285919]
 [ 115.26743317]
 [ 122.30565643]
 [ 116.71819305]
 [ 122.13831329]]
DEBUG:root:training time = %d0.201276
INFO:root:frame =14481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =14482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000327110290527
DEBUG:root: save sample needs time = 0.000108003616333
INFO:root:random_action_porb = 0.885525
DEBUG:root: dqn, choose action rondomly, need time 0.000153000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174999237061
INFO:root:frame =14485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =14486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.885493333333
DEBUG:root: dqn, choose action rondomly, need time 0.000193999999965
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 117.43639374]
 [ 123.34024811]
 [ 126.03536224]
 [ 121.59490967]
 [ 113.55078888]
 [ 122.67617798]
 [ 116.67302704]
 [ 143.23052979]
 [ 118.43959045]
 [ 112.47143555]
 [ 115.67440033]
 [ 115.59333801]
 [ 114.69051361]
 [ 141.53541565]
 [ 117.23573303]
 [ 130.08409119]]
DEBUG:root:training time = %d0.188424
INFO:root:frame =14489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =14490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000246047973633
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:random_action_porb = 0.885461666667
DEBUG:root: dqn, choose action rondomly, need time 0.000229000000047
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:frame =14493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000383138656616
INFO:root:frame =14494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000256061553955
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.88543
DEBUG:root: dqn, choose action rondomly, need time 0.000163999999984
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 114.3786087 ]
 [ 142.31599426]
 [ 114.48601532]
 [ 115.67932129]
 [ 116.20541382]
 [ 117.59849548]
 [ 115.97425842]
 [ 117.82199097]
 [ 119.98899841]
 [ 112.51675415]
 [ 116.61402893]
 [ 117.82199097]
 [ 117.37488556]
 [ 117.80443573]
 [ 115.69343567]
 [ 117.23771667]]
DEBUG:root:training time = %d0.190315
INFO:root:frame =14497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =14498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00100302696228
DEBUG:root: save sample needs time = 0.000175952911377
INFO:root:random_action_porb = 0.885398333333
DEBUG:root: dqn, choose action rondomly, need time 0.000169999999969
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000157833099365
INFO:root:frame =14501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:frame =14502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:random_action_porb = 0.885366666667
DEBUG:root: dqn, choose action rondomly, need time 0.000239000000022
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:training error  = [[ 115.6931076 ]
 [ 116.80294037]
 [ 117.2829895 ]
 [ 116.24324799]
 [ 111.70796204]
 [ 117.2829895 ]
 [ 122.25234222]
 [ 112.79402161]
 [ 121.93603516]
 [ 111.83378601]
 [ 114.44552612]
 [ 114.73627472]
 [ 121.93603516]
 [ 125.01236725]
 [ 120.08261871]
 [ 122.29890442]]
DEBUG:root:training time = %d0.189638
INFO:root:frame =14505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =14506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411987304688
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root:random_action_porb = 0.885335
DEBUG:root: dqn, choose action rondomly, need time 0.000209999999981
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:frame =14509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =14510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame = 14511 State into memory, numbers recorded 390 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:random_action_porb = 0.885303333333
DEBUG:root: dqn, choose action rondomly, need time 0.00018399999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14512current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 128.74609375]
 [ 150.90332031]
 [ 114.86019897]
 [ 115.8990097 ]
 [ 118.0609436 ]
 [ 120.48626709]
 [ 137.62609863]
 [ 118.35723877]
 [ 111.61573029]
 [ 115.29299164]
 [ 110.52093506]
 [ 118.93996429]
 [ 129.34550476]
 [ 117.12242126]
 [ 122.11133575]
 [ 122.88414001]]
DEBUG:root:training time = %d0.185151
INFO:root:frame =14513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =14514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000142812728882
INFO:root:random_action_porb = 0.885271666667
DEBUG:root: dqn, choose action rondomly, need time 0.000194000000022
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =14517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =14518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249862670898
DEBUG:root: save sample needs time = 0.000108003616333
INFO:root:random_action_porb = 0.88524
DEBUG:root: dqn, choose action rondomly, need time 0.000214999999969
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:training error  = [[ 124.6758194 ]
 [ 124.26010132]
 [ 119.26668549]
 [ 117.06859589]
 [ 122.03782654]
 [ 132.50842285]
 [ 125.11611938]
 [ 118.82317352]
 [ 115.5172348 ]
 [ 115.62123108]
 [ 118.68648529]
 [ 125.55924988]
 [ 119.18904877]
 [ 116.83460236]
 [ 123.512146  ]
 [ 117.96712494]]
DEBUG:root:training time = %d0.194813
INFO:root:frame =14521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =14522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265836715698
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.885208333333
DEBUG:root: dqn, choose action rondomly, need time 0.00023699999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00018310546875
INFO:root:frame =14525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =14526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000309944152832
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.885176666667
DEBUG:root: dqn, choose action rondomly, need time 0.000199000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 124.05267334]
 [ 117.22846222]
 [ 140.79899597]
 [ 142.94943237]
 [ 118.03872681]
 [ 125.53223419]
 [ 119.06946564]
 [ 117.91608429]
 [ 143.52723694]
 [ 119.99802399]
 [ 125.66390991]
 [ 116.59294128]
 [ 127.59146118]
 [ 119.8894043 ]
 [ 116.69445801]
 [ 115.72823334]]
DEBUG:root:training time = %d0.184147
INFO:root:frame =14529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =14530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:random_action_porb = 0.885145
DEBUG:root: dqn, choose action rondomly, need time 0.000202000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =14533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000357866287231
INFO:root:frame =14534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000519990921021
DEBUG:root: save sample needs time = 9.58442687988e-05
INFO:root:random_action_porb = 0.885113333333
DEBUG:root: dqn, choose action rondomly, need time 0.000252999999987
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185012817383
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 120.13847351]
 [ 117.8352356 ]
 [ 121.68948364]
 [ 122.09380341]
 [ 114.42920685]
 [ 140.23646545]
 [ 125.51377106]
 [ 122.20105743]
 [ 140.29067993]
 [ 120.83455658]
 [ 125.39653015]
 [ 125.0249939 ]
 [ 141.43559265]
 [ 119.81423187]
 [ 125.0249939 ]
 [ 125.22981262]]
DEBUG:root:training time = %d0.188505
INFO:root:frame =14537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =14538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000256061553955
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.885081666667
DEBUG:root: dqn, choose action rondomly, need time 0.000254999999981
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root:frame =14541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =14542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000284910202026
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.88505
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999968
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 140.16455078]
 [ 118.94062805]
 [ 112.43907166]
 [ 116.45688629]
 [ 113.69717407]
 [ 115.49951935]
 [ 118.3921051 ]
 [ 119.62156677]
 [ 119.39503479]
 [ 119.27201843]
 [ 116.07912445]
 [ 113.86807251]
 [ 103.467659  ]
 [ 115.7321701 ]
 [ 121.48657227]
 [ 117.06364441]]
DEBUG:root:training time = %d0.189653
INFO:root:frame =14545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame =14546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 0.000157833099365
INFO:root:random_action_porb = 0.885018333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =14549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =14550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000258922576904
DEBUG:root: save sample needs time = 9.58442687988e-05
INFO:root:random_action_porb = 0.884986666667
DEBUG:root: dqn, choose action rondomly, need time 0.000177000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:training error  = [[ 120.11238098]
 [ 117.30480194]
 [ 114.26147461]
 [ 119.12375641]
 [ 117.79151154]
 [ 121.33424377]
 [ 125.40370178]
 [ 127.89430237]
 [ 123.03404999]
 [ 125.32170105]
 [ 117.17131042]
 [ 120.67593384]
 [ 117.30480194]
 [ 131.1817627 ]
 [ 118.12926483]
 [ 118.88006592]]
DEBUG:root:training time = %d0.188648
INFO:root:frame =14553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =14554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000312089920044
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.884955
DEBUG:root: dqn, choose action rondomly, need time 0.000180999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000156164169312
INFO:root:frame =14557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =14558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000253200531006
DEBUG:root: save sample needs time = 0.000130891799927
INFO:root:random_action_porb = 0.884923333333
DEBUG:root: dqn, choose action rondomly, need time 0.000241000000017
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 120.68498993]
 [ 119.13475037]
 [ 122.93725586]
 [ 113.74403381]
 [ 122.16900635]
 [ 151.01506042]
 [ 122.83035278]
 [ 122.66941833]
 [ 116.40452576]
 [ 125.6714325 ]
 [ 122.0486145 ]
 [ 117.42183685]
 [ 118.68848419]
 [ 120.94293976]
 [ 126.80671692]
 [ 118.33798218]]
DEBUG:root:training time = %d0.190121
INFO:root:frame =14561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =14562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000256061553955
DEBUG:root: save sample needs time = 0.000180959701538
INFO:root:random_action_porb = 0.884891666667
DEBUG:root: dqn, choose action rondomly, need time 0.000213000000031
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =14565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =14566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509023666382
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.88486
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 122.97211456]
 [ 119.28535461]
 [ 132.87402344]
 [ 122.89767456]
 [ 140.98410034]
 [ 141.22807312]
 [ 118.60837555]
 [ 122.44676971]
 [ 117.8875885 ]
 [ 127.77146912]
 [ 116.66313934]
 [ 116.04394531]
 [ 126.85070801]
 [ 123.80297089]
 [ 123.40058136]
 [ 118.58211517]]
DEBUG:root:training time = %d0.228065
INFO:root:frame =14569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =14570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000582933425903
DEBUG:root: save sample needs time = 0.000255823135376
INFO:root:random_action_porb = 0.884828333333
DEBUG:root: dqn, choose action rondomly, need time 0.000407999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =14573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000688076019287
INFO:root:frame =14574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.884796666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000386953353882
INFO:root:training error  = [[ 123.36668396]
 [ 125.77614594]
 [ 119.49108887]
 [ 124.5398941 ]
 [ 122.06008148]
 [ 117.5812912 ]
 [ 120.93622589]
 [ 127.47325134]
 [ 128.12875366]
 [ 126.06517029]
 [ 130.24320984]
 [ 115.96308136]
 [ 117.02765656]
 [ 127.8853302 ]
 [ 123.53791809]
 [ 125.09700012]]
DEBUG:root:training time = %d0.22495
INFO:root:frame =14577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =14578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000601053237915
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:random_action_porb = 0.884765
DEBUG:root: dqn, choose action rondomly, need time 0.000242999999955
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000480890274048
INFO:root:frame =14581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465154647827
INFO:root:frame =14582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031590461731
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:random_action_porb = 0.884733333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999964
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294208526611
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 150.58033752]
 [ 126.30685425]
 [ 123.6427536 ]
 [ 126.24101257]
 [ 117.88360596]
 [ 131.12619019]
 [ 123.97553253]
 [ 157.53053284]
 [ 119.54380798]
 [ 117.93463898]
 [ 120.46247864]
 [ 115.4096756 ]
 [ 125.85144806]
 [ 125.26670074]
 [ 117.78157806]
 [ 121.12759399]]
DEBUG:root:training time = %d0.212523
INFO:root:frame =14585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =14586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000329971313477
DEBUG:root: save sample needs time = 0.000173091888428
INFO:root:random_action_porb = 0.884701666667
DEBUG:root: dqn, choose action rondomly, need time 0.000374000000022
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =14589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =14590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000334978103638
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.88467
DEBUG:root: dqn, choose action rondomly, need time 0.000577000000021
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:training error  = [[ 123.42431641]
 [ 120.2201004 ]
 [ 127.51528931]
 [ 127.54458618]
 [ 121.88043976]
 [ 119.93986511]
 [ 122.84490204]
 [ 121.3671875 ]
 [ 116.66907501]
 [ 132.19490051]
 [ 116.66907501]
 [ 115.13117218]
 [ 124.83226776]
 [ 122.5393219 ]
 [ 114.46511841]
 [ 120.47353363]]
DEBUG:root:training time = %d0.243914
INFO:root:frame =14593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000401973724365
INFO:root:frame =14594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509023666382
DEBUG:root: save sample needs time = 0.000235795974731
INFO:root:random_action_porb = 0.884638333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =14597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =14598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:random_action_porb = 0.884606666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 131.41955566]
 [ 107.89660645]
 [ 118.26330566]
 [ 143.70022583]
 [ 118.85511017]
 [ 130.74032593]
 [ 114.30747223]
 [ 120.99664307]
 [ 116.47829437]
 [ 132.50701904]
 [ 123.44499969]
 [ 149.21098328]
 [ 118.85511017]
 [ 129.66223145]
 [ 125.58968353]
 [ 122.08537292]]
DEBUG:root:training time = %d0.221169
INFO:root:frame =14601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =14602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.884575
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =14605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =14606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:random_action_porb = 0.884543333333
DEBUG:root: dqn, choose action rondomly, need time 0.000230000000045
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000217199325562
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 121.66255951]
 [ 125.07106018]
 [ 147.95661926]
 [ 126.04906464]
 [ 118.36985779]
 [ 121.38366699]
 [ 130.21186829]
 [ 148.43177795]
 [ 120.79330444]
 [ 125.40917206]
 [ 128.70455933]
 [ 105.20518494]
 [ 125.10314941]
 [ 132.07002258]
 [ 117.15314484]
 [ 121.67298889]]
DEBUG:root:training time = %d0.217509
INFO:root:frame =14609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =14610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.884511666667
DEBUG:root: dqn, choose action rondomly, need time 0.000476999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =14613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000582933425903
INFO:root:frame =14614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000643014907837
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.88448
DEBUG:root: dqn, choose action rondomly, need time 0.000271999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000269174575806
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 123.2023468 ]
 [ 124.34890747]
 [ 123.82504272]
 [ 115.53887939]
 [ 126.84796143]
 [ 119.42404938]
 [ 122.33435059]
 [ 127.58628845]
 [ 124.91582489]
 [ 117.51644135]
 [ 144.76235962]
 [ 121.78679657]
 [ 112.86533356]
 [ 121.93637848]
 [ 125.87404633]
 [ 131.04302979]]
DEBUG:root:training time = %d0.214393
INFO:root:frame =14617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =14618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049090385437
INFO:root:frame = 14619 State into memory, numbers recorded 391 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000547885894775
INFO:root:random_action_porb = 0.884448333333
DEBUG:root: dqn, choose action rondomly, need time 0.00051000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14620current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000360012054443
INFO:root:frame =14621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =14622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.884416666667
DEBUG:root: dqn, choose action rondomly, need time 0.000334000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:training error  = [[ 134.93386841]
 [ 121.3671875 ]
 [ 122.68834686]
 [ 119.97595978]
 [ 125.92369843]
 [ 126.13645172]
 [ 125.03181458]
 [ 122.08267212]
 [ 119.11476135]
 [ 134.69044495]
 [ 129.17375183]
 [ 119.87837219]
 [ 121.3671875 ]
 [ 132.06791687]
 [ 122.82325745]
 [ 119.86701202]]
DEBUG:root:training time = %d0.216923
INFO:root:frame =14625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =14626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000513076782227
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.884385
DEBUG:root: dqn, choose action rondomly, need time 0.000304000000028
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =14629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000648021697998
INFO:root:frame =14630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000359058380127
DEBUG:root: save sample needs time = 0.000156879425049
INFO:root:random_action_porb = 0.884353333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 134.36515808]
 [ 119.90611267]
 [ 121.28651428]
 [ 121.89694977]
 [ 122.99952698]
 [ 110.54306793]
 [ 133.66459656]
 [ 134.37329102]
 [ 123.43753815]
 [ 123.23384857]
 [ 128.49067688]
 [ 127.38919067]
 [ 125.95040894]
 [ 131.97463989]
 [ 121.52223206]
 [ 120.1411438 ]]
DEBUG:root:training time = %d0.225846
INFO:root:frame =14633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =14634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.884321666667
DEBUG:root: dqn, choose action rondomly, need time 0.000417000000027
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365972518921
INFO:root:frame =14637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =14638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.88429
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999983
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 117.45954132]
 [ 130.05763245]
 [ 116.90652466]
 [ 125.38969421]
 [ 140.48629761]
 [ 126.16387177]
 [ 125.53907013]
 [ 124.29003906]
 [ 124.62709045]
 [ 121.72248077]
 [ 123.73744965]
 [ 125.81002808]
 [ 128.99623108]
 [ 129.03921509]
 [ 123.65293121]
 [ 120.07324982]]
DEBUG:root:training time = %d0.219868
INFO:root:frame =14641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =14642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.884258333333
DEBUG:root: dqn, choose action rondomly, need time 0.000323999999978
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =14645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =14646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.884226666667
DEBUG:root: dqn, choose action rondomly, need time 0.000324999999975
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:training error  = [[ 120.46884918]
 [ 125.61978149]
 [ 123.80297089]
 [ 123.66005707]
 [ 122.3498764 ]
 [ 123.27518463]
 [ 127.96092224]
 [ 120.72187042]
 [ 122.42887878]
 [ 122.37451935]
 [ 126.47325134]
 [ 116.23008728]
 [ 126.84967804]
 [ 119.15106964]
 [ 118.66421509]
 [ 128.23448181]]
DEBUG:root:training time = %d0.227402
INFO:root:frame =14649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =14650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000284910202026
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.884195
DEBUG:root: dqn, choose action rondomly, need time 0.000173000000018
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =14653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000603914260864
INFO:root:frame =14654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476121902466
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:random_action_porb = 0.884163333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 113.03626251]
 [ 121.95120239]
 [ 113.03626251]
 [ 119.53679657]
 [ 122.7241745 ]
 [ 129.10369873]
 [ 124.60529327]
 [ 119.44773102]
 [ 133.10173035]
 [ 124.78181458]
 [ 125.73542023]
 [ 126.01789093]
 [ 123.25383759]
 [ 150.42085266]
 [ 122.53627777]
 [ 122.65522003]]
DEBUG:root:training time = %d0.231938
INFO:root:frame =14657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root:frame =14658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000371932983398
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:random_action_porb = 0.884131666667
DEBUG:root: dqn, choose action rondomly, need time 0.000325000000032
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =14661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488996505737
INFO:root:frame =14662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00048303604126
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.8841
DEBUG:root: dqn, choose action rondomly, need time 0.000303999999971
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:training error  = [[ 134.18444824]
 [ 117.62596893]
 [ 120.20872498]
 [ 125.5872879 ]
 [ 125.17620087]
 [ 136.08773804]
 [ 127.62869263]
 [ 124.61653137]
 [ 133.44274902]
 [ 121.15984344]
 [ 125.5872879 ]
 [ 120.40052795]
 [ 121.05606842]
 [ 128.25382996]
 [ 124.16555023]
 [ 129.10162354]]
DEBUG:root:training time = %d0.23613
INFO:root:frame =14665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000370979309082
INFO:root:frame =14666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.884068333333
INFO:root:dqn select action Tensor("ArgMax_219:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00883900000002
INFO:root:action choosen by dqn [4]
INFO:root:frame =14668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =14669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =14670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame = 14671 State into memory, numbers recorded 392 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00129389762878
INFO:root:random_action_porb = 0.884036666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14672current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:training error  = [[ 129.25146484]
 [ 128.51974487]
 [ 126.45849609]
 [ 127.64800262]
 [ 130.02632141]
 [ 129.18624878]
 [ 130.30311584]
 [ 134.3994751 ]
 [ 125.7956543 ]
 [ 123.79142761]
 [ 122.87703705]
 [ 131.30342102]
 [ 129.4367981 ]
 [ 141.1000824 ]
 [ 124.12304688]
 [ 133.27359009]]
DEBUG:root:training time = %d0.220858
INFO:root:frame =14673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root:frame =14674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.884005
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =14677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =14678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453233718872
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.883973333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 128.52250671]
 [ 122.54776764]
 [ 111.27970886]
 [ 122.0850296 ]
 [ 118.81053162]
 [ 115.04866791]
 [ 126.21872711]
 [ 116.22416687]
 [ 133.13728333]
 [ 127.38712311]
 [ 158.03616333]
 [ 124.90558624]
 [ 124.2910614 ]
 [ 138.55383301]
 [ 117.28926849]
 [ 125.35757446]]
DEBUG:root:training time = %d0.232907
INFO:root:frame =14681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =14682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.883941666667
DEBUG:root: dqn, choose action rondomly, need time 0.00032699999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root:frame =14685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000530004501343
INFO:root:frame =14686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000296115875244
DEBUG:root: save sample needs time = 0.000229835510254
INFO:root:random_action_porb = 0.88391
DEBUG:root: dqn, choose action rondomly, need time 0.000373000000025
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000498056411743
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 126.90020752]
 [ 124.21792603]
 [ 120.62264252]
 [ 129.6834259 ]
 [ 156.14854431]
 [ 128.34162903]
 [ 141.36155701]
 [ 131.73425293]
 [ 133.90391541]
 [ 121.78848267]
 [ 129.70880127]
 [ 154.70735168]
 [ 123.93476105]
 [ 131.26670837]
 [ 129.27227783]
 [ 138.5430603 ]]
DEBUG:root:training time = %d0.244527
INFO:root:frame =14689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =14690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000530958175659
INFO:root:frame = 14691 State into memory, numbers recorded 393 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000627994537354
INFO:root:random_action_porb = 0.883878333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999956
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14692current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =14693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =14694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424146652222
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.883846666667
INFO:root:dqn select action Tensor("ArgMax_220:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014226
INFO:root:action choosen by dqn [4]
INFO:root:frame =14696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000166177749634
INFO:root:training error  = [[ 122.50283813]
 [ 125.01407623]
 [ 129.24382019]
 [ 122.10054779]
 [ 129.00836182]
 [ 130.43518066]
 [ 120.68331146]
 [ 121.13565826]
 [ 126.98273468]
 [ 132.10264587]
 [ 127.62386322]
 [ 127.22528839]
 [ 119.44739532]
 [ 124.15330505]
 [ 119.81523132]
 [ 126.28181458]]
DEBUG:root:training time = %d0.231578
INFO:root:frame =14697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =14698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000280141830444
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.883815
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root:frame =14701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =14702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.883783333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000038
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[ 121.40316772]
 [ 132.51545715]
 [ 122.35223389]
 [ 134.89346313]
 [ 122.91695404]
 [ 123.78056335]
 [ 119.50576782]
 [ 125.71968079]
 [ 123.66956329]
 [ 122.61737061]
 [ 124.58008575]
 [ 130.86911011]
 [ 131.11990356]
 [ 135.8087616 ]
 [ 127.30929565]
 [ 137.64291382]]
DEBUG:root:training time = %d0.231601
INFO:root:frame =14705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =14706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.883751666667
DEBUG:root: dqn, choose action rondomly, need time 0.000336000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =14709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =14710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441789627075
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.88372
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999956
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 128.42703247]
 [ 134.28486633]
 [ 125.00281525]
 [ 145.13050842]
 [ 113.7075882 ]
 [ 128.42703247]
 [ 136.56591797]
 [ 153.87869263]
 [ 131.39471436]
 [ 121.23845673]
 [ 147.09222412]
 [ 125.32818604]
 [ 125.51958466]
 [ 142.83634949]
 [ 121.43410492]
 [ 137.516922  ]]
DEBUG:root:training time = %d0.237704
INFO:root:frame =14713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =14714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.883688333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =14717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046181678772
INFO:root:frame =14718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.883656666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:training error  = [[ 132.35214233]
 [ 133.570755  ]
 [ 123.37041473]
 [ 141.04498291]
 [ 128.83094788]
 [ 128.17987061]
 [ 120.52177429]
 [ 127.54665375]
 [ 123.07230377]
 [ 131.28733826]
 [ 123.44940948]
 [ 119.01752472]
 [ 125.63654327]
 [ 128.68135071]
 [ 134.33650208]
 [ 128.7454071 ]]
DEBUG:root:training time = %d0.216851
INFO:root:frame =14721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =14722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000387907028198
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.883625
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =14725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =14726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480175018311
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.883593333333
DEBUG:root: dqn, choose action rondomly, need time 0.000364999999988
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 124.07375336]
 [ 121.6834259 ]
 [ 132.91061401]
 [ 106.23313141]
 [ 123.24671936]
 [ 126.60713959]
 [ 129.46665955]
 [ 125.93807983]
 [ 128.751297  ]
 [ 123.794487  ]
 [ 124.50175476]
 [ 149.0004425 ]
 [ 130.77836609]
 [ 124.07035065]
 [ 145.40158081]
 [ 127.31446075]]
DEBUG:root:training time = %d0.221811
INFO:root:frame =14729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =14730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240087509155
DEBUG:root: save sample needs time = 9.58442687988e-05
INFO:root:random_action_porb = 0.883561666667
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000026
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =14733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000583171844482
INFO:root:frame =14734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000524997711182
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.88353
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 128.15155029]
 [ 131.47973633]
 [ 124.17778778]
 [ 130.40834045]
 [ 120.84429169]
 [ 136.2280426 ]
 [ 160.73733521]
 [ 124.69285583]
 [ 128.98202515]
 [ 138.16902161]
 [ 130.77033997]
 [ 125.01646423]
 [ 105.97222137]
 [ 122.18048096]
 [ 132.79031372]
 [ 127.67041016]]
DEBUG:root:training time = %d0.234407
INFO:root:frame =14737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =14738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049090385437
INFO:root:frame = 14739 State into memory, numbers recorded 394 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000586986541748
INFO:root:random_action_porb = 0.883498333333
INFO:root:dqn select action Tensor("ArgMax_221:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013682
INFO:root:action choosen by dqn [4]
INFO:root:frame =14740current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000391006469727
INFO:root:frame =14741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =14742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.883466666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 124.91480255]
 [ 126.81565857]
 [ 137.18501282]
 [ 121.75211334]
 [ 129.26083374]
 [ 152.80130005]
 [ 126.33463287]
 [ 128.6065979 ]
 [ 135.63562012]
 [ 132.48524475]
 [ 123.96024323]
 [ 128.42773438]
 [ 126.18992615]
 [ 125.63449097]
 [ 153.04811096]
 [ 127.76284027]]
DEBUG:root:training time = %d0.229494
INFO:root:frame =14745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =14746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.883435
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000047
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =14749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =14750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444173812866
INFO:root:frame = 14751 State into memory, numbers recorded 395 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000540971755981
INFO:root:random_action_porb = 0.883403333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000046
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14752current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:training error  = [[ 125.26089478]
 [ 121.54140472]
 [ 128.51835632]
 [ 131.61973572]
 [ 125.82064056]
 [ 125.71317291]
 [ 122.19261932]
 [ 125.01612091]
 [ 128.47164917]
 [ 130.23728943]
 [ 128.43983459]
 [ 137.96354675]
 [ 126.99373627]
 [ 118.91733551]
 [ 124.78215027]
 [ 124.09380341]]
DEBUG:root:training time = %d0.230281
INFO:root:frame =14753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =14754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049090385437
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.883371666667
DEBUG:root: dqn, choose action rondomly, need time 0.000526999999977
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root:frame =14757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =14758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.88334
DEBUG:root: dqn, choose action rondomly, need time 0.000516000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 158.07913208]
 [ 119.15473175]
 [ 131.55078125]
 [ 157.26252747]
 [ 118.94329071]
 [ 126.45540619]
 [ 124.14514923]
 [ 128.95429993]
 [ 126.76823425]
 [ 132.9211731 ]
 [ 128.96122742]
 [ 122.541008  ]
 [ 129.85272217]
 [ 129.72096252]
 [ 127.28037262]
 [ 113.98077393]]
DEBUG:root:training time = %d0.22759
INFO:root:frame =14761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =14762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.883308333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =14765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =14766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:random_action_porb = 0.883276666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 128.94113159]
 [ 129.59378052]
 [ 124.67173004]
 [ 131.52838135]
 [ 126.80947113]
 [ 124.97415161]
 [ 126.92290497]
 [ 133.08622742]
 [ 125.80797577]
 [ 101.17192841]
 [ 133.40397644]
 [ 135.68182373]
 [ 127.94779968]
 [ 135.70422363]
 [ 132.17175293]
 [ 122.53019714]]
DEBUG:root:training time = %d0.255273
INFO:root:frame =14769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =14770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.883245
DEBUG:root: dqn, choose action rondomly, need time 0.000320999999985
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root:frame =14773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =14774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.883213333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000315189361572
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 138.17404175]
 [ 165.2195282 ]
 [ 126.20741272]
 [ 126.1926651 ]
 [ 131.40870667]
 [ 134.86830139]
 [ 131.02381897]
 [ 140.10025024]
 [ 124.42072296]
 [ 127.99751282]
 [ 133.84776306]
 [ 130.86772156]
 [ 127.73179626]
 [ 126.20741272]
 [ 139.93052673]
 [ 135.32730103]]
DEBUG:root:training time = %d0.223145
INFO:root:frame =14777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =14778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269174575806
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root:random_action_porb = 0.883181666667
INFO:root:dqn select action Tensor("ArgMax_222:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011491
INFO:root:action choosen by dqn [4]
INFO:root:frame =14780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:frame =14781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285148620605
INFO:root:frame =14782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000596046447754
DEBUG:root: save sample needs time = 0.000130891799927
INFO:root:random_action_porb = 0.88315
DEBUG:root: dqn, choose action rondomly, need time 0.000175000000013
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 129.06938171]
 [ 130.02145386]
 [ 122.15518188]
 [ 135.85287476]
 [ 144.03039551]
 [ 125.21786499]
 [ 138.03633118]
 [ 133.75245667]
 [ 141.2436676 ]
 [ 134.25375366]
 [ 117.18716431]
 [ 132.73054504]
 [ 122.15518188]
 [ 132.73054504]
 [ 133.9197998 ]
 [ 138.64653015]]
DEBUG:root:training time = %d0.219724
INFO:root:frame =14785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =14786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame = 14787 State into memory, numbers recorded 396 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000594854354858
INFO:root:random_action_porb = 0.883118333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303999999971
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14788current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000417947769165
INFO:root:frame =14789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root:frame =14790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000507116317749
INFO:root:frame = 14791 State into memory, numbers recorded 397 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000590085983276
INFO:root:random_action_porb = 0.883086666667
DEBUG:root: dqn, choose action rondomly, need time 0.000344000000041
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14792current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 133.1464386 ]
 [ 111.20535278]
 [ 130.97073364]
 [ 129.55764771]
 [ 135.91192627]
 [ 127.99785614]
 [ 127.48324585]
 [ 134.47944641]
 [ 127.38299561]
 [ 129.07249451]
 [ 132.72351074]
 [ 124.26826477]
 [ 135.49882507]
 [ 127.82045746]
 [ 125.93534088]
 [ 131.09089661]]
DEBUG:root:training time = %d0.22368
INFO:root:frame =14793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =14794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root:frame = 14795 State into memory, numbers recorded 398 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000535011291504
INFO:root:random_action_porb = 0.883055
DEBUG:root: dqn, choose action rondomly, need time 0.000336000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14796current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =14797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =14798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.883023333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999964
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:training error  = [[ 121.96063995]
 [ 129.01841736]
 [ 129.9344635 ]
 [ 132.39744568]
 [ 131.28070068]
 [ 126.34046936]
 [ 129.07319641]
 [ 120.11573029]
 [ 125.43548584]
 [ 130.84294128]
 [ 133.15701294]
 [ 124.50106812]
 [ 133.73904419]
 [ 124.20703888]
 [ 126.72425842]
 [ 126.72425842]]
DEBUG:root:training time = %d0.22534
INFO:root:frame =14801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:frame =14802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame = 14803 State into memory, numbers recorded 399 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000588178634644
INFO:root:random_action_porb = 0.882991666667
DEBUG:root: dqn, choose action rondomly, need time 0.000166000000036
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14804current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000147104263306
INFO:root:frame =14805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =14806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000238180160522
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.88296
INFO:root:dqn select action Tensor("ArgMax_223:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012046
INFO:root:action choosen by dqn [4]
INFO:root:frame =14808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 136.79603577]
 [ 125.1167984 ]
 [ 119.27902222]
 [ 130.99726868]
 [ 130.00578308]
 [ 122.52884674]
 [ 127.41778564]
 [ 134.82009888]
 [ 128.31259155]
 [ 139.48504639]
 [ 125.37329102]
 [ 136.81924438]
 [ 156.039505  ]
 [ 122.52884674]
 [ 125.67827606]
 [ 144.00256348]]
DEBUG:root:training time = %d0.213378
INFO:root:frame =14809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =14810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000545978546143
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.882928333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000041
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =14813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000325202941895
INFO:root:frame =14814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485897064209
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:random_action_porb = 0.882896666667
DEBUG:root: dqn, choose action rondomly, need time 0.00042000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 134.27391052]
 [ 139.29084778]
 [ 132.03004456]
 [ 133.53901672]
 [ 137.86463928]
 [ 159.50354004]
 [ 129.63513184]
 [ 132.47364807]
 [ 134.55766296]
 [ 126.92806244]
 [ 131.90348816]
 [ 140.72079468]
 [ 135.61500549]
 [ 123.26230621]
 [ 135.67366028]
 [ 134.30891418]]
DEBUG:root:training time = %d0.24039
INFO:root:frame =14817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256776809692
INFO:root:frame =14818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.882865
DEBUG:root: dqn, choose action rondomly, need time 0.00036399999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =14821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488996505737
INFO:root:frame =14822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.882833333333
INFO:root:dqn select action Tensor("ArgMax_224:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010993
INFO:root:action choosen by dqn [4]
INFO:root:frame =14824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:training error  = [[ 139.64079285]
 [ 141.00402832]
 [ 140.2252655 ]
 [ 136.16036987]
 [ 136.97171021]
 [ 122.96907043]
 [ 127.77594757]
 [ 132.15209961]
 [ 132.3928833 ]
 [ 132.65003967]
 [ 128.40594482]
 [ 139.99082947]
 [ 127.55319977]
 [ 137.82594299]
 [ 122.96907043]
 [ 139.10902405]]
DEBUG:root:training time = %d0.242036
INFO:root:frame =14825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =14826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
DEBUG:root: save sample needs time = 0.000134944915771
INFO:root:random_action_porb = 0.882801666667
DEBUG:root: dqn, choose action rondomly, need time 0.000408999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000172853469849
INFO:root:frame =14829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =14830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000570058822632
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.88277
DEBUG:root: dqn, choose action rondomly, need time 0.000521999999989
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 129.12138367]
 [ 129.60072327]
 [ 134.39451599]
 [ 136.70895386]
 [ 145.16947937]
 [ 129.99673462]
 [ 141.35067749]
 [ 133.29403687]
 [ 131.25308228]
 [ 134.91685486]
 [ 126.79194641]
 [ 135.11933899]
 [ 129.12138367]
 [ 144.67277527]
 [ 159.83863831]
 [ 133.17884827]]
DEBUG:root:training time = %d0.211861
INFO:root:frame =14833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =14834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.882738333333
INFO:root:dqn select action Tensor("ArgMax_225:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015677
INFO:root:action choosen by dqn [4]
INFO:root:frame =14836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00018310546875
INFO:root:frame =14837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =14838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000578880310059
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.882706666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 137.35877991]
 [ 163.368927  ]
 [ 130.68833923]
 [ 130.01727295]
 [ 156.70962524]
 [ 140.56335449]
 [ 131.46818542]
 [ 133.60391235]
 [ 130.9574585 ]
 [ 131.59663391]
 [ 156.26182556]
 [ 136.95991516]
 [ 134.085495  ]
 [ 140.45230103]
 [ 131.4629364 ]
 [ 136.59979248]]
DEBUG:root:training time = %d0.226789
INFO:root:frame =14841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =14842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
DEBUG:root: save sample needs time = 0.000119209289551
INFO:root:random_action_porb = 0.882675
INFO:root:dqn select action Tensor("ArgMax_226:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00940099999997
INFO:root:action choosen by dqn [4]
INFO:root:frame =14844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:frame =14845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =14846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000425815582275
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.882643333333
DEBUG:root: dqn, choose action rondomly, need time 0.00046100000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 115.44639587]
 [ 141.46026611]
 [ 142.52612305]
 [ 135.78778076]
 [ 133.73445129]
 [ 105.70472717]
 [ 134.07241821]
 [ 130.7305603 ]
 [ 128.39073181]
 [ 130.83456421]
 [ 129.92472839]
 [ 129.95429993]
 [ 129.3767395 ]
 [ 125.98466492]
 [ 130.43377686]
 [ 161.71110535]]
DEBUG:root:training time = %d0.222533
INFO:root:frame =14849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =14850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.882611666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =14853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000527858734131
INFO:root:frame =14854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.88258
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 131.26356506]
 [ 135.72306824]
 [ 125.416008  ]
 [ 129.11445618]
 [ 145.35044861]
 [ 129.12519836]
 [ 130.4543457 ]
 [ 131.92521667]
 [ 131.45068359]
 [ 134.81974792]
 [ 160.77293396]
 [ 137.71812439]
 [ 135.68609619]
 [ 131.71743774]
 [ 136.44290161]
 [ 133.39305115]]
DEBUG:root:training time = %d0.239932
INFO:root:frame =14857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame =14858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002601146698
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.882548333333
DEBUG:root: dqn, choose action rondomly, need time 0.00017600000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:frame =14861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =14862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025200843811
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.882516666667
DEBUG:root: dqn, choose action rondomly, need time 0.000177000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162124633789
INFO:root:training error  = [[ 129.37257385]
 [ 133.23765564]
 [ 138.21099854]
 [ 129.19802856]
 [ 130.03398132]
 [ 142.37133789]
 [ 134.0158844 ]
 [ 133.364151  ]
 [ 135.74226379]
 [ 129.57780457]
 [ 136.73501587]
 [ 131.65370178]
 [ 118.11400604]
 [ 144.30851746]
 [ 130.29823303]
 [ 138.06573486]]
DEBUG:root:training time = %d0.246812
INFO:root:frame =14865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255823135376
INFO:root:frame =14866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.882485
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000022
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =14869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =14870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000285148620605
INFO:root:random_action_porb = 0.882453333333
DEBUG:root: dqn, choose action rondomly, need time 0.000419999999963
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 135.07748413]
 [ 137.00634766]
 [ 137.537323  ]
 [ 153.56729126]
 [ 136.33491516]
 [ 140.61437988]
 [ 134.29618835]
 [ 142.83306885]
 [ 159.2673645 ]
 [ 125.19976044]
 [ 138.78059387]
 [ 128.73397827]
 [ 135.29463196]
 [ 129.81309509]
 [ 135.29463196]
 [ 129.99569702]]
DEBUG:root:training time = %d0.217513
INFO:root:frame =14873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =14874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000295877456665
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.882421666667
DEBUG:root: dqn, choose action rondomly, need time 0.000344000000041
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00040602684021
INFO:root:frame =14877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000522136688232
INFO:root:frame =14878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000363826751709
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.88239
DEBUG:root: dqn, choose action rondomly, need time 0.000585999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000394105911255
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 127.78077698]
 [ 131.3097229 ]
 [ 137.51620483]
 [ 130.27455139]
 [ 130.69287109]
 [ 129.80613708]
 [ 125.50043488]
 [ 135.44021606]
 [ 130.38116455]
 [ 135.85713196]
 [ 133.19258118]
 [ 156.96072388]
 [ 140.35972595]
 [ 124.23833466]
 [ 137.59030151]
 [ 132.33634949]]
DEBUG:root:training time = %d0.23718
INFO:root:frame =14881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000399827957153
INFO:root:frame =14882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000378131866455
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.882358333333
DEBUG:root: dqn, choose action rondomly, need time 0.000160999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00017786026001
INFO:root:frame =14885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000269174575806
INFO:root:frame =14886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275850296021
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.882326666667
DEBUG:root: dqn, choose action rondomly, need time 0.000173000000018
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 139.22962952]
 [ 132.53302002]
 [ 130.97946167]
 [ 146.26396179]
 [ 148.4172821 ]
 [ 129.85725403]
 [ 135.13352966]
 [ 132.53302002]
 [ 135.87420654]
 [ 133.63284302]
 [ 132.21315002]
 [ 154.50054932]
 [ 134.17384338]
 [ 125.73404694]
 [ 133.69564819]
 [ 130.32402039]]
DEBUG:root:training time = %d0.24517
INFO:root:frame =14889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =14890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.882295
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =14893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =14894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.882263333333
DEBUG:root: dqn, choose action rondomly, need time 0.000334000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 133.16967773]
 [ 136.31532288]
 [ 157.71635437]
 [ 131.2205658 ]
 [ 131.16708374]
 [ 143.24549866]
 [ 137.33375549]
 [ 135.59510803]
 [ 135.79595947]
 [ 131.54867554]
 [ 141.26651001]
 [ 139.91645813]
 [ 143.67938232]
 [ 128.91929626]
 [ 152.80168152]
 [ 142.86187744]]
DEBUG:root:training time = %d0.241817
INFO:root:frame =14897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =14898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.882231666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =14901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:frame =14902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000329971313477
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.8822
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999952
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 161.97705078]
 [ 134.14344788]
 [ 139.85942078]
 [ 139.42269897]
 [ 113.68740845]
 [ 147.08557129]
 [ 147.59899902]
 [ 139.42269897]
 [ 138.98271179]
 [ 132.5446167 ]
 [ 141.36083984]
 [ 126.16729736]
 [ 140.1519165 ]
 [ 137.76933289]
 [ 136.4821167 ]
 [ 131.31532288]]
DEBUG:root:training time = %d0.239797
INFO:root:frame =14905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =14906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000558853149414
DEBUG:root: save sample needs time = 0.00016713142395
INFO:root:random_action_porb = 0.882168333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =14909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =14910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:random_action_porb = 0.882136666667
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 141.50093079]
 [ 137.50082397]
 [ 150.94006348]
 [ 159.08331299]
 [ 165.90553284]
 [ 167.99578857]
 [ 164.24462891]
 [ 133.72634888]
 [ 149.55563354]
 [ 163.41925049]
 [ 131.75071716]
 [ 137.65330505]
 [ 131.11047363]
 [ 142.73606873]
 [ 150.88795471]
 [ 133.61026001]]
DEBUG:root:training time = %d0.232612
INFO:root:frame =14913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =14914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.000156164169312
INFO:root:random_action_porb = 0.882105
DEBUG:root: dqn, choose action rondomly, need time 0.000575000000026
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =14917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =14918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
DEBUG:root: save sample needs time = 0.000126123428345
INFO:root:random_action_porb = 0.882073333333
DEBUG:root: dqn, choose action rondomly, need time 0.000186999999983
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00018310546875
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 134.44972229]
 [ 149.96681213]
 [ 130.40312195]
 [ 140.92974854]
 [ 123.1471405 ]
 [ 136.45680237]
 [ 138.53083801]
 [ 126.64971924]
 [ 138.02090454]
 [ 134.78289795]
 [ 164.15585327]
 [ 129.84820557]
 [ 146.20085144]
 [ 136.94421387]
 [ 135.27511597]
 [ 114.90991974]]
DEBUG:root:training time = %d0.233416
INFO:root:frame =14921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =14922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319957733154
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.882041666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000022
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =14925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000269174575806
INFO:root:frame =14926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.88201
DEBUG:root: dqn, choose action rondomly, need time 0.000360000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:training error  = [[ 139.00213623]
 [ 133.31939697]
 [ 139.18713379]
 [ 134.06570435]
 [ 134.41044617]
 [ 138.89997864]
 [ 134.06570435]
 [ 137.56237793]
 [ 143.91908264]
 [ 133.56088257]
 [ 139.61050415]
 [ 133.38142395]
 [ 136.81317139]
 [ 134.85377502]
 [ 133.89048767]
 [ 143.41172791]]
DEBUG:root:training time = %d0.240317
INFO:root:frame =14929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =14930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000266075134277
DEBUG:root: save sample needs time = 0.000245809555054
INFO:root:random_action_porb = 0.881978333333
DEBUG:root: dqn, choose action rondomly, need time 0.000196000000017
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:frame =14933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =14934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000192880630493
INFO:root:random_action_porb = 0.881946666667
DEBUG:root: dqn, choose action rondomly, need time 0.000337999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 127.79251099]
 [ 134.66069031]
 [ 138.11378479]
 [ 133.06193542]
 [ 146.86506653]
 [ 158.53489685]
 [ 136.16001892]
 [ 135.66192627]
 [ 142.43032837]
 [ 134.81869507]
 [ 135.43630981]
 [ 144.52159119]
 [ 137.05029297]
 [ 138.95069885]
 [ 146.86506653]
 [ 141.67160034]]
DEBUG:root:training time = %d0.224463
INFO:root:frame =14937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =14938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.881915
DEBUG:root: dqn, choose action rondomly, need time 0.000335000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =14940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root:frame =14941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =14942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000532150268555
INFO:root:frame = 14943 State into memory, numbers recorded 400 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000401973724365
INFO:root:random_action_porb = 0.881883333333
DEBUG:root: dqn, choose action rondomly, need time 0.000317999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14944current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 129.12416077]
 [ 146.31268311]
 [ 134.02400208]
 [ 129.88194275]
 [ 158.94207764]
 [ 138.63143921]
 [ 139.21485901]
 [ 144.34884644]
 [ 133.13412476]
 [ 137.54089355]
 [ 141.32020569]
 [ 138.29064941]
 [ 137.12640381]
 [ 130.12446594]
 [ 133.35957336]
 [ 140.66503906]]
DEBUG:root:training time = %d0.236239
INFO:root:frame =14945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =14946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.881851666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999969
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =14949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =14950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00040602684021
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.88182
DEBUG:root: dqn, choose action rondomly, need time 0.000546999999983
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 140.36405945]
 [ 142.59208679]
 [ 134.74534607]
 [ 140.89025879]
 [ 135.67045593]
 [ 133.68753052]
 [ 140.63356018]
 [ 163.1708374 ]
 [ 139.13961792]
 [ 133.37297058]
 [ 143.54150391]
 [ 145.81108093]
 [ 146.78112793]
 [ 130.73788452]
 [ 136.89956665]
 [ 136.91242981]]
DEBUG:root:training time = %d0.242384
INFO:root:frame =14953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =14954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259160995483
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.881788333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =14956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =14957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000389099121094
INFO:root:frame =14958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.881756666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 141.45518494]
 [ 139.66351318]
 [ 140.582901  ]
 [ 142.17585754]
 [ 142.67227173]
 [ 140.2979126 ]
 [ 135.72875977]
 [ 165.47813416]
 [ 143.92384338]
 [ 142.93849182]
 [ 137.17108154]
 [ 130.8837738 ]
 [ 139.85040283]
 [ 144.56745911]
 [ 134.67875671]
 [ 135.38659668]]
DEBUG:root:training time = %d0.242864
INFO:root:frame =14961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =14962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.881725
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =14965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =14966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.881693333333
INFO:root:dqn select action Tensor("ArgMax_227:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013297
INFO:root:action choosen by dqn [4]
INFO:root:frame =14968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:training error  = [[ 136.98348999]
 [ 136.89242554]
 [ 132.82055664]
 [ 143.3697052 ]
 [ 148.02604675]
 [ 129.79605103]
 [ 132.56217957]
 [ 136.54522705]
 [ 142.90820312]
 [ 148.65010071]
 [ 140.46386719]
 [ 149.17967224]
 [ 140.32827759]
 [ 150.02774048]
 [ 132.63000488]
 [ 134.46421814]]
DEBUG:root:training time = %d0.213822
INFO:root:frame =14969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =14970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.881661666667
DEBUG:root: dqn, choose action rondomly, need time 0.000169999999969
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:frame =14973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000514030456543
INFO:root:frame =14974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.88163
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =14976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 137.55235291]
 [ 142.7568512 ]
 [ 144.81008911]
 [ 145.89216614]
 [ 133.21159363]
 [ 136.37304688]
 [ 160.56906128]
 [ 133.21159363]
 [ 139.56256104]
 [ 168.10972595]
 [ 145.13969421]
 [ 141.78640747]
 [ 134.89523315]
 [ 135.29499817]
 [ 139.31858826]
 [ 141.99943542]]
DEBUG:root:training time = %d0.220556
INFO:root:frame =14977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =14978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000270843505859
DEBUG:root: save sample needs time = 0.000115156173706
INFO:root:random_action_porb = 0.881598333333
INFO:root:dqn select action Tensor("ArgMax_228:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010961
INFO:root:action choosen by dqn [4]
INFO:root:frame =14980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =14981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470876693726
INFO:root:frame =14982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.881566666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 138.5743103 ]
 [ 145.32357788]
 [ 154.95417786]
 [ 142.4372406 ]
 [ 140.35069275]
 [ 135.24353027]
 [ 136.34132385]
 [ 144.78585815]
 [ 136.04856873]
 [ 144.70471191]
 [ 139.23034668]
 [ 136.07492065]
 [ 149.30567932]
 [ 140.35935974]
 [ 135.37025452]
 [ 138.09011841]]
DEBUG:root:training time = %d0.223908
INFO:root:frame =14985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =14986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000291109085083
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.881535
DEBUG:root: dqn, choose action rondomly, need time 0.000174000000015
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =14988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:frame =14989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000604152679443
INFO:root:frame =14990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000343084335327
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:random_action_porb = 0.881503333333
DEBUG:root: dqn, choose action rondomly, need time 0.000395000000026
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000626087188721
INFO:root:training error  = [[ 135.14807129]
 [ 138.57969666]
 [ 139.79808044]
 [ 139.35856628]
 [ 139.54814148]
 [ 147.58007812]
 [ 145.40415955]
 [ 139.59320068]
 [ 138.05569458]
 [ 139.44108582]
 [ 135.03846741]
 [ 137.23899841]
 [ 150.6619873 ]
 [ 139.99768066]
 [ 135.75968933]
 [ 147.7046814 ]]
DEBUG:root:training time = %d0.224246
INFO:root:frame =14993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =14994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:random_action_porb = 0.881471666667
DEBUG:root: dqn, choose action rondomly, need time 0.000340999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =14996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =14997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =14998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.00022292137146
DEBUG:root:one frame running time = 0.00643299999996
DEBUG:root:total training time = 454.18097
INFO:root:frame num = 15000 frame round: 0
INFO:root:random_action_porb = 0.88144
INFO:root:dqn select action Tensor("ArgMax_229:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015692
INFO:root:action choosen by dqn [4]
INFO:root:frame =15000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 135.97596741]
 [ 139.58203125]
 [ 140.9884491 ]
 [ 140.59411621]
 [ 166.54371643]
 [ 134.68725586]
 [ 143.57221985]
 [ 148.18426514]
 [ 138.30931091]
 [ 139.01545715]
 [ 144.74363708]
 [ 132.37286377]
 [ 138.9384613 ]
 [ 144.10108948]
 [ 143.88064575]
 [ 140.15913391]]
DEBUG:root:training time = %d0.243567
INFO:root:frame =15001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270843505859
INFO:root:frame =15002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.881408333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000018
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root:frame =15005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =15006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame = 15007 State into memory, numbers recorded 401 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000586986541748
INFO:root:random_action_porb = 0.881376666667
DEBUG:root: dqn, choose action rondomly, need time 0.00032299999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15008current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 143.55247498]
 [ 145.02905273]
 [ 138.60377502]
 [ 145.85308838]
 [ 138.95681763]
 [ 149.85696411]
 [ 144.06776428]
 [ 134.91012573]
 [ 136.95562744]
 [ 130.87121582]
 [ 146.49102783]
 [ 131.56057739]
 [ 172.54772949]
 [ 142.33674622]
 [ 139.49154663]
 [ 139.59068298]]
DEBUG:root:training time = %d0.230908
INFO:root:frame =15009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =15010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.881345
DEBUG:root: dqn, choose action rondomly, need time 0.000369999999975
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =15013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000408172607422
INFO:root:frame =15014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000329971313477
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:random_action_porb = 0.881313333333
INFO:root:dqn select action Tensor("ArgMax_230:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01374
INFO:root:action choosen by dqn [4]
INFO:root:frame =15016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 146.8543396 ]
 [ 164.47819519]
 [ 179.73612976]
 [ 131.60153198]
 [ 148.2946167 ]
 [ 145.10992432]
 [ 144.37927246]
 [ 138.73565674]
 [ 142.03361511]
 [ 153.92260742]
 [ 138.94386292]
 [ 151.27693176]
 [ 136.41545105]
 [ 147.06965637]
 [ 163.17512512]
 [ 158.50032043]]
DEBUG:root:training time = %d0.219816
INFO:root:frame =15017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root:frame =15018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411033630371
DEBUG:root: save sample needs time = 0.000125169754028
INFO:root:random_action_porb = 0.881281666667
DEBUG:root: dqn, choose action rondomly, need time 0.000474999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =15021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root: ememy has been killed for 30 times 
INFO:root:enemies_left [0]
INFO:root:frame =15022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000328779220581
INFO:root:frame = 15023 State into memory, numbers recorded 402 action = 2, reward = 1
DEBUG:root: save sample needs time = 0.000536918640137
INFO:root:random_action_porb = 0.88125
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999955
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15024current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 137.40707397]
 [ 170.22174072]
 [ 145.84977722]
 [ 143.80230713]
 [ 145.35780334]
 [ 135.04307556]
 [ 160.59768677]
 [ 148.34255981]
 [ 146.35734558]
 [ 146.99786377]
 [ 118.7390213 ]
 [ 151.67018127]
 [ 148.94419861]
 [ 141.2150116 ]
 [ 146.73934937]
 [ 134.4281311 ]]
DEBUG:root:training time = %d0.210344
INFO:root:frame =15025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =15026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275850296021
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.881218333333
DEBUG:root: dqn, choose action rondomly, need time 0.000279999999975
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =15029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =15030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.881186666667
DEBUG:root: dqn, choose action rondomly, need time 0.000333000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:training error  = [[ 136.99992371]
 [ 144.39578247]
 [ 141.06164551]
 [ 145.18859863]
 [ 137.364151  ]
 [ 147.12480164]
 [ 146.19973755]
 [ 146.69572449]
 [ 138.43962097]
 [ 144.79467773]
 [ 157.10604858]
 [ 153.93699646]
 [ 142.12091064]
 [ 144.59313965]
 [ 150.64100647]
 [ 146.06767273]]
DEBUG:root:training time = %d0.241752
INFO:root:frame =15033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =15034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308990478516
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.881155
DEBUG:root: dqn, choose action rondomly, need time 0.000397999999961
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000396013259888
INFO:root:frame =15037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000603914260864
INFO:root:frame =15038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049090385437
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.881123333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 133.17462158]
 [ 138.1471405 ]
 [ 137.09924316]
 [ 140.05871582]
 [ 155.59037781]
 [ 134.9331665 ]
 [ 139.73638916]
 [ 145.03382874]
 [ 143.72547913]
 [ 141.57899475]
 [ 136.23658752]
 [ 142.62379456]
 [ 165.79116821]
 [ 143.50164795]
 [ 138.03346252]
 [ 146.43045044]]
DEBUG:root:training time = %d0.227643
INFO:root:frame =15041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =15042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000402212142944
INFO:root:frame = 15043 State into memory, numbers recorded 403 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000562906265259
INFO:root:random_action_porb = 0.881091666667
DEBUG:root: dqn, choose action rondomly, need time 0.000450000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15044current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:frame =15045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00048303604126
INFO:root:frame =15046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.88106
INFO:root:dqn select action Tensor("ArgMax_231:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00928699999997
INFO:root:action choosen by dqn [4]
INFO:root:frame =15048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 139.18534851]
 [ 143.23965454]
 [ 134.9671936 ]
 [ 152.65760803]
 [ 177.53033447]
 [ 138.26051331]
 [ 149.4783783 ]
 [ 175.28482056]
 [ 139.99516296]
 [ 144.84793091]
 [ 144.98789978]
 [ 164.18791199]
 [ 143.04724121]
 [ 138.26983643]
 [ 141.99906921]
 [ 122.45926666]]
DEBUG:root:training time = %d0.22651
INFO:root:frame =15049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =15050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame = 15051 State into memory, numbers recorded 404 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00117301940918
INFO:root:random_action_porb = 0.881028333333
DEBUG:root: dqn, choose action rondomly, need time 0.000335000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15052current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =15053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =15054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000492095947266
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.880996666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 138.66377258]
 [ 153.03717041]
 [ 148.58946228]
 [ 166.16073608]
 [ 164.64300537]
 [ 143.71522522]
 [ 147.75401306]
 [ 137.92053223]
 [ 138.51899719]
 [ 138.55886841]
 [ 146.28425598]
 [ 167.11369324]
 [ 139.68588257]
 [ 163.27104187]
 [ 139.38487244]
 [ 135.80627441]]
DEBUG:root:training time = %d0.227817
INFO:root:frame =15057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =15058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427007675171
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.880965
DEBUG:root: dqn, choose action rondomly, need time 0.000269000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =15061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =15062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000300884246826
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.880933333333
DEBUG:root: dqn, choose action rondomly, need time 0.000267000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00037407875061
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 146.16099548]
 [ 176.32919312]
 [ 166.36495972]
 [ 155.92095947]
 [ 147.81893921]
 [ 147.67056274]
 [ 136.10980225]
 [ 146.54237366]
 [ 144.79100037]
 [ 141.89907837]
 [ 145.23750305]
 [ 155.74687195]
 [ 141.23495483]
 [ 138.83560181]
 [ 160.90684509]
 [ 144.03259277]]
DEBUG:root:training time = %d0.214164
INFO:root:frame =15065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =15066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.0001060962677
INFO:root:random_action_porb = 0.880901666667
DEBUG:root: dqn, choose action rondomly, need time 0.000278000000037
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000147104263306
INFO:root:frame =15069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =15070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.88087
INFO:root:dqn select action Tensor("ArgMax_232:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015123
INFO:root:action choosen by dqn [4]
INFO:root:frame =15072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000235795974731
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 144.62617493]
 [ 141.53649902]
 [ 124.73033905]
 [ 151.62771606]
 [ 130.56207275]
 [ 146.7046051 ]
 [ 149.30381775]
 [ 141.998703  ]
 [ 143.7774353 ]
 [ 141.61494446]
 [ 152.28756714]
 [ 142.42851257]
 [ 140.85041809]
 [ 148.31988525]
 [ 140.08111572]
 [ 142.49771118]]
DEBUG:root:training time = %d0.234185
INFO:root:frame =15073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =15074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000425100326538
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.880838333333
DEBUG:root: dqn, choose action rondomly, need time 0.000173000000018
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:frame =15077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =15078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.880806666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:training error  = [[ 147.62828064]
 [ 132.78890991]
 [ 147.58601379]
 [ 143.18450928]
 [ 143.57295227]
 [ 147.87496948]
 [ 146.7947998 ]
 [ 151.33024597]
 [ 154.30183411]
 [ 143.45960999]
 [ 137.57131958]
 [ 145.3949585 ]
 [ 140.88917542]
 [ 141.6915741 ]
 [ 148.545578  ]
 [ 148.19874573]]
DEBUG:root:training time = %d0.242207
INFO:root:frame =15081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =15082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00032114982605
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.880775
INFO:root:dqn select action Tensor("ArgMax_233:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012222
INFO:root:action choosen by dqn [4]
INFO:root:frame =15084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:frame =15085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:frame =15086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000414848327637
INFO:root:frame = 15087 State into memory, numbers recorded 405 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00123000144958
INFO:root:random_action_porb = 0.880743333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000018
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15088current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 153.85635376]
 [ 140.59844971]
 [ 141.61820984]
 [ 168.31990051]
 [ 135.68502808]
 [ 139.83380127]
 [ 141.61384583]
 [ 123.10209656]
 [ 142.27885437]
 [ 166.71350098]
 [ 141.52452087]
 [ 141.8245697 ]
 [ 140.13963318]
 [ 164.96858215]
 [ 147.31141663]
 [ 146.52575684]]
DEBUG:root:training time = %d0.231604
INFO:root:frame =15089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =15090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame = 15091 State into memory, numbers recorded 406 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000576972961426
INFO:root:random_action_porb = 0.880711666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15092current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =15093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488996505737
INFO:root:frame =15094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame = 15095 State into memory, numbers recorded 407 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000550031661987
INFO:root:random_action_porb = 0.88068
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15096current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:training error  = [[ 143.87112427]
 [ 142.65513611]
 [ 149.07383728]
 [ 144.57809448]
 [ 150.70657349]
 [ 141.59750366]
 [ 144.73703003]
 [ 146.89761353]
 [ 149.66088867]
 [ 147.15626526]
 [ 143.45449829]
 [ 149.60452271]
 [ 143.09761047]
 [ 136.60301208]
 [ 142.63435364]
 [ 145.42146301]]
DEBUG:root:training time = %d0.226438
INFO:root:frame =15097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =15098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000192880630493
INFO:root:random_action_porb = 0.880648333333
DEBUG:root: dqn, choose action rondomly, need time 0.000324999999975
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =15101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =15102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000561952590942
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.880616666667
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 141.9677887 ]
 [ 142.32327271]
 [ 146.25915527]
 [ 144.81340027]
 [ 149.67582703]
 [ 142.78857422]
 [ 140.31887817]
 [ 168.4992981 ]
 [ 149.48025513]
 [ 140.41323853]
 [ 147.09370422]
 [ 159.45304871]
 [ 149.48025513]
 [ 175.13737488]
 [ 149.48025513]
 [ 147.15663147]]
DEBUG:root:training time = %d0.221752
INFO:root:frame =15105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =15106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000396013259888
DEBUG:root: save sample needs time = 0.0001060962677
INFO:root:random_action_porb = 0.880585
DEBUG:root: dqn, choose action rondomly, need time 0.000369999999975
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =15109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =15110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.880553333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 140.95075989]
 [ 147.93508911]
 [ 154.83415222]
 [ 143.64134216]
 [ 155.76286316]
 [ 163.9822998 ]
 [ 146.50285339]
 [ 142.38298035]
 [ 142.76924133]
 [ 142.64857483]
 [ 140.8109436 ]
 [ 161.28256226]
 [ 169.85643005]
 [ 146.41273499]
 [ 116.45787048]
 [ 142.98556519]]
DEBUG:root:training time = %d0.228315
INFO:root:frame =15113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:frame =15114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root:random_action_porb = 0.880521666667
DEBUG:root: dqn, choose action rondomly, need time 0.000178000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000158786773682
INFO:root:frame =15117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =15118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000490188598633
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.88049
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 151.78070068]
 [ 158.37164307]
 [ 147.11369324]
 [ 151.34112549]
 [ 144.71977234]
 [ 144.97686768]
 [ 144.65075684]
 [ 153.37826538]
 [ 141.00402832]
 [ 151.89389038]
 [ 146.2421875 ]
 [ 144.01831055]
 [ 152.82469177]
 [ 136.13046265]
 [ 142.51811218]
 [ 174.6204071 ]]
DEBUG:root:training time = %d0.20638
INFO:root:frame =15121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:frame =15122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000276803970337
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.880458333333
DEBUG:root: dqn, choose action rondomly, need time 0.000402000000008
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =15125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =15126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.880426666667
INFO:root:dqn select action Tensor("ArgMax_234:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013561
INFO:root:action choosen by dqn [4]
INFO:root:frame =15128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000177145004272
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 152.60595703]
 [ 143.52688599]
 [ 150.09165955]
 [ 135.73764038]
 [ 148.62666321]
 [ 175.12484741]
 [ 148.23330688]
 [ 142.69195557]
 [ 144.82662964]
 [ 146.26396179]
 [ 152.97299194]
 [ 157.34291077]
 [ 138.54341125]
 [ 147.6394043 ]
 [ 147.70950317]
 [ 179.80978394]]
DEBUG:root:training time = %d0.212222
INFO:root:frame =15129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =15130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240087509155
DEBUG:root: save sample needs time = 0.000134944915771
INFO:root:random_action_porb = 0.880395
DEBUG:root: dqn, choose action rondomly, need time 0.000382000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =15133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =15134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000255823135376
INFO:root:random_action_porb = 0.880363333333
DEBUG:root: dqn, choose action rondomly, need time 0.000345999999979
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 146.4987793 ]
 [ 181.96789551]
 [ 142.89689636]
 [ 155.07955933]
 [ 144.9588623 ]
 [ 143.24549866]
 [ 144.07948303]
 [ 149.58586121]
 [ 149.94364929]
 [ 148.41021729]
 [ 148.7743988 ]
 [ 141.79985046]
 [ 140.21333313]
 [ 140.22851562]
 [ 152.44841003]
 [ 149.42727661]]
DEBUG:root:training time = %d0.212227
INFO:root:frame =15137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =15138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.880331666667
DEBUG:root: dqn, choose action rondomly, need time 0.00028999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =15141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000525951385498
INFO:root:frame =15142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000594854354858
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.8803
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 149.28816223]
 [ 145.11102295]
 [ 179.34030151]
 [ 142.80497742]
 [ 140.24369812]
 [ 155.30462646]
 [ 158.43501282]
 [ 142.76158142]
 [ 144.16996765]
 [ 143.88832092]
 [ 147.32846069]
 [ 171.10121155]
 [ 143.93226624]
 [ 152.86921692]
 [ 145.58601379]
 [ 157.32759094]]
DEBUG:root:training time = %d0.235034
INFO:root:frame =15145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =15146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000346183776855
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.880268333333
DEBUG:root: dqn, choose action rondomly, need time 0.000280999999973
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =15149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =15150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00062084197998
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:random_action_porb = 0.880236666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283000000024
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 151.50598145]
 [ 144.67755127]
 [ 152.74584961]
 [ 140.60786438]
 [ 146.27023315]
 [ 171.94494629]
 [ 143.32476807]
 [ 141.40110779]
 [ 148.2537384 ]
 [ 153.94003296]
 [ 141.4236145 ]
 [ 147.55302429]
 [ 128.86871338]
 [ 148.21508789]
 [ 143.6186676 ]
 [ 148.6121521 ]]
DEBUG:root:training time = %d0.221803
INFO:root:frame =15153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =15154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000747203826904
DEBUG:root: save sample needs time = 0.000146865844727
INFO:root:random_action_porb = 0.880205
DEBUG:root: dqn, choose action rondomly, need time 0.000526999999977
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =15157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:frame =15158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000607013702393
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:random_action_porb = 0.880173333333
INFO:root:dqn select action Tensor("ArgMax_235:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011535
INFO:root:action choosen by dqn [4]
INFO:root:frame =15160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162124633789
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 152.91902161]
 [ 147.30993652]
 [ 148.44329834]
 [ 148.08285522]
 [ 145.44059753]
 [ 177.29498291]
 [ 149.45637512]
 [ 177.29498291]
 [ 150.04231262]
 [ 169.67550659]
 [ 148.36151123]
 [ 146.14402771]
 [ 150.94155884]
 [ 150.33065796]
 [ 148.15379333]
 [ 144.93130493]]
DEBUG:root:training time = %d0.220447
INFO:root:frame =15161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =15162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000495910644531
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.880141666667
DEBUG:root: dqn, choose action rondomly, need time 0.00046900000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000514030456543
INFO:root:frame =15165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000419139862061
INFO:root:frame =15166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.88011
INFO:root:dqn select action Tensor("ArgMax_236:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.0103
INFO:root:action choosen by dqn [4]
INFO:root:frame =15168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162124633789
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 151.74160767]
 [ 160.36495972]
 [ 147.62124634]
 [ 154.61398315]
 [ 137.63397217]
 [ 157.92338562]
 [ 158.385849  ]
 [ 179.80732727]
 [ 145.67366028]
 [ 154.93821716]
 [ 147.56303406]
 [ 143.66694641]
 [ 171.30966187]
 [ 151.00305176]
 [ 143.51664734]
 [ 174.199646  ]]
DEBUG:root:training time = %d0.222849
INFO:root:frame =15169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =15170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000416994094849
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.880078333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =15173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456809997559
INFO:root:frame =15174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480890274048
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:random_action_porb = 0.880046666667
DEBUG:root: dqn, choose action rondomly, need time 0.000481000000036
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:training error  = [[ 145.85456848]
 [ 148.72229004]
 [ 151.60629272]
 [ 142.49188232]
 [ 156.24504089]
 [ 153.80412292]
 [ 156.77037048]
 [ 133.89862061]
 [ 146.67355347]
 [ 133.82376099]
 [ 151.01992798]
 [ 149.12600708]
 [ 144.78181458]
 [ 143.37554932]
 [ 144.00366211]
 [ 146.85507202]]
DEBUG:root:training time = %d0.215614
INFO:root:frame =15177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =15178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000410795211792
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:random_action_porb = 0.880015
INFO:root:dqn select action Tensor("ArgMax_237:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012889
INFO:root:action choosen by dqn [4]
INFO:root:frame =15180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162124633789
INFO:root:frame =15181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =15182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241041183472
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.879983333333
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 163.20358276]
 [ 149.50524902]
 [ 158.53874207]
 [ 143.57112122]
 [ 149.66424561]
 [ 149.45674133]
 [ 162.59985352]
 [ 149.91711426]
 [ 158.02388   ]
 [ 170.33125305]
 [ 145.35375977]
 [ 136.00444031]
 [ 145.99317932]
 [ 146.52833557]
 [ 142.71492004]
 [ 148.51023865]]
DEBUG:root:training time = %d0.23069
INFO:root:frame =15185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270843505859
INFO:root:frame =15186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.879951666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =15189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =15190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000111103057861
INFO:root:random_action_porb = 0.87992
DEBUG:root: dqn, choose action rondomly, need time 0.000192000000027
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000166893005371
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 149.72250366]
 [ 145.06433105]
 [ 147.79444885]
 [ 121.29660034]
 [ 143.40077209]
 [ 149.26802063]
 [ 152.23936462]
 [ 152.46461487]
 [ 149.57316589]
 [ 155.91410828]
 [ 148.30130005]
 [ 158.28869629]
 [ 149.57951355]
 [ 148.67094421]
 [ 144.9158783 ]
 [ 149.57951355]]
DEBUG:root:training time = %d0.238074
INFO:root:frame =15193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =15194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324964523315
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.879888333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =15197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =15198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.879856666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 150.55674744]
 [ 180.88189697]
 [ 149.46942139]
 [ 154.02030945]
 [ 146.74821472]
 [ 148.70629883]
 [ 158.85821533]
 [ 149.29188538]
 [ 145.21324158]
 [ 152.80055237]
 [ 152.51887512]
 [ 150.85496521]
 [ 150.11708069]
 [ 180.09716797]
 [ 151.1474762 ]
 [ 149.80578613]]
DEBUG:root:training time = %d0.243928
INFO:root:frame =15201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =15202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000115871429443
INFO:root:random_action_porb = 0.879825
DEBUG:root: dqn, choose action rondomly, need time 0.000181999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:frame =15205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =15206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.879793333333
DEBUG:root: dqn, choose action rondomly, need time 0.000344000000041
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 128.80670166]
 [ 155.91296387]
 [ 154.0078125 ]
 [ 145.20808411]
 [ 154.46072388]
 [ 157.70256042]
 [ 144.82772827]
 [ 149.99745178]
 [ 148.7159729 ]
 [ 160.43026733]
 [ 151.6570282 ]
 [ 159.42915344]
 [ 149.67918396]
 [ 157.70256042]
 [ 136.53773499]
 [ 152.84431458]]
DEBUG:root:training time = %d0.228992
INFO:root:frame =15209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =15210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000292062759399
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.879761666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =15213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame =15214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.87973
DEBUG:root: dqn, choose action rondomly, need time 0.000352000000021
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 163.47583008]
 [ 155.73962402]
 [ 157.20628357]
 [ 140.78596497]
 [ 145.79264832]
 [ 140.77328491]
 [ 155.95373535]
 [ 155.30691528]
 [ 145.01582336]
 [ 155.95373535]
 [ 176.00393677]
 [ 150.85795593]
 [ 143.61061096]
 [ 152.04663086]
 [ 157.16954041]
 [ 151.48269653]]
DEBUG:root:training time = %d0.246369
INFO:root:frame =15217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =15218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324010848999
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.879698333333
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =15221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =15222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509977340698
INFO:root:frame = 15223 State into memory, numbers recorded 408 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:random_action_porb = 0.879666666667
INFO:root:dqn select action Tensor("ArgMax_238:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01451
INFO:root:action choosen by dqn [4]
INFO:root:frame =15224current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000410079956055
INFO:root:training error  = [[ 150.67434692]
 [ 143.93847656]
 [ 148.809021  ]
 [ 153.40963745]
 [ 147.8037262 ]
 [ 158.27563477]
 [ 155.59455872]
 [ 160.76634216]
 [ 153.35710144]
 [ 160.93664551]
 [ 149.94775391]
 [ 148.98591614]
 [ 146.26321411]
 [ 156.64620972]
 [ 152.45933533]
 [ 158.44769287]]
DEBUG:root:training time = %d0.222594
INFO:root:frame =15225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =15226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000557899475098
DEBUG:root: save sample needs time = 0.00019383430481
INFO:root:random_action_porb = 0.879635
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =15229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =15230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.879603333333
INFO:root:dqn select action Tensor("ArgMax_239:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013185
INFO:root:action choosen by dqn [4]
INFO:root:frame =15232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 157.57879639]
 [ 149.54928589]
 [ 147.32254028]
 [ 152.81526184]
 [ 149.10588074]
 [ 182.60820007]
 [ 155.61587524]
 [ 153.3563385 ]
 [ 147.36698914]
 [ 177.24784851]
 [ 152.59465027]
 [ 146.36878967]
 [ 147.93212891]
 [ 175.46708679]
 [ 155.04878235]
 [ 154.29577637]]
DEBUG:root:training time = %d0.237738
INFO:root:frame =15233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =15234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:frame = 15235 State into memory, numbers recorded 409 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00129508972168
INFO:root:random_action_porb = 0.879571666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999956
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15236current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =15237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =15238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494956970215
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.87954
DEBUG:root: dqn, choose action rondomly, need time 0.000320999999985
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 147.6831665 ]
 [ 148.2351532 ]
 [ 158.36357117]
 [ 151.33361816]
 [ 152.81600952]
 [ 142.10345459]
 [ 166.09819031]
 [ 162.06716919]
 [ 152.11248779]
 [ 176.66610718]
 [ 156.9148407 ]
 [ 166.09819031]
 [ 153.690979  ]
 [ 154.03129578]
 [ 142.64894104]
 [ 157.76963806]]
DEBUG:root:training time = %d0.231435
INFO:root:frame =15241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =15242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494003295898
INFO:root:frame = 15243 State into memory, numbers recorded 410 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.00061297416687
INFO:root:random_action_porb = 0.879508333333
DEBUG:root: dqn, choose action rondomly, need time 0.000242999999955
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15244current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =15245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =15246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000501155853271
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.879476666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 154.28364563]
 [ 150.51667786]
 [ 160.88400269]
 [ 158.11366272]
 [ 137.03742981]
 [ 158.07452393]
 [ 147.57415771]
 [ 152.10157776]
 [ 154.13812256]
 [ 167.67396545]
 [ 173.56019592]
 [ 156.9932251 ]
 [ 161.60671997]
 [ 157.77922058]
 [ 149.65678406]
 [ 154.33747864]]
DEBUG:root:training time = %d0.230468
INFO:root:frame =15249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =15250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480890274048
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.879445
DEBUG:root: dqn, choose action rondomly, need time 0.000276999999983
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:frame =15253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000493049621582
INFO:root:frame =15254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504970550537
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.879413333333
DEBUG:root: dqn, choose action rondomly, need time 0.000307999999961
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:training error  = [[ 149.34893799]
 [ 151.28482056]
 [ 147.5533905 ]
 [ 155.4168396 ]
 [ 154.23588562]
 [ 147.93917847]
 [ 162.84199524]
 [ 160.53929138]
 [ 158.22151184]
 [ 145.39901733]
 [ 149.08277893]
 [ 148.27119446]
 [ 157.80796814]
 [ 156.36521912]
 [ 156.84298706]
 [ 158.6525116 ]]
DEBUG:root:training time = %d0.240098
INFO:root:frame =15257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000356912612915
INFO:root:frame =15258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000217199325562
INFO:root:random_action_porb = 0.879381666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =15261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =15262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456809997559
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.87935
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000038
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 189.44412231]
 [ 164.72721863]
 [ 155.34950256]
 [ 153.83213806]
 [ 159.31358337]
 [ 151.34075928]
 [ 148.44702148]
 [ 147.71766663]
 [ 147.95068359]
 [ 154.32800293]
 [ 158.13285828]
 [ 177.30067444]
 [ 163.56362915]
 [ 149.1595459 ]
 [ 156.03263855]
 [ 145.83024597]]
DEBUG:root:training time = %d0.229409
INFO:root:frame =15265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame =15266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.879318333333
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =15269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =15270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.879286666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 163.79086304]
 [ 165.35214233]
 [ 169.70373535]
 [ 170.58505249]
 [ 155.86305237]
 [ 147.21476746]
 [ 160.90878296]
 [ 173.92424011]
 [ 183.33638   ]
 [ 149.52912903]
 [ 146.97677612]
 [ 157.9513855 ]
 [ 149.51980591]
 [ 155.45413208]
 [ 154.69216919]
 [ 147.91133118]]
DEBUG:root:training time = %d0.233751
INFO:root:frame =15273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =15274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.879255
DEBUG:root: dqn, choose action rondomly, need time 0.000202999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:frame =15277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000525951385498
INFO:root:frame =15278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494956970215
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.879223333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 154.87327576]
 [ 156.21910095]
 [ 161.27984619]
 [ 163.79125977]
 [ 154.258255  ]
 [ 150.19747925]
 [ 158.54220581]
 [ 149.29748535]
 [ 158.70825195]
 [ 158.4473114 ]
 [ 139.42883301]
 [ 138.96760559]
 [ 159.81124878]
 [ 150.15934753]
 [ 161.69519043]
 [ 148.10105896]]
DEBUG:root:training time = %d0.227494
INFO:root:frame =15281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000370025634766
INFO:root:frame =15282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:random_action_porb = 0.879191666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =15285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000368118286133
INFO:root:frame =15286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000559091567993
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:random_action_porb = 0.87916
DEBUG:root: dqn, choose action rondomly, need time 0.000323999999978
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:training error  = [[ 158.17544556]
 [ 162.1685791 ]
 [ 162.42556763]
 [ 151.2915802 ]
 [ 167.08015442]
 [ 154.00894165]
 [ 170.23846436]
 [ 160.60194397]
 [ 151.2915802 ]
 [ 158.44116211]
 [ 161.56211853]
 [ 156.94543457]
 [ 161.39497375]
 [ 162.50569153]
 [ 158.77822876]
 [ 157.65197754]]
DEBUG:root:training time = %d0.222056
INFO:root:frame =15289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =15290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000381946563721
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:random_action_porb = 0.879128333333
INFO:root:dqn select action Tensor("ArgMax_240:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011735
INFO:root:action choosen by dqn [4]
INFO:root:frame =15292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =15293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =15294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame = 15295 State into memory, numbers recorded 411 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00122690200806
INFO:root:random_action_porb = 0.879096666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15296current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 157.60293579]
 [ 170.0473938 ]
 [ 134.36231995]
 [ 151.99131775]
 [ 147.84454346]
 [ 181.78474426]
 [ 178.33308411]
 [ 152.11889648]
 [ 159.07369995]
 [ 155.88362122]
 [ 180.12542725]
 [ 155.75372314]
 [ 152.59237671]
 [ 156.95651245]
 [ 151.47819519]
 [ 162.15536499]]
DEBUG:root:training time = %d0.215728
INFO:root:frame =15297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =15298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259876251221
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.879065
DEBUG:root: dqn, choose action rondomly, need time 0.000521999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =15301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =15302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.879033333333
DEBUG:root: dqn, choose action rondomly, need time 0.000523999999984
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 172.49160767]
 [ 164.27748108]
 [ 181.41955566]
 [ 158.8039856 ]
 [ 147.7224884 ]
 [ 154.35643005]
 [ 158.77630615]
 [ 167.36863708]
 [ 152.37419128]
 [ 160.58917236]
 [ 157.44895935]
 [ 154.24232483]
 [ 147.91876221]
 [ 171.29608154]
 [ 163.05430603]
 [ 152.43409729]]
DEBUG:root:training time = %d0.219304
INFO:root:frame =15305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =15306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.879001666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =15309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449180603027
INFO:root:frame =15310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.87897
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000018
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 146.31047058]
 [ 172.90388489]
 [ 159.58795166]
 [ 157.99472046]
 [ 152.44012451]
 [ 161.30000305]
 [ 151.20037842]
 [ 151.25553894]
 [ 182.89614868]
 [ 154.26431274]
 [ 164.17266846]
 [ 157.73551941]
 [ 151.95671082]
 [ 168.76165771]
 [ 140.20646667]
 [ 161.35232544]]
DEBUG:root:training time = %d0.236492
INFO:root:frame =15313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =15314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.878938333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =15317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =15318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475883483887
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.878906666667
DEBUG:root: dqn, choose action rondomly, need time 0.00018399999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 158.17967224]
 [ 154.7616272 ]
 [ 149.52726746]
 [ 159.14183044]
 [ 167.73088074]
 [ 161.49772644]
 [ 180.64802551]
 [ 152.80847168]
 [ 172.0329895 ]
 [ 152.26609802]
 [ 158.10522461]
 [ 162.46951294]
 [ 146.21414185]
 [ 148.49797058]
 [ 150.95018005]
 [ 149.52726746]]
DEBUG:root:training time = %d0.240155
INFO:root:frame =15321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =15322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319957733154
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.878875
INFO:root:dqn select action Tensor("ArgMax_241:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00905499999999
INFO:root:action choosen by dqn [4]
INFO:root:frame =15324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root:frame =15325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =15326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.878843333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 159.13027954]
 [ 167.82969666]
 [ 166.86405945]
 [ 152.89675903]
 [ 186.99485779]
 [ 156.93205261]
 [ 179.1927948 ]
 [ 152.53395081]
 [ 151.56459045]
 [ 159.10795593]
 [ 156.68058777]
 [ 157.69987488]
 [ 166.10566711]
 [ 159.32859802]
 [ 157.88043213]
 [ 161.37481689]]
DEBUG:root:training time = %d0.215094
INFO:root:frame =15329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =15330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000162839889526
INFO:root:random_action_porb = 0.878811666667
DEBUG:root: dqn, choose action rondomly, need time 0.000382000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000519037246704
INFO:root:frame =15333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =15334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042200088501
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.87878
DEBUG:root: dqn, choose action rondomly, need time 0.000334000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 153.76628113]
 [ 155.40200806]
 [ 164.99993896]
 [ 163.35411072]
 [ 183.28720093]
 [ 160.00767517]
 [ 150.75527954]
 [ 158.71170044]
 [ 160.99162292]
 [ 157.63166809]
 [ 152.08615112]
 [ 154.1100769 ]
 [ 158.23034668]
 [ 155.02560425]
 [ 167.27272034]
 [ 160.37615967]]
DEBUG:root:training time = %d0.235361
INFO:root:frame =15337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:frame =15338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.878748333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999956
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =15341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:frame =15342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000360012054443
INFO:root:frame = 15343 State into memory, numbers recorded 412 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000498056411743
INFO:root:random_action_porb = 0.878716666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15344current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 159.51046753]
 [ 152.40583801]
 [ 151.90893555]
 [ 158.85668945]
 [ 152.81752014]
 [ 154.75442505]
 [ 150.02250671]
 [ 148.13745117]
 [ 166.83961487]
 [ 155.89125061]
 [ 158.25453186]
 [ 153.07151794]
 [ 153.60133362]
 [ 148.13745117]
 [ 161.67112732]
 [ 184.68218994]]
DEBUG:root:training time = %d0.215722
INFO:root:frame =15345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =15346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000151872634888
INFO:root:random_action_porb = 0.878685
DEBUG:root: dqn, choose action rondomly, need time 0.000324999999975
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =15349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =15350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
INFO:root:frame = 15351 State into memory, numbers recorded 413 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000565052032471
INFO:root:random_action_porb = 0.878653333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15352current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 160.24864197]
 [ 151.08969116]
 [ 160.91264343]
 [ 181.29954529]
 [ 166.279953  ]
 [ 153.2286377 ]
 [ 167.99578857]
 [ 153.2286377 ]
 [ 158.57295227]
 [ 156.67944336]
 [ 161.55862427]
 [ 177.13206482]
 [ 197.47891235]
 [ 165.2399292 ]
 [ 161.57220459]
 [ 164.19534302]]
DEBUG:root:training time = %d0.23422
INFO:root:frame =15353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =15354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:random_action_porb = 0.878621666667
DEBUG:root: dqn, choose action rondomly, need time 0.000225999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:frame =15357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =15358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466823577881
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:random_action_porb = 0.87859
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000359058380127
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 177.49252319]
 [ 153.77876282]
 [ 167.82852173]
 [ 157.11521912]
 [ 188.09275818]
 [ 153.51208496]
 [ 156.75088501]
 [ 148.72155762]
 [ 162.15847778]
 [ 165.72398376]
 [ 163.87835693]
 [ 165.85011292]
 [ 166.40118408]
 [ 160.729599  ]
 [ 153.47200012]
 [ 173.44282532]]
DEBUG:root:training time = %d0.236224
INFO:root:frame =15361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =15362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000175952911377
INFO:root:random_action_porb = 0.878558333333
DEBUG:root: dqn, choose action rondomly, need time 0.000815999999986
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =15365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000522136688232
INFO:root:frame =15366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:random_action_porb = 0.878526666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340223312378
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 159.28700256]
 [ 157.87239075]
 [ 164.91488647]
 [ 139.22206116]
 [ 162.77774048]
 [ 164.4112854 ]
 [ 163.05508423]
 [ 158.3785553 ]
 [ 154.38752747]
 [ 161.3841095 ]
 [ 164.24032593]
 [ 155.58314514]
 [ 154.4087677 ]
 [ 157.16265869]
 [ 153.52871704]
 [ 158.13438416]]
DEBUG:root:training time = %d0.232094
INFO:root:frame =15369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:frame =15370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.000174999237061
INFO:root:random_action_porb = 0.878495
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322818756104
INFO:root:frame =15373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =15374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.878463333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000360012054443
INFO:root:training error  = [[ 166.88337708]
 [ 159.51316833]
 [ 163.87211609]
 [ 156.34843445]
 [ 156.68899536]
 [ 157.08348083]
 [ 153.86317444]
 [ 161.19613647]
 [ 154.16047668]
 [ 176.95625305]
 [ 163.49533081]
 [ 161.74525452]
 [ 157.16418457]
 [ 157.70831299]
 [ 174.85639954]
 [ 151.58638   ]]
DEBUG:root:training time = %d0.213428
INFO:root:frame =15377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =15378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.878431666667
INFO:root:dqn select action Tensor("ArgMax_242:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011078
INFO:root:action choosen by dqn [4]
INFO:root:frame =15380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root:frame =15381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =15382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.8784
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 166.57995605]
 [ 161.53302002]
 [ 156.88311768]
 [ 153.31817627]
 [ 173.70858765]
 [ 171.15510559]
 [ 156.58013916]
 [ 161.50393677]
 [ 160.64602661]
 [ 159.4372406 ]
 [ 180.55328369]
 [ 152.92393494]
 [ 166.17608643]
 [ 157.17337036]
 [ 160.84490967]
 [ 161.65444946]]
DEBUG:root:training time = %d0.234394
INFO:root:frame =15385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =15386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000356912612915
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.878368333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000022
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =15389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =15390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.878336666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999963
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 165.43888855]
 [ 185.08303833]
 [ 147.05447388]
 [ 156.89764404]
 [ 159.94322205]
 [ 161.01176453]
 [ 171.53541565]
 [ 160.68354797]
 [ 170.93240356]
 [ 166.5901947 ]
 [ 160.95368958]
 [ 159.68511963]
 [ 156.40568542]
 [ 158.04075623]
 [ 165.01170349]
 [ 158.37010193]]
DEBUG:root:training time = %d0.220588
INFO:root:frame =15393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:frame =15394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240087509155
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.878305
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =15397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =15398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:random_action_porb = 0.878273333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 150.54139709]
 [ 183.56329346]
 [ 187.38482666]
 [ 162.65083313]
 [ 162.04696655]
 [ 186.03793335]
 [ 162.46290588]
 [ 160.21388245]
 [ 157.69796753]
 [ 152.45179749]
 [ 158.50340271]
 [ 158.14512634]
 [ 155.61549377]
 [ 161.80308533]
 [ 158.60830688]
 [ 156.70236206]]
DEBUG:root:training time = %d0.209031
INFO:root:frame =15401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =15402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000386953353882
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.878241666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000031
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =15405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =15406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame = 15407 State into memory, numbers recorded 414 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000565052032471
INFO:root:random_action_porb = 0.87821
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15408current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 164.18518066]
 [ 171.53781128]
 [ 162.24203491]
 [ 165.23286438]
 [ 160.74507141]
 [ 160.23474121]
 [ 162.73764038]
 [ 161.40194702]
 [ 174.67807007]
 [ 136.96777344]
 [ 171.69091797]
 [ 164.58309937]
 [ 160.90180969]
 [ 167.31535339]
 [ 159.7734375 ]
 [ 163.368927  ]]
DEBUG:root:training time = %d0.223176
INFO:root:frame =15409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =15410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000238180160522
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.878178333333
DEBUG:root: dqn, choose action rondomly, need time 0.000188999999978
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000182151794434
INFO:root:frame =15413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =15414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.878146666667
INFO:root:dqn select action Tensor("ArgMax_243:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012764
INFO:root:action choosen by dqn [4]
INFO:root:frame =15416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000364780426025
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 161.32945251]
 [ 176.64988708]
 [ 151.95219421]
 [ 156.44880676]
 [ 166.7568512 ]
 [ 162.59324646]
 [ 152.79563904]
 [ 178.74127197]
 [ 195.03178406]
 [ 156.61489868]
 [ 169.71009827]
 [ 173.80473328]
 [ 178.34571838]
 [ 163.85649109]
 [ 170.23210144]
 [ 159.77961731]]
DEBUG:root:training time = %d0.214961
INFO:root:frame =15417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =15418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 9.51290130615e-05
INFO:root:random_action_porb = 0.878115
DEBUG:root: dqn, choose action rondomly, need time 0.00018399999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:frame =15421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =15422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476121902466
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.878083333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 188.82591248]
 [ 159.38446045]
 [ 162.83732605]
 [ 184.45747375]
 [ 186.74246216]
 [ 172.90267944]
 [ 166.43188477]
 [ 160.50682068]
 [ 185.82362366]
 [ 169.14523315]
 [ 166.92044067]
 [ 155.76515198]
 [ 161.58189392]
 [ 158.3351593 ]
 [ 164.85336304]
 [ 150.41374207]]
DEBUG:root:training time = %d0.228348
INFO:root:frame =15425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =15426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424861907959
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:random_action_porb = 0.878051666667
INFO:root:dqn select action Tensor("ArgMax_244:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012274
INFO:root:action choosen by dqn [4]
INFO:root:frame =15428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =15429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000366926193237
INFO:root:frame =15430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00048303604126
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.87802
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 167.60403442]
 [ 178.54425049]
 [ 174.69824219]
 [ 154.75366211]
 [ 166.50906372]
 [ 163.99206543]
 [ 169.11585999]
 [ 157.14811707]
 [ 170.99026489]
 [ 202.10473633]
 [ 201.4800415 ]
 [ 160.46157837]
 [ 161.9634552 ]
 [ 164.11050415]
 [ 169.37272644]
 [ 164.43710327]]
DEBUG:root:training time = %d0.222927
INFO:root:frame =15433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =15434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
DEBUG:root: save sample needs time = 0.000111103057861
INFO:root:random_action_porb = 0.877988333333
DEBUG:root: dqn, choose action rondomly, need time 0.000185999999985
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root:frame =15437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =15438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.877956666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 168.80090332]
 [ 171.88891602]
 [ 164.34632874]
 [ 162.88639832]
 [ 157.9981842 ]
 [ 166.13124084]
 [ 200.57052612]
 [ 145.77607727]
 [ 160.91148376]
 [ 163.311203  ]
 [ 165.56608582]
 [ 163.4793396 ]
 [ 166.5783844 ]
 [ 158.61676025]
 [ 163.70533752]
 [ 185.81031799]]
DEBUG:root:training time = %d0.217956
INFO:root:frame =15441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =15442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000328063964844
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:random_action_porb = 0.877925
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =15445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =15446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000301122665405
DEBUG:root: save sample needs time = 0.000123977661133
INFO:root:random_action_porb = 0.877893333333
DEBUG:root: dqn, choose action rondomly, need time 0.000170000000026
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00013279914856
INFO:root:training error  = [[ 165.28739929]
 [ 165.06304932]
 [ 147.50779724]
 [ 162.5309906 ]
 [ 159.11218262]
 [ 165.28739929]
 [ 169.44343567]
 [ 155.5606842 ]
 [ 172.96528625]
 [ 158.60792542]
 [ 166.25752258]
 [ 155.43890381]
 [ 171.27050781]
 [ 165.83634949]
 [ 159.70941162]
 [ 159.01327515]]
DEBUG:root:training time = %d0.233953
INFO:root:frame =15449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =15450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.877861666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000038
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =15453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =15454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000571012496948
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.87783
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 160.17254639]
 [ 171.11598206]
 [ 156.68212891]
 [ 153.49960327]
 [ 171.25494385]
 [ 164.05264282]
 [ 162.29490662]
 [ 177.41772461]
 [ 157.94294739]
 [ 192.1947937 ]
 [ 164.47036743]
 [ 160.04859924]
 [ 166.09465027]
 [ 160.97691345]
 [ 161.54776001]
 [ 171.24015808]]
DEBUG:root:training time = %d0.222845
INFO:root:frame =15457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000377893447876
INFO:root:frame =15458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.877798333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =15461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000425100326538
INFO:root:frame =15462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.877766666667
INFO:root:dqn select action Tensor("ArgMax_245:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00866600000001
INFO:root:action choosen by dqn [4]
INFO:root:frame =15464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:training error  = [[ 165.38197327]
 [ 166.72492981]
 [ 166.6764679 ]
 [ 167.85342407]
 [ 168.56230164]
 [ 161.49734497]
 [ 162.014328  ]
 [ 175.58190918]
 [ 161.47445679]
 [ 170.63607788]
 [ 165.58924866]
 [ 162.23231506]
 [ 158.52684021]
 [ 163.01533508]
 [ 151.19361877]
 [ 166.27207947]]
DEBUG:root:training time = %d0.220064
INFO:root:frame =15465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000364065170288
INFO:root:frame =15466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00034499168396
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.877735
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =15469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =15470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031590461731
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.877703333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304222106934
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 164.86628723]
 [ 160.7237854 ]
 [ 161.9420929 ]
 [ 161.9420929 ]
 [ 172.25440979]
 [ 171.41671753]
 [ 167.74234009]
 [ 156.31027222]
 [ 162.39483643]
 [ 174.51556396]
 [ 188.5324707 ]
 [ 165.07598877]
 [ 156.31027222]
 [ 180.88148499]
 [ 174.36521912]
 [ 179.41183472]]
DEBUG:root:training time = %d0.24009
INFO:root:frame =15473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =15474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259160995483
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.877671666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999976
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =15477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275850296021
INFO:root:frame =15478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.87764
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000038
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 164.67669678]
 [ 178.34205627]
 [ 171.14912415]
 [ 165.37960815]
 [ 199.41563416]
 [ 169.79956055]
 [ 189.19848633]
 [ 172.20355225]
 [ 167.04978943]
 [ 164.50050354]
 [ 178.11022949]
 [ 183.78747559]
 [ 156.79025269]
 [ 166.81518555]
 [ 214.1741333 ]
 [ 167.56492615]]
DEBUG:root:training time = %d0.24173
INFO:root:frame =15481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =15482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259160995483
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.877608333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000038
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =15485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000387907028198
INFO:root:frame =15486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame = 15487 State into memory, numbers recorded 415 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000590085983276
INFO:root:random_action_porb = 0.877576666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000031
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15488current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 194.57559204]
 [ 170.192276  ]
 [ 165.79431152]
 [ 165.16423035]
 [ 159.83015442]
 [ 168.6894989 ]
 [ 160.42098999]
 [ 167.04071045]
 [ 153.81472778]
 [ 164.49777222]
 [ 161.60012817]
 [ 168.79653931]
 [ 159.45227051]
 [ 178.00558472]
 [ 159.99533081]
 [ 168.3416748 ]]
DEBUG:root:training time = %d0.236293
INFO:root:frame =15489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =15490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000115871429443
INFO:root:random_action_porb = 0.877545
INFO:root:dqn select action Tensor("ArgMax_246:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00935600000003
INFO:root:action choosen by dqn [4]
INFO:root:frame =15492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000165224075317
INFO:root:frame =15493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =15494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000137805938721
INFO:root:random_action_porb = 0.877513333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:training error  = [[ 170.60658264]
 [ 167.58467102]
 [ 180.68452454]
 [ 188.8422699 ]
 [ 166.4515686 ]
 [ 173.54853821]
 [ 152.28567505]
 [ 171.11079407]
 [ 165.54724121]
 [ 166.80809021]
 [ 162.11340332]
 [ 164.82514954]
 [ 158.30213928]
 [ 169.78683472]
 [ 168.74380493]
 [ 172.00737   ]]
DEBUG:root:training time = %d0.237041
INFO:root:frame =15497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =15498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root:frame = 15499 State into memory, numbers recorded 416 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000813961029053
INFO:root:random_action_porb = 0.877481666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15500current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =15501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488996505737
INFO:root:frame =15502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.00011420249939
INFO:root:random_action_porb = 0.87745
DEBUG:root: dqn, choose action rondomly, need time 0.000216000000023
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 160.66847229]
 [ 164.92507935]
 [ 178.36650085]
 [ 178.3815918 ]
 [ 174.21131897]
 [ 137.79190063]
 [ 192.88673401]
 [ 164.89529419]
 [ 166.68946838]
 [ 152.98959351]
 [ 170.27072144]
 [ 156.28318787]
 [ 193.79650879]
 [ 172.11465454]
 [ 169.58686829]
 [ 166.72612   ]]
DEBUG:root:training time = %d0.212839
INFO:root:frame =15505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =15506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000315189361572
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:random_action_porb = 0.877418333333
DEBUG:root: dqn, choose action rondomly, need time 0.000274000000047
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000187873840332
INFO:root:frame =15509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000487804412842
INFO:root:frame =15510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.877386666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000022
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 163.52577209]
 [ 158.53144836]
 [ 163.34747314]
 [ 167.18391418]
 [ 167.90126038]
 [ 166.20046997]
 [ 174.12312317]
 [ 167.23561096]
 [ 180.93156433]
 [ 176.32391357]
 [ 165.88508606]
 [ 186.15907288]
 [ 164.43397522]
 [ 164.27082825]
 [ 177.40309143]
 [ 149.36274719]]
DEBUG:root:training time = %d0.242109
INFO:root:frame =15513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =15514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:frame = 15515 State into memory, numbers recorded 417 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000602006912231
INFO:root:random_action_porb = 0.877355
DEBUG:root: dqn, choose action rondomly, need time 0.00027799999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15516current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root:frame =15517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000480175018311
INFO:root:frame =15518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.877323333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 159.00941467]
 [ 203.80158997]
 [ 158.40812683]
 [ 166.92832947]
 [ 166.41456604]
 [ 173.10256958]
 [ 167.07542419]
 [ 164.8368988 ]
 [ 190.68063354]
 [ 169.87631226]
 [ 165.20541382]
 [ 191.63673401]
 [ 174.16056824]
 [ 166.89086914]
 [ 167.07542419]
 [ 163.68424988]]
DEBUG:root:training time = %d0.232195
INFO:root:frame =15521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =15522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.877291666667
INFO:root:dqn select action Tensor("ArgMax_247:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.009412
INFO:root:action choosen by dqn [4]
INFO:root:frame =15524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:frame =15525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =15526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame = 15527 State into memory, numbers recorded 418 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.000726222991943
INFO:root:random_action_porb = 0.87726
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15528current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000188827514648
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 181.32337952]
 [ 172.01097107]
 [ 177.52952576]
 [ 174.7059021 ]
 [ 171.66493225]
 [ 164.14764404]
 [ 175.89503479]
 [ 175.77890015]
 [ 214.22280884]
 [ 135.64628601]
 [ 167.16577148]
 [ 171.48625183]
 [ 168.13861084]
 [ 165.0171814 ]
 [ 158.24108887]
 [ 168.82588196]]
DEBUG:root:training time = %d0.248745
INFO:root:frame =15529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =15530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000251054763794
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.877228333333
DEBUG:root: dqn, choose action rondomly, need time 0.000181999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163793563843
INFO:root:frame =15533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =15534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.877196666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 167.12001038]
 [ 194.42790222]
 [ 157.65811157]
 [ 167.00601196]
 [ 210.10533142]
 [ 164.19338989]
 [ 162.59907532]
 [ 193.24971008]
 [ 169.09840393]
 [ 163.72447205]
 [ 164.94702148]
 [ 169.56303406]
 [ 165.15873718]
 [ 170.34957886]
 [ 168.30010986]
 [ 167.89138794]]
DEBUG:root:training time = %d0.233673
INFO:root:frame =15537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =15538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000347852706909
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.877165
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =15541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =15542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.877133333333
DEBUG:root: dqn, choose action rondomly, need time 0.000319999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 162.92807007]
 [ 163.11782837]
 [ 168.04641724]
 [ 162.31163025]
 [ 208.87385559]
 [ 164.59759521]
 [ 167.90126038]
 [ 174.96376038]
 [ 172.57498169]
 [ 166.14028931]
 [ 169.41920471]
 [ 177.7975769 ]
 [ 176.47956848]
 [ 197.26583862]
 [ 164.38232422]
 [ 165.84265137]]
DEBUG:root:training time = %d0.210806
INFO:root:frame =15545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =15546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.877101666667
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =15549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame =15550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.87707
INFO:root:dqn select action Tensor("ArgMax_248:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010326
INFO:root:action choosen by dqn [4]
INFO:root:frame =15552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162839889526
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 174.33540344]
 [ 179.96286011]
 [ 182.39093018]
 [ 169.55070496]
 [ 185.80906677]
 [ 159.884552  ]
 [ 186.94145203]
 [ 171.60696411]
 [ 174.972229  ]
 [ 159.16415405]
 [ 174.18353271]
 [ 167.81230164]
 [ 196.29063416]
 [ 149.34446716]
 [ 169.79797363]
 [ 171.62974548]]
DEBUG:root:training time = %d0.236092
INFO:root:frame =15553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =15554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000329971313477
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:random_action_porb = 0.877038333333
DEBUG:root: dqn, choose action rondomly, need time 0.000249000000053
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000141143798828
INFO:root:frame =15557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:frame =15558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000490188598633
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:random_action_porb = 0.877006666667
INFO:root:dqn select action Tensor("ArgMax_249:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014564
INFO:root:action choosen by dqn [4]
INFO:root:frame =15560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000157117843628
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 161.15623474]
 [ 163.7026062 ]
 [ 162.39834595]
 [ 170.62690735]
 [ 170.02033997]
 [ 177.66941833]
 [ 167.9776001 ]
 [ 179.62159729]
 [ 197.49736023]
 [ 175.68746948]
 [ 168.81080627]
 [ 158.04574585]
 [ 163.89788818]
 [ 179.77418518]
 [ 174.33660889]
 [ 176.60202026]]
DEBUG:root:training time = %d0.232602
INFO:root:frame =15561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =15562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000260829925537
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.876975
INFO:root:dqn select action Tensor("ArgMax_250:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01211
INFO:root:action choosen by dqn [4]
INFO:root:frame =15564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root:frame =15565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:frame =15566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.876943333333
INFO:root:dqn select action Tensor("ArgMax_251:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015174
INFO:root:action choosen by dqn [4]
INFO:root:frame =15568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174045562744
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 170.71502686]
 [ 170.0692749 ]
 [ 175.1171875 ]
 [ 200.77154541]
 [ 170.58744812]
 [ 165.33683777]
 [ 165.44320679]
 [ 167.26916504]
 [ 166.19732666]
 [ 159.76341248]
 [ 169.86677551]
 [ 168.38444519]
 [ 171.92652893]
 [ 184.4707489 ]
 [ 176.41957092]
 [ 166.19142151]]
DEBUG:root:training time = %d0.238761
INFO:root:frame =15569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =15570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000278949737549
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:random_action_porb = 0.876911666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =15573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =15574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482797622681
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:random_action_porb = 0.87688
DEBUG:root: dqn, choose action rondomly, need time 0.000352999999961
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 165.87094116]
 [ 164.3651123 ]
 [ 168.07925415]
 [ 171.77090454]
 [ 163.81352234]
 [ 166.69696045]
 [ 167.55148315]
 [ 165.36549377]
 [ 173.26281738]
 [ 164.26574707]
 [ 163.33538818]
 [ 195.85391235]
 [ 168.81477356]
 [ 172.35496521]
 [ 159.40757751]
 [ 163.04533386]]
DEBUG:root:training time = %d0.231096
INFO:root:frame =15577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =15578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248908996582
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.876848333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =15581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491142272949
INFO:root:frame =15582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.876816666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 159.30548096]
 [ 161.51208496]
 [ 165.92282104]
 [ 169.68624878]
 [ 171.2908783 ]
 [ 179.24549866]
 [ 170.62492371]
 [ 172.14268494]
 [ 174.24757385]
 [ 208.82269287]
 [ 175.69596863]
 [ 200.39337158]
 [ 166.93463135]
 [ 168.31791687]
 [ 166.6721344 ]
 [ 162.2855835 ]]
DEBUG:root:training time = %d0.225748
INFO:root:frame =15585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =15586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000325918197632
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.876785
DEBUG:root: dqn, choose action rondomly, need time 0.000327000000027
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:frame =15589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =15590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.876753333333
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999954
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 165.87054443]
 [ 157.9835968 ]
 [ 193.76550293]
 [ 161.44692993]
 [ 169.64013672]
 [ 169.77331543]
 [ 196.10340881]
 [ 173.4528656 ]
 [ 172.0309906 ]
 [ 168.0650177 ]
 [ 174.77851868]
 [ 164.745224  ]
 [ 170.87416077]
 [ 181.22271729]
 [ 165.92832947]
 [ 171.98495483]]
DEBUG:root:training time = %d0.237258
INFO:root:frame =15593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =15594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.876721666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =15597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =15598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.87669
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:training error  = [[ 171.15989685]
 [ 171.25494385]
 [ 168.74935913]
 [ 177.45999146]
 [ 186.71076965]
 [ 182.1350708 ]
 [ 175.59849548]
 [ 169.2698822 ]
 [ 179.58151245]
 [ 178.3840332 ]
 [ 173.56341553]
 [ 169.08808899]
 [ 165.76248169]
 [ 169.08808899]
 [ 174.1468811 ]
 [ 174.82087708]]
DEBUG:root:training time = %d0.237924
INFO:root:frame =15601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =15602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.876658333333
INFO:root:dqn select action Tensor("ArgMax_252:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011064
INFO:root:action choosen by dqn [4]
INFO:root:frame =15604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =15605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame =15606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000304937362671
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.876626666667
DEBUG:root: dqn, choose action rondomly, need time 0.000317999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 173.71139526]
 [ 172.04418945]
 [ 149.10774231]
 [ 171.75370789]
 [ 196.86698914]
 [ 174.76600647]
 [ 179.34030151]
 [ 176.25180054]
 [ 165.87841797]
 [ 169.12379456]
 [ 200.03236389]
 [ 200.18173218]
 [ 171.80610657]
 [ 172.48840332]
 [ 169.53839111]
 [ 165.85679626]]
DEBUG:root:training time = %d0.218746
INFO:root:frame =15609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =15610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.876595
DEBUG:root: dqn, choose action rondomly, need time 0.000563999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =15613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000492095947266
INFO:root:frame =15614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000490188598633
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.876563333333
DEBUG:root: dqn, choose action rondomly, need time 0.00032299999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:training error  = [[ 172.41546631]
 [ 167.48907471]
 [ 169.75462341]
 [ 160.11424255]
 [ 158.7278595 ]
 [ 176.42645264]
 [ 167.26876831]
 [ 167.31889343]
 [ 179.90309143]
 [ 186.29318237]
 [ 176.2258606 ]
 [ 166.35316467]
 [ 179.29658508]
 [ 181.73703003]
 [ 178.76696777]
 [ 174.17225647]]
DEBUG:root:training time = %d0.235984
INFO:root:frame =15617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =15618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:random_action_porb = 0.876531666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304000000028
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =15621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =15622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame = 15623 State into memory, numbers recorded 419 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000627040863037
INFO:root:random_action_porb = 0.8765
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15624current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000351905822754
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 177.04638672]
 [ 183.53022766]
 [ 181.2268219 ]
 [ 186.03668213]
 [ 178.55892944]
 [ 174.26972961]
 [ 199.49493408]
 [ 170.77404785]
 [ 180.32167053]
 [ 161.47445679]
 [ 186.78668213]
 [ 162.67185974]
 [ 172.14347839]
 [ 170.74971008]
 [ 203.96412659]
 [ 174.51435852]]
DEBUG:root:training time = %d0.234768
INFO:root:frame =15625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =15626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00048303604126
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.876468333333
DEBUG:root: dqn, choose action rondomly, need time 0.000339999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =15629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =15630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.876436666667
DEBUG:root: dqn, choose action rondomly, need time 0.000327000000027
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 165.92715454]
 [ 165.97982788]
 [ 196.35862732]
 [ 165.35018921]
 [ 176.72167969]
 [ 177.08129883]
 [ 167.17878723]
 [ 193.27983093]
 [ 157.20550537]
 [ 175.32400513]
 [ 168.58726501]
 [ 200.17698669]
 [ 176.27407837]
 [ 185.54333496]
 [ 177.8394928 ]
 [ 193.27983093]]
DEBUG:root:training time = %d0.222104
INFO:root:frame =15633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =15634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441789627075
INFO:root:frame = 15635 State into memory, numbers recorded 420 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000550985336304
INFO:root:random_action_porb = 0.876405
DEBUG:root: dqn, choose action rondomly, need time 0.000311999999951
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15636current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =15637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =15638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:random_action_porb = 0.876373333333
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:training error  = [[ 181.23135376]
 [ 178.42112732]
 [ 171.47825623]
 [ 175.22058105]
 [ 170.40454102]
 [ 167.68701172]
 [ 172.04859924]
 [ 185.64645386]
 [ 175.88491821]
 [ 179.60891724]
 [ 171.72012329]
 [ 180.96850586]
 [ 180.91925049]
 [ 184.07345581]
 [ 179.28022766]
 [ 171.06329346]]
DEBUG:root:training time = %d0.219521
INFO:root:frame =15641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:frame =15642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000260829925537
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.876341666667
DEBUG:root: dqn, choose action rondomly, need time 0.000170000000026
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000137805938721
INFO:root:frame =15645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000481843948364
INFO:root:frame =15646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame = 15647 State into memory, numbers recorded 421 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00058388710022
INFO:root:random_action_porb = 0.87631
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000046
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15648current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 196.60801697]
 [ 178.87634277]
 [ 177.79269409]
 [ 177.7276001 ]
 [ 174.97747803]
 [ 181.93496704]
 [ 169.28338623]
 [ 181.07115173]
 [ 173.83329773]
 [ 182.90357971]
 [ 149.77253723]
 [ 181.93579102]
 [ 158.86437988]
 [ 181.79914856]
 [ 176.03146362]
 [ 176.65718079]]
DEBUG:root:training time = %d0.211574
INFO:root:frame =15649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =15650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000579118728638
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.876278333333
DEBUG:root: dqn, choose action rondomly, need time 0.000464999999963
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root:frame =15653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =15654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:random_action_porb = 0.876246666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000041
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 176.09057617]
 [ 200.73609924]
 [ 183.26242065]
 [ 182.64778137]
 [ 181.37187195]
 [ 170.3535614 ]
 [ 177.96446228]
 [ 172.84410095]
 [ 182.55581665]
 [ 177.03663635]
 [ 167.69767761]
 [ 177.00253296]
 [ 182.74142456]
 [ 156.24084473]
 [ 170.46710205]
 [ 175.99624634]]
DEBUG:root:training time = %d0.255654
INFO:root: ememy has been killed for 31 times 
INFO:root:enemies_left [0]
INFO:root:frame =15657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =15658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269174575806
INFO:root:frame = 15659 State into memory, numbers recorded 422 action = 0, reward = 1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:random_action_porb = 0.876215
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15660current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =15661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =15662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.876183333333
INFO:root:dqn select action Tensor("ArgMax_253:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011723
INFO:root:action choosen by dqn [4]
INFO:root:frame =15664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 192.98295593]
 [ 168.83421326]
 [ 174.52565002]
 [ 172.24038696]
 [ 177.38682556]
 [ 180.7575531 ]
 [ 207.16387939]
 [ 171.54100037]
 [ 179.61914062]
 [ 172.8493042 ]
 [ 164.99209595]
 [ 181.99754333]
 [ 170.94436646]
 [ 164.21060181]
 [ 178.60093689]
 [ 167.05728149]]
DEBUG:root:training time = %d0.233888
INFO:root:frame =15665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =15666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame = 15667 State into memory, numbers recorded 423 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.0012629032135
INFO:root:random_action_porb = 0.876151666667
INFO:root:dqn select action Tensor("ArgMax_254:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00965199999996
INFO:root:action choosen by dqn [4]
INFO:root:frame =15668current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000392913818359
INFO:root:frame =15669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =15670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame = 15671 State into memory, numbers recorded 424 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00122594833374
INFO:root:random_action_porb = 0.87612
DEBUG:root: dqn, choose action rondomly, need time 0.000171000000023
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15672current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000135183334351
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 194.7539978 ]
 [ 208.69041443]
 [ 173.38093567]
 [ 182.61685181]
 [ 178.15258789]
 [ 172.47276306]
 [ 176.18009949]
 [ 179.71118164]
 [ 176.28379822]
 [ 173.74398804]
 [ 181.83413696]
 [ 181.20957947]
 [ 172.73338318]
 [ 181.98147583]
 [ 186.9618988 ]
 [ 192.05055237]]
DEBUG:root:training time = %d0.221424
INFO:root:frame =15673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =15674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249862670898
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.876088333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000022
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =15677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =15678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475168228149
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.876056666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:training error  = [[ 180.74073792]
 [ 180.87327576]
 [ 176.2635498 ]
 [ 175.17008972]
 [ 171.31285095]
 [ 175.3187561 ]
 [ 175.9934082 ]
 [ 167.09831238]
 [ 174.13963318]
 [ 174.43212891]
 [ 182.80537415]
 [ 176.9172821 ]
 [ 181.01531982]
 [ 176.1651001 ]
 [ 171.21540833]
 [ 175.75866699]]
DEBUG:root:training time = %d0.224641
INFO:root:frame =15681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =15682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.876025
DEBUG:root: dqn, choose action rondomly, need time 0.000342999999987
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =15685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000425815582275
INFO:root:frame =15686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488042831421
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.875993333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 167.58901978]
 [ 197.54496765]
 [ 182.80990601]
 [ 214.33673096]
 [ 180.15942383]
 [ 174.51274109]
 [ 181.73620605]
 [ 179.68254089]
 [ 179.40080261]
 [ 180.62013245]
 [ 198.3865509 ]
 [ 173.38696289]
 [ 151.9315033 ]
 [ 176.50430298]
 [ 186.61987305]
 [ 186.39190674]]
DEBUG:root:training time = %d0.22706
INFO:root:frame =15689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =15690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 9.67979431152e-05
INFO:root:random_action_porb = 0.875961666667
DEBUG:root: dqn, choose action rondomly, need time 0.000175000000013
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:frame =15693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =15694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
INFO:root:frame = 15695 State into memory, numbers recorded 425 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000563859939575
INFO:root:random_action_porb = 0.87593
DEBUG:root: dqn, choose action rondomly, need time 0.000411999999983
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15696current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 191.60462952]
 [ 184.06600952]
 [ 179.44821167]
 [ 191.60462952]
 [ 172.38059998]
 [ 198.4140625 ]
 [ 174.39343262]
 [ 165.43025208]
 [ 190.55506897]
 [ 174.52806091]
 [ 195.98077393]
 [ 172.07821655]
 [ 181.04405212]
 [ 183.67536926]
 [ 184.02294922]
 [ 181.84277344]]
DEBUG:root:training time = %d0.233433
INFO:root:frame =15697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =15698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288009643555
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:random_action_porb = 0.875898333333
DEBUG:root: dqn, choose action rondomly, need time 0.000393999999972
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000359058380127
INFO:root:frame =15701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000510931015015
INFO:root:frame =15702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.875866666667
DEBUG:root: dqn, choose action rondomly, need time 0.000308999999959
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 187.18937683]
 [ 185.16773987]
 [ 180.82403564]
 [ 163.01495361]
 [ 184.46038818]
 [ 198.26579285]
 [ 179.8351593 ]
 [ 177.67999268]
 [ 179.51281738]
 [ 175.72103882]
 [ 202.51449585]
 [ 165.52053833]
 [ 195.35752869]
 [ 188.26104736]
 [ 177.82118225]
 [ 179.88876343]]
DEBUG:root:training time = %d0.219676
INFO:root:frame =15705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =15706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000281095504761
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.875835
INFO:root:dqn select action Tensor("ArgMax_255:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01388
INFO:root:action choosen by dqn [4]
INFO:root:frame =15708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:frame =15709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =15710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.875803333333
DEBUG:root: dqn, choose action rondomly, need time 0.000525999999979
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:training error  = [[ 188.385849  ]
 [ 182.07783508]
 [ 180.52745056]
 [ 174.74987793]
 [ 174.42889404]
 [ 175.03965759]
 [ 190.63891602]
 [ 170.6504364 ]
 [ 175.60739136]
 [ 176.02700806]
 [ 171.13356018]
 [ 176.36891174]
 [ 175.02713013]
 [ 181.88392639]
 [ 182.5925293 ]
 [ 183.34794617]]
DEBUG:root:training time = %d0.235613
INFO:root:frame =15713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000383138656616
INFO:root:frame =15714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.875771666667
DEBUG:root: dqn, choose action rondomly, need time 0.000540999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =15717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =15718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000270128250122
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.87574
DEBUG:root: dqn, choose action rondomly, need time 0.00055599999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 215.71862793]
 [ 172.21716309]
 [ 174.33903503]
 [ 183.56536865]
 [ 177.47666931]
 [ 174.92823792]
 [ 176.84138489]
 [ 184.06973267]
 [ 173.70497131]
 [ 184.60920715]
 [ 176.98791504]
 [ 182.42266846]
 [ 173.76087952]
 [ 184.73486328]
 [ 188.7013855 ]
 [ 180.06809998]]
DEBUG:root:training time = %d0.224591
INFO:root:frame =15721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000377893447876
INFO:root:frame =15722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.875708333333
DEBUG:root: dqn, choose action rondomly, need time 0.000327000000027
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =15725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =15726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.875676666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 173.83732605]
 [ 177.74752808]
 [ 187.01196289]
 [ 179.86134338]
 [ 189.31057739]
 [ 198.34916687]
 [ 182.73316956]
 [ 181.60621643]
 [ 178.33837891]
 [ 180.78135681]
 [ 178.08009338]
 [ 182.73316956]
 [ 174.64620972]
 [ 186.07746887]
 [ 179.75985718]
 [ 179.21322632]]
DEBUG:root:training time = %d0.249414
INFO:root:frame =15729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =15730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000325918197632
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.875645
INFO:root:dqn select action Tensor("ArgMax_256:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010773
INFO:root:action choosen by dqn [4]
INFO:root:frame =15732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =15733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:frame =15734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.875613333333
DEBUG:root: dqn, choose action rondomly, need time 0.000174000000015
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000131130218506
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 176.5209198 ]
 [ 177.68447876]
 [ 148.6434021 ]
 [ 186.54568481]
 [ 183.22276306]
 [ 198.74090576]
 [ 181.86540222]
 [ 184.08546448]
 [ 191.18792725]
 [ 171.98976135]
 [ 187.12591553]
 [ 174.16983032]
 [ 189.17120361]
 [ 179.34928894]
 [ 180.51843262]
 [ 177.57710266]]
DEBUG:root:training time = %d0.213765
INFO:root:frame =15737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =15738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000399112701416
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:random_action_porb = 0.875581666667
DEBUG:root: dqn, choose action rondomly, need time 0.000308999999959
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =15741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000516176223755
INFO:root:frame =15742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00054407119751
DEBUG:root: save sample needs time = 0.000285148620605
INFO:root:random_action_porb = 0.87555
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000038
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 172.08743286]
 [ 190.52305603]
 [ 186.69450378]
 [ 174.20205688]
 [ 207.00709534]
 [ 182.1577301 ]
 [ 206.17149353]
 [ 181.20710754]
 [ 171.36238098]
 [ 181.75430298]
 [ 177.68365479]
 [ 164.71311951]
 [ 177.36894226]
 [ 187.52522278]
 [ 180.25856018]
 [ 187.09628296]]
DEBUG:root:training time = %d0.217311
INFO:root:frame =15745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =15746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.875518333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =15749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =15750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.875486666667
DEBUG:root: dqn, choose action rondomly, need time 0.000398999999959
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000385046005249
INFO:root:training error  = [[ 179.79995728]
 [ 185.1569519 ]
 [ 175.80924988]
 [ 181.59100342]
 [ 175.55117798]
 [ 181.54577637]
 [ 177.86717224]
 [ 173.68203735]
 [ 181.92549133]
 [ 181.36077881]
 [ 169.86955261]
 [ 173.47618103]
 [ 184.79916382]
 [ 179.79995728]
 [ 182.19067383]
 [ 180.71652222]]
DEBUG:root:training time = %d0.22136
INFO:root:frame =15753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =15754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000270128250122
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:random_action_porb = 0.875455
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =15757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000508069992065
INFO:root:frame =15758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000527858734131
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:random_action_porb = 0.875423333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000018
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:training error  = [[ 183.11454773]
 [ 177.85862732]
 [ 178.74942017]
 [ 192.76637268]
 [ 199.26998901]
 [ 184.05151367]
 [ 174.05627441]
 [ 195.11616516]
 [ 178.98207092]
 [ 187.18478394]
 [ 169.61509705]
 [ 177.4937439 ]
 [ 176.02093506]
 [ 175.00613403]
 [ 183.91532898]
 [ 184.92323303]]
DEBUG:root:training time = %d0.222731
INFO:root:frame =15761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =15762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 0.000125169754028
INFO:root:random_action_porb = 0.875391666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000346899032593
INFO:root:frame =15765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =15766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000514030456543
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.87536
DEBUG:root: dqn, choose action rondomly, need time 0.000342999999987
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:training error  = [[ 183.08192444]
 [ 188.07852173]
 [ 166.55435181]
 [ 182.55581665]
 [ 183.16120911]
 [ 191.58647156]
 [ 186.07122803]
 [ 182.54428101]
 [ 174.75027466]
 [ 187.63891602]
 [ 181.03829956]
 [ 180.30528259]
 [ 178.08946228]
 [ 191.30819702]
 [ 185.57452393]
 [ 178.98738098]]
DEBUG:root:training time = %d0.215367
INFO:root:frame =15769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root:frame =15770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000320911407471
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.875328333333
INFO:root:dqn select action Tensor("ArgMax_257:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01127
INFO:root:action choosen by dqn [4]
INFO:root:frame =15772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root:frame =15773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000543117523193
INFO:root:frame =15774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485897064209
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.875296666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:training error  = [[ 178.03041077]
 [ 175.86427307]
 [ 179.25      ]
 [ 178.87878418]
 [ 187.84422302]
 [ 184.93940735]
 [ 174.80232239]
 [ 199.27215576]
 [ 205.4854126 ]
 [ 190.50367737]
 [ 177.58035278]
 [ 189.40884399]
 [ 176.46092224]
 [ 179.04862976]
 [ 188.31547546]
 [ 180.05212402]]
DEBUG:root:training time = %d0.226078
INFO:root:frame =15777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =15778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248193740845
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.875265
DEBUG:root: dqn, choose action rondomly, need time 0.00028599999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =15781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =15782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.875233333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304000000028
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000393867492676
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 211.43669128]
 [ 217.43423462]
 [ 182.41731262]
 [ 179.82983398]
 [ 184.68095398]
 [ 177.13206482]
 [ 178.30700684]
 [ 181.59059143]
 [ 179.59378052]
 [ 179.97227478]
 [ 193.40501404]
 [ 177.80245972]
 [ 182.13630676]
 [ 178.46351624]
 [ 198.91001892]
 [ 176.74520874]]
DEBUG:root:training time = %d0.230135
INFO:root:frame =15785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =15786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.875201666667
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =15789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =15790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491857528687
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.87517
DEBUG:root: dqn, choose action rondomly, need time 0.000320999999985
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 191.81843567]
 [ 184.00598145]
 [ 187.62260437]
 [ 181.18574524]
 [ 179.84703064]
 [ 177.09429932]
 [ 228.50582886]
 [ 185.48556519]
 [ 180.62136841]
 [ 178.74739075]
 [ 182.68449402]
 [ 184.06352234]
 [ 180.84742737]
 [ 178.74739075]
 [ 194.15693665]
 [ 182.83879089]]
DEBUG:root:training time = %d0.23377
INFO:root:frame =15793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000364065170288
INFO:root:frame =15794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.875138333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =15797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame =15798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.875106666667
DEBUG:root: dqn, choose action rondomly, need time 0.00028999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 221.60803223]
 [ 178.03082275]
 [ 182.56942749]
 [ 179.37626648]
 [ 193.26115417]
 [ 178.05851746]
 [ 177.57344055]
 [ 183.74899292]
 [ 180.23562622]
 [ 185.53004456]
 [ 185.56661987]
 [ 178.87878418]
 [ 165.11834717]
 [ 185.54750061]
 [ 162.50491333]
 [ 179.05555725]]
DEBUG:root:training time = %d0.224363
INFO:root:frame =15801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =15802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.875075
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =15805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =15806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:random_action_porb = 0.875043333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000022
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 217.50398254]
 [ 190.70001221]
 [ 198.91604614]
 [ 178.16888428]
 [ 217.32038879]
 [ 170.30815125]
 [ 198.37838745]
 [ 190.31628418]
 [ 199.51390076]
 [ 172.97973633]
 [ 180.51269531]
 [ 177.75689697]
 [ 177.40592957]
 [ 185.5242157 ]
 [ 208.7649231 ]
 [ 182.37980652]]
DEBUG:root:training time = %d0.220835
INFO:root:frame =15809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =15810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000258922576904
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.875011666667
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =15813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488996505737
INFO:root:frame =15814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:random_action_porb = 0.87498
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000033
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:training error  = [[ 178.58666992]
 [ 180.55943298]
 [ 180.56394958]
 [ 193.67289734]
 [ 189.56510925]
 [ 183.55419922]
 [ 176.8722229 ]
 [ 180.55943298]
 [ 175.32400513]
 [ 179.76681519]
 [ 179.00288391]
 [ 173.77375793]
 [ 191.48214722]
 [ 174.00634766]
 [ 196.41592407]
 [ 186.02502441]]
DEBUG:root:training time = %d0.215584
INFO:root:frame =15817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249147415161
INFO:root:frame =15818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:random_action_porb = 0.874948333333
DEBUG:root: dqn, choose action rondomly, need time 0.000181999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:frame =15821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =15822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame = 15823 State into memory, numbers recorded 426 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000545024871826
INFO:root:random_action_porb = 0.874916666667
DEBUG:root: dqn, choose action rondomly, need time 0.000365999999985
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15824current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 183.28514099]
 [ 185.8140564 ]
 [ 215.4573822 ]
 [ 182.29943848]
 [ 185.8140564 ]
 [ 189.51091003]
 [ 186.47691345]
 [ 183.6914978 ]
 [ 189.36222839]
 [ 186.8671875 ]
 [ 167.43182373]
 [ 185.02824402]
 [ 191.50959778]
 [ 215.4573822 ]
 [ 194.73057556]
 [ 166.70996094]]
DEBUG:root:training time = %d0.230412
INFO:root:frame =15825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280141830444
INFO:root:frame =15826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000517129898071
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.874885
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =15829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =15830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.874853333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 236.31930542]
 [ 172.79956055]
 [ 187.6234436 ]
 [ 183.29341125]
 [ 193.34898376]
 [ 212.56266785]
 [ 162.6084137 ]
 [ 182.43873596]
 [ 216.2258606 ]
 [ 198.89881897]
 [ 181.25888062]
 [ 182.67417908]
 [ 176.14039612]
 [ 170.01316833]
 [ 186.35316467]
 [ 182.0852356 ]]
DEBUG:root:training time = %d0.245594
INFO:root:frame =15833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =15834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.874821666667
DEBUG:root: dqn, choose action rondomly, need time 0.000342999999987
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =15837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =15838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame = 15839 State into memory, numbers recorded 427 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000572919845581
INFO:root:random_action_porb = 0.87479
INFO:root:dqn select action Tensor("ArgMax_258:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012441
INFO:root:action choosen by dqn [4]
INFO:root:frame =15840current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000900030136108
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 193.48225403]
 [ 181.56263733]
 [ 188.70767212]
 [ 201.06959534]
 [ 180.95454407]
 [ 196.92222595]
 [ 215.29974365]
 [ 182.2565918 ]
 [ 188.39422607]
 [ 175.93955994]
 [ 180.72555542]
 [ 186.88845825]
 [ 221.43997192]
 [ 185.95593262]
 [ 211.35594177]
 [ 194.64413452]]
DEBUG:root:training time = %d0.211248
INFO:root:frame =15841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame =15842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.874758333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000022
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =15845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =15846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.874726666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 190.9740448 ]
 [ 192.91725159]
 [ 211.43403625]
 [ 183.88346863]
 [ 191.9528656 ]
 [ 187.61508179]
 [ 189.0599823 ]
 [ 197.25039673]
 [ 217.08921814]
 [ 197.27183533]
 [ 190.0843811 ]
 [ 200.81263733]
 [ 186.94770813]
 [ 184.34559631]
 [ 196.98817444]
 [ 185.21923828]]
DEBUG:root:training time = %d0.238381
INFO:root:frame =15849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =15850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000538110733032
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.874695
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =15853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =15854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.874663333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999965
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320196151733
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 175.47113037]
 [ 183.84870911]
 [ 182.82888794]
 [ 182.82888794]
 [ 196.46939087]
 [ 205.88938904]
 [ 167.08291626]
 [ 189.23205566]
 [ 201.84407043]
 [ 186.60070801]
 [ 180.67961121]
 [ 178.26341248]
 [ 185.26824951]
 [ 213.31347656]
 [ 188.8921814 ]
 [ 193.11058044]]
DEBUG:root:training time = %d0.225319
INFO:root:frame =15857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000346183776855
INFO:root:frame =15858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.874631666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =15861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =15862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.8746
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 227.70523071]
 [ 190.74975586]
 [ 191.59533691]
 [ 195.83853149]
 [ 168.22409058]
 [ 181.72221375]
 [ 195.83853149]
 [ 196.85371399]
 [ 191.44076538]
 [ 188.38835144]
 [ 188.93998718]
 [ 189.23374939]
 [ 186.95355225]
 [ 199.10546875]
 [ 178.55770874]
 [ 190.09700012]]
DEBUG:root:training time = %d0.22559
INFO:root:frame =15865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =15866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000317096710205
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.874568333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =15869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488042831421
INFO:root:frame =15870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000557899475098
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.874536666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999976
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:training error  = [[ 197.27183533]
 [ 189.38322449]
 [ 191.4145813 ]
 [ 200.60597229]
 [ 195.09101868]
 [ 188.72695923]
 [ 193.18437195]
 [ 187.89190674]
 [ 182.90565491]
 [ 196.72698975]
 [ 185.45523071]
 [ 194.69055176]
 [ 192.04928589]
 [ 198.52111816]
 [ 186.05915833]
 [ 206.10926819]]
DEBUG:root:training time = %d0.235855
INFO:root:frame =15873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =15874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.874505
DEBUG:root: dqn, choose action rondomly, need time 0.000184999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162124633789
INFO:root:frame =15877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456809997559
INFO:root:frame =15878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:random_action_porb = 0.874473333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:training error  = [[ 186.3081665 ]
 [ 186.64990234]
 [ 188.47381592]
 [ 199.52166748]
 [ 194.83450317]
 [ 196.60031128]
 [ 187.92118835]
 [ 193.40925598]
 [ 182.05888367]
 [ 190.28808594]
 [ 192.1051178 ]
 [ 185.87104797]
 [ 195.1506958 ]
 [ 191.81420898]
 [ 185.64228821]
 [ 173.84898376]]
DEBUG:root:training time = %d0.231034
INFO:root:frame =15881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266790390015
INFO:root:frame =15882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000115871429443
INFO:root:random_action_porb = 0.874441666667
DEBUG:root: dqn, choose action rondomly, need time 0.000174000000015
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:frame =15885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame =15886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:random_action_porb = 0.87441
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000041
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 184.70625305]
 [ 182.04901123]
 [ 184.00598145]
 [ 215.97911072]
 [ 195.9239502 ]
 [ 188.72528076]
 [ 198.23570251]
 [ 200.43569946]
 [ 220.98516846]
 [ 197.23840332]
 [ 189.48739624]
 [ 184.70625305]
 [ 207.80126953]
 [ 197.16040039]
 [ 184.70625305]
 [ 198.8420105 ]]
DEBUG:root:training time = %d0.222813
INFO:root:frame =15889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:frame =15890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000282049179077
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.874378333333
DEBUG:root: dqn, choose action rondomly, need time 0.000205999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root:frame =15893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00048303604126
INFO:root:frame =15894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000406980514526
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:random_action_porb = 0.874346666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =15896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 187.42619324]
 [ 185.23834229]
 [ 203.3966217 ]
 [ 193.51452637]
 [ 234.09336853]
 [ 183.30207825]
 [ 195.52604675]
 [ 188.77810669]
 [ 185.51174927]
 [ 192.44026184]
 [ 197.99087524]
 [ 194.0693512 ]
 [ 184.70127869]
 [ 204.27238464]
 [ 197.51794434]
 [ 184.60671997]]
DEBUG:root:training time = %d0.233463
INFO:root:frame =15897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =15898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232219696045
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:random_action_porb = 0.874315
DEBUG:root: dqn, choose action rondomly, need time 0.000325999999973
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =15901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =15902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.874283333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999965
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:training error  = [[ 191.94271851]
 [ 196.88197327]
 [ 193.23867798]
 [ 191.6663208 ]
 [ 198.8523407 ]
 [ 178.41583252]
 [ 193.59094238]
 [ 190.29986572]
 [ 191.52522278]
 [ 192.45889282]
 [ 183.29547119]
 [ 188.00320435]
 [ 179.34153748]
 [ 184.33398438]
 [ 197.88525391]
 [ 188.3188324 ]]
DEBUG:root:training time = %d0.240385
INFO:root:frame =15905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =15906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268220901489
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.874251666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999976
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =15909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000496864318848
INFO:root:frame =15910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047492980957
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.87422
INFO:root:dqn select action Tensor("ArgMax_259:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010663
INFO:root:action choosen by dqn [4]
INFO:root:frame =15912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000404834747314
INFO:root:training error  = [[ 192.14657593]
 [ 198.93238831]
 [ 180.96604919]
 [ 192.37338257]
 [ 180.23521423]
 [ 193.5663147 ]
 [ 202.56530762]
 [ 184.82489014]
 [ 189.6655426 ]
 [ 191.98162842]
 [ 190.00613403]
 [ 195.42875671]
 [ 191.33605957]
 [ 192.93928528]
 [ 189.86398315]
 [ 199.57339478]]
DEBUG:root:training time = %d0.213388
INFO:root:frame =15913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =15914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame = 15915 State into memory, numbers recorded 428 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00124287605286
INFO:root:random_action_porb = 0.874188333333
DEBUG:root: dqn, choose action rondomly, need time 0.000164000000041
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15916current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =15917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =15918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.874156666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 193.39057922]
 [ 197.65435791]
 [ 192.10765076]
 [ 219.60005188]
 [ 188.0868988 ]
 [ 196.32142639]
 [ 196.32142639]
 [ 199.8217926 ]
 [ 200.39337158]
 [ 230.51649475]
 [ 186.68325806]
 [ 215.3588562 ]
 [ 202.43936157]
 [ 198.40159607]
 [ 197.62776184]
 [ 186.06166077]]
DEBUG:root:training time = %d0.221344
INFO:root:frame =15921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =15922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000317096710205
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.874125
INFO:root:dqn select action Tensor("ArgMax_260:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01017
INFO:root:action choosen by dqn [4]
INFO:root:frame =15924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root:frame =15925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =15926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:random_action_porb = 0.874093333333
DEBUG:root: dqn, choose action rondomly, need time 0.000179000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 184.85310364]
 [ 196.51473999]
 [ 202.55488586]
 [ 204.47219849]
 [ 193.9868927 ]
 [ 193.35238647]
 [ 197.15611267]
 [ 226.88258362]
 [ 203.16949463]
 [ 204.68432617]
 [ 188.78817749]
 [ 207.43101501]
 [ 187.15388489]
 [ 186.33233643]
 [ 198.5881958 ]
 [ 220.2427063 ]]
DEBUG:root:training time = %d0.229298
INFO:root:frame =15929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:frame =15930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:random_action_porb = 0.874061666667
INFO:root:dqn select action Tensor("ArgMax_261:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015065
INFO:root:action choosen by dqn [4]
INFO:root:frame =15932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =15933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =15934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000221014022827
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.87403
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:training error  = [[ 185.02989197]
 [ 202.57225037]
 [ 177.52261353]
 [ 200.72528076]
 [ 187.83000183]
 [ 192.38352966]
 [ 191.97317505]
 [ 189.41514587]
 [ 198.52197266]
 [ 194.13482666]
 [ 192.97914124]
 [ 194.2071228 ]
 [ 204.00553894]
 [ 185.60070801]
 [ 200.84291077]
 [ 195.71128845]]
DEBUG:root:training time = %d0.21724
INFO:root:frame =15937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =15938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.873998333333
DEBUG:root: dqn, choose action rondomly, need time 0.000181999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:frame =15941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =15942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000245809555054
INFO:root:random_action_porb = 0.873966666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:training error  = [[ 183.77754211]
 [ 197.00531006]
 [ 194.58750916]
 [ 195.08334351]
 [ 194.87539673]
 [ 190.36386108]
 [ 193.53829956]
 [ 192.9672699 ]
 [ 203.59513855]
 [ 194.85494995]
 [ 208.58154297]
 [ 187.01029968]
 [ 181.87693787]
 [ 195.95129395]
 [ 193.78800964]
 [ 192.06790161]]
DEBUG:root:training time = %d0.227878
INFO:root:frame =15945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =15946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:random_action_porb = 0.873935
DEBUG:root: dqn, choose action rondomly, need time 0.000335000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =15949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =15950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame = 15951 State into memory, numbers recorded 429 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000582933425903
INFO:root:random_action_porb = 0.873903333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15952current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 188.59281921]
 [ 191.15374756]
 [ 198.74821472]
 [ 197.79425049]
 [ 202.88337708]
 [ 190.85092163]
 [ 205.3021698 ]
 [ 205.3021698 ]
 [ 194.41641235]
 [ 184.18486023]
 [ 224.77758789]
 [ 197.60801697]
 [ 191.13096619]
 [ 200.66130066]
 [ 191.03562927]
 [ 187.36018372]]
DEBUG:root:training time = %d0.231746
INFO:root:frame =15953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000260829925537
INFO:root:frame =15954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294923782349
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.873871666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =15957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =15958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000359058380127
INFO:root:frame = 15959 State into memory, numbers recorded 430 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.00056791305542
INFO:root:random_action_porb = 0.87384
DEBUG:root: dqn, choose action rondomly, need time 0.000303999999971
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15960current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000304222106934
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 188.23591614]
 [ 197.30526733]
 [ 190.52474976]
 [ 200.12042236]
 [ 208.42642212]
 [ 191.02381897]
 [ 225.81463623]
 [ 207.22976685]
 [ 196.01367188]
 [ 182.89491272]
 [ 191.43907166]
 [ 194.60198975]
 [ 229.83958435]
 [ 197.43817139]
 [ 193.24716187]
 [ 186.60237122]]
DEBUG:root:training time = %d0.220131
INFO:root:frame =15961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =15962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000518083572388
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:random_action_porb = 0.873808333333
DEBUG:root: dqn, choose action rondomly, need time 0.000317999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =15965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =15966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.873776666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000046
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 198.64497375]
 [ 179.53857422]
 [ 173.26040649]
 [ 200.98738098]
 [ 193.47462463]
 [ 190.32849121]
 [ 197.75648499]
 [ 222.81811523]
 [ 202.94683838]
 [ 181.36283875]
 [ 187.2106781 ]
 [ 194.76976013]
 [ 192.72740173]
 [ 186.69326782]
 [ 188.97691345]
 [ 199.11752319]]
DEBUG:root:training time = %d0.233052
INFO:root:frame =15969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:frame =15970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.873745
DEBUG:root: dqn, choose action rondomly, need time 0.000160999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:frame =15973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =15974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.873713333333
DEBUG:root: dqn, choose action rondomly, need time 0.000323999999978
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 191.26937866]
 [ 196.08717346]
 [ 196.25556946]
 [ 194.69906616]
 [ 225.20878601]
 [ 193.94438171]
 [ 188.94921875]
 [ 233.74983215]
 [ 196.251297  ]
 [ 189.24465942]
 [ 199.11322021]
 [ 192.00445557]
 [ 199.38977051]
 [ 203.38792419]
 [ 193.67927551]
 [ 201.94207764]]
DEBUG:root:training time = %d0.228504
INFO:root:frame =15977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =15978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000405073165894
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.873681666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999965
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =15980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =15981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =15982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.87365
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =15984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 211.19625854]
 [ 183.83959961]
 [ 194.0438385 ]
 [ 176.37133789]
 [ 186.59403992]
 [ 230.64068604]
 [ 194.92652893]
 [ 197.77708435]
 [ 200.65698242]
 [ 193.940979  ]
 [ 187.45126343]
 [ 195.20016479]
 [ 197.35928345]
 [ 236.49855042]
 [ 179.93461609]
 [ 185.32475281]]
DEBUG:root:training time = %d0.233459
INFO:root:frame =15985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000371932983398
INFO:root:frame =15986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488042831421
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.873618333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =15988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =15989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000596046447754
INFO:root:frame =15990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame = 15991 State into memory, numbers recorded 431 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000669956207275
INFO:root:random_action_porb = 0.873586666667
DEBUG:root: dqn, choose action rondomly, need time 0.000567000000046
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =15992current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 185.65892029]
 [ 194.41217041]
 [ 187.7421875 ]
 [ 197.69125366]
 [ 207.12522888]
 [ 200.41410828]
 [ 203.16601562]
 [ 194.72377014]
 [ 199.39064026]
 [ 203.51763916]
 [ 197.01730347]
 [ 197.08842468]
 [ 219.99911499]
 [ 193.52470398]
 [ 197.49906921]
 [ 197.49649048]]
DEBUG:root:training time = %d0.209977
INFO:root:frame =15993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =15994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000514030456543
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.873555
INFO:root:dqn select action Tensor("ArgMax_262:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014386
INFO:root:action choosen by dqn [4]
INFO:root:frame =15996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root:frame =15997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =15998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000518083572388
DEBUG:root: save sample needs time = 0.000213861465454
DEBUG:root:one frame running time = 0.00758299999995
DEBUG:root:total training time = 490.097659
INFO:root:frame num = 16000 frame round: 0
INFO:root:random_action_porb = 0.873523333333
DEBUG:root: dqn, choose action rondomly, need time 0.000209999999981
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 193.2895813 ]
 [ 190.20809937]
 [ 227.2743988 ]
 [ 190.20809937]
 [ 191.16555786]
 [ 200.86453247]
 [ 194.52961731]
 [ 182.81404114]
 [ 205.68188477]
 [ 194.78849792]
 [ 187.05871582]
 [ 201.26524353]
 [ 206.1469574 ]
 [ 191.82521057]
 [ 197.24868774]
 [ 195.50726318]]
DEBUG:root:training time = %d0.214025
INFO:root:frame =16001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000217199325562
INFO:root:frame =16002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 0.000258207321167
INFO:root:random_action_porb = 0.873491666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =16005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =16006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000326871871948
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.87346
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000031
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 196.12904358]
 [ 199.05380249]
 [ 187.58415222]
 [ 187.17393494]
 [ 226.93223572]
 [ 204.97346497]
 [ 190.74552917]
 [ 207.63764954]
 [ 189.24382019]
 [ 189.60923767]
 [ 193.11906433]
 [ 193.78717041]
 [ 190.28639221]
 [ 199.69929504]
 [ 199.77433777]
 [ 190.22157288]]
DEBUG:root:training time = %d0.240903
INFO:root:frame =16009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =16010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
INFO:root:frame = 16011 State into memory, numbers recorded 432 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000703096389771
INFO:root:random_action_porb = 0.873428333333
DEBUG:root: dqn, choose action rondomly, need time 0.000162999999986
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16012current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000145196914673
INFO:root:frame =16013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000564098358154
INFO:root:frame =16014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000597953796387
INFO:root: ememy has been killed for 32 times 
INFO:root:enemies_left [0]
INFO:root:frame = 16015 State into memory, numbers recorded 433 action = 0, reward = 1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:random_action_porb = 0.873396666667
DEBUG:root: dqn, choose action rondomly, need time 0.000278000000037
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16016current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 203.93579102]
 [ 192.39369202]
 [ 202.2743988 ]
 [ 187.96052551]
 [ 200.85760498]
 [ 190.39839172]
 [ 190.40934753]
 [ 202.59484863]
 [ 194.08041382]
 [ 198.29071045]
 [ 199.96591187]
 [ 229.7960968 ]
 [ 186.44148254]
 [ 206.17411804]
 [ 198.70948792]
 [ 209.75822449]]
DEBUG:root:training time = %d0.208748
INFO:root:frame =16017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =16018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000340938568115
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.873365
DEBUG:root: dqn, choose action rondomly, need time 0.000256000000036
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =16021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457763671875
INFO:root:frame =16022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479221343994
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:random_action_porb = 0.873333333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000018
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 202.60092163]
 [ 202.60092163]
 [ 187.78233337]
 [ 197.71356201]
 [ 192.42417908]
 [ 215.50486755]
 [ 201.1847229 ]
 [ 221.79069519]
 [ 196.5917511 ]
 [ 209.80154419]
 [ 200.39854431]
 [ 223.568573  ]
 [ 193.87214661]
 [ 183.67826843]
 [ 191.40867615]
 [ 192.89181519]]
DEBUG:root:training time = %d0.210762
INFO:root:frame =16025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =16026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000326156616211
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.873301666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000041
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =16029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000579118728638
INFO:root:frame =16030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame = 16031 State into memory, numbers recorded 434 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000492095947266
INFO:root:random_action_porb = 0.87327
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16032current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:training error  = [[ 201.32585144]
 [ 188.70683289]
 [ 200.70021057]
 [ 202.72169495]
 [ 191.78547668]
 [ 201.54934692]
 [ 195.09869385]
 [ 194.61730957]
 [ 201.60481262]
 [ 199.83905029]
 [ 211.5796051 ]
 [ 204.93676758]
 [ 197.5513916 ]
 [ 195.6754303 ]
 [ 200.11437988]
 [ 202.17372131]]
DEBUG:root:training time = %d0.238232
INFO:root:frame =16033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:frame =16034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000244140625
DEBUG:root: save sample needs time = 0.000171184539795
INFO:root:random_action_porb = 0.873238333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000347852706909
INFO:root:frame =16037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =16038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481843948364
INFO:root:frame = 16039 State into memory, numbers recorded 435 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000545978546143
INFO:root:random_action_porb = 0.873206666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16040current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 201.56062317]
 [ 243.08033752]
 [ 193.70985413]
 [ 198.6552887 ]
 [ 195.62591553]
 [ 198.97975159]
 [ 191.86325073]
 [ 195.79412842]
 [ 187.41700745]
 [ 193.09446716]
 [ 195.17372131]
 [ 182.47171021]
 [ 199.33720398]
 [ 201.0868988 ]
 [ 194.96658325]
 [ 195.09613037]]
DEBUG:root:training time = %d0.221269
INFO:root:frame =16041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =16042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000282049179077
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.873175
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000370979309082
INFO:root:frame =16045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =16046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.873143333333
DEBUG:root: dqn, choose action rondomly, need time 0.000329000000022
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000357151031494
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 206.94168091]
 [ 221.27380371]
 [ 188.98696899]
 [ 206.94168091]
 [ 197.52822876]
 [ 194.61305237]
 [ 194.51089478]
 [ 209.38534546]
 [ 198.51681519]
 [ 193.41519165]
 [ 212.90005493]
 [ 191.51931763]
 [ 199.78901672]
 [ 197.06956482]
 [ 226.43600464]
 [ 198.34744263]]
DEBUG:root:training time = %d0.205205
INFO:root:frame =16049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =16050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494003295898
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.873111666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =16053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046181678772
INFO:root:frame =16054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000499963760376
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:random_action_porb = 0.87308
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 211.97753906]
 [ 205.10368347]
 [ 201.45057678]
 [ 195.38439941]
 [ 203.9697876 ]
 [ 194.90266418]
 [ 203.05293274]
 [ 202.6313324 ]
 [ 202.34559631]
 [ 191.58857727]
 [ 188.86364746]
 [ 195.97949219]
 [ 202.96075439]
 [ 226.53887939]
 [ 206.18638611]
 [ 206.92323303]]
DEBUG:root:training time = %d0.224355
INFO:root:frame =16057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =16058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.873048333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =16061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =16062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.873016666667
DEBUG:root: dqn, choose action rondomly, need time 0.000456999999983
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 217.14677429]
 [ 204.88346863]
 [ 203.17819214]
 [ 197.56169128]
 [ 179.82983398]
 [ 215.05172729]
 [ 200.45211792]
 [ 215.05172729]
 [ 199.57684326]
 [ 194.80126953]
 [ 200.43569946]
 [ 188.87371826]
 [ 207.17880249]
 [ 202.59484863]
 [ 238.55014038]
 [ 201.50949097]]
DEBUG:root:training time = %d0.241259
INFO:root:frame =16065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275850296021
INFO:root:frame =16066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.872985
DEBUG:root: dqn, choose action rondomly, need time 0.000338999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =16069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =16070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:random_action_porb = 0.872953333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000363111495972
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 194.34579468]
 [ 209.77677917]
 [ 197.09698486]
 [ 200.72874451]
 [ 208.4475708 ]
 [ 210.44740295]
 [ 206.43624878]
 [ 198.06387329]
 [ 229.41876221]
 [ 201.39167786]
 [ 198.30961609]
 [ 202.25444031]
 [ 218.7624054 ]
 [ 211.68171692]
 [ 203.40881348]
 [ 234.94113159]]
DEBUG:root:training time = %d0.205234
INFO:root:frame =16073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000260829925537
INFO:root:frame =16074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.872921666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =16077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049090385437
INFO:root:frame =16078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame = 16079 State into memory, numbers recorded 436 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000632047653198
INFO:root:random_action_porb = 0.87289
INFO:root:dqn select action Tensor("ArgMax_263:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00843400000002
INFO:root:action choosen by dqn [4]
INFO:root:frame =16080current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000410079956055
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 204.38317871]
 [ 212.26199341]
 [ 200.84291077]
 [ 206.17149353]
 [ 200.16619873]
 [ 199.47079468]
 [ 212.30734253]
 [ 200.18519592]
 [ 197.23240662]
 [ 192.86129761]
 [ 207.70802307]
 [ 193.28619385]
 [ 218.74255371]
 [ 207.09008789]
 [ 199.94346619]
 [ 177.08535767]]
DEBUG:root:training time = %d0.212049
INFO:root:frame =16081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =16082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.872858333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =16085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =16086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.872826666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:training error  = [[ 201.16394043]
 [ 214.28623962]
 [ 193.60368347]
 [ 201.78077698]
 [ 205.47622681]
 [ 217.35638428]
 [ 210.10488892]
 [ 210.53417969]
 [ 200.60250854]
 [ 203.62039185]
 [ 193.53405762]
 [ 195.83511353]
 [ 200.32252502]
 [ 214.57403564]
 [ 206.14607239]
 [ 206.09086609]]
DEBUG:root:training time = %d0.228863
INFO:root:frame =16089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =16090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00036883354187
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.872795
INFO:root:dqn select action Tensor("ArgMax_264:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00909800000005
INFO:root:action choosen by dqn [4]
INFO:root:frame =16092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:frame =16093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =16094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:random_action_porb = 0.872763333333
DEBUG:root: dqn, choose action rondomly, need time 0.000316000000055
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:training error  = [[ 203.16340637]
 [ 197.49049377]
 [ 198.91775513]
 [ 205.13516235]
 [ 215.90197754]
 [ 208.19033813]
 [ 186.80252075]
 [ 193.06817627]
 [ 208.25463867]
 [ 211.71990967]
 [ 222.08621216]
 [ 183.02700806]
 [ 201.40727234]
 [ 198.94789124]
 [ 200.18519592]
 [ 202.53317261]]
DEBUG:root:training time = %d0.223694
INFO:root:frame =16097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =16098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000408172607422
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.872731666667
DEBUG:root: dqn, choose action rondomly, need time 0.000527999999974
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =16101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00044584274292
INFO:root:frame =16102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000633955001831
INFO:root: ememy has been killed for 33 times 
INFO:root:enemies_left [0]
INFO:root:frame = 16103 State into memory, numbers recorded 437 action = 2, reward = 1
DEBUG:root: save sample needs time = 0.000419139862061
INFO:root:random_action_porb = 0.8727
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16104current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:training error  = [[ 225.5725708 ]
 [ 202.20756531]
 [ 206.74328613]
 [ 219.55574036]
 [ 200.20851135]
 [ 217.98222351]
 [ 197.77536011]
 [ 206.49588013]
 [ 212.04507446]
 [ 203.37138367]
 [ 200.34152222]
 [ 196.28379822]
 [ 197.42616272]
 [ 201.85360718]
 [ 203.47323608]
 [ 204.2933197 ]]
DEBUG:root:training time = %d0.227521
INFO:root:frame =16105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =16106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000345945358276
DEBUG:root: save sample needs time = 0.000171899795532
INFO:root:random_action_porb = 0.872668333333
DEBUG:root: dqn, choose action rondomly, need time 0.000239000000022
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =16109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000604867935181
INFO:root:frame =16110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:random_action_porb = 0.872636666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999974
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 202.43849182]
 [ 202.68867493]
 [ 204.89657593]
 [ 214.0879364 ]
 [ 215.90019226]
 [ 214.97029114]
 [ 195.25558472]
 [ 210.92935181]
 [ 211.88778687]
 [ 199.13647461]
 [ 212.26020813]
 [ 208.50662231]
 [ 202.2900238 ]
 [ 197.8629303 ]
 [ 202.16851807]
 [ 240.21405029]]
DEBUG:root:training time = %d0.236166
INFO:root:frame =16113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =16114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494003295898
DEBUG:root: save sample needs time = 0.000131845474243
INFO:root:random_action_porb = 0.872605
DEBUG:root: dqn, choose action rondomly, need time 0.000335000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =16117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000482082366943
INFO:root:frame =16118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.872573333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 198.85491943]
 [ 190.56855774]
 [ 197.62174988]
 [ 211.92776489]
 [ 198.7026062 ]
 [ 209.73524475]
 [ 212.46656799]
 [ 218.16699219]
 [ 214.02008057]
 [ 207.02947998]
 [ 235.76698303]
 [ 208.56214905]
 [ 183.23101807]
 [ 216.87702942]
 [ 213.62916565]
 [ 206.9864502 ]]
DEBUG:root:training time = %d0.228158
INFO:root:frame =16121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =16122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046181678772
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.872541666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =16125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =16126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.87251
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 201.74349976]
 [ 215.00787354]
 [ 209.7502594 ]
 [ 197.39958191]
 [ 206.13555908]
 [ 192.47836304]
 [ 233.57164001]
 [ 179.42817688]
 [ 200.8714447 ]
 [ 213.34913635]
 [ 203.44537354]
 [ 223.77212524]
 [ 210.66615295]
 [ 193.33795166]
 [ 200.22491455]
 [ 216.94715881]]
DEBUG:root:training time = %d0.22989
INFO:root:frame =16129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =16130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247955322266
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:random_action_porb = 0.872478333333
DEBUG:root: dqn, choose action rondomly, need time 0.000473
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000351905822754
INFO:root:frame =16133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =16134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000697135925293
INFO:root:frame = 16135 State into memory, numbers recorded 438 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000555038452148
INFO:root:random_action_porb = 0.872446666667
DEBUG:root: dqn, choose action rondomly, need time 0.000340999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16136current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 238.5868988 ]
 [ 211.12530518]
 [ 211.64974976]
 [ 207.44772339]
 [ 195.70445251]
 [ 197.78738403]
 [ 244.41726685]
 [ 198.36463928]
 [ 244.41726685]
 [ 204.24098206]
 [ 236.2339325 ]
 [ 188.28366089]
 [ 206.88285828]
 [ 210.83363342]
 [ 214.90228271]
 [ 205.22695923]]
DEBUG:root:training time = %d0.229976
INFO:root:frame =16137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =16138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475883483887
DEBUG:root: save sample needs time = 0.000199794769287
INFO:root:random_action_porb = 0.872415
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000414848327637
INFO:root:frame =16141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =16142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:random_action_porb = 0.872383333333
DEBUG:root: dqn, choose action rondomly, need time 0.000328999999965
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 215.64646912]
 [ 203.87478638]
 [ 208.30747986]
 [ 217.80023193]
 [ 204.04127502]
 [ 207.58840942]
 [ 200.57398987]
 [ 213.00337219]
 [ 204.04127502]
 [ 196.83572388]
 [ 220.62510681]
 [ 225.79904175]
 [ 223.11979675]
 [ 252.10671997]
 [ 220.41120911]
 [ 205.87800598]]
DEBUG:root:training time = %d0.222332
INFO:root:frame =16145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000346899032593
INFO:root:frame =16146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000365018844604
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.872351666667
DEBUG:root: dqn, choose action rondomly, need time 0.000271999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =16149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000537872314453
INFO:root:frame =16150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:random_action_porb = 0.87232
DEBUG:root: dqn, choose action rondomly, need time 0.000382000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314235687256
INFO:root:training error  = [[ 197.58999634]
 [ 209.52580261]
 [ 222.74980164]
 [ 224.21791077]
 [ 209.95539856]
 [ 199.81144714]
 [ 209.59030151]
 [ 221.16848755]
 [ 199.8243866 ]
 [ 216.45388794]
 [ 209.27938843]
 [ 207.91654968]
 [ 199.22433472]
 [ 211.02864075]
 [ 199.22433472]
 [ 209.20346069]]
DEBUG:root:training time = %d0.225454
INFO:root:frame =16153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =16154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000287055969238
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.872288333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999964
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: ememy has been killed for 34 times 
INFO:root:enemies_left [0]
INFO:root:frame =16157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =16158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000588893890381
INFO:root:frame = 16159 State into memory, numbers recorded 439 action = 1, reward = 1
DEBUG:root: save sample needs time = 0.000634908676147
INFO:root:random_action_porb = 0.872256666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16160current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 213.440979  ]
 [ 204.92715454]
 [ 204.32559204]
 [ 210.80969238]
 [ 198.08448792]
 [ 208.66793823]
 [ 213.21899414]
 [ 209.24847412]
 [ 222.2636261 ]
 [ 200.40028381]
 [ 188.01826477]
 [ 207.50750732]
 [ 206.27667236]
 [ 200.31214905]
 [ 208.39205933]
 [ 200.9250946 ]]
DEBUG:root:training time = %d0.226778
INFO:root:frame =16161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =16162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042200088501
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:random_action_porb = 0.872225
DEBUG:root: dqn, choose action rondomly, need time 0.000332999999955
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =16165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =16166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.872193333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 195.23854065]
 [ 214.02186584]
 [ 233.42240906]
 [ 204.35177612]
 [ 204.84503174]
 [ 201.21934509]
 [ 217.06584167]
 [ 193.543396  ]
 [ 210.05799866]
 [ 210.40933228]
 [ 233.42240906]
 [ 207.10063171]
 [ 237.38639832]
 [ 219.41105652]
 [ 204.40063477]
 [ 191.91819763]]
DEBUG:root:training time = %d0.236488
INFO:root:frame =16169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =16170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000340938568115
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.872161666667
INFO:root:dqn select action Tensor("ArgMax_265:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014126
INFO:root:action choosen by dqn [4]
INFO:root:frame =16172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000352144241333
INFO:root:frame =16173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =16174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.87213
DEBUG:root: dqn, choose action rondomly, need time 0.000327999999968
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 213.63273621]
 [ 218.50068665]
 [ 203.90615845]
 [ 207.10502625]
 [ 208.73847961]
 [ 220.2698822 ]
 [ 192.26080322]
 [ 221.20661926]
 [ 213.06306458]
 [ 208.87077332]
 [ 218.88067627]
 [ 216.38743591]
 [ 213.50517273]
 [ 209.25819397]
 [ 235.70420837]
 [ 209.9120636 ]]
DEBUG:root:training time = %d0.223282
INFO:root:frame =16177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =16178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000223875045776
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.872098333333
DEBUG:root: dqn, choose action rondomly, need time 0.000192999999967
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:frame =16181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000493049621582
INFO:root:frame =16182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466823577881
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.872066666667
INFO:root:dqn select action Tensor("ArgMax_266:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.009748
INFO:root:action choosen by dqn [4]
INFO:root:frame =16184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000168085098267
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 242.30635071]
 [ 208.5683136 ]
 [ 217.91194153]
 [ 192.12203979]
 [ 203.20169067]
 [ 207.10502625]
 [ 212.44432068]
 [ 241.14958191]
 [ 197.85691833]
 [ 216.06434631]
 [ 203.52546692]
 [ 206.05757141]
 [ 188.18902588]
 [ 206.8407135 ]
 [ 205.46136475]
 [ 206.44151306]]
DEBUG:root:training time = %d0.209802
INFO:root:frame =16185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =16186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.872035
INFO:root:dqn select action Tensor("ArgMax_267:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00888399999997
INFO:root:action choosen by dqn [4]
INFO:root:frame =16188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000386953353882
INFO:root:frame =16189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000500917434692
INFO:root:frame =16190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame = 16191 State into memory, numbers recorded 440 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00117611885071
INFO:root:random_action_porb = 0.872003333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999958
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16192current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000358819961548
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 206.09526062]
 [ 205.23657227]
 [ 203.17384338]
 [ 206.04267883]
 [ 203.17384338]
 [ 203.11555481]
 [ 208.05033875]
 [ 209.23788452]
 [ 187.66775513]
 [ 247.20671082]
 [ 204.41896057]
 [ 237.97167969]
 [ 206.01991272]
 [ 245.35328674]
 [ 215.1063385 ]
 [ 199.02537537]]
DEBUG:root:training time = %d0.233006
INFO:root:frame =16193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =16194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470161437988
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.871971666667
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000026
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =16197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =16198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000495910644531
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:random_action_porb = 0.87194
DEBUG:root: dqn, choose action rondomly, need time 0.00032200000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000378847122192
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 206.7134552 ]
 [ 220.28617859]
 [ 257.31808472]
 [ 247.64834595]
 [ 259.49032593]
 [ 233.97758484]
 [ 202.07653809]
 [ 217.37889099]
 [ 205.04600525]
 [ 207.62005615]
 [ 212.52528381]
 [ 216.22137451]
 [ 204.94551086]
 [ 205.07922363]
 [ 245.3618927 ]
 [ 214.75556946]]
DEBUG:root:training time = %d0.230011
INFO:root:frame =16201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame =16202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271797180176
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.871908333333
INFO:root:dqn select action Tensor("ArgMax_268:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013807
INFO:root:action choosen by dqn [4]
INFO:root:frame =16204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:frame =16205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =16206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000497817993164
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.871876666667
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999983
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 231.55090332]
 [ 214.01115417]
 [ 210.70071411]
 [ 203.20864868]
 [ 207.56906128]
 [ 248.17402649]
 [ 211.2698822 ]
 [ 203.29391479]
 [ 203.94973755]
 [ 206.4055481 ]
 [ 207.83647156]
 [ 243.23928833]
 [ 206.35119629]
 [ 217.67504883]
 [ 212.77005005]
 [ 201.94033813]]
DEBUG:root:training time = %d0.213798
INFO:root:frame =16209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =16210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.871845
INFO:root:dqn select action Tensor("ArgMax_269:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015593
INFO:root:action choosen by dqn [4]
INFO:root:frame =16212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:frame =16213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:frame =16214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.871813333333
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999983
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:training error  = [[ 210.74943542]
 [ 210.63337708]
 [ 205.06872559]
 [ 212.10018921]
 [ 218.04170227]
 [ 201.0929718 ]
 [ 213.91918945]
 [ 210.92669678]
 [ 205.46572876]
 [ 209.72463989]
 [ 210.74943542]
 [ 214.63305664]
 [ 216.9165802 ]
 [ 200.74258423]
 [ 222.01164246]
 [ 219.84976196]]
DEBUG:root:training time = %d0.231951
INFO:root:frame =16217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =16218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00033712387085
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:random_action_porb = 0.871781666667
DEBUG:root: dqn, choose action rondomly, need time 0.000188999999978
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =16221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =16222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000500917434692
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.87175
INFO:root:dqn select action Tensor("ArgMax_270:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011517
INFO:root:action choosen by dqn [4]
INFO:root:frame =16224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 204.41023254]
 [ 218.8842926 ]
 [ 207.89454651]
 [ 211.85580444]
 [ 210.1446991 ]
 [ 218.94389343]
 [ 204.93676758]
 [ 234.78771973]
 [ 200.74343872]
 [ 205.09320068]
 [ 212.71128845]
 [ 213.40618896]
 [ 241.2472229 ]
 [ 205.74403381]
 [ 210.63072205]
 [ 191.46694946]]
DEBUG:root:training time = %d0.217067
INFO:root:frame =16225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =16226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000414133071899
INFO:root:frame = 16227 State into memory, numbers recorded 441 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00125193595886
INFO:root:random_action_porb = 0.871718333333
INFO:root:dqn select action Tensor("ArgMax_271:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014573
INFO:root:action choosen by dqn [4]
INFO:root:frame =16228current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =16229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375032424927
INFO:root:frame =16230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.871686666667
DEBUG:root: dqn, choose action rondomly, need time 0.000214000000028
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 204.20521545]
 [ 216.35870361]
 [ 218.43934631]
 [ 207.27458191]
 [ 217.02537537]
 [ 217.27630615]
 [ 203.39575195]
 [ 221.66073608]
 [ 221.61347961]
 [ 212.41586304]
 [ 245.36572266]
 [ 224.55526733]
 [ 211.668396  ]
 [ 218.48175049]
 [ 218.47993469]
 [ 215.69396973]]
DEBUG:root:training time = %d0.200871
INFO:root:frame =16233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =16234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042986869812
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:random_action_porb = 0.871655
DEBUG:root: dqn, choose action rondomly, need time 0.000311999999951
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =16237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =16238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480175018311
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:random_action_porb = 0.871623333333
DEBUG:root: dqn, choose action rondomly, need time 0.000220000000013
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 248.71949768]
 [ 211.008255  ]
 [ 201.45144653]
 [ 203.37138367]
 [ 215.49591064]
 [ 219.75022888]
 [ 219.40925598]
 [ 203.81466675]
 [ 265.01748657]
 [ 233.40748596]
 [ 211.82649231]
 [ 208.02392578]
 [ 254.81680298]
 [ 209.88111877]
 [ 230.22097778]
 [ 198.96339417]]
DEBUG:root:training time = %d0.218511
INFO:root:frame =16241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:frame =16242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000266075134277
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.871591666667
DEBUG:root: dqn, choose action rondomly, need time 0.000508000000025
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =16245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470161437988
INFO:root:frame =16246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324010848999
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.87156
DEBUG:root: dqn, choose action rondomly, need time 0.000283000000024
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326156616211
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 214.65719604]
 [ 216.71258545]
 [ 214.0254364 ]
 [ 215.87687683]
 [ 219.07847595]
 [ 204.36747742]
 [ 220.60969543]
 [ 222.04255676]
 [ 227.31028748]
 [ 206.93113708]
 [ 219.67332458]
 [ 177.46975708]
 [ 231.76643372]
 [ 207.97286987]
 [ 211.32666016]
 [ 214.53381348]]
DEBUG:root:training time = %d0.225872
INFO:root:frame =16249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =16250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000397205352783
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:random_action_porb = 0.871528333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000041
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =16253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =16254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000258207321167
INFO:root:random_action_porb = 0.871496666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 200.47631836]
 [ 250.72569275]
 [ 256.09570312]
 [ 208.15687561]
 [ 207.58312988]
 [ 210.66438293]
 [ 209.13725281]
 [ 210.27389526]
 [ 220.28346252]
 [ 208.26960754]
 [ 215.56311035]
 [ 215.20213318]
 [ 209.41273499]
 [ 211.02598572]
 [ 221.02510071]
 [ 210.00404358]]
DEBUG:root:training time = %d0.219628
INFO:root:frame =16257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =16258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame = 16259 State into memory, numbers recorded 442 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000471115112305
INFO:root:random_action_porb = 0.871465
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999983
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16260current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =16261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000401973724365
INFO:root:frame =16262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.871433333333
INFO:root:dqn select action Tensor("ArgMax_272:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00837100000001
INFO:root:action choosen by dqn [4]
INFO:root:frame =16264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000391960144043
INFO:root:training error  = [[ 213.45077515]
 [ 215.92709351]
 [ 227.38943481]
 [ 203.63519287]
 [ 209.01457214]
 [ 221.80070496]
 [ 224.45741272]
 [ 211.32221985]
 [ 221.58532715]
 [ 209.01457214]
 [ 217.57150269]
 [ 211.24859619]
 [ 214.74125671]
 [ 217.04875183]
 [ 228.03230286]
 [ 211.31689453]]
DEBUG:root:training time = %d0.238289
INFO:root:frame =16265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =16266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025486946106
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.871401666667
INFO:root:dqn select action Tensor("ArgMax_273:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01154
INFO:root:action choosen by dqn [4]
INFO:root:frame =16268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000380992889404
INFO:root:frame =16269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000403165817261
INFO:root:frame =16270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494956970215
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.87137
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000031
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 209.104599  ]
 [ 197.48620605]
 [ 218.62611389]
 [ 252.18812561]
 [ 216.80693054]
 [ 216.05537415]
 [ 221.52444458]
 [ 217.78222656]
 [ 213.5970459 ]
 [ 244.00427246]
 [ 253.1796875 ]
 [ 222.35826111]
 [ 217.57870483]
 [ 204.68432617]
 [ 213.66305542]
 [ 216.5921936 ]]
DEBUG:root:training time = %d0.234758
INFO:root:frame =16273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =16274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame = 16275 State into memory, numbers recorded 443 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000545978546143
INFO:root:random_action_porb = 0.871338333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16276current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000341176986694
INFO:root:frame =16277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =16278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.871306666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999969
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000380992889404
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 222.54032898]
 [ 224.70803833]
 [ 192.06620789]
 [ 212.50570679]
 [ 210.79197693]
 [ 217.73268127]
 [ 216.1468811 ]
 [ 209.03045654]
 [ 210.8699646 ]
 [ 226.32763672]
 [ 211.58139038]
 [ 215.38751221]
 [ 215.1860199 ]
 [ 223.19546509]
 [ 193.13687134]
 [ 211.48994446]]
DEBUG:root:training time = %d0.225987
INFO:root:frame =16281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:frame =16282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.871275
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =16285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =16286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.871243333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999976
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 220.9243927 ]
 [ 213.37409973]
 [ 211.2290802 ]
 [ 208.49957275]
 [ 215.58282471]
 [ 209.04370117]
 [ 208.20179749]
 [ 207.92797852]
 [ 223.88261414]
 [ 216.66676331]
 [ 223.24014282]
 [ 201.45837402]
 [ 216.29138184]
 [ 255.04776001]
 [ 233.1688385 ]
 [ 219.97103882]]
DEBUG:root:training time = %d0.222365
INFO:root:frame =16289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000336170196533
INFO:root:frame =16290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.871211666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =16293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =16294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame = 16295 State into memory, numbers recorded 444 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.00056791305542
INFO:root:random_action_porb = 0.87118
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16296current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 220.5834198 ]
 [ 215.92709351]
 [ 212.37316895]
 [ 211.55741882]
 [ 209.1628418 ]
 [ 238.70288086]
 [ 212.76559448]
 [ 212.91252136]
 [ 255.55195618]
 [ 209.1628418 ]
 [ 218.55392456]
 [ 222.80262756]
 [ 222.17900085]
 [ 217.61291504]
 [ 209.67160034]
 [ 224.72085571]]
DEBUG:root:training time = %d0.224884
INFO:root:frame =16297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =16298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.871148333333
DEBUG:root: dqn, choose action rondomly, need time 0.000184999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016713142395
INFO:root:frame =16301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =16302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.871116666667
DEBUG:root: dqn, choose action rondomly, need time 0.00037500000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000485897064209
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 206.00502014]
 [ 223.39884949]
 [ 192.9596405 ]
 [ 220.59881592]
 [ 212.18019104]
 [ 218.83824158]
 [ 221.27017212]
 [ 210.87971497]
 [ 238.75946045]
 [ 213.73265076]
 [ 223.88900757]
 [ 214.35237122]
 [ 210.54393005]
 [ 211.43936157]
 [ 210.68388367]
 [ 218.89784241]]
DEBUG:root:training time = %d0.237561
INFO:root:frame =16305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =16306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000524997711182
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:random_action_porb = 0.871085
DEBUG:root: dqn, choose action rondomly, need time 0.000184999999988
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000181913375854
INFO:root:frame =16309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000475883483887
INFO:root:frame =16310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.871053333333
DEBUG:root: dqn, choose action rondomly, need time 0.00036799999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 224.36233521]
 [ 220.073349  ]
 [ 251.87998962]
 [ 247.77610779]
 [ 220.34959412]
 [ 212.33224487]
 [ 255.68077087]
 [ 237.59519958]
 [ 232.82785034]
 [ 177.52992249]
 [ 248.68388367]
 [ 208.13574219]
 [ 216.05715942]
 [ 244.73417664]
 [ 212.1072998 ]
 [ 208.293396  ]]
DEBUG:root:training time = %d0.2366
INFO:root:frame =16313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =16314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.871021666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =16317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =16318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.87099
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 227.97239685]
 [ 219.24925232]
 [ 241.29556274]
 [ 206.28018188]
 [ 225.06134033]
 [ 226.91752625]
 [ 215.24958801]
 [ 227.97239685]
 [ 209.8024292 ]
 [ 263.76998901]
 [ 211.11376953]
 [ 219.43818665]
 [ 212.18730164]
 [ 222.52485657]
 [ 233.17909241]
 [ 225.65690613]]
DEBUG:root:training time = %d0.221906
INFO:root:frame =16321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =16322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.870958333333
DEBUG:root: dqn, choose action rondomly, need time 0.000524000000041
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =16325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =16326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000638961791992
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.870926666667
DEBUG:root: dqn, choose action rondomly, need time 0.00036799999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 221.33009338]
 [ 225.60189819]
 [ 218.9556427 ]
 [ 225.94490051]
 [ 213.58366394]
 [ 216.29856873]
 [ 216.034729  ]
 [ 229.93490601]
 [ 229.34295654]
 [ 215.4152832 ]
 [ 218.04891968]
 [ 209.65657043]
 [ 223.30581665]
 [ 209.37033081]
 [ 214.77613831]
 [ 250.35760498]]
DEBUG:root:training time = %d0.235018
INFO:root:frame =16329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =16330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame = 16331 State into memory, numbers recorded 445 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000571966171265
INFO:root:random_action_porb = 0.870895
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999964
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16332current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =16333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000524044036865
INFO:root:frame =16334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046181678772
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.870863333333
DEBUG:root: dqn, choose action rondomly, need time 0.000175000000013
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 213.5256958 ]
 [ 210.76628113]
 [ 223.3596344 ]
 [ 247.93754578]
 [ 212.31535339]
 [ 224.24075317]
 [ 256.73098755]
 [ 237.52653503]
 [ 229.42338562]
 [ 230.0756073 ]
 [ 214.77882385]
 [ 217.17195129]
 [ 227.77706909]
 [ 227.04718018]
 [ 235.59083557]
 [ 215.28092957]]
DEBUG:root:training time = %d0.211732
INFO:root:frame =16337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:frame =16338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239133834839
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.870831666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =16341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =16342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.8708
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:training error  = [[ 211.91711426]
 [ 222.38101196]
 [ 236.01728821]
 [ 223.53845215]
 [ 209.52580261]
 [ 218.69470215]
 [ 232.80363464]
 [ 211.27432251]
 [ 221.90797424]
 [ 219.10377502]
 [ 204.93502808]
 [ 211.28851318]
 [ 228.78132629]
 [ 206.73364258]
 [ 218.95202637]
 [ 214.09866333]]
DEBUG:root:training time = %d0.232739
INFO:root:frame =16345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:frame =16346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.870768333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =16349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =16350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000490188598633
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.870736666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 229.75169373]
 [ 211.02687073]
 [ 214.84503174]
 [ 221.05232239]
 [ 214.95597839]
 [ 221.01602173]
 [ 237.9274292 ]
 [ 267.0383606 ]
 [ 217.52018738]
 [ 233.27696228]
 [ 217.90563965]
 [ 218.34643555]
 [ 218.31938171]
 [ 221.70072937]
 [ 218.76150513]
 [ 217.40228271]]
DEBUG:root:training time = %d0.226194
INFO:root:frame =16353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =16354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000250816345215
INFO:root:random_action_porb = 0.870705
DEBUG:root: dqn, choose action rondomly, need time 0.000350000000026
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =16357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =16358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000497102737427
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.870673333333
DEBUG:root: dqn, choose action rondomly, need time 0.000336000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 223.75933838]
 [ 232.056427  ]
 [ 218.84997559]
 [ 244.22932434]
 [ 263.4519043 ]
 [ 249.05941772]
 [ 223.93011475]
 [ 239.96060181]
 [ 218.63604736]
 [ 193.8840332 ]
 [ 213.50785828]
 [ 230.35899353]
 [ 216.49249268]
 [ 216.93006897]
 [ 235.60020447]
 [ 220.76475525]]
DEBUG:root:training time = %d0.239347
INFO:root:frame =16361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:frame =16362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.870641666667
DEBUG:root: dqn, choose action rondomly, need time 0.000253999999984
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =16365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =16366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame = 16367 State into memory, numbers recorded 446 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000571012496948
INFO:root:random_action_porb = 0.87061
INFO:root:dqn select action Tensor("ArgMax_274:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010209
INFO:root:action choosen by dqn [4]
INFO:root:frame =16368current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000946998596191
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 224.35958862]
 [ 220.78741455]
 [ 208.05209351]
 [ 215.10543823]
 [ 220.86541748]
 [ 233.54737854]
 [ 218.45648193]
 [ 223.56217957]
 [ 223.49282837]
 [ 221.17756653]
 [ 219.57202148]
 [ 227.35169983]
 [ 221.57168579]
 [ 225.61106873]
 [ 230.42198181]
 [ 206.94606018]]
DEBUG:root:training time = %d0.22822
INFO:root:frame =16369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =16370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000313997268677
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.870578333333
DEBUG:root: dqn, choose action rondomly, need time 0.000182999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000265836715698
INFO:root:frame =16373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =16374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466823577881
INFO:root:frame = 16375 State into memory, numbers recorded 447 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000562906265259
INFO:root:random_action_porb = 0.870546666667
DEBUG:root: dqn, choose action rondomly, need time 0.000174000000015
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16376current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 215.85534668]
 [ 222.74797058]
 [ 228.25816345]
 [ 224.65040588]
 [ 225.87701416]
 [ 215.4287262 ]
 [ 223.8762207 ]
 [ 244.76759338]
 [ 232.07409668]
 [ 222.72247314]
 [ 251.11434937]
 [ 234.40257263]
 [ 217.28260803]
 [ 218.82019043]
 [ 220.24179077]
 [ 223.85522461]]
DEBUG:root:training time = %d0.227154
INFO:root:frame =16377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =16378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.870515
DEBUG:root: dqn, choose action rondomly, need time 0.000182999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root:frame =16381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =16382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000201225280762
INFO:root:random_action_porb = 0.870483333333
DEBUG:root: dqn, choose action rondomly, need time 0.000359000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 224.81784058]
 [ 217.86959839]
 [ 232.54109192]
 [ 223.21644592]
 [ 237.15135193]
 [ 216.36769104]
 [ 216.85006714]
 [ 224.72724915]
 [ 218.97279358]
 [ 223.38243103]
 [ 184.70376587]
 [ 194.49472046]
 [ 216.22676086]
 [ 216.19265747]
 [ 257.11743164]
 [ 221.72889709]]
DEBUG:root:training time = %d0.219851
INFO:root:frame =16385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =16386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000197172164917
INFO:root:random_action_porb = 0.870451666667
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000021
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =16389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =16390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493764877319
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:random_action_porb = 0.87042
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 218.41227722]
 [ 227.12167358]
 [ 222.14533997]
 [ 258.66314697]
 [ 232.08432007]
 [ 220.9987793 ]
 [ 228.70469666]
 [ 252.84474182]
 [ 236.19923401]
 [ 215.39109802]
 [ 222.60679626]
 [ 217.78942871]
 [ 218.5990448 ]
 [ 230.60453796]
 [ 220.28799438]
 [ 238.45399475]]
DEBUG:root:training time = %d0.21867
INFO:root:frame =16393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =16394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000305891036987
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:random_action_porb = 0.870388333333
DEBUG:root: dqn, choose action rondomly, need time 0.00027399999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =16397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =16398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.870356666667
DEBUG:root: dqn, choose action rondomly, need time 0.00059200000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 219.40202332]
 [ 224.68791199]
 [ 209.83424377]
 [ 249.88945007]
 [ 231.25657654]
 [ 224.15209961]
 [ 219.90496826]
 [ 217.35908508]
 [ 226.72264099]
 [ 231.50726318]
 [ 230.4284668 ]
 [ 218.9646759 ]
 [ 218.71456909]
 [ 199.20623779]
 [ 217.23942566]
 [ 226.85133362]]
DEBUG:root:training time = %d0.228137
INFO:root:frame =16401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =16402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.870325
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999964
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =16405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000497102737427
INFO:root:frame =16406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.870293333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 216.11906433]
 [ 254.08076477]
 [ 222.44200134]
 [ 228.47769165]
 [ 240.30108643]
 [ 225.41676331]
 [ 231.18791199]
 [ 228.08483887]
 [ 216.05357361]
 [ 222.68695068]
 [ 239.64207458]
 [ 225.72843933]
 [ 220.9806366 ]
 [ 235.10580444]
 [ 229.55931091]
 [ 240.14027405]]
DEBUG:root:training time = %d0.240359
INFO:root:frame =16409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =16410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.870261666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =16413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =16414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.87023
DEBUG:root: dqn, choose action rondomly, need time 0.000170000000026
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:training error  = [[ 224.9395752 ]
 [ 227.18882751]
 [ 234.13165283]
 [ 224.93591309]
 [ 227.50080872]
 [ 226.7869873 ]
 [ 228.09405518]
 [ 221.41455078]
 [ 226.39834595]
 [ 213.62023926]
 [ 216.38475037]
 [ 215.62495422]
 [ 212.80032349]
 [ 238.4342041 ]
 [ 217.70025635]
 [ 216.91119385]]
DEBUG:root:training time = %d0.224127
INFO:root:frame =16417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root: ememy has been killed for 35 times 
INFO:root:enemies_left [0]
INFO:root:frame =16418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000351905822754
INFO:root:frame = 16419 State into memory, numbers recorded 448 action = 3, reward = 1
DEBUG:root: save sample needs time = 0.000560998916626
INFO:root:random_action_porb = 0.870198333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16420current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =16421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =16422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.870166666667
INFO:root:dqn select action Tensor("ArgMax_275:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.0116
INFO:root:action choosen by dqn [4]
INFO:root:frame =16424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000389099121094
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 243.75454712]
 [ 234.3530426 ]
 [ 263.8046875 ]
 [ 227.65089417]
 [ 230.77511597]
 [ 233.06072998]
 [ 224.95239258]
 [ 220.32785034]
 [ 224.19871521]
 [ 225.93939209]
 [ 221.45632935]
 [ 256.97946167]
 [ 239.38703918]
 [ 224.84805298]
 [ 274.39120483]
 [ 225.45707703]]
DEBUG:root:training time = %d0.235197
INFO:root:frame =16425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =16426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
DEBUG:root: save sample needs time = 0.000108957290649
INFO:root:random_action_porb = 0.870135
DEBUG:root: dqn, choose action rondomly, need time 0.000180999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000130891799927
INFO:root:frame =16429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00050687789917
INFO:root:frame =16430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.870103333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304000000028
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:training error  = [[ 232.36335754]
 [ 212.89915466]
 [ 221.72616577]
 [ 224.16307068]
 [ 223.8515625 ]
 [ 223.59959412]
 [ 217.32939148]
 [ 233.33848572]
 [ 223.14622498]
 [ 214.14956665]
 [ 245.54931641]
 [ 234.31193542]
 [ 226.70426941]
 [ 218.48625183]
 [ 228.49429321]
 [ 225.81280518]]
DEBUG:root:training time = %d0.212706
INFO:root:frame =16433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471830368042
INFO:root:frame =16434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.870071666667
DEBUG:root: dqn, choose action rondomly, need time 0.000202999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000178813934326
INFO:root:frame =16437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000497102737427
INFO:root:frame =16438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.87004
INFO:root:dqn select action Tensor("ArgMax_276:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012162
INFO:root:action choosen by dqn [4]
INFO:root:frame =16440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 242.86532593]
 [ 231.67352295]
 [ 240.73178101]
 [ 224.71536255]
 [ 221.84251404]
 [ 229.04820251]
 [ 224.58363342]
 [ 226.06326294]
 [ 260.71289062]
 [ 232.97874451]
 [ 197.23840332]
 [ 226.51040649]
 [ 236.03791809]
 [ 243.91941833]
 [ 236.02478027]
 [ 226.95521545]]
DEBUG:root:training time = %d0.221319
INFO:root:frame =16441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =16442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.870008333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =16445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000503778457642
INFO:root:frame =16446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.869976666667
DEBUG:root: dqn, choose action rondomly, need time 0.000272999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 197.34812927]
 [ 245.43360901]
 [ 226.7961731 ]
 [ 215.22273254]
 [ 232.71238708]
 [ 236.20297241]
 [ 271.85839844]
 [ 276.84744263]
 [ 266.22012329]
 [ 242.75785828]
 [ 225.72843933]
 [ 225.431427  ]
 [ 237.19364929]
 [ 255.94628906]
 [ 228.04060364]
 [ 233.29653931]]
DEBUG:root:training time = %d0.234845
INFO:root:frame =16449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =16450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.869945
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =16453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =16454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.869913333333
DEBUG:root: dqn, choose action rondomly, need time 0.000361999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 230.49703979]
 [ 224.92858887]
 [ 226.46907043]
 [ 225.96875   ]
 [ 229.91362   ]
 [ 227.50817871]
 [ 257.099823  ]
 [ 239.70443726]
 [ 218.96647644]
 [ 227.35169983]
 [ 228.77578735]
 [ 229.07591248]
 [ 231.06356812]
 [ 203.68397522]
 [ 232.12522888]
 [ 248.13363647]]
DEBUG:root:training time = %d0.22925
INFO:root:frame =16457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:frame =16458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000305891036987
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.869881666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =16461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00048303604126
INFO:root:frame =16462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047779083252
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.86985
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000026
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000370025634766
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 237.14100647]
 [ 246.99180603]
 [ 241.897995  ]
 [ 228.02308655]
 [ 261.03329468]
 [ 244.33903503]
 [ 219.39207458]
 [ 237.06300354]
 [ 238.09408569]
 [ 223.22099304]
 [ 192.2184906 ]
 [ 229.52693176]
 [ 244.33903503]
 [ 233.60520935]
 [ 236.59524536]
 [ 233.54924011]]
DEBUG:root:training time = %d0.231379
INFO:root:frame =16465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000388145446777
INFO:root:frame =16466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000305891036987
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.869818333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =16469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000416994094849
INFO:root:frame =16470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000291109085083
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.869786666667
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 239.94830322]
 [ 232.36521912]
 [ 231.07191467]
 [ 228.61886597]
 [ 217.43287659]
 [ 226.44425964]
 [ 230.49333191]
 [ 227.36825562]
 [ 229.57409668]
 [ 257.88528442]
 [ 208.96516418]
 [ 231.36611938]
 [ 225.69633484]
 [ 237.12127686]
 [ 206.36959839]
 [ 216.8581543 ]]
DEBUG:root:training time = %d0.219762
INFO:root:frame =16473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:frame =16474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239849090576
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.869755
DEBUG:root: dqn, choose action rondomly, need time 0.000169999999969
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000136137008667
INFO:root:frame =16477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =16478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231981277466
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:random_action_porb = 0.869723333333
DEBUG:root: dqn, choose action rondomly, need time 0.000159999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 231.49517822]
 [ 248.32981873]
 [ 222.06347656]
 [ 220.42208862]
 [ 260.92089844]
 [ 221.46177673]
 [ 235.48217773]
 [ 247.16641235]
 [ 237.79376221]
 [ 242.21420288]
 [ 227.06741333]
 [ 195.22915649]
 [ 214.17904663]
 [ 238.55767822]
 [ 221.06593323]
 [ 249.8344574 ]]
DEBUG:root:training time = %d0.220017
INFO:root:frame =16481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =16482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000270128250122
DEBUG:root: save sample needs time = 0.00011682510376
INFO:root:random_action_porb = 0.869691666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =16485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame =16486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000201225280762
INFO:root:random_action_porb = 0.86966
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000031
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:training error  = [[ 236.07354736]
 [ 231.55183411]
 [ 225.11628723]
 [ 216.69371033]
 [ 235.1572876 ]
 [ 234.77650452]
 [ 247.81069946]
 [ 229.69989014]
 [ 233.48396301]
 [ 218.17150879]
 [ 219.95204163]
 [ 229.69989014]
 [ 233.20425415]
 [ 240.0400238 ]
 [ 226.59216309]
 [ 240.0400238 ]]
DEBUG:root:training time = %d0.245883
INFO:root:frame =16489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000451803207397
INFO:root:frame =16490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000325918197632
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.869628333333
DEBUG:root: dqn, choose action rondomly, need time 0.000423000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =16493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =16494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044322013855
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.869596666667
DEBUG:root: dqn, choose action rondomly, need time 0.000354999999956
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 237.41178894]
 [ 237.07427979]
 [ 230.39697266]
 [ 242.26835632]
 [ 258.31381226]
 [ 241.84103394]
 [ 235.26774597]
 [ 225.70918274]
 [ 237.25663757]
 [ 224.45010376]
 [ 245.40492249]
 [ 262.93997192]
 [ 220.87268066]
 [ 232.27684021]
 [ 241.77174377]
 [ 209.61416626]]
DEBUG:root:training time = %d0.24069
INFO:root:frame =16497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =16498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000407934188843
INFO:root:frame = 16499 State into memory, numbers recorded 449 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000573873519897
INFO:root:random_action_porb = 0.869565
INFO:root:dqn select action Tensor("ArgMax_277:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012674
INFO:root:action choosen by dqn [4]
INFO:root:frame =16500current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =16501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =16502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.869533333333
DEBUG:root: dqn, choose action rondomly, need time 0.000338999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 213.36607361]
 [ 231.83518982]
 [ 239.04153442]
 [ 250.57301331]
 [ 237.87471008]
 [ 204.89744568]
 [ 233.52406311]
 [ 237.81822205]
 [ 228.39466858]
 [ 233.00669861]
 [ 222.98214722]
 [ 253.72091675]
 [ 213.36607361]
 [ 221.20298767]
 [ 237.21057129]
 [ 239.20953369]]
DEBUG:root:training time = %d0.232959
INFO:root:frame =16505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =16506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.869501666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =16509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =16510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:random_action_porb = 0.86947
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320196151733
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 259.04611206]
 [ 238.26176453]
 [ 219.46983337]
 [ 241.34771729]
 [ 228.37252808]
 [ 230.02746582]
 [ 236.42440796]
 [ 270.2666626 ]
 [ 237.91612244]
 [ 254.80511475]
 [ 221.94706726]
 [ 226.06694031]
 [ 232.2089386 ]
 [ 228.06916809]
 [ 238.26176453]
 [ 237.96226501]]
DEBUG:root:training time = %d0.219839
INFO:root:frame =16513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280857086182
INFO:root:frame =16514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504016876221
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.869438333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =16517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456809997559
INFO:root:frame =16518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.869406666667
DEBUG:root: dqn, choose action rondomly, need time 0.000170999999966
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 231.36054993]
 [ 234.06535339]
 [ 231.91326904]
 [ 223.01586914]
 [ 245.33226013]
 [ 246.18959045]
 [ 227.91618347]
 [ 279.14935303]
 [ 230.87989807]
 [ 227.26979065]
 [ 262.88552856]
 [ 230.98284912]
 [ 226.75297546]
 [ 235.01690674]
 [ 231.02182007]
 [ 233.25738525]]
DEBUG:root:training time = %d0.232097
INFO:root:frame =16521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =16522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240087509155
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.869375
DEBUG:root: dqn, choose action rondomly, need time 0.000304000000028
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =16525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =16526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.869343333333
INFO:root:dqn select action Tensor("ArgMax_278:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011045
INFO:root:action choosen by dqn [4]
INFO:root:frame =16528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:training error  = [[ 230.0756073 ]
 [ 235.30050659]
 [ 232.01644897]
 [ 235.17881775]
 [ 226.1789093 ]
 [ 225.10621643]
 [ 236.78305054]
 [ 233.32730103]
 [ 234.26708984]
 [ 234.74656677]
 [ 227.07844543]
 [ 228.93829346]
 [ 237.47291565]
 [ 235.85978699]
 [ 222.30821228]
 [ 240.33705139]]
DEBUG:root:training time = %d0.217643
INFO:root:frame =16529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =16530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
INFO:root:frame = 16531 State into memory, numbers recorded 450 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00093412399292
INFO:root:random_action_porb = 0.869311666667
INFO:root:dqn select action Tensor("ArgMax_279:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012595
INFO:root:action choosen by dqn [4]
INFO:root:frame =16532current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000386953353882
INFO:root:frame =16533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:frame =16534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239849090576
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.86928
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000026
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 240.76870728]
 [ 240.76870728]
 [ 288.30627441]
 [ 240.80754089]
 [ 237.27168274]
 [ 273.8192749 ]
 [ 240.0050354 ]
 [ 267.24685669]
 [ 241.29936218]
 [ 233.39723206]
 [ 250.80300903]
 [ 224.40438843]
 [ 234.53715515]
 [ 224.70072937]
 [ 231.98391724]
 [ 238.09126282]]
DEBUG:root:training time = %d0.227038
INFO:root:frame =16537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =16538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame = 16539 State into memory, numbers recorded 451 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000368118286133
INFO:root:random_action_porb = 0.869248333333
DEBUG:root: dqn, choose action rondomly, need time 0.000200000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16540current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root:frame =16541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =16542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame = 16543 State into memory, numbers recorded 452 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000628232955933
INFO:root:random_action_porb = 0.869216666667
DEBUG:root: dqn, choose action rondomly, need time 0.000340999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16544current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000326156616211
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 241.20172119]
 [ 233.4848938 ]
 [ 232.78874207]
 [ 239.99462891]
 [ 237.83892822]
 [ 239.86795044]
 [ 212.1259613 ]
 [ 235.83447266]
 [ 245.47280884]
 [ 232.60903931]
 [ 233.73023987]
 [ 248.88990784]
 [ 230.26913452]
 [ 237.54440308]
 [ 233.38697815]
 [ 275.59567261]]
DEBUG:root:training time = %d0.219149
INFO:root:frame =16545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =16546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.869185
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =16549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =16550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.869153333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 240.33799744]
 [ 198.91690063]
 [ 239.07362366]
 [ 244.33998108]
 [ 242.49925232]
 [ 273.62539673]
 [ 231.09790039]
 [ 230.70187378]
 [ 216.12983704]
 [ 232.66955566]
 [ 221.78616333]
 [ 243.30496216]
 [ 236.59524536]
 [ 268.22457886]
 [ 242.49925232]
 [ 243.25737   ]]
DEBUG:root:training time = %d0.227448
INFO:root:frame =16553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =16554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275850296021
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.869121666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =16557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =16558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324964523315
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:random_action_porb = 0.86909
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 239.06512451]
 [ 234.5249939 ]
 [ 243.58685303]
 [ 241.28419495]
 [ 238.86132812]
 [ 233.58842468]
 [ 240.35597229]
 [ 233.88423157]
 [ 209.45600891]
 [ 244.14349365]
 [ 249.20584106]
 [ 267.06729126]
 [ 246.8019104 ]
 [ 250.76048279]
 [ 240.29446411]
 [ 234.33061218]]
DEBUG:root:training time = %d0.223901
INFO:root:frame =16561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =16562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000261783599854
INFO:root:frame = 16563 State into memory, numbers recorded 453 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root:random_action_porb = 0.869058333333
DEBUG:root: dqn, choose action rondomly, need time 0.000185999999985
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16564current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:frame =16565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049901008606
INFO:root:frame =16566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.869026666667
DEBUG:root: dqn, choose action rondomly, need time 0.000334000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 239.30488586]
 [ 230.60083008]
 [ 233.00297546]
 [ 235.21157837]
 [ 234.14285278]
 [ 215.48516846]
 [ 226.32304382]
 [ 215.48516846]
 [ 246.60250854]
 [ 238.52468872]
 [ 239.45787048]
 [ 241.51177979]
 [ 250.01199341]
 [ 254.10800171]
 [ 233.66772461]
 [ 262.86968994]]
DEBUG:root:training time = %d0.24093
INFO:root:frame =16569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:frame =16570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
DEBUG:root: save sample needs time = 0.000197172164917
INFO:root:random_action_porb = 0.868995
INFO:root:dqn select action Tensor("ArgMax_280:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012366
INFO:root:action choosen by dqn [4]
INFO:root:frame =16572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000229835510254
INFO:root:frame =16573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =16574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.868963333333
DEBUG:root: dqn, choose action rondomly, need time 0.000161999999989
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 261.82574463]
 [ 232.61090088]
 [ 288.47937012]
 [ 241.93215942]
 [ 285.93893433]
 [ 246.25375366]
 [ 235.80354309]
 [ 238.42572021]
 [ 241.81730652]
 [ 235.33702087]
 [ 252.60119629]
 [ 246.55554199]
 [ 234.06907654]
 [ 232.22567749]
 [ 248.74742126]
 [ 280.06176758]]
DEBUG:root:training time = %d0.224612
INFO:root:frame =16577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =16578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.868931666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =16581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =16582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.8689
INFO:root:dqn select action Tensor("ArgMax_281:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.0128989999999
INFO:root:action choosen by dqn [4]
INFO:root:frame =16584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185012817383
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 239.42858887]
 [ 230.78253174]
 [ 239.90292358]
 [ 231.7766571 ]
 [ 278.71002197]
 [ 216.41886902]
 [ 240.43734741]
 [ 229.14982605]
 [ 247.53118896]
 [ 241.71386719]
 [ 242.72076416]
 [ 242.59336853]
 [ 235.90759277]
 [ 235.67703247]
 [ 270.43927002]
 [ 240.00408936]]
DEBUG:root:training time = %d0.23636
INFO:root:frame =16585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =16586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456809997559
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.868868333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000051
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =16589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =16590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.868836666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 233.3291626 ]
 [ 254.04866028]
 [ 254.85577393]
 [ 229.16552734]
 [ 228.9770813 ]
 [ 235.3913269 ]
 [ 234.79614258]
 [ 299.74591064]
 [ 230.47943115]
 [ 239.86795044]
 [ 234.58763123]
 [ 233.97944641]
 [ 243.610672  ]
 [ 231.68374634]
 [ 240.77629089]
 [ 240.81890869]]
DEBUG:root:training time = %d0.212507
INFO:root:frame =16593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =16594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000339031219482
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.868805
INFO:root:dqn select action Tensor("ArgMax_282:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00881600000002
INFO:root:action choosen by dqn [4]
INFO:root:frame =16596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:frame =16597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =16598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000500917434692
DEBUG:root: save sample needs time = 0.00018310546875
INFO:root:random_action_porb = 0.868773333333
INFO:root:dqn select action Tensor("ArgMax_283:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014194
INFO:root:action choosen by dqn [4]
INFO:root:frame =16600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:training error  = [[ 237.33374023]
 [ 243.55160522]
 [ 263.8324585 ]
 [ 239.36248779]
 [ 233.1259613 ]
 [ 230.59341431]
 [ 245.92437744]
 [ 255.4309845 ]
 [ 236.7661438 ]
 [ 239.74130249]
 [ 230.77511597]
 [ 237.48326111]
 [ 241.40081787]
 [ 245.18792725]
 [ 236.87509155]
 [ 237.29612732]]
DEBUG:root:training time = %d0.214858
INFO:root:frame =16601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =16602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000333070755005
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.868741666667
DEBUG:root: dqn, choose action rondomly, need time 0.000326000000086
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =16605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =16606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.86871
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 242.39376831]
 [ 230.39233398]
 [ 230.84095764]
 [ 281.06774902]
 [ 236.6882019 ]
 [ 235.10394287]
 [ 257.06652832]
 [ 249.32919312]
 [ 230.84095764]
 [ 217.32128906]
 [ 238.66798401]
 [ 251.70857239]
 [ 242.86247253]
 [ 232.68910217]
 [ 245.272995  ]
 [ 245.21372986]]
DEBUG:root:training time = %d0.228892
INFO:root:frame =16609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =16610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000316858291626
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:random_action_porb = 0.868678333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000051
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000384092330933
INFO:root:frame =16613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =16614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.868646666667
DEBUG:root: dqn, choose action rondomly, need time 0.000319999999988
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 248.87257385]
 [ 245.38961792]
 [ 265.44293213]
 [ 250.79238892]
 [ 238.52185059]
 [ 237.01039124]
 [ 222.82449341]
 [ 245.55697632]
 [ 243.07368469]
 [ 248.15576172]
 [ 282.81204224]
 [ 245.31217957]
 [ 266.80004883]
 [ 250.47061157]
 [ 230.04598999]
 [ 228.31166077]]
DEBUG:root:training time = %d0.223506
INFO:root:frame =16617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:frame =16618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000334024429321
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:random_action_porb = 0.868615
DEBUG:root: dqn, choose action rondomly, need time 0.000210000000038
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:frame =16621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469207763672
INFO:root:frame =16622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487089157104
INFO:root:frame = 16623 State into memory, numbers recorded 454 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000579833984375
INFO:root:random_action_porb = 0.868583333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16624current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:training error  = [[ 262.693573  ]
 [ 234.99632263]
 [ 262.30395508]
 [ 237.073349  ]
 [ 242.28450012]
 [ 248.81770325]
 [ 242.55058289]
 [ 229.89233398]
 [ 259.11981201]
 [ 266.93365479]
 [ 243.66973877]
 [ 251.9972229 ]
 [ 241.18655396]
 [ 238.83680725]
 [ 234.05413818]
 [ 254.85090637]]
DEBUG:root:training time = %d0.242769
INFO:root:frame =16625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =16626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000304937362671
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.868551666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000038
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =16629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =16630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame = 16631 State into memory, numbers recorded 455 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00056791305542
INFO:root:random_action_porb = 0.86852
DEBUG:root: dqn, choose action rondomly, need time 0.000450000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16632current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000363826751709
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 248.54820251]
 [ 244.51078796]
 [ 244.23886108]
 [ 214.37828064]
 [ 248.91879272]
 [ 237.3873291 ]
 [ 259.02154541]
 [ 236.97843933]
 [ 251.23043823]
 [ 254.84602356]
 [ 235.38383484]
 [ 273.38818359]
 [ 247.31613159]
 [ 247.95484924]
 [ 244.18354797]
 [ 237.46069336]]
DEBUG:root:training time = %d0.231038
INFO:root:frame =16633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =16634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.868488333333
DEBUG:root: dqn, choose action rondomly, need time 0.00028999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =16637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =16638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame = 16639 State into memory, numbers recorded 456 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000674962997437
INFO:root:random_action_porb = 0.868456666667
DEBUG:root: dqn, choose action rondomly, need time 0.000397000000021
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16640current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:training error  = [[ 242.53442383]
 [ 237.68835449]
 [ 238.44833374]
 [ 250.91708374]
 [ 252.32189941]
 [ 248.31057739]
 [ 251.43943787]
 [ 229.77851868]
 [ 238.07243347]
 [ 228.51182556]
 [ 247.27006531]
 [ 244.33044434]
 [ 263.24984741]
 [ 236.43379211]
 [ 248.21922302]
 [ 240.24905396]]
DEBUG:root:training time = %d0.239365
INFO:root:frame =16641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =16642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.868425
INFO:root:dqn select action Tensor("ArgMax_284:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015985
INFO:root:action choosen by dqn [4]
INFO:root:frame =16644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162124633789
INFO:root:frame =16645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:frame =16646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000393152236938
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.868393333333
DEBUG:root: dqn, choose action rondomly, need time 0.000515999999948
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332832336426
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 251.0708313 ]
 [ 237.57263184]
 [ 235.18162537]
 [ 249.21258545]
 [ 238.2645874 ]
 [ 242.05558777]
 [ 249.79586792]
 [ 284.10681152]
 [ 239.33227539]
 [ 241.07945251]
 [ 245.0809021 ]
 [ 247.59072876]
 [ 260.69613647]
 [ 232.54481506]
 [ 255.84182739]
 [ 244.50315857]]
DEBUG:root:training time = %d0.226399
INFO:root:frame =16649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000322818756104
INFO:root:frame =16650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.868361666667
DEBUG:root: dqn, choose action rondomly, need time 0.000380000000064
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =16653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000528812408447
INFO:root:frame =16654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:random_action_porb = 0.86833
DEBUG:root: dqn, choose action rondomly, need time 0.000537000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:training error  = [[ 259.94476318]
 [ 231.07469177]
 [ 247.91255188]
 [ 238.3361969 ]
 [ 255.09942627]
 [ 248.66848755]
 [ 240.22161865]
 [ 239.58067322]
 [ 252.56918335]
 [ 266.21514893]
 [ 245.47377014]
 [ 251.03794861]
 [ 240.22161865]
 [ 244.18067932]
 [ 266.21514893]
 [ 269.28121948]]
DEBUG:root:training time = %d0.224854
INFO:root:frame =16657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:frame =16658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root:random_action_porb = 0.868298333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999955
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =16661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =16662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.868266666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000064
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 237.60461426]
 [ 249.27232361]
 [ 252.00497437]
 [ 242.206604  ]
 [ 247.00906372]
 [ 257.51885986]
 [ 252.1280365 ]
 [ 249.69555664]
 [ 250.94802856]
 [ 235.32110596]
 [ 236.57740784]
 [ 232.79711914]
 [ 245.19270325]
 [ 262.17745972]
 [ 247.63874817]
 [ 240.34367371]]
DEBUG:root:training time = %d0.257701
INFO:root:frame =16665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265836715698
INFO:root:frame =16666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.868235
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999937
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =16669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =16670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:random_action_porb = 0.868203333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 285.61392212]
 [ 267.27182007]
 [ 239.05569458]
 [ 247.27101135]
 [ 252.18521118]
 [ 264.31945801]
 [ 241.93312073]
 [ 245.6870575 ]
 [ 241.897995  ]
 [ 246.40127563]
 [ 247.13954163]
 [ 285.68612671]
 [ 253.30303955]
 [ 246.0660553 ]
 [ 228.88658142]
 [ 241.75466919]]
DEBUG:root:training time = %d0.231612
INFO:root:frame =16673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:frame =16674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411033630371
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.868171666667
DEBUG:root: dqn, choose action rondomly, need time 0.000536000000011
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =16677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000422954559326
INFO:root:frame =16678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000418901443481
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.86814
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999952
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 260.14654541]
 [ 240.52726746]
 [ 280.94805908]
 [ 253.16026306]
 [ 247.96446228]
 [ 242.8130188 ]
 [ 251.58850098]
 [ 237.76174927]
 [ 255.19107056]
 [ 253.37590027]
 [ 255.51097107]
 [ 245.73394775]
 [ 243.98616028]
 [ 251.18302917]
 [ 236.31742859]
 [ 247.87507629]]
DEBUG:root:training time = %d0.231759
INFO:root:frame =16681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root:frame =16682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487089157104
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.868108333333
DEBUG:root: dqn, choose action rondomly, need time 0.000518000000056
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =16685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =16686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.868076666667
DEBUG:root: dqn, choose action rondomly, need time 0.000525000000039
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 277.82830811]
 [ 242.96426392]
 [ 244.37147522]
 [ 259.14434814]
 [ 261.58184814]
 [ 248.53569031]
 [ 256.74761963]
 [ 266.70733643]
 [ 252.95054626]
 [ 240.9032135 ]
 [ 258.34616089]
 [ 245.35520935]
 [ 245.56079102]
 [ 243.62686157]
 [ 260.94158936]
 [ 254.49343872]]
DEBUG:root:training time = %d0.21934
INFO:root:frame =16689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =16690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000795125961304
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:random_action_porb = 0.868045
DEBUG:root: dqn, choose action rondomly, need time 0.000317999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =16693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =16694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471830368042
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.868013333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000038
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 270.03692627]
 [ 257.79022217]
 [ 228.55058289]
 [ 258.01959229]
 [ 238.72079468]
 [ 285.33959961]
 [ 266.36654663]
 [ 244.09294128]
 [ 242.09927368]
 [ 272.29934692]
 [ 234.21852112]
 [ 245.00924683]
 [ 270.31784058]
 [ 244.2875061 ]
 [ 245.87078857]
 [ 299.46383667]]
DEBUG:root:training time = %d0.221254
INFO:root:frame =16697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =16698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.867981666667
DEBUG:root: dqn, choose action rondomly, need time 0.000349000000028
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =16701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =16702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.86795
DEBUG:root: dqn, choose action rondomly, need time 0.000293000000056
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0003821849823
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 267.85586548]
 [ 248.66175842]
 [ 248.99487305]
 [ 238.29379272]
 [ 266.01602173]
 [ 242.52587891]
 [ 240.71757507]
 [ 242.08503723]
 [ 293.08377075]
 [ 242.94332886]
 [ 222.49935913]
 [ 277.11154175]
 [ 244.61291504]
 [ 242.17906189]
 [ 241.02732849]
 [ 248.53953552]]
DEBUG:root:training time = %d0.222646
INFO:root:frame =16705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =16706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480890274048
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.867918333333
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000021
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304222106934
INFO:root:frame =16709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =16710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
INFO:root:frame = 16711 State into memory, numbers recorded 457 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:random_action_porb = 0.867886666667
INFO:root:dqn select action Tensor("ArgMax_285:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014781
INFO:root:action choosen by dqn [4]
INFO:root:frame =16712current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 284.54730225]
 [ 266.59970093]
 [ 246.92945862]
 [ 245.47663879]
 [ 261.13388062]
 [ 269.99481201]
 [ 243.60400391]
 [ 250.92868042]
 [ 250.90838623]
 [ 250.22532654]
 [ 282.98657227]
 [ 260.97906494]
 [ 280.06994629]
 [ 251.272995  ]
 [ 275.35760498]
 [ 244.91275024]]
DEBUG:root:training time = %d0.226188
INFO:root:frame =16713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000385046005249
INFO:root:frame =16714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047492980957
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.867855
DEBUG:root: dqn, choose action rondomly, need time 0.000352000000021
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =16717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =16718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame = 16719 State into memory, numbers recorded 458 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000549077987671
INFO:root:random_action_porb = 0.867823333333
DEBUG:root: dqn, choose action rondomly, need time 0.00029799999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16720current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 245.22998047]
 [ 243.41921997]
 [ 261.36767578]
 [ 284.7677002 ]
 [ 242.17051697]
 [ 246.24513245]
 [ 269.24014282]
 [ 256.49926758]
 [ 252.97966003]
 [ 259.05496216]
 [ 249.10565186]
 [ 242.78543091]
 [ 294.95504761]
 [ 247.07527161]
 [ 257.01858521]
 [ 240.53579712]]
DEBUG:root:training time = %d0.22703
INFO:root:frame =16721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:frame =16722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000245094299316
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.867791666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000043
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =16725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =16726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324010848999
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:random_action_porb = 0.86776
INFO:root:dqn select action Tensor("ArgMax_286:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.0116549999999
INFO:root:action choosen by dqn [4]
INFO:root:frame =16728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000383138656616
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 245.20991516]
 [ 294.48458862]
 [ 246.81245422]
 [ 267.25784302]
 [ 255.03216553]
 [ 258.58166504]
 [ 258.61895752]
 [ 235.48872375]
 [ 276.34597778]
 [ 249.97434998]
 [ 266.3296814 ]
 [ 235.19752502]
 [ 258.3039856 ]
 [ 256.51980591]
 [ 254.58886719]
 [ 278.08676147]]
DEBUG:root:training time = %d0.225037
INFO:root:frame =16729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =16730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000514984130859
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:random_action_porb = 0.867728333333
DEBUG:root: dqn, choose action rondomly, need time 0.000378000000069
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =16733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000554084777832
INFO:root:frame =16734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:random_action_porb = 0.867696666667
DEBUG:root: dqn, choose action rondomly, need time 0.000279999999975
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 240.53485107]
 [ 230.49333191]
 [ 260.58972168]
 [ 279.38497925]
 [ 272.48471069]
 [ 249.97628784]
 [ 249.94830322]
 [ 242.22370911]
 [ 245.90428162]
 [ 254.89183044]
 [ 266.46218872]
 [ 244.65206909]
 [ 245.90428162]
 [ 264.50900269]
 [ 264.29760742]
 [ 260.86862183]]
DEBUG:root:training time = %d0.225355
INFO:root:frame =16737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:frame =16738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509023666382
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.867665
DEBUG:root: dqn, choose action rondomly, need time 0.000448000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =16741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441789627075
INFO:root:frame =16742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.867633333333
DEBUG:root: dqn, choose action rondomly, need time 0.000272000000109
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 255.11404419]
 [ 271.82415771]
 [ 244.44207764]
 [ 283.72015381]
 [ 264.37799072]
 [ 270.53161621]
 [ 247.17216492]
 [ 263.10922241]
 [ 266.58374023]
 [ 242.30065918]
 [ 256.3614502 ]
 [ 255.84671021]
 [ 258.08822632]
 [ 256.61657715]
 [ 253.93095398]
 [ 254.14108276]]
DEBUG:root:training time = %d0.211243
INFO:root:frame =16745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =16746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000362873077393
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root:random_action_porb = 0.867601666667
DEBUG:root: dqn, choose action rondomly, need time 0.00025299999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000209808349609
INFO:root:frame =16749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000373840332031
INFO:root:frame =16750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000287055969238
DEBUG:root: save sample needs time = 0.000105142593384
INFO:root:random_action_porb = 0.86757
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:training error  = [[ 251.34362793]
 [ 262.74996948]
 [ 267.65811157]
 [ 254.56744385]
 [ 244.98440552]
 [ 255.50317383]
 [ 254.85966492]
 [ 247.24127197]
 [ 246.04595947]
 [ 250.11526489]
 [ 260.74935913]
 [ 231.87794495]
 [ 247.27774048]
 [ 247.27774048]
 [ 239.39743042]
 [ 261.60949707]]
DEBUG:root:training time = %d0.230528
INFO:root:frame =16753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000357866287231
INFO:root:frame =16754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.867538333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999917
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326156616211
INFO:root:frame =16757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =16758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000355005264282
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:random_action_porb = 0.867506666667
DEBUG:root: dqn, choose action rondomly, need time 0.00019999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 254.65022278]
 [ 263.28448486]
 [ 262.00848389]
 [ 238.10728455]
 [ 250.41169739]
 [ 257.78533936]
 [ 254.36102295]
 [ 246.76739502]
 [ 256.84249878]
 [ 249.40629578]
 [ 256.46896362]
 [ 289.21273804]
 [ 245.17932129]
 [ 245.16690063]
 [ 263.80767822]
 [ 283.65744019]]
DEBUG:root:training time = %d0.19216
INFO:root:frame =16761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =16762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:random_action_porb = 0.867475
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999952
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =16765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =16766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame = 16767 State into memory, numbers recorded 459 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:random_action_porb = 0.867443333333
INFO:root:dqn select action Tensor("ArgMax_287:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.0152440000001
INFO:root:action choosen by dqn [4]
INFO:root:frame =16768current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000823974609375
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 254.70768738]
 [ 258.09802246]
 [ 251.2797699 ]
 [ 262.89245605]
 [ 304.40921021]
 [ 248.92842102]
 [ 273.91824341]
 [ 215.60075378]
 [ 256.16702271]
 [ 254.39900208]
 [ 265.0632019 ]
 [ 261.28579712]
 [ 239.78193665]
 [ 262.59069824]
 [ 215.60075378]
 [ 250.11526489]]
DEBUG:root:training time = %d0.212151
INFO:root:frame =16769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =16770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000280857086182
DEBUG:root: save sample needs time = 0.000141143798828
INFO:root:random_action_porb = 0.867411666667
DEBUG:root: dqn, choose action rondomly, need time 0.000198000000069
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =16773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =16774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.86738
DEBUG:root: dqn, choose action rondomly, need time 0.00028599999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 251.56913757]
 [ 263.15576172]
 [ 260.60351562]
 [ 261.68157959]
 [ 270.2796936 ]
 [ 250.59136963]
 [ 257.99899292]
 [ 250.14904785]
 [ 250.11430359]
 [ 246.00669861]
 [ 247.56959534]
 [ 261.87017822]
 [ 255.40464783]
 [ 248.35290527]
 [ 251.85481262]
 [ 250.58267212]]
DEBUG:root:training time = %d0.219558
INFO:root:frame =16777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:frame =16778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000106811523438
INFO:root:random_action_porb = 0.867348333333
DEBUG:root: dqn, choose action rondomly, need time 0.00028599999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000217199325562
INFO:root:frame =16781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =16782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.867316666667
INFO:root:dqn select action Tensor("ArgMax_288:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012916
INFO:root:action choosen by dqn [4]
INFO:root:frame =16784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000386953353882
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 265.60406494]
 [ 258.48156738]
 [ 255.98242188]
 [ 237.28108215]
 [ 234.94393921]
 [ 269.01486206]
 [ 259.19055176]
 [ 292.48535156]
 [ 256.20510864]
 [ 267.46542358]
 [ 261.71020508]
 [ 262.12210083]
 [ 245.15925598]
 [ 258.5090332 ]
 [ 309.23944092]
 [ 260.05105591]]
DEBUG:root:training time = %d0.217126
INFO:root:frame =16785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =16786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.867285
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999925
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =16789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =16790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427007675171
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.867253333333
DEBUG:root: dqn, choose action rondomly, need time 0.000348000000031
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000518083572388
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 253.92997742]
 [ 263.9524231 ]
 [ 239.92939758]
 [ 252.0088501 ]
 [ 270.45935059]
 [ 253.2467041 ]
 [ 270.58682251]
 [ 256.92074585]
 [ 256.30184937]
 [ 251.82865906]
 [ 252.0088501 ]
 [ 252.04663086]
 [ 289.8130188 ]
 [ 244.32376099]
 [ 246.44343567]
 [ 260.74050903]]
DEBUG:root:training time = %d0.213838
INFO:root:frame =16793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =16794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000495195388794
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.867221666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000051
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =16797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =16798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.86719
DEBUG:root: dqn, choose action rondomly, need time 0.000279999999975
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 249.69651794]
 [ 249.78622437]
 [ 271.51229858]
 [ 254.44670105]
 [ 290.00839233]
 [ 254.77101135]
 [ 266.68939209]
 [ 253.35258484]
 [ 261.35879517]
 [ 260.98397827]
 [ 259.42739868]
 [ 246.46833801]
 [ 261.94229126]
 [ 286.2321167 ]
 [ 240.66549683]
 [ 259.60241699]]
DEBUG:root:training time = %d0.220035
INFO:root:frame =16801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250816345215
INFO:root:frame =16802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000507831573486
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.867158333333
DEBUG:root: dqn, choose action rondomly, need time 0.000258000000031
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root:frame =16805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =16806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.867126666667
DEBUG:root: dqn, choose action rondomly, need time 0.000164000000041
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 258.45605469]
 [ 270.91824341]
 [ 255.118927  ]
 [ 252.15516663]
 [ 255.53829956]
 [ 259.36547852]
 [ 254.7447052 ]
 [ 244.90606689]
 [ 248.07691956]
 [ 252.45474243]
 [ 282.46316528]
 [ 254.2461853 ]
 [ 256.26763916]
 [ 267.38955688]
 [ 286.72592163]
 [ 272.88885498]]
DEBUG:root:training time = %d0.200435
INFO:root:frame =16809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00040602684021
INFO:root:frame =16810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.867095
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =16813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =16814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000243902206421
DEBUG:root: save sample needs time = 9.20295715332e-05
INFO:root:random_action_porb = 0.867063333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999925
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 253.01557922]
 [ 257.37783813]
 [ 266.50802612]
 [ 272.7053833 ]
 [ 260.48431396]
 [ 261.60852051]
 [ 275.58248901]
 [ 262.56698608]
 [ 291.78329468]
 [ 268.51754761]
 [ 257.11154175]
 [ 254.99804688]
 [ 268.97381592]
 [ 267.50436401]
 [ 259.89459229]
 [ 267.88183594]]
DEBUG:root:training time = %d0.233853
INFO:root:frame =16817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =16818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000296831130981
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.867031666667
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000391960144043
INFO:root:frame =16821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000341892242432
INFO:root:frame =16822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.867
DEBUG:root: dqn, choose action rondomly, need time 0.000193999999965
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 278.17022705]
 [ 266.34960938]
 [ 256.19631958]
 [ 261.01947021]
 [ 251.53138733]
 [ 250.9538269 ]
 [ 236.75674438]
 [ 250.43101501]
 [ 253.10977173]
 [ 252.65940857]
 [ 243.46875   ]
 [ 251.81703186]
 [ 265.5244751 ]
 [ 243.46875   ]
 [ 260.36907959]
 [ 256.74273682]]
DEBUG:root:training time = %d0.229658
INFO:root:frame =16825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =16826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:random_action_porb = 0.866968333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291999999945
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =16829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470876693726
INFO:root:frame =16830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.866936666667
DEBUG:root: dqn, choose action rondomly, need time 0.000324999999975
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 265.68264771]
 [ 265.78610229]
 [ 254.07394409]
 [ 253.81912231]
 [ 258.43447876]
 [ 255.99804688]
 [ 264.03771973]
 [ 266.14346313]
 [ 270.6199646 ]
 [ 250.29774475]
 [ 286.20629883]
 [ 265.07214355]
 [ 274.61166382]
 [ 258.46881104]
 [ 260.18984985]
 [ 255.81546021]]
DEBUG:root:training time = %d0.215637
INFO:root:frame =16833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =16834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000568866729736
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:random_action_porb = 0.866905
DEBUG:root: dqn, choose action rondomly, need time 0.00027399999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =16837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000633955001831
INFO:root:frame =16838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000360012054443
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.866873333333
INFO:root:dqn select action Tensor("ArgMax_289:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010808
INFO:root:action choosen by dqn [4]
INFO:root:frame =16840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:training error  = [[ 262.89343262]
 [ 263.87606812]
 [ 254.91424561]
 [ 264.53878784]
 [ 253.85995483]
 [ 253.58384705]
 [ 263.87606812]
 [ 265.32461548]
 [ 262.88058472]
 [ 253.86384583]
 [ 262.47897339]
 [ 261.80895996]
 [ 258.76623535]
 [ 259.24557495]
 [ 261.47723389]
 [ 264.60131836]]
DEBUG:root:training time = %d0.214093
INFO:root:frame =16841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =16842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485181808472
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:random_action_porb = 0.866841666667
INFO:root:dqn select action Tensor("ArgMax_290:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011448
INFO:root:action choosen by dqn [4]
INFO:root:frame =16844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:frame =16845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =16846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.86681
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000394105911255
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 306.93182373]
 [ 264.78106689]
 [ 249.51040649]
 [ 243.49827576]
 [ 255.48170471]
 [ 249.71870422]
 [ 255.44561768]
 [ 254.38536072]
 [ 258.10684204]
 [ 248.17114258]
 [ 266.61065674]
 [ 257.36508179]
 [ 254.49050903]
 [ 265.85577393]
 [ 252.57792664]
 [ 255.20861816]]
DEBUG:root:training time = %d0.214409
INFO:root:frame =16849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000363111495972
INFO:root:frame =16850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000347852706909
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:random_action_porb = 0.866778333333
DEBUG:root: dqn, choose action rondomly, need time 0.000324000000091
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =16853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000475883483887
INFO:root:frame =16854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.866746666667
INFO:root:dqn select action Tensor("ArgMax_291:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00854299999992
INFO:root:action choosen by dqn [4]
INFO:root:frame =16856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180006027222
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 250.9954071 ]
 [ 258.31478882]
 [ 256.95010376]
 [ 252.84474182]
 [ 267.83288574]
 [ 286.26516724]
 [ 252.87385559]
 [ 258.15588379]
 [ 253.78897095]
 [ 265.41409302]
 [ 266.35559082]
 [ 257.07339478]
 [ 261.71612549]
 [ 274.94351196]
 [ 249.32919312]
 [ 294.71713257]]
DEBUG:root:training time = %d0.218961
INFO:root:frame =16857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000355958938599
INFO:root:frame =16858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.866715
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =16861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046181678772
INFO:root:frame =16862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.866683333333
DEBUG:root: dqn, choose action rondomly, need time 0.000386000000049
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 269.21310425]
 [ 233.75357056]
 [ 256.53543091]
 [ 261.58581543]
 [ 237.15040588]
 [ 251.66693115]
 [ 260.58676147]
 [ 299.66455078]
 [ 259.27801514]
 [ 261.36965942]
 [ 261.40716553]
 [ 256.10839844]
 [ 265.13674927]
 [ 298.54351807]
 [ 254.79147339]
 [ 257.03033447]]
DEBUG:root:training time = %d0.232115
INFO:root:frame =16865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =16866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame = 16867 State into memory, numbers recorded 460 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.00049901008606
INFO:root:random_action_porb = 0.866651666667
DEBUG:root: dqn, choose action rondomly, need time 0.000180999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16868current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000180006027222
INFO:root:frame =16869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =16870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000320911407471
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:random_action_porb = 0.86662
DEBUG:root: dqn, choose action rondomly, need time 0.000166000000036
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 257.7510376 ]
 [ 247.79052734]
 [ 254.18583679]
 [ 264.62911987]
 [ 263.61834717]
 [ 252.72053528]
 [ 253.02044678]
 [ 261.75366211]
 [ 292.91244507]
 [ 253.24475098]
 [ 260.90411377]
 [ 266.73025513]
 [ 295.69766235]
 [ 268.54754639]
 [ 265.89160156]
 [ 300.39929199]]
DEBUG:root:training time = %d0.213531
INFO:root:frame =16873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00036883354187
INFO:root:frame =16874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000244855880737
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root:random_action_porb = 0.866588333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999968
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =16877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =16878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000497817993164
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.866556666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000038
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:training error  = [[ 268.31356812]
 [ 277.84356689]
 [ 275.8520813 ]
 [ 284.47216797]
 [ 288.23477173]
 [ 273.47900391]
 [ 280.04748535]
 [ 250.67060852]
 [ 260.70205688]
 [ 262.58477783]
 [ 254.62586975]
 [ 254.63755798]
 [ 257.71673584]
 [ 274.59851074]
 [ 261.36572266]
 [ 263.86715698]]
DEBUG:root:training time = %d0.225683
INFO:root:frame =16881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =16882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.866525
DEBUG:root: dqn, choose action rondomly, need time 0.000323999999978
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =16885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0003821849823
INFO:root:frame =16886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046181678772
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:random_action_porb = 0.866493333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 267.83886719]
 [ 271.30718994]
 [ 259.68701172]
 [ 273.78292847]
 [ 268.58456421]
 [ 317.77130127]
 [ 250.49766541]
 [ 270.28771973]
 [ 262.28320312]
 [ 270.39208984]
 [ 256.35266113]
 [ 272.31948853]
 [ 269.47055054]
 [ 278.67538452]
 [ 247.13858032]
 [ 270.89315796]]
DEBUG:root:training time = %d0.231398
INFO:root:frame =16889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =16890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000408172607422
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.866461666667
DEBUG:root: dqn, choose action rondomly, need time 0.000350000000026
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =16893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000504970550537
INFO:root:frame =16894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486135482788
DEBUG:root: save sample needs time = 0.00010085105896
INFO:root:random_action_porb = 0.86643
DEBUG:root: dqn, choose action rondomly, need time 0.000307999999904
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:training error  = [[ 269.62887573]
 [ 275.61087036]
 [ 271.36450195]
 [ 261.30157471]
 [ 262.85287476]
 [ 266.75817871]
 [ 253.36618042]
 [ 289.32070923]
 [ 269.33731079]
 [ 266.93466187]
 [ 276.69714355]
 [ 264.84463501]
 [ 258.06173706]
 [ 263.67483521]
 [ 264.4414978 ]
 [ 254.97660828]]
DEBUG:root:training time = %d0.236591
INFO:root:frame =16897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =16898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:random_action_porb = 0.866398333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =16901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =16902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:random_action_porb = 0.866366666667
DEBUG:root: dqn, choose action rondomly, need time 0.000324999999975
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 264.89630127]
 [ 268.24258423]
 [ 259.14730835]
 [ 253.94749451]
 [ 266.75018311]
 [ 272.77593994]
 [ 260.92877197]
 [ 263.09832764]
 [ 280.70974731]
 [ 266.11358643]
 [ 316.77438354]
 [ 279.46047974]
 [ 243.81744385]
 [ 250.33830261]
 [ 270.06903076]
 [ 268.24258423]]
DEBUG:root:training time = %d0.237645
INFO:root:frame =16905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =16906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480175018311
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.866335
INFO:root:dqn select action Tensor("ArgMax_292:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.0115089999999
INFO:root:action choosen by dqn [4]
INFO:root:frame =16908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000360012054443
INFO:root:frame =16909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =16910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438213348389
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.866303333333
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:training error  = [[ 289.46502686]
 [ 261.60653687]
 [ 263.97323608]
 [ 272.27719116]
 [ 276.86367798]
 [ 276.8210144 ]
 [ 254.42333984]
 [ 255.53536987]
 [ 261.60653687]
 [ 272.15231323]
 [ 250.33346558]
 [ 260.57000732]
 [ 270.57879639]
 [ 251.84512329]
 [ 281.59805298]
 [ 278.16412354]]
DEBUG:root:training time = %d0.229096
INFO:root:frame =16913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =16914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000516891479492
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.866271666667
DEBUG:root: dqn, choose action rondomly, need time 0.000349999999912
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =16917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046181678772
INFO:root:frame =16918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.86624
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999942
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00037693977356
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 265.39520264]
 [ 263.90383911]
 [ 294.74124146]
 [ 318.1206665 ]
 [ 273.82028198]
 [ 291.88754272]
 [ 258.6680603 ]
 [ 294.17044067]
 [ 259.84637451]
 [ 296.26678467]
 [ 272.34869385]
 [ 261.30554199]
 [ 280.53900146]
 [ 279.88305664]
 [ 283.53204346]
 [ 256.17385864]]
DEBUG:root:training time = %d0.217319
INFO:root:frame =16921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =16922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.866208333333
INFO:root:dqn select action Tensor("ArgMax_293:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01545
INFO:root:action choosen by dqn [4]
INFO:root:frame =16924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174045562744
INFO:root:frame =16925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame =16926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame = 16927 State into memory, numbers recorded 461 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00131416320801
INFO:root:random_action_porb = 0.866176666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000041
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =16928current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 269.25317383]
 [ 270.20846558]
 [ 271.38259888]
 [ 252.92918396]
 [ 283.05432129]
 [ 282.84899902]
 [ 291.60397339]
 [ 262.75491333]
 [ 302.50814819]
 [ 269.88751221]
 [ 290.66879272]
 [ 262.34844971]
 [ 270.38607788]
 [ 304.7543335 ]
 [ 270.20846558]
 [ 282.3503418 ]]
DEBUG:root:training time = %d0.235963
INFO:root:frame =16929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =16930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame = 16931 State into memory, numbers recorded 462 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:random_action_porb = 0.866145
DEBUG:root: dqn, choose action rondomly, need time 0.000178000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16932current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000171899795532
INFO:root:frame =16933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =16934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.866113333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030599999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 257.80001831]
 [ 326.80206299]
 [ 267.64910889]
 [ 267.39157104]
 [ 239.85661316]
 [ 221.9216156 ]
 [ 258.84085083]
 [ 264.80093384]
 [ 262.01541138]
 [ 264.64801025]
 [ 259.68011475]
 [ 251.38911438]
 [ 262.36227417]
 [ 260.90115356]
 [ 270.91925049]
 [ 295.11755371]]
DEBUG:root:training time = %d0.248234
INFO:root:frame =16937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =16938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000382900238037
INFO:root:frame = 16939 State into memory, numbers recorded 463 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000586032867432
INFO:root:random_action_porb = 0.866081666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999952
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16940current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =16941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =16942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame = 16943 State into memory, numbers recorded 464 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000593900680542
INFO:root:random_action_porb = 0.86605
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000021
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16944current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 267.03637695]
 [ 275.41635132]
 [ 265.76123047]
 [ 277.47335815]
 [ 266.69735718]
 [ 275.60073853]
 [ 270.4352417 ]
 [ 279.82995605]
 [ 273.06332397]
 [ 320.39230347]
 [ 277.9382019 ]
 [ 281.41168213]
 [ 262.20315552]
 [ 298.91061401]
 [ 254.8187561 ]
 [ 259.18170166]]
DEBUG:root:training time = %d0.207244
INFO:root:frame =16945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:frame =16946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.00011682510376
INFO:root:random_action_porb = 0.866018333333
DEBUG:root: dqn, choose action rondomly, need time 0.000269000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000182151794434
INFO:root:frame =16949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =16950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:random_action_porb = 0.865986666667
INFO:root:dqn select action Tensor("ArgMax_294:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013592
INFO:root:action choosen by dqn [4]
INFO:root:frame =16952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 270.43225098]
 [ 261.05300903]
 [ 299.96572876]
 [ 276.28613281]
 [ 266.11856079]
 [ 267.82589722]
 [ 290.96542358]
 [ 304.76605225]
 [ 281.14553833]
 [ 258.74264526]
 [ 274.36694336]
 [ 265.25900269]
 [ 261.99365234]
 [ 278.13867188]
 [ 298.39376831]
 [ 267.50036621]]
DEBUG:root:training time = %d0.222166
INFO:root:frame =16953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =16954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.865955
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174999237061
INFO:root:frame =16957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000402927398682
INFO:root:frame =16958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444173812866
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.865923333333
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 269.10195923]
 [ 277.81100464]
 [ 292.17959595]
 [ 260.62225342]
 [ 296.9994812 ]
 [ 288.08660889]
 [ 286.53268433]
 [ 281.27859497]
 [ 250.64935303]
 [ 290.11856079]
 [ 300.04290771]
 [ 271.09811401]
 [ 268.75164795]
 [ 283.38098145]
 [ 260.75231934]
 [ 285.09942627]]
DEBUG:root:training time = %d0.237753
INFO:root:frame =16961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =16962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000276803970337
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.865891666667
DEBUG:root: dqn, choose action rondomly, need time 0.000361999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =16965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =16966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:random_action_porb = 0.86586
INFO:root:dqn select action Tensor("ArgMax_295:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.0120010000001
INFO:root:action choosen by dqn [4]
INFO:root:frame =16968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000408887863159
INFO:root:training error  = [[ 272.53707886]
 [ 278.39016724]
 [ 284.87173462]
 [ 282.58422852]
 [ 274.29821777]
 [ 271.94494629]
 [ 272.59048462]
 [ 284.17474365]
 [ 276.67886353]
 [ 265.43795776]
 [ 281.81829834]
 [ 261.98278809]
 [ 276.78039551]
 [ 273.10769653]
 [ 257.36410522]
 [ 278.89651489]]
DEBUG:root:training time = %d0.233175
INFO:root:frame =16969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =16970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000109910964966
INFO:root:random_action_porb = 0.865828333333
DEBUG:root: dqn, choose action rondomly, need time 0.000191000000086
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =16972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162124633789
INFO:root:frame =16973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000499963760376
INFO:root:frame =16974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000492095947266
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.865796666667
DEBUG:root: dqn, choose action rondomly, need time 0.000405000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =16976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 302.44869995]
 [ 267.61618042]
 [ 291.58209229]
 [ 279.46252441]
 [ 280.09753418]
 [ 252.08442688]
 [ 300.28717041]
 [ 273.68597412]
 [ 313.17810059]
 [ 286.50894165]
 [ 274.73608398]
 [ 309.78601074]
 [ 269.04190063]
 [ 273.62237549]
 [ 268.02468872]
 [ 266.50302124]]
DEBUG:root:training time = %d0.215489
INFO:root:frame =16977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =16978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00036096572876
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:random_action_porb = 0.865765
DEBUG:root: dqn, choose action rondomly, need time 0.000355000000013
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =16980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =16981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =16982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00056791305542
DEBUG:root: save sample needs time = 0.000103950500488
INFO:root:random_action_porb = 0.865733333333
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 259.60931396]
 [ 288.4493103 ]
 [ 268.82769775]
 [ 276.83322144]
 [ 296.32141113]
 [ 283.52587891]
 [ 270.18740845]
 [ 274.23959351]
 [ 277.90460205]
 [ 261.40518188]
 [ 265.59509277]
 [ 261.25915527]
 [ 298.61102295]
 [ 262.30496216]
 [ 263.61141968]
 [ 281.94436646]]
DEBUG:root:training time = %d0.212341
INFO:root:frame =16985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:frame =16986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241041183472
DEBUG:root: save sample needs time = 0.000174999237061
INFO:root:random_action_porb = 0.865701666667
DEBUG:root: dqn, choose action rondomly, need time 0.000169000000028
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000137805938721
INFO:root:frame =16989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =16990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231981277466
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.86567
INFO:root:dqn select action Tensor("ArgMax_296:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010353
INFO:root:action choosen by dqn [4]
INFO:root:frame =16992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 266.78210449]
 [ 276.58853149]
 [ 306.09408569]
 [ 270.76959229]
 [ 271.36950684]
 [ 275.95346069]
 [ 264.22915649]
 [ 271.72958374]
 [ 265.85876465]
 [ 272.96246338]
 [ 258.85949707]
 [ 320.49282837]
 [ 259.20626831]
 [ 271.53042603]
 [ 271.01974487]
 [ 290.56680298]]
DEBUG:root:training time = %d0.200436
INFO:root:frame =16993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =16994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000385999679565
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:random_action_porb = 0.865638333333
DEBUG:root: dqn, choose action rondomly, need time 0.000206999999932
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =16996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =16997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000493049621582
INFO:root:frame =16998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000330924987793
DEBUG:root: save sample needs time = 0.00020694732666
DEBUG:root:one frame running time = 0.00746700000002
DEBUG:root:total training time = 525.931053
INFO:root:frame num = 17000 frame round: 0
INFO:root:random_action_porb = 0.865606666667
DEBUG:root: dqn, choose action rondomly, need time 0.000496999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =17000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 282.61090088]
 [ 283.69854736]
 [ 289.10375977]
 [ 271.50527954]
 [ 261.6746521 ]
 [ 259.59555054]
 [ 280.4173584 ]
 [ 268.07766724]
 [ 268.49453735]
 [ 312.0546875 ]
 [ 283.36557007]
 [ 266.25500488]
 [ 272.54818726]
 [ 292.99914551]
 [ 311.62680054]
 [ 264.47824097]]
DEBUG:root:training time = %d0.242414
INFO:root:frame =17001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:frame =17002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000206232070923
INFO:root:random_action_porb = 0.865575
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =17004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =17005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =17006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame = 17007 State into memory, numbers recorded 465 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000565052032471
INFO:root:random_action_porb = 0.865543333333
DEBUG:root: dqn, choose action rondomly, need time 0.000485000000026
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =17008current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000363111495972
INFO:root:training error  = [[ 278.75384521]
 [ 300.47970581]
 [ 272.8303833 ]
 [ 279.39007568]
 [ 279.81057739]
 [ 266.10165405]
 [ 276.47790527]
 [ 272.24899292]
 [ 280.95727539]
 [ 294.77059937]
 [ 276.50326538]
 [ 275.06903076]
 [ 274.2507019 ]
 [ 263.27856445]
 [ 257.05871582]
 [ 287.38464355]]
DEBUG:root:training time = %d0.210745
INFO:root:frame =17009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =17010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000322103500366
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.865511666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000033
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =17013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000405073165894
INFO:root:frame =17014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:random_action_porb = 0.86548
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000061
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =17016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 308.21206665]
 [ 269.02886963]
 [ 263.62924194]
 [ 257.85394287]
 [ 283.21865845]
 [ 275.40216064]
 [ 249.28196716]
 [ 275.40420532]
 [ 255.94824219]
 [ 276.74081421]
 [ 283.76846313]
 [ 272.59857178]
 [ 275.66964722]
 [ 276.67990112]
 [ 257.85394287]
 [ 280.10058594]]
DEBUG:root:training time = %d0.234056
INFO:root:frame =17017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000191926956177
INFO:root:frame =17018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000496864318848
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.865448333333
INFO:root:dqn select action Tensor("ArgMax_297:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.0132229999999
INFO:root:action choosen by dqn [4]
INFO:root:frame =17020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180959701538
INFO:root:frame =17021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =17022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000242948532104
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.865416666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000043
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 259.03237915]
 [ 304.48587036]
 [ 271.046875  ]
 [ 312.40304565]
 [ 304.82678223]
 [ 274.9354248 ]
 [ 275.56323242]
 [ 298.08496094]
 [ 266.02597046]
 [ 273.47698975]
 [ 263.70062256]
 [ 265.69656372]
 [ 260.37200928]
 [ 275.86627197]
 [ 294.51705933]
 [ 282.89007568]]
DEBUG:root:training time = %d0.204639
INFO:root:frame =17025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:frame =17026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227928161621
DEBUG:root: save sample needs time = 9.51290130615e-05
INFO:root:random_action_porb = 0.865385
DEBUG:root: dqn, choose action rondomly, need time 0.000248000000056
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =17029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:frame =17030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047492980957
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:random_action_porb = 0.865353333333
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 275.65240479]
 [ 278.32397461]
 [ 280.90304565]
 [ 280.95419312]
 [ 286.42834473]
 [ 277.27108765]
 [ 302.93505859]
 [ 274.72293091]
 [ 269.66394043]
 [ 281.62365723]
 [ 285.69955444]
 [ 270.71035767]
 [ 260.67938232]
 [ 279.76052856]
 [ 293.90985107]
 [ 257.22705078]]
DEBUG:root:training time = %d0.221813
INFO:root:frame =17033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =17034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame = 17035 State into memory, numbers recorded 466 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000395059585571
INFO:root:random_action_porb = 0.865321666667
INFO:root:dqn select action Tensor("ArgMax_298:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012642
INFO:root:action choosen by dqn [4]
INFO:root:frame =17036current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.00048303604126
INFO:root:frame =17037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =17038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.86529
INFO:root:dqn select action Tensor("ArgMax_299:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010855
INFO:root:action choosen by dqn [4]
INFO:root:frame =17040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00035285949707
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 262.81924438]
 [ 286.45004272]
 [ 270.3348999 ]
 [ 283.2361145 ]
 [ 275.97271729]
 [ 284.53805542]
 [ 277.02416992]
 [ 276.7885437 ]
 [ 318.05535889]
 [ 276.24249268]
 [ 291.26950073]
 [ 279.85955811]
 [ 275.40216064]
 [ 294.30130005]
 [ 270.3348999 ]
 [ 279.85955811]]
DEBUG:root:training time = %d0.229706
INFO:root:frame =17041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =17042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.865258333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000041
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =17044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =17045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000591993331909
INFO:root:frame =17046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.865226666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000066
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =17048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 295.23080444]
 [ 277.81304932]
 [ 279.19320679]
 [ 262.42358398]
 [ 281.48950195]
 [ 288.29589844]
 [ 271.66921997]
 [ 271.59680176]
 [ 277.93005371]
 [ 270.68725586]
 [ 282.7925415 ]
 [ 272.80718994]
 [ 305.90188599]
 [ 326.63766479]
 [ 284.96032715]
 [ 318.86135864]]
DEBUG:root:training time = %d0.228153
INFO:root:frame =17049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =17050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000515937805176
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.865195
INFO:root:dqn select action Tensor("ArgMax_300:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012893
INFO:root:action choosen by dqn [4]
INFO:root:frame =17052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000381946563721
INFO:root:frame =17053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000379085540771
INFO:root:frame =17054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.865163333333
DEBUG:root: dqn, choose action rondomly, need time 0.000529999999912
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 279.49008179]
 [ 279.64926147]
 [ 304.61477661]
 [ 257.84512329]
 [ 282.43753052]
 [ 279.29519653]
 [ 313.37792969]
 [ 277.96566772]
 [ 298.12921143]
 [ 292.39978027]
 [ 284.93972778]
 [ 296.15753174]
 [ 281.94537354]
 [ 277.91375732]
 [ 283.61938477]
 [ 294.42486572]]
DEBUG:root:training time = %d0.225233
INFO:root:frame =17057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =17058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00051212310791
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.865131666667
DEBUG:root: dqn, choose action rondomly, need time 0.000352000000021
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =17061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =17062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame = 17063 State into memory, numbers recorded 467 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000623941421509
INFO:root:random_action_porb = 0.8651
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17064current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 267.61218262]
 [ 335.90228271]
 [ 256.8581543 ]
 [ 333.58734131]
 [ 308.80276489]
 [ 289.37988281]
 [ 279.66867065]
 [ 270.83789062]
 [ 261.36471558]
 [ 307.47207642]
 [ 273.69000244]
 [ 294.62286377]
 [ 287.33706665]
 [ 292.59393311]
 [ 282.25701904]
 [ 268.19958496]]
DEBUG:root:training time = %d0.221107
INFO:root:frame =17065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =17066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.865068333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000048
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =17069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =17070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.865036666667
DEBUG:root: dqn, choose action rondomly, need time 0.000189999999975
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =17072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016713142395
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 307.27090454]
 [ 263.42614746]
 [ 277.49978638]
 [ 305.94458008]
 [ 277.26904297]
 [ 313.99087524]
 [ 277.49978638]
 [ 300.54953003]
 [ 281.75274658]
 [ 285.24990845]
 [ 278.5378418 ]
 [ 296.37817383]
 [ 280.18334961]
 [ 281.4147644 ]
 [ 279.19219971]
 [ 282.13500977]]
DEBUG:root:training time = %d0.239531
INFO:root:frame =17073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280141830444
INFO:root:frame =17074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.865005
INFO:root:dqn select action Tensor("ArgMax_301:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00881099999992
INFO:root:action choosen by dqn [4]
INFO:root:frame =17076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:frame =17077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =17078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.864973333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 253.70439148]
 [ 268.43954468]
 [ 293.54476929]
 [ 297.11624146]
 [ 281.09335327]
 [ 279.2819519 ]
 [ 278.21911621]
 [ 287.22015381]
 [ 284.69146729]
 [ 278.68048096]
 [ 270.70230103]
 [ 275.6138916 ]
 [ 295.34197998]
 [ 285.72637939]
 [ 322.00686646]
 [ 284.49584961]]
DEBUG:root:training time = %d0.223595
INFO:root:frame =17081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =17082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274896621704
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.864941666667
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000026
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =17084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =17085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =17086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000516891479492
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:random_action_porb = 0.86491
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000104
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =17088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 285.28909302]
 [ 268.81066895]
 [ 283.21865845]
 [ 284.32086182]
 [ 271.67022705]
 [ 268.34854126]
 [ 262.05688477]
 [ 284.94485474]
 [ 283.77050781]
 [ 259.4942627 ]
 [ 284.18295288]
 [ 269.90856934]
 [ 300.63842773]
 [ 295.84146118]
 [ 295.84146118]
 [ 275.26037598]]
DEBUG:root:training time = %d0.224068
INFO:root:frame =17089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266790390015
INFO:root:frame =17090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:random_action_porb = 0.864878333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000373840332031
INFO:root:frame =17093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491142272949
INFO:root:frame =17094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000162124633789
INFO:root:random_action_porb = 0.864846666667
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000018
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:training error  = [[ 286.96987915]
 [ 265.83187866]
 [ 305.94671631]
 [ 273.85766602]
 [ 252.02822876]
 [ 280.60238647]
 [ 265.27789307]
 [ 283.03994751]
 [ 274.52468872]
 [ 270.80273438]
 [ 269.98678589]
 [ 286.53372192]
 [ 306.21902466]
 [ 276.84744263]
 [ 273.83441162]
 [ 285.70779419]]
DEBUG:root:training time = %d0.23742
INFO:root:frame =17097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046181678772
INFO:root:frame =17098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000292062759399
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.864815
DEBUG:root: dqn, choose action rondomly, need time 0.000188999999978
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:frame =17101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00050687789917
INFO:root:frame =17102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame = 17103 State into memory, numbers recorded 468 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000565052032471
INFO:root:random_action_porb = 0.864783333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17104current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 303.02215576]
 [ 264.03869629]
 [ 277.25076294]
 [ 275.58148193]
 [ 294.94772339]
 [ 297.98800659]
 [ 320.1574707 ]
 [ 311.49642944]
 [ 278.59082031]
 [ 284.35894775]
 [ 269.27719116]
 [ 259.15319824]
 [ 316.50720215]
 [ 294.47619629]
 [ 299.2769165 ]
 [ 272.39605713]]
DEBUG:root:training time = %d0.223118
INFO:root:frame =17105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279188156128
INFO:root:frame =17106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000266075134277
DEBUG:root: save sample needs time = 0.000121831893921
INFO:root:random_action_porb = 0.864751666667
DEBUG:root: dqn, choose action rondomly, need time 0.000169000000028
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root:frame =17109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259160995483
INFO:root:frame =17110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259876251221
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.86472
DEBUG:root: dqn, choose action rondomly, need time 0.000177000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 286.17224121]
 [ 278.71206665]
 [ 278.54293823]
 [ 281.65133667]
 [ 283.09951782]
 [ 268.98181152]
 [ 311.28747559]
 [ 306.85379028]
 [ 265.83886719]
 [ 285.8347168 ]
 [ 290.60427856]
 [ 277.76928711]
 [ 277.15625   ]
 [ 294.8125    ]
 [ 289.29473877]
 [ 317.80612183]]
DEBUG:root:training time = %d0.220389
INFO:root:frame =17113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =17114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame = 17115 State into memory, numbers recorded 469 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000584125518799
INFO:root:random_action_porb = 0.864688333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999932
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17116current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =17117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00048303604126
INFO:root:frame =17118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000505924224854
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.864656666667
DEBUG:root: dqn, choose action rondomly, need time 0.00037199999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 316.06976318]
 [ 264.89630127]
 [ 283.23919678]
 [ 279.06881714]
 [ 318.09564209]
 [ 284.34143066]
 [ 294.13381958]
 [ 298.09863281]
 [ 291.45288086]
 [ 321.36865234]
 [ 289.71429443]
 [ 287.52020264]
 [ 300.02600098]
 [ 311.40811157]
 [ 275.05081177]
 [ 297.52566528]]
DEBUG:root:training time = %d0.236385
INFO:root:frame =17121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =17122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487089157104
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.864625
DEBUG:root: dqn, choose action rondomly, need time 0.000276999999983
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =17125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =17126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.864593333333
DEBUG:root: dqn, choose action rondomly, need time 0.00028199999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 276.91546631]
 [ 287.47155762]
 [ 288.60067749]
 [ 287.39086914]
 [ 292.21612549]
 [ 285.37258911]
 [ 283.28646851]
 [ 283.18167114]
 [ 290.85714722]
 [ 286.08343506]
 [ 286.89440918]
 [ 321.32925415]
 [ 275.68383789]
 [ 285.20352173]
 [ 282.84899902]
 [ 283.72116089]]
DEBUG:root:training time = %d0.228445
INFO:root:frame =17129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:frame =17130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469207763672
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.864561666667
DEBUG:root: dqn, choose action rondomly, need time 0.000327999999968
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338792800903
INFO:root:frame =17133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000612020492554
INFO:root:frame =17134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000798940658569
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.86453
DEBUG:root: dqn, choose action rondomly, need time 0.000293000000056
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000397920608521
INFO:root:training error  = [[ 287.27911377]
 [ 297.74676514]
 [ 320.73980713]
 [ 291.51748657]
 [ 294.17254639]
 [ 286.33642578]
 [ 279.56048584]
 [ 302.85006714]
 [ 317.05471802]
 [ 302.30859375]
 [ 311.09799194]
 [ 301.82699585]
 [ 286.44900513]
 [ 287.5874939 ]
 [ 305.74713135]
 [ 292.13891602]]
DEBUG:root:training time = %d0.232575
INFO:root:frame =17137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame =17138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000588893890381
DEBUG:root: save sample needs time = 0.000125885009766
INFO:root:random_action_porb = 0.864498333333
DEBUG:root: dqn, choose action rondomly, need time 0.00033899999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000362157821655
INFO:root:frame =17141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =17142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:random_action_porb = 0.864466666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000041
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 260.7749939 ]
 [ 288.39642334]
 [ 284.5267334 ]
 [ 326.86383057]
 [ 307.80609131]
 [ 320.87536621]
 [ 293.13812256]
 [ 280.76803589]
 [ 255.45732117]
 [ 296.80386353]
 [ 314.94876099]
 [ 294.86489868]
 [ 255.59294128]
 [ 288.71160889]
 [ 300.181427  ]
 [ 296.39181519]]
DEBUG:root:training time = %d0.232371
INFO:root:frame =17145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =17146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000360012054443
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.864435
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999932
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =17148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =17149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000703096389771
INFO:root:frame =17150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.864403333333
DEBUG:root: dqn, choose action rondomly, need time 0.000582000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 303.11886597]
 [ 321.4463501 ]
 [ 290.32861328]
 [ 307.23345947]
 [ 287.7769165 ]
 [ 282.5975647 ]
 [ 292.2328186 ]
 [ 288.77487183]
 [ 278.51339722]
 [ 292.85083008]
 [ 282.550354  ]
 [ 289.20755005]
 [ 293.4130249 ]
 [ 289.87329102]
 [ 314.02441406]
 [ 288.88897705]]
DEBUG:root:training time = %d0.218124
INFO:root:frame =17153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =17154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000284194946289
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.864371666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =17157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =17158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.86434
INFO:root:dqn select action Tensor("ArgMax_302:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.019094
INFO:root:action choosen by dqn [4]
INFO:root:frame =17160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000189065933228
INFO:root:training error  = [[ 291.27679443]
 [ 271.25289917]
 [ 302.93716431]
 [ 293.38375854]
 [ 284.35171509]
 [ 272.0486145 ]
 [ 280.04748535]
 [ 294.01763916]
 [ 281.55810547]
 [ 277.42150879]
 [ 275.54907227]
 [ 284.11917114]
 [ 268.94177246]
 [ 286.18151855]
 [ 292.68164062]
 [ 277.76013184]]
DEBUG:root:training time = %d0.228135
INFO:root:frame =17161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root:frame =17162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000157833099365
INFO:root:random_action_porb = 0.864308333333
DEBUG:root: dqn, choose action rondomly, need time 0.000254000000041
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:frame =17165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000643014907837
INFO:root:frame =17166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000505208969116
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:random_action_porb = 0.864276666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 280.93884277]
 [ 285.06130981]
 [ 281.09335327]
 [ 304.37088013]
 [ 294.49295044]
 [ 297.27093506]
 [ 314.31756592]
 [ 295.01062012]
 [ 310.62234497]
 [ 289.38818359]
 [ 317.83007812]
 [ 293.362854  ]
 [ 277.94631958]
 [ 277.87814331]
 [ 277.4276123 ]
 [ 302.95629883]]
DEBUG:root:training time = %d0.252082
INFO:root:frame =17169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029182434082
INFO:root:frame =17170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.864245
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000097
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =17173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0003981590271
INFO:root:frame =17174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047779083252
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.864213333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030599999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =17176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00044584274292
INFO:root:training error  = [[ 276.77331543]
 [ 277.48251343]
 [ 276.44845581]
 [ 297.20672607]
 [ 284.78829956]
 [ 292.6701355 ]
 [ 288.38607788]
 [ 298.91378784]
 [ 302.86175537]
 [ 280.73733521]
 [ 297.77838135]
 [ 280.30593872]
 [ 289.05810547]
 [ 290.81655884]
 [ 318.5954895 ]
 [ 291.74575806]]
DEBUG:root:training time = %d0.228718
INFO:root:frame =17177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =17178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000429153442383
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.864181666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999922
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =17181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470161437988
INFO:root:frame =17182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.86415
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[ 294.1065979 ]
 [ 292.70669556]
 [ 291.07266235]
 [ 287.04846191]
 [ 294.9781189 ]
 [ 302.72579956]
 [ 287.46536255]
 [ 304.92376709]
 [ 301.53546143]
 [ 283.34603882]
 [ 287.98403931]
 [ 306.61862183]
 [ 272.17446899]
 [ 286.98126221]
 [ 287.7789917 ]
 [ 286.98126221]]
DEBUG:root:training time = %d0.206544
INFO:root:frame =17185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000412940979004
INFO:root:frame =17186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000660181045532
INFO:root:frame = 17187 State into memory, numbers recorded 470 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:random_action_porb = 0.864118333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030199999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =17188current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =17189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =17190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame = 17191 State into memory, numbers recorded 471 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000564098358154
INFO:root:random_action_porb = 0.864086666667
INFO:root:dqn select action Tensor("ArgMax_303:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013042
INFO:root:action choosen by dqn [4]
INFO:root:frame =17192current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000899791717529
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 345.16714478]
 [ 294.76849365]
 [ 297.49090576]
 [ 296.38235474]
 [ 294.12020874]
 [ 274.82006836]
 [ 294.00402832]
 [ 288.65353394]
 [ 284.83670044]
 [ 272.99475098]
 [ 293.56567383]
 [ 313.2515564 ]
 [ 283.97720337]
 [ 297.14886475]
 [ 258.18334961]
 [ 292.04190063]]
DEBUG:root:training time = %d0.239818
INFO:root:frame =17193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =17194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.864055
DEBUG:root: dqn, choose action rondomly, need time 0.00027
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =17196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:frame =17197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =17198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000416994094849
INFO:root:frame = 17199 State into memory, numbers recorded 472 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:random_action_porb = 0.864023333333
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17200current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:training error  = [[ 320.28088379]
 [ 296.22268677]
 [ 286.17224121]
 [ 301.24301147]
 [ 298.30523682]
 [ 303.21130371]
 [ 296.41073608]
 [ 303.02429199]
 [ 300.64160156]
 [ 281.04830933]
 [ 305.58172607]
 [ 290.03125   ]
 [ 293.97262573]
 [ 291.97515869]
 [ 284.33114624]
 [ 288.56021118]]
DEBUG:root:training time = %d0.204494
INFO:root:frame =17201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =17202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000867128372192
DEBUG:root: save sample needs time = 0.000180006027222
INFO:root:random_action_porb = 0.863991666667
DEBUG:root: dqn, choose action rondomly, need time 0.000189999999975
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174999237061
INFO:root:frame =17205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =17206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000300884246826
DEBUG:root: save sample needs time = 0.000395059585571
INFO:root:random_action_porb = 0.86396
INFO:root:dqn select action Tensor("ArgMax_304:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.018178
INFO:root:action choosen by dqn [4]
INFO:root:frame =17208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 327.24356079]
 [ 287.30499268]
 [ 307.06124878]
 [ 313.14135742]
 [ 295.37133789]
 [ 275.76895142]
 [ 306.19232178]
 [ 272.32351685]
 [ 290.44821167]
 [ 283.82296753]
 [ 282.22421265]
 [ 291.12368774]
 [ 295.64520264]
 [ 290.66879272]
 [ 292.38830566]
 [ 295.62210083]]
DEBUG:root:training time = %d0.216063
INFO:root:frame =17209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =17210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root:random_action_porb = 0.863928333333
DEBUG:root: dqn, choose action rondomly, need time 0.000455999999986
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =17212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000514030456543
INFO:root:frame =17213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000227212905884
INFO:root:frame =17214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000347852706909
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.863896666667
INFO:root:dqn select action Tensor("ArgMax_305:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.017972
INFO:root:action choosen by dqn [4]
INFO:root:frame =17216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000166893005371
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 293.91088867]
 [ 325.62802124]
 [ 297.17095947]
 [ 291.54769897]
 [ 269.87646484]
 [ 305.16256714]
 [ 297.8805542 ]
 [ 290.00942993]
 [ 283.92477417]
 [ 263.5668335 ]
 [ 285.75628662]
 [ 284.29925537]
 [ 281.99765015]
 [ 288.00476074]
 [ 287.34326172]
 [ 304.08343506]]
DEBUG:root:training time = %d0.23056
INFO:root:frame =17217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame =17218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:random_action_porb = 0.863865
DEBUG:root: dqn, choose action rondomly, need time 0.000499999999988
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =17220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =17221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046181678772
INFO:root:frame =17222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.863833333333
DEBUG:root: dqn, choose action rondomly, need time 0.00028999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 295.21191406]
 [ 286.92233276]
 [ 318.06842041]
 [ 295.9317627 ]
 [ 277.27108765]
 [ 350.91049194]
 [ 287.85977173]
 [ 299.87167358]
 [ 298.90112305]
 [ 295.9317627 ]
 [ 290.85403442]
 [ 300.10107422]
 [ 295.3241272 ]
 [ 309.34356689]
 [ 299.53143311]
 [ 296.98266602]]
DEBUG:root:training time = %d0.211162
INFO:root:frame =17225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00035285949707
INFO:root:frame =17226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000340223312378
DEBUG:root: save sample needs time = 0.000187158584595
INFO:root:random_action_porb = 0.863801666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000074
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =17228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root:frame =17229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =17230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.86377
DEBUG:root: dqn, choose action rondomly, need time 0.000529000000029
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 330.42559814]
 [ 299.1333313 ]
 [ 305.10391235]
 [ 293.58346558]
 [ 299.08370972]
 [ 291.24972534]
 [ 320.64691162]
 [ 315.68899536]
 [ 301.17733765]
 [ 316.46810913]
 [ 286.77554321]
 [ 316.03503418]
 [ 293.02212524]
 [ 310.16317749]
 [ 307.36077881]
 [ 310.25561523]]
DEBUG:root:training time = %d0.224729
INFO:root:frame =17233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000379085540771
INFO:root:frame =17234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249862670898
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.863738333333
DEBUG:root: dqn, choose action rondomly, need time 0.00041699999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000397920608521
INFO:root:frame =17237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =17238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000306129455566
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:random_action_porb = 0.863706666667
DEBUG:root: dqn, choose action rondomly, need time 0.00028599999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 307.91210938]
 [ 299.86425781]
 [ 288.35705566]
 [ 297.06997681]
 [ 327.3727417 ]
 [ 307.49240112]
 [ 287.07226562]
 [ 290.76141357]
 [ 285.40045166]
 [ 364.35806274]
 [ 290.22357178]
 [ 314.30136108]
 [ 283.97000122]
 [ 287.57299805]
 [ 271.76379395]
 [ 307.4057312 ]]
DEBUG:root:training time = %d0.234461
INFO:root:frame =17241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =17242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.863675
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root:frame =17245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =17246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000103950500488
INFO:root:random_action_porb = 0.863643333333
INFO:root:dqn select action Tensor("ArgMax_306:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015357
INFO:root:action choosen by dqn [4]
INFO:root:frame =17248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000215768814087
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 308.01171875]
 [ 293.7633667 ]
 [ 327.35287476]
 [ 330.50991821]
 [ 306.30767822]
 [ 318.97363281]
 [ 354.08239746]
 [ 320.15307617]
 [ 297.59936523]
 [ 295.87506104]
 [ 297.22885132]
 [ 297.73202515]
 [ 323.5892334 ]
 [ 343.25003052]
 [ 293.71002197]
 [ 293.7633667 ]]
DEBUG:root:training time = %d0.225177
INFO:root:frame =17249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =17250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame = 17251 State into memory, numbers recorded 473 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.000695943832397
INFO:root:random_action_porb = 0.863611666667
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17252current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000172138214111
INFO:root:frame =17253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255823135376
INFO:root:frame =17254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame = 17255 State into memory, numbers recorded 474 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000662088394165
INFO:root:random_action_porb = 0.86358
INFO:root:dqn select action Tensor("ArgMax_307:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010626
INFO:root:action choosen by dqn [4]
INFO:root:frame =17256current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000415086746216
INFO:root:training error  = [[ 294.19241333]
 [ 309.11065674]
 [ 298.44967651]
 [ 307.93566895]
 [ 296.28149414]
 [ 294.32330322]
 [ 307.70758057]
 [ 287.51608276]
 [ 291.34973145]
 [ 293.00961304]
 [ 321.59628296]
 [ 293.85647583]
 [ 295.7322998 ]
 [ 295.69555664]
 [ 298.48025513]
 [ 315.59573364]]
DEBUG:root:training time = %d0.237927
INFO:root:frame =17257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:frame =17258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000309944152832
DEBUG:root: save sample needs time = 0.000123977661133
INFO:root:random_action_porb = 0.863548333333
DEBUG:root: dqn, choose action rondomly, need time 0.000810999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =17261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =17262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476121902466
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.863516666667
INFO:root:dqn select action Tensor("ArgMax_308:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.0129499999999
INFO:root:action choosen by dqn [4]
INFO:root:frame =17264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000161170959473
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 291.65087891]
 [ 341.46795654]
 [ 329.91876221]
 [ 291.22991943]
 [ 294.03543091]
 [ 353.00363159]
 [ 293.82196045]
 [ 316.24990845]
 [ 297.14886475]
 [ 296.93322754]
 [ 311.34994507]
 [ 291.64880371]
 [ 274.68347168]
 [ 304.27185059]
 [ 306.67205811]
 [ 293.90670776]]
DEBUG:root:training time = %d0.23464
INFO:root:frame =17265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =17266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.863485
DEBUG:root: dqn, choose action rondomly, need time 0.000280999999973
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root:frame =17269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =17270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.863453333333
INFO:root:dqn select action Tensor("ArgMax_309:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011606
INFO:root:action choosen by dqn [4]
INFO:root:frame =17272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 294.37252808]
 [ 295.00430298]
 [ 305.41210938]
 [ 297.40039062]
 [ 307.09545898]
 [ 300.5791626 ]
 [ 290.76556396]
 [ 291.16015625]
 [ 300.94436646]
 [ 288.51254272]
 [ 327.29101562]
 [ 292.25054932]
 [ 300.75695801]
 [ 289.17745972]
 [ 278.07250977]
 [ 289.51174927]]
DEBUG:root:training time = %d0.213531
INFO:root:frame =17273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:frame =17274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000306129455566
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.863421666667
DEBUG:root: dqn, choose action rondomly, need time 0.000367000000097
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =17277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:frame =17278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.86339
INFO:root:dqn select action Tensor("ArgMax_310:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013944
INFO:root:action choosen by dqn [4]
INFO:root:frame =17280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 333.24853516]
 [ 303.29528809]
 [ 300.83953857]
 [ 294.2144165 ]
 [ 322.49224854]
 [ 319.03793335]
 [ 287.44674683]
 [ 294.5725708 ]
 [ 321.20452881]
 [ 291.03829956]
 [ 297.50564575]
 [ 284.05230713]
 [ 296.54736328]
 [ 321.29315186]
 [ 295.84671021]
 [ 301.67645264]]
DEBUG:root:training time = %d0.228972
INFO:root:frame =17281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =17282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000339984893799
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.863358333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =17284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =17285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427961349487
INFO:root:player has been killed for 8 times 
INFO:root:frame =17286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame = 17287 State into memory, numbers recorded 475 action = 1, reward = -1
DEBUG:root: save sample needs time = 0.000547885894775
INFO:root:random_action_porb = 0.863326666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =17288current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 316.51696777]
 [ 292.5020752 ]
 [ 316.64187622]
 [ 313.12731934]
 [ 303.66848755]
 [ 303.28997803]
 [ 330.53988647]
 [ 293.14334106]
 [ 289.29681396]
 [ 313.60379028]
 [ 304.0536499 ]
 [ 300.99093628]
 [ 307.51916504]
 [ 309.74731445]
 [ 320.17382812]
 [ 300.99093628]]
DEBUG:root:training time = %d0.222588
INFO:root:frame =17289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =17290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471830368042
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.863295
DEBUG:root: dqn, choose action rondomly, need time 0.000520999999935
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =17293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =17294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.863263333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000031
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 313.3109436 ]
 [ 333.91183472]
 [ 317.65490723]
 [ 296.35083008]
 [ 297.50354004]
 [ 309.19543457]
 [ 258.71615601]
 [ 306.79071045]
 [ 283.39022827]
 [ 299.45327759]
 [ 298.11550903]
 [ 305.65322876]
 [ 313.17053223]
 [ 300.03445435]
 [ 300.01858521]
 [ 331.07940674]]
DEBUG:root:training time = %d0.230798
INFO:root:frame =17297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =17298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000425815582275
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.863231666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999917
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =17301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000416994094849
INFO:root:frame =17302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.8632
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000411033630371
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 301.86410522]
 [ 346.28158569]
 [ 338.19152832]
 [ 301.57891846]
 [ 297.43511963]
 [ 306.37924194]
 [ 309.93426514]
 [ 309.8526001 ]
 [ 322.12295532]
 [ 317.85183716]
 [ 367.19110107]
 [ 274.73913574]
 [ 296.6104126 ]
 [ 315.67272949]
 [ 316.59841919]
 [ 299.19665527]]
DEBUG:root:training time = %d0.227643
INFO:root:frame =17305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =17306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000330924987793
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.863168333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999922
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =17309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =17310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000339984893799
DEBUG:root: save sample needs time = 0.000486850738525
INFO:root:random_action_porb = 0.863136666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =17312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 319.21456909]
 [ 336.42373657]
 [ 305.65853882]
 [ 303.07528687]
 [ 286.88098145]
 [ 312.26495361]
 [ 324.03295898]
 [ 287.2253418 ]
 [ 295.68505859]
 [ 317.18948364]
 [ 311.25732422]
 [ 311.87789917]
 [ 333.3243103 ]
 [ 357.95999146]
 [ 290.55535889]
 [ 309.52285767]]
DEBUG:root:training time = %d0.233637
INFO:root:frame =17313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000191926956177
INFO:root:frame =17314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000289916992188
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.863105
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =17317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =17318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.863073333333
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000097
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =17320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 311.59338379]
 [ 319.5461731 ]
 [ 297.03735352]
 [ 294.6343689 ]
 [ 320.01004028]
 [ 310.51046753]
 [ 334.99456787]
 [ 314.08389282]
 [ 307.72042847]
 [ 353.52215576]
 [ 302.28948975]
 [ 314.46908569]
 [ 300.96765137]
 [ 378.51907349]
 [ 299.68884277]
 [ 297.71517944]]
DEBUG:root:training time = %d0.24192
INFO:root:frame =17321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =17322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.863041666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000074
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =17325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame =17326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.86301
DEBUG:root: dqn, choose action rondomly, need time 0.000181999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =17328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 333.38562012]
 [ 324.94329834]
 [ 318.71749878]
 [ 256.83563232]
 [ 296.99423218]
 [ 323.3543396 ]
 [ 292.81738281]
 [ 296.28781128]
 [ 298.34844971]
 [ 293.362854  ]
 [ 315.01483154]
 [ 315.97644043]
 [ 279.91470337]
 [ 316.17935181]
 [ 309.05914307]
 [ 304.26864624]]
DEBUG:root:training time = %d0.21438
INFO:root:frame =17329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:frame =17330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.862978333333
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =17332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =17333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491142272949
INFO:root:frame =17334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000418901443481
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:random_action_porb = 0.862946666667
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000372886657715
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 280.15371704]
 [ 303.22619629]
 [ 290.00424194]
 [ 319.91943359]
 [ 319.91943359]
 [ 315.1567688 ]
 [ 300.67654419]
 [ 304.39749146]
 [ 289.3840332 ]
 [ 262.81924438]
 [ 288.20782471]
 [ 306.6645813 ]
 [ 302.16003418]
 [ 307.53735352]
 [ 330.16159058]
 [ 309.24801636]]
DEBUG:root:training time = %d0.232035
INFO:root:frame =17337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =17338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.862915
DEBUG:root: dqn, choose action rondomly, need time 0.000347000000033
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =17341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000526905059814
INFO:root:frame =17342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.862883333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000048
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 312.09674072]
 [ 305.08047485]
 [ 286.33435059]
 [ 289.42971802]
 [ 321.04156494]
 [ 353.39938354]
 [ 294.13485718]
 [ 346.93722534]
 [ 318.54537964]
 [ 296.69451904]
 [ 292.25576782]
 [ 313.19537354]
 [ 300.43951416]
 [ 332.30325317]
 [ 339.52178955]
 [ 333.33990479]]
DEBUG:root:training time = %d0.213825
INFO:root:frame =17345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =17346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488042831421
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.862851666667
DEBUG:root: dqn, choose action rondomly, need time 0.000320999999985
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =17348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =17349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =17350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000680923461914
INFO:root:frame = 17351 State into memory, numbers recorded 476 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000576972961426
INFO:root:random_action_porb = 0.86282
DEBUG:root: dqn, choose action rondomly, need time 0.000525000000039
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =17352current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000362873077393
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 296.19219971]
 [ 322.86721802]
 [ 327.79693604]
 [ 289.42141724]
 [ 305.04101562]
 [ 321.68493652]
 [ 280.93579102]
 [ 346.79171753]
 [ 308.97439575]
 [ 287.8069458 ]
 [ 342.59561157]
 [ 337.08233643]
 [ 295.49093628]
 [ 306.30447388]
 [ 311.89297485]
 [ 312.95239258]]
DEBUG:root:training time = %d0.22852
INFO:root:frame =17353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:frame =17354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265836715698
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.862788333333
INFO:root:dqn select action Tensor("ArgMax_311:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.0152599999999
INFO:root:action choosen by dqn [4]
INFO:root:frame =17356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =17357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =17358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.862756666667
DEBUG:root: dqn, choose action rondomly, need time 0.000346000000036
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 301.00894165]
 [ 303.91104126]
 [ 300.43103027]
 [ 299.42581177]
 [ 317.37649536]
 [ 327.61685181]
 [ 283.15600586]
 [ 300.12432861]
 [ 311.45657349]
 [ 300.62997437]
 [ 337.9928894 ]
 [ 336.34875488]
 [ 308.98190308]
 [ 292.32150269]
 [ 297.71307373]
 [ 346.97589111]]
DEBUG:root:training time = %d0.23761
INFO:root:frame =17361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =17362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000547170639038
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.862725
INFO:root:dqn select action Tensor("ArgMax_312:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00879799999996
INFO:root:action choosen by dqn [4]
INFO:root:frame =17364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000381946563721
INFO:root:frame =17365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =17366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00040602684021
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.862693333333
DEBUG:root: dqn, choose action rondomly, need time 0.000210000000038
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 298.76397705]
 [ 313.7616272 ]
 [ 328.73471069]
 [ 303.3835144 ]
 [ 309.85153198]
 [ 320.41195679]
 [ 313.46005249]
 [ 302.23855591]
 [ 315.73779297]
 [ 338.41156006]
 [ 306.80352783]
 [ 312.49905396]
 [ 329.38684082]
 [ 322.94726562]
 [ 336.06225586]
 [ 310.09222412]]
DEBUG:root:training time = %d0.215659
INFO:root:frame =17369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =17370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485181808472
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.862661666667
DEBUG:root: dqn, choose action rondomly, need time 0.000177000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =17372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000182867050171
INFO:root:frame =17373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =17374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000311136245728
DEBUG:root: save sample needs time = 0.000120162963867
INFO:root:random_action_porb = 0.86263
DEBUG:root: dqn, choose action rondomly, need time 0.000333999999953
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:training error  = [[ 306.51174927]
 [ 339.43969727]
 [ 312.35665894]
 [ 324.21755981]
 [ 296.69030762]
 [ 308.77056885]
 [ 312.35665894]
 [ 306.51174927]
 [ 297.27197266]
 [ 320.33657837]
 [ 315.55236816]
 [ 295.39022827]
 [ 307.73648071]
 [ 311.19918823]
 [ 303.66955566]
 [ 308.05349731]]
DEBUG:root:training time = %d0.190295
INFO:root:frame =17377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000382900238037
INFO:root:frame =17378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000300884246826
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:random_action_porb = 0.862598333333
DEBUG:root: dqn, choose action rondomly, need time 0.000257000000033
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000187873840332
INFO:root:frame =17381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =17382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000289916992188
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:random_action_porb = 0.862566666667
DEBUG:root: dqn, choose action rondomly, need time 0.000345999999922
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =17384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00048303604126
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 306.30981445]
 [ 313.78109741]
 [ 312.87249756]
 [ 319.15023804]
 [ 325.78994751]
 [ 298.67428589]
 [ 309.48635864]
 [ 316.39862061]
 [ 314.27755737]
 [ 310.26315308]
 [ 305.43237305]
 [ 306.43267822]
 [ 333.51379395]
 [ 302.45825195]
 [ 299.99429321]
 [ 303.3314209 ]]
DEBUG:root:training time = %d0.204653
INFO:root:frame =17385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000367879867554
INFO:root:frame =17386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481128692627
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:random_action_porb = 0.862535
DEBUG:root: dqn, choose action rondomly, need time 0.000290999999947
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =17389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000394821166992
INFO:root:frame =17390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.862503333333
DEBUG:root: dqn, choose action rondomly, need time 0.000523999999928
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =17392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 352.35717773]
 [ 317.72888184]
 [ 318.53448486]
 [ 302.07199097]
 [ 293.89624023]
 [ 323.01635742]
 [ 311.80352783]
 [ 304.72131348]
 [ 311.00216675]
 [ 282.45599365]
 [ 326.37518311]
 [ 304.30911255]
 [ 307.5619812 ]
 [ 319.6913147 ]
 [ 307.29870605]
 [ 362.06069946]]
DEBUG:root:training time = %d0.237529
INFO:root:frame =17393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =17394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000156879425049
INFO:root:random_action_porb = 0.862471666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000051
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =17397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =17398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.86244
DEBUG:root: dqn, choose action rondomly, need time 0.000339000000054
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000341892242432
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 309.9546814 ]
 [ 306.57266235]
 [ 309.63775635]
 [ 306.25213623]
 [ 309.36932373]
 [ 285.89971924]
 [ 350.08660889]
 [ 309.21151733]
 [ 278.16311646]
 [ 319.02377319]
 [ 305.37796021]
 [ 316.722229  ]
 [ 306.81314087]
 [ 323.03283691]
 [ 311.50289917]
 [ 315.51226807]]
DEBUG:root:training time = %d0.232699
INFO:root:frame =17401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =17402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:random_action_porb = 0.862408333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000059
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =17405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =17406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:random_action_porb = 0.862376666667
DEBUG:root: dqn, choose action rondomly, need time 0.000541999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 332.03405762]
 [ 350.8236084 ]
 [ 323.12060547]
 [ 317.26776123]
 [ 365.86251831]
 [ 316.7895813 ]
 [ 310.89456177]
 [ 317.11340332]
 [ 303.10290527]
 [ 302.74172974]
 [ 317.11340332]
 [ 316.77548218]
 [ 317.8659668 ]
 [ 337.42196655]
 [ 320.56384277]
 [ 314.64447021]]
DEBUG:root:training time = %d0.21874
INFO:root:frame =17409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =17410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.862345
DEBUG:root: dqn, choose action rondomly, need time 0.000335999999947
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00044322013855
INFO:root:frame =17413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =17414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411033630371
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:random_action_porb = 0.862313333333
DEBUG:root: dqn, choose action rondomly, need time 0.000225
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 279.17996216]
 [ 321.67947388]
 [ 314.09579468]
 [ 310.38357544]
 [ 316.7722168 ]
 [ 316.07192993]
 [ 316.88519287]
 [ 309.33712769]
 [ 302.84899902]
 [ 326.47662354]
 [ 290.27038574]
 [ 313.09817505]
 [ 320.14871216]
 [ 310.02130127]
 [ 303.76315308]
 [ 303.76315308]]
DEBUG:root:training time = %d0.237081
INFO:root:frame =17417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000222206115723
INFO:root:frame =17418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame = 17419 State into memory, numbers recorded 477 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000687837600708
INFO:root:random_action_porb = 0.862281666667
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000026
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =17420current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =17421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =17422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.86225
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999922
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:training error  = [[ 294.88272095]
 [ 304.34637451]
 [ 297.41195679]
 [ 319.87139893]
 [ 321.8699646 ]
 [ 312.91567993]
 [ 330.12054443]
 [ 322.47470093]
 [ 301.88955688]
 [ 309.65603638]
 [ 304.34637451]
 [ 292.03564453]
 [ 318.07275391]
 [ 306.6998291 ]
 [ 319.50689697]
 [ 308.20776367]]
DEBUG:root:training time = %d0.226925
INFO:root:frame =17425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000360012054443
INFO:root:frame =17426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000394105911255
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:random_action_porb = 0.862218333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999965
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =17428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =17429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000355958938599
INFO:root:frame =17430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045919418335
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.862186666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000031
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 294.75802612]
 [ 309.27807617]
 [ 321.11047363]
 [ 306.66351318]
 [ 308.84350586]
 [ 328.46362305]
 [ 308.16491699]
 [ 312.22720337]
 [ 330.17489624]
 [ 322.67312622]
 [ 303.41009521]
 [ 301.35955811]
 [ 305.01010132]
 [ 352.44769287]
 [ 334.13269043]
 [ 329.18081665]]
DEBUG:root:training time = %d0.239843
INFO:root:frame =17433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270843505859
INFO:root:frame =17434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.862155
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999968
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =17436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =17437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491142272949
INFO:root:frame =17438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000209808349609
INFO:root:random_action_porb = 0.862123333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000031
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =17440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000392913818359
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 306.66564941]
 [ 304.77990723]
 [ 333.73117065]
 [ 317.71038818]
 [ 319.83428955]
 [ 310.16104126]
 [ 318.14025879]
 [ 304.58068848]
 [ 304.71917725]
 [ 302.95629883]
 [ 317.75280762]
 [ 329.3979187 ]
 [ 333.04135132]
 [ 300.87023926]
 [ 307.42498779]
 [ 371.23840332]]
DEBUG:root:training time = %d0.19147
INFO:root:frame =17441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =17442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000339984893799
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.862091666667
DEBUG:root: dqn, choose action rondomly, need time 0.00024099999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =17444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =17445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000861883163452
INFO:root:frame =17446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000538110733032
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.86206
INFO:root:dqn select action Tensor("ArgMax_313:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.0141659999999
INFO:root:action choosen by dqn [4]
INFO:root:frame =17448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000186920166016
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 307.58016968]
 [ 302.53894043]
 [ 308.57003784]
 [ 312.29733276]
 [ 309.20294189]
 [ 303.98233032]
 [ 295.36083984]
 [ 330.93392944]
 [ 321.33691406]
 [ 321.6663208 ]
 [ 310.78372192]
 [ 312.08917236]
 [ 323.76052856]
 [ 335.91122437]
 [ 378.84332275]
 [ 303.35906982]]
DEBUG:root:training time = %d0.186697
INFO:root:frame =17449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258207321167
INFO:root:frame =17450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482082366943
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:random_action_porb = 0.862028333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030199999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =17453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000699996948242
INFO:root:frame =17454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000505924224854
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.861996666667
DEBUG:root: dqn, choose action rondomly, need time 0.00023299999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 374.21725464]
 [ 329.89215088]
 [ 326.98745728]
 [ 311.85308838]
 [ 301.83761597]
 [ 309.67749023]
 [ 320.72341919]
 [ 322.63583374]
 [ 342.57867432]
 [ 319.01394653]
 [ 333.44467163]
 [ 314.40197754]
 [ 312.76669312]
 [ 306.90509033]
 [ 363.91314697]
 [ 315.66622925]]
DEBUG:root:training time = %d0.223579
INFO:root:frame =17457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =17458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000403165817261
DEBUG:root: save sample needs time = 0.000286817550659
INFO:root:random_action_porb = 0.861965
DEBUG:root: dqn, choose action rondomly, need time 0.000328999999965
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =17461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000503063201904
INFO:root:frame =17462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.861933333333
DEBUG:root: dqn, choose action rondomly, need time 0.00032699999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00037693977356
INFO:root:training error  = [[ 321.86450195]
 [ 318.83737183]
 [ 317.03515625]
 [ 337.08795166]
 [ 329.18637085]
 [ 336.71264648]
 [ 303.86846924]
 [ 320.65563965]
 [ 325.97174072]
 [ 311.93179321]
 [ 325.30978394]
 [ 318.56390381]
 [ 308.27099609]
 [ 311.48348999]
 [ 304.1355896 ]
 [ 310.1803894 ]]
DEBUG:root:training time = %d0.222556
INFO:root:frame =17465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =17466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.861901666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291999999945
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =17469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =17470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.86187
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000038
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:training error  = [[ 321.90829468]
 [ 321.28659058]
 [ 323.16885376]
 [ 322.3092041 ]
 [ 331.42599487]
 [ 331.42599487]
 [ 316.74395752]
 [ 317.1166687 ]
 [ 317.03622437]
 [ 322.74768066]
 [ 306.56625366]
 [ 325.05993652]
 [ 321.28659058]
 [ 346.64056396]
 [ 297.96166992]
 [ 318.91040039]]
DEBUG:root:training time = %d0.239839
INFO:root:frame =17473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:frame =17474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248908996582
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.861838333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000048
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =17477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456809997559
INFO:root:frame =17478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000209808349609
INFO:root:random_action_porb = 0.861806666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000074
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 321.07110596]
 [ 327.61575317]
 [ 329.6937561 ]
 [ 341.70483398]
 [ 358.96533203]
 [ 354.73620605]
 [ 316.86129761]
 [ 309.9213562 ]
 [ 342.90634155]
 [ 319.73168945]
 [ 312.38253784]
 [ 320.53106689]
 [ 308.89605713]
 [ 333.64642334]
 [ 319.37380981]
 [ 305.93179321]]
DEBUG:root:training time = %d0.236793
INFO:root:frame =17481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =17482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root:frame = 17483 State into memory, numbers recorded 478 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000543117523193
INFO:root:random_action_porb = 0.861775
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999955
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17484current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root:frame =17485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =17486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488996505737
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.861743333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999958
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 315.71286011]
 [ 320.69937134]
 [ 308.3460083 ]
 [ 324.62213135]
 [ 342.67694092]
 [ 334.36703491]
 [ 313.97140503]
 [ 375.40481567]
 [ 309.55508423]
 [ 334.45184326]
 [ 315.07983398]
 [ 372.87600708]
 [ 329.02026367]
 [ 335.73562622]
 [ 311.42965698]
 [ 332.85424805]]
DEBUG:root:training time = %d0.215421
INFO:root:frame =17489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:frame =17490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:random_action_porb = 0.861711666667
INFO:root:dqn select action Tensor("ArgMax_314:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00846000000001
INFO:root:action choosen by dqn [4]
INFO:root:frame =17492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000346183776855
INFO:root:frame =17493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:frame =17494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000545024871826
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.86168
INFO:root:dqn select action Tensor("ArgMax_315:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.0158210000001
INFO:root:action choosen by dqn [4]
INFO:root:frame =17496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 335.46725464]
 [ 318.1729126 ]
 [ 325.19641113]
 [ 320.1651001 ]
 [ 327.70413208]
 [ 328.10644531]
 [ 317.67883301]
 [ 303.25808716]
 [ 327.31973267]
 [ 366.6579895 ]
 [ 317.66470337]
 [ 335.80270386]
 [ 330.59313965]
 [ 291.77807617]
 [ 300.215271  ]
 [ 347.24880981]]
DEBUG:root:training time = %d0.185214
INFO:root:frame =17497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =17498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000285863876343
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:random_action_porb = 0.861648333333
INFO:root:dqn select action Tensor("ArgMax_316:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.0113180000001
INFO:root:action choosen by dqn [4]
INFO:root:frame =17500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =17501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000425100326538
INFO:root:frame =17502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:random_action_porb = 0.861616666667
DEBUG:root: dqn, choose action rondomly, need time 0.000178000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 316.31719971]
 [ 319.60180664]
 [ 322.20513916]
 [ 296.41598511]
 [ 315.56973267]
 [ 317.24603271]
 [ 337.69332886]
 [ 321.00109863]
 [ 334.71868896]
 [ 322.18322754]
 [ 324.43301392]
 [ 327.42797852]
 [ 295.53186035]
 [ 337.7696228 ]
 [ 321.109375  ]
 [ 328.81549072]]
DEBUG:root:training time = %d0.182417
INFO:root:frame =17505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root:frame =17506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319004058838
DEBUG:root: save sample needs time = 0.000141143798828
INFO:root:random_action_porb = 0.861585
INFO:root:dqn select action Tensor("ArgMax_317:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010228
INFO:root:action choosen by dqn [4]
INFO:root:frame =17508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root:frame =17509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000269174575806
INFO:root:frame =17510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000251054763794
DEBUG:root: save sample needs time = 0.000107049942017
INFO:root:random_action_porb = 0.861553333333
DEBUG:root: dqn, choose action rondomly, need time 0.000606999999945
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =17512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 313.86975098]
 [ 313.75622559]
 [ 321.04595947]
 [ 307.42498779]
 [ 325.01812744]
 [ 375.48403931]
 [ 370.88098145]
 [ 318.01290894]
 [ 327.54837036]
 [ 298.43701172]
 [ 317.04058838]
 [ 285.23135376]
 [ 322.07806396]
 [ 317.13186646]
 [ 353.24450684]
 [ 309.21044922]]
DEBUG:root:training time = %d0.233784
INFO:root:frame =17513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =17514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234127044678
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.861521666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999917
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =17517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =17518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.86149
DEBUG:root: dqn, choose action rondomly, need time 0.00028599999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:training error  = [[ 315.49273682]
 [ 288.95330811]
 [ 328.10202026]
 [ 327.32305908]
 [ 344.2651062 ]
 [ 329.13098145]
 [ 333.47921753]
 [ 343.5135498 ]
 [ 343.62893677]
 [ 321.52841187]
 [ 317.09274292]
 [ 336.33642578]
 [ 315.08743286]
 [ 327.36831665]
 [ 305.58279419]
 [ 333.8326416 ]]
DEBUG:root:training time = %d0.230275
INFO:root:frame =17521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00037407875061
INFO:root:frame =17522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.861458333333
DEBUG:root: dqn, choose action rondomly, need time 0.000184999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000173091888428
INFO:root:frame =17525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000424861907959
INFO:root:frame =17526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000416040420532
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.861426666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000036
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =17528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[ 347.02703857]
 [ 322.09558105]
 [ 320.32348633]
 [ 333.58511353]
 [ 321.61706543]
 [ 340.99441528]
 [ 341.09020996]
 [ 309.78170776]
 [ 300.43103027]
 [ 289.58758545]
 [ 313.76379395]
 [ 357.20861816]
 [ 337.90872192]
 [ 325.26574707]
 [ 325.20080566]
 [ 348.64916992]]
DEBUG:root:training time = %d0.225862
INFO:root:frame =17529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =17530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.861395
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =17532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =17533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491857528687
INFO:root:frame =17534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.861363333333
DEBUG:root: dqn, choose action rondomly, need time 0.000196000000074
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000141859054565
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 337.89077759]
 [ 320.56494141]
 [ 307.93566895]
 [ 324.27471924]
 [ 357.15325928]
 [ 318.94747925]
 [ 325.4760437 ]
 [ 322.02658081]
 [ 339.72424316]
 [ 371.75720215]
 [ 290.52313232]
 [ 321.48571777]
 [ 327.47875977]
 [ 308.68048096]
 [ 309.83435059]
 [ 322.74108887]]
DEBUG:root:training time = %d0.203396
INFO:root:frame =17537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00041389465332
INFO:root:frame =17538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000329971313477
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.861331666667
DEBUG:root: dqn, choose action rondomly, need time 0.000216000000023
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =17541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000495195388794
INFO:root:frame =17542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000394105911255
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:random_action_porb = 0.8613
DEBUG:root: dqn, choose action rondomly, need time 0.000200999999947
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =17544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 332.61709595]
 [ 323.64852905]
 [ 314.13040161]
 [ 305.69589233]
 [ 334.08694458]
 [ 333.06472778]
 [ 353.74597168]
 [ 320.05917358]
 [ 313.13165283]
 [ 323.60021973]
 [ 335.03366089]
 [ 344.38061523]
 [ 326.20098877]
 [ 329.85778809]
 [ 329.58071899]
 [ 311.40487671]]
DEBUG:root:training time = %d0.205563
INFO:root:frame =17545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270843505859
INFO:root:frame =17546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000383853912354
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:random_action_porb = 0.861268333333
INFO:root:dqn select action Tensor("ArgMax_318:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.0125499999999
INFO:root:action choosen by dqn [4]
INFO:root:frame =17548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000255823135376
INFO:root:frame =17549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =17550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.861236666667
DEBUG:root: dqn, choose action rondomly, need time 0.000682999999981
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =17552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 346.56900024]
 [ 319.92489624]
 [ 307.55020142]
 [ 360.68695068]
 [ 324.89050293]
 [ 300.45431519]
 [ 333.00680542]
 [ 332.81304932]
 [ 386.54693604]
 [ 324.04064941]
 [ 317.85620117]
 [ 321.95648193]
 [ 322.9395752 ]
 [ 324.18789673]
 [ 337.49484253]
 [ 325.39785767]]
DEBUG:root:training time = %d0.223537
INFO:root:frame =17553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =17554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241041183472
DEBUG:root: save sample needs time = 0.000106811523438
INFO:root:random_action_porb = 0.861205
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000069
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =17556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =17557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000487089157104
INFO:root:frame =17558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000497102737427
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.861173333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000031
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:training error  = [[ 333.42907715]
 [ 348.01809692]
 [ 319.14587402]
 [ 326.8583374 ]
 [ 338.45983887]
 [ 319.55053711]
 [ 323.74407959]
 [ 315.16867065]
 [ 326.41818237]
 [ 348.48165894]
 [ 325.92987061]
 [ 345.77975464]
 [ 331.29821777]
 [ 335.26608276]
 [ 316.45401001]
 [ 336.33306885]]
DEBUG:root:training time = %d0.226138
INFO:root:frame =17561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =17562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.861141666667
DEBUG:root: dqn, choose action rondomly, need time 0.000388999999927
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =17565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000451803207397
INFO:root:frame =17566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.86111
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 338.55078125]
 [ 331.56045532]
 [ 326.26272583]
 [ 335.19900513]
 [ 350.7298584 ]
 [ 316.9916687 ]
 [ 314.36627197]
 [ 309.95574951]
 [ 344.47238159]
 [ 324.89050293]
 [ 365.09240723]
 [ 321.60174561]
 [ 320.31802368]
 [ 297.12255859]
 [ 332.56921387]
 [ 329.56741333]]
DEBUG:root:training time = %d0.228034
INFO:root:frame =17569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =17570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000323057174683
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.861078333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000041
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =17573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =17574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame = 17575 State into memory, numbers recorded 479 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000586032867432
INFO:root:random_action_porb = 0.861046666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999935
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17576current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 343.45248413]
 [ 337.6428833 ]
 [ 333.58178711]
 [ 341.14093018]
 [ 321.13671875]
 [ 336.23458862]
 [ 343.93225098]
 [ 337.82232666]
 [ 320.43054199]
 [ 318.93548584]
 [ 336.11932373]
 [ 303.31228638]
 [ 320.85351562]
 [ 309.12890625]
 [ 325.03903198]
 [ 311.45333862]]
DEBUG:root:training time = %d0.234629
INFO:root:frame =17577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =17578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame = 17579 State into memory, numbers recorded 480 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000562906265259
INFO:root:random_action_porb = 0.861015
INFO:root:dqn select action Tensor("ArgMax_319:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010528
INFO:root:action choosen by dqn [4]
INFO:root:frame =17580current_observation done, NOT record action [4], reward = 0
DEBUG:root: save sample needs time = 0.000481128692627
INFO:root:frame =17581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =17582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000398874282837
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.860983333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999955
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000364065170288
INFO:root:training error  = [[ 329.4909668 ]
 [ 345.07983398]
 [ 320.58789062]
 [ 332.99789429]
 [ 331.41265869]
 [ 332.39672852]
 [ 334.5020752 ]
 [ 313.55300903]
 [ 339.53192139]
 [ 345.82287598]
 [ 312.25958252]
 [ 330.2281189 ]
 [ 322.35961914]
 [ 326.50421143]
 [ 334.44625854]
 [ 345.45748901]]
DEBUG:root:training time = %d0.212937
INFO:root:frame =17585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =17586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308990478516
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:random_action_porb = 0.860951666667
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000021
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =17589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000495910644531
INFO:root:frame =17590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000242948532104
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.86092
INFO:root:dqn select action Tensor("ArgMax_320:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012023
INFO:root:action choosen by dqn [4]
INFO:root:frame =17592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000399112701416
INFO:root:training error  = [[ 335.38677979]
 [ 314.32733154]
 [ 347.27154541]
 [ 334.32015991]
 [ 334.42172241]
 [ 342.99224854]
 [ 343.96054077]
 [ 347.39099121]
 [ 309.69360352]
 [ 339.03274536]
 [ 327.32196045]
 [ 339.46893311]
 [ 328.42379761]
 [ 332.87426758]
 [ 344.94039917]
 [ 316.07302856]]
DEBUG:root:training time = %d0.208069
INFO:root:frame =17593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =17594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame = 17595 State into memory, numbers recorded 481 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00126814842224
INFO:root:random_action_porb = 0.860888333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999937
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17596current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000627994537354
INFO:root:frame =17597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000503063201904
INFO:root:frame =17598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.860856666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000041
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 323.06903076]
 [ 335.87316895]
 [ 312.8347168 ]
 [ 352.76171875]
 [ 332.67053223]
 [ 352.4465332 ]
 [ 388.80743408]
 [ 341.78833008]
 [ 323.71221924]
 [ 325.73046875]
 [ 348.82354736]
 [ 369.18792725]
 [ 349.26599121]
 [ 303.63977051]
 [ 365.17053223]
 [ 381.14434814]]
DEBUG:root:training time = %d0.216058
INFO:root:frame =17601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290155410767
INFO:root:frame =17602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.860825
DEBUG:root: dqn, choose action rondomly, need time 0.00028999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =17604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000370979309082
INFO:root:frame =17605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =17606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.860793333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999937
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =17608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[ 340.30947876]
 [ 314.37710571]
 [ 316.59625244]
 [ 318.66738892]
 [ 346.82470703]
 [ 342.07162476]
 [ 342.51202393]
 [ 322.4385376 ]
 [ 342.15402222]
 [ 326.21200562]
 [ 330.20706177]
 [ 342.51202393]
 [ 369.8062439 ]
 [ 356.13775635]
 [ 325.3119812 ]
 [ 327.43347168]]
DEBUG:root:training time = %d0.221732
INFO:root:frame =17609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =17610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.860761666667
INFO:root:dqn select action Tensor("ArgMax_321:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014037
INFO:root:action choosen by dqn [4]
INFO:root:frame =17612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:frame =17613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:frame =17614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.86073
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000046
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =17616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 326.30462646]
 [ 305.16470337]
 [ 381.05142212]
 [ 332.74066162]
 [ 333.24966431]
 [ 354.87533569]
 [ 329.15313721]
 [ 325.91665649]
 [ 309.22012329]
 [ 339.0383606 ]
 [ 343.47622681]
 [ 325.91665649]
 [ 335.89108276]
 [ 350.76187134]
 [ 338.85070801]
 [ 330.42004395]]
DEBUG:root:training time = %d0.22019
INFO:root:frame =17617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000418901443481
INFO:root:frame =17618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481128692627
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.860698333333
DEBUG:root: dqn, choose action rondomly, need time 0.000250999999935
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =17620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000194072723389
INFO:root:frame =17621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =17622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:random_action_porb = 0.860666666667
INFO:root:dqn select action Tensor("ArgMax_322:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.0144969999999
INFO:root:action choosen by dqn [4]
INFO:root:frame =17624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000381946563721
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 327.3815918 ]
 [ 351.76852417]
 [ 327.59475708]
 [ 336.7328186 ]
 [ 349.60598755]
 [ 338.23641968]
 [ 329.39126587]
 [ 376.61557007]
 [ 332.06854248]
 [ 389.29501343]
 [ 345.43481445]
 [ 325.90783691]
 [ 399.39962769]
 [ 402.95834351]
 [ 329.46658325]
 [ 335.34542847]]
DEBUG:root:training time = %d0.216747
