INFO:root:enemies_left [0]
INFO:root:frame =0 recording current_observation no.0
DEBUG:root: save sample needs time = 0.000513076782227
INFO:root:frame =1 recording current_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =2 recording current_observation no.2
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root:frame =3 recording current_observation no.3
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =4current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame =5 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =6 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430822372437
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:frame =8 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =9 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427961349487
INFO:root:frame =10 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =12 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000433206558228
INFO:root:frame =13 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =14 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000499963760376
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:frame =16 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =17 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =18 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424146652222
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.999968333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =20 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =21 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:frame =22 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.999936666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =24 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =25 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =26 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.999905
DEBUG:root: dqn, choose action rondomly, need time 0.00031
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =28 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =29 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =30 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.999873333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =32 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =33 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:frame =34 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.999841666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =36 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =37 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =38 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.99981
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =40 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =41 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000493049621582
INFO:root:frame =42 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.999778333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =44 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =45 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000554084777832
INFO:root:frame =46 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.999746666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =48 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =49 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =50 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.999715
DEBUG:root: dqn, choose action rondomly, need time 0.000292
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =52 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000363111495972
INFO:root:frame =53 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000617027282715
INFO:root:frame =54 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000323057174683
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.999683333333
DEBUG:root: dqn, choose action rondomly, need time 0.00043
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =56 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =57 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =58 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255107879639
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.999651666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =60 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =61 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =62 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264167785645
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.99962
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =64 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =65 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =66 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.999588333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =68 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =69 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =70 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.999556666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =72 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =73 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =74 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436782836914
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.999525
DEBUG:root: dqn, choose action rondomly, need time 0.000296
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =76 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000385046005249
INFO:root:frame =77 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000451803207397
INFO:root:frame =78 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.999493333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =80 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =81 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =82 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.999461666667
DEBUG:root: dqn, choose action rondomly, need time 0.000321
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =84 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =85 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000484943389893
INFO:root:frame =86 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.99943
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =88 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =89 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =90 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame = 91 State into memory, numbers recorded 1 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000610113143921
INFO:root:random_action_porb = 0.999398333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =92current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:frame =93 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000500917434692
INFO:root:frame =94 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.999366666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =96 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =97 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469207763672
INFO:root:frame =98 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.999335
DEBUG:root: dqn, choose action rondomly, need time 0.00031
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame =102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.999303333333
DEBUG:root: dqn, choose action rondomly, need time 0.000354
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:player has been killed for 1 times 
INFO:root:frame =105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame = 107 State into memory, numbers recorded 2 action = 1, reward = -1
DEBUG:root: save sample needs time = 0.000658988952637
INFO:root:random_action_porb = 0.999271666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =108current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430822372437
INFO:root:frame =110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:random_action_porb = 0.99924
DEBUG:root: dqn, choose action rondomly, need time 0.000312
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427961349487
INFO:root:frame =114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame = 115 State into memory, numbers recorded 3 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000569105148315
INFO:root:random_action_porb = 0.999208333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =116current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.999176666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.999145
DEBUG:root: dqn, choose action rondomly, need time 0.000286
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.999113333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000338077545166
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.999081666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255823135376
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.99905
DEBUG:root: dqn, choose action rondomly, need time 0.000169
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000131130218506
INFO:root:frame =137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:random_action_porb = 0.999018333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000503063201904
INFO:root:frame =142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000678062438965
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:random_action_porb = 0.998986666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root: ememy has been killed for 1 times 
INFO:root:enemies_left [0]
INFO:root:frame =144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame = 147 State into memory, numbers recorded 4 action = 3, reward = 1
DEBUG:root: save sample needs time = 0.000547885894775
INFO:root:random_action_porb = 0.998955
DEBUG:root: dqn, choose action rondomly, need time 0.0003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =148current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000428199768066
INFO:root:frame =150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428199768066
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.998923333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000429153442383
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.998891666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.99886
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000423908233643
INFO:root:frame =162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000451803207397
DEBUG:root: save sample needs time = 9.82284545898e-05
INFO:root:random_action_porb = 0.998828333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000221014022827
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.998796666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.998765
DEBUG:root: dqn, choose action rondomly, need time 0.000286
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.998733333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.998701666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.99867
DEBUG:root: dqn, choose action rondomly, need time 0.000278
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00056004524231
INFO:root:frame = 187 State into memory, numbers recorded 5 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00055193901062
INFO:root:random_action_porb = 0.998638333333
DEBUG:root: dqn, choose action rondomly, need time 0.000499
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =188current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.998606666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487089157104
INFO:root:frame = 195 State into memory, numbers recorded 6 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000542163848877
INFO:root:random_action_porb = 0.998575
DEBUG:root: dqn, choose action rondomly, need time 0.000281
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =196current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000420808792114
INFO:root:frame =198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root: ememy has been killed for 2 times 
INFO:root:enemies_left [0]
INFO:root:frame = 199 State into memory, numbers recorded 7 action = 4, reward = 1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:random_action_porb = 0.998543333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =200current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431776046753
INFO:root:frame =202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000111103057861
INFO:root:random_action_porb = 0.998511666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049090385437
INFO:root:frame =206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042200088501
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.99848
DEBUG:root: dqn, choose action rondomly, need time 0.000292
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249147415161
INFO:root:frame =210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233888626099
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.998448333333
DEBUG:root: dqn, choose action rondomly, need time 0.000241
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:frame =213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000419855117798
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.998416666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.998385
DEBUG:root: dqn, choose action rondomly, need time 0.000286
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00041389465332
INFO:root:frame =222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame = 223 State into memory, numbers recorded 8 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000558853149414
INFO:root:random_action_porb = 0.998353333333
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =224current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.998321666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.99829
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame =234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.998258333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root:frame =237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.998226666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.998195
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233173370361
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.998163333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235795974731
INFO:root:frame =250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.998131666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000121831893921
INFO:root:random_action_porb = 0.9981
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.998068333333
DEBUG:root: dqn, choose action rondomly, need time 0.000272
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494956970215
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.998036666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame = 267 State into memory, numbers recorded 9 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000545024871826
INFO:root:random_action_porb = 0.998005
DEBUG:root: dqn, choose action rondomly, need time 0.000279
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =268current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame =270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame = 271 State into memory, numbers recorded 10 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000540018081665
INFO:root:random_action_porb = 0.997973333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =272current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000168085098267
INFO:root:random_action_porb = 0.997941666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000417947769165
INFO:root:frame =278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame = 279 State into memory, numbers recorded 11 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000564098358154
INFO:root:random_action_porb = 0.99791
DEBUG:root: dqn, choose action rondomly, need time 0.000293
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =280current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.997878333333
DEBUG:root: dqn, choose action rondomly, need time 0.000742
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.00010085105896
INFO:root:random_action_porb = 0.997846666667
DEBUG:root: dqn, choose action rondomly, need time 0.000564
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.997815
DEBUG:root: dqn, choose action rondomly, need time 0.000538
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.997783333333
DEBUG:root: dqn, choose action rondomly, need time 0.000566
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.997751666667
DEBUG:root: dqn, choose action rondomly, need time 0.000593
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.99772
DEBUG:root: dqn, choose action rondomly, need time 0.000546
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234127044678
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.997688333333
DEBUG:root: dqn, choose action rondomly, need time 0.000525
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.997656666667
DEBUG:root: dqn, choose action rondomly, need time 0.0005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame =314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.997625
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:frame =318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231981277466
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.997593333333
DEBUG:root: dqn, choose action rondomly, need time 0.000265
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000270843505859
INFO:root:frame =321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000417947769165
INFO:root:frame =322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 9.51290130615e-05
INFO:root:random_action_porb = 0.997561666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000411033630371
INFO:root:frame =326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.99753
DEBUG:root: dqn, choose action rondomly, need time 0.000281
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.997498333333
DEBUG:root: dqn, choose action rondomly, need time 0.000268
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.997466666667
DEBUG:root: dqn, choose action rondomly, need time 0.000164
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.997435
DEBUG:root: dqn, choose action rondomly, need time 0.000234
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482082366943
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.997403333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame = 347 State into memory, numbers recorded 12 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00055718421936
INFO:root:random_action_porb = 0.997371666667
DEBUG:root: dqn, choose action rondomly, need time 0.000278
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =348current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.99734
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.997308333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.997276666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.997245
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.997213333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00048303604126
INFO:root:frame =370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000229835510254
INFO:root:random_action_porb = 0.997181666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449180603027
INFO:root:frame =374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.99715
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.997118333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000243186950684
INFO:root:frame =381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471115112305
INFO:root:frame =382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.997086666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.997055
DEBUG:root: dqn, choose action rondomly, need time 0.000324
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000423908233643
INFO:root:frame =389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame = 391 State into memory, numbers recorded 13 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000514030456543
INFO:root:random_action_porb = 0.997023333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =392current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.996991666667
DEBUG:root: dqn, choose action rondomly, need time 0.000311
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000482797622681
INFO:root:frame =398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.99696
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.996928333333
DEBUG:root: dqn, choose action rondomly, need time 0.000317
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000481128692627
INFO:root:frame =406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000213861465454
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.996896666667
DEBUG:root: dqn, choose action rondomly, need time 0.000334
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.996865
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:frame =414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.996833333333
DEBUG:root: dqn, choose action rondomly, need time 0.000307
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000378847122192
INFO:root:frame =417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000300884246826
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.996801666667
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame =422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.99677
DEBUG:root: dqn, choose action rondomly, need time 0.000164
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000404119491577
INFO:root:frame =426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000419139862061
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.996738333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000423908233643
INFO:root:frame =430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.996706666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.996675
DEBUG:root: dqn, choose action rondomly, need time 0.000488
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000381946563721
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:random_action_porb = 0.996643333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.996611666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.99658
DEBUG:root: dqn, choose action rondomly, need time 0.000186
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000181913375854
INFO:root:frame =449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:random_action_porb = 0.996548333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame = 455 State into memory, numbers recorded 14 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000571012496948
INFO:root:random_action_porb = 0.996516666667
DEBUG:root: dqn, choose action rondomly, need time 0.000279000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =456current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.996485
INFO:root:dqn select action Tensor("ArgMax:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015208
INFO:root:action choosen by dqn [3]
INFO:root:frame =460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000191926956177
INFO:root:frame =461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00058388710022
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:random_action_porb = 0.996453333333
DEBUG:root: dqn, choose action rondomly, need time 0.000563000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.996421666667
DEBUG:root: dqn, choose action rondomly, need time 0.000518
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.99639
DEBUG:root: dqn, choose action rondomly, need time 0.000551
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227212905884
DEBUG:root: save sample needs time = 9.29832458496e-05
INFO:root:random_action_porb = 0.996358333333
DEBUG:root: dqn, choose action rondomly, need time 0.000307
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.996326666667
DEBUG:root: dqn, choose action rondomly, need time 0.000527
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000417947769165
INFO:root:frame =482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423192977905
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.996295
DEBUG:root: dqn, choose action rondomly, need time 0.000296
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000498056411743
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.996263333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.996231666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.9962
DEBUG:root: dqn, choose action rondomly, need time 0.000306
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:random_action_porb = 0.996168333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000501871109009
INFO:root:frame =502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame = 503 State into memory, numbers recorded 15 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000547170639038
INFO:root:random_action_porb = 0.996136666667
DEBUG:root: dqn, choose action rondomly, need time 0.0003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =504current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00065803527832
INFO:root:frame = 507 State into memory, numbers recorded 16 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000521183013916
INFO:root:random_action_porb = 0.996105
DEBUG:root: dqn, choose action rondomly, need time 0.000418
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =508current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame = 511 State into memory, numbers recorded 17 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root:random_action_porb = 0.996073333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =512current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000487089157104
INFO:root:frame =514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:random_action_porb = 0.996041666667
DEBUG:root: dqn, choose action rondomly, need time 0.000476
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000524044036865
INFO:root:frame =517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.99601
DEBUG:root: dqn, choose action rondomly, need time 0.000158
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00044584274292
INFO:root:frame =522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.995978333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000353097915649
INFO:root:frame =525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame = 527 State into memory, numbers recorded 18 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000538110733032
INFO:root:random_action_porb = 0.995946666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =528current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.995915
DEBUG:root: dqn, choose action rondomly, need time 0.000346
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000358104705811
INFO:root:frame =533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471830368042
INFO:root:frame =534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame = 535 State into memory, numbers recorded 19 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.00054407119751
INFO:root:random_action_porb = 0.995883333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =536current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.995851666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.99582
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000486135482788
INFO:root:frame =546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000512838363647
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.995788333333
DEBUG:root: dqn, choose action rondomly, need time 0.000324
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481128692627
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.995756666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame =553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000485897064209
INFO:root:frame =554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.995725
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.995693333333
DEBUG:root: dqn, choose action rondomly, need time 0.000437
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.995661666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000560998916626
INFO:root:frame =566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.99563
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000417947769165
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.995598333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000419139862061
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.995566666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000245809555054
INFO:root:random_action_porb = 0.995535
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.995503333333
DEBUG:root: dqn, choose action rondomly, need time 0.000395
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000530958175659
INFO:root:frame =585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.995471666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.99544
INFO:root:dqn select action Tensor("ArgMax_1:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.008503
INFO:root:action choosen by dqn [3]
INFO:root:frame =592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root:frame =593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441789627075
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.995408333333
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root:frame =598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.995376666667
DEBUG:root: dqn, choose action rondomly, need time 0.000179
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504970550537
DEBUG:root: save sample needs time = 0.000141143798828
INFO:root:random_action_porb = 0.995345
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000386953353882
DEBUG:root: save sample needs time = 0.000250816345215
INFO:root:random_action_porb = 0.995313333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.995281666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.99525
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444173812866
INFO:root:frame =618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.995218333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000361919403076
INFO:root:frame =621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.995186666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:frame =625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame =626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433206558228
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.995155
DEBUG:root: dqn, choose action rondomly, need time 0.000276
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000423908233643
INFO:root:frame =630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482082366943
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.995123333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.995091666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438213348389
INFO:root:frame =638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.99506
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.995028333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.994996666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.994965
DEBUG:root: dqn, choose action rondomly, need time 0.000296
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491857528687
INFO:root:frame =654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:random_action_porb = 0.994933333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:random_action_porb = 0.994901666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:frame =661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00039005279541
INFO:root:frame =662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449180603027
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.99487
DEBUG:root: dqn, choose action rondomly, need time 0.0005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00035285949707
INFO:root:frame =665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root:frame =666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.994838333333
DEBUG:root: dqn, choose action rondomly, need time 0.000495
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476121902466
DEBUG:root: save sample needs time = 9.58442687988e-05
INFO:root:random_action_porb = 0.994806666667
INFO:root:dqn select action Tensor("ArgMax_2:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013649
INFO:root:action choosen by dqn [3]
INFO:root:frame =672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000156879425049
INFO:root:frame =673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.994775
DEBUG:root: dqn, choose action rondomly, need time 0.000538
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.994743333333
DEBUG:root: dqn, choose action rondomly, need time 0.000566
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.994711666667
DEBUG:root: dqn, choose action rondomly, need time 0.000533
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.99468
DEBUG:root: dqn, choose action rondomly, need time 0.000565
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000422954559326
INFO:root:frame =690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame = 691 State into memory, numbers recorded 20 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000545978546143
INFO:root:random_action_porb = 0.994648333333
DEBUG:root: dqn, choose action rondomly, need time 0.000575
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =692current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.994616666667
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000490188598633
INFO:root:frame =698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449180603027
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.994585
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491142272949
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.994553333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.994521666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326156616211
INFO:root:frame =709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446796417236
INFO:root:frame = 711 State into memory, numbers recorded 21 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000591039657593
INFO:root:random_action_porb = 0.99449
DEBUG:root: dqn, choose action rondomly, need time 0.00031
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =712current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440835952759
INFO:root:frame =714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.994458333333
DEBUG:root: dqn, choose action rondomly, need time 0.000169
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000425100326538
INFO:root:frame =718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.994426666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00027322769165
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.994395
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000420093536377
INFO:root:frame =726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.994363333333
DEBUG:root: dqn, choose action rondomly, need time 0.000165999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000108957290649
INFO:root:random_action_porb = 0.994331666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.9943
DEBUG:root: dqn, choose action rondomly, need time 0.000529
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448226928711
INFO:root:frame =738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000585079193115
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.994268333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame =742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.994236666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.994205
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000429153442383
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.994173333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame =754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.994141666667
DEBUG:root: dqn, choose action rondomly, need time 0.000156
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.99411
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.994078333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438213348389
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.994046666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000492095947266
INFO:root:frame =770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.994015
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame =774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000397920608521
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.993983333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000423908233643
INFO:root:frame =778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:random_action_porb = 0.993951666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00035285949707
INFO:root:frame =781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.99392
DEBUG:root: dqn, choose action rondomly, need time 0.000264
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.993888333333
DEBUG:root: dqn, choose action rondomly, need time 0.000278
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.993856666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame =794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.993825
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234127044678
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.993793333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.993761666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000358104705811
INFO:root:frame =805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.99373
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000838994979858
INFO:root:frame =810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231981277466
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:random_action_porb = 0.993698333333
DEBUG:root: dqn, choose action rondomly, need time 0.000244
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:frame =813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000395059585571
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.993666666667
DEBUG:root: dqn, choose action rondomly, need time 0.000341000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000485897064209
INFO:root:frame =817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438213348389
INFO:root:frame =818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504970550537
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.993635
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.993603333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:frame =826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476121902466
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.993571666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.99354
DEBUG:root: dqn, choose action rondomly, need time 0.000314
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000495910644531
INFO:root:frame =834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000534057617188
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:random_action_porb = 0.993508333333
DEBUG:root: dqn, choose action rondomly, need time 0.000355
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.993476666667
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476121902466
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:random_action_porb = 0.993445
DEBUG:root: dqn, choose action rondomly, need time 0.000280999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000346899032593
INFO:root:frame =845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000425100326538
INFO:root:frame =846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:random_action_porb = 0.993413333333
DEBUG:root: dqn, choose action rondomly, need time 0.0003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.993381666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000352144241333
INFO:root:frame =853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.99335
DEBUG:root: dqn, choose action rondomly, need time 0.000178
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.993318333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.993286666667
DEBUG:root: dqn, choose action rondomly, need time 0.000266
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.993255
DEBUG:root: dqn, choose action rondomly, need time 0.000281
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488996505737
INFO:root:frame =870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.993223333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.993191666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000467777252197
INFO:root:frame = 879 State into memory, numbers recorded 22 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000550031661987
INFO:root:random_action_porb = 0.99316
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =880current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446796417236
INFO:root:frame =882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000201225280762
INFO:root:random_action_porb = 0.993128333333
DEBUG:root: dqn, choose action rondomly, need time 0.000313
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488996505737
INFO:root:frame =886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475883483887
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.993096666667
DEBUG:root: dqn, choose action rondomly, need time 0.000365
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142812728882
INFO:root:frame =889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449180603027
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:random_action_porb = 0.993065
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049090385437
INFO:root:frame =894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame = 895 State into memory, numbers recorded 23 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000604867935181
INFO:root:random_action_porb = 0.993033333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =896current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.993001666667
DEBUG:root: dqn, choose action rondomly, need time 0.000312
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328779220581
INFO:root:frame =901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:frame =902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000418186187744
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.99297
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.992938333333
DEBUG:root: dqn, choose action rondomly, need time 0.00031
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:frame =910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:random_action_porb = 0.992906666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.992875
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.992843333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:random_action_porb = 0.992811666667
DEBUG:root: dqn, choose action rondomly, need time 0.000305
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000424146652222
INFO:root:frame =926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:random_action_porb = 0.99278
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:random_action_porb = 0.992748333333
DEBUG:root: dqn, choose action rondomly, need time 0.000279
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000498056411743
INFO:root:frame =934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.992716666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame = 939 State into memory, numbers recorded 24 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000562191009521
INFO:root:random_action_porb = 0.992685
DEBUG:root: dqn, choose action rondomly, need time 0.000296
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =940current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:random_action_porb = 0.992653333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.992621666667
DEBUG:root: dqn, choose action rondomly, need time 0.000324
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000530004501343
INFO:root:frame =950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000549793243408
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:random_action_porb = 0.99259
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00053596496582
INFO:root:frame =954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.992558333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00048303604126
INFO:root:frame =958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.992526666667
DEBUG:root: dqn, choose action rondomly, need time 0.000194
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491857528687
INFO:root:frame =962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.992495
DEBUG:root: dqn, choose action rondomly, need time 0.000293
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491142272949
INFO:root:frame =966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.992463333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000367879867554
INFO:root:frame =970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000185012817383
INFO:root:random_action_porb = 0.992431666667
DEBUG:root: dqn, choose action rondomly, need time 0.000360000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame = 975 State into memory, numbers recorded 25 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000545024871826
INFO:root:random_action_porb = 0.9924
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =976current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame =978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000284910202026
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.992368333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame =982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.992336666667
DEBUG:root: dqn, choose action rondomly, need time 0.000275999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431776046753
INFO:root:frame =986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.992305
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430822372437
INFO:root:frame =990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470876693726
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.992273333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.992241666667
DEBUG:root: dqn, choose action rondomly, need time 0.000159
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:frame =997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000524997711182
INFO:root:frame =998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000451803207397
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root:one frame running time = 0.006866
DEBUG:root:total training time = 6.50402
INFO:root:frame num = 1000 frame round: 0
INFO:root:random_action_porb = 0.99221
DEBUG:root: dqn, choose action rondomly, need time 0.00033
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root:frame =1001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =1002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.992178333333
DEBUG:root: dqn, choose action rondomly, need time 0.00031
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =1005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =1006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.992146666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =1009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =1010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000517845153809
INFO:root:frame = 1011 State into memory, numbers recorded 26 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000638961791992
INFO:root:random_action_porb = 0.992115
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1012current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000336170196533
INFO:root:frame =1013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =1014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000192880630493
INFO:root:random_action_porb = 0.992083333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root:frame =1017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =1018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.992051666667
DEBUG:root: dqn, choose action rondomly, need time 0.000279
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame =1022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.99202
DEBUG:root: dqn, choose action rondomly, need time 0.000296
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =1025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000418186187744
INFO:root:frame =1026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000420093536377
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.991988333333
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =1029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =1030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.991956666667
DEBUG:root: dqn, choose action rondomly, need time 0.000305
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000392913818359
INFO:root:frame =1034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.991925
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433206558228
INFO:root:frame =1038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.991893333333
DEBUG:root: dqn, choose action rondomly, need time 0.000598
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =1041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.991861666667
DEBUG:root: dqn, choose action rondomly, need time 0.000416
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:frame =1045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =1046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.99183
DEBUG:root: dqn, choose action rondomly, need time 0.000309
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000352144241333
INFO:root:frame =1049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =1050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.991798333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000357151031494
INFO:root:frame =1053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =1054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame = 1055 State into memory, numbers recorded 27 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000540971755981
INFO:root:random_action_porb = 0.991766666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1056current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000352144241333
INFO:root:frame =1057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =1058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:random_action_porb = 0.991735
INFO:root:dqn select action Tensor("ArgMax_3:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014181
INFO:root:action choosen by dqn [3]
INFO:root:frame =1060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162124633789
INFO:root:frame =1061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame =1062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.991703333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =1065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000481128692627
INFO:root:frame =1066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame = 1067 State into memory, numbers recorded 28 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000576972961426
INFO:root:random_action_porb = 0.991671666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1068current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =1069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:frame =1070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.99164
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =1073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042986869812
INFO:root:frame =1074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:random_action_porb = 0.991608333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000396013259888
INFO:root:frame =1077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =1078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.991576666667
DEBUG:root: dqn, choose action rondomly, need time 0.000275999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000506162643433
INFO:root:frame =1082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
DEBUG:root: save sample needs time = 0.000201225280762
INFO:root:random_action_porb = 0.991545
DEBUG:root: dqn, choose action rondomly, need time 0.000313999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =1085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000428915023804
INFO:root:frame =1086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.991513333333
DEBUG:root: dqn, choose action rondomly, need time 0.000279000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000315189361572
INFO:root:frame =1089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =1090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000429153442383
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.991481666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =1093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =1094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231981277466
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.99145
DEBUG:root: dqn, choose action rondomly, need time 0.000159999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:frame =1097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =1098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.991418333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =1102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000201225280762
INFO:root:random_action_porb = 0.991386666667
DEBUG:root: dqn, choose action rondomly, need time 0.000556000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000428199768066
INFO:root:frame =1106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.991355
DEBUG:root: dqn, choose action rondomly, need time 0.000546
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000341176986694
INFO:root:frame =1109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =1110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:random_action_porb = 0.991323333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =1113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000451803207397
INFO:root:frame =1114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:player has been killed for 2 times 
INFO:root:frame = 1115 State into memory, numbers recorded 29 action = -1, reward = -1
DEBUG:root: save sample needs time = 0.000616073608398
INFO:root:random_action_porb = 0.991291666667
DEBUG:root: dqn, choose action rondomly, need time 0.000274000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1116current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:frame =1117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =1118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000256061553955
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.99126
DEBUG:root: dqn, choose action rondomly, need time 0.000293000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355958938599
INFO:root:frame =1121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =1122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:random_action_porb = 0.991228333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =1125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000380039215088
INFO:root:frame =1126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481128692627
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.991196666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =1129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042986869812
INFO:root:frame =1130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464200973511
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.991165
DEBUG:root: dqn, choose action rondomly, need time 0.000306
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =1133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =1134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000552892684937
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.991133333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =1137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000425100326538
INFO:root:frame =1138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424146652222
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.991101666667
DEBUG:root: dqn, choose action rondomly, need time 0.000220000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =1141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000418901443481
INFO:root:frame =1142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.99107
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =1145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame =1146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.991038333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =1150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.991006666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =1153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000523090362549
INFO:root:frame =1154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.990975
DEBUG:root: dqn, choose action rondomly, need time 0.000235
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:frame =1157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =1158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.990943333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame =1161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =1162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.990911666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00050687789917
INFO:root:frame =1166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame = 1167 State into memory, numbers recorded 30 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000537872314453
INFO:root:random_action_porb = 0.99088
DEBUG:root: dqn, choose action rondomly, need time 0.000283000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1168current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =1169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =1170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 9.41753387451e-05
INFO:root:random_action_porb = 0.990848333333
DEBUG:root: dqn, choose action rondomly, need time 0.000169
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:frame =1173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =1174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.990816666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =1177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =1178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.990785
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =1181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000518083572388
INFO:root:frame =1182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446796417236
INFO:root:frame = 1183 State into memory, numbers recorded 31 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000541925430298
INFO:root:random_action_porb = 0.990753333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1184current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000396966934204
INFO:root:frame =1185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =1186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.990721666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =1189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =1190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.99069
DEBUG:root: dqn, choose action rondomly, need time 0.000397
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =1193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =1194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:random_action_porb = 0.990658333333
DEBUG:root: dqn, choose action rondomly, need time 0.000339
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000566005706787
INFO:root:frame =1198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000369071960449
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:random_action_porb = 0.990626666667
DEBUG:root: dqn, choose action rondomly, need time 0.000321000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =1201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =1202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.990595
DEBUG:root: dqn, choose action rondomly, need time 0.000575
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =1205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame =1206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000380992889404
INFO:root:frame = 1207 State into memory, numbers recorded 32 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000574827194214
INFO:root:random_action_porb = 0.990563333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1208current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =1209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =1210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.990531666667
DEBUG:root: dqn, choose action rondomly, need time 0.000342999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root:frame =1213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =1214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.9905
DEBUG:root: dqn, choose action rondomly, need time 0.000347000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000351905822754
INFO:root:frame =1217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =1218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000221014022827
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.990468333333
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =1221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000512838363647
INFO:root:frame =1222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000513076782227
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.990436666667
DEBUG:root: dqn, choose action rondomly, need time 0.000457000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =1225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000550031661987
INFO:root:frame =1226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469207763672
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.990405
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =1229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =1230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:random_action_porb = 0.990373333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000353097915649
INFO:root:frame =1233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame =1234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000500917434692
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.990341666667
DEBUG:root: dqn, choose action rondomly, need time 0.000159999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000343799591064
INFO:root:frame =1237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =1238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 9.58442687988e-05
INFO:root:random_action_porb = 0.99031
DEBUG:root: dqn, choose action rondomly, need time 0.000394
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =1241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000529050827026
INFO:root:frame =1242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232219696045
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.990278333333
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =1245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =1246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame = 1247 State into memory, numbers recorded 33 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000691175460815
INFO:root:random_action_porb = 0.990246666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1248current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =1249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =1250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482082366943
INFO:root:frame = 1251 State into memory, numbers recorded 34 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000567197799683
INFO:root:random_action_porb = 0.990215
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1252current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =1253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =1254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488042831421
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:random_action_porb = 0.990183333333
DEBUG:root: dqn, choose action rondomly, need time 0.000273999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336170196533
INFO:root:frame =1257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =1258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000166893005371
INFO:root:random_action_porb = 0.990151666667
DEBUG:root: dqn, choose action rondomly, need time 0.000201000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:frame =1261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =1262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.99012
DEBUG:root: dqn, choose action rondomly, need time 0.000375999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =1265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =1266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000122785568237
INFO:root:random_action_porb = 0.990088333333
DEBUG:root: dqn, choose action rondomly, need time 0.000261999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =1269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =1270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame = 1271 State into memory, numbers recorded 35 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000541925430298
INFO:root:random_action_porb = 0.990056666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1272current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =1273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000501871109009
INFO:root:frame =1274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000284194946289
INFO:root:random_action_porb = 0.990025
DEBUG:root: dqn, choose action rondomly, need time 0.000375
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =1277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =1278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444173812866
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.989993333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =1281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =1282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000244140625
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:random_action_porb = 0.989961666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000396966934204
INFO:root:frame =1286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000366926193237
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.98993
DEBUG:root: dqn, choose action rondomly, need time 0.000168
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000131130218506
INFO:root:frame =1289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =1290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411033630371
INFO:root:frame = 1291 State into memory, numbers recorded 36 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:random_action_porb = 0.989898333333
DEBUG:root: dqn, choose action rondomly, need time 0.000173999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1292current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =1293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =1294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.989866666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =1297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000416994094849
INFO:root:frame =1298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.989835
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =1301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000509023666382
INFO:root:frame =1302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045919418335
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.989803333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =1305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame =1306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.989771666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =1310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.98974
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =1313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =1314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.989708333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000408887863159
INFO:root:frame =1317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000580072402954
INFO:root:frame =1318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:random_action_porb = 0.989676666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =1321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =1322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.989645
DEBUG:root: dqn, choose action rondomly, need time 0.000166999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =1325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000515222549438
INFO:root:frame =1326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:random_action_porb = 0.989613333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =1329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =1330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.989581666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =1333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =1334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.98955
DEBUG:root: dqn, choose action rondomly, need time 0.000254
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =1337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =1338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:random_action_porb = 0.989518333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =1341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame =1342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame = 1343 State into memory, numbers recorded 37 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.00055718421936
INFO:root:random_action_porb = 0.989486666667
DEBUG:root: dqn, choose action rondomly, need time 0.000408999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1344current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =1345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =1346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045919418335
DEBUG:root: save sample needs time = 0.000171184539795
INFO:root:random_action_porb = 0.989455
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325202941895
INFO:root:frame =1349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =1350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:random_action_porb = 0.989423333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000514030456543
INFO:root:frame =1354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487089157104
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.989391666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =1358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:random_action_porb = 0.98936
DEBUG:root: dqn, choose action rondomly, need time 0.000341000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =1361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =1362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000240802764893
INFO:root:random_action_porb = 0.989328333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000485181808472
INFO:root:frame =1366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.989296666667
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =1369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =1370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.989265
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =1373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000398874282837
INFO:root:frame =1374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame = 1375 State into memory, numbers recorded 38 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000572919845581
INFO:root:random_action_porb = 0.989233333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1376current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =1377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =1378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame = 1379 State into memory, numbers recorded 39 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000534057617188
INFO:root:random_action_porb = 0.989201666667
DEBUG:root: dqn, choose action rondomly, need time 0.000381000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1380current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =1381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame =1382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411033630371
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.98917
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =1385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000425100326538
INFO:root:frame =1386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.989138333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =1389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =1390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.989106666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =1394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.989075
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =1397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =1398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000224113464355
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.989043333333
DEBUG:root: dqn, choose action rondomly, need time 0.000158000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000131130218506
INFO:root:frame =1401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =1402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448226928711
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.989011666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =1405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000429153442383
INFO:root:frame =1406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000209093093872
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.98898
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =1409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235795974731
INFO:root:frame =1410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.988948333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =1414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.988916666667
DEBUG:root: dqn, choose action rondomly, need time 0.000317000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =1417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =1418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.988885
DEBUG:root: dqn, choose action rondomly, need time 0.000254
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000271797180176
INFO:root:frame =1421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =1422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.988853333333
DEBUG:root: dqn, choose action rondomly, need time 0.000313
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =1425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =1426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:random_action_porb = 0.988821666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =1429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =1430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.98879
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =1433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:frame =1434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.988758333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =1438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame = 1439 State into memory, numbers recorded 40 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:random_action_porb = 0.988726666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1440current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =1442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000224828720093
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.988695
DEBUG:root: dqn, choose action rondomly, need time 0.000268999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =1445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =1446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:random_action_porb = 0.988663333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =1449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =1450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.988631666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:frame =1453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =1454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9886
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =1458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000578880310059
INFO:root:frame = 1459 State into memory, numbers recorded 41 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000542879104614
INFO:root:random_action_porb = 0.988568333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1460current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000362157821655
INFO:root:frame =1461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =1462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438213348389
INFO:root:frame = 1463 State into memory, numbers recorded 42 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000675916671753
INFO:root:random_action_porb = 0.988536666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1464current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =1465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =1466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.988505
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =1469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =1470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264883041382
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.988473333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =1473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =1474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame = 1475 State into memory, numbers recorded 43 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000545024871826
INFO:root:random_action_porb = 0.988441666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1476current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =1477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000419855117798
INFO:root:frame =1478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.98841
DEBUG:root: dqn, choose action rondomly, need time 0.0006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000510931015015
INFO:root:frame =1481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000424861907959
INFO:root:frame =1482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00048303604126
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.988378333333
DEBUG:root: dqn, choose action rondomly, need time 0.000547000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =1485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =1486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame = 1487 State into memory, numbers recorded 44 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000540971755981
INFO:root:random_action_porb = 0.988346666667
DEBUG:root: dqn, choose action rondomly, need time 0.00056
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1488current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =1489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =1490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.988315
DEBUG:root: dqn, choose action rondomly, need time 0.000539
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =1493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =1494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431776046753
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.988283333333
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000379085540771
INFO:root:frame =1497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =1498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:random_action_porb = 0.988251666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =1501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =1502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000420093536377
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.98822
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =1505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame =1506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423192977905
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.988188333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =1509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =1510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:random_action_porb = 0.988156666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =1513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =1514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.988125
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =1517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =1518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.988093333333
DEBUG:root: dqn, choose action rondomly, need time 0.000276999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266790390015
INFO:root:frame =1522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:random_action_porb = 0.988061666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =1525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =1526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.98803
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =1529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =1530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame = 1531 State into memory, numbers recorded 45 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00055718421936
INFO:root:random_action_porb = 0.987998333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1532current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =1533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =1534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488996505737
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.987966666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000694036483765
INFO:root:frame =1537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =1538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.987935
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333786010742
INFO:root:frame =1541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438213348389
INFO:root:frame =1542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.987903333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =1545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224828720093
INFO:root:frame =1546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.987871666667
DEBUG:root: dqn, choose action rondomly, need time 0.000154
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000130176544189
INFO:root:frame =1549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =1550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.98784
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000451803207397
INFO:root:frame =1554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.987808333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000341176986694
INFO:root:frame =1557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =1558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.987776666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =1561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000418901443481
INFO:root:frame =1562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433206558228
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.987745
DEBUG:root: dqn, choose action rondomly, need time 0.000313999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =1565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =1566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.987713333333
DEBUG:root: dqn, choose action rondomly, need time 0.000323
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =1569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =1570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504016876221
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.987681666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =1573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =1574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.98765
DEBUG:root: dqn, choose action rondomly, need time 0.000311
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =1577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =1578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.987618333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =1581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00044584274292
INFO:root:frame =1582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476121902466
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.987586666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =1585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =1586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.987555
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =1590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.987523333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000424146652222
INFO:root:frame =1594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame = 1595 State into memory, numbers recorded 46 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:random_action_porb = 0.987491666667
DEBUG:root: dqn, choose action rondomly, need time 0.000280999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1596current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =1597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =1598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.98746
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =1601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430822372437
INFO:root:frame =1602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:random_action_porb = 0.987428333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =1605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame =1606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000419139862061
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.987396666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.09183121e+01]
 [  6.93056717e+01]
 [  6.93056717e+01]
 [  2.19418243e+02]
 [  7.00052643e+01]
 [  2.70538391e+02]
 [  2.39032928e+02]
 [  1.16580434e-01]
 [  2.64294189e+02]
 [  2.09970385e-01]
 [  6.93056717e+01]
 [  2.39032928e+02]
 [  2.24615097e+02]
 [  7.25595703e+01]
 [  7.18563766e+01]
 [  6.91338425e+01]]
DEBUG:root:training time = %d0.214074
INFO:root:frame =1609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =1610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509023666382
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.987365
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =1613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =1614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.987333333333
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:training error  = [[  1.68249488e-01]
 [  9.53613520e-02]
 [  3.09962292e+01]
 [  7.09870224e+01]
 [  7.11575317e+01]
 [  2.82764664e+01]
 [  2.32252572e-03]
 [  1.34959057e-01]
 [  3.11158388e-03]
 [  7.08109894e+01]
 [  3.44256521e-04]
 [  7.08109894e+01]
 [  1.77385584e-02]
 [  2.29630107e-03]
 [  2.92817822e+01]
 [  1.77385584e-02]]
DEBUG:root:training time = %d0.226644
INFO:root:frame =1617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =1618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.987301666667
DEBUG:root: dqn, choose action rondomly, need time 0.000333999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =1621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =1622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.98727
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.78989410e+01]
 [  1.08538719e-03]
 [  6.34882090e-05]
 [  7.32626343e+01]
 [  2.61081200e+01]
 [  6.18257484e+01]
 [  3.79736186e-03]
 [  3.20290937e-03]
 [  6.21232643e+01]
 [  3.94018646e-03]
 [  6.13637962e+01]
 [  7.29930191e+01]
 [  5.24575880e-04]
 [  1.05109310e+01]
 [  7.32626343e+01]
 [  2.40719585e+01]]
DEBUG:root:training time = %d0.213988
INFO:root:frame =1625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:frame =1626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000136852264404
INFO:root:random_action_porb = 0.987238333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =1629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =1630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:random_action_porb = 0.987206666667
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.89509106e+00]
 [  3.43549652e+01]
 [  7.85144615e+00]
 [  9.25964451e+00]
 [  8.80440231e-03]
 [  8.78890038e+00]
 [  3.57256546e+01]
 [  4.77363434e+01]
 [  1.65153294e+01]
 [  8.77979183e+00]
 [  7.70009375e+00]
 [  9.07505035e+00]
 [  4.59956398e+01]
 [  4.67985573e+01]
 [  7.29651749e-03]
 [  7.29651749e-03]]
DEBUG:root:training time = %d0.224687
INFO:root:frame =1633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =1634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047779083252
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.987175
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =1637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265836715698
INFO:root:frame =1638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000243186950684
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.987143333333
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.54931545]
 [  0.11295719]
 [ 10.40248871]
 [  0.10020135]
 [  0.09805302]
 [  9.97202778]
 [ 22.71314049]
 [  9.54931545]
 [  0.1203343 ]
 [  0.1361205 ]
 [  0.15754375]
 [  0.0927816 ]
 [  0.09805302]
 [  5.33655119]
 [  0.1361205 ]
 [  0.1361205 ]]
DEBUG:root:training time = %d0.225159
INFO:root:frame =1641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =1642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000260829925537
DEBUG:root: save sample needs time = 0.000108957290649
INFO:root:random_action_porb = 0.987111666667
DEBUG:root: dqn, choose action rondomly, need time 0.000184000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000157833099365
INFO:root:frame =1645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =1646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.98708
DEBUG:root: dqn, choose action rondomly, need time 0.000349999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.21220779]
 [ 23.68010712]
 [  0.13341287]
 [  0.10118911]
 [  5.1162324 ]
 [ 22.77838516]
 [  9.14355659]
 [  3.51560187]
 [  3.51560187]
 [  3.51560187]
 [  0.05329028]
 [ 23.68010712]
 [  4.86652994]
 [  0.10909642]
 [  0.23395489]
 [  0.43092319]]
DEBUG:root:training time = %d0.225579
INFO:root:frame =1649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270128250122
INFO:root:frame =1650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000221014022827
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.987048333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =1653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =1654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446796417236
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.987016666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 22.75961494]
 [  1.56485641]
 [  4.00365925]
 [  7.41731834]
 [  6.23343611]
 [  6.14476538]
 [ 22.55169678]
 [  7.13283253]
 [  7.45701408]
 [  0.08725166]
 [ 22.56034851]
 [  4.00365925]
 [  6.70047045]
 [  6.7510438 ]
 [  6.10700369]
 [  7.45701408]]
DEBUG:root:training time = %d0.226599
INFO:root:frame =1657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =1658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298023223877
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.986985
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =1661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =1662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000526189804077
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.986953333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:training error  = [[  0.83342904]
 [  0.83342904]
 [  0.58541232]
 [  0.97878575]
 [  0.49998084]
 [  0.63780415]
 [ 11.87508774]
 [  0.69881302]
 [ 12.37368488]
 [ 12.37368488]
 [  0.7781679 ]
 [  0.83342904]
 [  0.70219815]
 [  0.66484779]
 [  0.52452886]
 [  0.91581756]]
DEBUG:root:training time = %d0.228043
INFO:root:frame =1665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =1666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:random_action_porb = 0.986921666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =1669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =1670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428915023804
INFO:root:frame = 1671 State into memory, numbers recorded 47 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000531911849976
INFO:root:random_action_porb = 0.98689
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1672current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:training error  = [[  0.22578213]
 [  0.23746958]
 [  0.11325739]
 [  0.43033242]
 [  0.43033242]
 [  0.29596987]
 [  0.54007381]
 [  0.48666823]
 [  0.26293716]
 [  6.50950193]
 [  6.64496326]
 [  0.29596987]
 [ 12.01351643]
 [ 11.31225109]
 [ 11.35555553]
 [  0.17200737]]
DEBUG:root:training time = %d0.216531
INFO:root:frame =1673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =1674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.986858333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =1678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.986826666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  0.81185776]
 [  0.6778031 ]
 [ 12.41215897]
 [  1.37805164]
 [  4.98206806]
 [  0.73154128]
 [  4.45481539]
 [  0.03520598]
 [  3.93288207]
 [ 11.94267273]
 [  1.11321676]
 [  0.78422672]
 [  4.32667351]
 [  0.17382841]
 [  4.00837374]
 [  0.23513772]]
DEBUG:root:training time = %d0.207832
INFO:root:frame =1681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =1682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.986795
DEBUG:root: dqn, choose action rondomly, need time 0.000309
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =1685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =1686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:random_action_porb = 0.986763333333
DEBUG:root: dqn, choose action rondomly, need time 0.000278
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.13676453]
 [  3.17551231]
 [  0.25301501]
 [  1.94348073]
 [  3.24094844]
 [  2.35004807]
 [  1.84035265]
 [ 10.56532097]
 [  1.94627368]
 [  2.89077425]
 [  2.11856246]
 [  0.24539323]
 [  0.18666287]
 [  0.22006017]
 [  0.18666287]
 [  4.04117823]]
DEBUG:root:training time = %d0.213918
INFO:root:frame =1689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:frame =1690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000334024429321
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.986731666667
DEBUG:root: dqn, choose action rondomly, need time 0.000368
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =1693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =1694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000535011291504
INFO:root:frame = 1695 State into memory, numbers recorded 48 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000566959381104
INFO:root:random_action_porb = 0.9867
DEBUG:root: dqn, choose action rondomly, need time 0.000211
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1696current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000209808349609
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.54563808]
 [ 6.13279963]
 [ 0.23848563]
 [ 7.17489958]
 [ 2.56848001]
 [ 6.15047836]
 [ 2.87757134]
 [ 2.50764704]
 [ 3.1329186 ]
 [ 0.03017578]
 [ 0.7655015 ]
 [ 0.35805646]
 [ 6.13279963]
 [ 2.87757134]
 [ 6.15047836]
 [ 0.03017578]]
DEBUG:root:training time = %d0.224628
INFO:root:frame =1697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:frame =1698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.986668333333
DEBUG:root: dqn, choose action rondomly, need time 0.000391
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =1701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000480890274048
INFO:root:frame =1702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.986636666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.12039453]
 [ 3.9028945 ]
 [ 0.29012692]
 [ 2.57091975]
 [ 1.62796187]
 [ 2.11790729]
 [ 1.01149023]
 [ 0.1720034 ]
 [ 8.17620564]
 [ 3.73474741]
 [ 1.62796187]
 [ 0.2174108 ]
 [ 1.9876101 ]
 [ 0.72042692]
 [ 0.18482071]
 [ 2.89544272]]
DEBUG:root:training time = %d0.225484
INFO:root:frame =1705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =1706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.986605
DEBUG:root: dqn, choose action rondomly, need time 0.000325999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =1709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =1710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame = 1711 State into memory, numbers recorded 49 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000574111938477
INFO:root:random_action_porb = 0.986573333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1712current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[ 0.27036873]
 [ 2.03043795]
 [ 2.03043795]
 [ 8.0881834 ]
 [ 0.20615366]
 [ 8.19862556]
 [ 7.94528389]
 [ 1.55369329]
 [ 2.03043795]
 [ 2.03043795]
 [ 1.98540568]
 [ 7.65918255]
 [ 8.62298489]
 [ 7.4458437 ]
 [ 8.95402527]
 [ 1.98540568]]
DEBUG:root:training time = %d0.213114
INFO:root:frame =1713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =1714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:random_action_porb = 0.986541666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =1717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =1718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.98651
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.00146866]
 [  2.40763855]
 [  0.64742374]
 [  0.2510291 ]
 [ 10.98896313]
 [  0.60667354]
 [ 10.00146866]
 [  5.51782322]
 [  0.2510291 ]
 [  2.81469345]
 [  3.27075958]
 [  9.90110779]
 [  0.35594586]
 [  3.27075958]
 [  0.25676668]
 [  5.64459372]]
DEBUG:root:training time = %d0.210541
INFO:root:frame =1721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =1722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000211000442505
DEBUG:root: save sample needs time = 8.98838043213e-05
INFO:root:random_action_porb = 0.986478333333
DEBUG:root: dqn, choose action rondomly, need time 0.000173999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:frame =1725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =1726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234127044678
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.986446666667
DEBUG:root: dqn, choose action rondomly, need time 0.000159999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.4745464 ]
 [ 2.28487849]
 [ 2.81393838]
 [ 9.35385799]
 [ 5.02509117]
 [ 0.28574136]
 [ 9.1252594 ]
 [ 9.62222767]
 [ 4.00610209]
 [ 8.43326187]
 [ 3.19852018]
 [ 4.63326931]
 [ 0.26840961]
 [ 3.9105401 ]
 [ 0.35523385]
 [ 0.69228709]]
DEBUG:root:training time = %d0.221309
INFO:root:frame =1729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000397920608521
INFO:root:frame =1730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.986415
DEBUG:root: dqn, choose action rondomly, need time 0.000306
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =1733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =1734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.986383333333
DEBUG:root: dqn, choose action rondomly, need time 0.000313
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.26712555]
 [ 4.00206804]
 [ 0.20655222]
 [ 2.76925325]
 [ 9.50025082]
 [ 0.56475818]
 [ 0.26653439]
 [ 2.82347775]
 [ 0.56475818]
 [ 0.26653439]
 [ 2.63047481]
 [ 4.63773298]
 [ 0.35777459]
 [ 3.54298997]
 [ 2.63047481]
 [ 3.30899096]]
DEBUG:root:training time = %d0.229927
INFO:root:frame =1737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =1738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame = 1739 State into memory, numbers recorded 50 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000585079193115
INFO:root:random_action_porb = 0.986351666667
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1740current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =1741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =1742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.98632
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.08589077]
 [ 2.74572349]
 [ 1.3721602 ]
 [ 6.84097719]
 [ 1.68718493]
 [ 1.56715262]
 [ 0.41451499]
 [ 1.4599396 ]
 [ 2.59886837]
 [ 6.24285412]
 [ 1.11975873]
 [ 2.1178019 ]
 [ 1.11975873]
 [ 1.4599396 ]
 [ 0.60999846]
 [ 1.08589077]]
DEBUG:root:training time = %d0.231007
INFO:root:frame =1745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =1746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame = 1747 State into memory, numbers recorded 51 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000400066375732
INFO:root:random_action_porb = 0.986288333333
DEBUG:root: dqn, choose action rondomly, need time 0.000222999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1748current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:frame =1749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =1750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.986256666667
DEBUG:root: dqn, choose action rondomly, need time 0.000548000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:training error  = [[ 0.75725496]
 [ 4.60125208]
 [ 0.44911864]
 [ 0.67410225]
 [ 0.29361495]
 [ 0.52101016]
 [ 0.82687306]
 [ 5.37659025]
 [ 0.889094  ]
 [ 3.52064443]
 [ 0.66645688]
 [ 0.66296422]
 [ 4.38291073]
 [ 4.54385424]
 [ 0.6848405 ]
 [ 0.889094  ]]
DEBUG:root:training time = %d0.219748
INFO:root:frame =1753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280141830444
INFO:root:frame =1754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000360012054443
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.986225
DEBUG:root: dqn, choose action rondomly, need time 0.000336000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =1757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000486850738525
INFO:root:frame =1758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame = 1759 State into memory, numbers recorded 52 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000576019287109
INFO:root:random_action_porb = 0.986193333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1760current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 8.15661049]
 [ 3.07814789]
 [ 0.69729036]
 [ 7.56647635]
 [ 0.58845901]
 [ 2.88539696]
 [ 2.33495855]
 [ 0.53865689]
 [ 8.72209644]
 [ 0.8441205 ]
 [ 7.54093122]
 [ 2.88539696]
 [ 2.88539696]
 [ 3.15676808]
 [ 0.45694843]
 [ 2.33495855]]
DEBUG:root:training time = %d0.198163
INFO:root:frame =1761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =1762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264883041382
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:random_action_porb = 0.986161666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =1765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000475168228149
INFO:root:frame =1766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.98613
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.0637722 ]
 [ 15.67287731]
 [ 15.67287731]
 [  2.35942578]
 [  7.48583746]
 [  0.44576445]
 [  2.87991095]
 [  0.57404423]
 [  0.6355601 ]
 [  2.07412887]
 [  8.75687504]
 [  9.00311279]
 [  0.57404423]
 [  2.05904841]
 [  8.06163597]
 [  0.53017521]]
DEBUG:root:training time = %d0.217987
INFO:root:frame =1769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =1770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000407934188843
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:random_action_porb = 0.986098333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =1773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:frame =1774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame = 1775 State into memory, numbers recorded 53 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000546216964722
INFO:root:random_action_porb = 0.986066666667
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1776current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.36798286]
 [  0.61300981]
 [  3.5369432 ]
 [ 15.59659958]
 [  5.64521456]
 [ 16.55690193]
 [ 16.39429855]
 [  3.38038039]
 [  5.64521456]
 [  0.50736088]
 [ 12.03483963]
 [ 14.75566673]
 [  1.80493879]
 [ 15.64563751]
 [ 16.39429855]
 [  6.8354311 ]]
DEBUG:root:training time = %d0.228912
INFO:root:frame =1777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =1778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000358104705811
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.986035
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =1781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =1782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:random_action_porb = 0.986003333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.58072281]
 [ 11.20782375]
 [  2.46245313]
 [  2.51096153]
 [ 17.04400826]
 [  4.95879078]
 [  4.95879078]
 [  4.73902178]
 [  5.04653931]
 [ 15.98203754]
 [  0.81389385]
 [  0.43128136]
 [  5.03600883]
 [  5.01133347]
 [  0.81389385]
 [ 17.04119682]]
DEBUG:root:training time = %d0.224262
INFO:root:frame =1785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =1786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000120162963867
INFO:root:random_action_porb = 0.985971666667
DEBUG:root: dqn, choose action rondomly, need time 0.000171999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root:frame =1789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =1790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.98594
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:training error  = [[ 15.90477467]
 [  8.34011173]
 [  2.98219061]
 [ 14.2506218 ]
 [ 17.91302299]
 [  3.25379968]
 [  0.55863571]
 [  3.63958693]
 [ 20.78688049]
 [  2.96805048]
 [  8.34011173]
 [ 15.58259964]
 [ 18.67857552]
 [ 15.87304783]
 [ 20.68371773]
 [  0.63013566]]
DEBUG:root:training time = %d0.211295
INFO:root:frame =1793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =1794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.985908333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =1797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =1798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449180603027
INFO:root:frame = 1799 State into memory, numbers recorded 54 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000560998916626
INFO:root:random_action_porb = 0.985876666667
DEBUG:root: dqn, choose action rondomly, need time 0.000159
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1800current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000146150588989
INFO:root:training error  = [[ 11.91778946]
 [  0.63190228]
 [ 11.15123081]
 [ 12.27368355]
 [  0.5660274 ]
 [ 11.91778946]
 [ 11.17165375]
 [  4.04331064]
 [  0.80455482]
 [ 11.70633698]
 [  4.60451746]
 [ 11.37770271]
 [ 11.37770271]
 [ 16.45530319]
 [  0.42126063]
 [  4.42946529]]
DEBUG:root:training time = %d0.208105
INFO:root:frame =1801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =1802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:random_action_porb = 0.985845
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =1806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000246047973633
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.985813333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.72386408]
 [  6.60537863]
 [  5.35406256]
 [  9.48436737]
 [  6.41803598]
 [  8.96530056]
 [  7.00474787]
 [  8.0328083 ]
 [ 15.9542408 ]
 [  0.87242371]
 [  7.9119482 ]
 [  8.57352734]
 [  6.44132853]
 [  6.03603697]
 [  9.69085789]
 [  5.72386408]]
DEBUG:root:training time = %d0.221052
INFO:root:frame =1809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =1810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000408887863159
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.985781666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =1814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.98575
DEBUG:root: dqn, choose action rondomly, need time 0.000271000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032377243042
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.13983297]
 [  2.36170268]
 [  0.8210851 ]
 [  2.44227052]
 [ 12.4011879 ]
 [  2.51502228]
 [  3.78344679]
 [  2.2981832 ]
 [  2.44227052]
 [  2.3985908 ]
 [  3.07946634]
 [  6.78171062]
 [  3.78344679]
 [  2.2981832 ]
 [  3.04120827]
 [  3.78344679]]
DEBUG:root:training time = %d0.200843
INFO:root:frame =1817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root:frame =1818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000345945358276
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:random_action_porb = 0.985718333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =1821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =1822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000492095947266
INFO:root:frame = 1823 State into memory, numbers recorded 55 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000562906265259
INFO:root:random_action_porb = 0.985686666667
DEBUG:root: dqn, choose action rondomly, need time 0.000329000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1824current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.1372931 ]
 [  1.77145779]
 [  0.81421739]
 [  1.67251801]
 [  2.86930084]
 [ 10.85750294]
 [  0.81421739]
 [  3.50896907]
 [  1.72415364]
 [ 12.63423061]
 [ 12.48826885]
 [  0.91871476]
 [  1.67251801]
 [  1.77145779]
 [  6.39600182]
 [  0.91871476]]
DEBUG:root:training time = %d0.222156
INFO:root:frame =1825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =1826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298976898193
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.985655
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =1830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446796417236
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.985623333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:training error  = [[  1.4988414 ]
 [ 10.11923313]
 [  0.91985959]
 [  1.84193134]
 [  1.51991701]
 [  1.41688216]
 [  1.5666703 ]
 [ 10.92486763]
 [  0.91985959]
 [  8.99393559]
 [  1.51991701]
 [  1.84193134]
 [  1.43538666]
 [  8.19666481]
 [  1.51991701]
 [  8.7578125 ]]
DEBUG:root:training time = %d0.209532
INFO:root:frame =1833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.985591666667
DEBUG:root: dqn, choose action rondomly, need time 0.000177000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root:frame =1837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000418901443481
INFO:root:frame =1838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428915023804
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.98556
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 9.88682938]
 [ 0.95944232]
 [ 9.14181995]
 [ 7.75220871]
 [ 1.17982376]
 [ 1.33542359]
 [ 1.10986459]
 [ 1.33542359]
 [ 1.306422  ]
 [ 9.02110386]
 [ 9.83152771]
 [ 9.08728886]
 [ 9.37623119]
 [ 4.15260506]
 [ 7.75220871]
 [ 7.08597326]]
DEBUG:root:training time = %d0.234643
INFO:root:frame =1841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =1842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494956970215
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.985528333333
DEBUG:root: dqn, choose action rondomly, need time 0.000157999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000166893005371
INFO:root:frame =1845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =1846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430822372437
INFO:root:frame = 1847 State into memory, numbers recorded 56 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000545024871826
INFO:root:random_action_porb = 0.985496666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1848current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4.60231972]
 [ 1.11358917]
 [ 1.24216557]
 [ 6.76629162]
 [ 6.76629162]
 [ 3.16498113]
 [ 3.4201448 ]
 [ 3.16383433]
 [ 3.31687856]
 [ 4.82490873]
 [ 7.04118156]
 [ 4.11820078]
 [ 3.16383433]
 [ 2.73144388]
 [ 4.04234028]
 [ 6.4256053 ]]
DEBUG:root:training time = %d0.222517
INFO:root:frame =1849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =1850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.985465
DEBUG:root: dqn, choose action rondomly, need time 0.000183999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root:frame =1853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =1854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame = 1855 State into memory, numbers recorded 57 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:random_action_porb = 0.985433333333
DEBUG:root: dqn, choose action rondomly, need time 0.000187
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1856current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000192165374756
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.56839442]
 [ 1.3774606 ]
 [ 3.41716814]
 [ 0.99666494]
 [ 1.18217838]
 [ 2.56570506]
 [ 2.56570506]
 [ 4.96900272]
 [ 1.66456008]
 [ 2.81854439]
 [ 2.70080185]
 [ 7.59036732]
 [ 7.59036732]
 [ 2.75770855]
 [ 0.99666494]
 [ 1.18217838]]
DEBUG:root:training time = %d0.209323
INFO:root:frame =1857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =1858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.985401666667
DEBUG:root: dqn, choose action rondomly, need time 0.000201000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =1861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =1862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000550031661987
DEBUG:root: save sample needs time = 0.000284194946289
INFO:root:random_action_porb = 0.98537
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14.3222971 ]
 [  1.11212838]
 [ 13.3203392 ]
 [ 14.09330177]
 [  1.34672379]
 [  6.86194611]
 [  0.93581772]
 [  3.0180552 ]
 [  2.65964627]
 [  6.4762392 ]
 [ 15.69862175]
 [  1.22877967]
 [  1.22877967]
 [  6.44629622]
 [  2.9635241 ]
 [  1.15709114]]
DEBUG:root:training time = %d0.22927
INFO:root:frame =1865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =1866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.985338333333
DEBUG:root: dqn, choose action rondomly, need time 0.000169
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016713142395
INFO:root:frame =1869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =1870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.985306666667
DEBUG:root: dqn, choose action rondomly, need time 0.000326999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[  1.13457143]
 [  4.59273338]
 [  4.18969727]
 [ 10.12539768]
 [  1.36428022]
 [  1.3407321 ]
 [  9.98740768]
 [  1.13457143]
 [  1.30848956]
 [  1.13469744]
 [  9.51047707]
 [  1.13457143]
 [  9.95357227]
 [ 13.57043648]
 [ 10.02789497]
 [  1.17634988]]
DEBUG:root:training time = %d0.226911
INFO:root:frame =1873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =1874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
DEBUG:root: save sample needs time = 0.000168800354004
INFO:root:random_action_porb = 0.985275
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root: ememy has been killed for 3 times 
INFO:root:enemies_left [0]
INFO:root:frame =1876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =1877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =1878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame = 1879 State into memory, numbers recorded 58 action = 1, reward = 1
DEBUG:root: save sample needs time = 0.000591039657593
INFO:root:random_action_porb = 0.985243333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1880current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:training error  = [[ 10.51509476]
 [  7.65315533]
 [  7.72481966]
 [  7.72481966]
 [  1.27986121]
 [  8.74616623]
 [  1.47146463]
 [  5.50529432]
 [  2.24081969]
 [  1.98758864]
 [ 10.2565155 ]
 [ 10.28290844]
 [  7.60034418]
 [  5.87788343]
 [  5.39044619]
 [  2.03510451]]
DEBUG:root:training time = %d0.224215
INFO:root:frame =1881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =1882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319957733154
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.985211666667
DEBUG:root: dqn, choose action rondomly, need time 0.000352000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =1885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000411033630371
INFO:root:frame =1886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000557899475098
INFO:root:frame = 1887 State into memory, numbers recorded 59 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000539064407349
INFO:root:random_action_porb = 0.98518
DEBUG:root: dqn, choose action rondomly, need time 0.000198000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1888current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.34020042]
 [  7.30857611]
 [  1.55211747]
 [  1.58876872]
 [  3.44815993]
 [  7.1014266 ]
 [  7.31481647]
 [  1.28296173]
 [ 13.34020042]
 [ 20.95449638]
 [  7.31975937]
 [  3.08485079]
 [  7.31975937]
 [  3.36802673]
 [  7.30857611]
 [ 20.95449638]]
DEBUG:root:training time = %d0.220953
INFO:root:frame =1889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =1890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.985148333333
DEBUG:root: dqn, choose action rondomly, need time 0.000236000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =1893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000346183776855
INFO:root:frame =1894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494956970215
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:random_action_porb = 0.985116666667
DEBUG:root: dqn, choose action rondomly, need time 0.000330999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.51918006]
 [  4.69796324]
 [  1.42515385]
 [  3.97029305]
 [  7.26477098]
 [  4.19235229]
 [  2.47896338]
 [  7.04482603]
 [  2.59947109]
 [  3.27298474]
 [  4.69796324]
 [  4.69796324]
 [ 21.13042831]
 [  7.7309494 ]
 [  7.54809284]
 [ 19.62304306]]
DEBUG:root:training time = %d0.200787
INFO:root:frame =1897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:frame =1898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000105857849121
INFO:root:random_action_porb = 0.985085
DEBUG:root: dqn, choose action rondomly, need time 0.000347999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =1901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =1902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00022292137146
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:random_action_porb = 0.985053333333
DEBUG:root: dqn, choose action rondomly, need time 0.000153000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.81317759]
 [ 10.93594074]
 [ 19.96103287]
 [ 21.12171364]
 [  3.86172032]
 [ 21.21053505]
 [  3.73809147]
 [ 21.21053505]
 [  1.48185277]
 [ 10.93594074]
 [ 21.86146736]
 [ 23.33184814]
 [  1.41079509]
 [  1.53769875]
 [  4.19199324]
 [ 20.29568672]]
DEBUG:root:training time = %d0.176121
INFO:root:frame =1905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =1906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame = 1907 State into memory, numbers recorded 60 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000364065170288
INFO:root:random_action_porb = 0.985021666667
DEBUG:root: dqn, choose action rondomly, need time 0.000253000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1908current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:frame =1909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =1910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000245094299316
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:random_action_porb = 0.98499
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000179052352905
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.79338777]
 [  1.80333245]
 [  2.24711704]
 [ 17.6698513 ]
 [ 16.73150253]
 [  1.79338777]
 [  1.52107406]
 [  1.52873361]
 [  1.52873361]
 [ 17.6698513 ]
 [  2.4589076 ]
 [ 14.68775272]
 [  5.13411093]
 [  6.44428158]
 [ 13.00049114]
 [  1.38078904]]
DEBUG:root:training time = %d0.180861
INFO:root:frame =1913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:frame =1914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00033712387085
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.984958333333
DEBUG:root: dqn, choose action rondomly, need time 0.000183
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =1917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =1918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000342130661011
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:random_action_porb = 0.984926666667
DEBUG:root: dqn, choose action rondomly, need time 0.000240000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14.37227631]
 [ 17.73385811]
 [  1.19225371]
 [  1.87775946]
 [ 13.13911819]
 [ 15.72099972]
 [ 15.95675564]
 [ 17.73385811]
 [  1.78457105]
 [  5.05586767]
 [ 15.28038883]
 [ 15.44937038]
 [ 16.62010574]
 [  1.60619831]
 [ 15.37730408]
 [ 17.13788986]]
DEBUG:root:training time = %d0.178132
INFO:root:frame =1921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00036096572876
INFO:root:frame =1922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239849090576
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.984895
DEBUG:root: dqn, choose action rondomly, need time 0.000187
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root:frame =1925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =1926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227212905884
DEBUG:root: save sample needs time = 0.000104904174805
INFO:root:random_action_porb = 0.984863333333
DEBUG:root: dqn, choose action rondomly, need time 0.000164999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4.60263109]
 [ 5.74210453]
 [ 3.45790672]
 [ 5.48357487]
 [ 4.60263109]
 [ 5.28013039]
 [ 6.93018532]
 [ 5.51932001]
 [ 3.63304734]
 [ 6.98069906]
 [ 4.24594784]
 [ 1.88067746]
 [ 4.82834482]
 [ 3.65628624]
 [ 4.28092003]
 [ 5.29273415]]
DEBUG:root:training time = %d0.188734
INFO:root:frame =1929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =1930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root:random_action_porb = 0.984831666667
DEBUG:root: dqn, choose action rondomly, need time 0.000219000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =1933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000363111495972
INFO:root:frame =1934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000287055969238
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.9848
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 15.07189369]
 [  3.30280399]
 [  2.60422754]
 [  3.73111773]
 [  1.93762207]
 [ 15.92815113]
 [  4.5931015 ]
 [  2.73185372]
 [  2.18237782]
 [  9.66096687]
 [ 15.0042448 ]
 [  3.98888397]
 [  4.82769108]
 [ 15.39195156]
 [  2.39916396]
 [  3.98888397]]
DEBUG:root:training time = %d0.173753
INFO:root:frame =1937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000389814376831
INFO:root:frame =1938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame = 1939 State into memory, numbers recorded 61 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000397920608521
INFO:root:random_action_porb = 0.984768333333
DEBUG:root: dqn, choose action rondomly, need time 0.000190999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1940current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:frame =1941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000834941864014
INFO:root:frame =1942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000245094299316
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.984736666667
DEBUG:root: dqn, choose action rondomly, need time 0.000254999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180006027222
INFO:root:training error  = [[  2.20255947]
 [  2.94095731]
 [ 12.1426506 ]
 [ 13.06200504]
 [  3.18967772]
 [ 17.54330444]
 [ 17.42529869]
 [  3.43552732]
 [  2.10737801]
 [  1.60236669]
 [  5.34159756]
 [  3.01560378]
 [  3.14095521]
 [ 13.06200504]
 [ 17.42529869]
 [  1.73931384]]
DEBUG:root:training time = %d0.180421
INFO:root:frame =1945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:frame =1946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000244855880737
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.984705
DEBUG:root: dqn, choose action rondomly, need time 0.000247999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000191926956177
INFO:root:frame =1949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =1950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00126600265503
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.984673333333
DEBUG:root: dqn, choose action rondomly, need time 0.000158000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000351905822754
INFO:root:training error  = [[ 16.95431137]
 [ 12.27344322]
 [  4.41414404]
 [ 15.46474266]
 [ 12.54528999]
 [ 12.54528999]
 [ 15.39931583]
 [ 17.96327019]
 [ 17.06849098]
 [  4.78315353]
 [ 12.27344322]
 [ 11.51634312]
 [ 12.87889957]
 [ 17.91946602]
 [  1.53164518]
 [  2.16263103]]
DEBUG:root:training time = %d0.180515
INFO:root:player has been killed for 3 times 
INFO:root:frame =1953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:frame =1954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000603199005127
INFO:root:frame = 1955 State into memory, numbers recorded 62 action = 3, reward = -1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:random_action_porb = 0.984641666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1956current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =1957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =1958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
DEBUG:root: save sample needs time = 0.000371217727661
INFO:root:random_action_porb = 0.98461
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 10.07767677]
 [ 10.07767677]
 [  5.90725613]
 [ 10.66459274]
 [ 15.53286362]
 [  5.32711315]
 [ 10.39769936]
 [ 10.66459274]
 [  5.00912619]
 [  5.35199738]
 [  2.29088497]
 [  9.67752647]
 [ 10.66459274]
 [ 14.93418407]
 [ 14.73031235]
 [ 15.28796482]]
DEBUG:root:training time = %d0.232186
INFO:root:frame =1961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245809555054
INFO:root:frame =1962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294208526611
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.984578333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =1965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000592947006226
INFO:root:frame =1966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000361919403076
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.984546666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.19246101]
 [  4.15975189]
 [  7.50619841]
 [  2.82161283]
 [ 22.10601997]
 [  4.86676121]
 [  4.44638968]
 [  4.91964436]
 [ 20.6943531 ]
 [  8.10918999]
 [  1.97096241]
 [  2.82161283]
 [  4.04241705]
 [  7.50619841]
 [  2.8011899 ]
 [  2.7678473 ]]
DEBUG:root:training time = %d0.215974
INFO:root:frame =1969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =1970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000499963760376
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.984515
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =1973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =1974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.984483333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.42171144]
 [  5.15143871]
 [ 11.22953224]
 [ 20.99230194]
 [ 22.33761597]
 [ 21.6763649 ]
 [  5.97966528]
 [  4.90381765]
 [ 30.65563011]
 [  2.48088574]
 [ 30.65563011]
 [  2.41657877]
 [  5.97966528]
 [  4.91489887]
 [  2.3494544 ]
 [  5.77263021]]
DEBUG:root:training time = %d0.210434
INFO:root:frame =1977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =1978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.984451666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00048303604126
INFO:root:frame =1982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049614906311
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.98442
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:training error  = [[ 18.79289436]
 [ 12.95501804]
 [  3.00079656]
 [ 18.40320778]
 [ 19.16793823]
 [ 18.40320778]
 [  2.89986157]
 [  2.7179625 ]
 [  3.59073043]
 [  2.89986157]
 [ 12.73578835]
 [ 18.28222656]
 [  3.07018185]
 [  3.0320878 ]
 [ 12.73578835]
 [  2.7179625 ]]
DEBUG:root:training time = %d0.202615
INFO:root:frame =1985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =1986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233888626099
DEBUG:root: save sample needs time = 0.00010085105896
INFO:root:random_action_porb = 0.984388333333
DEBUG:root: dqn, choose action rondomly, need time 0.000183
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:frame =1989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =1990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.984356666667
DEBUG:root: dqn, choose action rondomly, need time 0.000216000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.30298424]
 [ 16.7262764 ]
 [ 17.76633835]
 [ 10.1092968 ]
 [ 10.42093658]
 [  9.94979286]
 [  2.84869266]
 [ 16.83427048]
 [  2.46406054]
 [ 16.87755775]
 [ 11.03144264]
 [ 17.45059586]
 [  2.80996895]
 [  2.44389844]
 [ 17.31950378]
 [ 10.39769936]]
DEBUG:root:training time = %d0.170363
INFO:root:frame =1993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =1994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000270128250122
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:random_action_porb = 0.984325
DEBUG:root: dqn, choose action rondomly, need time 0.000170000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000186204910278
INFO:root:frame =1997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =1998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000205039978027
DEBUG:root:one frame running time = 0.006238
DEBUG:root:total training time = 22.83247
INFO:root:frame num = 2000 frame round: 0
INFO:root:random_action_porb = 0.984293333333
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.60968685]
 [ 11.30729866]
 [  5.82532215]
 [  6.14837313]
 [  5.42778873]
 [  7.01646423]
 [ 11.45937538]
 [  6.11427402]
 [ 11.98173237]
 [  3.09040093]
 [ 11.54727745]
 [  7.01646423]
 [ 11.50081348]
 [  7.02236652]
 [ 11.25704575]
 [  7.28236389]]
DEBUG:root:training time = %d0.193863
INFO:root:frame =2001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000377893447876
INFO:root:frame =2002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.984261666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root:frame =2005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =2006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000399827957153
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.98423
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 22.27495384]
 [ 23.89008713]
 [  6.4524765 ]
 [ 22.14745331]
 [  2.87825084]
 [  7.28508186]
 [ 10.0206604 ]
 [  6.42897081]
 [ 23.89008713]
 [  5.89900732]
 [ 10.93788338]
 [ 23.32788658]
 [  3.29769659]
 [  6.14591408]
 [  3.2161324 ]
 [  6.42897081]]
DEBUG:root:training time = %d0.228927
INFO:root:frame =2009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =2010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.984198333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =2013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =2014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.984166666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.76098442]
 [ 17.59267807]
 [  8.01977444]
 [ 11.69774437]
 [  3.1048224 ]
 [ 19.161726  ]
 [  3.03367567]
 [  3.01904941]
 [  8.88380814]
 [ 27.58325195]
 [ 19.10342598]
 [  5.19152546]
 [  5.42537165]
 [  4.95257044]
 [  9.51665401]
 [  8.21037674]]
DEBUG:root:training time = %d0.215706
INFO:root:frame =2017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =2018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.984135
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =2021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =2022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:random_action_porb = 0.984103333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.40616989]
 [  9.11268616]
 [  9.60412598]
 [ 19.17525482]
 [  4.38658476]
 [  4.4829998 ]
 [  4.38658476]
 [  3.40547943]
 [  2.8448503 ]
 [ 16.5697422 ]
 [ 10.59461021]
 [ 11.80429268]
 [  3.02918577]
 [  9.02168846]
 [  4.4829998 ]
 [ 19.17525482]]
DEBUG:root:training time = %d0.223516
INFO:root:frame =2025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =2026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235080718994
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:random_action_porb = 0.984071666667
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root:frame =2029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000418901443481
INFO:root:frame =2030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:random_action_porb = 0.98404
DEBUG:root: dqn, choose action rondomly, need time 0.000422
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000484943389893
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.14131069]
 [ 25.04598808]
 [ 15.89817238]
 [ 14.88497162]
 [  3.16208386]
 [  8.14984608]
 [ 16.09287643]
 [  3.17252541]
 [  3.62338328]
 [ 25.04598808]
 [ 24.65387726]
 [ 25.04598808]
 [  3.17252541]
 [  8.89700222]
 [  8.36387444]
 [  3.45819759]]
DEBUG:root:training time = %d0.222569
INFO:root:frame =2033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000394821166992
INFO:root:frame =2034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293016433716
DEBUG:root: save sample needs time = 0.000125885009766
INFO:root:random_action_porb = 0.984008333333
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000178813934326
INFO:root:frame =2037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =2038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.983976666667
DEBUG:root: dqn, choose action rondomly, need time 0.000505
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.4744072 ]
 [ 16.38130379]
 [ 16.48726654]
 [  8.00202465]
 [ 18.279356  ]
 [  8.20681381]
 [  5.25359535]
 [ 17.61819077]
 [  3.81185174]
 [  5.10173178]
 [  3.99331951]
 [  4.06403589]
 [  8.26566887]
 [ 16.27882195]
 [ 17.26978493]
 [  1.41348314]]
DEBUG:root:training time = %d0.222821
INFO:root:frame =2041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =2042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000251054763794
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.983945
DEBUG:root: dqn, choose action rondomly, need time 0.000236999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:frame =2045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000476837158203
INFO:root:frame =2046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00053596496582
INFO:root:frame = 2047 State into memory, numbers recorded 63 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000380039215088
INFO:root:random_action_porb = 0.983913333333
DEBUG:root: dqn, choose action rondomly, need time 0.000239000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2048current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 20.17560196]
 [ 20.19723129]
 [ 30.19220352]
 [ 15.78524113]
 [ 15.47898293]
 [ 18.32933044]
 [ 15.30976391]
 [ 18.32933044]
 [  3.43924022]
 [ 18.32933044]
 [  3.36710954]
 [ 11.40698147]
 [  3.18916678]
 [ 15.82130241]
 [  8.17613411]
 [ 25.46952248]]
DEBUG:root:training time = %d0.222392
INFO:root:frame =2049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:frame =2050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.983881666667
DEBUG:root: dqn, choose action rondomly, need time 0.000314999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =2053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =2054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.98385
DEBUG:root: dqn, choose action rondomly, need time 0.000368000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000527143478394
INFO:root:training error  = [[ 12.34275341]
 [ 12.39690304]
 [ 28.77280617]
 [ 28.68100548]
 [ 13.89269924]
 [  3.76947308]
 [ 13.89269924]
 [ 30.45301437]
 [ 13.95393467]
 [  3.23880267]
 [ 28.49173164]
 [ 12.7986927 ]
 [ 15.68255997]
 [  3.72459197]
 [  3.74433374]
 [  3.75613856]]
DEBUG:root:training time = %d0.213319
INFO:root:frame =2057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000347852706909
INFO:root:frame =2058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000122785568237
INFO:root:random_action_porb = 0.983818333333
DEBUG:root: dqn, choose action rondomly, need time 0.000333000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000377893447876
INFO:root:frame =2061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049614906311
INFO:root:frame =2062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.983786666667
DEBUG:root: dqn, choose action rondomly, need time 0.000344999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[  4.20941257]
 [ 15.98129845]
 [ 15.44775105]
 [  3.86482453]
 [  4.11939287]
 [  7.81190825]
 [  4.91921282]
 [  4.20941257]
 [  5.07760048]
 [  4.57582664]
 [  4.06315947]
 [ 11.95201492]
 [  4.36215496]
 [  4.43597078]
 [  7.29229069]
 [  3.88183665]]
DEBUG:root:training time = %d0.230766
INFO:root:frame =2065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =2066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.983755
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =2069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =2070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000329971313477
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.983723333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:training error  = [[  3.97229242]
 [ 10.61612606]
 [  4.59698582]
 [  8.49171543]
 [  4.2998991 ]
 [  5.34393406]
 [ 12.06371307]
 [  4.59698582]
 [ 11.83962727]
 [  5.26006746]
 [  8.49171543]
 [  9.12939072]
 [ 12.06371307]
 [  4.44901228]
 [  4.59698582]
 [  3.68265867]]
DEBUG:root:training time = %d0.223444
INFO:root:frame =2073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =2074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000406980514526
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.983691666667
DEBUG:root: dqn, choose action rondomly, need time 0.000164999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000147104263306
INFO:root:frame =2077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229835510254
INFO:root:frame =2078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000221014022827
DEBUG:root: save sample needs time = 0.000178098678589
INFO:root:random_action_porb = 0.98366
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000177145004272
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.56032944]
 [  6.6988759 ]
 [  6.09241009]
 [ 16.76934814]
 [ 15.0440197 ]
 [  2.25543928]
 [  6.09241009]
 [  2.25543928]
 [  8.89060879]
 [ 16.61194229]
 [  7.77352953]
 [ 16.73599625]
 [  8.54127693]
 [ 26.16550636]
 [ 15.95191002]
 [  7.12135506]]
DEBUG:root:training time = %d0.236958
INFO:root:frame =2081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =2082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.983628333333
DEBUG:root: dqn, choose action rondomly, need time 0.000277999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =2085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =2086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.983596666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.4571209 ]
 [  5.39465427]
 [ 28.71410942]
 [ 27.1113472 ]
 [ 14.05440426]
 [ 13.92009735]
 [  5.87514639]
 [  5.51129293]
 [  5.45115185]
 [ 10.75769138]
 [  5.87514639]
 [ 28.05781364]
 [  5.82486153]
 [ 15.1402874 ]
 [ 27.52886391]
 [  3.76529694]]
DEBUG:root:training time = %d0.211325
INFO:root:frame =2089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root:frame =2090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.983565
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:frame =2093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000423908233643
INFO:root:frame =2094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame = 2095 State into memory, numbers recorded 64 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000529050827026
INFO:root:random_action_porb = 0.983533333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2096current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:training error  = [[ 22.47242546]
 [  5.43965101]
 [ 13.2783823 ]
 [  5.12054968]
 [  4.25766802]
 [ 28.31278801]
 [ 28.81468773]
 [ 13.0596056 ]
 [ 13.2783823 ]
 [ 12.88218594]
 [  5.51161528]
 [ 29.70313263]
 [ 13.35935116]
 [  3.94381738]
 [  4.2964983 ]
 [  5.59882784]]
DEBUG:root:training time = %d0.218385
INFO:root:frame =2097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =2098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.983501666667
DEBUG:root: dqn, choose action rondomly, need time 0.000339
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =2101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =2102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame = 2103 State into memory, numbers recorded 65 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.00055193901062
INFO:root:random_action_porb = 0.98347
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2104current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000392913818359
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.96533966]
 [ 34.79088974]
 [ 16.96533966]
 [ 33.46485519]
 [ 16.6975975 ]
 [ 33.46485519]
 [ 37.10027695]
 [ 36.35421371]
 [ 35.6005249 ]
 [ 17.35775185]
 [ 36.53181076]
 [  4.52175522]
 [ 18.42666626]
 [ 48.43994141]
 [ 16.97335434]
 [ 16.58639145]]
DEBUG:root:training time = %d0.229062
INFO:root:frame =2105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =2106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000266075134277
DEBUG:root: save sample needs time = 0.000243186950684
INFO:root:random_action_porb = 0.983438333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =2109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000481128692627
INFO:root:frame =2110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.983406666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:training error  = [[ 22.12803268]
 [ 18.11519623]
 [  5.05191422]
 [ 18.1623764 ]
 [ 17.63580894]
 [ 18.33047295]
 [ 18.1623764 ]
 [  5.26248264]
 [  5.32280874]
 [  4.43667793]
 [ 18.30885506]
 [ 13.18577194]
 [ 18.11519623]
 [  4.89619255]
 [ 18.1623764 ]
 [ 18.33047295]]
DEBUG:root:training time = %d0.213996
INFO:root:frame =2113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =2114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000425815582275
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.983375
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root: ememy has been killed for 4 times 
INFO:root:enemies_left [0]
INFO:root:frame =2116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =2117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =2118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame = 2119 State into memory, numbers recorded 66 action = 3, reward = 1
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:random_action_porb = 0.983343333333
DEBUG:root: dqn, choose action rondomly, need time 0.000208000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2120current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 24.06559944]
 [ 13.02420139]
 [  5.04163027]
 [ 24.60469437]
 [  5.14360619]
 [ 24.7355442 ]
 [ 26.15364265]
 [ 10.49476814]
 [ 17.74353027]
 [ 12.09404755]
 [ 16.53485298]
 [ 17.06377792]
 [ 12.6201601 ]
 [  4.86785555]
 [  6.43359518]
 [ 11.97088051]]
DEBUG:root:training time = %d0.184841
INFO:root:frame =2121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =2122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000220060348511
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.983311666667
DEBUG:root: dqn, choose action rondomly, need time 0.000159
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:frame =2125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =2126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000401020050049
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.98328
DEBUG:root: dqn, choose action rondomly, need time 0.000198000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.65756226]
 [ 14.3438158 ]
 [  5.89048672]
 [ 14.03419018]
 [ 15.59943199]
 [ 14.5280304 ]
 [  5.08508158]
 [ 15.3538866 ]
 [ 10.21180153]
 [ 23.94829559]
 [ 14.3438158 ]
 [  5.65304375]
 [ 14.10900116]
 [  5.61658764]
 [  9.66059971]
 [  5.11471605]]
DEBUG:root:training time = %d0.189716
INFO:root:frame =2129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =2130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root:random_action_porb = 0.983248333333
DEBUG:root: dqn, choose action rondomly, need time 0.000252
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:frame =2133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =2134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000224828720093
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.983216666667
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000184059143066
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.87598801]
 [ 12.47791767]
 [  5.55873299]
 [  5.3638649 ]
 [  8.71182442]
 [  5.58529663]
 [ 27.64198494]
 [  9.16069984]
 [ 18.39098549]
 [ 26.49333   ]
 [  5.58529663]
 [ 13.42996693]
 [ 11.93527126]
 [  8.62738228]
 [ 13.15608978]
 [ 27.41397858]]
DEBUG:root:training time = %d0.190343
INFO:root:frame =2137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =2138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264883041382
DEBUG:root: save sample needs time = 9.91821289062e-05
INFO:root:random_action_porb = 0.983185
DEBUG:root: dqn, choose action rondomly, need time 0.000232
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:frame =2141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =2142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457763671875
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.983153333333
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.44625425]
 [  7.84441853]
 [  7.13496208]
 [ 19.01353073]
 [  7.3267169 ]
 [ 14.98518944]
 [  7.74218559]
 [  6.05073214]
 [  6.33362913]
 [  6.05073214]
 [  7.66056538]
 [  7.83454943]
 [  6.07020903]
 [ 21.66400719]
 [ 17.5385437 ]
 [  5.99067736]]
DEBUG:root:training time = %d0.190919
INFO:root:frame =2145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000411987304688
INFO:root:frame =2146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000175952911377
INFO:root:random_action_porb = 0.983121666667
DEBUG:root: dqn, choose action rondomly, need time 0.000156999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000141143798828
INFO:root:frame =2149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =2150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.98309
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.79258347]
 [  5.62165165]
 [ 18.40675926]
 [ 16.79719543]
 [  8.91020584]
 [  6.04367781]
 [ 16.79719543]
 [ 13.69480515]
 [ 23.78642082]
 [  7.41333485]
 [ 13.94544315]
 [  8.51389599]
 [  5.79464769]
 [ 13.96733189]
 [  8.5246067 ]
 [ 14.84446716]]
DEBUG:root:training time = %d0.2052
INFO:root:frame =2153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =2154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame = 2155 State into memory, numbers recorded 67 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000355958938599
INFO:root:random_action_porb = 0.983058333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2156current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =2157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454187393188
INFO:root:frame =2158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.983026666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.13678217]
 [ 20.78589058]
 [ 10.8250351 ]
 [ 13.33368015]
 [  5.92106056]
 [ 11.73493195]
 [  4.1406188 ]
 [ 18.28447723]
 [ 13.28880978]
 [  6.27604342]
 [ 10.65725708]
 [ 10.65725708]
 [  9.473773  ]
 [ 11.51623917]
 [  9.473773  ]
 [ 21.37298584]]
DEBUG:root:training time = %d0.196724
INFO:root:frame =2161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =2162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.982995
DEBUG:root: dqn, choose action rondomly, need time 0.000195000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =2165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =2166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491142272949
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:random_action_porb = 0.982963333333
DEBUG:root: dqn, choose action rondomly, need time 0.000277000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000158786773682
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.81322765]
 [  6.39161253]
 [  8.63513756]
 [  8.93874168]
 [ 17.0265789 ]
 [  8.75258636]
 [  8.93874168]
 [ 18.0606842 ]
 [ 16.24451828]
 [ 26.85046768]
 [  8.50417042]
 [ 31.0902462 ]
 [  8.93874168]
 [  9.35725975]
 [  6.07370615]
 [ 16.8631115 ]]
DEBUG:root:training time = %d0.18703
INFO:root:frame =2169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:frame =2170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000121831893921
INFO:root:random_action_porb = 0.982931666667
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =2173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =2174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.9829
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14.35251427]
 [ 34.46620178]
 [  6.48418236]
 [ 13.75447083]
 [  6.74219084]
 [ 33.63565445]
 [ 22.37008095]
 [ 14.39303684]
 [  7.09418058]
 [ 23.01630402]
 [ 13.73057175]
 [ 13.73057175]
 [  6.48418236]
 [  6.48418236]
 [  7.38048792]
 [ 23.25542259]]
DEBUG:root:training time = %d0.206995
INFO:root:frame =2177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255823135376
INFO:root:frame =2178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.982868333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =2181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000422954559326
INFO:root:frame =2182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.982836666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:training error  = [[ 17.04922104]
 [ 16.40620232]
 [ 10.80859947]
 [ 11.599473  ]
 [ 22.39191818]
 [ 11.95333385]
 [ 22.42326546]
 [ 16.66307259]
 [ 10.72066307]
 [  7.31385708]
 [ 11.3751297 ]
 [ 12.10721111]
 [ 11.29609108]
 [ 22.39191818]
 [ 11.5996809 ]
 [ 26.75902557]]
DEBUG:root:training time = %d0.186395
INFO:root:frame =2185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =2186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000115871429443
INFO:root:random_action_porb = 0.982805
DEBUG:root: dqn, choose action rondomly, need time 0.000177000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:frame =2189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =2190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000328063964844
DEBUG:root: save sample needs time = 0.000151872634888
INFO:root:random_action_porb = 0.982773333333
DEBUG:root: dqn, choose action rondomly, need time 0.000211
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14.29003429]
 [ 23.74461555]
 [  7.35867882]
 [ 20.66991043]
 [ 15.04653549]
 [  7.43566179]
 [ 26.40249825]
 [  6.56306362]
 [ 15.16820526]
 [ 10.88289642]
 [ 14.0588665 ]
 [  7.30880308]
 [  7.00688839]
 [ 27.95780182]
 [ 21.5918026 ]
 [ 29.0700264 ]]
DEBUG:root:training time = %d0.19595
INFO:root:frame =2193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =2194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232219696045
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:random_action_porb = 0.982741666667
DEBUG:root: dqn, choose action rondomly, need time 0.000173
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000280857086182
INFO:root:frame =2197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =2198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
DEBUG:root: save sample needs time = 0.000121116638184
INFO:root:random_action_porb = 0.98271
DEBUG:root: dqn, choose action rondomly, need time 0.000385999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.71974659]
 [ 27.35074043]
 [ 13.32551861]
 [ 26.23693275]
 [ 19.12887764]
 [  7.18941641]
 [ 22.66898918]
 [ 18.26667023]
 [ 14.10467434]
 [ 18.81822205]
 [ 23.6547699 ]
 [ 28.99319458]
 [ 12.99987221]
 [ 18.23968124]
 [  2.76760602]
 [ 14.98028755]]
DEBUG:root:training time = %d0.19803
INFO:root:frame =2201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:frame =2202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000355005264282
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.982678333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =2205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =2206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame = 2207 State into memory, numbers recorded 68 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000571012496948
INFO:root:random_action_porb = 0.982646666667
DEBUG:root: dqn, choose action rondomly, need time 0.00027
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2208current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 23.55750275]
 [ 22.52395821]
 [  8.00396633]
 [ 18.57976151]
 [ 22.52395821]
 [  6.61596155]
 [ 15.98480606]
 [  7.41026068]
 [ 14.8303318 ]
 [ 14.01419067]
 [ 19.03446198]
 [  3.01063752]
 [  6.93612146]
 [ 19.04664612]
 [ 14.72264099]
 [ 19.00741005]]
DEBUG:root:training time = %d0.236647
INFO:root:frame =2209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =2210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.982615
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =2213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427961349487
INFO:root:frame =2214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000625133514404
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.982583333333
DEBUG:root: dqn, choose action rondomly, need time 0.000225
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 15.99273777]
 [ 29.83242226]
 [ 24.32514381]
 [ 14.85655117]
 [  7.66073465]
 [ 29.14724541]
 [ 14.02404594]
 [ 14.38695908]
 [  7.03573704]
 [  7.66073465]
 [ 11.03420448]
 [ 15.29105186]
 [ 15.29105186]
 [ 16.24550247]
 [ 14.05580616]
 [ 15.11464977]]
DEBUG:root:training time = %d0.217706
INFO:root:frame =2217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =2218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000419139862061
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.982551666667
DEBUG:root: dqn, choose action rondomly, need time 0.000160000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000343799591064
INFO:root:frame =2221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =2222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000561952590942
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.98252
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.98324776]
 [  8.26132679]
 [ 14.18700027]
 [ 10.33750153]
 [ 10.98324776]
 [ 17.11528206]
 [ 10.98324776]
 [ 17.11528206]
 [ 21.04709435]
 [ 31.72625542]
 [  7.9943428 ]
 [ 10.17920685]
 [  9.89177132]
 [ 32.0831604 ]
 [ 11.21804333]
 [ 23.48564529]]
DEBUG:root:training time = %d0.22765
INFO:root:frame =2225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =2226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000555992126465
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.982488333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =2229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =2230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.982456666667
DEBUG:root: dqn, choose action rondomly, need time 0.000465999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.89183712]
 [ 21.59350395]
 [ 41.39785385]
 [  8.76062393]
 [ 41.35451889]
 [ 27.39668465]
 [ 42.7254715 ]
 [ 21.17943382]
 [  3.40107417]
 [ 27.34403801]
 [ 26.95572853]
 [  8.84900475]
 [  9.27761364]
 [ 40.59506607]
 [ 20.02322197]
 [  9.47428989]]
DEBUG:root:training time = %d0.219754
INFO:root:frame =2233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000517129898071
INFO:root:frame =2234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.982425
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =2237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =2238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000372171401978
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:random_action_porb = 0.982393333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17.44524193]
 [  8.32425022]
 [ 16.44902992]
 [ 26.01955795]
 [ 26.95529366]
 [ 28.08162308]
 [ 37.70235825]
 [ 16.10943985]
 [ 17.20184326]
 [  8.32425022]
 [ 40.32461166]
 [  7.88359261]
 [ 22.87487221]
 [ 27.50429153]
 [ 16.10943985]
 [ 37.78424072]]
DEBUG:root:training time = %d0.218307
INFO:root:frame =2241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270128250122
INFO:root:frame =2242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.982361666667
DEBUG:root: dqn, choose action rondomly, need time 0.000328
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =2245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =2246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 9.58442687988e-05
INFO:root:random_action_porb = 0.98233
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.47456074]
 [ 24.44343948]
 [ 24.27053642]
 [  8.49927616]
 [  9.81943893]
 [ 22.23547173]
 [ 14.15262318]
 [ 25.00247955]
 [ 11.91085052]
 [ 11.10744095]
 [ 22.26570129]
 [ 22.26570129]
 [  6.88848209]
 [ 22.12365532]
 [  8.56961823]
 [ 24.53261566]]
DEBUG:root:training time = %d0.219836
INFO:root:frame =2249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =2250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000340938568115
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.982298333333
DEBUG:root: dqn, choose action rondomly, need time 0.000272000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000380039215088
INFO:root:frame =2253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =2254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.982266666667
DEBUG:root: dqn, choose action rondomly, need time 0.000187999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 36.35899734]
 [ 27.48109055]
 [ 44.45682144]
 [ 23.65376854]
 [ 42.36944962]
 [ 21.02823448]
 [ 13.57923508]
 [ 28.29298019]
 [ 14.09550667]
 [ 24.96525955]
 [ 44.71020889]
 [ 43.87960815]
 [ 42.36130524]
 [ 23.65376854]
 [ 23.34845161]
 [ 28.02096939]]
DEBUG:root:training time = %d0.216604
INFO:root:frame =2257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000402927398682
INFO:root:frame =2258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.982235
DEBUG:root: dqn, choose action rondomly, need time 0.000331000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =2261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =2262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.982203333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:training error  = [[ 26.33526993]
 [ 43.92515564]
 [ 10.04731655]
 [ 44.26834488]
 [ 10.04731655]
 [ 26.83837128]
 [ 19.93534088]
 [ 35.40032959]
 [ 21.63393974]
 [ 34.23341751]
 [ 43.21222687]
 [ 34.58948898]
 [ 10.04731655]
 [ 35.40032959]
 [ 45.51966476]
 [ 19.05370522]]
DEBUG:root:training time = %d0.22897
INFO:root:frame =2265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =2266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000278949737549
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.982171666667
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =2269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470876693726
INFO:root:frame =2270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.98214
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:training error  = [[ 10.28451157]
 [  8.85722256]
 [ 24.37773895]
 [ 24.61555672]
 [ 19.37290573]
 [  8.85722256]
 [ 24.37773895]
 [ 23.31182289]
 [ 25.53652382]
 [ 16.67531395]
 [ 20.51629257]
 [ 26.70332718]
 [ 20.01161575]
 [ 19.4114418 ]
 [ 17.36862564]
 [  9.46245766]]
DEBUG:root:training time = %d0.224486
INFO:root:frame =2273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249147415161
INFO:root:frame =2274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.982108333333
DEBUG:root: dqn, choose action rondomly, need time 0.000323999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =2277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =2278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.982076666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 26.88823509]
 [ 27.10749435]
 [ 13.62028503]
 [ 25.68764877]
 [ 14.41388416]
 [ 23.2436142 ]
 [  9.90017223]
 [ 14.02964592]
 [ 37.64742661]
 [ 19.22476387]
 [ 13.95444679]
 [ 15.1093111 ]
 [ 13.95444679]
 [ 24.36832237]
 [ 14.41388416]
 [ 15.44025517]]
DEBUG:root:training time = %d0.19772
INFO:root:frame =2281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:frame =2282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268220901489
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.982045
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =2285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =2286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:random_action_porb = 0.982013333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 20.13795662]
 [ 42.24399948]
 [ 19.06819534]
 [ 42.70193481]
 [ 13.97993755]
 [ 20.64830589]
 [ 10.64485741]
 [ 10.53799152]
 [  9.6810751 ]
 [ 11.39850521]
 [ 42.00013351]
 [ 42.00013351]
 [ 21.01913834]
 [ 13.89440536]
 [ 41.85612869]
 [ 14.22642517]]
DEBUG:root:training time = %d0.227296
INFO:root:frame =2289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:frame =2290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247001647949
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.981981666667
DEBUG:root: dqn, choose action rondomly, need time 0.000311999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =2293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000581979751587
INFO:root:frame =2294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000416994094849
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.98195
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.59143162]
 [ 37.76379776]
 [ 49.83101654]
 [ 20.53426552]
 [ 41.38779068]
 [ 37.76379776]
 [ 19.75703812]
 [ 43.78944397]
 [ 35.79439163]
 [ 23.97559738]
 [ 42.52304077]
 [ 43.19813538]
 [ 37.3585434 ]
 [ 10.29141235]
 [ 23.97559738]
 [ 10.53378105]]
DEBUG:root:training time = %d0.211663
INFO:root:frame =2297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =2298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288009643555
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.981918333333
DEBUG:root: dqn, choose action rondomly, need time 0.000366999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =2301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =2302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root:random_action_porb = 0.981886666667
DEBUG:root: dqn, choose action rondomly, need time 0.000487999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 23.58650589]
 [ 10.61905956]
 [ 21.57918358]
 [ 11.7292614 ]
 [ 53.801651  ]
 [ 55.84800339]
 [ 54.95095825]
 [ 23.4724102 ]
 [ 46.7411499 ]
 [ 32.76556396]
 [ 47.20380402]
 [ 35.52877426]
 [ 22.77558327]
 [ 33.59964752]
 [ 46.56917953]
 [ 47.32092667]]
DEBUG:root:training time = %d0.237507
INFO:root:frame =2305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =2306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000266075134277
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.981855
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =2309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =2310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.981823333333
DEBUG:root: dqn, choose action rondomly, need time 0.000570999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 32.46187973]
 [ 33.2752533 ]
 [ 32.92585754]
 [ 28.63219833]
 [ 11.28422165]
 [ 19.20596886]
 [ 18.90337563]
 [ 11.01535702]
 [ 33.24489594]
 [ 11.08185005]
 [ 32.42181396]
 [ 32.16410828]
 [ 32.46074677]
 [ 17.49211693]
 [ 11.778409  ]
 [ 11.61808491]]
DEBUG:root:training time = %d0.221615
INFO:root:frame =2313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =2314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.981791666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =2317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =2318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.98176
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 26.61981201]
 [ 39.44097137]
 [ 27.39500809]
 [ 12.82160282]
 [ 19.90472794]
 [ 25.3795433 ]
 [ 26.33300018]
 [ 26.67069435]
 [ 27.3888588 ]
 [ 32.40982437]
 [ 29.76911545]
 [ 28.87233925]
 [ 12.33972549]
 [ 12.82160282]
 [ 28.63440323]
 [ 28.63440323]]
DEBUG:root:training time = %d0.218258
INFO:root:frame =2321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =2322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.981728333333
DEBUG:root: dqn, choose action rondomly, need time 0.000368000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =2325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =2326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.981696666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 34.38701248]
 [  8.43086338]
 [ 16.81167603]
 [ 13.92021084]
 [ 15.54899979]
 [ 35.61595917]
 [ 17.98224068]
 [ 15.58217049]
 [ 15.16155052]
 [ 23.62620735]
 [ 17.13359451]
 [ 13.92021084]
 [ 15.41828823]
 [ 15.98932076]
 [ 34.38701248]
 [ 14.43225479]]
DEBUG:root:training time = %d0.228373
INFO:root:frame =2329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:frame =2330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000250816345215
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.981665
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =2333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =2334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.981633333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.29159927]
 [ 22.34053802]
 [ 14.92217159]
 [ 13.20092964]
 [ 13.41484547]
 [ 16.52145386]
 [ 13.41484547]
 [ 22.95207596]
 [ 22.34053802]
 [ 16.7746582 ]
 [ 15.29451275]
 [ 11.9500103 ]
 [ 16.01550674]
 [ 23.08553505]
 [ 15.63021374]
 [ 11.35398769]]
DEBUG:root:training time = %d0.206552
INFO:root:frame =2337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =2338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000290155410767
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.981601666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =2341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000476121902466
INFO:root:frame =2342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.98157
DEBUG:root: dqn, choose action rondomly, need time 0.000283000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17.23239326]
 [ 13.95855141]
 [ 37.62757874]
 [ 39.68715286]
 [ 14.42866039]
 [ 33.79890442]
 [ 40.26145935]
 [ 13.2260561 ]
 [ 13.17771053]
 [ 14.42866039]
 [ 13.85220623]
 [ 22.38881302]
 [ 14.05243111]
 [ 31.70623398]
 [ 17.48254585]
 [ 27.2287426 ]]
DEBUG:root:training time = %d0.245497
INFO:root:frame =2345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame =2346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00048303604126
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.981538333333
DEBUG:root: dqn, choose action rondomly, need time 0.000339000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =2349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =2350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.981506666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:training error  = [[ 35.43470001]
 [ 14.43561649]
 [ 14.66932297]
 [ 43.39406967]
 [ 13.37218094]
 [ 13.5017786 ]
 [ 33.03530502]
 [ 15.35998631]
 [ 43.05148697]
 [ 13.78442383]
 [ 14.43561649]
 [ 13.72149849]
 [ 13.5017786 ]
 [ 43.46747971]
 [ 13.50912476]
 [ 42.1687088 ]]
DEBUG:root:training time = %d0.218835
INFO:root:frame =2353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =2354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame = 2355 State into memory, numbers recorded 69 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:random_action_porb = 0.981475
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2356current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =2357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =2358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.981443333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 40.89334869]
 [ 36.01501465]
 [ 22.92328262]
 [ 12.37448311]
 [ 13.34663773]
 [ 47.56044388]
 [ 39.45112991]
 [ 29.95455933]
 [ 14.23048306]
 [ 35.24511719]
 [ 29.95455933]
 [ 13.8345499 ]
 [ 22.92328262]
 [ 23.96973228]
 [ 31.90958595]
 [ 35.24511719]]
DEBUG:root:training time = %d0.218649
INFO:root:frame =2361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =2362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame = 2363 State into memory, numbers recorded 70 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:random_action_porb = 0.981411666667
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2364current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root:frame =2365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =2366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.98138
DEBUG:root: dqn, choose action rondomly, need time 0.000175999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 29.10030937]
 [ 14.55034351]
 [ 22.17740822]
 [ 23.22416115]
 [ 13.54127884]
 [ 29.10030937]
 [ 35.63544846]
 [ 13.54127884]
 [ 36.92440796]
 [ 22.6068058 ]
 [ 28.34218788]
 [ 14.26642418]
 [ 29.57520103]
 [ 33.74383926]
 [ 35.21269608]
 [ 33.19133759]]
DEBUG:root:training time = %d0.21553
INFO:root:frame =2369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =2370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000335216522217
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.981348333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000388145446777
INFO:root:frame =2373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00051212310791
INFO:root:frame =2374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.981316666667
DEBUG:root: dqn, choose action rondomly, need time 0.000225
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 44.19816971]
 [ 15.49009037]
 [ 27.57019043]
 [ 15.72404003]
 [ 27.09863663]
 [ 15.72404003]
 [ 15.80655766]
 [ 27.57019043]
 [ 28.465065  ]
 [ 27.09863663]
 [ 14.89848518]
 [ 24.45219231]
 [  7.79121637]
 [ 24.45173836]
 [ 25.51416779]
 [ 16.89636993]]
DEBUG:root:training time = %d0.230748
INFO:root:frame =2377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:frame =2378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000401973724365
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.981285
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =2381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471830368042
INFO:root:frame =2382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000176191329956
INFO:root:random_action_porb = 0.981253333333
DEBUG:root: dqn, choose action rondomly, need time 0.000332999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 56.52728653]
 [ 15.49321365]
 [ 27.61940575]
 [ 15.49321365]
 [ 16.01813316]
 [ 29.23702621]
 [ 26.61611176]
 [ 27.8013382 ]
 [ 41.48178864]
 [ 25.60735893]
 [ 39.77467728]
 [ 30.03988647]
 [ 26.56874275]
 [ 23.77708244]
 [ 54.17612457]
 [ 27.61940575]]
DEBUG:root:training time = %d0.222912
INFO:root:frame =2385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =2386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000492811203003
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.981221666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =2389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449180603027
INFO:root:frame =2390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.98119
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17.97033691]
 [ 15.88485146]
 [ 43.55806732]
 [ 32.55644989]
 [ 16.1460228 ]
 [ 43.55806732]
 [ 25.97093391]
 [ 15.39487076]
 [ 17.08915901]
 [ 36.46907806]
 [ 15.18330383]
 [ 31.12237358]
 [ 16.22472191]
 [ 25.91474342]
 [ 16.1460228 ]
 [ 31.12237358]]
DEBUG:root:training time = %d0.208485
INFO:root:frame =2393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =2394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.981158333333
DEBUG:root: dqn, choose action rondomly, need time 0.000333000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =2397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =2398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 9.91821289062e-05
INFO:root:random_action_porb = 0.981126666667
DEBUG:root: dqn, choose action rondomly, need time 0.000202999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 24.46547318]
 [ 17.10127068]
 [ 15.31146526]
 [ 14.44570637]
 [ 17.85680199]
 [ 15.65839863]
 [ 25.12099648]
 [ 24.73740196]
 [ 16.47602272]
 [ 30.93461609]
 [ 15.38996124]
 [ 25.12099648]
 [ 25.12099648]
 [ 17.7503109 ]
 [ 27.40794754]
 [ 14.44570637]]
DEBUG:root:training time = %d0.195792
INFO:root:frame =2401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =2402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275135040283
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.981095
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =2405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =2406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.981063333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[ 16.11985207]
 [ 20.92424583]
 [ 28.35518646]
 [ 23.58224487]
 [ 16.11985207]
 [ 42.65483475]
 [ 16.75947571]
 [ 16.61001587]
 [ 43.16840363]
 [ 29.71485901]
 [ 42.33683014]
 [ 31.46919632]
 [ 16.46902466]
 [ 41.96543121]
 [ 28.50252533]
 [ 43.53541183]]
DEBUG:root:training time = %d0.227041
INFO:root:frame =2409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =2410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000334978103638
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.981031666667
DEBUG:root: dqn, choose action rondomly, need time 0.000177000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:frame =2413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =2414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000258922576904
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.981
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:training error  = [[ 23.55409622]
 [ 52.01896667]
 [ 37.85818863]
 [ 39.69186401]
 [ 53.91396713]
 [ 54.05265045]
 [ 39.23052597]
 [ 39.97104263]
 [ 15.70619488]
 [ 17.98256302]
 [ 23.16419601]
 [ 23.16419601]
 [ 37.9197998 ]
 [ 38.25325012]
 [ 16.77009773]
 [ 52.90677643]]
DEBUG:root:training time = %d0.220643
INFO:root:frame =2417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =2418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279188156128
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.980968333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =2421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049901008606
INFO:root:frame =2422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462770462036
INFO:root:frame = 2423 State into memory, numbers recorded 71 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000540018081665
INFO:root:random_action_porb = 0.980936666667
DEBUG:root: dqn, choose action rondomly, need time 0.000344999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2424current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 30.04264641]
 [ 18.2443409 ]
 [ 34.76438904]
 [ 30.63204193]
 [ 30.38535118]
 [ 16.51295853]
 [ 45.74158096]
 [ 43.92813873]
 [ 17.70322037]
 [ 32.36197662]
 [ 16.91858101]
 [ 29.20947647]
 [ 32.97175217]
 [ 59.43173218]
 [ 29.20947647]
 [ 33.60791779]]
DEBUG:root:training time = %d0.231898
INFO:root:frame =2425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:frame =2426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444173812866
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.980905
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =2429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000419855117798
INFO:root:frame =2430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:random_action_porb = 0.980873333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335216522217
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 44.04725266]
 [ 24.24731445]
 [ 26.63729095]
 [ 28.1811676 ]
 [ 27.19284439]
 [ 44.39701843]
 [ 19.6140213 ]
 [ 22.14544296]
 [ 44.39701843]
 [ 28.22338676]
 [ 22.21349525]
 [ 19.91643906]
 [ 19.98643684]
 [ 18.40908241]
 [ 30.57439041]
 [ 44.39701843]]
DEBUG:root:training time = %d0.21883
INFO:root:frame =2433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =2434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274896621704
DEBUG:root: save sample needs time = 0.000121831893921
INFO:root:random_action_porb = 0.980841666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root:frame =2437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000502824783325
INFO:root:frame =2438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.98081
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:training error  = [[ 19.80539322]
 [ 45.55879211]
 [ 49.19180679]
 [ 43.82686234]
 [ 22.50100708]
 [ 20.27610016]
 [ 21.75205612]
 [ 51.86698532]
 [ 19.67360306]
 [ 21.9895401 ]
 [ 45.86447144]
 [ 18.38656807]
 [ 44.1339798 ]
 [ 19.67360306]
 [ 47.68122101]
 [ 45.86447144]]
DEBUG:root:training time = %d0.235667
INFO:root:frame =2441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root:frame =2442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481843948364
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.980778333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =2445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =2446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.980746666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 46.14204025]
 [ 39.37966537]
 [ 41.59695053]
 [ 63.61873245]
 [ 21.89790344]
 [ 21.89790344]
 [ 19.11119652]
 [ 18.55569649]
 [ 21.15591431]
 [ 61.43432236]
 [ 42.9146347 ]
 [ 41.1284523 ]
 [ 62.33181381]
 [ 46.70761871]
 [ 48.21945572]
 [ 46.17666626]]
DEBUG:root:training time = %d0.209844
INFO:root:frame =2449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =2450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424861907959
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.980715
DEBUG:root: dqn, choose action rondomly, need time 0.000283000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =2453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =2454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.980683333333
DEBUG:root: dqn, choose action rondomly, need time 0.000250999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 61.19786453]
 [ 19.6923542 ]
 [ 40.5850029 ]
 [ 42.31439209]
 [ 62.58107376]
 [ 37.03928375]
 [ 19.39803314]
 [ 62.58107376]
 [ 43.27142715]
 [ 19.55432892]
 [ 73.8002243 ]
 [ 41.22146988]
 [ 19.43985558]
 [ 20.73538017]
 [ 39.24945068]
 [ 43.41176224]]
DEBUG:root:training time = %d0.212751
INFO:root:frame =2457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270843505859
INFO:root:frame =2458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000261068344116
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.980651666667
DEBUG:root: dqn, choose action rondomly, need time 0.000279999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =2461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame =2462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame = 2463 State into memory, numbers recorded 72 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000545024871826
INFO:root:random_action_porb = 0.98062
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2464current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 26.67282104]
 [ 52.69145966]
 [ 52.69145966]
 [ 25.93727303]
 [ 38.6973381 ]
 [ 51.63493347]
 [ 49.9152298 ]
 [ 45.29735947]
 [ 21.4797802 ]
 [ 26.68212128]
 [ 43.33900452]
 [ 37.33005524]
 [ 25.31063652]
 [ 45.29735947]
 [ 44.78502655]
 [ 20.38804436]]
DEBUG:root:training time = %d0.211273
INFO:root:frame =2465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =2466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000246047973633
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.980588333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =2469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =2470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.980556666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 28.63489342]
 [ 16.65064812]
 [ 61.51148987]
 [ 63.90348053]
 [ 37.80112457]
 [ 37.0139389 ]
 [ 36.20950317]
 [ 37.26678085]
 [ 63.90348053]
 [ 21.30820656]
 [ 45.21165085]
 [ 37.26678085]
 [ 31.87063789]
 [ 62.31699753]
 [ 20.37034035]
 [ 39.5451088 ]]
DEBUG:root:training time = %d0.241502
INFO:root:frame =2473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =2474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.980525
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =2477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =2478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456809997559
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.980493333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 29.08467102]
 [ 61.96108246]
 [ 58.5738945 ]
 [ 30.34087372]
 [ 30.34087372]
 [ 75.98281097]
 [ 30.34087372]
 [ 58.84057617]
 [ 61.96108246]
 [ 59.31027985]
 [ 61.06949234]
 [ 58.72557449]
 [ 45.44690704]
 [ 57.8455925 ]
 [ 34.0302124 ]
 [ 59.31027985]]
DEBUG:root:training time = %d0.221566
INFO:root:frame =2481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000331163406372
INFO:root:frame =2482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.980461666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =2485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame =2486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.98043
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 48.15251541]
 [ 51.47081757]
 [ 29.28151512]
 [ 45.27620697]
 [ 65.23527527]
 [ 48.68445587]
 [ 49.70458603]
 [ 49.55677795]
 [ 72.86217499]
 [ 47.07290268]
 [ 51.94580841]
 [ 47.52393723]
 [ 47.59970474]
 [ 47.61497116]
 [ 42.30417252]
 [ 57.76426697]]
DEBUG:root:training time = %d0.231168
INFO:root:frame =2489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000260829925537
INFO:root:frame =2490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000285863876343
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.980398333333
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =2493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =2494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.980366666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 36.90132523]
 [ 22.8120079 ]
 [ 59.98057556]
 [ 36.05596161]
 [ 24.504282  ]
 [ 22.85801697]
 [ 37.57976532]
 [ 67.52465057]
 [ 50.66326523]
 [ 38.29072571]
 [ 22.8120079 ]
 [ 22.46888161]
 [ 37.67045975]
 [ 32.38203049]
 [ 23.0911808 ]
 [ 37.72517395]]
DEBUG:root:training time = %d0.198392
INFO:root:frame =2497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =2498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259876251221
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.980335
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =2501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =2502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.980303333333
DEBUG:root: dqn, choose action rondomly, need time 0.000270999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000359058380127
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 30.6349144 ]
 [ 25.55071449]
 [ 14.87475967]
 [ 24.41334915]
 [ 53.37841415]
 [ 23.32707596]
 [ 32.43945312]
 [ 25.21522903]
 [ 61.77936935]
 [ 23.23225021]
 [ 24.11922455]
 [ 23.23225021]
 [ 61.3985672 ]
 [ 61.77936935]
 [ 25.55071449]
 [ 24.65899277]]
DEBUG:root:training time = %d0.234209
INFO:root:frame =2505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =2506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025486946106
DEBUG:root: save sample needs time = 0.000318765640259
INFO:root:random_action_porb = 0.980271666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =2509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame =2510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.98024
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 31.85651207]
 [ 57.17940521]
 [ 40.88661575]
 [ 57.34429169]
 [ 47.39170074]
 [ 32.74486542]
 [ 57.6801033 ]
 [ 34.21364594]
 [ 35.52531815]
 [ 46.1342659 ]
 [ 41.42058563]
 [ 33.78143311]
 [ 48.71320343]
 [ 41.54293823]
 [ 35.1806488 ]
 [ 24.01599693]]
DEBUG:root:training time = %d0.223164
INFO:root:frame =2513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268220901489
INFO:root:frame =2514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000305891036987
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.980208333333
DEBUG:root: dqn, choose action rondomly, need time 0.000271999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =2517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =2518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480890274048
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.980176666667
INFO:root:dqn select action Tensor("ArgMax_4:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013985
INFO:root:action choosen by dqn [3]
INFO:root:frame =2520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 24.73899651]
 [ 25.02136612]
 [ 24.50994873]
 [ 56.30654907]
 [ 26.65729904]
 [ 48.95952606]
 [ 48.41270447]
 [ 40.42263412]
 [ 33.34544373]
 [ 41.20873642]
 [ 49.78896332]
 [ 24.73899651]
 [ 25.59994698]
 [ 40.42263412]
 [ 25.08376503]
 [ 56.1762085 ]]
DEBUG:root:training time = %d0.200588
INFO:root:frame =2521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =2522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.980145
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =2525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =2526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:random_action_porb = 0.980113333333
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 45.10726547]
 [ 26.23161888]
 [ 25.9961338 ]
 [ 51.16115189]
 [ 38.83747101]
 [ 63.28193283]
 [ 47.33110809]
 [ 46.21182251]
 [ 51.16115189]
 [ 35.41917038]
 [ 46.21182251]
 [ 26.44485474]
 [ 59.50268936]
 [ 60.76687241]
 [ 64.33772278]
 [ 26.15594482]]
DEBUG:root:training time = %d0.237211
INFO:root:frame =2529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =2530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277996063232
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:random_action_porb = 0.980081666667
DEBUG:root: dqn, choose action rondomly, need time 0.000188000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root:frame =2533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =2534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame = 2535 State into memory, numbers recorded 73 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000535011291504
INFO:root:random_action_porb = 0.98005
DEBUG:root: dqn, choose action rondomly, need time 0.000191999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2536current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000189781188965
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 50.92175674]
 [ 39.6077919 ]
 [ 53.44487762]
 [ 70.84922791]
 [ 53.05960846]
 [ 27.97402   ]
 [ 37.83959961]
 [ 38.43788147]
 [ 39.7375412 ]
 [ 28.07321358]
 [ 16.98196793]
 [ 74.26144409]
 [ 76.40116882]
 [ 27.12112045]
 [ 37.69996643]
 [ 27.37712097]]
DEBUG:root:training time = %d0.21173
INFO:root:frame =2537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =2538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame = 2539 State into memory, numbers recorded 74 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000539064407349
INFO:root:random_action_porb = 0.980018333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2540current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =2541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =2542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488042831421
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.979986666667
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312805175781
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 45.89775085]
 [ 28.41339302]
 [ 44.29855347]
 [ 45.89775085]
 [ 31.28414917]
 [ 43.99015427]
 [ 53.29383087]
 [ 43.99015427]
 [ 47.56223297]
 [ 29.96073914]
 [ 78.50582886]
 [ 78.51813507]
 [ 44.26606369]
 [ 92.54592133]
 [ 29.95706558]
 [ 38.7714119 ]]
DEBUG:root:training time = %d0.214291
INFO:root:frame =2545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =2546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000365018844604
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:random_action_porb = 0.979955
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =2549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =2550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.979923333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 84.83265686]
 [ 36.49045944]
 [ 35.27066803]
 [ 30.16119003]
 [ 47.4130249 ]
 [ 30.16119003]
 [ 48.2498703 ]
 [ 35.27066803]
 [ 70.54579926]
 [ 66.34072113]
 [ 46.15375519]
 [ 47.8016243 ]
 [ 49.58890152]
 [ 62.71392441]
 [ 28.03668213]
 [ 67.26259613]]
DEBUG:root:training time = %d0.225564
INFO:root:frame =2553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =2554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277996063232
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.979891666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =2557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =2558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.97986
DEBUG:root: dqn, choose action rondomly, need time 0.000340999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 28.32245064]
 [ 29.00293159]
 [ 28.97237015]
 [ 40.26242828]
 [ 56.16397476]
 [ 30.09602928]
 [ 30.40242767]
 [ 30.97307396]
 [ 84.65440369]
 [ 56.38959122]
 [ 59.64142227]
 [ 41.07826996]
 [ 28.58184433]
 [ 30.09602928]
 [ 29.64419937]
 [ 85.74354553]]
DEBUG:root:training time = %d0.228861
INFO:root:frame =2561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =2562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000251054763794
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.979828333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =2565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =2566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.979796666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336170196533
INFO:root:training error  = [[ 52.69633102]
 [ 70.9468689 ]
 [ 82.76040649]
 [ 71.03956604]
 [ 71.56216431]
 [ 72.59307098]
 [ 30.30869102]
 [ 80.46721649]
 [ 47.21884918]
 [ 72.86986542]
 [ 70.82713318]
 [ 53.82415009]
 [ 68.8576355 ]
 [ 29.98956108]
 [ 73.13308716]
 [ 71.60076141]]
DEBUG:root:training time = %d0.229297
INFO:root:frame =2569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =2570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427007675171
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:random_action_porb = 0.979765
DEBUG:root: dqn, choose action rondomly, need time 0.000324000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =2573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =2574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.979733333333
DEBUG:root: dqn, choose action rondomly, need time 0.000278999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000359058380127
INFO:root:training error  = [[ 54.77752686]
 [ 53.33572388]
 [ 61.9184494 ]
 [ 35.36316299]
 [ 49.31967163]
 [ 64.06056213]
 [ 37.23297501]
 [ 63.71844864]
 [ 62.78777695]
 [ 60.96782303]
 [ 63.71844864]
 [ 49.44534302]
 [ 29.83750534]
 [ 51.29810715]
 [ 62.78777695]
 [ 31.75256157]]
DEBUG:root:training time = %d0.204763
INFO:root:frame =2577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =2578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000515937805176
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.979701666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =2581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =2582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:random_action_porb = 0.97967
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 49.9848938 ]
 [ 46.68666077]
 [ 76.67429352]
 [ 45.9601059 ]
 [ 33.43467331]
 [ 64.14179993]
 [ 59.94040298]
 [ 47.05343246]
 [ 33.05065536]
 [ 30.42388725]
 [ 46.04600525]
 [ 45.67988968]
 [ 45.8495903 ]
 [ 59.82952499]
 [ 30.3626461 ]
 [ 95.48608398]]
DEBUG:root:training time = %d0.222207
INFO:root:frame =2585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:frame =2586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame = 2587 State into memory, numbers recorded 75 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000275850296021
INFO:root:random_action_porb = 0.979638333333
DEBUG:root: dqn, choose action rondomly, need time 0.000168000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2588current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:frame =2589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =2590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00023889541626
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.979606666667
DEBUG:root: dqn, choose action rondomly, need time 0.000175999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 58.19706726]
 [ 54.42551422]
 [ 45.0223465 ]
 [ 33.25395584]
 [ 73.67339325]
 [ 41.77852249]
 [ 34.12213516]
 [ 40.74623489]
 [ 57.15483093]
 [ 79.36029816]
 [ 33.25395584]
 [ 32.26318359]
 [ 56.83665848]
 [ 42.26150513]
 [ 94.69152832]
 [ 46.99075699]]
DEBUG:root:training time = %d0.189937
INFO:root:frame =2593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287771224976
INFO:root:frame =2594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.979575
DEBUG:root: dqn, choose action rondomly, need time 0.000319999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =2597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =2598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.979543333333
DEBUG:root: dqn, choose action rondomly, need time 0.000357999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 77.96300507]
 [ 72.27775574]
 [ 36.17663956]
 [ 74.32260132]
 [ 34.73992157]
 [ 45.22816849]
 [ 72.27775574]
 [ 33.62826538]
 [ 35.0944519 ]
 [ 33.20698547]
 [ 62.07367706]
 [ 36.17663956]
 [ 74.84562683]
 [ 33.20698547]
 [ 62.07367706]
 [ 34.92399597]]
DEBUG:root:training time = %d0.191933
INFO:root:frame =2601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =2602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277996063232
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.979511666667
DEBUG:root: dqn, choose action rondomly, need time 0.000341999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331163406372
INFO:root:frame =2605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =2606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.97948
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[ 45.92318344]
 [ 65.92738342]
 [ 63.50815201]
 [ 52.50753403]
 [ 49.76355743]
 [ 67.3612442 ]
 [ 51.08826828]
 [ 60.18626022]
 [ 34.66270828]
 [ 53.89884567]
 [ 51.08826828]
 [ 55.16851807]
 [ 52.10748672]
 [ 65.92738342]
 [ 36.09592056]
 [ 62.52640533]]
DEBUG:root:training time = %d0.236183
INFO:root:frame =2609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265836715698
INFO:root:frame =2610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
DEBUG:root: save sample needs time = 0.000121116638184
INFO:root:random_action_porb = 0.979448333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000270843505859
INFO:root:frame =2613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =2614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.979416666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 43.09134293]
 [ 37.73079681]
 [ 49.96558762]
 [ 50.76834488]
 [ 35.52304459]
 [ 38.82777405]
 [ 43.74649048]
 [ 41.67305756]
 [ 74.49436951]
 [ 57.65820312]
 [ 41.67305756]
 [ 47.31105804]
 [ 93.57453918]
 [ 62.0146637 ]
 [ 72.20980072]
 [ 35.52304459]]
DEBUG:root:training time = %d0.233003
INFO:root:frame =2617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root:frame =2618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame = 2619 State into memory, numbers recorded 76 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000541925430298
INFO:root:random_action_porb = 0.979385
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2620current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =2621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =2622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000179052352905
INFO:root:random_action_porb = 0.979353333333
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  73.89398193]
 [  75.35975647]
 [  37.38032532]
 [ 106.34230804]
 [  47.71283722]
 [ 106.84784698]
 [  36.74521255]
 [  63.5460968 ]
 [  44.72153473]
 [  47.57759857]
 [  25.30081177]
 [  45.70412827]
 [  35.22555542]
 [  47.0641098 ]
 [  36.89974976]
 [  38.58730698]]
DEBUG:root:training time = %d0.200707
INFO:root:frame =2625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =2626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.979321666667
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =2629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame =2630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00053596496582
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.97929
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 40.2702713 ]
 [ 80.96923828]
 [ 37.86034775]
 [ 39.87376404]
 [ 94.9237442 ]
 [ 83.04035187]
 [ 98.04069519]
 [ 36.0306778 ]
 [ 37.88485336]
 [ 74.47737885]
 [ 44.47991943]
 [ 82.25188446]
 [ 77.89040375]
 [ 44.47991943]
 [ 36.0306778 ]
 [ 40.6394577 ]]
DEBUG:root:training time = %d0.209093
INFO:root:frame =2633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =2634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.979258333333
DEBUG:root: dqn, choose action rondomly, need time 0.000337999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =2637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =2638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.979226666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  63.30961227]
 [  48.22369385]
 [  65.99665833]
 [  82.68019104]
 [  41.15213776]
 [  83.16136932]
 [  60.70004272]
 [  46.40464783]
 [  83.2201004 ]
 [  41.15213776]
 [  81.94232941]
 [ 104.38964081]
 [  46.88841248]
 [  38.59309006]
 [ 104.38964081]
 [  73.51133728]]
DEBUG:root:training time = %d0.219086
INFO:root:frame =2641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000322818756104
INFO:root:frame =2642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000365018844604
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.979195
DEBUG:root: dqn, choose action rondomly, need time 0.000180999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:frame =2645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =2646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308036804199
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.979163333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[  77.69821167]
 [  73.20212555]
 [ 127.07990265]
 [  57.0416069 ]
 [  54.9835968 ]
 [  57.01613998]
 [  57.8699646 ]
 [  73.20212555]
 [  55.81094742]
 [  77.69821167]
 [  82.72335052]
 [  72.85618591]
 [ 126.55477905]
 [  82.72335052]
 [  74.77105713]
 [ 123.56183624]]
DEBUG:root:training time = %d0.226464
INFO:root:frame =2649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =2650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000302076339722
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.979131666667
DEBUG:root: dqn, choose action rondomly, need time 0.000349
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =2653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =2654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000285863876343
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.9791
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000292778015137
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 112.31420135]
 [  55.433815  ]
 [  57.32499695]
 [  40.56536865]
 [  40.96011734]
 [  64.24217224]
 [  62.88684082]
 [  71.03313446]
 [ 110.73213959]
 [  63.22441101]
 [  51.19247818]
 [ 114.74019623]
 [  43.78959274]
 [  51.7064476 ]
 [  55.00170135]
 [  47.74751663]]
DEBUG:root:training time = %d0.216108
INFO:root:frame =2657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =2658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000304937362671
DEBUG:root: save sample needs time = 0.000126838684082
INFO:root:random_action_porb = 0.979068333333
DEBUG:root: dqn, choose action rondomly, need time 0.000196000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185012817383
INFO:root:frame =2661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000476121902466
INFO:root:frame =2662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:random_action_porb = 0.979036666667
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330209732056
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  43.62858963]
 [  94.92121887]
 [  45.61813354]
 [  43.62858963]
 [  81.37892151]
 [ 105.86386871]
 [  44.54079819]
 [  42.11254501]
 [  76.42343903]
 [  42.00320053]
 [  95.27685547]
 [  43.1583786 ]
 [  41.85933685]
 [  47.59043884]
 [  96.79489899]
 [  31.5189476 ]]
DEBUG:root:training time = %d0.217392
INFO:root:frame =2665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =2666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000254154205322
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.979005
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =2669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =2670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427007675171
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.978973333333
DEBUG:root: dqn, choose action rondomly, need time 0.000324999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  42.08145905]
 [  68.28373718]
 [  97.84574127]
 [  66.33301544]
 [  93.90738678]
 [ 104.15981293]
 [ 101.96235657]
 [  53.56497192]
 [  89.92124176]
 [  42.08145905]
 [  98.9701004 ]
 [  44.20993805]
 [  92.25579834]
 [  31.34827805]
 [  41.10184097]
 [  53.56497192]]
DEBUG:root:training time = %d0.217184
INFO:root:frame =2673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:frame =2674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271797180176
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.978941666667
DEBUG:root: dqn, choose action rondomly, need time 0.000340000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000427961349487
INFO:root:frame =2677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =2678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000506162643433
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.97891
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:training error  = [[  82.81316376]
 [  63.56519318]
 [  97.76290131]
 [  62.8676033 ]
 [  76.61778259]
 [  47.04390717]
 [  80.79139709]
 [  55.86339951]
 [  74.56207275]
 [  55.86339951]
 [  74.89263153]
 [  67.82679749]
 [ 107.00610352]
 [  61.41578674]
 [  44.75592804]
 [  62.97024155]]
DEBUG:root:training time = %d0.21111
INFO:root:frame =2681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =2682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000287055969238
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.978878333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:frame =2685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =2686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000511169433594
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.978846666667
DEBUG:root: dqn, choose action rondomly, need time 0.000219000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000402927398682
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  63.87920761]
 [  91.29701233]
 [  95.68538666]
 [  90.69150543]
 [  88.60532379]
 [  83.50054169]
 [  88.60532379]
 [  93.39911652]
 [  64.31288147]
 [ 107.82592773]
 [  60.15690613]
 [  89.50645447]
 [  77.28061676]
 [  95.68538666]
 [  94.28156281]
 [  55.95969391]]
DEBUG:root:training time = %d0.218617
INFO:root:frame =2689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:frame =2690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000361919403076
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.978815
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root:frame =2693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =2694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.978783333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  84.36277771]
 [  56.80065918]
 [  56.17266464]
 [  52.42695999]
 [  47.65288162]
 [  56.80065918]
 [ 132.9672699 ]
 [  83.85955048]
 [  68.98329163]
 [  69.95851135]
 [  56.80065918]
 [  87.08110809]
 [  56.108181  ]
 [  84.36277771]
 [ 129.46839905]
 [  69.09892273]]
DEBUG:root:training time = %d0.222428
INFO:root:frame =2697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =2698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000370025634766
INFO:root:frame = 2699 State into memory, numbers recorded 77 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000545978546143
INFO:root:random_action_porb = 0.978751666667
DEBUG:root: dqn, choose action rondomly, need time 0.000323999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2700current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =2701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433206558228
INFO:root:frame =2702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480175018311
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.97872
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  48.69350433]
 [  68.44799805]
 [ 141.59823608]
 [  63.88628006]
 [ 100.10348511]
 [ 141.59823608]
 [  52.82767105]
 [  48.48588181]
 [  52.82767105]
 [  75.15590668]
 [ 141.93760681]
 [ 121.0302124 ]
 [  94.51194763]
 [ 138.55563354]
 [  48.69350433]
 [  68.19651031]]
DEBUG:root:training time = %d0.222094
INFO:root:frame =2705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =2706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000346899032593
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.978688333333
DEBUG:root: dqn, choose action rondomly, need time 0.000336999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =2709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =2710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000467777252197
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.978656666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  53.8798027 ]
 [  90.86130524]
 [ 100.22931671]
 [  53.36358643]
 [  48.31603241]
 [  58.4666214 ]
 [  54.20914841]
 [  90.6676712 ]
 [ 119.36969757]
 [ 106.62825012]
 [  59.00361633]
 [ 106.90479279]
 [  50.60875702]
 [  90.6676712 ]
 [  37.8423233 ]
 [  52.04582214]]
DEBUG:root:training time = %d0.217549
INFO:root:frame =2713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =2714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:random_action_porb = 0.978625
DEBUG:root: dqn, choose action rondomly, need time 0.000396000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =2717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =2718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 9.51290130615e-05
INFO:root:random_action_porb = 0.978593333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:training error  = [[ 116.35942078]
 [ 134.17668152]
 [ 102.22106171]
 [  78.08646393]
 [ 123.25180817]
 [  97.90990448]
 [  80.69377136]
 [  79.05841064]
 [ 116.35942078]
 [ 143.64828491]
 [ 101.95619202]
 [  80.96457672]
 [ 101.95619202]
 [  51.37605667]
 [  94.79727173]
 [  79.05841064]]
DEBUG:root:training time = %d0.215925
INFO:root:frame =2721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:frame =2722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476837158203
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.978561666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =2725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =2726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:random_action_porb = 0.97853
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 109.19287109]
 [  54.10337067]
 [  55.75806808]
 [  93.57025909]
 [  55.39973831]
 [  54.94140244]
 [  74.764328  ]
 [  55.39973831]
 [  53.64887238]
 [ 105.04936218]
 [ 124.32168579]
 [ 129.00315857]
 [  88.4936142 ]
 [  87.98735046]
 [ 113.462677  ]
 [  93.23167419]]
DEBUG:root:training time = %d0.242295
INFO:root:frame =2729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =2730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.978498333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =2733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =2734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.978466666667
DEBUG:root: dqn, choose action rondomly, need time 0.000737999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:training error  = [[  80.21747589]
 [  81.50285339]
 [  79.57671356]
 [ 123.63596344]
 [ 125.98260498]
 [  86.19372559]
 [  52.96572876]
 [ 123.63596344]
 [  73.91418457]
 [  79.57671356]
 [  56.54449844]
 [  85.25367737]
 [  79.2077179 ]
 [ 124.38430023]
 [  80.5329361 ]
 [  74.29695129]]
DEBUG:root:training time = %d0.214593
INFO:root:frame =2737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =2738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.978435
DEBUG:root: dqn, choose action rondomly, need time 0.000603999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =2741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =2742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.978403333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 137.44392395]
 [  67.69817352]
 [  60.98414612]
 [  57.41248322]
 [ 110.36442566]
 [ 109.22986603]
 [ 119.11043549]
 [  68.87687683]
 [ 103.3094101 ]
 [  99.76789856]
 [  97.7903595 ]
 [ 116.16561127]
 [ 113.72711182]
 [  65.04229736]
 [  67.69817352]
 [  79.11594391]]
DEBUG:root:training time = %d0.20506
INFO:root:frame =2745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000369071960449
INFO:root:frame =2746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.978371666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =2749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =2750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000413179397583
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.97834
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  87.29768372]
 [  80.37991333]
 [ 106.03380585]
 [ 133.35534668]
 [ 106.38322449]
 [  64.07692719]
 [  47.46872711]
 [  65.68502045]
 [  60.36514282]
 [  61.65613937]
 [ 113.82411194]
 [ 173.41670227]
 [ 108.37452698]
 [  77.03105164]
 [  63.14787674]
 [  49.44491577]]
DEBUG:root:training time = %d0.212509
INFO:root:frame =2753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =2754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000415086746216
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.978308333333
DEBUG:root: dqn, choose action rondomly, need time 0.000321
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =2757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000451803207397
INFO:root:frame =2758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.978276666667
DEBUG:root: dqn, choose action rondomly, need time 0.000321000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 170.19029236]
 [ 124.36388397]
 [ 169.75700378]
 [ 108.13352966]
 [ 133.75422668]
 [ 164.21685791]
 [ 171.54180908]
 [  80.88523102]
 [ 166.42480469]
 [ 164.21685791]
 [ 104.12306213]
 [  62.35012817]
 [ 100.78338623]
 [  60.21609497]
 [  58.38871002]
 [ 128.54084778]]
DEBUG:root:training time = %d0.239808
INFO:root:frame =2761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =2762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255823135376
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.978245
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =2765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =2766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.978213333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 152.51210022]
 [ 147.47073364]
 [  62.17169571]
 [ 114.06941223]
 [  98.38335419]
 [ 159.90423584]
 [ 171.44989014]
 [ 136.10945129]
 [ 149.01422119]
 [ 113.96448517]
 [  91.71125031]
 [  92.62682343]
 [  98.83641052]
 [ 167.54792786]
 [  62.57177734]
 [  98.38335419]]
DEBUG:root:training time = %d0.206705
INFO:root:frame =2769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =2770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.978181666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =2773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454187393188
INFO:root:frame =2774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476121902466
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.97815
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 127.38954163]
 [ 130.36582947]
 [  66.36421204]
 [ 128.42634583]
 [  65.41891479]
 [ 130.94068909]
 [ 124.20874023]
 [  64.66161346]
 [  81.72451019]
 [ 121.01544189]
 [ 144.64195251]
 [  62.11636353]
 [ 138.25260925]
 [ 122.8635025 ]
 [ 108.74273682]
 [ 125.70872498]]
DEBUG:root:training time = %d0.221344
INFO:root:frame =2777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =2778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame = 2779 State into memory, numbers recorded 78 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000600099563599
INFO:root:random_action_porb = 0.978118333333
DEBUG:root: dqn, choose action rondomly, need time 0.000307999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2780current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =2781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame =2782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.978086666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 145.18713379]
 [ 113.3674469 ]
 [ 163.85374451]
 [ 113.3674469 ]
 [ 120.33557129]
 [ 140.5098114 ]
 [ 109.62987518]
 [ 109.4749527 ]
 [ 106.76726532]
 [ 106.11143494]
 [ 113.82574463]
 [ 131.38911438]
 [ 115.94205475]
 [ 105.48552704]
 [ 106.76726532]
 [ 140.5098114 ]]
DEBUG:root:training time = %d0.213803
INFO:root:frame =2785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =2786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.978055
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =2789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =2790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000419139862061
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:random_action_porb = 0.978023333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:training error  = [[  89.11883545]
 [  74.43405914]
 [  81.18742371]
 [  72.0605011 ]
 [  75.99318695]
 [  74.49620819]
 [  92.14693451]
 [  74.43405914]
 [  94.74409485]
 [  90.65605164]
 [  92.70937347]
 [  75.02658844]
 [  73.37965393]
 [  72.44467926]
 [ 118.83348846]
 [  94.17521667]]
DEBUG:root:training time = %d0.221141
INFO:root:frame =2793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =2794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000278949737549
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.977991666667
DEBUG:root: dqn, choose action rondomly, need time 0.000165000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:frame =2797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =2798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:random_action_porb = 0.97796
DEBUG:root: dqn, choose action rondomly, need time 0.000324999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 146.02009583]
 [ 103.95933533]
 [ 120.08796692]
 [ 147.70802307]
 [ 114.09809875]
 [  70.55118561]
 [ 103.87782288]
 [  74.37693787]
 [ 119.08512115]
 [  99.57899475]
 [  72.25933838]
 [ 103.87782288]
 [ 106.87135315]
 [ 101.97961426]
 [ 101.69166565]
 [ 113.52672577]]
DEBUG:root:training time = %d0.207566
INFO:root:frame =2801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =2802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.977928333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =2805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =2806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.977896666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  96.18247223]
 [ 104.49209595]
 [ 109.14631653]
 [ 102.63678741]
 [ 160.44612122]
 [ 100.734375  ]
 [  90.24246216]
 [ 154.15631104]
 [ 152.14749146]
 [ 106.65598297]
 [ 106.65598297]
 [  92.13111877]
 [  95.0868988 ]
 [  96.5983429 ]
 [  94.16099548]
 [ 106.53152466]]
DEBUG:root:training time = %d0.240396
INFO:root:frame =2809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029182434082
INFO:root:frame =2810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000282049179077
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.977865
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =2813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =2814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.977833333333
DEBUG:root: dqn, choose action rondomly, need time 0.000169999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:training error  = [[ 147.77478027]
 [ 154.08357239]
 [ 157.89578247]
 [ 132.91729736]
 [  81.65914154]
 [ 157.30731201]
 [  81.65914154]
 [ 133.68717957]
 [ 153.50830078]
 [  85.8585968 ]
 [ 152.64743042]
 [  75.18024445]
 [  98.50901794]
 [ 152.87487793]
 [ 155.63529968]
 [ 100.28951263]]
DEBUG:root:training time = %d0.214439
INFO:root:frame =2817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =2818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.977801666667
DEBUG:root: dqn, choose action rondomly, need time 0.000317000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =2821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame =2822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.97777
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  79.36206055]
 [ 128.97265625]
 [ 119.75511169]
 [ 130.87156677]
 [ 152.99261475]
 [ 150.48561096]
 [  88.30452728]
 [  80.82623291]
 [  83.2770462 ]
 [ 195.63700867]
 [ 116.19817352]
 [ 171.60415649]
 [ 146.21339417]
 [  86.50311279]
 [  85.72093964]
 [  80.14014435]]
DEBUG:root:training time = %d0.225304
INFO:root:frame =2825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =2826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.977738333333
DEBUG:root: dqn, choose action rondomly, need time 0.000172000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root:frame =2829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =2830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame = 2831 State into memory, numbers recorded 79 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000547170639038
INFO:root:random_action_porb = 0.977706666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2832current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000353097915649
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  82.82094574]
 [ 213.635849  ]
 [  81.68534088]
 [ 142.75064087]
 [ 111.66796875]
 [  82.82094574]
 [ 117.74613953]
 [ 111.66796875]
 [ 109.1370697 ]
 [ 114.71437836]
 [ 102.16799927]
 [  80.51951599]
 [ 216.75840759]
 [  83.5630188 ]
 [ 136.47106934]
 [  63.41200256]]
DEBUG:root:training time = %d0.2364
INFO:root:frame =2833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =2834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.977675
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000341892242432
INFO:root:frame =2837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =2838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.977643333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  83.42777252]
 [ 117.38381195]
 [ 117.38381195]
 [ 127.20360565]
 [  83.09584045]
 [  83.70814514]
 [  83.70814514]
 [ 145.52561951]
 [  83.09584045]
 [ 117.38381195]
 [ 113.29922485]
 [ 191.72589111]
 [ 123.35007477]
 [ 185.34011841]
 [ 136.0606842 ]
 [ 191.72589111]]
DEBUG:root:training time = %d0.221621
INFO:root:frame =2841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00036883354187
INFO:root:frame =2842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.977611666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =2845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =2846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00048303604126
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.97758
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  96.02959442]
 [ 135.28646851]
 [  99.80691528]
 [ 130.93406677]
 [ 101.92321777]
 [ 167.61587524]
 [ 138.18551636]
 [  96.11603546]
 [ 167.48789978]
 [  84.23249054]
 [ 161.32403564]
 [ 152.44389343]
 [  88.01397705]
 [  96.02959442]
 [  83.94900513]
 [  93.74214172]]
DEBUG:root:training time = %d0.239394
INFO:root:frame =2849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =2850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.977548333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =2853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =2854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame = 2855 State into memory, numbers recorded 80 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000543117523193
INFO:root:random_action_porb = 0.977516666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2856current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 142.62414551]
 [ 130.53034973]
 [ 179.03718567]
 [ 113.90911102]
 [ 177.93717957]
 [ 129.64416504]
 [ 173.44403076]
 [ 139.52145386]
 [  87.2794342 ]
 [ 135.53257751]
 [ 140.90077209]
 [ 157.97401428]
 [ 132.42483521]
 [ 155.61663818]
 [  90.74120331]
 [ 135.53257751]]
DEBUG:root:training time = %d0.20855
INFO:root:frame =2857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =2858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.977485
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =2861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000503063201904
INFO:root:frame =2862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.977453333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:training error  = [[ 150.79350281]
 [ 139.54380798]
 [  95.1753006 ]
 [ 143.23234558]
 [ 105.14572144]
 [  95.10951996]
 [ 131.00601196]
 [ 145.24302673]
 [  95.10951996]
 [ 152.32673645]
 [  91.80947113]
 [ 133.6804657 ]
 [  90.62060547]
 [ 141.17584229]
 [  94.66777039]
 [ 130.34178162]]
DEBUG:root:training time = %d0.210373
INFO:root:frame =2865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:frame =2866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:random_action_porb = 0.977421666667
DEBUG:root: dqn, choose action rondomly, need time 0.000355999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =2869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000482082366943
INFO:root:frame =2870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.97739
DEBUG:root: dqn, choose action rondomly, need time 0.000324999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:training error  = [[  94.42889404]
 [ 142.76013184]
 [ 151.50523376]
 [ 139.69309998]
 [ 131.83270264]
 [ 108.33196259]
 [ 224.07078552]
 [  96.10137939]
 [ 112.89289856]
 [ 224.10414124]
 [ 135.85215759]
 [ 153.3616333 ]
 [ 127.54940796]
 [  92.99314117]
 [  96.10137939]
 [  94.79697418]]
DEBUG:root:training time = %d0.223758
INFO:root:frame =2873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =2874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000172853469849
INFO:root:random_action_porb = 0.977358333333
DEBUG:root: dqn, choose action rondomly, need time 0.000317000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =2877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =2878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:random_action_porb = 0.977326666667
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 193.31971741]
 [ 132.54777527]
 [ 121.87067413]
 [  96.99947357]
 [ 191.88015747]
 [ 170.02511597]
 [ 195.18907166]
 [ 192.11695862]
 [ 132.36479187]
 [ 156.14167786]
 [ 140.1204834 ]
 [ 114.14634705]
 [ 133.93640137]
 [ 218.66537476]
 [  95.11725616]
 [ 200.16619873]]
DEBUG:root:training time = %d0.228443
INFO:root:frame =2881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =2882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000123977661133
INFO:root:random_action_porb = 0.977295
DEBUG:root: dqn, choose action rondomly, need time 0.000193000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174045562744
INFO:root:frame =2885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame =2886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047779083252
DEBUG:root: save sample needs time = 0.000168085098267
INFO:root:random_action_porb = 0.977263333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 105.72073364]
 [ 182.71295166]
 [ 114.9308548 ]
 [ 176.04199219]
 [ 165.49031067]
 [ 174.59458923]
 [ 128.69451904]
 [ 104.95179749]
 [ 107.31855011]
 [ 110.25801086]
 [ 179.73695374]
 [ 163.92367554]
 [ 110.85163116]
 [  99.39453125]
 [ 174.59458923]
 [ 107.31855011]]
DEBUG:root:training time = %d0.22864
INFO:root:frame =2889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =2890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:random_action_porb = 0.977231666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335216522217
INFO:root:frame =2893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =2894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9772
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 129.88471985]
 [ 164.60542297]
 [ 238.89575195]
 [ 178.11756897]
 [ 100.39070129]
 [ 160.36882019]
 [ 212.63786316]
 [ 197.9646759 ]
 [ 167.65460205]
 [ 248.80084229]
 [ 100.52773285]
 [ 108.73127747]
 [ 172.32330322]
 [ 171.71812439]
 [ 248.80084229]
 [ 164.80555725]]
DEBUG:root:training time = %d0.22176
INFO:root:frame =2897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =2898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000425100326538
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.977168333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =2901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =2902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.977136666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 105.55888367]
 [ 107.09830475]
 [ 107.09830475]
 [ 115.15900421]
 [ 146.22631836]
 [ 145.45016479]
 [ 108.72109985]
 [ 159.16030884]
 [ 106.89375305]
 [ 111.94773865]
 [ 110.71704865]
 [ 110.78513336]
 [ 140.79066467]
 [ 105.86543274]
 [ 112.89549255]
 [ 171.84490967]]
DEBUG:root:training time = %d0.226425
INFO:root:frame =2905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =2906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229835510254
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.977105
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =2909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame =2910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.977073333333
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 162.86886597]
 [ 147.04226685]
 [ 192.38819885]
 [ 198.83125305]
 [ 117.80211639]
 [ 192.38819885]
 [ 127.20601654]
 [ 123.41719818]
 [ 127.20601654]
 [ 140.24513245]
 [ 117.80211639]
 [ 154.41369629]
 [ 131.02590942]
 [ 105.66111755]
 [ 155.97546387]
 [ 140.24513245]]
DEBUG:root:training time = %d0.202208
INFO:root:frame =2913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =2914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.977041666667
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000346183776855
INFO:root:frame =2917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =2918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.97701
DEBUG:root: dqn, choose action rondomly, need time 0.000168000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 127.30413055]
 [ 128.61628723]
 [ 137.37702942]
 [ 156.37133789]
 [ 108.35642242]
 [ 119.88606262]
 [ 103.24365997]
 [ 243.59495544]
 [ 109.81240082]
 [ 160.67272949]
 [ 118.90802002]
 [ 131.26286316]
 [ 114.32150269]
 [ 157.49337769]
 [ 156.96453857]
 [ 256.32235718]]
DEBUG:root:training time = %d0.221179
INFO:root:frame =2921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =2922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.976978333333
DEBUG:root: dqn, choose action rondomly, need time 0.000324000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =2925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =2926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.976946666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 133.51010132]
 [ 136.47677612]
 [  99.83649445]
 [ 231.31181335]
 [ 135.1693573 ]
 [ 266.24203491]
 [ 238.84246826]
 [ 131.29258728]
 [ 139.01725769]
 [ 231.31181335]
 [ 236.71824646]
 [ 245.32843018]
 [ 252.16389465]
 [ 252.16389465]
 [ 135.1693573 ]
 [ 154.09492493]]
DEBUG:root:training time = %d0.218386
INFO:root:frame =2929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =2930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.976915
DEBUG:root: dqn, choose action rondomly, need time 0.000194
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304222106934
INFO:root:frame =2933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000367879867554
INFO:root:frame =2934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436782836914
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.976883333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 137.69233704]
 [ 207.89762878]
 [ 225.14237976]
 [ 240.91268921]
 [ 230.10523987]
 [ 231.72462463]
 [ 126.53091431]
 [ 124.48132324]
 [ 200.72615051]
 [ 234.08262634]
 [ 242.76403809]
 [ 213.12988281]
 [ 200.75512695]
 [ 122.18722534]
 [ 234.08262634]
 [ 210.03057861]]
DEBUG:root:training time = %d0.225885
INFO:root:frame =2937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =2938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000519990921021
INFO:root: ememy has been killed for 5 times 
INFO:root:enemies_left [0]
INFO:root:frame = 2939 State into memory, numbers recorded 81 action = 2, reward = 1
DEBUG:root: save sample needs time = 0.000475168228149
INFO:root:random_action_porb = 0.976851666667
DEBUG:root: dqn, choose action rondomly, need time 0.000307999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2940current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =2941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =2942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.97682
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 267.59619141]
 [ 219.93121338]
 [ 210.36064148]
 [ 122.15450287]
 [ 196.85414124]
 [ 213.37632751]
 [ 221.667099  ]
 [ 121.12188721]
 [ 227.44924927]
 [ 228.44862366]
 [ 120.44204712]
 [ 233.57395935]
 [ 118.31607819]
 [ 214.49357605]
 [ 215.17616272]
 [ 221.60575867]]
DEBUG:root:training time = %d0.241149
INFO:root:frame =2945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =2946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.976788333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =2949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453233718872
INFO:root:frame =2950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000451803207397
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.976756666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 205.59742737]
 [ 214.87947083]
 [ 156.5415802 ]
 [ 134.32377625]
 [ 127.116539  ]
 [ 132.85820007]
 [ 134.32377625]
 [ 135.68537903]
 [ 133.23167419]
 [ 141.13887024]
 [ 138.77844238]
 [ 127.116539  ]
 [ 106.77767181]
 [ 205.59742737]
 [ 139.03704834]
 [ 224.29559326]]
DEBUG:root:training time = %d0.217628
INFO:root:frame =2953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =2954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000311136245728
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.976725
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =2957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =2958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.976693333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 219.86650085]
 [ 214.94210815]
 [ 188.53121948]
 [ 202.53056335]
 [ 121.50271606]
 [ 217.41802979]
 [ 238.45257568]
 [ 208.09083557]
 [ 190.65197754]
 [ 185.15736389]
 [ 220.43930054]
 [ 172.87820435]
 [ 191.30018616]
 [ 156.26869202]
 [ 188.13084412]
 [ 137.47076416]]
DEBUG:root:training time = %d0.210109
INFO:root:frame =2961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000260829925537
INFO:root:frame =2962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.976661666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =2965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =2966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.97663
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000378131866455
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 136.35415649]
 [ 149.93019104]
 [ 141.4254303 ]
 [ 131.73214722]
 [ 141.4254303 ]
 [ 134.44299316]
 [ 226.49295044]
 [ 233.15858459]
 [ 163.78890991]
 [ 144.12820435]
 [ 170.4475708 ]
 [ 145.25369263]
 [ 146.15657043]
 [ 222.51756287]
 [ 136.21058655]
 [ 135.13885498]]
DEBUG:root:training time = %d0.218032
INFO:root:frame =2969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =2970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.976598333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =2973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =2974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.976566666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:training error  = [[ 141.02250671]
 [ 137.57525635]
 [ 208.22601318]
 [ 172.3321228 ]
 [ 302.88299561]
 [ 148.16345215]
 [ 300.81307983]
 [ 154.89302063]
 [ 302.88299561]
 [ 138.26338196]
 [ 141.79077148]
 [ 216.13612366]
 [ 155.34190369]
 [ 292.37838745]
 [ 228.69500732]
 [ 311.64349365]]
DEBUG:root:training time = %d0.239069
INFO:root:frame =2977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =2978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame = 2979 State into memory, numbers recorded 82 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:random_action_porb = 0.976535
DEBUG:root: dqn, choose action rondomly, need time 0.000195000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2980current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:frame =2981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =2982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.976503333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 174.9758606 ]
 [ 294.81356812]
 [ 286.68096924]
 [ 176.72087097]
 [ 171.29168701]
 [ 208.24978638]
 [ 290.56838989]
 [ 165.40748596]
 [ 274.50192261]
 [ 321.19906616]
 [ 144.18463135]
 [ 278.28427124]
 [ 248.42408752]
 [ 292.60803223]
 [ 207.89057922]
 [ 282.99325562]]
DEBUG:root:training time = %d0.241721
INFO:root:frame =2985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:frame =2986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame = 2987 State into memory, numbers recorded 83 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:random_action_porb = 0.976471666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2988current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =2989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =2990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.97644
DEBUG:root: dqn, choose action rondomly, need time 0.000279999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 327.77981567]
 [ 261.69192505]
 [ 323.64523315]
 [ 372.63208008]
 [ 237.61683655]
 [ 180.78012085]
 [ 190.55212402]
 [ 284.90261841]
 [ 253.56781006]
 [ 284.90261841]
 [ 190.55212402]
 [ 239.26712036]
 [ 242.98709106]
 [ 146.24034119]
 [ 235.37120056]
 [ 329.63833618]]
DEBUG:root:training time = %d0.221197
INFO:root:frame =2993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =2994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000260829925537
DEBUG:root: save sample needs time = 0.000120162963867
INFO:root:random_action_porb = 0.976408333333
DEBUG:root: dqn, choose action rondomly, need time 0.000171000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163793563843
INFO:root:frame =2997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =2998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
DEBUG:root: save sample needs time = 0.000205993652344
DEBUG:root:one frame running time = 0.006317
DEBUG:root:total training time = 55.740064
INFO:root:frame num = 3000 frame round: 0
INFO:root:random_action_porb = 0.976376666667
DEBUG:root: dqn, choose action rondomly, need time 0.000278999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[ 304.58493042]
 [ 351.86813354]
 [ 243.41732788]
 [ 201.84320068]
 [ 211.52545166]
 [ 310.99734497]
 [ 188.1693573 ]
 [ 286.36639404]
 [ 242.31538391]
 [ 223.26339722]
 [ 213.55735779]
 [ 246.72904968]
 [ 351.86813354]
 [ 242.31538391]
 [ 162.96313477]
 [ 151.83221436]]
DEBUG:root:training time = %d0.230515
INFO:root:frame =3001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =3002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.976345
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:frame =3005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =3006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.976313333333
INFO:root:dqn select action Tensor("ArgMax_5:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013259
INFO:root:action choosen by dqn [3]
INFO:root:frame =3008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 250.37402344]
 [ 189.74583435]
 [ 239.24871826]
 [ 276.93731689]
 [ 267.381073  ]
 [ 165.32585144]
 [ 156.11079407]
 [ 203.52243042]
 [ 241.99768066]
 [ 297.76467896]
 [ 259.96395874]
 [ 246.47312927]
 [ 281.33694458]
 [ 250.37402344]
 [ 282.04071045]
 [ 156.44232178]]
DEBUG:root:training time = %d0.21952
INFO:root:frame =3009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =3010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.976281666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =3013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =3014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.97625
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 160.64990234]
 [ 195.39506531]
 [ 148.91998291]
 [ 262.06628418]
 [ 170.67236328]
 [ 161.91452026]
 [ 156.48812866]
 [ 276.12786865]
 [ 195.39506531]
 [ 277.0942688 ]
 [ 231.96252441]
 [ 277.2532959 ]
 [ 261.92254639]
 [ 160.64990234]
 [ 319.70385742]
 [ 319.70385742]]
DEBUG:root:training time = %d0.22422
INFO:root:frame =3017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290155410767
INFO:root:frame =3018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.976218333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =3021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =3022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000108003616333
INFO:root:random_action_porb = 0.976186666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:training error  = [[ 193.41902161]
 [ 175.95292664]
 [ 227.52658081]
 [ 285.1272583 ]
 [ 296.25732422]
 [ 286.10409546]
 [ 285.1272583 ]
 [ 171.23178101]
 [ 300.64743042]
 [ 226.44059753]
 [ 290.88317871]
 [ 237.11470032]
 [ 300.64743042]
 [ 264.6534729 ]
 [ 202.36729431]
 [ 172.85934448]]
DEBUG:root:training time = %d0.231266
INFO:root:frame =3025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000325202941895
INFO:root:frame =3026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.976155
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root:frame =3029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000429153442383
INFO:root:frame =3030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.976123333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:training error  = [[ 244.3046875 ]
 [ 211.04681396]
 [ 372.63208008]
 [ 231.11552429]
 [ 368.00442505]
 [ 380.84176636]
 [ 383.60116577]
 [ 207.32247925]
 [ 372.63208008]
 [ 284.97628784]
 [ 215.63929749]
 [ 371.74365234]
 [ 371.74365234]
 [ 289.30618286]
 [ 276.41445923]
 [ 213.91026306]]
DEBUG:root:training time = %d0.210957
INFO:root:frame =3033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =3034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame = 3035 State into memory, numbers recorded 84 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000540018081665
INFO:root:random_action_porb = 0.976091666667
DEBUG:root: dqn, choose action rondomly, need time 0.000278999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3036current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root:frame =3037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =3038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042986869812
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.97606
INFO:root:dqn select action Tensor("ArgMax_6:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.008328
INFO:root:action choosen by dqn [3]
INFO:root:frame =3040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 316.33078003]
 [ 230.3001709 ]
 [ 230.3001709 ]
 [ 171.352005  ]
 [ 246.48416138]
 [ 319.82171631]
 [ 179.11151123]
 [ 222.01254272]
 [ 179.6579895 ]
 [ 240.63424683]
 [ 299.14334106]
 [ 314.82907104]
 [ 210.35488892]
 [ 358.35214233]
 [ 313.47735596]
 [ 185.22879028]]
DEBUG:root:training time = %d0.229678
INFO:root:frame =3041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =3042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324010848999
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.976028333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =3045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =3046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.975996666667
DEBUG:root: dqn, choose action rondomly, need time 0.000279999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 298.83465576]
 [ 205.3730011 ]
 [ 334.58581543]
 [ 181.48861694]
 [ 183.29794312]
 [ 382.53738403]
 [ 181.71398926]
 [ 276.2800293 ]
 [ 336.40585327]
 [ 245.65071106]
 [ 284.27557373]
 [ 294.80517578]
 [ 299.59164429]
 [ 216.78356934]
 [ 259.84243774]
 [ 289.48580933]]
DEBUG:root:training time = %d0.215489
INFO:root:frame =3049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =3050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.975965
DEBUG:root: dqn, choose action rondomly, need time 0.000183999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000168800354004
INFO:root:frame =3053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000429153442383
INFO:root:frame =3054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.975933333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 194.66755676]
 [ 265.53045654]
 [ 374.51367188]
 [ 202.17459106]
 [ 183.29382324]
 [ 394.10028076]
 [ 356.55368042]
 [ 180.18687439]
 [ 387.36096191]
 [ 401.02728271]
 [ 387.36096191]
 [ 369.7616272 ]
 [ 256.19631958]
 [ 370.15609741]
 [ 271.32528687]
 [ 233.64067078]]
DEBUG:root:training time = %d0.221317
INFO:root:frame =3057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:frame =3058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430822372437
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.975901666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =3061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000327825546265
INFO:root:frame =3062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.97587
DEBUG:root: dqn, choose action rondomly, need time 0.000333000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 304.77246094]
 [ 208.15071106]
 [ 333.62637329]
 [ 200.47631836]
 [ 194.84132385]
 [ 198.24859619]
 [ 195.32296753]
 [ 333.73452759]
 [ 175.0138092 ]
 [ 321.95318604]
 [ 294.78839111]
 [ 292.15246582]
 [ 301.68917847]
 [ 208.15071106]
 [ 175.0138092 ]
 [ 336.96917725]]
DEBUG:root:training time = %d0.22878
INFO:root:frame =3065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =3066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000284910202026
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.975838333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =3069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438213348389
INFO:root:frame =3070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.975806666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 199.41648865]
 [ 283.98648071]
 [ 266.33865356]
 [ 262.11123657]
 [ 309.41656494]
 [ 278.02163696]
 [ 236.8807373 ]
 [ 244.2073822 ]
 [ 249.1942749 ]
 [ 205.00579834]
 [ 257.54138184]
 [ 309.41656494]
 [ 271.08001709]
 [ 291.50082397]
 [ 199.41648865]
 [ 266.33865356]]
DEBUG:root:training time = %d0.231264
INFO:root:frame =3073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =3074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame = 3075 State into memory, numbers recorded 85 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000543832778931
INFO:root:random_action_porb = 0.975775
DEBUG:root: dqn, choose action rondomly, need time 0.000157000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3076current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root:frame =3077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =3078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247955322266
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.975743333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:training error  = [[ 203.82772827]
 [ 264.58843994]
 [ 445.08535767]
 [ 206.29244995]
 [ 259.64373779]
 [ 263.32214355]
 [ 428.81021118]
 [ 256.4112854 ]
 [ 204.45474243]
 [ 209.70518494]
 [ 264.50305176]
 [ 435.83825684]
 [ 245.18792725]
 [ 204.24621582]
 [ 210.35002136]
 [ 428.67623901]]
DEBUG:root:training time = %d0.218156
INFO:root:frame =3081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =3082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031304359436
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.975711666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =3085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =3086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.97568
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 240.97994995]
 [ 221.53625488]
 [ 240.97994995]
 [ 206.51956177]
 [ 372.55551147]
 [ 233.95516968]
 [ 357.32052612]
 [ 222.21903992]
 [ 205.31616211]
 [ 205.04600525]
 [ 205.31616211]
 [ 356.80612183]
 [ 227.43913269]
 [ 252.05342102]
 [ 205.04600525]
 [ 240.97994995]]
DEBUG:root:training time = %d0.231374
INFO:root:frame =3089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =3090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000351905822754
INFO:root:frame = 3091 State into memory, numbers recorded 86 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000579118728638
INFO:root:random_action_porb = 0.975648333333
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3092current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =3093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =3094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.975616666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 324.18240356]
 [ 278.12747192]
 [ 226.7869873 ]
 [ 354.57644653]
 [ 213.13166809]
 [ 359.98599243]
 [ 391.81234741]
 [ 392.51580811]
 [ 354.08126831]
 [ 359.98599243]
 [ 297.28356934]
 [ 278.12747192]
 [ 197.08070374]
 [ 343.2805481 ]
 [ 359.98599243]
 [ 324.18240356]]
DEBUG:root:training time = %d0.22545
INFO:root:frame =3097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =3098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:random_action_porb = 0.975585
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =3101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042986869812
INFO:root:frame =3102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame = 3103 State into memory, numbers recorded 87 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.00053882598877
INFO:root:random_action_porb = 0.975553333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3104current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 231.9281311 ]
 [ 269.23513794]
 [ 230.66664124]
 [ 219.77827454]
 [ 283.81781006]
 [ 260.41043091]
 [ 218.89332581]
 [ 281.28881836]
 [ 283.69854736]
 [ 271.95098877]
 [ 275.44369507]
 [ 295.09866333]
 [ 290.60739136]
 [ 368.34991455]
 [ 270.27468872]
 [ 292.27349854]]
DEBUG:root:training time = %d0.223313
INFO:root:frame =3105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280141830444
INFO:root:frame =3106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000116109848022
INFO:root:random_action_porb = 0.975521666667
DEBUG:root: dqn, choose action rondomly, need time 0.000178000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000166177749634
INFO:root:frame =3109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =3110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.97549
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 231.17584229]
 [ 232.01644897]
 [ 230.51927185]
 [ 226.37355042]
 [ 230.51927185]
 [ 241.6275177 ]
 [ 209.2414093 ]
 [ 393.78411865]
 [ 237.35159302]
 [ 375.26174927]
 [ 246.0612793 ]
 [ 230.51927185]
 [ 237.88412476]
 [ 248.3971405 ]
 [ 415.85974121]
 [ 230.51927185]]
DEBUG:root:training time = %d0.224296
INFO:root:frame =3113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =3114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000381946563721
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.975458333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:frame =3117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =3118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.975426666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 392.693573  ]
 [ 469.38317871]
 [ 323.78359985]
 [ 322.83538818]
 [ 322.35961914]
 [ 384.90350342]
 [ 329.64718628]
 [ 295.67562866]
 [ 237.934021  ]
 [ 243.41732788]
 [ 482.90490723]
 [ 446.96603394]
 [ 242.71791077]
 [ 281.37072754]
 [ 322.36291504]
 [ 385.08673096]]
DEBUG:root:training time = %d0.231847
INFO:root:frame =3121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =3122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000251770019531
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.975395
DEBUG:root: dqn, choose action rondomly, need time 0.000183999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root:frame =3125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =3126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame = 3127 State into memory, numbers recorded 88 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000587940216064
INFO:root:random_action_porb = 0.975363333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3128current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 380.70239258]
 [ 360.43197632]
 [ 465.92767334]
 [ 243.56018066]
 [ 392.79882812]
 [ 391.14212036]
 [ 344.44293213]
 [ 395.49249268]
 [ 351.76507568]
 [ 487.65924072]
 [ 381.39700317]
 [ 241.0045929 ]
 [ 282.03353882]
 [ 476.29519653]
 [ 243.56018066]
 [ 329.1619873 ]]
DEBUG:root:training time = %d0.207976
INFO:root:frame =3129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:player has been killed for 4 times 
INFO:root:frame =3130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame = 3131 State into memory, numbers recorded 89 action = 0, reward = -1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:random_action_porb = 0.975331666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3132current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =3133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000402927398682
INFO:root:frame =3134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9753
DEBUG:root: dqn, choose action rondomly, need time 0.000291999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 254.40678406]
 [ 281.37686157]
 [ 322.81567383]
 [ 488.15670776]
 [ 604.41729736]
 [ 329.14648438]
 [ 565.25323486]
 [ 345.30664062]
 [ 379.4303894 ]
 [ 583.86798096]
 [ 349.2796936 ]
 [ 488.15670776]
 [ 448.29998779]
 [ 395.87008667]
 [ 347.63562012]
 [ 576.21826172]]
DEBUG:root:training time = %d0.229797
INFO:root:frame =3137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =3138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.975268333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =3141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =3142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.975236666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 364.19262695]
 [ 395.64181519]
 [ 296.88696289]
 [ 354.14788818]
 [ 261.36868286]
 [ 272.71444702]
 [ 264.33828735]
 [ 372.85949707]
 [ 390.30361938]
 [ 463.9548645 ]
 [ 473.37319946]
 [ 269.20108032]
 [ 252.72149658]
 [ 399.18984985]
 [ 296.88696289]
 [ 291.37786865]]
DEBUG:root:training time = %d0.225489
INFO:root:frame =3145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255823135376
INFO:root:frame =3146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044322013855
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.975205
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =3149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:frame =3150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.975173333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:training error  = [[ 385.12145996]
 [ 362.07696533]
 [ 453.6725769 ]
 [ 488.66253662]
 [ 515.95721436]
 [ 500.37435913]
 [ 494.18423462]
 [ 499.51187134]
 [ 419.66213989]
 [ 365.43652344]
 [ 494.79229736]
 [ 526.26470947]
 [ 385.12145996]
 [ 471.9944458 ]
 [ 517.24316406]
 [ 368.37802124]]
DEBUG:root:training time = %d0.218642
INFO:root:frame =3153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =3154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288963317871
DEBUG:root: save sample needs time = 0.000115871429443
INFO:root:random_action_porb = 0.975141666667
DEBUG:root: dqn, choose action rondomly, need time 0.000186999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:frame =3157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =3158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.97511
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 368.68618774]
 [ 388.15301514]
 [ 320.61849976]
 [ 391.9984436 ]
 [ 318.42663574]
 [ 282.21087646]
 [ 404.43728638]
 [ 350.60757446]
 [ 495.60043335]
 [ 282.61706543]
 [ 382.14474487]
 [ 393.6557312 ]
 [ 282.14321899]
 [ 260.88439941]
 [ 505.7571106 ]
 [ 271.68533325]]
DEBUG:root:training time = %d0.216934
INFO:root:frame =3161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =3162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000199794769287
INFO:root:random_action_porb = 0.975078333333
DEBUG:root: dqn, choose action rondomly, need time 0.000307999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =3165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =3166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.975046666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:training error  = [[ 402.84072876]
 [ 291.78433228]
 [ 368.96984863]
 [ 368.96984863]
 [ 252.2278595 ]
 [ 380.58926392]
 [ 444.63348389]
 [ 411.09887695]
 [ 390.94778442]
 [ 569.09210205]
 [ 366.1824646 ]
 [ 554.19952393]
 [ 569.09210205]
 [ 377.53765869]
 [ 552.72058105]
 [ 387.10513306]]
DEBUG:root:training time = %d0.230541
INFO:root:frame =3169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =3170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446796417236
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.975015
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =3173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =3174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449180603027
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.974983333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:training error  = [[ 461.68328857]
 [ 480.91522217]
 [ 294.48773193]
 [ 331.18490601]
 [ 465.93557739]
 [ 344.15072632]
 [ 369.44128418]
 [ 353.6862793 ]
 [ 461.68328857]
 [ 303.1932373 ]
 [ 278.25778198]
 [ 303.1932373 ]
 [ 344.15072632]
 [ 369.35684204]
 [ 423.66900635]
 [ 289.96160889]]
DEBUG:root:training time = %d0.229554
INFO:root:frame =3177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028920173645
INFO:root:frame =3178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.974951666667
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =3181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00044584274292
INFO:root:frame =3182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.97492
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 404.43606567]
 [ 374.50305176]
 [ 302.86068726]
 [ 403.97836304]
 [ 374.50305176]
 [ 381.3326416 ]
 [ 390.91641235]
 [ 496.91793823]
 [ 316.38452148]
 [ 404.32315063]
 [ 415.29608154]
 [ 393.6993103 ]
 [ 453.03579712]
 [ 307.68188477]
 [ 492.86764526]
 [ 292.44674683]]
DEBUG:root:training time = %d0.21294
INFO:root:frame =3185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =3186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274896621704
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.974888333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =3189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =3190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.974856666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 516.16381836]
 [ 629.63806152]
 [ 394.74636841]
 [ 393.48379517]
 [ 395.88467407]
 [ 523.75860596]
 [ 408.30560303]
 [ 641.06256104]
 [ 294.82299805]
 [ 424.52624512]
 [ 305.66921997]
 [ 394.87490845]
 [ 276.53778076]
 [ 368.9335022 ]
 [ 276.53778076]
 [ 355.90628052]]
DEBUG:root:training time = %d0.24099
INFO:root:frame =3193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =3194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000280857086182
INFO:root:frame = 3195 State into memory, numbers recorded 90 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000583171844482
INFO:root:random_action_porb = 0.974825
DEBUG:root: dqn, choose action rondomly, need time 0.000346
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3196current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root:frame =3197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488996505737
INFO:root:frame =3198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.974793333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:training error  = [[ 438.10675049]
 [ 527.58868408]
 [ 503.39346313]
 [ 427.25576782]
 [ 473.40374756]
 [ 314.54486084]
 [ 495.23498535]
 [ 499.32635498]
 [ 529.30889893]
 [ 425.34405518]
 [ 491.06442261]
 [ 531.5144043 ]
 [ 507.49908447]
 [ 527.58868408]
 [ 534.88275146]
 [ 530.95025635]]
DEBUG:root:training time = %d0.220718
INFO:root: ememy has been killed for 6 times 
INFO:root:enemies_left [0]
INFO:root:frame =3201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =3202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame = 3203 State into memory, numbers recorded 91 action = 4, reward = 1
DEBUG:root: save sample needs time = 0.000550031661987
INFO:root:random_action_porb = 0.974761666667
DEBUG:root: dqn, choose action rondomly, need time 0.000189999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3204current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000172138214111
INFO:root:frame =3205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =3206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.97473
DEBUG:root: dqn, choose action rondomly, need time 0.000351999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 319.86593628]
 [ 423.93161011]
 [ 451.23440552]
 [ 388.57159424]
 [ 419.84344482]
 [ 342.2612915 ]
 [ 311.52981567]
 [ 339.00015259]
 [ 420.45022583]
 [ 319.35855103]
 [ 398.91796875]
 [ 378.82312012]
 [ 320.53762817]
 [ 320.08538818]
 [ 370.86688232]
 [ 378.82312012]]
DEBUG:root:training time = %d0.229128
INFO:root:frame =3209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281810760498
INFO:root:frame =3210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308990478516
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.974698333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =3213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =3214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:random_action_porb = 0.974666666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 357.02868652]
 [ 334.99008179]
 [ 395.35415649]
 [ 383.19543457]
 [ 559.17785645]
 [ 402.40472412]
 [ 392.44204712]
 [ 421.15386963]
 [ 368.72720337]
 [ 621.4664917 ]
 [ 336.38009644]
 [ 338.30825806]
 [ 392.44204712]
 [ 352.16241455]
 [ 346.07034302]
 [ 388.44766235]]
DEBUG:root:training time = %d0.218521
INFO:root:frame =3217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =3218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000242948532104
DEBUG:root: save sample needs time = 0.000126123428345
INFO:root:random_action_porb = 0.974635
DEBUG:root: dqn, choose action rondomly, need time 0.000280000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =3221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =3222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000416040420532
DEBUG:root: save sample needs time = 9.51290130615e-05
INFO:root:random_action_porb = 0.974603333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:training error  = [[ 567.33166504]
 [ 618.0993042 ]
 [ 639.99212646]
 [ 358.38391113]
 [ 354.29376221]
 [ 624.73297119]
 [ 359.9732666 ]
 [ 346.64285278]
 [ 357.55822754]
 [ 527.94769287]
 [ 549.09472656]
 [ 349.88793945]
 [ 358.31689453]
 [ 525.9888916 ]
 [ 358.38391113]
 [ 349.88793945]]
DEBUG:root:training time = %d0.224861
INFO:root:frame =3225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =3226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.974571666667
INFO:root:dqn select action Tensor("ArgMax_7:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010922
INFO:root:action choosen by dqn [3]
INFO:root:frame =3228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root:frame =3229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:frame =3230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.97454
DEBUG:root: dqn, choose action rondomly, need time 0.000509000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 579.30352783]
 [ 572.62261963]
 [ 334.53335571]
 [ 514.43743896]
 [ 349.84799194]
 [ 353.27203369]
 [ 565.40563965]
 [ 479.87442017]
 [ 420.05984497]
 [ 511.52474976]
 [ 572.51019287]
 [ 429.21350098]
 [ 572.62261963]
 [ 542.94915771]
 [ 618.75653076]
 [ 589.48278809]]
DEBUG:root:training time = %d0.235281
INFO:root:frame =3233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =3234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:random_action_porb = 0.974508333333
INFO:root:dqn select action Tensor("ArgMax_8:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011519
INFO:root:action choosen by dqn [3]
INFO:root:frame =3236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000156879425049
INFO:root:frame =3237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =3238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235080718994
DEBUG:root: save sample needs time = 9.20295715332e-05
INFO:root:random_action_porb = 0.974476666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 441.68344116]
 [ 448.2947998 ]
 [ 327.28439331]
 [ 546.66601562]
 [ 405.54888916]
 [ 720.5737915 ]
 [ 470.70645142]
 [ 352.44998169]
 [ 528.51300049]
 [ 508.30789185]
 [ 353.6449585 ]
 [ 458.00546265]
 [ 510.25692749]
 [ 532.96612549]
 [ 378.62356567]
 [ 705.328125  ]]
DEBUG:root:training time = %d0.227273
INFO:root:frame =3241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275850296021
INFO:root:frame =3242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000414133071899
INFO:root:frame = 3243 State into memory, numbers recorded 92 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000541925430298
INFO:root:random_action_porb = 0.974445
DEBUG:root: dqn, choose action rondomly, need time 0.000187999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3244current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000179052352905
INFO:root:frame =3245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000327825546265
INFO:root:frame =3246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000581979751587
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:random_action_porb = 0.974413333333
INFO:root:dqn select action Tensor("ArgMax_9:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015833
INFO:root:action choosen by dqn [3]
INFO:root:frame =3248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 422.55288696]
 [ 369.90951538]
 [ 334.53335571]
 [ 596.7276001 ]
 [ 371.75247192]
 [ 378.97280884]
 [ 601.99633789]
 [ 384.10522461]
 [ 400.55316162]
 [ 406.35562134]
 [ 384.10522461]
 [ 378.97280884]
 [ 384.10522461]
 [ 379.9881897 ]
 [ 614.90466309]
 [ 396.77410889]]
DEBUG:root:training time = %d0.221134
INFO:root:frame =3249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =3250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.974381666667
DEBUG:root: dqn, choose action rondomly, need time 0.000484999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root:frame =3253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =3254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame = 3255 State into memory, numbers recorded 93 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000562906265259
INFO:root:random_action_porb = 0.97435
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3256current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:training error  = [[ 590.86175537]
 [ 598.23895264]
 [ 603.17700195]
 [ 703.56719971]
 [ 442.26342773]
 [ 575.16973877]
 [ 388.3899231 ]
 [ 453.24237061]
 [ 372.12210083]
 [ 703.56719971]
 [ 598.23895264]
 [ 581.95379639]
 [ 711.25054932]
 [ 593.90258789]
 [ 590.3692627 ]
 [ 712.0760498 ]]
DEBUG:root:training time = %d0.217336
INFO:root:frame =3257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =3258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428915023804
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:random_action_porb = 0.974318333333
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =3261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =3262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433206558228
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.974286666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 555.49487305]
 [ 546.1138916 ]
 [ 629.74072266]
 [ 585.52832031]
 [ 365.6010437 ]
 [ 394.22872925]
 [ 621.72821045]
 [ 548.12969971]
 [ 669.22033691]
 [ 548.24261475]
 [ 572.88555908]
 [ 603.82922363]
 [ 560.9675293 ]
 [ 586.57891846]
 [ 549.58538818]
 [ 555.49487305]]
DEBUG:root:training time = %d0.22448
INFO:root:frame =3265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =3266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000404119491577
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.974255
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =3269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =3270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.974223333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000397920608521
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 437.93173218]
 [ 453.29434204]
 [ 420.12612915]
 [ 534.52996826]
 [ 392.4130249 ]
 [ 565.92382812]
 [ 600.74505615]
 [ 434.15283203]
 [ 408.85214233]
 [ 414.57373047]
 [ 605.51470947]
 [ 422.26937866]
 [ 421.1350708 ]
 [ 395.35656738]
 [ 480.55255127]
 [ 492.06039429]]
DEBUG:root:training time = %d0.228685
INFO:root:frame =3273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =3274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275850296021
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.974191666667
DEBUG:root: dqn, choose action rondomly, need time 0.000324000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =3277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =3278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.97416
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 418.77236938]
 [ 511.15209961]
 [ 566.54400635]
 [ 443.15722656]
 [ 713.6519165 ]
 [ 419.85595703]
 [ 525.36199951]
 [ 427.73532104]
 [ 481.39852905]
 [ 430.00543213]
 [ 592.64044189]
 [ 697.64306641]
 [ 556.58294678]
 [ 454.25256348]
 [ 713.6519165 ]
 [ 556.58294678]]
DEBUG:root:training time = %d0.229866
INFO:root:frame =3281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =3282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame = 3283 State into memory, numbers recorded 94 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000565052032471
INFO:root:random_action_porb = 0.974128333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3284current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =3285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =3286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.974096666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:training error  = [[ 663.26208496]
 [ 680.93951416]
 [ 416.93331909]
 [ 424.88095093]
 [ 702.36810303]
 [ 857.4541626 ]
 [ 689.34613037]
 [ 678.86425781]
 [ 503.64685059]
 [ 860.10308838]
 [ 420.60290527]
 [ 402.98773193]
 [ 876.41693115]
 [ 523.49041748]
 [ 430.38775635]
 [ 718.99688721]]
DEBUG:root:training time = %d0.220801
INFO:root:frame =3289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =3290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000316143035889
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.974065
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame =3293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =3294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.974033333333
DEBUG:root: dqn, choose action rondomly, need time 0.000278000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 528.82171631]
 [ 663.83282471]
 [ 882.47869873]
 [ 471.94140625]
 [ 876.35369873]
 [ 716.36761475]
 [ 442.78341675]
 [ 451.28369141]
 [ 861.14520264]
 [ 876.35369873]
 [ 882.47869873]
 [ 664.54382324]
 [ 841.34875488]
 [ 453.26965332]
 [ 858.31225586]
 [ 882.47869873]]
DEBUG:root:training time = %d0.219389
INFO:root:frame =3297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =3298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00048303604126
DEBUG:root: save sample needs time = 0.000162124633789
INFO:root:random_action_porb = 0.974001666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =3301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =3302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000633955001831
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.97397
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 712.70324707]
 [ 450.37133789]
 [ 612.35559082]
 [ 444.84072876]
 [ 849.56915283]
 [ 945.3861084 ]
 [ 623.78753662]
 [ 807.68847656]
 [ 444.84072876]
 [ 444.84072876]
 [ 623.35162354]
 [ 831.12591553]
 [ 837.90179443]
 [ 461.7645874 ]
 [ 791.796875  ]
 [ 841.69396973]]
DEBUG:root:training time = %d0.214252
INFO:root:frame =3305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =3306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.973938333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =3309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =3310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000225067138672
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:random_action_porb = 0.973906666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 625.92199707]
 [ 689.65704346]
 [ 689.65704346]
 [ 495.88851929]
 [ 625.92199707]
 [ 686.33673096]
 [ 597.29730225]
 [ 647.56951904]
 [ 594.13317871]
 [ 668.75933838]
 [ 658.08972168]
 [ 467.37536621]
 [ 727.5604248 ]
 [ 580.37792969]
 [ 486.16964722]
 [ 647.56951904]]
DEBUG:root:training time = %d0.221018
INFO:root:frame =3313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =3314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.973875
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000362157821655
INFO:root:frame =3317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =3318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.973843333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 512.17510986]
 [ 497.76187134]
 [ 484.45532227]
 [ 513.71643066]
 [ 505.44421387]
 [ 470.2616272 ]
 [ 487.82232666]
 [ 713.38287354]
 [ 497.76187134]
 [ 716.00994873]
 [ 510.35757446]
 [ 510.35757446]
 [ 484.45532227]
 [ 495.86950684]
 [ 518.32373047]
 [ 520.86553955]]
DEBUG:root:training time = %d0.224153
INFO:root:frame =3321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =3322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.973811666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =3325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =3326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.97378
DEBUG:root: dqn, choose action rondomly, need time 0.000206000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 476.9694519 ]
 [ 639.27893066]
 [ 682.86010742]
 [ 535.52386475]
 [ 628.9230957 ]
 [ 719.25384521]
 [ 725.34777832]
 [ 725.87719727]
 [ 624.42944336]
 [ 648.85620117]
 [ 697.67370605]
 [ 746.49951172]
 [ 816.02038574]
 [ 594.20758057]
 [ 628.22070312]
 [ 713.66656494]]
DEBUG:root:training time = %d0.222348
INFO:root:frame =3329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =3330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438213348389
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:random_action_porb = 0.973748333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =3333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000377893447876
INFO:root:frame =3334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.973716666667
DEBUG:root: dqn, choose action rondomly, need time 0.000317999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365972518921
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 648.75671387]
 [ 583.40203857]
 [ 583.40203857]
 [ 615.73736572]
 [ 711.56634521]
 [ 634.01818848]
 [ 663.18823242]
 [ 511.13967896]
 [ 648.75671387]
 [ 608.00439453]
 [ 634.01818848]
 [ 932.53930664]
 [ 481.58468628]
 [ 513.68603516]
 [ 555.05621338]
 [ 589.50201416]]
DEBUG:root:training time = %d0.233354
INFO:root:frame =3337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =3338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002601146698
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.973685
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =3341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =3342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.973653333333
INFO:root:dqn select action Tensor("ArgMax_10:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014533
INFO:root:action choosen by dqn [3]
INFO:root:frame =3344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:training error  = [[ 848.65673828]
 [ 532.32519531]
 [ 601.05175781]
 [ 580.45880127]
 [ 572.40795898]
 [ 604.38128662]
 [ 510.31207275]
 [ 576.26812744]
 [ 995.95062256]
 [ 580.72058105]
 [ 592.46514893]
 [ 579.71496582]
 [ 887.18096924]
 [ 600.36816406]
 [ 571.15576172]
 [ 522.59289551]]
DEBUG:root:training time = %d0.226981
INFO:root:frame =3345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =3346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000300884246826
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.973621666667
DEBUG:root: dqn, choose action rondomly, need time 0.000276999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =3349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000414848327637
INFO:root:frame =3350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.97359
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 526.91461182]
 [ 507.6159668 ]
 [ 758.96313477]
 [ 550.66479492]
 [ 513.00976562]
 [ 801.78082275]
 [ 941.64398193]
 [ 508.41387939]
 [ 895.16705322]
 [ 755.34051514]
 [ 754.20367432]
 [ 941.48480225]
 [ 864.190979  ]
 [ 907.32995605]
 [ 521.9052124 ]
 [ 904.02368164]]
DEBUG:root:training time = %d0.234765
INFO:root:frame =3353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =3354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000295877456665
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.973558333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =3357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000485181808472
INFO:root:frame =3358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.973526666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 636.86920166]
 [ 658.00518799]
 [ 705.67016602]
 [ 636.86920166]
 [ 665.87872314]
 [ 740.63275146]
 [ 600.68225098]
 [ 624.18847656]
 [ 634.97137451]
 [ 625.4440918 ]
 [ 548.27832031]
 [ 636.86920166]
 [ 582.41326904]
 [ 669.81097412]
 [ 690.35766602]
 [ 548.27832031]]
DEBUG:root:training time = %d0.24098
INFO:root:frame =3361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root:frame =3362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.973495
DEBUG:root: dqn, choose action rondomly, need time 0.000473999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =3365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =3366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.973463333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  631.76873779]
 [ 1009.38647461]
 [  703.90557861]
 [ 1005.28356934]
 [  703.90557861]
 [  577.39245605]
 [  575.92089844]
 [  544.91784668]
 [  691.57702637]
 [ 1020.35089111]
 [  627.82299805]
 [  566.81860352]
 [  588.52587891]
 [  511.34115601]
 [  714.36950684]
 [  580.49993896]]
DEBUG:root:training time = %d0.231718
INFO:root:frame =3369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =3370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.973431666667
DEBUG:root: dqn, choose action rondomly, need time 0.000358000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =3373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =3374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 9.58442687988e-05
INFO:root:random_action_porb = 0.9734
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:training error  = [[  620.46875   ]
 [  566.96539307]
 [ 1038.10876465]
 [ 1003.71472168]
 [  585.12817383]
 [  620.46875   ]
 [  642.24072266]
 [  506.15386963]
 [  650.05236816]
 [ 1026.34899902]
 [  680.35992432]
 [  961.29138184]
 [ 1008.94439697]
 [  714.43475342]
 [ 1062.3326416 ]
 [  598.58679199]]
DEBUG:root:training time = %d0.220321
INFO:root:frame =3377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =3378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.973368333333
DEBUG:root: dqn, choose action rondomly, need time 0.000364000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =3381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471115112305
INFO:root:frame =3382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.973336666667
DEBUG:root: dqn, choose action rondomly, need time 0.000230999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  606.74688721]
 [  714.1998291 ]
 [  570.30126953]
 [ 1027.44824219]
 [ 1034.16577148]
 [ 1065.17333984]
 [  653.05609131]
 [  910.76013184]
 [  993.0557251 ]
 [  528.18188477]
 [  590.9418335 ]
 [  868.4989624 ]
 [  564.60186768]
 [  676.50476074]
 [  905.06817627]
 [ 1032.5078125 ]]
DEBUG:root:training time = %d0.219181
INFO:root:frame =3385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =3386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:random_action_porb = 0.973305
DEBUG:root: dqn, choose action rondomly, need time 0.000242
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =3389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =3390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470876693726
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.973273333333
DEBUG:root: dqn, choose action rondomly, need time 0.00028300000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[  620.94775391]
 [ 1018.7411499 ]
 [ 1069.5402832 ]
 [ 1036.2611084 ]
 [ 1041.48608398]
 [  782.80078125]
 [  603.17401123]
 [  786.74188232]
 [  605.17980957]
 [  575.30584717]
 [ 1031.52355957]
 [  945.79901123]
 [ 1010.65313721]
 [  908.12982178]
 [  737.60113525]
 [  912.02783203]]
DEBUG:root:training time = %d0.225314
INFO:root:frame =3393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =3394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000404834747314
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.973241666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =3397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =3398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000355005264282
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.97321
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  688.93914795]
 [ 1089.77758789]
 [ 1099.53723145]
 [  598.83325195]
 [  832.60107422]
 [  753.08605957]
 [  917.23876953]
 [  874.80950928]
 [  836.89324951]
 [ 1068.97143555]
 [  760.66070557]
 [ 1104.3026123 ]
 [  717.04248047]
 [  790.52130127]
 [ 1099.90563965]
 [  829.55181885]]
DEBUG:root:training time = %d0.213113
INFO:root:frame =3401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =3402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:random_action_porb = 0.973178333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =3405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =3406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448226928711
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.973146666667
DEBUG:root: dqn, choose action rondomly, need time 0.000395999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  678.55895996]
 [ 1190.45007324]
 [  717.09313965]
 [ 1080.8338623 ]
 [  713.69104004]
 [  796.93353271]
 [  748.63891602]
 [  695.80322266]
 [ 1003.53106689]
 [  620.24377441]
 [  620.24377441]
 [  717.09313965]
 [  803.23150635]
 [ 1150.27124023]
 [ 1044.42114258]
 [ 1143.38427734]]
DEBUG:root:training time = %d0.230324
INFO:root:frame =3409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =3410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:random_action_porb = 0.973115
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =3413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000422954559326
INFO:root:frame =3414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:random_action_porb = 0.973083333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1004.6895752 ]
 [  661.58282471]
 [  762.79669189]
 [ 1362.64123535]
 [ 1184.82971191]
 [  623.72351074]
 [  725.47601318]
 [ 1220.83154297]
 [  655.67443848]
 [  771.52825928]
 [ 1036.86437988]
 [  573.9130249 ]
 [ 1022.51226807]
 [  749.56774902]
 [  954.85675049]
 [  655.67443848]]
DEBUG:root:training time = %d0.222476
INFO:root:frame =3417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =3418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247955322266
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:random_action_porb = 0.973051666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =3421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =3422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.97302
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1110.99169922]
 [  671.35675049]
 [ 1120.71289062]
 [ 1057.83557129]
 [  667.11096191]
 [ 1033.12963867]
 [  928.64599609]
 [  602.19555664]
 [  692.18865967]
 [  758.98162842]
 [ 1127.11547852]
 [  729.67749023]
 [ 1164.52600098]
 [ 1191.21887207]
 [ 1033.12963867]
 [ 1077.86608887]]
DEBUG:root:training time = %d0.230874
INFO:root:frame =3425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =3426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
DEBUG:root: save sample needs time = 0.000111103057861
INFO:root:random_action_porb = 0.972988333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =3429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449180603027
INFO:root:frame =3430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.972956666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1008.29504395]
 [  697.06121826]
 [  920.08398438]
 [  715.84173584]
 [  911.61315918]
 [  673.54571533]
 [  829.73284912]
 [  825.97125244]
 [  911.61315918]
 [  700.8548584 ]
 [  697.36419678]
 [  957.30639648]
 [  962.95550537]
 [  706.86401367]
 [  840.88140869]
 [  957.30639648]]
DEBUG:root:training time = %d0.230289
INFO:root:frame =3433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:frame =3434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame = 3435 State into memory, numbers recorded 95 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000572204589844
INFO:root:random_action_porb = 0.972925
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3436current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000357866287231
INFO:root:frame =3437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =3438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000500917434692
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.972893333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 825.07513428]
 [ 838.78186035]
 [ 761.19274902]
 [ 834.4230957 ]
 [ 834.63824463]
 [ 868.53674316]
 [ 822.33190918]
 [ 734.73126221]
 [ 924.92608643]
 [ 823.43847656]
 [ 721.49487305]
 [ 779.59020996]
 [ 848.59454346]
 [ 817.21862793]
 [ 823.43847656]
 [ 807.40057373]]
DEBUG:root:training time = %d0.231816
INFO:root:frame =3441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =3442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265836715698
DEBUG:root: save sample needs time = 0.000117778778076
INFO:root:random_action_porb = 0.972861666667
DEBUG:root: dqn, choose action rondomly, need time 0.000185999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000166177749634
INFO:root:frame =3445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =3446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.97283
DEBUG:root: dqn, choose action rondomly, need time 0.000478999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 712.41162109]
 [ 818.00396729]
 [ 732.76879883]
 [ 997.82568359]
 [ 774.07849121]
 [ 725.96765137]
 [ 816.18255615]
 [ 736.64996338]
 [ 767.31097412]
 [ 843.06866455]
 [ 740.78393555]
 [ 712.41162109]
 [ 759.3112793 ]
 [ 695.85638428]
 [ 738.74206543]
 [ 740.71081543]]
DEBUG:root:training time = %d0.224307
INFO:root:frame =3449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =3450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:random_action_porb = 0.972798333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:frame =3453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00040602684021
INFO:root: ememy has been killed for 7 times 
INFO:root:enemies_left [0]
INFO:root:frame =3454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame = 3455 State into memory, numbers recorded 96 action = 4, reward = 1
DEBUG:root: save sample needs time = 0.00055193901062
INFO:root:random_action_porb = 0.972766666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3456current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1090.55554199]
 [ 1088.81066895]
 [  716.89215088]
 [ 1103.50561523]
 [ 1167.58361816]
 [  708.88085938]
 [  897.26281738]
 [ 1142.22460938]
 [ 1235.54992676]
 [ 1103.50561523]
 [  803.37854004]
 [ 1095.03869629]
 [  866.50170898]
 [  726.69799805]
 [ 1208.14794922]
 [ 1085.07592773]]
DEBUG:root:training time = %d0.224829
INFO:root:frame =3457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265836715698
INFO:root:frame =3458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000429153442383
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.972735
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =3461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =3462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.972703333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1350.7598877 ]
 [  728.097229  ]
 [  765.1585083 ]
 [ 1323.93994141]
 [ 1044.31860352]
 [  875.8984375 ]
 [  728.097229  ]
 [ 1276.34362793]
 [ 1265.09521484]
 [ 1277.89672852]
 [ 1017.01586914]
 [  702.53466797]
 [  843.93017578]
 [  746.05932617]
 [  806.73126221]
 [ 1051.55395508]]
DEBUG:root:training time = %d0.204829
INFO:root:frame =3465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =3466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.972671666667
DEBUG:root: dqn, choose action rondomly, need time 0.000151000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:frame =3469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =3470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame = 3471 State into memory, numbers recorded 97 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000557899475098
INFO:root:random_action_porb = 0.97264
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3472current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1155.71777344]
 [ 1283.57141113]
 [  894.84020996]
 [ 1378.30639648]
 [ 1229.66992188]
 [ 1101.81530762]
 [ 1354.98046875]
 [  785.34039307]
 [  918.8550415 ]
 [  956.87213135]
 [ 1074.7824707 ]
 [  798.79376221]
 [  786.61352539]
 [  873.24865723]
 [ 1116.05505371]
 [ 1101.81530762]]
DEBUG:root:training time = %d0.219019
INFO:root:frame =3473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =3474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247955322266
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.972608333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =3477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =3478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000420093536377
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.972576666667
DEBUG:root: dqn, choose action rondomly, need time 0.00028300000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1205.1796875 ]
 [  774.3026123 ]
 [  990.0133667 ]
 [  990.0133667 ]
 [  813.85809326]
 [ 1239.43188477]
 [ 1024.16796875]
 [  838.23394775]
 [ 1038.32312012]
 [  800.21234131]
 [ 1485.20288086]
 [  825.76605225]
 [  800.21234131]
 [ 1239.43188477]
 [ 1228.46313477]
 [ 1075.19873047]]
DEBUG:root:training time = %d0.218865
INFO:root:frame =3481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =3482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259876251221
DEBUG:root: save sample needs time = 0.000120162963867
INFO:root:random_action_porb = 0.972545
DEBUG:root: dqn, choose action rondomly, need time 0.000174999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:frame =3485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =3486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.972513333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:training error  = [[ 1282.48266602]
 [  814.71502686]
 [  817.40008545]
 [  856.63397217]
 [  848.74212646]
 [  799.51153564]
 [  826.4151001 ]
 [ 1002.13751221]
 [  915.65344238]
 [  831.56054688]
 [ 1045.43518066]
 [  987.97106934]
 [  880.07250977]
 [  857.16998291]
 [  873.47235107]
 [  873.47235107]]
DEBUG:root:training time = %d0.213779
INFO:root:frame =3489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =3490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000373840332031
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.972481666667
INFO:root:dqn select action Tensor("ArgMax_11:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013306
INFO:root:action choosen by dqn [3]
INFO:root:frame =3492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =3493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000424861907959
INFO:root:frame =3494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.97245
DEBUG:root: dqn, choose action rondomly, need time 0.000280000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1220.51806641]
 [ 1181.43078613]
 [  951.15240479]
 [  864.18914795]
 [ 1220.51806641]
 [  879.44610596]
 [ 1307.92773438]
 [ 1170.23791504]
 [ 1259.97705078]
 [  950.35821533]
 [  938.48510742]
 [ 1106.59777832]
 [ 1126.54382324]
 [  856.68762207]
 [  863.7119751 ]
 [ 1217.84558105]]
DEBUG:root:training time = %d0.223612
INFO:root:frame =3497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =3498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000136852264404
INFO:root:random_action_porb = 0.972418333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =3501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000422954559326
INFO:root:frame =3502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
INFO:root:frame = 3503 State into memory, numbers recorded 98 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000556945800781
INFO:root:random_action_porb = 0.972386666667
DEBUG:root: dqn, choose action rondomly, need time 0.000255999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3504current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  870.19598389]
 [ 1298.6204834 ]
 [ 1130.64880371]
 [ 1254.1472168 ]
 [  857.01275635]
 [  999.05615234]
 [ 1420.83996582]
 [  870.19598389]
 [ 1487.06640625]
 [  921.76208496]
 [  887.00280762]
 [ 1190.84387207]
 [ 1452.30114746]
 [ 1436.76806641]
 [  932.17211914]
 [ 1363.72070312]]
DEBUG:root:training time = %d0.223352
INFO:root:frame =3505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =3506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.972355
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =3509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466823577881
INFO:root:frame =3510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:random_action_porb = 0.972323333333
DEBUG:root: dqn, choose action rondomly, need time 0.000535999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1305.6418457 ]
 [ 1509.98461914]
 [  871.61175537]
 [  884.16210938]
 [ 1226.84216309]
 [ 1114.35510254]
 [  892.58856201]
 [ 1336.49060059]
 [ 1190.44799805]
 [ 1493.38098145]
 [ 1242.30004883]
 [ 1080.36437988]
 [  840.22491455]
 [ 1385.8215332 ]
 [  891.73901367]
 [ 1150.03942871]]
DEBUG:root:training time = %d0.223031
INFO:root:frame =3513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =3514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.972291666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =3517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000415802001953
INFO:root:frame =3518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.97226
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:training error  = [[ 1593.87304688]
 [ 1035.83874512]
 [  903.37597656]
 [ 1593.87304688]
 [  992.77685547]
 [  908.58972168]
 [ 1435.14904785]
 [ 1567.19628906]
 [  974.65991211]
 [ 1490.41052246]
 [  940.10131836]
 [ 1296.85705566]
 [  968.65167236]
 [  904.86987305]
 [  989.88659668]
 [ 1058.21069336]]
DEBUG:root:training time = %d0.20801
INFO:root:frame =3521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270843505859
INFO:root:frame =3522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000312089920044
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.972228333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =3525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000416994094849
INFO:root:frame =3526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.972196666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1616.8605957 ]
 [  992.10388184]
 [ 1616.8605957 ]
 [  992.10388184]
 [ 1196.98095703]
 [ 1011.37896729]
 [ 1715.34191895]
 [  901.65234375]
 [ 1196.98095703]
 [  839.58813477]
 [ 1535.10534668]
 [ 1254.69628906]
 [  900.35528564]
 [  839.58813477]
 [  901.34448242]
 [  980.90460205]]
DEBUG:root:training time = %d0.228574
INFO:root:frame =3529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =3530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002601146698
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.972165
DEBUG:root: dqn, choose action rondomly, need time 0.00028300000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =3533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000576019287109
INFO:root:frame =3534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.972133333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  931.16986084]
 [ 1632.9362793 ]
 [ 1737.85778809]
 [ 1465.23449707]
 [  973.45599365]
 [ 1188.43139648]
 [ 1510.71044922]
 [ 1692.40039062]
 [ 1684.16955566]
 [ 1531.2623291 ]
 [ 1209.42114258]
 [ 1675.25427246]
 [ 1664.13098145]
 [ 1715.57958984]
 [ 1179.30871582]
 [ 1649.06677246]]
DEBUG:root:training time = %d0.223351
INFO:root:frame =3537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =3538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:random_action_porb = 0.972101666667
INFO:root:dqn select action Tensor("ArgMax_12:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010897
INFO:root:action choosen by dqn [3]
INFO:root:frame =3540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root:frame =3541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000669956207275
INFO:root:frame =3542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000224828720093
INFO:root:random_action_porb = 0.97207
DEBUG:root: dqn, choose action rondomly, need time 0.000527000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  953.72546387]
 [ 1037.75292969]
 [  971.16455078]
 [ 1555.24902344]
 [ 1684.28979492]
 [ 1536.36816406]
 [ 1254.67028809]
 [ 1270.45861816]
 [ 1501.87939453]
 [ 1185.42858887]
 [ 1290.66174316]
 [ 1440.44433594]
 [ 1585.25390625]
 [ 1013.61627197]
 [ 1283.74633789]
 [ 1725.00183105]]
DEBUG:root:training time = %d0.236093
INFO:root:frame =3545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =3546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame = 3547 State into memory, numbers recorded 99 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:random_action_porb = 0.972038333333
INFO:root:dqn select action Tensor("ArgMax_13:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00924099999999
INFO:root:action choosen by dqn [1]
INFO:root:frame =3548current_observation done, NOT record action [1], reward = 0
DEBUG:root: save sample needs time = 0.000390768051147
INFO:root:frame =3549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =3550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.972006666667
DEBUG:root: dqn, choose action rondomly, need time 0.000528000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:training error  = [[ 1286.63903809]
 [ 1362.47680664]
 [ 1374.52490234]
 [ 1524.68225098]
 [ 1524.68225098]
 [ 1459.91711426]
 [ 1141.95654297]
 [ 1314.15100098]
 [ 1362.47680664]
 [ 1029.37426758]
 [ 1330.05432129]
 [ 1001.37249756]
 [ 1471.64306641]
 [  960.20172119]
 [ 1141.21411133]
 [ 1354.05493164]]
DEBUG:root:training time = %d0.232512
INFO:root:frame =3553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =3554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031304359436
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.971975
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000315189361572
INFO:root:frame =3557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =3558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.971943333333
DEBUG:root: dqn, choose action rondomly, need time 0.000280999999987
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1265.06481934]
 [ 1139.95666504]
 [ 1139.95666504]
 [ 1126.31445312]
 [ 1701.55249023]
 [ 1116.62597656]
 [ 1137.08996582]
 [ 1185.90356445]
 [ 1064.09191895]
 [ 1247.84790039]
 [ 1087.61877441]
 [ 1150.37890625]
 [ 1757.16723633]
 [ 1002.46209717]
 [ 1074.39025879]
 [ 1289.85498047]]
DEBUG:root:training time = %d0.215478
INFO:root:frame =3561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =3562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486135482788
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.971911666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =3565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000400066375732
INFO:root:frame =3566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.97188
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1726.59423828]
 [ 1066.51037598]
 [ 1713.87109375]
 [ 1247.8651123 ]
 [ 1713.87109375]
 [ 1664.4597168 ]
 [ 1724.5       ]
 [ 1677.32836914]
 [ 1670.40136719]
 [ 1713.48193359]
 [ 1083.89807129]
 [ 1588.32214355]
 [ 1265.1081543 ]
 [ 1036.94689941]
 [ 1241.01391602]
 [ 1221.23461914]]
DEBUG:root:training time = %d0.207836
INFO:root:frame =3569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =3570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.971848333333
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000363111495972
INFO:root:frame =3573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000475883483887
INFO:root:frame =3574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491857528687
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.971816666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1615.89379883]
 [ 1629.42602539]
 [ 1215.72924805]
 [ 1637.93212891]
 [ 1099.35717773]
 [ 1166.27001953]
 [ 1628.48999023]
 [ 1886.41345215]
 [ 1547.82983398]
 [ 1128.86816406]
 [ 1653.47167969]
 [ 1583.54345703]
 [ 1728.30407715]
 [ 1729.04504395]
 [ 1563.05749512]
 [ 1020.03118896]]
DEBUG:root:training time = %d0.213314
INFO:root:frame =3577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =3578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.971785
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =3581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =3582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485181808472
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:random_action_porb = 0.971753333333
DEBUG:root: dqn, choose action rondomly, need time 0.000343000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1748.02490234]
 [ 1684.14453125]
 [ 1085.80383301]
 [ 1862.40917969]
 [ 1768.81237793]
 [ 1432.58825684]
 [ 1432.95800781]
 [ 1943.02099609]
 [ 1801.1953125 ]
 [ 1121.03173828]
 [ 1829.96899414]
 [ 1367.79882812]
 [ 1367.79882812]
 [ 1129.11425781]
 [ 1541.41064453]
 [ 1541.41064453]]
DEBUG:root:training time = %d0.213593
INFO:root:frame =3585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =3586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.971721666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =3589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =3590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449180603027
INFO:root:frame = 3591 State into memory, numbers recorded 100 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000584840774536
INFO:root:random_action_porb = 0.97169
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3592current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1152.63232422]
 [ 1402.00061035]
 [ 1152.63232422]
 [ 1178.91052246]
 [ 1168.31359863]
 [ 1662.33886719]
 [ 1662.33886719]
 [ 1397.83520508]
 [ 1075.79516602]
 [ 1284.45935059]
 [ 1154.40270996]
 [ 1075.79516602]
 [ 1135.69909668]
 [ 1154.5769043 ]
 [ 1295.34094238]
 [ 1199.13574219]]
DEBUG:root:training time = %d0.24334
INFO:root:frame =3593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =3594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.971658333333
DEBUG:root: dqn, choose action rondomly, need time 0.000332999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =3597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =3598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.971626666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1331.38574219]
 [ 1138.66296387]
 [ 1211.33654785]
 [ 1560.11022949]
 [ 1184.59655762]
 [ 2047.7779541 ]
 [ 1890.3494873 ]
 [ 1622.93811035]
 [ 1663.72766113]
 [ 1130.94433594]
 [ 1884.52111816]
 [ 1127.87585449]
 [ 1430.74072266]
 [ 1265.66833496]
 [ 1205.56958008]
 [ 2068.28417969]]
DEBUG:root:training time = %d0.213073
INFO:root:frame =3601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =3602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.971595
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =3605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =3606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.971563333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2058.37548828]
 [ 1127.38806152]
 [ 1984.8536377 ]
 [ 1621.74816895]
 [ 1948.52954102]
 [ 1483.01147461]
 [ 1420.86291504]
 [ 2054.06347656]
 [ 2058.59155273]
 [ 1556.50085449]
 [ 1909.77636719]
 [ 2158.48828125]
 [ 1503.82434082]
 [ 1556.50085449]
 [ 1521.53320312]
 [ 1594.13623047]]
DEBUG:root:training time = %d0.209666
INFO:root:frame =3609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =3610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000301122665405
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.971531666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =3613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame =3614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000524044036865
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9715
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1918.25720215]
 [ 1774.66479492]
 [ 1890.62011719]
 [ 1797.32214355]
 [ 1242.72167969]
 [ 1838.28662109]
 [ 1918.25720215]
 [ 1734.4855957 ]
 [ 1239.47912598]
 [ 1774.66479492]
 [ 1895.52770996]
 [ 1620.27868652]
 [ 1305.74780273]
 [ 1593.83898926]
 [ 1922.74536133]
 [ 1242.72167969]]
DEBUG:root:training time = %d0.234399
INFO:root:frame =3617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =3618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame = 3619 State into memory, numbers recorded 101 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000604152679443
INFO:root:random_action_porb = 0.971468333333
DEBUG:root: dqn, choose action rondomly, need time 0.000278000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3620current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =3621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =3622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.971436666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1966.33032227]
 [ 1828.62719727]
 [ 1531.63977051]
 [ 1284.64758301]
 [ 1579.35412598]
 [ 1850.62756348]
 [ 1594.85766602]
 [ 1583.7767334 ]
 [ 1699.43322754]
 [ 1805.01025391]
 [ 1713.92163086]
 [ 1550.44348145]
 [ 2022.12255859]
 [ 1226.64111328]
 [ 1284.64758301]
 [ 1745.86669922]]
DEBUG:root:training time = %d0.21678
INFO:root:frame =3625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255823135376
INFO:root:frame =3626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.971405
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =3629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =3630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.971373333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1250.734375  ]
 [ 1356.93127441]
 [ 1289.03967285]
 [ 1438.28613281]
 [ 1506.73706055]
 [ 2038.84436035]
 [ 1354.94445801]
 [ 1573.35400391]
 [ 2082.49291992]
 [ 1336.22729492]
 [ 1476.92529297]
 [ 1734.50585938]
 [ 1573.35400391]
 [ 1734.50585938]
 [ 2087.16357422]
 [ 1264.48742676]]
DEBUG:root:training time = %d0.213252
INFO:root:frame =3633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =3634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000261068344116
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.971341666667
DEBUG:root: dqn, choose action rondomly, need time 0.000178000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000176906585693
INFO:root:frame =3637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =3638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.97131
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1420.19128418]
 [ 2071.17773438]
 [ 2066.26953125]
 [ 1537.73693848]
 [ 1378.29284668]
 [ 2004.93395996]
 [ 1322.41699219]
 [ 1533.46044922]
 [ 1314.06689453]
 [ 1538.15820312]
 [ 2066.26953125]
 [ 1927.51757812]
 [ 1345.76660156]
 [ 1323.94445801]
 [ 1962.19152832]
 [ 1386.04418945]]
DEBUG:root:training time = %d0.20782
INFO:root:frame =3641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =3642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.971278333333
DEBUG:root: dqn, choose action rondomly, need time 0.00031700000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =3645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000476121902466
INFO:root:frame =3646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.971246666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1518.93933105]
 [ 1552.45812988]
 [ 1309.51745605]
 [ 1326.4552002 ]
 [ 2331.69799805]
 [ 1326.4552002 ]
 [ 1311.15246582]
 [ 1447.75512695]
 [ 1351.96252441]
 [ 1787.36865234]
 [ 1752.00805664]
 [ 2203.14599609]
 [ 1309.51745605]
 [ 2218.0168457 ]
 [ 1878.19921875]
 [ 2320.88232422]]
DEBUG:root:training time = %d0.217053
INFO:root:frame =3649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =3650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:random_action_porb = 0.971215
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =3653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =3654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:random_action_porb = 0.971183333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2159.02148438]
 [ 2210.09594727]
 [ 2375.49731445]
 [ 2271.19384766]
 [ 2221.93920898]
 [ 2137.29003906]
 [ 2198.91967773]
 [ 1880.4588623 ]
 [ 1829.3581543 ]
 [ 2028.17077637]
 [ 1649.48327637]
 [ 1372.43933105]
 [ 2264.50268555]
 [ 2271.19384766]
 [ 2369.29614258]
 [ 2475.51806641]]
DEBUG:root:training time = %d0.212665
INFO:root:frame =3657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =3658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.971151666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000373840332031
INFO:root:frame =3661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000417947769165
INFO:root:frame =3662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000418901443481
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.97112
DEBUG:root: dqn, choose action rondomly, need time 0.00028300000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1468.25927734]
 [ 1429.78979492]
 [ 1631.72802734]
 [ 1481.45117188]
 [ 1987.85144043]
 [ 1760.86877441]
 [ 1786.35205078]
 [ 1380.91345215]
 [ 1703.94506836]
 [ 1436.27770996]
 [ 1759.99304199]
 [ 1759.99304199]
 [ 1721.62695312]
 [ 1762.19580078]
 [ 1728.35473633]
 [ 1476.37646484]]
DEBUG:root:training time = %d0.227115
INFO:root:frame =3665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =3666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265836715698
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.971088333333
DEBUG:root: dqn, choose action rondomly, need time 0.000178999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:frame =3669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =3670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame = 3671 State into memory, numbers recorded 102 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000579118728638
INFO:root:random_action_porb = 0.971056666667
DEBUG:root: dqn, choose action rondomly, need time 0.000267999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3672current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1840.82580566]
 [ 1452.79431152]
 [ 1945.02856445]
 [ 1612.04406738]
 [ 1861.34521484]
 [ 1628.78552246]
 [ 1654.31066895]
 [ 1853.60620117]
 [ 1758.51330566]
 [ 1935.60791016]
 [ 1769.23852539]
 [ 1544.11010742]
 [ 1668.2767334 ]
 [ 1646.24743652]
 [ 1639.31079102]
 [ 1847.00585938]]
DEBUG:root:training time = %d0.214551
INFO:root:frame =3673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000332832336426
INFO:root:frame =3674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.971025
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320196151733
INFO:root:frame =3677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =3678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.970993333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1431.10095215]
 [ 1581.46508789]
 [ 1542.52270508]
 [ 2388.66430664]
 [ 2479.1027832 ]
 [ 1882.74108887]
 [ 2512.79101562]
 [ 1657.5345459 ]
 [ 1637.9519043 ]
 [ 2388.66430664]
 [ 1706.64196777]
 [ 2433.67333984]
 [ 1767.13391113]
 [ 1446.27844238]
 [ 2464.89453125]
 [ 1555.9855957 ]]
DEBUG:root:training time = %d0.219267
INFO:root:frame =3681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =3682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.970961666667
DEBUG:root: dqn, choose action rondomly, need time 0.000339999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =3685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491142272949
INFO:root:frame =3686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.97093
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2471.48071289]
 [ 1811.84692383]
 [ 1509.81384277]
 [ 2579.78295898]
 [ 1557.50280762]
 [ 1767.28271484]
 [ 2223.44702148]
 [ 1613.40686035]
 [ 2368.34545898]
 [ 1702.28771973]
 [ 2386.32006836]
 [ 1587.2520752 ]
 [ 1590.67773438]
 [ 1686.4597168 ]
 [ 1577.2154541 ]
 [ 2370.58569336]]
DEBUG:root:training time = %d0.215722
INFO:root:frame =3689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =3690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000270128250122
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.970898333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:frame =3693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453233718872
INFO:root:frame =3694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame = 3695 State into memory, numbers recorded 103 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000560998916626
INFO:root:random_action_porb = 0.970866666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3696current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:training error  = [[ 1621.06005859]
 [ 2143.06713867]
 [ 2454.06420898]
 [ 2146.21606445]
 [ 1612.98522949]
 [ 2132.83422852]
 [ 2154.37280273]
 [ 2233.13354492]
 [ 2365.42358398]
 [ 1571.40332031]
 [ 2579.54736328]
 [ 2433.32421875]
 [ 2359.82836914]
 [ 1490.38696289]
 [ 2376.72924805]
 [ 1490.38696289]]
DEBUG:root:training time = %d0.244437
INFO:root:frame =3697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root:frame =3698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441789627075
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:random_action_porb = 0.970835
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =3701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =3702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.970803333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1639.00927734]
 [ 1521.90466309]
 [ 1628.94812012]
 [ 1566.22021484]
 [ 1634.00195312]
 [ 1541.61669922]
 [ 1865.13903809]
 [ 1759.4041748 ]
 [ 1865.63989258]
 [ 1982.59191895]
 [ 1909.33361816]
 [ 1587.44177246]
 [ 1865.63989258]
 [ 2169.55004883]
 [ 1608.87463379]
 [ 1521.90466309]]
DEBUG:root:training time = %d0.209034
INFO:root:frame =3705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =3706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.970771666667
DEBUG:root: dqn, choose action rondomly, need time 0.000234000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =3709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =3710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000126838684082
INFO:root:random_action_porb = 0.97074
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1669.26403809]
 [ 1747.77478027]
 [ 1896.53759766]
 [ 1728.58825684]
 [ 1598.3548584 ]
 [ 1488.25756836]
 [ 2224.31640625]
 [ 1739.49682617]
 [ 2239.88793945]
 [ 1714.35620117]
 [ 1744.78552246]
 [ 1613.94140625]
 [ 1705.57299805]
 [ 1833.23937988]
 [ 2211.92114258]
 [ 1665.19689941]]
DEBUG:root:training time = %d0.225095
INFO:root:frame =3713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =3714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288963317871
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.970708333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =3717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =3718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466823577881
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.970676666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1693.82189941]
 [ 1842.51269531]
 [ 1739.7208252 ]
 [ 1860.42370605]
 [ 1829.13879395]
 [ 2807.67382812]
 [ 2798.68383789]
 [ 2222.4284668 ]
 [ 2592.07397461]
 [ 1693.82189941]
 [ 2807.67382812]
 [ 2194.72583008]
 [ 1884.21386719]
 [ 1906.24658203]
 [ 1663.25476074]
 [ 1848.61157227]]
DEBUG:root:training time = %d0.223401
INFO:root:frame =3721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =3722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00032901763916
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:random_action_porb = 0.970645
DEBUG:root: dqn, choose action rondomly, need time 0.000182999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000158071517944
INFO:root:frame =3725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame =3726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000416040420532
INFO:root:frame = 3727 State into memory, numbers recorded 104 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000538110733032
INFO:root:random_action_porb = 0.970613333333
INFO:root:dqn select action Tensor("ArgMax_14:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013651
INFO:root:action choosen by dqn [1]
INFO:root:frame =3728current_observation done, NOT record action [1], reward = 0
DEBUG:root: save sample needs time = 0.000385046005249
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1773.49243164]
 [ 2672.5378418 ]
 [ 2151.37670898]
 [ 2595.10766602]
 [ 1734.75500488]
 [ 1807.59912109]
 [ 1706.66723633]
 [ 2778.25      ]
 [ 2161.78466797]
 [ 1807.59912109]
 [ 1756.27697754]
 [ 2604.54980469]
 [ 1670.60095215]
 [ 2690.69897461]
 [ 2497.71166992]
 [ 2228.49804688]]
DEBUG:root:training time = %d0.21011
INFO:root:frame =3729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =3730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
DEBUG:root: save sample needs time = 0.000117778778076
INFO:root:random_action_porb = 0.970581666667
DEBUG:root: dqn, choose action rondomly, need time 0.000271000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =3733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =3734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame = 3735 State into memory, numbers recorded 105 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000549077987671
INFO:root:random_action_porb = 0.97055
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3736current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3035.67089844]
 [ 1638.02111816]
 [ 3353.22558594]
 [ 1791.64428711]
 [ 3049.23852539]
 [ 2843.45922852]
 [ 2735.60791016]
 [ 2787.3359375 ]
 [ 3069.18969727]
 [ 3249.86279297]
 [ 2284.30786133]
 [ 1750.79211426]
 [ 2880.70947266]
 [ 1747.0604248 ]
 [ 2349.95947266]
 [ 2835.93310547]]
DEBUG:root:training time = %d0.211002
INFO:root:frame =3737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =3738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271797180176
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:random_action_porb = 0.970518333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root:frame =3741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =3742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.970486666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291999999988
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:training error  = [[ 2270.69360352]
 [ 2650.71630859]
 [ 2310.16821289]
 [ 2712.30908203]
 [ 2310.16821289]
 [ 1825.85119629]
 [ 2817.36499023]
 [ 2262.11010742]
 [ 2614.18994141]
 [ 1798.66271973]
 [ 2360.17822266]
 [ 2238.98681641]
 [ 2242.50561523]
 [ 2107.1315918 ]
 [ 2479.40649414]
 [ 2770.92626953]]
DEBUG:root:training time = %d0.220082
INFO:root:frame =3745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =3746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.970455
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =3749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =3750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.970423333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2104.13476562]
 [ 1946.41235352]
 [ 3138.98803711]
 [ 2104.13476562]
 [ 2264.03222656]
 [ 2209.17211914]
 [ 2142.06713867]
 [ 2135.05029297]
 [ 2845.06738281]
 [ 1796.01831055]
 [ 1929.08825684]
 [ 2848.14794922]
 [ 2218.25830078]
 [ 2104.13476562]
 [ 2259.9855957 ]
 [ 2085.18432617]]
DEBUG:root:training time = %d0.207133
INFO:root:frame =3753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =3754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265836715698
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.970391666667
DEBUG:root: dqn, choose action rondomly, need time 0.000317999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =3757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488996505737
INFO:root:frame =3758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.97036
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2780.01318359]
 [ 2587.97363281]
 [ 1976.4276123 ]
 [ 1935.72607422]
 [ 1922.12451172]
 [ 2123.71679688]
 [ 2061.37841797]
 [ 2077.45458984]
 [ 1986.06665039]
 [ 1976.4276123 ]
 [ 2753.62939453]
 [ 2620.49145508]
 [ 1985.07128906]
 [ 2808.45019531]
 [ 2720.28076172]
 [ 2427.28222656]]
DEBUG:root:training time = %d0.228817
INFO:root:frame =3761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =3762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000516891479492
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:random_action_porb = 0.970328333333
DEBUG:root: dqn, choose action rondomly, need time 0.000318000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =3765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000519037246704
INFO:root:frame =3766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.970296666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2685.32592773]
 [ 2040.00756836]
 [ 1865.19702148]
 [ 2499.95727539]
 [ 2722.80908203]
 [ 1865.19702148]
 [ 1906.32116699]
 [ 2892.00927734]
 [ 1950.68005371]
 [ 3113.31176758]
 [ 2722.80908203]
 [ 2665.70141602]
 [ 2575.42626953]
 [ 2505.41674805]
 [ 2539.84863281]
 [ 2981.72387695]]
DEBUG:root:training time = %d0.238375
INFO:root:frame =3769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =3770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475883483887
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.970265
DEBUG:root: dqn, choose action rondomly, need time 0.000163999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =3773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =3774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488996505737
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.970233333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2414.55517578]
 [ 1988.34667969]
 [ 2425.36401367]
 [ 2527.8972168 ]
 [ 2531.10205078]
 [ 2393.10498047]
 [ 2553.17895508]
 [ 1946.72473145]
 [ 1813.42175293]
 [ 2765.98706055]
 [ 2400.72485352]
 [ 2525.2097168 ]
 [ 2496.99194336]
 [ 2509.57324219]
 [ 2512.64404297]
 [ 2509.57324219]]
DEBUG:root:training time = %d0.217864
INFO:root:frame =3777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000510215759277
INFO:root:frame =3778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame = 3779 State into memory, numbers recorded 106 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000539064407349
INFO:root:random_action_porb = 0.970201666667
INFO:root:dqn select action Tensor("ArgMax_15:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011583
INFO:root:action choosen by dqn [3]
INFO:root:frame =3780current_observation done, NOT record action [3], reward = 0
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =3781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =3782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227928161621
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.97017
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2298.41357422]
 [ 2162.67016602]
 [ 2162.67016602]
 [ 2182.70996094]
 [ 2177.14160156]
 [ 2429.85083008]
 [ 2077.2097168 ]
 [ 2949.05200195]
 [ 2339.4675293 ]
 [ 2476.69042969]
 [ 2182.70996094]
 [ 2177.14160156]
 [ 2298.41357422]
 [ 1831.54638672]
 [ 3014.22045898]
 [ 3099.81298828]]
DEBUG:root:training time = %d0.207323
INFO:root:frame =3785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243186950684
INFO:root:frame =3786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000510931015015
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.970138333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =3789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =3790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476121902466
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.970106666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:training error  = [[ 2124.20629883]
 [ 3146.37182617]
 [ 3228.04858398]
 [ 2265.65893555]
 [ 3091.58129883]
 [ 2388.109375  ]
 [ 2786.20825195]
 [ 2370.05664062]
 [ 2429.27319336]
 [ 2891.61547852]
 [ 2494.08300781]
 [ 2870.64160156]
 [ 2416.06689453]
 [ 2069.58349609]
 [ 3091.58129883]
 [ 2890.98535156]]
DEBUG:root:training time = %d0.209766
INFO:root:frame =3793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =3794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.970075
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =3797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000482797622681
INFO:root:frame =3798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:random_action_porb = 0.970043333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3064.64697266]
 [ 2829.55297852]
 [ 2273.29443359]
 [ 3182.91821289]
 [ 3237.63354492]
 [ 2247.19628906]
 [ 2829.55297852]
 [ 2246.46728516]
 [ 2444.18115234]
 [ 2166.41845703]
 [ 2224.68481445]
 [ 3155.41674805]
 [ 3228.20800781]
 [ 3022.11376953]
 [ 3682.01708984]
 [ 3041.01367188]]
DEBUG:root:training time = %d0.210989
INFO:root:frame =3801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =3802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324964523315
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.970011666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =3805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =3806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.96998
DEBUG:root: dqn, choose action rondomly, need time 0.00028300000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000411987304688
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3607.11523438]
 [ 2406.23657227]
 [ 2498.32177734]
 [ 2820.90405273]
 [ 3059.57397461]
 [ 3510.16479492]
 [ 3511.56079102]
 [ 3510.16479492]
 [ 3070.10961914]
 [ 2407.39233398]
 [ 3528.57324219]
 [ 2506.015625  ]
 [ 2531.16943359]
 [ 2820.90405273]
 [ 2562.46435547]
 [ 3332.41943359]]
DEBUG:root:training time = %d0.220216
INFO:root:frame =3809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =3810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000354051589966
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.969948333333
DEBUG:root: dqn, choose action rondomly, need time 0.000278999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =3813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =3814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.969916666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3748.25854492]
 [ 3355.9831543 ]
 [ 3200.42114258]
 [ 2807.02709961]
 [ 2949.14501953]
 [ 3893.14599609]
 [ 3618.67163086]
 [ 2909.04321289]
 [ 2826.75512695]
 [ 3674.56933594]
 [ 2230.40014648]
 [ 3321.5480957 ]
 [ 3187.96142578]
 [ 2656.60839844]
 [ 3450.28613281]
 [ 2927.99609375]]
DEBUG:root:training time = %d0.233118
INFO:root:frame =3817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =3818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000199794769287
INFO:root:random_action_porb = 0.969885
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =3821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =3822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000518083572388
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.969853333333
INFO:root:dqn select action Tensor("ArgMax_16:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01392
INFO:root:action choosen by dqn [3]
INFO:root:frame =3824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2290.45556641]
 [ 2208.98852539]
 [ 2424.04174805]
 [ 2426.30810547]
 [ 2943.96972656]
 [ 2424.04174805]
 [ 2990.8828125 ]
 [ 3013.53027344]
 [ 2598.60986328]
 [ 2362.62817383]
 [ 3397.28027344]
 [ 3024.44287109]
 [ 2771.52368164]
 [ 3513.61523438]
 [ 2230.65942383]
 [ 2883.39624023]]
DEBUG:root:training time = %d0.22151
INFO:root:frame =3825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000408887863159
INFO:root:frame =3826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame = 3827 State into memory, numbers recorded 107 action = [3], reward = 0
DEBUG:root: save sample needs time = 0.0012218952179
INFO:root:random_action_porb = 0.969821666667
DEBUG:root: dqn, choose action rondomly, need time 0.000278999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3828current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =3829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000484943389893
INFO:root:frame =3830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.96979
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3481.05761719]
 [ 2954.75585938]
 [ 2922.66821289]
 [ 2714.54736328]
 [ 2866.22851562]
 [ 3054.46459961]
 [ 2799.18115234]
 [ 2591.37792969]
 [ 2323.63549805]
 [ 2388.2644043 ]
 [ 3193.91918945]
 [ 2429.72460938]
 [ 2033.30871582]
 [ 2795.41699219]
 [ 2363.13232422]
 [ 3422.70703125]]
DEBUG:root:training time = %d0.225543
INFO:root:frame =3833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame =3834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000276803970337
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.969758333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root:frame =3837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =3838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.969726666667
DEBUG:root: dqn, choose action rondomly, need time 0.000271999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2580.74414062]
 [ 2340.38867188]
 [ 2467.38623047]
 [ 2445.29174805]
 [ 2597.22875977]
 [ 2374.84301758]
 [ 3306.57299805]
 [ 2427.70922852]
 [ 3286.99682617]
 [ 2932.13256836]
 [ 3255.49511719]
 [ 3358.93969727]
 [ 3538.16577148]
 [ 2445.29174805]
 [ 3069.94042969]
 [ 3152.52368164]]
DEBUG:root:training time = %d0.2162
INFO:root:frame =3841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:frame =3842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame = 3843 State into memory, numbers recorded 108 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000594139099121
INFO:root:random_action_porb = 0.969695
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3844current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =3845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00044322013855
INFO:root:frame =3846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.969663333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2380.25952148]
 [ 2987.63916016]
 [ 2427.71533203]
 [ 4169.17529297]
 [ 2542.84570312]
 [ 4110.30175781]
 [ 2981.1640625 ]
 [ 2725.82910156]
 [ 3381.67382812]
 [ 3138.20849609]
 [ 2736.15698242]
 [ 3201.06347656]
 [ 3318.91040039]
 [ 3212.15795898]
 [ 2552.47583008]
 [ 2950.3581543 ]]
DEBUG:root:training time = %d0.223147
INFO:root:frame =3849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:frame =3850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame = 3851 State into memory, numbers recorded 109 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000573873519897
INFO:root:random_action_porb = 0.969631666667
DEBUG:root: dqn, choose action rondomly, need time 0.000159000000011
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3852current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:frame =3853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:frame =3854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000617980957031
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9696
DEBUG:root: dqn, choose action rondomly, need time 0.000545000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2263.78833008]
 [ 2448.80615234]
 [ 3003.58056641]
 [ 2546.8359375 ]
 [ 4215.07177734]
 [ 2546.8359375 ]
 [ 4192.52294922]
 [ 4370.90966797]
 [ 4392.71044922]
 [ 3290.53198242]
 [ 2994.89648438]
 [ 4229.75390625]
 [ 4221.3984375 ]
 [ 2440.35644531]
 [ 2313.57836914]
 [ 4312.08984375]]
DEBUG:root:training time = %d0.215971
INFO:root:frame =3857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =3858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:random_action_porb = 0.969568333333
DEBUG:root: dqn, choose action rondomly, need time 0.000596000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =3861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =3862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481128692627
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.969536666667
DEBUG:root: dqn, choose action rondomly, need time 0.00045999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root:training error  = [[ 3659.51879883]
 [ 2668.24194336]
 [ 3771.85961914]
 [ 3789.34033203]
 [ 2694.45532227]
 [ 3664.29833984]
 [ 2563.08227539]
 [ 2725.6887207 ]
 [ 3642.79003906]
 [ 3533.42578125]
 [ 2643.88916016]
 [ 2614.32104492]
 [ 3652.89794922]
 [ 2663.11181641]
 [ 2710.3894043 ]
 [ 2832.39770508]]
DEBUG:root:training time = %d0.196534
INFO:root:frame =3865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =3866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247001647949
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:random_action_porb = 0.969505
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =3869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =3870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.969473333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3424.68554688]
 [ 2602.41333008]
 [ 3615.67626953]
 [ 2634.00634766]
 [ 3611.53027344]
 [ 3473.24047852]
 [ 4129.41162109]
 [ 3163.73974609]
 [ 3429.82373047]
 [ 3191.38793945]
 [ 4161.03759766]
 [ 4184.73339844]
 [ 4184.43310547]
 [ 3660.66357422]
 [ 3962.45043945]
 [ 2702.61645508]]
DEBUG:root:training time = %d0.240777
INFO:root:frame =3873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =3874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000386953353882
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:random_action_porb = 0.969441666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =3877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =3878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame = 3879 State into memory, numbers recorded 110 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000578165054321
INFO:root:random_action_porb = 0.96941
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3880current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[ 2931.73608398]
 [ 2988.546875  ]
 [ 3130.13061523]
 [ 3273.15429688]
 [ 3025.54394531]
 [ 3223.63916016]
 [ 2862.75952148]
 [ 3315.43725586]
 [ 3315.43725586]
 [ 2768.97949219]
 [ 2653.19946289]
 [ 2783.65087891]
 [ 2696.66699219]
 [ 3262.81933594]
 [ 2656.91040039]
 [ 2472.7734375 ]]
DEBUG:root:training time = %d0.223459
INFO:root:frame =3881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =3882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:random_action_porb = 0.969378333333
DEBUG:root: dqn, choose action rondomly, need time 0.00041499999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =3885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =3886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491142272949
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.969346666667
DEBUG:root: dqn, choose action rondomly, need time 0.000439999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00036096572876
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3297.08959961]
 [ 3055.92211914]
 [ 3601.67016602]
 [ 3055.92211914]
 [ 2719.74609375]
 [ 2867.88891602]
 [ 3006.95996094]
 [ 3262.51953125]
 [ 3404.84790039]
 [ 3257.48046875]
 [ 2955.47241211]
 [ 3234.50878906]
 [ 4363.45556641]
 [ 4210.66650391]
 [ 2946.15600586]
 [ 2939.44775391]]
DEBUG:root:training time = %d0.224528
INFO:root:frame =3889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =3890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00036883354187
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:random_action_porb = 0.969315
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =3893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000482082366943
INFO:root:frame =3894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.969283333333
INFO:root:dqn select action Tensor("ArgMax_17:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011474
INFO:root:action choosen by dqn [3]
INFO:root:frame =3896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3740.62451172]
 [ 4015.14526367]
 [ 4394.65234375]
 [ 4451.57910156]
 [ 2777.41992188]
 [ 2774.11425781]
 [ 3160.84301758]
 [ 4145.15429688]
 [ 3125.9387207 ]
 [ 3299.45898438]
 [ 3018.36352539]
 [ 4015.14526367]
 [ 3089.35546875]
 [ 3343.74609375]
 [ 4428.96582031]
 [ 3317.20166016]]
DEBUG:root:training time = %d0.233112
INFO:root:frame =3897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =3898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.969251666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331163406372
INFO:root:frame =3901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =3902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430822372437
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.96922
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2769.23657227]
 [ 4549.93212891]
 [ 3051.49707031]
 [ 4709.57470703]
 [ 4319.5078125 ]
 [ 2863.15795898]
 [ 2979.91772461]
 [ 2768.10595703]
 [ 3631.13647461]
 [ 2863.0402832 ]
 [ 4582.58105469]
 [ 4707.765625  ]
 [ 2809.8347168 ]
 [ 4085.32739258]
 [ 3040.85864258]
 [ 4774.93310547]]
DEBUG:root:training time = %d0.218278
INFO:root:frame =3905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =3906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275850296021
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root:random_action_porb = 0.969188333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00035285949707
INFO:root:frame =3909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =3910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.969156666667
DEBUG:root: dqn, choose action rondomly, need time 0.000166000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000150918960571
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3889.72705078]
 [ 2921.10424805]
 [ 4123.07568359]
 [ 3838.9309082 ]
 [ 4317.87939453]
 [ 2920.70849609]
 [ 4020.47631836]
 [ 2900.58251953]
 [ 4121.11669922]
 [ 4614.55859375]
 [ 4099.29736328]
 [ 2951.38598633]
 [ 2534.57910156]
 [ 3032.88720703]
 [ 3918.00805664]
 [ 3536.69189453]]
DEBUG:root:training time = %d0.194991
INFO:root:frame =3913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =3914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:random_action_porb = 0.969125
DEBUG:root: dqn, choose action rondomly, need time 0.000388999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:frame =3917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000509023666382
INFO:root:frame =3918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433206558228
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.969093333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999988
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3592.53320312]
 [ 4313.19580078]
 [ 2934.12915039]
 [ 4055.00927734]
 [ 3105.09594727]
 [ 4055.00927734]
 [ 4593.70214844]
 [ 4034.82397461]
 [ 4190.63427734]
 [ 3971.23046875]
 [ 4261.60986328]
 [ 3079.09838867]
 [ 4145.69677734]
 [ 2716.93920898]
 [ 3645.45019531]
 [ 3747.42138672]]
DEBUG:root:training time = %d0.226311
INFO:root:frame =3921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =3922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000254154205322
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.969061666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000337839126587
INFO:root:frame =3925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:frame =3926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000519037246704
INFO:root:frame = 3927 State into memory, numbers recorded 111 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000536918640137
INFO:root:random_action_porb = 0.96903
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3928current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000356912612915
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3700.28344727]
 [ 4744.28710938]
 [ 3088.92797852]
 [ 3340.74682617]
 [ 3379.04077148]
 [ 3268.87451172]
 [ 4588.80566406]
 [ 4152.91503906]
 [ 3973.10766602]
 [ 4152.91503906]
 [ 3407.15600586]
 [ 3384.89013672]
 [ 3917.82470703]
 [ 2982.45043945]
 [ 3234.59912109]
 [ 3437.32006836]]
DEBUG:root:training time = %d0.214996
INFO:root:frame =3929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =3930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049614906311
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.968998333333
DEBUG:root: dqn, choose action rondomly, need time 0.000318000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =3933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =3934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame = 3935 State into memory, numbers recorded 112 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000554084777832
INFO:root:random_action_porb = 0.968966666667
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3936current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3043.93579102]
 [ 3324.62329102]
 [ 3601.90454102]
 [ 3218.29077148]
 [ 5078.52832031]
 [ 3555.41723633]
 [ 3275.73168945]
 [ 3030.22558594]
 [ 3617.93725586]
 [ 4060.0480957 ]
 [ 5109.16064453]
 [ 3275.73168945]
 [ 4949.05029297]
 [ 5117.80273438]
 [ 3148.1796875 ]
 [ 3017.65942383]]
DEBUG:root:training time = %d0.227724
INFO:root:frame =3937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =3938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000355005264282
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.968935
INFO:root:dqn select action Tensor("ArgMax_18:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012726
INFO:root:action choosen by dqn [3]
INFO:root:frame =3940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162124633789
INFO:root:frame =3941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:frame =3942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.968903333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3348.49829102]
 [ 3201.26391602]
 [ 4695.41113281]
 [ 3308.21557617]
 [ 4507.38818359]
 [ 4918.79980469]
 [ 4719.21386719]
 [ 3161.20678711]
 [ 3022.6640625 ]
 [ 4197.57519531]
 [ 4847.75976562]
 [ 4839.7734375 ]
 [ 3677.72949219]
 [ 4653.51464844]
 [ 4764.1171875 ]
 [ 3321.33007812]]
DEBUG:root:training time = %d0.220088
INFO:root:frame =3945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000192880630493
INFO:root:frame =3946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:random_action_porb = 0.968871666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =3949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =3950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
INFO:root:frame = 3951 State into memory, numbers recorded 113 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000574827194214
INFO:root:random_action_porb = 0.96884
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3952current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4072.23779297]
 [ 3992.76806641]
 [ 3578.36767578]
 [ 4270.12451172]
 [ 4318.20019531]
 [ 3480.20776367]
 [ 4183.09863281]
 [ 4075.43212891]
 [ 4073.73339844]
 [ 4199.14111328]
 [ 3034.48730469]
 [ 4257.22802734]
 [ 4196.98974609]
 [ 4098.34423828]
 [ 3311.48828125]
 [ 4087.45751953]]
DEBUG:root:training time = %d0.232419
INFO:root:frame =3953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000377893447876
INFO:root:frame =3954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000297069549561
DEBUG:root: save sample needs time = 0.000141859054565
INFO:root:random_action_porb = 0.968808333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =3957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000509023666382
INFO:root:frame =3958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000245809555054
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.968776666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3948.98413086]
 [ 4150.19384766]
 [ 3881.06787109]
 [ 4366.33496094]
 [ 4418.30566406]
 [ 3961.42089844]
 [ 3844.31787109]
 [ 3622.31469727]
 [ 4415.40136719]
 [ 4251.89306641]
 [ 5415.05175781]
 [ 3563.76342773]
 [ 3622.31469727]
 [ 4024.9050293 ]
 [ 5469.20898438]
 [ 3714.27148438]]
DEBUG:root:training time = %d0.222556
INFO:root:frame =3961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =3962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame = 3963 State into memory, numbers recorded 114 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000547885894775
INFO:root:random_action_porb = 0.968745
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3964current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =3965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =3966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:random_action_porb = 0.968713333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3408.79516602]
 [ 3623.4609375 ]
 [ 5090.20947266]
 [ 4717.82177734]
 [ 3585.6003418 ]
 [ 3332.32788086]
 [ 4849.03466797]
 [ 4700.49853516]
 [ 4833.6953125 ]
 [ 4637.98925781]
 [ 3744.58251953]
 [ 4869.03125   ]
 [ 3332.32788086]
 [ 3534.7175293 ]
 [ 3319.30419922]
 [ 3352.83691406]]
DEBUG:root:training time = %d0.216037
INFO:root:frame =3969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =3970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259160995483
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.968681666667
DEBUG:root: dqn, choose action rondomly, need time 0.000217000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:frame =3973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =3974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259876251221
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.96865
DEBUG:root: dqn, choose action rondomly, need time 0.000153999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4390.48583984]
 [ 4080.6550293 ]
 [ 4402.72412109]
 [ 3394.20019531]
 [ 4602.04541016]
 [ 3462.63012695]
 [ 3576.89257812]
 [ 3467.37255859]
 [ 3567.72900391]
 [ 4483.96337891]
 [ 4153.30859375]
 [ 5099.79394531]
 [ 3611.11206055]
 [ 4253.59667969]
 [ 5595.39404297]
 [ 4127.08984375]]
DEBUG:root:training time = %d0.184054
INFO:root:frame =3977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:frame =3978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227928161621
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.968618333333
DEBUG:root: dqn, choose action rondomly, need time 0.000164999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:frame =3981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =3982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000221014022827
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.968586666667
DEBUG:root: dqn, choose action rondomly, need time 0.00028300000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3375.13916016]
 [ 3628.5769043 ]
 [ 3989.2824707 ]
 [ 4863.27441406]
 [ 4269.53466797]
 [ 3516.68408203]
 [ 5103.03759766]
 [ 5040.74023438]
 [ 5295.65332031]
 [ 4933.39892578]
 [ 4856.90917969]
 [ 4947.81396484]
 [ 5146.15332031]
 [ 4808.48779297]
 [ 3397.60058594]
 [ 4682.63867188]]
DEBUG:root:training time = %d0.207248
INFO:root:frame =3985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =3986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.968555
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =3989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =3990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487089157104
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.968523333333
DEBUG:root: dqn, choose action rondomly, need time 0.000327999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4601.68115234]
 [ 3932.09521484]
 [ 4740.60498047]
 [ 3932.09521484]
 [ 5079.69384766]
 [ 4740.60498047]
 [ 4740.60498047]
 [ 5003.09277344]
 [ 5003.09277344]
 [ 4711.40136719]
 [ 3652.85375977]
 [ 3888.72216797]
 [ 6294.67529297]
 [ 3972.21533203]
 [ 4618.72216797]
 [ 6200.90869141]]
DEBUG:root:training time = %d0.209546
INFO:root:frame =3993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000396966934204
INFO:root:frame =3994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042200088501
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.968491666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =3997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =3998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000205039978027
DEBUG:root:one frame running time = 0.006286
DEBUG:root:total training time = 89.467862
INFO:root:frame num = 4000 frame round: 0
INFO:root:random_action_porb = 0.96846
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 6157.34472656]
 [ 6031.953125  ]
 [ 4851.65283203]
 [ 4624.19921875]
 [ 6232.24658203]
 [ 3888.34155273]
 [ 6047.85302734]
 [ 4498.29589844]
 [ 4482.86816406]
 [ 4787.31542969]
 [ 5941.41357422]
 [ 4683.82519531]
 [ 4604.09960938]
 [ 6047.53027344]
 [ 4936.65771484]
 [ 6127.74365234]]
DEBUG:root:training time = %d0.215365
INFO:root:frame =4001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.968428333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =4005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame =4006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame = 4007 State into memory, numbers recorded 115 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000602006912231
INFO:root:random_action_porb = 0.968396666667
DEBUG:root: dqn, choose action rondomly, need time 0.000426000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4008current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4604.69580078]
 [ 5289.08203125]
 [ 5398.91308594]
 [ 5336.89794922]
 [ 4165.18017578]
 [ 4213.96240234]
 [ 4232.00097656]
 [ 5250.19824219]
 [ 3986.86181641]
 [ 3822.68676758]
 [ 5349.01513672]
 [ 4963.28173828]
 [ 5478.29443359]
 [ 5433.15820312]
 [ 5068.87695312]
 [ 5117.48828125]]
DEBUG:root:training time = %d0.214892
INFO:root:frame =4009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =4010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.968365
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =4013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =4014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame = 4015 State into memory, numbers recorded 116 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000566959381104
INFO:root:random_action_porb = 0.968333333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4016current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3776.14160156]
 [ 5019.1484375 ]
 [ 5231.48144531]
 [ 3752.5793457 ]
 [ 6236.50683594]
 [ 3829.87524414]
 [ 4428.99023438]
 [ 3829.87524414]
 [ 4789.68066406]
 [ 4023.7434082 ]
 [ 3828.22851562]
 [ 5103.29882812]
 [ 5019.1484375 ]
 [ 4007.14355469]
 [ 4118.71875   ]
 [ 5017.43603516]]
DEBUG:root:training time = %d0.227482
INFO:root:frame =4017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =4018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000355005264282
DEBUG:root: save sample needs time = 0.000116109848022
INFO:root:random_action_porb = 0.968301666667
DEBUG:root: dqn, choose action rondomly, need time 0.000227999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =4022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.96827
DEBUG:root: dqn, choose action rondomly, need time 0.000278000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:training error  = [[ 5456.99267578]
 [ 5187.81494141]
 [ 4513.50390625]
 [ 5319.23779297]
 [ 4256.95703125]
 [ 5435.10205078]
 [ 5401.31689453]
 [ 5187.81494141]
 [ 5453.89111328]
 [ 5247.63330078]
 [ 3939.58496094]
 [ 4352.68115234]
 [ 3914.234375  ]
 [ 3997.8605957 ]
 [ 4479.30517578]
 [ 5620.45996094]]
DEBUG:root:training time = %d0.217858
INFO:root:frame =4025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =4026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:random_action_porb = 0.968238333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =4029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame =4030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000425100326538
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.968206666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5328.28710938]
 [ 6362.16552734]
 [ 6387.87695312]
 [ 5735.28857422]
 [ 5045.81982422]
 [ 4640.84912109]
 [ 5017.59179688]
 [ 4348.36572266]
 [ 4969.95751953]
 [ 5317.68896484]
 [ 4034.21899414]
 [ 5735.28857422]
 [ 4640.84912109]
 [ 5362.54052734]
 [ 5441.63769531]
 [ 3519.42089844]]
DEBUG:root:training time = %d0.220833
INFO:root:frame =4033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =4034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.968175
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =4037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =4038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.968143333333
DEBUG:root: dqn, choose action rondomly, need time 0.000326000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:training error  = [[ 4885.72314453]
 [ 3955.69140625]
 [ 4155.57421875]
 [ 5840.13525391]
 [ 4905.55566406]
 [ 6159.29882812]
 [ 5691.18457031]
 [ 4481.95263672]
 [ 5765.89208984]
 [ 4741.05859375]
 [ 4288.33105469]
 [ 5665.46582031]
 [ 4991.09814453]
 [ 4835.32470703]
 [ 5765.89208984]
 [ 5013.25195312]]
DEBUG:root:training time = %d0.234634
INFO:root:frame =4041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =4042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:random_action_porb = 0.968111666667
DEBUG:root: dqn, choose action rondomly, need time 0.000189000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180959701538
INFO:root:frame =4045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000503063201904
INFO:root:frame =4046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000503063201904
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.96808
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5417.83691406]
 [ 6517.05371094]
 [ 5394.42919922]
 [ 4130.19628906]
 [ 4392.21728516]
 [ 6647.04638672]
 [ 5410.75878906]
 [ 5072.28417969]
 [ 4262.7734375 ]
 [ 6640.87695312]
 [ 5410.75878906]
 [ 5287.16455078]
 [ 5460.13134766]
 [ 4419.37695312]
 [ 4261.80078125]
 [ 4360.99658203]]
DEBUG:root:training time = %d0.224501
INFO:root:frame =4049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =4050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000350952148438
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.968048333333
DEBUG:root: dqn, choose action rondomly, need time 0.00032800000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =4053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000393867492676
INFO:root:frame =4054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000511169433594
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.968016666667
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4490.55419922]
 [ 4821.32910156]
 [ 4465.54150391]
 [ 4977.89501953]
 [ 4410.45458984]
 [ 3948.37036133]
 [ 4797.67626953]
 [ 4844.24169922]
 [ 4821.32910156]
 [ 5684.40917969]
 [ 4605.83935547]
 [ 4613.08251953]
 [ 5758.49755859]
 [ 4563.96582031]
 [ 4904.17089844]
 [ 4284.52685547]]
DEBUG:root:training time = %d0.218626
INFO:root:frame =4057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =4058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000365972518921
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.967985
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =4061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =4062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.967953333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5959.19189453]
 [ 5959.19189453]
 [ 6964.40380859]
 [ 6957.35595703]
 [ 4877.60400391]
 [ 5615.53759766]
 [ 5740.98486328]
 [ 5058.609375  ]
 [ 4946.85205078]
 [ 6643.48388672]
 [ 4662.97949219]
 [ 5674.73095703]
 [ 6948.39892578]
 [ 4662.97949219]
 [ 4272.98095703]
 [ 4415.25537109]]
DEBUG:root:training time = %d0.215855
INFO:root:frame =4065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =4066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000419139862061
DEBUG:root: save sample needs time = 0.000206232070923
INFO:root:random_action_porb = 0.967921666667
DEBUG:root: dqn, choose action rondomly, need time 0.000579999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =4069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =4070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:random_action_porb = 0.96789
DEBUG:root: dqn, choose action rondomly, need time 0.000604999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:training error  = [[ 4525.41992188]
 [ 6444.60888672]
 [ 5607.27099609]
 [ 5400.20458984]
 [ 6665.11181641]
 [ 4578.24365234]
 [ 4531.71240234]
 [ 6528.21386719]
 [ 4755.18994141]
 [ 5376.63818359]
 [ 5607.27099609]
 [ 6529.65380859]
 [ 6550.83935547]
 [ 5467.74658203]
 [ 4931.30712891]
 [ 6540.0546875 ]]
DEBUG:root:training time = %d0.239298
INFO:root:frame =4073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000694990158081
INFO:root:frame =4074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.967858333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =4077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =4078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.967826666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[ 7161.390625  ]
 [ 4422.26611328]
 [ 5626.52001953]
 [ 4691.24658203]
 [ 5089.33837891]
 [ 4771.53417969]
 [ 6234.11621094]
 [ 6872.69726562]
 [ 4799.92529297]
 [ 4474.796875  ]
 [ 7107.97998047]
 [ 7376.12988281]
 [ 6338.68261719]
 [ 7107.97998047]
 [ 5670.86962891]
 [ 5626.52001953]]
DEBUG:root:training time = %d0.229526
INFO:root:frame =4081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =4082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.967795
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =4085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =4086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.967763333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5143.77148438]
 [ 4643.81005859]
 [ 5143.77148438]
 [ 5656.39111328]
 [ 6836.49609375]
 [ 5357.21435547]
 [ 5865.18164062]
 [ 6352.29638672]
 [ 6564.71826172]
 [ 6392.89257812]
 [ 4895.796875  ]
 [ 5749.64550781]
 [ 6407.05273438]
 [ 6492.87353516]
 [ 5574.52148438]
 [ 6942.15234375]]
DEBUG:root:training time = %d0.21118
INFO:root:frame =4089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root:frame =4090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame = 4091 State into memory, numbers recorded 117 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00053882598877
INFO:root:random_action_porb = 0.967731666667
DEBUG:root: dqn, choose action rondomly, need time 0.00016699999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4092current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =4093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =4094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000548839569092
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9677
DEBUG:root: dqn, choose action rondomly, need time 0.000343000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:training error  = [[ 5742.16894531]
 [ 4835.20605469]
 [ 7686.05810547]
 [ 4880.09326172]
 [ 4770.91064453]
 [ 5905.07470703]
 [ 5013.45947266]
 [ 6265.26757812]
 [ 7630.46630859]
 [ 6144.47753906]
 [ 6224.59765625]
 [ 4980.73779297]
 [ 7381.52001953]
 [ 7845.75976562]
 [ 4838.31298828]
 [ 4833.40673828]]
DEBUG:root:training time = %d0.220037
INFO:root:frame =4097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =4098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000296115875244
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.967668333333
DEBUG:root: dqn, choose action rondomly, need time 0.00027
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =4101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =4102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.967636666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 6087.59960938]
 [ 7725.74902344]
 [ 7487.55175781]
 [ 5482.41552734]
 [ 8075.16796875]
 [ 6122.24121094]
 [ 7588.95751953]
 [ 4734.79052734]
 [ 5996.85009766]
 [ 4951.72998047]
 [ 4879.08740234]
 [ 7736.33203125]
 [ 7831.234375  ]
 [ 6082.60986328]
 [ 5782.97851562]
 [ 5957.91015625]]
DEBUG:root:training time = %d0.224856
INFO:root:frame =4105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =4106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.967605
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =4109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00037407875061
INFO:root:frame =4110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446796417236
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:random_action_porb = 0.967573333333
DEBUG:root: dqn, choose action rondomly, need time 0.00028300000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 6683.6015625 ]
 [ 5262.87207031]
 [ 5356.05273438]
 [ 6493.66064453]
 [ 5350.40820312]
 [ 5165.015625  ]
 [ 5245.68847656]
 [ 6823.84521484]
 [ 6455.47119141]
 [ 5303.58007812]
 [ 7084.98681641]
 [ 6954.38330078]
 [ 6775.62890625]
 [ 6794.69384766]
 [ 4897.30029297]
 [ 5288.83349609]]
DEBUG:root:training time = %d0.227488
INFO:root:frame =4113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =4114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249147415161
DEBUG:root: save sample needs time = 0.000115871429443
INFO:root:random_action_porb = 0.967541666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root:frame =4117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =4118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000497102737427
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.96751
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4985.21826172]
 [ 5350.47949219]
 [ 6401.03515625]
 [ 7685.80126953]
 [ 6205.19677734]
 [ 7827.90771484]
 [ 6122.73779297]
 [ 6190.22412109]
 [ 7749.17871094]
 [ 5001.84960938]
 [ 6624.21533203]
 [ 5350.47949219]
 [ 5006.33984375]
 [ 5434.79589844]
 [ 4930.03857422]
 [ 7749.17871094]]
DEBUG:root:training time = %d0.238643
INFO:root:frame =4121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =4122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000258207321167
INFO:root:random_action_porb = 0.967478333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436782836914
INFO:root:frame =4126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.967446666667
DEBUG:root: dqn, choose action rondomly, need time 0.000271999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:training error  = [[ 5645.78320312]
 [ 7129.25830078]
 [ 7264.83642578]
 [ 7428.68505859]
 [ 6871.28076172]
 [ 5528.31835938]
 [ 4894.14013672]
 [ 6638.11181641]
 [ 5160.82275391]
 [ 8008.41455078]
 [ 5592.39990234]
 [ 5805.78125   ]
 [ 5762.31494141]
 [ 5140.14794922]
 [ 5775.31347656]
 [ 7112.48876953]]
DEBUG:root:training time = %d0.210352
INFO:root:frame =4129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000416994094849
INFO:root:frame =4130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.967415
DEBUG:root: dqn, choose action rondomly, need time 0.000325000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =4133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =4134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.967383333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5608.31298828]
 [ 5506.39355469]
 [ 5422.97753906]
 [ 5395.79199219]
 [ 7469.20458984]
 [ 6908.02050781]
 [ 7338.58251953]
 [ 7021.11865234]
 [ 5473.43505859]
 [ 8497.83789062]
 [ 5591.19482422]
 [ 5801.20605469]
 [ 5422.97753906]
 [ 8188.46044922]
 [ 8404.24707031]
 [ 6906.7421875 ]]
DEBUG:root:training time = %d0.208953
INFO:root:frame =4137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =4138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.967351666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =4141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =4142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.96732
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5437.83837891]
 [ 7808.26367188]
 [ 6488.54638672]
 [ 6468.30615234]
 [ 6122.546875  ]
 [ 7847.81445312]
 [ 7889.00439453]
 [ 7182.31445312]
 [ 8130.50488281]
 [ 6990.20117188]
 [ 6798.07519531]
 [ 6066.15087891]
 [ 8130.50488281]
 [ 6697.42041016]
 [ 6331.88134766]
 [ 8065.25439453]]
DEBUG:root:training time = %d0.2068
INFO:root:frame =4145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =4146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame = 4147 State into memory, numbers recorded 118 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000547170639038
INFO:root:random_action_porb = 0.967288333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4148current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =4149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =4150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.967256666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 7301.36035156]
 [ 8552.00488281]
 [ 5774.05175781]
 [ 7620.61669922]
 [ 8779.13183594]
 [ 8336.96972656]
 [ 8422.6328125 ]
 [ 8522.07128906]
 [ 5671.71533203]
 [ 7335.65478516]
 [ 6071.83740234]
 [ 8427.62988281]
 [ 5757.05273438]
 [ 7160.97753906]
 [ 5856.32226562]
 [ 7338.33154297]]
DEBUG:root:training time = %d0.214232
INFO:root:frame =4153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =4154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.967225
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =4157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =4158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226020812988
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.967193333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5887.62109375]
 [ 8839.58007812]
 [ 7738.37207031]
 [ 6955.97119141]
 [ 6723.91992188]
 [ 5517.05126953]
 [ 6972.78027344]
 [ 5740.18945312]
 [ 9305.65429688]
 [ 5525.37792969]
 [ 8836.43652344]
 [ 8453.76074219]
 [ 5898.82861328]
 [ 5898.82861328]
 [ 8663.42382812]
 [ 6605.84765625]]
DEBUG:root:training time = %d0.224717
INFO:root:frame =4161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290155410767
INFO:root:frame =4162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:frame = 4163 State into memory, numbers recorded 119 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:random_action_porb = 0.967161666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4164current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =4165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =4166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:player has been killed for 5 times 
INFO:root:frame =4168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5343.16015625]
 [ 8012.82861328]
 [ 5792.52539062]
 [ 6188.70703125]
 [ 8027.74023438]
 [ 8199.17871094]
 [ 6014.33203125]
 [ 7336.99316406]
 [ 8476.49316406]
 [ 7242.234375  ]
 [ 8476.49316406]
 [ 5889.77539062]
 [ 6286.0390625 ]
 [ 7084.26757812]
 [ 7706.16943359]
 [ 5836.73974609]]
DEBUG:root:training time = %d0.227207
INFO:root:frame =4169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =4170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:frame = 4171 State into memory, numbers recorded 120 action = 2, reward = -1
DEBUG:root: save sample needs time = 0.000414133071899
INFO:root:random_action_porb = 0.96713
DEBUG:root: dqn, choose action rondomly, need time 0.000201000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4172current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =4173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =4174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.967098333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5637.27490234]
 [ 7608.38818359]
 [ 5824.39892578]
 [ 8537.92285156]
 [ 7354.06738281]
 [ 7658.70703125]
 [ 7334.21191406]
 [ 9622.12011719]
 [ 7250.921875  ]
 [ 8075.23388672]
 [ 7640.38623047]
 [ 8157.38378906]
 [ 5985.81396484]
 [ 5878.66992188]
 [ 7870.75683594]
 [ 9950.08691406]]
DEBUG:root:training time = %d0.2053
INFO:root:frame =4177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =4178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame = 4179 State into memory, numbers recorded 121 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000548124313354
INFO:root:random_action_porb = 0.967066666667
DEBUG:root: dqn, choose action rondomly, need time 0.00031700000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4180current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.00037693977356
INFO:root:frame =4181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =4182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.967035
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5920.84423828]
 [ 7724.8046875 ]
 [ 6087.61865234]
 [ 7465.17529297]
 [ 6004.13085938]
 [ 6662.18212891]
 [ 7597.27587891]
 [ 5804.77685547]
 [ 7003.39355469]
 [ 6301.32080078]
 [ 6143.08056641]
 [ 6686.81542969]
 [ 7530.30761719]
 [ 6554.57470703]
 [ 6129.80810547]
 [ 6186.44091797]]
DEBUG:root:training time = %d0.208489
INFO:root:frame =4185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000424861907959
INFO:root:frame =4186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000327110290527
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.967003333333
DEBUG:root: dqn, choose action rondomly, need time 0.000326999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:frame =4189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488996505737
INFO:root:frame =4190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000260829925537
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.966971666667
DEBUG:root: dqn, choose action rondomly, need time 0.000308999999987
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 9815.45898438]
 [ 9815.45898438]
 [ 6497.30078125]
 [ 9369.421875  ]
 [ 6023.27197266]
 [ 9807.33398438]
 [ 6730.28759766]
 [ 6156.54003906]
 [ 6212.46826172]
 [ 6156.54003906]
 [ 6455.15722656]
 [ 7555.96435547]
 [ 7721.95117188]
 [ 6148.76513672]
 [ 9369.421875  ]
 [ 9650.6640625 ]]
DEBUG:root:training time = %d0.227546
INFO:root:frame =4193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000358104705811
INFO:root:frame =4194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.96694
DEBUG:root: dqn, choose action rondomly, need time 0.00028300000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000351905822754
INFO:root:frame =4197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =4198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000328063964844
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.966908333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6665.64990234]
 [  9358.41308594]
 [  8946.15332031]
 [  6237.41308594]
 [  9576.2421875 ]
 [  7611.64648438]
 [  9237.62207031]
 [  9838.54785156]
 [  6676.45800781]
 [  9764.15136719]
 [  6460.35644531]
 [  7355.42822266]
 [  9634.16992188]
 [  9838.54785156]
 [ 10004.41894531]
 [  9237.62207031]]
DEBUG:root:training time = %d0.216994
INFO:root:frame =4201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248193740845
INFO:root:frame =4202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000358819961548
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.966876666667
DEBUG:root: dqn, choose action rondomly, need time 0.000506999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =4205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =4206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame = 4207 State into memory, numbers recorded 122 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000556945800781
INFO:root:random_action_porb = 0.966845
DEBUG:root: dqn, choose action rondomly, need time 0.000523999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4208current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:training error  = [[ 6943.33251953]
 [ 9234.99414062]
 [ 6368.76855469]
 [ 9130.67480469]
 [ 9736.28320312]
 [ 6550.56298828]
 [ 6754.88525391]
 [ 9712.49707031]
 [ 6453.17626953]
 [ 9378.83007812]
 [ 6897.65527344]
 [ 9389.8984375 ]
 [ 9405.96875   ]
 [ 8783.13574219]
 [ 9317.10351562]
 [ 9357.37402344]]
DEBUG:root:training time = %d0.225186
INFO:root:frame =4209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame =4210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.966813333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =4213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023078918457
INFO:root:frame =4214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.966781666667
DEBUG:root: dqn, choose action rondomly, need time 0.000163000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9403.45898438]
 [  8967.36425781]
 [  9070.33007812]
 [  8731.06835938]
 [  9563.99023438]
 [  9067.35449219]
 [  9070.33007812]
 [  9753.58789062]
 [  9693.11425781]
 [  9067.35449219]
 [ 10094.09277344]
 [  9251.16601562]
 [  9477.3984375 ]
 [  9563.99023438]
 [  9282.37695312]
 [  9513.05859375]]
DEBUG:root:training time = %d0.219869
INFO:root:frame =4217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =4218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000312805175781
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:random_action_porb = 0.96675
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342845916748
INFO:root:frame =4221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000424146652222
INFO:root:frame =4222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.966718333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 6735.93701172]
 [ 7032.53808594]
 [ 7567.53466797]
 [ 7606.30126953]
 [ 6925.19775391]
 [ 7044.68408203]
 [ 7478.97705078]
 [ 7928.02001953]
 [ 6806.53222656]
 [ 7614.05371094]
 [ 6949.29443359]
 [ 6947.25927734]
 [ 7001.79980469]
 [ 6816.34472656]
 [ 7045.75      ]
 [ 7920.39160156]]
DEBUG:root:training time = %d0.221443
INFO:root:frame =4225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =4226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.966686666667
DEBUG:root: dqn, choose action rondomly, need time 0.000434999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =4229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =4230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.966655
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 7702.39794922]
 [ 8051.09716797]
 [ 7380.72265625]
 [ 7264.41992188]
 [ 7726.13525391]
 [ 7365.00048828]
 [ 7709.36279297]
 [ 7256.05761719]
 [ 7373.13183594]
 [ 7425.94970703]
 [ 7425.94970703]
 [ 7162.46484375]
 [ 7300.15039062]
 [ 8017.50585938]
 [ 7900.43652344]
 [ 7668.58105469]]
DEBUG:root:training time = %d0.211463
INFO:root:frame =4233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =4234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.966623333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =4237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =4238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.966591666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 7500.71875   ]
 [ 7010.68896484]
 [ 6586.69335938]
 [ 8067.95166016]
 [ 7361.20849609]
 [ 7811.45703125]
 [ 7604.23583984]
 [ 7620.42480469]
 [ 6776.97558594]
 [ 7238.24560547]
 [ 7404.54785156]
 [ 7761.32617188]
 [ 6596.44580078]
 [ 7595.06298828]
 [ 8931.45019531]
 [ 7679.12451172]]
DEBUG:root:training time = %d0.223711
INFO:root:frame =4241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =4242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000216007232666
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:random_action_porb = 0.96656
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =4245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =4246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475883483887
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.966528333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7094.40185547]
 [ 10449.34667969]
 [ 10514.08398438]
 [ 10239.70117188]
 [  7595.14794922]
 [  7267.45849609]
 [  6825.80126953]
 [  7670.63378906]
 [  6994.59033203]
 [  8610.89746094]
 [ 11406.12011719]
 [  8134.46777344]
 [  6825.80126953]
 [  7338.75      ]
 [  7269.20703125]
 [  6962.85546875]]
DEBUG:root:training time = %d0.236106
INFO:root:frame =4249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =4250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.966496666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =4253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =4254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.966465
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8148.91894531]
 [ 10608.24609375]
 [  8830.37792969]
 [  8151.18896484]
 [  8376.80761719]
 [ 10263.28320312]
 [  8815.47265625]
 [ 10886.75195312]
 [  6281.10449219]
 [  7304.09326172]
 [  8531.49414062]
 [  8237.71191406]
 [  8725.3203125 ]
 [  8542.20898438]
 [  7242.296875  ]
 [  8830.37792969]]
DEBUG:root:training time = %d0.219147
INFO:root:frame =4257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =4258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.966433333333
DEBUG:root: dqn, choose action rondomly, need time 0.000166000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root:frame =4261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224828720093
INFO:root:frame =4262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000224113464355
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.966401666667
DEBUG:root: dqn, choose action rondomly, need time 0.000158999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9206.29980469]
 [  8685.16113281]
 [  9814.05566406]
 [  7500.57080078]
 [ 10407.01367188]
 [  9847.21875   ]
 [ 10082.1015625 ]
 [  7831.08349609]
 [ 10049.37695312]
 [  9820.24902344]
 [ 10082.1015625 ]
 [  7539.22949219]
 [  7213.73583984]
 [  7831.08349609]
 [  7914.39599609]
 [ 10197.37597656]]
DEBUG:root:training time = %d0.237151
INFO:root:frame =4265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =4266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.96637
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =4269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =4270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.966338333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8159.10400391]
 [  7623.45117188]
 [ 10113.74902344]
 [  9209.81347656]
 [  9940.08007812]
 [  9459.67578125]
 [  9330.09277344]
 [  8853.93261719]
 [ 10113.74902344]
 [ 11376.20703125]
 [  8853.93261719]
 [  8971.64160156]
 [  9649.9921875 ]
 [  7861.90039062]
 [  7624.83691406]
 [ 10288.12988281]]
DEBUG:root:training time = %d0.210565
INFO:root:frame =4273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =4274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame = 4275 State into memory, numbers recorded 123 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:random_action_porb = 0.966306666667
DEBUG:root: dqn, choose action rondomly, need time 0.000181999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4276current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root:frame =4277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =4278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.966275
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9202.71582031]
 [  8990.19726562]
 [ 11112.02148438]
 [  9221.25097656]
 [  8753.78125   ]
 [  8964.40527344]
 [  8192.15039062]
 [  8252.78613281]
 [ 11112.02148438]
 [  8312.82226562]
 [  8636.44824219]
 [  8736.06445312]
 [  8542.00585938]
 [ 11336.296875  ]
 [  7720.79296875]
 [ 11244.1015625 ]]
DEBUG:root:training time = %d0.221445
INFO:root:frame =4281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =4282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.966243333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =4285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root:frame =4286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294923782349
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.966211666667
DEBUG:root: dqn, choose action rondomly, need time 0.00027
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8904.03710938]
 [  8432.51660156]
 [  9141.89941406]
 [  9163.48144531]
 [  9252.59863281]
 [ 12565.96679688]
 [  8150.81445312]
 [  7954.88916016]
 [ 10553.875     ]
 [  8041.15478516]
 [  7949.40283203]
 [  7953.12548828]
 [ 10388.83984375]
 [ 11980.76171875]
 [ 10526.93066406]
 [  9084.19335938]]
DEBUG:root:training time = %d0.219942
INFO:root:frame =4289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280857086182
INFO:root:frame =4290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.96618
DEBUG:root: dqn, choose action rondomly, need time 0.000186999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root:frame =4293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:frame =4294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042986869812
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.966148333333
INFO:root:dqn select action Tensor("ArgMax_19:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013469
INFO:root:action choosen by dqn [4]
INFO:root:frame =4296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9961.63378906]
 [ 11181.10058594]
 [ 10460.48046875]
 [  9581.66601562]
 [ 12129.85449219]
 [ 10681.34375   ]
 [  8570.84472656]
 [ 10360.01953125]
 [  8451.875     ]
 [  9961.63378906]
 [  9393.68457031]
 [ 10085.45996094]
 [ 12129.85449219]
 [  7978.51074219]
 [ 10185.32324219]
 [  9987.38183594]]
DEBUG:root:training time = %d0.210224
INFO:root:frame =4297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290155410767
INFO:root:frame =4298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.966116666667
INFO:root:dqn select action Tensor("ArgMax_20:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012336
INFO:root:action choosen by dqn [2]
INFO:root:frame =4300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000161170959473
INFO:root:frame =4301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =4302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229120254517
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.966085
DEBUG:root: dqn, choose action rondomly, need time 0.00022100000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000146150588989
INFO:root:training error  = [[  8181.63525391]
 [ 11836.78613281]
 [  9605.22070312]
 [  8764.01757812]
 [  8225.86132812]
 [  9306.12597656]
 [  8577.35546875]
 [  9034.37207031]
 [  8002.73535156]
 [  9284.96484375]
 [ 10263.13476562]
 [  8181.63525391]
 [ 11236.54394531]
 [  9147.03613281]
 [  9220.89941406]
 [  9213.8671875 ]]
DEBUG:root:training time = %d0.225302
INFO:root:frame =4305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =4306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255107879639
DEBUG:root: save sample needs time = 0.000117778778076
INFO:root:random_action_porb = 0.966053333333
DEBUG:root: dqn, choose action rondomly, need time 0.000275000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162839889526
INFO:root:frame =4309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:frame =4310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.966021666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9574.85644531]
 [ 11211.14453125]
 [  9840.75097656]
 [ 13014.26464844]
 [ 10361.36132812]
 [ 10429.09179688]
 [ 11152.51464844]
 [ 12439.16503906]
 [  9941.93066406]
 [  9704.96777344]
 [ 12668.31054688]
 [ 13152.74707031]
 [ 11700.3359375 ]
 [ 12782.93554688]
 [  8515.76171875]
 [  8537.24609375]]
DEBUG:root:training time = %d0.231454
INFO:root:frame =4313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =4314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000550985336304
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.96599
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000412225723267
INFO:root:frame =4317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000386953353882
INFO:root:frame =4318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.965958333333
DEBUG:root: dqn, choose action rondomly, need time 0.000159999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12130.33886719]
 [ 12844.53710938]
 [ 13367.30566406]
 [  8919.52539062]
 [ 12844.53710938]
 [ 13319.58886719]
 [ 12130.33886719]
 [  7383.68066406]
 [ 10880.05371094]
 [  9173.93066406]
 [ 12565.74804688]
 [  8524.86621094]
 [  7383.68066406]
 [ 12898.74316406]
 [  9795.27246094]
 [ 10805.89648438]]
DEBUG:root:training time = %d0.212176
INFO:root:frame =4321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =4322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.965926666667
DEBUG:root: dqn, choose action rondomly, need time 0.000182000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000166177749634
INFO:root:frame =4325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =4326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame = 4327 State into memory, numbers recorded 124 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000553131103516
INFO:root:random_action_porb = 0.965895
INFO:root:dqn select action Tensor("ArgMax_21:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013101
INFO:root:action choosen by dqn [1]
INFO:root:frame =4328current_observation done, NOT record action [1], reward = 0
DEBUG:root: save sample needs time = 0.000381946563721
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8956.89453125]
 [  9164.83691406]
 [  8803.16699219]
 [ 11954.26757812]
 [ 11533.00878906]
 [ 12261.04785156]
 [ 13416.83300781]
 [  9489.80859375]
 [  9713.12304688]
 [  8956.89453125]
 [  8986.6328125 ]
 [  8534.35839844]
 [ 10333.        ]
 [  8429.49023438]
 [  8986.6328125 ]
 [ 11543.52441406]]
DEBUG:root:training time = %d0.211133
INFO:root:frame =4329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253200531006
INFO:root:frame =4330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277996063232
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.965863333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =4333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000484943389893
INFO:root:frame =4334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:random_action_porb = 0.965831666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9000.43164062]
 [ 12928.06738281]
 [  8967.29492188]
 [ 10063.89550781]
 [ 10129.125     ]
 [ 10287.015625  ]
 [ 12556.93652344]
 [ 10930.25292969]
 [ 10195.67480469]
 [ 10083.30273438]
 [  8967.29492188]
 [  9398.44140625]
 [ 12556.93652344]
 [  8695.01660156]
 [ 10444.08105469]
 [ 10440.13964844]]
DEBUG:root:training time = %d0.195382
INFO:root:frame =4337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =4338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476121902466
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9658
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =4341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =4342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.965768333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12203.3984375 ]
 [ 12298.62597656]
 [  9202.80957031]
 [  9328.04199219]
 [  8958.2109375 ]
 [  9694.96484375]
 [  9430.20703125]
 [ 10068.28027344]
 [  9230.53710938]
 [  9252.31738281]
 [ 11832.90917969]
 [ 10343.15332031]
 [  9088.91796875]
 [ 11732.62890625]
 [  9338.98535156]
 [  9119.13085938]]
DEBUG:root:training time = %d0.226345
INFO:root:frame =4345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root:frame =4346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
DEBUG:root: save sample needs time = 0.000167846679688
INFO:root:random_action_porb = 0.965736666667
DEBUG:root: dqn, choose action rondomly, need time 0.000169
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:frame =4349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =4350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root:random_action_porb = 0.965705
DEBUG:root: dqn, choose action rondomly, need time 0.000390999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12123.48339844]
 [ 13880.015625  ]
 [  9925.67578125]
 [ 11456.86425781]
 [ 14659.70507812]
 [ 10852.11035156]
 [ 11252.36132812]
 [ 10922.3671875 ]
 [ 12217.69726562]
 [ 13553.96777344]
 [ 10852.11035156]
 [  8793.54882812]
 [  9525.73144531]
 [ 12349.44433594]
 [ 11177.43457031]
 [ 14261.81738281]]
DEBUG:root:training time = %d0.210503
INFO:root:frame =4353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =4354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.965673333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318765640259
INFO:root:frame =4357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000514984130859
INFO:root:frame =4358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.965641666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[ 12553.51757812]
 [ 12293.86132812]
 [  9600.12402344]
 [  9422.78808594]
 [  9070.84179688]
 [  9582.28808594]
 [ 10209.60742188]
 [ 11049.95703125]
 [ 10107.39160156]
 [  9070.84179688]
 [ 10810.46582031]
 [ 10054.86035156]
 [ 12945.8671875 ]
 [ 10885.40234375]
 [ 10973.6875    ]
 [ 10946.16113281]]
DEBUG:root:training time = %d0.225333
INFO:root:frame =4361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =4362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436782836914
DEBUG:root: save sample needs time = 0.000115871429443
INFO:root:random_action_porb = 0.96561
DEBUG:root: dqn, choose action rondomly, need time 0.000187000000011
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:frame =4365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =4366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:random_action_porb = 0.965578333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12101.85351562]
 [ 11805.19921875]
 [  8784.73730469]
 [  9954.69042969]
 [ 13750.99804688]
 [ 12918.43652344]
 [  9674.68652344]
 [ 12443.63085938]
 [ 13000.37011719]
 [ 11948.52832031]
 [ 14416.67480469]
 [ 12563.39453125]
 [  9902.87402344]
 [ 10765.65820312]
 [ 10117.89941406]
 [ 15196.70117188]]
DEBUG:root:training time = %d0.218417
INFO:root:frame =4369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:frame =4370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000336170196533
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.965546666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =4373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =4374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.965515
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:training error  = [[ 11190.86132812]
 [ 15119.96289062]
 [ 10258.53417969]
 [ 11503.55761719]
 [ 10769.48339844]
 [ 10541.46386719]
 [ 10258.53417969]
 [ 13752.40039062]
 [  9879.9765625 ]
 [ 12910.19726562]
 [ 10865.03417969]
 [  9915.38964844]
 [ 13457.44433594]
 [ 14709.82226562]
 [ 11507.95703125]
 [ 14904.08203125]]
DEBUG:root:training time = %d0.230436
INFO:root:frame =4377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =4378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264167785645
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:random_action_porb = 0.965483333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =4381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000418901443481
INFO:root:frame =4382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.965451666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14213.80859375]
 [ 14213.80859375]
 [ 13737.54492188]
 [ 12203.64160156]
 [ 10377.71972656]
 [ 14974.47558594]
 [ 14033.890625  ]
 [ 13408.57714844]
 [ 13330.80566406]
 [ 11127.15917969]
 [ 12155.546875  ]
 [ 14097.93847656]
 [ 14232.44335938]
 [ 14067.89453125]
 [ 13519.91015625]
 [ 14042.42382812]]
DEBUG:root:training time = %d0.226364
INFO:root:frame =4385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =4386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.96542
DEBUG:root: dqn, choose action rondomly, need time 0.000324000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =4389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488042831421
INFO:root:frame =4390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042986869812
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.965388333333
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14756.67382812]
 [ 10801.78613281]
 [ 14700.05273438]
 [ 12192.61328125]
 [ 14589.05371094]
 [ 12257.77636719]
 [ 11480.08105469]
 [ 13210.37597656]
 [ 13046.75976562]
 [ 14200.24804688]
 [ 12757.1953125 ]
 [ 13089.79589844]
 [ 10683.81640625]
 [ 10455.21191406]
 [ 10732.85351562]
 [ 10983.91992188]]
DEBUG:root:training time = %d0.216573
INFO:root:frame =4393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =4394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000496864318848
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.965356666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =4397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =4398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root:random_action_porb = 0.965325
DEBUG:root: dqn, choose action rondomly, need time 0.00022700000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12067.47265625]
 [ 11228.08203125]
 [ 13029.55957031]
 [ 11671.12011719]
 [ 13605.29199219]
 [ 15808.08984375]
 [ 10996.71777344]
 [ 16000.953125  ]
 [ 12541.8125    ]
 [ 12854.47167969]
 [ 10567.17285156]
 [ 13546.09570312]
 [ 16218.04785156]
 [ 11924.70898438]
 [ 10631.21582031]
 [ 10554.80371094]]
DEBUG:root:training time = %d0.233305
INFO:root:frame =4401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =4402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428199768066
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.965293333333
INFO:root:dqn select action Tensor("ArgMax_22:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01089
INFO:root:action choosen by dqn [1]
INFO:root:frame =4404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame =4405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000402927398682
INFO:root:frame =4406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000261068344116
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.965261666667
DEBUG:root: dqn, choose action rondomly, need time 0.000342000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14613.62792969]
 [ 14406.62207031]
 [ 11862.75195312]
 [ 14951.00292969]
 [ 10619.69042969]
 [ 14749.91308594]
 [ 11287.73925781]
 [ 15147.08300781]
 [ 10602.61328125]
 [ 11654.24609375]
 [ 14872.65429688]
 [ 12460.98535156]
 [ 15181.95800781]
 [ 12184.66210938]
 [ 11167.99023438]
 [ 13651.26367188]]
DEBUG:root:training time = %d0.214333
INFO:root:frame =4409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =4410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00022292137146
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.96523
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433206558228
INFO:root:frame =4414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.965198333333
DEBUG:root: dqn, choose action rondomly, need time 0.000336000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:training error  = [[ 11373.52441406]
 [ 14141.9765625 ]
 [ 15637.30078125]
 [ 11359.57324219]
 [ 12077.34472656]
 [ 13708.97363281]
 [ 10316.65234375]
 [ 14364.01660156]
 [ 15517.91503906]
 [ 10316.65234375]
 [ 11450.88085938]
 [ 16270.91503906]
 [ 14472.51269531]
 [ 15635.25585938]
 [ 11320.80957031]
 [ 13097.00292969]]
DEBUG:root:training time = %d0.218557
INFO:root:frame =4417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =4418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.965166666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =4421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =4422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.965135
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16626.546875  ]
 [ 13789.90332031]
 [ 16595.8671875 ]
 [ 14798.84765625]
 [ 15990.79394531]
 [ 11447.45898438]
 [ 16084.29003906]
 [ 16478.63671875]
 [ 14142.76074219]
 [ 14645.875     ]
 [ 14252.25585938]
 [ 16340.84082031]
 [ 15827.95605469]
 [ 10986.78613281]
 [ 16413.04492188]
 [ 10849.38867188]]
DEBUG:root:training time = %d0.223708
INFO:root:frame =4425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:frame =4426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.965103333333
DEBUG:root: dqn, choose action rondomly, need time 0.000185000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000173807144165
INFO:root:frame =4429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =4430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000103950500488
INFO:root:random_action_porb = 0.965071666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:training error  = [[ 15547.24707031]
 [ 13759.53027344]
 [ 13439.40917969]
 [ 15729.88085938]
 [ 11836.91894531]
 [ 10816.609375  ]
 [ 14115.65625   ]
 [ 13851.58300781]
 [ 12147.44628906]
 [ 13245.8125    ]
 [ 12542.55078125]
 [ 11428.11132812]
 [ 12919.76855469]
 [ 12303.47265625]
 [ 15544.44628906]
 [ 13164.39746094]]
DEBUG:root:training time = %d0.242072
INFO:root:frame =4433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280141830444
INFO:root:frame =4434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308990478516
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.96504
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =4437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =4438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.965008333333
DEBUG:root: dqn, choose action rondomly, need time 0.000331000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000361919403076
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12716.80175781]
 [ 13522.23730469]
 [ 14696.26464844]
 [ 12155.7890625 ]
 [ 12452.97460938]
 [ 12452.97460938]
 [ 13444.10839844]
 [ 11893.45703125]
 [ 12651.85546875]
 [ 12680.73339844]
 [ 13134.97265625]
 [ 13363.21289062]
 [ 13305.56054688]
 [ 13039.67773438]
 [ 15160.45703125]
 [ 12423.97558594]]
DEBUG:root:training time = %d0.228191
INFO:root:frame =4441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =4442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000831127166748
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.964976666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =4446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.964945
DEBUG:root: dqn, choose action rondomly, need time 0.000393000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11914.98046875]
 [ 11461.01953125]
 [ 12366.67773438]
 [ 13994.09277344]
 [ 12004.4765625 ]
 [ 12301.27929688]
 [ 11923.29589844]
 [ 17166.88476562]
 [ 15021.38671875]
 [ 16774.9921875 ]
 [ 13949.01660156]
 [ 17396.49023438]
 [ 12307.07519531]
 [ 11387.796875  ]
 [ 16754.88867188]
 [ 14916.18554688]]
DEBUG:root:training time = %d0.240112
INFO:root:frame =4449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =4450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:random_action_porb = 0.964913333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =4453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =4454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000418901443481
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.964881666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16752.04492188]
 [ 12369.06738281]
 [ 14011.94726562]
 [ 16469.54882812]
 [ 11839.25683594]
 [ 17230.47265625]
 [ 10688.56152344]
 [ 15586.44921875]
 [ 12118.48339844]
 [ 12027.06347656]
 [ 17295.203125  ]
 [ 14022.41015625]
 [ 12027.06347656]
 [ 12802.29296875]
 [ 12410.80859375]
 [ 11900.75390625]]
DEBUG:root:training time = %d0.237458
INFO:root:frame =4457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =4458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000244855880737
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.96485
DEBUG:root: dqn, choose action rondomly, need time 0.000191999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000136852264404
INFO:root:frame =4461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =4462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:random_action_porb = 0.964818333333
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16431.41015625]
 [ 17094.54101562]
 [ 14125.05566406]
 [ 12607.24316406]
 [ 11934.44238281]
 [ 13795.06445312]
 [ 16747.87304688]
 [ 16564.80859375]
 [ 15948.06445312]
 [ 14481.73632812]
 [ 16859.3359375 ]
 [ 16643.9609375 ]
 [ 16431.41015625]
 [ 12652.6796875 ]
 [ 17143.86132812]
 [ 16313.76269531]]
DEBUG:root:training time = %d0.217237
INFO:root:frame =4465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =4466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274181365967
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:random_action_porb = 0.964786666667
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =4469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =4470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.964755
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12996.83496094]
 [ 14832.81347656]
 [ 13899.58105469]
 [ 16966.58984375]
 [ 16083.20605469]
 [ 14832.81347656]
 [ 13899.58105469]
 [ 12086.57617188]
 [ 15214.46386719]
 [ 14858.3359375 ]
 [ 15659.56542969]
 [ 16087.41699219]
 [ 15361.47265625]
 [ 15801.828125  ]
 [ 15323.49023438]
 [ 13899.58105469]]
DEBUG:root:training time = %d0.204219
INFO:root:frame =4473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:frame =4474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.964723333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =4477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000480175018311
INFO:root:frame =4478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.964691666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320196151733
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13745.21484375]
 [ 12632.47558594]
 [ 13232.18847656]
 [ 13283.57519531]
 [ 13598.14453125]
 [ 13333.765625  ]
 [ 15911.45703125]
 [ 14715.59765625]
 [ 15255.265625  ]
 [ 13217.64550781]
 [ 15562.92773438]
 [ 14266.54101562]
 [ 13804.87304688]
 [ 12319.91601562]
 [ 14266.54101562]
 [ 14369.25488281]]
DEBUG:root:training time = %d0.217901
INFO:root:frame =4481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =4482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.96466
DEBUG:root: dqn, choose action rondomly, need time 0.000311999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =4485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =4486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.964628333333
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 19421.51171875]
 [ 15808.08984375]
 [ 18780.0390625 ]
 [ 12448.47949219]
 [ 13825.6484375 ]
 [ 13692.08496094]
 [ 12931.23242188]
 [ 12762.7109375 ]
 [ 20231.10351562]
 [ 13091.359375  ]
 [ 13530.13085938]
 [ 13391.39453125]
 [ 12687.96582031]
 [ 16249.21582031]
 [ 20217.35546875]
 [ 14792.16601562]]
DEBUG:root:training time = %d0.214045
INFO:root:frame =4489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =4490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000391960144043
INFO:root:frame = 4491 State into memory, numbers recorded 125 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:random_action_porb = 0.964596666667
INFO:root:dqn select action Tensor("ArgMax_23:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013022
INFO:root:action choosen by dqn [3]
INFO:root:frame =4492current_observation done, NOT record action [3], reward = 0
DEBUG:root: save sample needs time = 0.000377893447876
INFO:root:frame =4493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:frame =4494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 9.29832458496e-05
INFO:root:random_action_porb = 0.964565
DEBUG:root: dqn, choose action rondomly, need time 0.000157999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000130891799927
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13743.61230469]
 [ 13178.26660156]
 [ 19197.0625    ]
 [ 13105.33007812]
 [ 12923.515625  ]
 [ 18534.0703125 ]
 [ 18767.59570312]
 [ 18183.49609375]
 [ 13178.26660156]
 [ 14555.75097656]
 [ 13743.61230469]
 [ 13178.26660156]
 [ 14173.37890625]
 [ 13632.89941406]
 [ 17906.56835938]
 [ 14282.64257812]]
DEBUG:root:training time = %d0.221153
INFO:root:frame =4497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =4498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:random_action_porb = 0.964533333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =4501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000494003295898
INFO:root:frame =4502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame = 4503 State into memory, numbers recorded 126 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000542879104614
INFO:root:random_action_porb = 0.964501666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4504current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13441.44726562]
 [ 17648.36914062]
 [ 14159.54785156]
 [ 14300.6796875 ]
 [ 13940.48339844]
 [ 18064.44921875]
 [ 17253.49023438]
 [ 14159.54785156]
 [ 16956.79492188]
 [ 13399.30566406]
 [ 17253.49023438]
 [ 17692.1171875 ]
 [ 17268.5       ]
 [ 16958.00390625]
 [ 17487.4140625 ]
 [ 13726.2734375 ]]
DEBUG:root:training time = %d0.206999
INFO:root:frame =4505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =4506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000343084335327
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.96447
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =4509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448226928711
INFO:root:frame =4510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.964438333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 19295.55664062]
 [ 17966.47070312]
 [ 18036.04492188]
 [ 18447.2890625 ]
 [ 17620.87695312]
 [ 17494.1953125 ]
 [ 18240.625     ]
 [ 13188.97460938]
 [ 17447.79101562]
 [ 16403.19335938]
 [ 15886.4609375 ]
 [ 20000.14648438]
 [ 13916.28027344]
 [ 16514.94726562]
 [ 16362.25683594]
 [ 21178.4921875 ]]
DEBUG:root:training time = %d0.210215
INFO:root:frame =4513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =4514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame = 4515 State into memory, numbers recorded 127 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:random_action_porb = 0.964406666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4516current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =4517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =4518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.964375
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17647.52734375]
 [ 16893.27148438]
 [ 14156.46777344]
 [ 14485.0859375 ]
 [ 15720.29882812]
 [ 15260.15039062]
 [ 14832.63476562]
 [ 15423.50585938]
 [ 17571.91015625]
 [ 16988.5390625 ]
 [ 14658.84863281]
 [ 16098.25683594]
 [ 14658.84863281]
 [ 13708.25878906]
 [ 12655.92089844]
 [ 15423.50585938]]
DEBUG:root:training time = %d0.210761
INFO:root:frame =4521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000411033630371
INFO:root:frame =4522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000360012054443
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:random_action_porb = 0.964343333333
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =4525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =4526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.964311666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16859.71679688]
 [ 18272.55859375]
 [ 17123.79296875]
 [ 18002.02734375]
 [ 15473.87792969]
 [ 16397.87890625]
 [ 14102.02636719]
 [ 18272.55859375]
 [ 18250.78320312]
 [ 15042.81933594]
 [ 16734.03710938]
 [ 15437.03125   ]
 [ 13445.296875  ]
 [ 18329.89453125]
 [ 18471.50390625]
 [ 15626.28222656]]
DEBUG:root:training time = %d0.213453
INFO:root:frame =4529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =4530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.96428
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:frame =4533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =4534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.964248333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17215.09375   ]
 [ 20189.03710938]
 [ 17015.98046875]
 [ 16097.20410156]
 [ 18995.11132812]
 [ 15995.703125  ]
 [ 15889.10742188]
 [ 14155.9453125 ]
 [ 14556.63476562]
 [ 15547.3984375 ]
 [ 14567.12304688]
 [ 18874.50585938]
 [ 16541.37695312]
 [ 13607.37011719]
 [ 19352.77734375]
 [ 13607.37011719]]
DEBUG:root:training time = %d0.225534
INFO:root:frame =4537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265836715698
INFO:root:frame =4538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277996063232
DEBUG:root: save sample needs time = 0.00011682510376
INFO:root:random_action_porb = 0.964216666667
DEBUG:root: dqn, choose action rondomly, need time 0.000200000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root:frame =4541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000486850738525
INFO:root:frame =4542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.964185
DEBUG:root: dqn, choose action rondomly, need time 0.000233999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:training error  = [[ 15992.4921875 ]
 [ 14716.07128906]
 [ 19262.47070312]
 [ 15229.28320312]
 [ 18726.61328125]
 [ 17901.27734375]
 [ 20309.3125    ]
 [ 19140.27734375]
 [ 21985.80859375]
 [ 15426.84082031]
 [ 16237.39160156]
 [ 14093.79394531]
 [ 21744.87304688]
 [ 15229.28320312]
 [ 19083.37109375]
 [ 18726.61328125]]
DEBUG:root:training time = %d0.21811
INFO:root:frame =4545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =4546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.964153333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =4549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root:frame =4550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.964121666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 20572.21484375]
 [ 20266.40039062]
 [ 17894.61328125]
 [ 20775.88671875]
 [ 21227.05273438]
 [ 21776.92578125]
 [ 20751.75390625]
 [ 17558.83789062]
 [ 19068.0625    ]
 [ 14687.77148438]
 [ 21003.26953125]
 [ 20887.51757812]
 [ 16777.77539062]
 [ 16580.90039062]
 [ 21280.93945312]
 [ 14472.27832031]]
DEBUG:root:training time = %d0.225236
INFO:root:frame =4553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =4554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000266790390015
INFO:root:frame = 4555 State into memory, numbers recorded 128 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:random_action_porb = 0.96409
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4556current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =4557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =4558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame = 4559 State into memory, numbers recorded 129 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000541925430298
INFO:root:random_action_porb = 0.964058333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4560current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:training error  = [[ 19035.71289062]
 [ 20133.15820312]
 [ 19757.40429688]
 [ 20120.7578125 ]
 [ 17678.74023438]
 [ 20769.69335938]
 [ 18308.61328125]
 [ 18651.58398438]
 [ 16285.33691406]
 [ 17633.77734375]
 [ 19298.13476562]
 [ 17382.25976562]
 [ 16361.9453125 ]
 [ 18090.18359375]
 [ 16827.33398438]
 [ 20176.2734375 ]]
DEBUG:root:training time = %d0.21896
INFO:root:frame =4561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =4562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.000125885009766
INFO:root:random_action_porb = 0.964026666667
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root:frame =4565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =4566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.963995
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 21541.50976562]
 [ 17997.375     ]
 [ 19082.69726562]
 [ 18079.67773438]
 [ 16363.44433594]
 [ 21516.43554688]
 [ 17808.30273438]
 [ 18297.3828125 ]
 [ 21541.50976562]
 [ 18716.52539062]
 [ 17455.14453125]
 [ 16773.85351562]
 [ 15611.08691406]
 [ 15428.35742188]
 [ 18689.14648438]
 [ 18455.18359375]]
DEBUG:root:training time = %d0.234977
INFO:root:frame =4569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =4570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.963963333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000408172607422
INFO:root:frame =4574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.963931666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000401973724365
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 19539.00195312]
 [ 16151.33203125]
 [ 17227.84375   ]
 [ 17806.08789062]
 [ 17259.83984375]
 [ 21688.67382812]
 [ 16474.5625    ]
 [ 15915.83105469]
 [ 17056.83203125]
 [ 16467.79492188]
 [ 16212.01660156]
 [ 15680.65234375]
 [ 23123.74609375]
 [ 17819.578125  ]
 [ 20627.36914062]
 [ 15237.41894531]]
DEBUG:root:training time = %d0.217842
INFO:root:frame =4577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =4578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9639
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =4581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000407934188843
INFO:root:frame =4582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.963868333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 20634.3125    ]
 [ 18296.72265625]
 [ 23150.11328125]
 [ 17904.28320312]
 [ 23150.11328125]
 [ 16265.71386719]
 [ 18540.91796875]
 [ 19847.62304688]
 [ 19668.76171875]
 [ 16863.45703125]
 [ 15300.89257812]
 [ 14672.62597656]
 [ 17538.3984375 ]
 [ 21041.85351562]
 [ 18540.91796875]
 [ 16339.09375   ]]
DEBUG:root:training time = %d0.2189
INFO:root:frame =4585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =4586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.963836666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =4589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =4590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.963805
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:training error  = [[ 16806.18554688]
 [ 22726.59375   ]
 [ 21188.65429688]
 [ 21038.3125    ]
 [ 19167.171875  ]
 [ 20614.046875  ]
 [ 20192.92382812]
 [ 20255.41796875]
 [ 16237.08105469]
 [ 20188.34375   ]
 [ 23264.66601562]
 [ 23803.08007812]
 [ 22221.44921875]
 [ 16951.20117188]
 [ 16951.20117188]
 [ 19300.5078125 ]]
DEBUG:root:training time = %d0.214049
INFO:root:frame =4593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =4594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476837158203
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.963773333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =4597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =4598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.963741666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 20306.45898438]
 [ 20455.35546875]
 [ 16898.73046875]
 [ 19822.59179688]
 [ 16286.02148438]
 [ 22850.57421875]
 [ 17288.140625  ]
 [ 21906.45703125]
 [ 20306.45898438]
 [ 23733.1484375 ]
 [ 16236.64550781]
 [ 16864.40820312]
 [ 16513.44140625]
 [ 22730.86328125]
 [ 19315.63867188]
 [ 19546.6484375 ]]
DEBUG:root:training time = %d0.223546
INFO:root:frame =4601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =4602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449180603027
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.96371
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root:frame =4605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =4606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.963678333333
DEBUG:root: dqn, choose action rondomly, need time 0.000326999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:training error  = [[ 20385.30078125]
 [ 19505.1640625 ]
 [ 23431.11914062]
 [ 20881.44921875]
 [ 22935.4609375 ]
 [ 17849.703125  ]
 [ 23731.4921875 ]
 [ 21474.19726562]
 [ 20848.44140625]
 [ 21739.75976562]
 [ 23561.27539062]
 [ 20222.35351562]
 [ 20696.50390625]
 [ 20696.92382812]
 [ 20514.7578125 ]
 [ 23903.37890625]]
DEBUG:root:training time = %d0.208853
INFO:root:frame =4609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:frame =4610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame = 4611 State into memory, numbers recorded 130 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000584840774536
INFO:root:random_action_porb = 0.963646666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4612current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =4613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456809997559
INFO:root:frame =4614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.963615
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:training error  = [[ 20094.515625  ]
 [ 18931.36914062]
 [ 19854.5703125 ]
 [ 20551.49023438]
 [ 25177.5390625 ]
 [ 19481.91601562]
 [ 20697.41601562]
 [ 18931.36914062]
 [ 20255.34960938]
 [ 20397.8515625 ]
 [ 24206.07226562]
 [ 20397.8515625 ]
 [ 16686.19335938]
 [ 21417.77929688]
 [ 19532.72460938]
 [ 18924.1796875 ]]
DEBUG:root:training time = %d0.231887
INFO:root:frame =4617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =4618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.963583333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =4621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:frame =4622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.963551666667
DEBUG:root: dqn, choose action rondomly, need time 0.000371000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:training error  = [[ 22354.046875  ]
 [ 18462.74609375]
 [ 18340.80273438]
 [ 18462.74609375]
 [ 16683.41796875]
 [ 21688.171875  ]
 [ 20726.01757812]
 [ 22125.98242188]
 [ 18297.44921875]
 [ 18507.68945312]
 [ 22429.37695312]
 [ 16547.53125   ]
 [ 18988.71875   ]
 [ 17690.0390625 ]
 [ 24581.35546875]
 [ 18492.61328125]]
DEBUG:root:training time = %d0.238265
INFO:root:frame =4625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =4626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:frame = 4627 State into memory, numbers recorded 131 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00054407119751
INFO:root:random_action_porb = 0.96352
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4628current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =4629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame =4630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494956970215
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.963488333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:training error  = [[ 22242.48828125]
 [ 25308.95703125]
 [ 20965.21679688]
 [ 20716.03515625]
 [ 20087.73242188]
 [ 20087.73242188]
 [ 23028.13671875]
 [ 19133.18359375]
 [ 22146.46875   ]
 [ 22175.68945312]
 [ 22146.46875   ]
 [ 19256.98242188]
 [ 17805.50195312]
 [ 25308.95703125]
 [ 23314.06835938]
 [ 23513.55664062]]
DEBUG:root:training time = %d0.201617
INFO:root:frame =4633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284194946289
INFO:root:frame =4634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000313997268677
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.963456666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =4637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:frame =4638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.963425
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root:training error  = [[ 18152.16796875]
 [ 21669.11914062]
 [ 23113.72460938]
 [ 18949.17578125]
 [ 24475.82421875]
 [ 18123.69335938]
 [ 18152.16796875]
 [ 19195.98046875]
 [ 17738.06445312]
 [ 18598.20703125]
 [ 20621.33789062]
 [ 26311.359375  ]
 [ 20475.54101562]
 [ 17712.45117188]
 [ 18598.20703125]
 [ 24475.82421875]]
DEBUG:root:training time = %d0.222409
INFO:root:frame =4641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =4642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235080718994
DEBUG:root: save sample needs time = 9.29832458496e-05
INFO:root:random_action_porb = 0.963393333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =4645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =4646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.963361666667
DEBUG:root: dqn, choose action rondomly, need time 0.000181999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:training error  = [[ 18115.21484375]
 [ 26573.53710938]
 [ 22575.94335938]
 [ 24757.82421875]
 [ 22031.58984375]
 [ 25733.140625  ]
 [ 18633.05078125]
 [ 27015.046875  ]
 [ 23674.359375  ]
 [ 18820.0078125 ]
 [ 18115.21484375]
 [ 23674.359375  ]
 [ 18633.05078125]
 [ 18554.41796875]
 [ 19508.64257812]
 [ 24909.09960938]]
DEBUG:root:training time = %d0.222248
INFO:root:frame =4649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =4650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428915023804
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.96333
DEBUG:root: dqn, choose action rondomly, need time 0.00029099999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =4653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =4654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.963298333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:training error  = [[ 22451.90625   ]
 [ 25658.78320312]
 [ 18125.46875   ]
 [ 21318.78125   ]
 [ 27975.9921875 ]
 [ 22808.00585938]
 [ 19680.74609375]
 [ 25836.95117188]
 [ 25035.79882812]
 [ 28419.2421875 ]
 [ 23096.578125  ]
 [ 21318.78125   ]
 [ 25035.79882812]
 [ 25836.95117188]
 [ 27134.51953125]
 [ 19844.390625  ]]
DEBUG:root:training time = %d0.215366
INFO:root:frame =4657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =4658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275850296021
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.963266666667
DEBUG:root: dqn, choose action rondomly, need time 0.000275999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =4661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =4662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.963235
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:training error  = [[ 19927.15429688]
 [ 22535.75585938]
 [ 22535.75585938]
 [ 19004.6015625 ]
 [ 23951.265625  ]
 [ 19800.32421875]
 [ 22373.39648438]
 [ 23079.21679688]
 [ 20337.43359375]
 [ 20024.25390625]
 [ 18895.44140625]
 [ 19308.51367188]
 [ 18207.734375  ]
 [ 19760.97460938]
 [ 20064.6953125 ]
 [ 18378.3828125 ]]
DEBUG:root:training time = %d0.219827
INFO:root:frame =4665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000388860702515
INFO:root:frame =4666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000385046005249
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.963203333333
DEBUG:root: dqn, choose action rondomly, need time 0.000329999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:frame =4669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =4670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame = 4671 State into memory, numbers recorded 132 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000545024871826
INFO:root:random_action_porb = 0.963171666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4672current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:training error  = [[ 23676.46289062]
 [ 19741.828125  ]
 [ 20965.49804688]
 [ 23728.2578125 ]
 [ 25418.91601562]
 [ 23442.77929688]
 [ 23987.703125  ]
 [ 25297.92773438]
 [ 23676.46289062]
 [ 20532.734375  ]
 [ 23728.2578125 ]
 [ 22612.34765625]
 [ 23442.77929688]
 [ 21944.125     ]
 [ 28771.31640625]
 [ 19833.1796875 ]]
DEBUG:root:training time = %d0.204916
INFO:root:frame =4673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =4674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000253915786743
DEBUG:root: save sample needs time = 0.000115871429443
INFO:root:random_action_porb = 0.96314
DEBUG:root: dqn, choose action rondomly, need time 0.000291999999988
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000346899032593
INFO:root:frame =4677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =4678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.963108333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 27489.98046875]
 [ 22686.2734375 ]
 [ 23221.4140625 ]
 [ 19315.1640625 ]
 [ 28885.06054688]
 [ 21805.7578125 ]
 [ 26440.77734375]
 [ 24615.51171875]
 [ 27163.96484375]
 [ 22574.4765625 ]
 [ 21939.20703125]
 [ 26257.92382812]
 [ 26555.39257812]
 [ 26519.8359375 ]
 [ 22075.67773438]
 [ 28093.96679688]]
DEBUG:root:training time = %d0.23266
INFO:root:frame =4681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =4682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.963076666667
DEBUG:root: dqn, choose action rondomly, need time 0.000234000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:frame =4685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =4686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.963045
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 20182.72460938]
 [ 26701.28320312]
 [ 19971.70703125]
 [ 26657.09960938]
 [ 18486.43945312]
 [ 26250.40820312]
 [ 21290.84179688]
 [ 25960.32226562]
 [ 25533.63671875]
 [ 20488.05078125]
 [ 22181.50585938]
 [ 28303.46289062]
 [ 24604.02148438]
 [ 20868.328125  ]
 [ 27513.625     ]
 [ 24986.84179688]]
DEBUG:root:training time = %d0.201417
INFO:root:frame =4689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =4690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000256776809692
DEBUG:root: save sample needs time = 0.000109195709229
INFO:root:random_action_porb = 0.963013333333
DEBUG:root: dqn, choose action rondomly, need time 0.000191000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root:frame =4693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =4694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.962981666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:training error  = [[ 20653.81640625]
 [ 22450.58789062]
 [ 22532.38476562]
 [ 27340.00976562]
 [ 24675.1484375 ]
 [ 23573.34375   ]
 [ 22071.9765625 ]
 [ 24880.36328125]
 [ 25222.10742188]
 [ 25299.32617188]
 [ 24055.73828125]
 [ 25222.10742188]
 [ 21138.71875   ]
 [ 23352.10742188]
 [ 24215.94921875]
 [ 24451.765625  ]]
DEBUG:root:training time = %d0.227542
INFO:root:frame =4697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:frame =4698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.96295
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =4702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.962918333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:training error  = [[ 25796.07617188]
 [ 21988.05273438]
 [ 20664.625     ]
 [ 22853.00976562]
 [ 22788.91015625]
 [ 31217.609375  ]
 [ 21837.06054688]
 [ 24157.78125   ]
 [ 25205.12890625]
 [ 22853.00976562]
 [ 24975.72851562]
 [ 24975.72851562]
 [ 29872.8515625 ]
 [ 23194.78515625]
 [ 20764.34570312]
 [ 23534.37695312]]
DEBUG:root:training time = %d0.236532
INFO:root:frame =4705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =4706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.962886666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =4709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =4710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:random_action_porb = 0.962855
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 21812.89648438]
 [ 28024.19921875]
 [ 29627.18359375]
 [ 21947.38085938]
 [ 28010.87695312]
 [ 22897.61523438]
 [ 23480.09960938]
 [ 21947.38085938]
 [ 21674.7265625 ]
 [ 24230.99609375]
 [ 20983.31835938]
 [ 22015.6484375 ]
 [ 21771.88085938]
 [ 30561.54492188]
 [ 22167.40039062]
 [ 27701.27929688]]
DEBUG:root:training time = %d0.218885
INFO:root:frame =4713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248193740845
INFO:root:frame =4714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000287055969238
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.962823333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =4717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =4718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.962791666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:training error  = [[ 23726.00195312]
 [ 27470.39257812]
 [ 27008.70703125]
 [ 27925.70703125]
 [ 19501.890625  ]
 [ 23557.30273438]
 [ 21469.61914062]
 [ 21167.62109375]
 [ 21469.61914062]
 [ 27131.78320312]
 [ 27925.70703125]
 [ 28939.60742188]
 [ 28033.84570312]
 [ 27008.70703125]
 [ 27812.64648438]
 [ 23105.9296875 ]]
DEBUG:root:training time = %d0.215453
INFO:root:frame =4721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.96276
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =4725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454187393188
INFO:root:frame =4726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame = 4727 State into memory, numbers recorded 133 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000540971755981
INFO:root:random_action_porb = 0.962728333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4728current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 26702.56054688]
 [ 30096.40429688]
 [ 29180.83007812]
 [ 27058.16210938]
 [ 25811.13671875]
 [ 23332.48828125]
 [ 29474.25      ]
 [ 23129.61328125]
 [ 22727.4765625 ]
 [ 26543.37890625]
 [ 22771.00195312]
 [ 27636.46484375]
 [ 27806.5390625 ]
 [ 30962.93945312]
 [ 29120.80664062]
 [ 21320.77734375]]
DEBUG:root:training time = %d0.235339
INFO:root:frame =4729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =4730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000270843505859
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.962696666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282000000013
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =4733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471830368042
INFO:root:frame =4734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000417947769165
INFO:root:frame = 4735 State into memory, numbers recorded 134 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000536918640137
INFO:root:random_action_porb = 0.962665
DEBUG:root: dqn, choose action rondomly, need time 0.000274000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4736current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:training error  = [[ 26134.63671875]
 [ 26608.09375   ]
 [ 27246.35351562]
 [ 20595.96289062]
 [ 23675.03710938]
 [ 25433.0859375 ]
 [ 25001.66210938]
 [ 26197.27148438]
 [ 25661.83398438]
 [ 24543.55273438]
 [ 22840.97851562]
 [ 27246.35351562]
 [ 29488.16796875]
 [ 23227.21875   ]
 [ 22840.97851562]
 [ 27732.73828125]]
DEBUG:root:training time = %d0.220281
INFO:root:frame =4737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =4738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root:random_action_porb = 0.962633333333
DEBUG:root: dqn, choose action rondomly, need time 0.000177000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:frame =4741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root:frame =4742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000535011291504
INFO:root:frame = 4743 State into memory, numbers recorded 135 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000548124313354
INFO:root:random_action_porb = 0.962601666667
INFO:root:dqn select action Tensor("ArgMax_24:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012896
INFO:root:action choosen by dqn [1]
INFO:root:frame =4744current_observation done, NOT record action [1], reward = 0
DEBUG:root: save sample needs time = 0.000383853912354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 26796.71484375]
 [ 25005.21484375]
 [ 26601.24414062]
 [ 25902.29296875]
 [ 25607.5       ]
 [ 25547.13671875]
 [ 26162.3515625 ]
 [ 23797.43164062]
 [ 23994.58398438]
 [ 23482.34570312]
 [ 25658.62695312]
 [ 23059.26757812]
 [ 24730.86328125]
 [ 23159.62304688]
 [ 23451.9765625 ]
 [ 26025.9765625 ]]
DEBUG:root:training time = %d0.21957
INFO:root:frame =4745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.96257
DEBUG:root: dqn, choose action rondomly, need time 0.000263999999987
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =4749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =4750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000535011291504
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.962538333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 22498.97460938]
 [ 26985.84179688]
 [ 25057.51367188]
 [ 34578.8359375 ]
 [ 23575.66796875]
 [ 24565.20507812]
 [ 25387.31835938]
 [ 23981.72851562]
 [ 21805.1796875 ]
 [ 34073.58984375]
 [ 23851.46875   ]
 [ 25288.84179688]
 [ 23671.4296875 ]
 [ 34999.3203125 ]
 [ 24664.2578125 ]
 [ 25115.43945312]]
DEBUG:root:training time = %d0.218664
INFO:root:frame =4753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =4754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247001647949
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:random_action_porb = 0.962506666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =4757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049614906311
INFO:root:frame =4758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.962475
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 25574.53710938]
 [ 24695.78515625]
 [ 24763.27929688]
 [ 25333.12109375]
 [ 23642.36523438]
 [ 25105.38085938]
 [ 21781.10546875]
 [ 26358.82226562]
 [ 26329.0234375 ]
 [ 24885.21679688]
 [ 25591.875     ]
 [ 32554.78320312]
 [ 32639.15039062]
 [ 33207.9453125 ]
 [ 33294.578125  ]
 [ 25911.72460938]]
DEBUG:root:training time = %d0.201574
INFO:root:frame =4761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =4762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277996063232
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.962443333333
DEBUG:root: dqn, choose action rondomly, need time 0.00032800000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =4765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =4766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.962411666667
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 24107.4140625 ]
 [ 31728.16796875]
 [ 34634.79296875]
 [ 38416.19140625]
 [ 26321.97265625]
 [ 24058.3125    ]
 [ 35454.3359375 ]
 [ 37347.35546875]
 [ 35215.05078125]
 [ 31642.72851562]
 [ 33954.26953125]
 [ 24107.4140625 ]
 [ 26042.36328125]
 [ 34942.52734375]
 [ 24973.64453125]
 [ 34401.1015625 ]]
DEBUG:root:training time = %d0.229161
INFO:root:frame =4769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =4770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.96238
DEBUG:root: dqn, choose action rondomly, need time 0.000169
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000131130218506
INFO:root:frame =4773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000423908233643
INFO:root:frame =4774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.962348333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 21631.61523438]
 [ 33895.36328125]
 [ 24483.5390625 ]
 [ 29662.41015625]
 [ 30581.3515625 ]
 [ 30441.73046875]
 [ 32399.296875  ]
 [ 29111.30859375]
 [ 25323.71875   ]
 [ 30471.5546875 ]
 [ 30471.5546875 ]
 [ 30441.73046875]
 [ 29153.14453125]
 [ 24735.47265625]
 [ 30753.39453125]
 [ 31043.32617188]]
DEBUG:root:training time = %d0.207915
INFO:root:frame =4777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =4778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.962316666667
INFO:root:dqn select action Tensor("ArgMax_25:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011964
INFO:root:action choosen by dqn [1]
INFO:root:frame =4780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root:frame =4781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =4782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428915023804
INFO:root:frame = 4783 State into memory, numbers recorded 136 action = [1], reward = 0
DEBUG:root: save sample needs time = 0.0010838508606
INFO:root:random_action_porb = 0.962285
DEBUG:root: dqn, choose action rondomly, need time 0.000280000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4784current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[ 25346.1796875 ]
 [ 30282.8828125 ]
 [ 25806.4296875 ]
 [ 25785.5703125 ]
 [ 24505.16601562]
 [ 26769.78515625]
 [ 26721.55273438]
 [ 25336.46289062]
 [ 25982.43359375]
 [ 25929.5703125 ]
 [ 25829.49609375]
 [ 25683.97460938]
 [ 29352.49023438]
 [ 30282.8828125 ]
 [ 25377.20507812]
 [ 25878.88085938]]
DEBUG:root:training time = %d0.211848
INFO:root:frame =4785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =4786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.962253333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =4789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000501155853271
INFO:root:frame =4790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:random_action_porb = 0.962221666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:training error  = [[ 23953.60742188]
 [ 34877.66015625]
 [ 35504.4609375 ]
 [ 26999.56054688]
 [ 33321.22265625]
 [ 33015.05078125]
 [ 25406.15039062]
 [ 25671.69140625]
 [ 27011.7578125 ]
 [ 31826.00195312]
 [ 27699.49023438]
 [ 25327.29296875]
 [ 26751.97265625]
 [ 25215.75      ]
 [ 27501.96289062]
 [ 34369.23046875]]
DEBUG:root:training time = %d0.24163
INFO:root:frame =4793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =4794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000382900238037
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.96219
DEBUG:root: dqn, choose action rondomly, need time 0.00028300000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =4797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =4798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.962158333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 39515.734375  ]
 [ 26575.20898438]
 [ 25797.64648438]
 [ 30893.8125    ]
 [ 30550.02148438]
 [ 30585.96289062]
 [ 24973.49023438]
 [ 25782.35546875]
 [ 27955.49804688]
 [ 31345.59570312]
 [ 36123.75390625]
 [ 34494.5390625 ]
 [ 33663.91796875]
 [ 28264.78515625]
 [ 35148.01171875]
 [ 34370.40625   ]]
DEBUG:root:training time = %d0.223603
INFO:root:frame =4801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =4802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.962126666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =4806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.962095
INFO:root:dqn select action Tensor("ArgMax_26:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012535
INFO:root:action choosen by dqn [3]
INFO:root:frame =4808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000337839126587
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 27229.9140625 ]
 [ 38473.828125  ]
 [ 35636.42578125]
 [ 38262.64453125]
 [ 37536.79296875]
 [ 25930.43359375]
 [ 26591.05078125]
 [ 34516.21484375]
 [ 30422.65039062]
 [ 33830.48828125]
 [ 35557.56640625]
 [ 30076.24804688]
 [ 39685.96875   ]
 [ 31043.06835938]
 [ 35914.96875   ]
 [ 26844.45507812]]
DEBUG:root:training time = %d0.231023
INFO:root:frame =4809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000355958938599
INFO:root:frame =4810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428915023804
DEBUG:root: save sample needs time = 9.29832458496e-05
INFO:root:random_action_porb = 0.962063333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =4813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =4814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.962031666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 26356.91992188]
 [ 31151.21679688]
 [ 36904.79296875]
 [ 39174.80859375]
 [ 34452.37890625]
 [ 38380.6953125 ]
 [ 30227.84570312]
 [ 33385.0703125 ]
 [ 30741.578125  ]
 [ 35648.1328125 ]
 [ 36535.859375  ]
 [ 32223.75585938]
 [ 31771.49609375]
 [ 33072.03125   ]
 [ 39032.1953125 ]
 [ 27567.99804688]]
DEBUG:root:training time = %d0.222969
INFO:root:frame =4817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =4818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298976898193
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.962
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =4821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =4822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.961968333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 33473.453125  ]
 [ 34748.65625   ]
 [ 33698.59765625]
 [ 30938.88671875]
 [ 27000.60351562]
 [ 28094.21289062]
 [ 31225.02929688]
 [ 26809.82421875]
 [ 28337.97460938]
 [ 33505.4453125 ]
 [ 27613.984375  ]
 [ 29251.27148438]
 [ 28545.984375  ]
 [ 29251.27148438]
 [ 30938.88671875]
 [ 34987.90234375]]
DEBUG:root:training time = %d0.224962
INFO:root:frame =4825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =4826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame = 4827 State into memory, numbers recorded 137 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000542879104614
INFO:root:random_action_porb = 0.961936666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4828current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =4830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.961905
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 29304.07421875]
 [ 31415.3125    ]
 [ 30325.72265625]
 [ 29451.87304688]
 [ 28007.93554688]
 [ 39556.5078125 ]
 [ 29123.30664062]
 [ 27737.53710938]
 [ 27203.41210938]
 [ 34357.64453125]
 [ 33187.8359375 ]
 [ 32506.5234375 ]
 [ 29565.359375  ]
 [ 30325.72265625]
 [ 38421.16796875]
 [ 32974.25      ]]
DEBUG:root:training time = %d0.232545
INFO:root:frame =4833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =4834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
DEBUG:root: save sample needs time = 0.00011682510376
INFO:root:random_action_porb = 0.961873333333
DEBUG:root: dqn, choose action rondomly, need time 0.000180999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:frame =4837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =4838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame = 4839 State into memory, numbers recorded 138 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000574111938477
INFO:root:random_action_porb = 0.961841666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4840current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:training error  = [[ 25705.26367188]
 [ 34782.33984375]
 [ 32606.078125  ]
 [ 31451.7578125 ]
 [ 28255.09765625]
 [ 32367.04882812]
 [ 31451.7578125 ]
 [ 32830.4140625 ]
 [ 29740.33203125]
 [ 27579.4296875 ]
 [ 28159.47851562]
 [ 31363.234375  ]
 [ 29009.83984375]
 [ 29539.16992188]
 [ 37723.29296875]
 [ 34992.46875   ]]
DEBUG:root:training time = %d0.212808
INFO:root:frame =4841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =4842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.96181
DEBUG:root: dqn, choose action rondomly, need time 0.000316000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =4845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =4846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.961778333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 34054.39453125]
 [ 29317.19726562]
 [ 29317.19726562]
 [ 34835.453125  ]
 [ 36984.94140625]
 [ 30424.5234375 ]
 [ 41705.89453125]
 [ 40310.46484375]
 [ 36893.8203125 ]
 [ 39442.67578125]
 [ 29403.79296875]
 [ 39171.91015625]
 [ 36785.76171875]
 [ 29584.25195312]
 [ 29553.35351562]
 [ 32918.05859375]]
DEBUG:root:training time = %d0.221974
INFO:root:frame =4849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000414133071899
INFO:root:frame =4850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.961746666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =4854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.961715
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:training error  = [[ 38962.2890625 ]
 [ 29748.41796875]
 [ 32999.5234375 ]
 [ 41506.00390625]
 [ 29623.06640625]
 [ 30420.34960938]
 [ 33619.765625  ]
 [ 34277.50390625]
 [ 28873.52734375]
 [ 36444.44921875]
 [ 40776.2890625 ]
 [ 34266.203125  ]
 [ 35476.49609375]
 [ 29505.52734375]
 [ 29361.10742188]
 [ 41742.6015625 ]]
DEBUG:root:training time = %d0.232893
INFO:root:frame =4857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000330209732056
INFO:root:frame =4858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000355005264282
DEBUG:root: save sample needs time = 0.000140190124512
INFO:root:random_action_porb = 0.961683333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =4862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000250101089478
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.961651666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00040602684021
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 31196.1328125 ]
 [ 29555.95507812]
 [ 39266.28515625]
 [ 38806.5       ]
 [ 33090.68359375]
 [ 29148.89257812]
 [ 28839.35351562]
 [ 27106.29492188]
 [ 32341.22851562]
 [ 32626.2734375 ]
 [ 34884.2265625 ]
 [ 35334.1796875 ]
 [ 40239.51953125]
 [ 29353.99609375]
 [ 35869.1796875 ]
 [ 29474.50195312]]
DEBUG:root:training time = %d0.22701
INFO:root:frame =4865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.96162
DEBUG:root: dqn, choose action rondomly, need time 0.000169999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174045562744
INFO:root:frame =4869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000380992889404
INFO:root:frame =4870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:random_action_porb = 0.961588333333
INFO:root:dqn select action Tensor("ArgMax_27:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01387
INFO:root:action choosen by dqn [2]
INFO:root:frame =4872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 32438.68359375]
 [ 26935.41210938]
 [ 37957.5234375 ]
 [ 39049.75390625]
 [ 30657.90625   ]
 [ 35179.234375  ]
 [ 33026.8515625 ]
 [ 30419.24414062]
 [ 38646.51171875]
 [ 39115.296875  ]
 [ 38667.15234375]
 [ 39337.2421875 ]
 [ 35344.3671875 ]
 [ 40582.08203125]
 [ 30424.94921875]
 [ 29916.58398438]]
DEBUG:root:training time = %d0.225681
INFO:root:frame =4873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =4874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
DEBUG:root: save sample needs time = 0.000120878219604
INFO:root:random_action_porb = 0.961556666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =4877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =4878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.961525
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:training error  = [[ 35171.90625   ]
 [ 30633.03320312]
 [ 38748.7109375 ]
 [ 38561.4140625 ]
 [ 30866.35546875]
 [ 37503.59375   ]
 [ 30633.03320312]
 [ 38465.49609375]
 [ 37661.76953125]
 [ 31756.96289062]
 [ 43345.8984375 ]
 [ 38584.140625  ]
 [ 34364.5234375 ]
 [ 35909.41796875]
 [ 32685.48046875]
 [ 39175.29296875]]
DEBUG:root:training time = %d0.222036
INFO:root:frame =4881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =4882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000327110290527
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.961493333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root:frame =4885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =4886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.961461666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000418901443481
INFO:root:training error  = [[ 31227.4453125 ]
 [ 36509.63671875]
 [ 32921.07421875]
 [ 36212.15625   ]
 [ 33032.44140625]
 [ 31522.45898438]
 [ 42701.15625   ]
 [ 37453.87109375]
 [ 36338.44921875]
 [ 32921.07421875]
 [ 40626.26171875]
 [ 38542.046875  ]
 [ 40773.52734375]
 [ 35613.3828125 ]
 [ 36782.015625  ]
 [ 45503.0546875 ]]
DEBUG:root:training time = %d0.210012
INFO:root:frame =4889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000327825546265
INFO:root:frame =4890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.96143
DEBUG:root: dqn, choose action rondomly, need time 0.000294000000011
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =4893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =4894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame = 4895 State into memory, numbers recorded 139 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000566005706787
INFO:root:random_action_porb = 0.961398333333
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4896current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 39710.48828125]
 [ 33118.4921875 ]
 [ 39442.        ]
 [ 30394.296875  ]
 [ 32336.31054688]
 [ 39453.734375  ]
 [ 35245.203125  ]
 [ 32216.56835938]
 [ 34616.34765625]
 [ 39026.40625   ]
 [ 34701.88671875]
 [ 32223.66796875]
 [ 36740.9140625 ]
 [ 38760.7265625 ]
 [ 38267.32421875]
 [ 34414.32421875]]
DEBUG:root:training time = %d0.22471
INFO:root:frame =4897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00039005279541
INFO:root:frame =4898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.961366666667
DEBUG:root: dqn, choose action rondomly, need time 0.000276999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =4901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000422954559326
INFO:root:frame =4902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame = 4903 State into memory, numbers recorded 140 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000569105148315
INFO:root:random_action_porb = 0.961335
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4904current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 37887.6328125 ]
 [ 42197.9453125 ]
 [ 32413.625     ]
 [ 34947.453125  ]
 [ 32920.09765625]
 [ 41335.078125  ]
 [ 38120.37109375]
 [ 32283.73632812]
 [ 36953.2109375 ]
 [ 40503.33203125]
 [ 32783.09765625]
 [ 36227.58203125]
 [ 34185.8984375 ]
 [ 36764.50390625]
 [ 34391.7734375 ]
 [ 41138.75390625]]
DEBUG:root:training time = %d0.212817
INFO:root:frame =4905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =4906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.961303333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =4909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =4910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:random_action_porb = 0.961271666667
DEBUG:root: dqn, choose action rondomly, need time 0.000214999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 33066.3515625 ]
 [ 47831.26953125]
 [ 35984.40234375]
 [ 40503.625     ]
 [ 42779.58984375]
 [ 42019.796875  ]
 [ 35082.953125  ]
 [ 36007.37890625]
 [ 34207.02734375]
 [ 41302.2265625 ]
 [ 34047.09765625]
 [ 36233.625     ]
 [ 38688.56640625]
 [ 40676.2734375 ]
 [ 40380.6875    ]
 [ 34116.8671875 ]]
DEBUG:root:training time = %d0.220349
INFO:root:frame =4913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =4914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288009643555
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:random_action_porb = 0.96124
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =4917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =4918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.961208333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 40956.234375  ]
 [ 37829.96484375]
 [ 34859.60546875]
 [ 43813.4609375 ]
 [ 45948.89453125]
 [ 33998.28125   ]
 [ 41851.91015625]
 [ 39654.9453125 ]
 [ 33562.578125  ]
 [ 32888.7421875 ]
 [ 35540.80859375]
 [ 32757.2890625 ]
 [ 46395.12109375]
 [ 42605.95703125]
 [ 48323.8671875 ]
 [ 35198.8359375 ]]
DEBUG:root:training time = %d0.237476
INFO:root:frame =4921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =4922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000290870666504
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:random_action_porb = 0.961176666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =4925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =4926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.961145
DEBUG:root: dqn, choose action rondomly, need time 0.000330000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 32846.9609375 ]
 [ 42766.4609375 ]
 [ 43636.0078125 ]
 [ 40288.80078125]
 [ 34188.15625   ]
 [ 39129.109375  ]
 [ 38299.04296875]
 [ 43357.69140625]
 [ 37035.48046875]
 [ 39793.23828125]
 [ 43909.7890625 ]
 [ 42241.1875    ]
 [ 35471.7109375 ]
 [ 40187.23046875]
 [ 45830.48828125]
 [ 47606.        ]]
DEBUG:root:training time = %d0.224791
INFO:root:frame =4929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =4930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000295877456665
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.961113333333
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =4934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.961081666667
DEBUG:root: dqn, choose action rondomly, need time 0.00028300000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 40540.78125   ]
 [ 38106.26171875]
 [ 46370.30078125]
 [ 39494.4765625 ]
 [ 34604.80859375]
 [ 43851.28515625]
 [ 39947.671875  ]
 [ 37670.203125  ]
 [ 45651.80859375]
 [ 32934.62890625]
 [ 36297.78515625]
 [ 45597.9921875 ]
 [ 34132.83203125]
 [ 41382.1484375 ]
 [ 45152.6171875 ]
 [ 43592.66796875]]
DEBUG:root:training time = %d0.227795
INFO:root:frame =4937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =4938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.96105
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =4941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =4942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.961018333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 38273.62890625]
 [ 40303.6015625 ]
 [ 47935.33984375]
 [ 40614.44921875]
 [ 37048.91796875]
 [ 44031.53125   ]
 [ 38509.26953125]
 [ 38985.328125  ]
 [ 34320.27734375]
 [ 36562.7421875 ]
 [ 50109.7421875 ]
 [ 40614.44921875]
 [ 39735.7890625 ]
 [ 39789.33984375]
 [ 37048.91796875]
 [ 40614.44921875]]
DEBUG:root:training time = %d0.241231
INFO:root:frame =4945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:frame =4946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288963317871
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.960986666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:frame =4949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =4950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.960955
DEBUG:root: dqn, choose action rondomly, need time 0.000269000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 36605.703125  ]
 [ 32188.79296875]
 [ 48652.44921875]
 [ 45604.66796875]
 [ 49104.546875  ]
 [ 39851.30859375]
 [ 50870.51171875]
 [ 36425.71484375]
 [ 49301.12890625]
 [ 52659.04296875]
 [ 38553.359375  ]
 [ 40442.23046875]
 [ 48028.60546875]
 [ 47857.4375    ]
 [ 34279.40234375]
 [ 34765.22265625]]
DEBUG:root:training time = %d0.212015
INFO:root:frame =4953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258207321167
INFO:root:frame =4954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275135040283
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.960923333333
DEBUG:root: dqn, choose action rondomly, need time 0.000178000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000171899795532
INFO:root:frame =4957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:frame =4958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.960891666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 50147.12890625]
 [ 46344.546875  ]
 [ 47345.4453125 ]
 [ 47744.171875  ]
 [ 45317.63671875]
 [ 38276.58984375]
 [ 37810.78515625]
 [ 50147.12890625]
 [ 51263.546875  ]
 [ 38593.54296875]
 [ 46987.65234375]
 [ 38574.93359375]
 [ 45503.6796875 ]
 [ 46433.7265625 ]
 [ 49793.37109375]
 [ 39731.9921875 ]]
DEBUG:root:training time = %d0.224796
INFO:root:frame =4961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =4962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.96086
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =4965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =4966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.960828333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 45738.65234375]
 [ 43098.00390625]
 [ 43823.06640625]
 [ 42087.984375  ]
 [ 46577.45703125]
 [ 43759.51171875]
 [ 46139.796875  ]
 [ 50612.2578125 ]
 [ 44418.95703125]
 [ 44119.79296875]
 [ 35636.88671875]
 [ 45231.609375  ]
 [ 37944.5859375 ]
 [ 45303.0859375 ]
 [ 37063.20703125]
 [ 44984.27734375]]
DEBUG:root:training time = %d0.201877
INFO:root:frame =4969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =4970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.960796666667
DEBUG:root: dqn, choose action rondomly, need time 0.000343000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =4973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =4974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.960765
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 48243.71875   ]
 [ 41319.        ]
 [ 49421.98046875]
 [ 48832.2578125 ]
 [ 39376.5703125 ]
 [ 37577.29296875]
 [ 42073.4609375 ]
 [ 41282.58203125]
 [ 40947.93359375]
 [ 41537.7421875 ]
 [ 38078.2421875 ]
 [ 42614.52734375]
 [ 44005.71484375]
 [ 41603.44921875]
 [ 48243.71875   ]
 [ 38147.83203125]]
DEBUG:root:training time = %d0.244815
INFO:root:frame =4977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =4978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.960733333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =4981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =4982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.960701666667
DEBUG:root: dqn, choose action rondomly, need time 0.000165999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:training error  = [[ 40276.35546875]
 [ 41862.30078125]
 [ 39643.18359375]
 [ 37124.23828125]
 [ 40403.453125  ]
 [ 35272.16015625]
 [ 37222.4296875 ]
 [ 41156.87890625]
 [ 37602.7578125 ]
 [ 50427.4375    ]
 [ 40052.359375  ]
 [ 38679.25      ]
 [ 44266.4765625 ]
 [ 50911.59765625]
 [ 43897.41015625]
 [ 41821.34765625]]
DEBUG:root:training time = %d0.200685
INFO:root:frame =4985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =4986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000375986099243
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:random_action_porb = 0.96067
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =4989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =4990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000225067138672
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.960638333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 33279.69921875]
 [ 43279.5390625 ]
 [ 49619.73828125]
 [ 39213.66796875]
 [ 47465.26171875]
 [ 44027.73828125]
 [ 44435.8359375 ]
 [ 43984.515625  ]
 [ 51903.3203125 ]
 [ 50062.421875  ]
 [ 48842.94140625]
 [ 38589.2265625 ]
 [ 42774.33984375]
 [ 38133.05078125]
 [ 39690.54296875]
 [ 44700.7578125 ]]
DEBUG:root:training time = %d0.213937
INFO:root:frame =4993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =4994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239133834839
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.960606666667
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000519990921021
INFO:root:frame =4998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000507116317749
DEBUG:root: save sample needs time = 0.000217914581299
DEBUG:root:one frame running time = 0.006629
DEBUG:root:total training time = 122.896541
INFO:root:frame num = 5000 frame round: 0
INFO:root:random_action_porb = 0.960575
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[ 45366.08984375]
 [ 40716.7578125 ]
 [ 41646.78515625]
 [ 39682.078125  ]
 [ 42502.01171875]
 [ 50056.9609375 ]
 [ 45816.06640625]
 [ 43902.1171875 ]
 [ 42171.26953125]
 [ 42144.90234375]
 [ 50973.8671875 ]
 [ 38914.11328125]
 [ 44121.7421875 ]
 [ 38181.59765625]
 [ 50681.046875  ]
 [ 42036.8125    ]]
DEBUG:root:training time = %d0.225464
INFO:root:frame =5001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =5002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame = 5003 State into memory, numbers recorded 141 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000327825546265
INFO:root:random_action_porb = 0.960543333333
DEBUG:root: dqn, choose action rondomly, need time 0.000181000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5004current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root:frame =5005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =5006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000499963760376
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.960511666667
DEBUG:root: dqn, choose action rondomly, need time 0.000444000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:training error  = [[ 49275.65234375]
 [ 42603.94140625]
 [ 43110.87890625]
 [ 43184.10546875]
 [ 35887.4921875 ]
 [ 40936.078125  ]
 [ 39048.2109375 ]
 [ 52516.16796875]
 [ 43597.359375  ]
 [ 55341.64453125]
 [ 40202.89453125]
 [ 41629.84765625]
 [ 47944.21484375]
 [ 40857.96875   ]
 [ 42402.0078125 ]
 [ 45661.09375   ]]
DEBUG:root:training time = %d0.227986
INFO:root:frame =5009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =5010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:random_action_porb = 0.96048
INFO:root:dqn select action Tensor("ArgMax_28:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015306
INFO:root:action choosen by dqn [2]
INFO:root:frame =5012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000161170959473
INFO:root:frame =5013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:frame =5014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 9.41753387451e-05
INFO:root:random_action_porb = 0.960448333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:training error  = [[ 41197.69921875]
 [ 54653.78515625]
 [ 47681.5625    ]
 [ 45803.41796875]
 [ 55287.44140625]
 [ 43296.5078125 ]
 [ 56380.5078125 ]
 [ 52589.375     ]
 [ 48854.3828125 ]
 [ 44061.86328125]
 [ 42659.08984375]
 [ 42288.87109375]
 [ 40914.24609375]
 [ 53930.421875  ]
 [ 43017.5546875 ]
 [ 56935.59765625]]
DEBUG:root:training time = %d0.207725
INFO:root:frame =5017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:frame =5018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame = 5019 State into memory, numbers recorded 142 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000545978546143
INFO:root:random_action_porb = 0.960416666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5020current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =5021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =5022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.960385
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 52142.65234375]
 [ 55990.58203125]
 [ 40213.37109375]
 [ 58374.734375  ]
 [ 51932.578125  ]
 [ 44917.08984375]
 [ 43590.32421875]
 [ 57525.4921875 ]
 [ 41685.75390625]
 [ 52330.13671875]
 [ 46109.90625   ]
 [ 52337.734375  ]
 [ 47489.41015625]
 [ 56889.5859375 ]
 [ 44744.64453125]
 [ 46472.76953125]]
DEBUG:root:training time = %d0.209439
INFO:root:frame =5025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:frame =5026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:random_action_porb = 0.960353333333
DEBUG:root: dqn, choose action rondomly, need time 0.000348000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =5029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =5030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.960321666667
DEBUG:root: dqn, choose action rondomly, need time 0.000330000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 51220.7734375 ]
 [ 55946.80078125]
 [ 44473.9296875 ]
 [ 53582.8671875 ]
 [ 47010.30859375]
 [ 42064.94921875]
 [ 45625.73046875]
 [ 59283.5703125 ]
 [ 47010.30859375]
 [ 59396.92578125]
 [ 43815.30078125]
 [ 47010.30859375]
 [ 59807.59375   ]
 [ 57307.75390625]
 [ 47024.6015625 ]
 [ 51901.87109375]]
DEBUG:root:training time = %d0.231085
INFO:root:frame =5033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:frame =5034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000417947769165
INFO:root:frame = 5035 State into memory, numbers recorded 143 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000581979751587
INFO:root:random_action_porb = 0.96029
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5036current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000304222106934
INFO:root:frame =5037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =5038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:random_action_porb = 0.960258333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 55001.2421875 ]
 [ 45453.4921875 ]
 [ 52954.70703125]
 [ 41790.8984375 ]
 [ 44948.5546875 ]
 [ 41790.8984375 ]
 [ 48665.48046875]
 [ 54816.        ]
 [ 43337.96875   ]
 [ 49243.25      ]
 [ 42681.68359375]
 [ 43337.96875   ]
 [ 43438.76171875]
 [ 51597.078125  ]
 [ 45734.16015625]
 [ 45597.0546875 ]]
DEBUG:root:training time = %d0.224751
INFO:root:frame =5041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =5042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.960226666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =5045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00044584274292
INFO:root:frame =5046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.960195
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 42974.01953125]
 [ 50047.45703125]
 [ 44734.31640625]
 [ 42437.30859375]
 [ 43453.21484375]
 [ 41788.3046875 ]
 [ 42189.921875  ]
 [ 51210.60546875]
 [ 52325.109375  ]
 [ 50206.95703125]
 [ 43981.03125   ]
 [ 62409.82421875]
 [ 51167.19140625]
 [ 60766.703125  ]
 [ 49428.7109375 ]
 [ 50012.9453125 ]]
DEBUG:root:training time = %d0.209888
INFO:root:frame =5049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =5050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.960163333333
DEBUG:root: dqn, choose action rondomly, need time 0.000325000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =5053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =5054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.960131666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 49873.48828125]
 [ 51211.6015625 ]
 [ 53989.859375  ]
 [ 46942.89453125]
 [ 45366.7109375 ]
 [ 51599.8515625 ]
 [ 49873.48828125]
 [ 52868.3359375 ]
 [ 51036.390625  ]
 [ 53150.51171875]
 [ 44092.20703125]
 [ 54353.296875  ]
 [ 45897.62109375]
 [ 50121.65625   ]
 [ 54079.0703125 ]
 [ 44003.76953125]]
DEBUG:root:training time = %d0.209883
INFO:root:frame =5057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =5058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000166893005371
INFO:root:random_action_porb = 0.9601
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =5061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =5062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame = 5063 State into memory, numbers recorded 144 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000677108764648
INFO:root:random_action_porb = 0.960068333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5064current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 54935.98828125]
 [ 45261.109375  ]
 [ 62916.953125  ]
 [ 44291.23828125]
 [ 64101.19140625]
 [ 52845.546875  ]
 [ 63169.5078125 ]
 [ 54312.32421875]
 [ 53978.171875  ]
 [ 49881.44921875]
 [ 45261.109375  ]
 [ 45261.109375  ]
 [ 50878.8828125 ]
 [ 43776.67578125]
 [ 64032.72265625]
 [ 46950.40625   ]]
DEBUG:root:training time = %d0.221187
INFO:root:frame =5065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270843505859
INFO:root:frame =5066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000108003616333
INFO:root:random_action_porb = 0.960036666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =5069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000428915023804
INFO:root:frame =5070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.960005
DEBUG:root: dqn, choose action rondomly, need time 0.000271999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 47639.5625    ]
 [ 60143.37109375]
 [ 60442.9921875 ]
 [ 45386.47265625]
 [ 46151.125     ]
 [ 62183.26171875]
 [ 60008.61328125]
 [ 47491.328125  ]
 [ 45386.47265625]
 [ 45972.76171875]
 [ 45413.734375  ]
 [ 55485.08984375]
 [ 50680.38671875]
 [ 50218.1171875 ]
 [ 64585.96875   ]
 [ 63176.50390625]]
DEBUG:root:training time = %d0.200357
INFO:root:frame =5073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =5074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000356197357178
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.959973333333
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =5077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =5078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471830368042
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.959941666667
DEBUG:root: dqn, choose action rondomly, need time 0.000187999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162124633789
INFO:root:training error  = [[ 55851.90625   ]
 [ 45978.8359375 ]
 [ 61434.26953125]
 [ 67318.203125  ]
 [ 59240.421875  ]
 [ 65365.609375  ]
 [ 63758.22265625]
 [ 49773.87109375]
 [ 63326.19921875]
 [ 58580.0703125 ]
 [ 48434.48828125]
 [ 47848.14453125]
 [ 60871.34765625]
 [ 68625.3203125 ]
 [ 65038.8203125 ]
 [ 45291.23828125]]
DEBUG:root:training time = %d0.225576
INFO:root:frame =5081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =5082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.95991
DEBUG:root: dqn, choose action rondomly, need time 0.00033599999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =5085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =5086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.959878333333
DEBUG:root: dqn, choose action rondomly, need time 0.000249999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:training error  = [[ 54984.5234375 ]
 [ 64380.63671875]
 [ 56974.0546875 ]
 [ 64380.63671875]
 [ 59802.21875   ]
 [ 64635.1171875 ]
 [ 67805.5625    ]
 [ 62112.90625   ]
 [ 63651.7421875 ]
 [ 64411.61328125]
 [ 66687.765625  ]
 [ 44790.515625  ]
 [ 58338.76171875]
 [ 63060.578125  ]
 [ 65556.        ]
 [ 66687.765625  ]]
DEBUG:root:training time = %d0.235413
INFO:root:frame =5089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000327825546265
INFO:root:frame =5090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000361919403076
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.959846666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =5093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00044584274292
INFO:root:frame =5094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446796417236
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:random_action_porb = 0.959815
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 60498.703125  ]
 [ 59848.3203125 ]
 [ 48056.21875   ]
 [ 45926.70703125]
 [ 62291.43359375]
 [ 51774.0234375 ]
 [ 55632.640625  ]
 [ 59848.3203125 ]
 [ 58830.171875  ]
 [ 57138.5078125 ]
 [ 47046.83984375]
 [ 55177.046875  ]
 [ 58025.70703125]
 [ 45122.63671875]
 [ 60193.796875  ]
 [ 64977.4453125 ]]
DEBUG:root:training time = %d0.22538
INFO:root:frame =5097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:frame =5098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000314950942993
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:random_action_porb = 0.959783333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =5101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =5102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.959751666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 65017.03125   ]
 [ 65818.8046875 ]
 [ 58788.48828125]
 [ 59736.5625    ]
 [ 53274.63671875]
 [ 57948.57421875]
 [ 57145.04296875]
 [ 43791.69140625]
 [ 48416.97265625]
 [ 56327.8828125 ]
 [ 59062.05078125]
 [ 60948.953125  ]
 [ 54774.73828125]
 [ 60948.953125  ]
 [ 59062.05078125]
 [ 63713.3515625 ]]
DEBUG:root:training time = %d0.212874
INFO:root:frame =5105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =5106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000254154205322
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.95972
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000394105911255
INFO:root:frame =5109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471115112305
INFO:root:frame =5110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.959688333333
DEBUG:root: dqn, choose action rondomly, need time 0.000386999999989
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 47442.49609375]
 [ 51857.38671875]
 [ 48248.4375    ]
 [ 55013.3828125 ]
 [ 47965.70703125]
 [ 50713.80859375]
 [ 52209.125     ]
 [ 50033.4765625 ]
 [ 53395.74609375]
 [ 63970.4609375 ]
 [ 67217.90625   ]
 [ 54613.7265625 ]
 [ 52209.125     ]
 [ 62213.46484375]
 [ 65216.140625  ]
 [ 58601.8203125 ]]
DEBUG:root:training time = %d0.22069
INFO:root:frame =5113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =5114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000244855880737
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.959656666667
DEBUG:root: dqn, choose action rondomly, need time 0.000181999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:frame =5117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =5118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.959625
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 54051.9375    ]
 [ 54999.1796875 ]
 [ 55640.47265625]
 [ 63158.21875   ]
 [ 61435.23828125]
 [ 60933.5234375 ]
 [ 50040.46484375]
 [ 51247.41015625]
 [ 48589.67578125]
 [ 61848.62890625]
 [ 50601.05078125]
 [ 65143.33984375]
 [ 54340.890625  ]
 [ 65281.49609375]
 [ 53929.40234375]
 [ 59858.83203125]]
DEBUG:root:training time = %d0.227571
INFO:root:frame =5121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =5122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000833034515381
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.959593333333
DEBUG:root: dqn, choose action rondomly, need time 0.000160999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =5125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =5126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame = 5127 State into memory, numbers recorded 145 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.00036096572876
INFO:root:random_action_porb = 0.959561666667
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5128current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 63050.03125   ]
 [ 55748.328125  ]
 [ 69451.8046875 ]
 [ 57863.26953125]
 [ 53141.50390625]
 [ 56381.4375    ]
 [ 44822.76171875]
 [ 58869.734375  ]
 [ 59000.36328125]
 [ 50935.2890625 ]
 [ 67755.2265625 ]
 [ 56164.6015625 ]
 [ 57807.84375   ]
 [ 57863.26953125]
 [ 60299.7421875 ]
 [ 52927.1796875 ]]
DEBUG:root:training time = %d0.225173
INFO:root:frame =5129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =5130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.95953
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =5133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =5134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000417947769165
DEBUG:root: save sample needs time = 0.000180006027222
INFO:root:random_action_porb = 0.959498333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 56878.05859375]
 [ 54630.16015625]
 [ 54195.9765625 ]
 [ 62032.859375  ]
 [ 56850.11328125]
 [ 68220.4375    ]
 [ 54724.46875   ]
 [ 56940.2578125 ]
 [ 54630.16015625]
 [ 64602.34765625]
 [ 59306.7578125 ]
 [ 63659.625     ]
 [ 63201.6640625 ]
 [ 60523.20703125]
 [ 51842.265625  ]
 [ 55496.1328125 ]]
DEBUG:root:training time = %d0.218092
INFO:root:frame =5137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =5138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000222206115723
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:random_action_porb = 0.959466666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =5141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =5142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.959435
DEBUG:root: dqn, choose action rondomly, need time 0.000490999999982
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:training error  = [[ 60764.8984375 ]
 [ 60764.8984375 ]
 [ 63856.6484375 ]
 [ 60838.82421875]
 [ 62252.9296875 ]
 [ 53835.1015625 ]
 [ 68591.5625    ]
 [ 71815.1015625 ]
 [ 61974.25390625]
 [ 60643.390625  ]
 [ 56565.46875   ]
 [ 50619.7265625 ]
 [ 53274.18359375]
 [ 54683.35546875]
 [ 61952.86328125]
 [ 50484.25390625]]
DEBUG:root:training time = %d0.206312
INFO:root:frame =5145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =5146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame = 5147 State into memory, numbers recorded 146 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000576019287109
INFO:root:random_action_porb = 0.959403333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293000000028
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5148current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =5149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =5150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.959371666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289999999978
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 51688.51171875]
 [ 68301.578125  ]
 [ 62749.515625  ]
 [ 68301.578125  ]
 [ 58839.41015625]
 [ 54052.6171875 ]
 [ 51688.953125  ]
 [ 51188.3984375 ]
 [ 55825.828125  ]
 [ 71932.65625   ]
 [ 69749.375     ]
 [ 56292.1953125 ]
 [ 53344.30859375]
 [ 72728.1875    ]
 [ 72982.5546875 ]
 [ 62749.515625  ]]
DEBUG:root:training time = %d0.212436
INFO:root:frame =5153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =5154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471830368042
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:random_action_porb = 0.95934
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =5157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =5158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.959308333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 76404.734375  ]
 [ 56162.984375  ]
 [ 63786.828125  ]
 [ 63502.03125   ]
 [ 73086.796875  ]
 [ 48519.7421875 ]
 [ 57422.24609375]
 [ 63652.48046875]
 [ 55194.0234375 ]
 [ 68591.046875  ]
 [ 54663.03515625]
 [ 52853.96484375]
 [ 64137.046875  ]
 [ 69708.1171875 ]
 [ 53269.67578125]
 [ 63778.69140625]]
DEBUG:root:training time = %d0.227058
INFO:root:frame =5161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =5162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000425100326538
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.959276666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000337839126587
INFO:root:frame =5165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =5166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433206558228
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.959245
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:training error  = [[ 60837.62109375]
 [ 56715.14453125]
 [ 70958.765625  ]
 [ 71703.65625   ]
 [ 58238.55859375]
 [ 71703.65625   ]
 [ 58963.125     ]
 [ 57897.3359375 ]
 [ 55949.8046875 ]
 [ 67383.59375   ]
 [ 68037.9296875 ]
 [ 57390.19140625]
 [ 67478.6875    ]
 [ 63323.7421875 ]
 [ 57480.0625    ]
 [ 70460.1796875 ]]
DEBUG:root:training time = %d0.209316
INFO:root:frame =5169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =5170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264883041382
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.959213333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =5173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =5174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:random_action_porb = 0.959181666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:training error  = [[ 67987.7578125 ]
 [ 68448.40625   ]
 [ 82656.8125    ]
 [ 82326.125     ]
 [ 78137.9921875 ]
 [ 56346.1953125 ]
 [ 53344.53515625]
 [ 55772.7734375 ]
 [ 60446.59375   ]
 [ 67722.6953125 ]
 [ 64486.734375  ]
 [ 64565.37109375]
 [ 58273.20703125]
 [ 61547.359375  ]
 [ 79843.7734375 ]
 [ 66462.75      ]]
DEBUG:root:training time = %d0.216075
INFO:root:frame =5177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =5178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:random_action_porb = 0.95915
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =5181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =5182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.959118333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 67885.6953125 ]
 [ 59713.4140625 ]
 [ 55749.01953125]
 [ 58854.5703125 ]
 [ 59493.59375   ]
 [ 75525.6640625 ]
 [ 72972.        ]
 [ 58108.0703125 ]
 [ 60536.1796875 ]
 [ 64840.35546875]
 [ 62212.734375  ]
 [ 76552.7265625 ]
 [ 64489.4609375 ]
 [ 56960.76953125]
 [ 60052.51953125]
 [ 71733.2109375 ]]
DEBUG:root:training time = %d0.20553
INFO:root:frame =5185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =5186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.959086666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =5189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440835952759
INFO:root:frame =5190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.959055
INFO:root:dqn select action Tensor("ArgMax_29:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014967
INFO:root:action choosen by dqn [3]
INFO:root:frame =5192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000428199768066
INFO:root:training error  = [[ 58269.43359375]
 [ 63342.41796875]
 [ 72586.828125  ]
 [ 81431.0859375 ]
 [ 58369.6640625 ]
 [ 58269.43359375]
 [ 64262.49609375]
 [ 77246.8125    ]
 [ 63104.97265625]
 [ 74810.53125   ]
 [ 75457.515625  ]
 [ 70343.3125    ]
 [ 74019.8671875 ]
 [ 74717.609375  ]
 [ 73063.3046875 ]
 [ 74810.53125   ]]
DEBUG:root:training time = %d0.223057
INFO:root:frame =5193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =5194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000524997711182
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.959023333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =5197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =5198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:random_action_porb = 0.958991666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 58974.74609375]
 [ 75657.2265625 ]
 [ 76796.9140625 ]
 [ 75578.0078125 ]
 [ 74587.3984375 ]
 [ 79730.3984375 ]
 [ 72347.078125  ]
 [ 61273.171875  ]
 [ 70338.9140625 ]
 [ 76796.9140625 ]
 [ 62862.09375   ]
 [ 57002.7265625 ]
 [ 85440.890625  ]
 [ 69688.78125   ]
 [ 72600.515625  ]
 [ 79392.6953125 ]]
DEBUG:root:training time = %d0.208289
INFO:root:frame =5201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame =5202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00029993057251
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.95896
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000018
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =5205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470161437988
INFO:root:frame =5206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:random_action_porb = 0.958928333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:training error  = [[ 72403.828125  ]
 [ 68370.5       ]
 [ 66376.9296875 ]
 [ 66414.421875  ]
 [ 76007.6328125 ]
 [ 79168.046875  ]
 [ 75478.7109375 ]
 [ 60097.0390625 ]
 [ 63568.4921875 ]
 [ 52899.328125  ]
 [ 65347.63671875]
 [ 67768.1875    ]
 [ 71206.3671875 ]
 [ 69104.0390625 ]
 [ 70879.1796875 ]
 [ 56897.390625  ]]
DEBUG:root:training time = %d0.213411
INFO:root:frame =5209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =5210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264167785645
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.958896666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =5213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00048303604126
INFO:root:frame =5214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.958865
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 70353.9375   ]
 [ 62798.6953125]
 [ 72321.078125 ]
 [ 61323.4609375]
 [ 63501.5390625]
 [ 78571.265625 ]
 [ 65535.5      ]
 [ 71493.5703125]
 [ 61427.9765625]
 [ 63148.15625  ]
 [ 77729.0625   ]
 [ 80058.6015625]
 [ 78269.625    ]
 [ 72153.09375  ]
 [ 60034.5703125]
 [ 62393.6015625]]
DEBUG:root:training time = %d0.214578
INFO:root:frame =5217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =5218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.958833333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root:frame =5221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =5222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.958801666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 61207.6796875 ]
 [ 58943.921875  ]
 [ 84395.359375  ]
 [ 90422.078125  ]
 [ 65389.58203125]
 [ 61207.6796875 ]
 [ 65514.25      ]
 [ 63949.46875   ]
 [ 84241.09375   ]
 [ 90422.078125  ]
 [ 74045.90625   ]
 [ 53984.52734375]
 [ 62966.93359375]
 [ 80046.171875  ]
 [ 74458.1015625 ]
 [ 62966.93359375]]
DEBUG:root:training time = %d0.221784
INFO:root:frame =5225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266790390015
INFO:root:frame =5226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000291109085083
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.95877
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =5229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =5230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.958738333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 79463.421875  ]
 [ 87579.8671875 ]
 [ 65443.53125   ]
 [ 82187.203125  ]
 [ 60444.671875  ]
 [ 79463.421875  ]
 [ 68833.9765625 ]
 [ 62351.89453125]
 [ 76222.3671875 ]
 [ 74310.28125   ]
 [ 67493.3984375 ]
 [ 76501.671875  ]
 [ 84552.8828125 ]
 [ 87168.234375  ]
 [ 61384.41796875]
 [ 83335.3984375 ]]
DEBUG:root:training time = %d0.234855
INFO:root:frame =5233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =5234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491142272949
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:random_action_porb = 0.958706666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999986
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =5237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =5238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:random_action_porb = 0.958675
DEBUG:root: dqn, choose action rondomly, need time 0.000399000000016
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 76556.2421875]
 [ 80570.875    ]
 [ 83009.265625 ]
 [ 66655.9921875]
 [ 71189.6953125]
 [ 78509.6875   ]
 [ 72349.4453125]
 [ 80289.765625 ]
 [ 66239.625    ]
 [ 82973.25     ]
 [ 83678.5546875]
 [ 69438.171875 ]
 [ 84022.703125 ]
 [ 77890.59375  ]
 [ 81313.53125  ]
 [ 82973.25     ]]
DEBUG:root:training time = %d0.208199
INFO:root:frame =5241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =5242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.958643333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =5245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =5246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.958611666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 77918.9453125 ]
 [ 71260.578125  ]
 [ 79723.234375  ]
 [ 70925.2109375 ]
 [ 78786.5703125 ]
 [ 86711.2734375 ]
 [ 64894.078125  ]
 [ 79224.3828125 ]
 [ 78730.6640625 ]
 [ 76629.7578125 ]
 [ 78474.1171875 ]
 [ 85016.09375   ]
 [ 66961.1640625 ]
 [ 77678.96875   ]
 [ 89409.1796875 ]
 [ 62722.12109375]]
DEBUG:root:training time = %d0.219212
INFO:root:frame =5249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265836715698
INFO:root:frame =5250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000310897827148
DEBUG:root: save sample needs time = 0.000121116638184
INFO:root:random_action_porb = 0.95858
DEBUG:root: dqn, choose action rondomly, need time 0.000191999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174045562744
INFO:root:frame =5253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259160995483
INFO:root:frame =5254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.958548333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 72680.        ]
 [ 70025.6171875 ]
 [ 67062.28125   ]
 [ 75911.28125   ]
 [ 69660.6875    ]
 [ 62763.94921875]
 [ 67062.28125   ]
 [ 68305.1484375 ]
 [ 64357.1015625 ]
 [ 73821.5234375 ]
 [ 69660.6875    ]
 [ 67838.375     ]
 [ 80359.7890625 ]
 [ 86118.75      ]
 [ 71991.59375   ]
 [ 69109.6875    ]]
DEBUG:root:training time = %d0.220659
INFO:root:frame =5257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285148620605
INFO:root:frame =5258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482082366943
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.958516666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =5261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =5262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.958485
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 78303.78125   ]
 [ 71687.96875   ]
 [ 75718.21875   ]
 [ 69808.453125  ]
 [ 69364.3359375 ]
 [ 67609.6484375 ]
 [ 85067.640625  ]
 [ 68973.9453125 ]
 [ 83158.171875  ]
 [ 69725.90625   ]
 [ 74459.96875   ]
 [ 85067.640625  ]
 [ 64479.54296875]
 [ 72980.703125  ]
 [ 81590.5703125 ]
 [ 68973.9453125 ]]
DEBUG:root:training time = %d0.218184
INFO:root:frame =5265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =5266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame = 5267 State into memory, numbers recorded 147 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000556945800781
INFO:root:random_action_porb = 0.958453333333
INFO:root:dqn select action Tensor("ArgMax_30:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011473
INFO:root:action choosen by dqn [1]
INFO:root:frame =5268current_observation done, NOT record action [1], reward = 0
DEBUG:root: save sample needs time = 0.000887870788574
INFO:root:frame =5269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =5270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.958421666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 86891.3828125 ]
 [ 81808.5703125 ]
 [ 86777.1328125 ]
 [ 81243.09375   ]
 [ 69449.4921875 ]
 [ 67667.8125    ]
 [ 84104.53125   ]
 [ 72888.3984375 ]
 [ 65285.48828125]
 [ 83483.1875    ]
 [ 69886.65625   ]
 [ 74050.421875  ]
 [ 84507.171875  ]
 [ 75578.8125    ]
 [ 75621.5078125 ]
 [ 75578.8125    ]]
DEBUG:root:training time = %d0.219377
INFO:root:frame =5273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =5274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000355958938599
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.95839
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =5277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =5278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.958358333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 92257.2421875]
 [ 75616.140625 ]
 [ 69120.9765625]
 [ 82383.578125 ]
 [ 75234.21875  ]
 [ 75735.6875   ]
 [ 76255.53125  ]
 [ 81462.578125 ]
 [ 79033.4609375]
 [ 78113.4296875]
 [ 82383.578125 ]
 [ 76788.5234375]
 [ 71848.8671875]
 [ 77752.75     ]
 [ 76911.96875  ]
 [ 88895.6953125]]
DEBUG:root:training time = %d0.219969
INFO:root:frame =5281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =5282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.958326666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =5285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =5286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.958295
DEBUG:root: dqn, choose action rondomly, need time 0.00023299999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:training error  = [[ 73466.671875 ]
 [ 69411.40625  ]
 [ 70500.359375 ]
 [ 86231.125    ]
 [ 76307.859375 ]
 [ 69467.765625 ]
 [ 88434.5078125]
 [ 74273.8125   ]
 [ 73150.96875  ]
 [ 76238.546875 ]
 [ 78939.3203125]
 [ 77429.3125   ]
 [ 89257.3984375]
 [ 76547.59375  ]
 [ 69317.015625 ]
 [ 69411.40625  ]]
DEBUG:root:training time = %d0.190885
INFO:root:frame =5289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240802764893
INFO:root:frame =5290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000349044799805
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.958263333333
DEBUG:root: dqn, choose action rondomly, need time 0.000331999999986
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =5293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =5294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.958231666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  73694.21875  ]
 [  99256.9921875]
 [ 100635.4765625]
 [  76457.921875 ]
 [  76457.921875 ]
 [  94156.6796875]
 [  79701.7265625]
 [  82976.625    ]
 [  87683.9453125]
 [  79231.8046875]
 [  78530.2109375]
 [  82872.296875 ]
 [  96817.296875 ]
 [  77029.2890625]
 [  86004.15625  ]
 [  77682.234375 ]]
DEBUG:root:training time = %d0.21268
INFO:root:frame =5297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =5298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
DEBUG:root: save sample needs time = 0.000156164169312
INFO:root:random_action_porb = 0.9582
DEBUG:root: dqn, choose action rondomly, need time 0.000272999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000364065170288
INFO:root:frame =5301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =5302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00052809715271
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.958168333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 69687.75     ]
 [ 83837.109375 ]
 [ 95813.5234375]
 [ 95455.046875 ]
 [ 72418.5390625]
 [ 78593.7109375]
 [ 83443.125    ]
 [ 75088.578125 ]
 [ 92921.671875 ]
 [ 75036.40625  ]
 [ 93156.9921875]
 [ 94412.4609375]
 [ 91573.9140625]
 [ 75794.28125  ]
 [ 81684.6015625]
 [ 69385.9375   ]]
DEBUG:root:training time = %d0.209341
INFO:root:frame =5305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =5306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000310897827148
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.958136666667
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999982
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =5309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =5310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430822372437
INFO:root:frame = 5311 State into memory, numbers recorded 148 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000550031661987
INFO:root:random_action_porb = 0.958105
DEBUG:root: dqn, choose action rondomly, need time 0.000326000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5312current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 93228.84375  ]
 [ 85297.6484375]
 [ 79190.0234375]
 [ 89735.9375   ]
 [ 98696.9140625]
 [ 74936.125    ]
 [ 90980.5859375]
 [ 71316.640625 ]
 [ 75561.09375  ]
 [ 73424.0625   ]
 [ 78415.0390625]
 [ 91077.5234375]
 [ 91066.6171875]
 [ 86048.546875 ]
 [ 75453.21875  ]
 [ 90172.0546875]]
DEBUG:root:training time = %d0.219817
INFO:root:frame =5313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =5314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000314950942993
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:random_action_porb = 0.958073333333
DEBUG:root: dqn, choose action rondomly, need time 0.000325000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =5317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =5318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame = 5319 State into memory, numbers recorded 149 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000563144683838
INFO:root:random_action_porb = 0.958041666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5320current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 103964.0546875]
 [  81317.1484375]
 [  87052.0859375]
 [  86589.09375  ]
 [  85919.40625  ]
 [  83077.0859375]
 [  87732.2421875]
 [  98644.453125 ]
 [  76763.359375 ]
 [  78758.3359375]
 [  77906.1328125]
 [  85105.5234375]
 [  89848.890625 ]
 [  89848.890625 ]
 [  89848.890625 ]
 [  82365.359375 ]]
DEBUG:root:training time = %d0.22659
INFO:root:frame =5321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =5322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.95801
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =5325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =5326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000120162963867
INFO:root:random_action_porb = 0.957978333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:training error  = [[ 93315.0390625 ]
 [ 92548.453125  ]
 [ 97925.90625   ]
 [ 96114.2265625 ]
 [ 93740.3203125 ]
 [ 91124.390625  ]
 [ 73099.734375  ]
 [ 97427.5       ]
 [ 95370.2890625 ]
 [ 96836.140625  ]
 [ 74921.1484375 ]
 [ 77806.671875  ]
 [ 84160.8984375 ]
 [ 94161.7734375 ]
 [ 64407.40234375]
 [ 95998.609375  ]]
DEBUG:root:training time = %d0.220728
INFO:root:frame =5329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =5330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame = 5331 State into memory, numbers recorded 150 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000548124313354
INFO:root:random_action_porb = 0.957946666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5332current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =5333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =5334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:random_action_porb = 0.957915
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:training error  = [[ 92009.4296875]
 [ 85703.9921875]
 [ 73756.0078125]
 [ 86303.40625  ]
 [ 80767.25     ]
 [ 73187.15625  ]
 [ 77265.5390625]
 [ 88846.4921875]
 [ 93069.3828125]
 [ 85655.96875  ]
 [ 89382.0234375]
 [ 76746.8515625]
 [ 77582.375    ]
 [ 86912.3984375]
 [ 93553.2421875]
 [ 88282.9765625]]
DEBUG:root:training time = %d0.21812
INFO:root:frame =5337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =5338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000111103057861
INFO:root:random_action_porb = 0.957883333333
DEBUG:root: dqn, choose action rondomly, need time 0.000177000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000158071517944
INFO:root:frame =5341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =5342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.957851666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 87118.9375   ]
 [ 91071.3359375]
 [ 80833.875    ]
 [ 74887.4765625]
 [ 80489.40625  ]
 [ 87535.3671875]
 [ 76967.5      ]
 [ 78619.7265625]
 [ 87665.7265625]
 [ 86773.3984375]
 [ 82034.1328125]
 [ 98467.8671875]
 [ 87228.21875  ]
 [ 86218.796875 ]
 [ 78198.609375 ]
 [ 87476.1484375]]
DEBUG:root:training time = %d0.230051
INFO:root:frame =5345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame =5346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root:frame = 5347 State into memory, numbers recorded 151 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000534057617188
INFO:root:random_action_porb = 0.95782
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5348current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =5349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =5350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.957788333333
DEBUG:root: dqn, choose action rondomly, need time 0.000187000000011
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 105286.3046875]
 [  92707.4609375]
 [  84692.0859375]
 [  82730.109375 ]
 [ 104648.140625 ]
 [  69344.2734375]
 [  79270.015625 ]
 [ 103886.921875 ]
 [  81722.28125  ]
 [  92707.4609375]
 [  82709.6015625]
 [ 103554.796875 ]
 [  99934.703125 ]
 [  96015.25     ]
 [  96971.7265625]
 [  92045.28125  ]]
DEBUG:root:training time = %d0.207756
INFO:root:frame =5353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =5354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000398874282837
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:random_action_porb = 0.957756666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =5357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =5358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000406980514526
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.957725
DEBUG:root: dqn, choose action rondomly, need time 0.000261999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  89090.59375  ]
 [  82099.875    ]
 [ 113073.9140625]
 [ 105939.7578125]
 [  84646.8984375]
 [  81432.7578125]
 [ 109126.9921875]
 [  90623.9296875]
 [  80032.6328125]
 [  78882.265625 ]
 [  83605.125    ]
 [ 109347.765625 ]
 [ 101194.1953125]
 [  77152.9296875]
 [  96428.75     ]
 [ 101194.1953125]]
DEBUG:root:training time = %d0.188342
INFO:root:frame =5361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =5362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428915023804
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.957693333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000285148620605
INFO:root:frame =5365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =5366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000339031219482
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:random_action_porb = 0.957661666667
DEBUG:root: dqn, choose action rondomly, need time 0.000268000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  97535.7421875]
 [ 102187.921875 ]
 [ 104718.6015625]
 [ 107712.484375 ]
 [ 107935.03125  ]
 [  92060.09375  ]
 [ 110290.1484375]
 [ 107406.9375   ]
 [  76782.03125  ]
 [ 107196.453125 ]
 [ 115522.984375 ]
 [  80445.9140625]
 [  91146.5      ]
 [ 110011.4140625]
 [  91559.1328125]
 [  95568.2265625]]
DEBUG:root:training time = %d0.220686
INFO:root:frame =5369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =5370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame = 5371 State into memory, numbers recorded 152 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:random_action_porb = 0.95763
DEBUG:root: dqn, choose action rondomly, need time 0.000164000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5372current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000229835510254
INFO:root:frame =5373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =5374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 9.51290130615e-05
INFO:root:random_action_porb = 0.957598333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999981
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  91407.90625  ]
 [  74860.21875  ]
 [  92562.4140625]
 [  82133.7421875]
 [  93759.7578125]
 [  91818.46875  ]
 [  94155.1875   ]
 [  80518.7734375]
 [ 106021.1484375]
 [  78569.078125 ]
 [ 105129.515625 ]
 [  82760.1640625]
 [  87786.34375  ]
 [  92599.5625   ]
 [ 102169.5078125]
 [  81050.8671875]]
DEBUG:root:training time = %d0.214824
INFO:root:frame =5377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =5378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.0002281665802
INFO:root:random_action_porb = 0.957566666667
DEBUG:root: dqn, choose action rondomly, need time 0.000276999999983
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =5381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =5382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:random_action_porb = 0.957535
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:training error  = [[  83796.6796875]
 [ 109808.09375  ]
 [  86945.796875 ]
 [  97750.5703125]
 [ 107085.8515625]
 [ 105151.046875 ]
 [ 100582.203125 ]
 [  89681.2421875]
 [ 103661.671875 ]
 [ 112569.09375  ]
 [  85928.5625   ]
 [  88183.1875   ]
 [ 104071.140625 ]
 [  86915.8515625]
 [  95332.890625 ]
 [ 106997.03125  ]]
DEBUG:root:training time = %d0.219644
INFO:root:frame =5385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000260829925537
INFO:root:frame =5386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000292062759399
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.957503333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =5389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =5390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487089157104
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.957471666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 102134.859375 ]
 [  96811.2265625]
 [  99470.015625 ]
 [  95985.90625  ]
 [ 103666.078125 ]
 [ 108488.859375 ]
 [ 111762.5625   ]
 [ 120183.421875 ]
 [  90019.046875 ]
 [ 105329.7265625]
 [  89982.71875  ]
 [ 112335.9296875]
 [ 108488.859375 ]
 [ 109417.8515625]
 [  98751.21875  ]
 [  94213.328125 ]]
DEBUG:root:training time = %d0.208107
INFO:root:frame =5393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =5394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:random_action_porb = 0.95744
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =5397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000619888305664
INFO:root:frame =5398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.957408333333
DEBUG:root: dqn, choose action rondomly, need time 0.000335000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 110474.4375   ]
 [ 103025.640625 ]
 [  88341.890625 ]
 [  85980.3828125]
 [  85470.2890625]
 [  90213.1171875]
 [ 101235.828125 ]
 [ 113111.6796875]
 [  99645.9609375]
 [  99752.03125  ]
 [  91457.8125   ]
 [  85470.2890625]
 [  99752.03125  ]
 [  97129.3125   ]
 [ 101182.390625 ]
 [  82821.421875 ]]
DEBUG:root:training time = %d0.223147
INFO:root:frame =5401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =5402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.957376666667
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =5405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =5406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433206558228
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.957345
DEBUG:root: dqn, choose action rondomly, need time 0.000370000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000497102737427
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 114893.8515625]
 [  88871.8203125]
 [ 108454.4375   ]
 [  97616.578125 ]
 [  91004.7421875]
 [  91579.5234375]
 [  87076.2890625]
 [  97610.78125  ]
 [  90557.5      ]
 [  93437.6796875]
 [  97610.78125  ]
 [ 117826.2578125]
 [ 114893.8515625]
 [  90111.65625  ]
 [  99546.1015625]
 [  87182.078125 ]]
DEBUG:root:training time = %d0.20414
INFO:root:frame =5409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =5410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:random_action_porb = 0.957313333333
DEBUG:root: dqn, choose action rondomly, need time 0.000507999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =5413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root:frame =5414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.957281666667
DEBUG:root: dqn, choose action rondomly, need time 0.000498000000022
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 123385.484375 ]
 [ 121611.578125 ]
 [ 102163.5703125]
 [ 107557.4140625]
 [ 112414.828125 ]
 [ 109696.15625  ]
 [ 109696.15625  ]
 [  94354.5625   ]
 [ 119524.828125 ]
 [ 110850.6328125]
 [ 102330.328125 ]
 [  94226.8125   ]
 [  86600.8828125]
 [ 113843.6328125]
 [ 104708.4921875]
 [ 102163.5703125]]
DEBUG:root:training time = %d0.216001
INFO:root:frame =5417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =5418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.95725
DEBUG:root: dqn, choose action rondomly, need time 0.000367000000011
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =5421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427961349487
INFO:root:frame =5422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.957218333333
DEBUG:root: dqn, choose action rondomly, need time 0.000529
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[  76484.3828125]
 [ 121044.1953125]
 [  94805.9609375]
 [  93972.78125  ]
 [  99922.046875 ]
 [ 103150.4296875]
 [ 118983.8984375]
 [ 123025.21875  ]
 [  99922.046875 ]
 [ 107118.1328125]
 [  92351.2890625]
 [  93434.3984375]
 [ 122799.9375   ]
 [ 119490.3984375]
 [ 121825.203125 ]
 [ 109423.015625 ]]
DEBUG:root:training time = %d0.227368
INFO:root:frame =5425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =5426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265836715698
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.957186666667
DEBUG:root: dqn, choose action rondomly, need time 0.000495000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322818756104
INFO:root:frame =5429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000490188598633
INFO:root:frame =5430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424861907959
INFO:root:frame = 5431 State into memory, numbers recorded 153 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000547885894775
INFO:root:random_action_porb = 0.957155
DEBUG:root: dqn, choose action rondomly, need time 0.000543999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5432current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root:training error  = [[ 102828.2578125]
 [ 102828.2578125]
 [ 131925.375    ]
 [ 102418.4375   ]
 [ 117070.5625   ]
 [ 116448.5625   ]
 [ 114691.6953125]
 [ 118221.4765625]
 [ 114009.1015625]
 [ 115036.5703125]
 [ 119607.5625   ]
 [ 120381.5546875]
 [ 113702.328125 ]
 [  94233.109375 ]
 [  94064.4140625]
 [  98039.3125   ]]
DEBUG:root:training time = %d0.232611
INFO:root:frame =5433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:frame =5434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000387191772461
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.957123333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =5437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000490188598633
INFO:root:frame =5438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.957091666667
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000011
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 117635.265625 ]
 [  91690.9765625]
 [ 110627.046875 ]
 [ 105104.5      ]
 [ 111084.203125 ]
 [ 107267.125    ]
 [ 118248.671875 ]
 [ 109401.703125 ]
 [ 116118.546875 ]
 [  89695.859375 ]
 [  96491.8359375]
 [ 105442.8984375]
 [ 117339.703125 ]
 [ 114525.3984375]
 [  94805.359375 ]
 [ 105561.21875  ]]
DEBUG:root:training time = %d0.222479
INFO:root:frame =5441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =5442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453233718872
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.95706
DEBUG:root: dqn, choose action rondomly, need time 0.000528000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =5445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =5446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:random_action_porb = 0.957028333333
DEBUG:root: dqn, choose action rondomly, need time 0.000241999999986
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 100224.8046875]
 [  95887.296875 ]
 [  96760.7890625]
 [  96539.7734375]
 [ 112630.046875 ]
 [ 114436.1875   ]
 [  94558.3515625]
 [ 106254.3515625]
 [  97697.7578125]
 [  97889.8515625]
 [  90740.3828125]
 [ 101660.7109375]
 [ 114426.2734375]
 [  92705.3828125]
 [  96539.7734375]
 [  92572.515625 ]]
DEBUG:root:training time = %d0.218766
INFO:root:frame =5449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =5450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031590461731
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:random_action_porb = 0.956996666667
DEBUG:root: dqn, choose action rondomly, need time 0.00035699999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =5453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000389099121094
INFO:root:frame =5454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame = 5455 State into memory, numbers recorded 154 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000627040863037
INFO:root:random_action_porb = 0.956965
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5456current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 115912.3203125]
 [ 100373.5625   ]
 [  97809.5078125]
 [  97457.6796875]
 [ 111487.1875   ]
 [ 105091.203125 ]
 [ 114973.3125   ]
 [ 118776.8203125]
 [  91674.1171875]
 [ 109897.109375 ]
 [ 103545.375    ]
 [ 100076.765625 ]
 [ 118776.8203125]
 [ 102543.171875 ]
 [ 114561.421875 ]
 [ 102853.625    ]]
DEBUG:root:training time = %d0.226734
INFO:root:frame =5457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000322818756104
INFO:root:frame =5458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.956933333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =5461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =5462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000173807144165
INFO:root:random_action_porb = 0.956901666667
DEBUG:root: dqn, choose action rondomly, need time 0.000529
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  94236.7109375]
 [ 104122.1796875]
 [ 101209.109375 ]
 [  99758.5078125]
 [ 107376.5390625]
 [ 109618.8671875]
 [ 113429.8359375]
 [  95067.734375 ]
 [ 108368.5859375]
 [ 131188.28125  ]
 [  94898.59375  ]
 [ 131235.671875 ]
 [ 131235.671875 ]
 [ 116268.015625 ]
 [ 111530.8828125]
 [ 110232.4296875]]
DEBUG:root:training time = %d0.232565
INFO:root:frame =5465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =5466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:frame = 5467 State into memory, numbers recorded 155 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:random_action_porb = 0.95687
DEBUG:root: dqn, choose action rondomly, need time 0.000192999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5468current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000185012817383
INFO:root:frame =5469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263214111328
INFO:root:frame =5470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.956838333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:training error  = [[ 102299.0859375]
 [ 110765.1328125]
 [  93486.046875 ]
 [ 100129.9140625]
 [ 100157.4140625]
 [  95822.2890625]
 [  93486.046875 ]
 [ 126022.5703125]
 [ 100129.2890625]
 [ 122865.3125   ]
 [ 126783.2890625]
 [ 127428.4296875]
 [ 116231.0546875]
 [ 132108.828125 ]
 [ 100878.1953125]
 [ 110765.1328125]]
DEBUG:root:training time = %d0.218175
INFO:root:frame =5473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =5474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000400066375732
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.956806666667
DEBUG:root: dqn, choose action rondomly, need time 0.000149999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =5477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =5478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.956775
DEBUG:root: dqn, choose action rondomly, need time 0.000274999999988
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:training error  = [[ 119785.6171875]
 [ 114122.890625 ]
 [ 128295.8359375]
 [  98807.6953125]
 [ 106630.9453125]
 [ 108779.1875   ]
 [ 115646.8203125]
 [ 118421.6796875]
 [ 104283.5859375]
 [ 122286.8125   ]
 [  95468.328125 ]
 [ 123347.0625   ]
 [ 124796.9453125]
 [ 103090.21875  ]
 [  94391.7578125]
 [ 121968.7421875]]
DEBUG:root:training time = %d0.232246
INFO:root:frame =5481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root:frame =5482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000429153442383
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.956743333333
DEBUG:root: dqn, choose action rondomly, need time 0.000313999999975
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =5485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =5486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.956711666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 123259.9609375]
 [ 102475.640625 ]
 [ 117094.2890625]
 [ 135444.484375 ]
 [ 103178.3515625]
 [ 124615.8984375]
 [ 122506.4921875]
 [ 113441.015625 ]
 [ 123518.265625 ]
 [ 105966.78125  ]
 [ 105817.421875 ]
 [ 101218.7421875]
 [  87807.75     ]
 [ 114985.8984375]
 [  99608.046875 ]
 [  95917.84375  ]]
DEBUG:root:training time = %d0.225374
INFO:root:frame =5489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root:frame =5490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.95668
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =5493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =5494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.956648333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 109332.5859375]
 [ 108200.5234375]
 [ 106323.125    ]
 [ 115185.3359375]
 [ 107974.8125   ]
 [ 123550.53125  ]
 [  99235.765625 ]
 [ 121496.5      ]
 [ 106219.9765625]
 [ 110631.59375  ]
 [ 102745.6015625]
 [ 121466.8828125]
 [ 106323.125    ]
 [ 123025.5625   ]
 [ 125147.0078125]
 [  99300.6875   ]]
DEBUG:root:training time = %d0.208406
INFO:root:frame =5497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root:frame =5498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000336885452271
DEBUG:root: save sample needs time = 0.000101804733276
INFO:root:random_action_porb = 0.956616666667
DEBUG:root: dqn, choose action rondomly, need time 0.000169
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root:frame =5501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =5502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240087509155
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.956585
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 108469.875    ]
 [ 107607.703125 ]
 [ 103331.171875 ]
 [ 112867.125    ]
 [ 103331.171875 ]
 [ 108587.9453125]
 [ 120512.71875  ]
 [ 106965.40625  ]
 [ 106485.90625  ]
 [ 110849.328125 ]
 [ 112267.859375 ]
 [ 104203.5      ]
 [ 116089.9296875]
 [ 104496.2421875]
 [ 132096.046875 ]
 [ 105752.9453125]]
DEBUG:root:training time = %d0.187464
INFO:root:frame =5505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =5506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265836715698
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.956553333333
DEBUG:root: dqn, choose action rondomly, need time 0.00023299999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000270128250122
INFO:root:frame =5509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =5510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000323057174683
DEBUG:root: save sample needs time = 0.000131845474243
INFO:root:random_action_porb = 0.956521666667
DEBUG:root: dqn, choose action rondomly, need time 0.000169999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 101283.375    ]
 [ 101731.40625  ]
 [ 128602.4375   ]
 [ 111864.1171875]
 [ 113365.703125 ]
 [ 102012.5546875]
 [ 128125.1953125]
 [ 123337.1171875]
 [ 103875.2734375]
 [  93901.84375  ]
 [ 107592.0078125]
 [ 130776.171875 ]
 [ 102493.1484375]
 [ 105975.3671875]
 [ 127604.1875   ]
 [ 103324.890625 ]]
DEBUG:root:training time = %d0.204877
INFO:root:frame =5513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =5514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.95649
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =5517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =5518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000601053237915
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:random_action_porb = 0.956458333333
DEBUG:root: dqn, choose action rondomly, need time 0.000616000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 127833.484375 ]
 [ 110605.609375 ]
 [ 128972.8671875]
 [ 134221.34375  ]
 [ 120695.8515625]
 [ 103019.0546875]
 [ 107298.7890625]
 [ 115880.734375 ]
 [ 102751.8671875]
 [ 119024.6640625]
 [ 111776.6015625]
 [ 142086.671875 ]
 [ 114783.984375 ]
 [ 139356.75     ]
 [ 123067.6953125]
 [ 116775.0390625]]
DEBUG:root:training time = %d0.221336
INFO:root:frame =5521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =5522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000378131866455
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.956426666667
DEBUG:root: dqn, choose action rondomly, need time 0.000340999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =5525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000326156616211
INFO:root:frame =5526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000347852706909
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:random_action_porb = 0.956395
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 130112.03125  ]
 [ 128461.34375  ]
 [ 116744.671875 ]
 [ 140265.96875  ]
 [ 135057.6875   ]
 [ 137750.796875 ]
 [ 122789.328125 ]
 [ 112542.8828125]
 [ 116123.5390625]
 [ 129380.015625 ]
 [ 105380.7578125]
 [ 114463.609375 ]
 [ 111234.625    ]
 [ 119388.1328125]
 [  95979.546875 ]
 [ 126875.1015625]]
DEBUG:root:training time = %d0.224612
INFO:root:frame =5529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =5530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000253915786743
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.956363333333
DEBUG:root: dqn, choose action rondomly, need time 0.000337000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =5533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =5534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.956331666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:training error  = [[ 116494.21875  ]
 [ 128828.4140625]
 [ 107669.21875  ]
 [ 134922.421875 ]
 [ 121806.109375 ]
 [ 145794.578125 ]
 [ 124390.1953125]
 [ 141897.515625 ]
 [ 110299.8828125]
 [ 126990.9609375]
 [ 124390.1953125]
 [ 126155.0390625]
 [ 116729.6640625]
 [ 116494.21875  ]
 [ 131538.328125 ]
 [ 109839.1640625]]
DEBUG:root:training time = %d0.217137
INFO:root:frame =5537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000403881072998
INFO:root:frame =5538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.9563
DEBUG:root: dqn, choose action rondomly, need time 0.000331000000017
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =5541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =5542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:random_action_porb = 0.956268333333
DEBUG:root: dqn, choose action rondomly, need time 0.000511999999986
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000559091567993
INFO:root:training error  = [[ 119481.6171875]
 [ 138662.046875 ]
 [ 140238.90625  ]
 [ 135395.609375 ]
 [ 123875.46875  ]
 [ 108416.8203125]
 [ 110612.4296875]
 [ 126934.2421875]
 [ 121685.1484375]
 [ 122527.6875   ]
 [ 113081.796875 ]
 [ 116218.734375 ]
 [ 106615.0078125]
 [ 124124.7890625]
 [ 136290.03125  ]
 [ 119728.5      ]]
DEBUG:root:training time = %d0.228608
INFO:root:frame =5545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =5546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.956236666667
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =5549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000505924224854
INFO:root:frame =5550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame = 5551 State into memory, numbers recorded 156 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000631809234619
INFO:root:random_action_porb = 0.956205
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5552current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root:training error  = [[ 132604.4375   ]
 [ 130981.078125 ]
 [ 133957.078125 ]
 [ 110581.25     ]
 [ 127159.1015625]
 [ 130528.7265625]
 [ 157839.765625 ]
 [ 113159.96875  ]
 [ 129775.140625 ]
 [ 125750.578125 ]
 [ 150500.421875 ]
 [ 153623.8125   ]
 [ 100602.3359375]
 [ 124129.2578125]
 [ 118880.171875 ]
 [ 133490.328125 ]]
DEBUG:root:training time = %d0.226966
INFO:root:frame =5553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =5554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444173812866
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:random_action_porb = 0.956173333333
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =5557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame =5558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424146652222
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.956141666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:training error  = [[ 117267.7890625]
 [ 110482.2265625]
 [ 129371.9375   ]
 [ 129327.6796875]
 [ 136508.59375  ]
 [ 155496.203125 ]
 [ 117267.7890625]
 [ 171155.9375   ]
 [ 128155.2578125]
 [ 155221.765625 ]
 [ 125279.015625 ]
 [ 113226.9921875]
 [ 136508.59375  ]
 [ 128967.609375 ]
 [ 147441.375    ]
 [ 149256.21875  ]]
DEBUG:root:training time = %d0.219396
INFO:root:frame =5561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root:frame =5562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.95611
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =5565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =5566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449180603027
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.956078333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289999999978
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 147901.078125 ]
 [ 115467.5546875]
 [ 132957.09375  ]
 [ 115804.953125 ]
 [ 157767.21875  ]
 [ 137974.890625 ]
 [ 121897.1328125]
 [ 144050.265625 ]
 [ 121185.234375 ]
 [ 116122.5390625]
 [ 115653.4609375]
 [ 115320.265625 ]
 [ 144395.546875 ]
 [ 120875.390625 ]
 [ 117819.890625 ]
 [ 115653.4609375]]
DEBUG:root:training time = %d0.207235
INFO:root:frame =5569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =5570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.956046666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999983
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =5573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =5574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame = 5575 State into memory, numbers recorded 157 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000569820404053
INFO:root:random_action_porb = 0.956015
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5576current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 141161.640625]
 [ 144050.265625]
 [ 150150.578125]
 [ 145334.4375  ]
 [ 139864.3125  ]
 [ 143101.5     ]
 [ 144469.40625 ]
 [ 146177.78125 ]
 [ 143633.234375]
 [ 160504.296875]
 [ 156455.015625]
 [ 152908.875   ]
 [ 117700.921875]
 [ 146539.0625  ]
 [ 138536.984375]
 [ 147643.1875  ]]
DEBUG:root:training time = %d0.219365
INFO:root:frame =5577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263214111328
INFO:root:frame =5578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255107879639
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.955983333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =5581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000429153442383
INFO:root:frame =5582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.955951666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 106553.7890625]
 [ 144657.28125  ]
 [ 114200.1015625]
 [ 120510.       ]
 [ 126329.5703125]
 [ 137265.1875   ]
 [ 125358.1796875]
 [ 131007.234375 ]
 [ 117490.28125  ]
 [ 139718.625    ]
 [ 114926.625    ]
 [ 119401.6328125]
 [ 147275.3125   ]
 [ 126329.5703125]
 [ 116881.1875   ]
 [ 121678.3359375]]
DEBUG:root:training time = %d0.226103
INFO:root:frame =5585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =5586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002601146698
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.95592
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =5589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =5590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.955888333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 153389.640625 ]
 [ 118751.5859375]
 [ 123386.5078125]
 [ 139212.421875 ]
 [ 132254.03125  ]
 [ 120083.90625  ]
 [ 132895.84375  ]
 [ 138835.5625   ]
 [ 154640.5625   ]
 [ 134206.671875 ]
 [ 138014.796875 ]
 [ 125801.4921875]
 [ 150369.       ]
 [ 133664.140625 ]
 [ 159407.1875   ]
 [ 127969.6875   ]]
DEBUG:root:training time = %d0.224085
INFO:root:frame =5593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =5594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.955856666667
DEBUG:root: dqn, choose action rondomly, need time 0.000187000000011
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =5597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =5598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.955825
DEBUG:root: dqn, choose action rondomly, need time 0.00029600000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 134214.546875 ]
 [ 122968.0234375]
 [ 128265.7578125]
 [ 143391.28125  ]
 [ 129675.2421875]
 [ 128423.1953125]
 [ 132348.875    ]
 [ 141893.84375  ]
 [ 124713.1328125]
 [ 119724.4453125]
 [ 122798.9140625]
 [ 149729.3125   ]
 [ 138626.421875 ]
 [ 129675.2421875]
 [ 143716.515625 ]
 [ 131635.03125  ]]
DEBUG:root:training time = %d0.233709
INFO:root:frame =5601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =5602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame = 5603 State into memory, numbers recorded 158 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:random_action_porb = 0.955793333333
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5604current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =5605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =5606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.955761666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999974
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 131858.703125 ]
 [ 128438.9375   ]
 [ 139516.46875  ]
 [ 123122.171875 ]
 [ 176243.765625 ]
 [ 176243.765625 ]
 [ 121440.3359375]
 [ 169539.671875 ]
 [ 147672.828125 ]
 [ 149506.078125 ]
 [ 161512.546875 ]
 [ 131908.359375 ]
 [ 150550.4375   ]
 [ 135325.1875   ]
 [ 124929.109375 ]
 [ 123840.4140625]]
DEBUG:root:training time = %d0.214299
INFO:root:frame =5609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =5610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438213348389
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.95573
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =5613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =5614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.955698333333
DEBUG:root: dqn, choose action rondomly, need time 0.000280000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:training error  = [[ 138954.9375   ]
 [ 134060.03125  ]
 [ 154470.875    ]
 [ 136927.46875  ]
 [ 139647.453125 ]
 [ 137454.109375 ]
 [ 154506.1875   ]
 [ 160540.296875 ]
 [ 141148.796875 ]
 [ 125691.3671875]
 [ 134079.34375  ]
 [ 134632.375    ]
 [ 163773.546875 ]
 [ 162600.71875  ]
 [ 134056.453125 ]
 [ 158515.5625   ]]
DEBUG:root:training time = %d0.222715
INFO:root:frame =5617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =5618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000375986099243
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.955666666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =5621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436782836914
INFO:root:frame =5622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000501871109009
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:random_action_porb = 0.955635
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 138591.140625 ]
 [ 160270.03125  ]
 [ 169317.375    ]
 [ 151679.0625   ]
 [ 169326.625    ]
 [ 149181.515625 ]
 [ 161663.671875 ]
 [ 138591.140625 ]
 [ 175119.765625 ]
 [ 170227.5625   ]
 [ 154928.34375  ]
 [ 137141.828125 ]
 [ 125011.6171875]
 [ 165966.328125 ]
 [ 152953.9375   ]
 [ 152584.84375  ]]
DEBUG:root:training time = %d0.220937
INFO:root:frame =5625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =5626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.955603333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =5629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root:frame =5630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324010848999
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.955571666667
DEBUG:root: dqn, choose action rondomly, need time 0.000420999999989
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000366926193237
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 139599.296875 ]
 [ 128101.7734375]
 [ 144104.765625 ]
 [ 133398.640625 ]
 [ 130477.21875  ]
 [ 136005.375    ]
 [ 150687.640625 ]
 [ 147051.65625  ]
 [ 140376.8125   ]
 [ 132842.453125 ]
 [ 168080.375    ]
 [ 166097.640625 ]
 [ 144419.671875 ]
 [ 127660.359375 ]
 [ 144965.734375 ]
 [ 172788.796875 ]]
DEBUG:root:training time = %d0.225218
INFO:root:frame =5633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =5634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000296115875244
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.95554
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =5637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =5638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:random_action_porb = 0.955508333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 125236.5      ]
 [ 138917.078125 ]
 [ 128741.15625  ]
 [ 144912.5625   ]
 [ 157653.59375  ]
 [ 149681.328125 ]
 [ 128680.1953125]
 [ 154191.96875  ]
 [ 158095.546875 ]
 [ 158240.796875 ]
 [ 152303.0625   ]
 [ 155060.984375 ]
 [ 150420.5      ]
 [ 127929.8671875]
 [ 117770.9609375]
 [ 155662.609375 ]]
DEBUG:root:training time = %d0.216267
INFO:root:frame =5641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =5642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000373840332031
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.955476666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =5645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000377893447876
INFO:root:frame =5646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.955445
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:training error  = [[ 155739.296875]
 [ 150861.3125  ]
 [ 159335.453125]
 [ 153868.484375]
 [ 157255.625   ]
 [ 132425.984375]
 [ 181543.40625 ]
 [ 172977.609375]
 [ 178403.9375  ]
 [ 165349.453125]
 [ 172952.421875]
 [ 158106.03125 ]
 [ 163734.03125 ]
 [ 145257.75    ]
 [ 153413.359375]
 [ 145257.75    ]]
DEBUG:root:training time = %d0.23708
INFO:root:frame =5649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000333786010742
INFO:root:frame =5650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.955413333333
DEBUG:root: dqn, choose action rondomly, need time 0.000280000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =5653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =5654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.955381666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 156204.421875]
 [ 139685.78125 ]
 [ 142943.8125  ]
 [ 150423.90625 ]
 [ 153342.609375]
 [ 150094.953125]
 [ 115488.796875]
 [ 140662.359375]
 [ 138666.046875]
 [ 133549.5625  ]
 [ 142107.640625]
 [ 158995.328125]
 [ 138210.765625]
 [ 138117.484375]
 [ 143014.703125]
 [ 166601.890625]]
DEBUG:root:training time = %d0.226748
INFO:root:frame =5657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000355958938599
INFO:root:frame =5658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.95535
DEBUG:root: dqn, choose action rondomly, need time 0.00029600000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =5661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =5662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.955318333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 153488.34375  ]
 [ 140787.28125  ]
 [ 142606.546875 ]
 [ 137733.046875 ]
 [ 157600.859375 ]
 [ 135189.78125  ]
 [ 135881.15625  ]
 [ 164133.78125  ]
 [ 153488.34375  ]
 [ 159615.859375 ]
 [ 136568.5      ]
 [ 134868.96875  ]
 [ 128415.4921875]
 [ 148986.953125 ]
 [ 161868.3125   ]
 [ 142606.546875 ]]
DEBUG:root:training time = %d0.205362
INFO:root:frame =5665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =5666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424146652222
INFO:root:frame = 5667 State into memory, numbers recorded 159 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000545024871826
INFO:root:random_action_porb = 0.955286666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000015
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5668current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =5669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =5670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.955255
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999986
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 151284.90625 ]
 [ 175735.765625]
 [ 152002.140625]
 [ 178319.796875]
 [ 138214.03125 ]
 [ 203917.0625  ]
 [ 158042.734375]
 [ 136209.296875]
 [ 123860.6875  ]
 [ 177253.328125]
 [ 183652.421875]
 [ 187158.890625]
 [ 136377.296875]
 [ 164119.546875]
 [ 136208.203125]
 [ 142320.515625]]
DEBUG:root:training time = %d0.233251
INFO:root:frame =5673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =5674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000512838363647
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.955223333333
DEBUG:root: dqn, choose action rondomly, need time 0.000197000000014
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =5677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =5678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.955191666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:training error  = [[ 161422.6875  ]
 [ 168682.265625]
 [ 174696.65625 ]
 [ 174696.65625 ]
 [ 171912.265625]
 [ 180000.484375]
 [ 194319.96875 ]
 [ 141469.28125 ]
 [ 173391.3125  ]
 [ 166324.96875 ]
 [ 137211.640625]
 [ 152593.609375]
 [ 170535.921875]
 [ 153322.71875 ]
 [ 155217.53125 ]
 [ 143862.046875]]
DEBUG:root:training time = %d0.223184
INFO:root:frame =5681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =5682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00032901763916
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.95516
DEBUG:root: dqn, choose action rondomly, need time 0.000289999999978
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =5685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =5686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000361204147339
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.955128333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:training error  = [[ 153745.171875]
 [ 197976.765625]
 [ 154703.9375  ]
 [ 158853.234375]
 [ 191170.484375]
 [ 146307.75    ]
 [ 169975.828125]
 [ 189541.1875  ]
 [ 173197.40625 ]
 [ 179733.359375]
 [ 134594.046875]
 [ 149212.078125]
 [ 169322.203125]
 [ 165295.84375 ]
 [ 175682.953125]
 [ 175624.015625]]
DEBUG:root:training time = %d0.206143
INFO:root:frame =5689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =5690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.955096666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =5693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000424146652222
INFO:root:frame =5694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.955065
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:training error  = [[ 179662.5625   ]
 [ 161086.609375 ]
 [ 173394.984375 ]
 [ 165447.546875 ]
 [ 126434.0703125]
 [ 150343.25     ]
 [ 145869.171875 ]
 [ 192370.90625  ]
 [ 169809.59375  ]
 [ 188325.0625   ]
 [ 149043.875    ]
 [ 175698.921875 ]
 [ 138167.9375   ]
 [ 158180.203125 ]
 [ 167442.       ]
 [ 158662.578125 ]]
DEBUG:root:training time = %d0.240807
INFO:root:frame =5697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =5698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.955033333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000015
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =5701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456809997559
INFO:root:frame =5702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.955001666667
DEBUG:root: dqn, choose action rondomly, need time 0.00027399999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 149372.8125  ]
 [ 151790.515625]
 [ 150822.625   ]
 [ 153545.734375]
 [ 158684.75    ]
 [ 162942.703125]
 [ 151798.515625]
 [ 143669.875   ]
 [ 147947.65625 ]
 [ 155161.359375]
 [ 155108.28125 ]
 [ 142589.203125]
 [ 150696.734375]
 [ 147848.515625]
 [ 182872.328125]
 [ 167077.359375]]
DEBUG:root:training time = %d0.223022
INFO:root:frame =5705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =5706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000280141830444
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:random_action_porb = 0.95497
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =5709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =5710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.954938333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 192012.140625]
 [ 176449.625   ]
 [ 151767.6875  ]
 [ 161494.484375]
 [ 181905.578125]
 [ 157255.625   ]
 [ 176449.625   ]
 [ 174858.328125]
 [ 149637.125   ]
 [ 188986.328125]
 [ 155291.796875]
 [ 185992.140625]
 [ 163043.234375]
 [ 147606.78125 ]
 [ 192012.140625]
 [ 156900.703125]]
DEBUG:root:training time = %d0.245294
INFO:root:frame =5713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =5714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486135482788
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:random_action_porb = 0.954906666667
DEBUG:root: dqn, choose action rondomly, need time 0.00022100000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:frame =5717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root:frame =5718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000110864639282
INFO:root:random_action_porb = 0.954875
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 153374.734375]
 [ 168470.5625  ]
 [ 155530.875   ]
 [ 163704.40625 ]
 [ 153460.40625 ]
 [ 147126.9375  ]
 [ 150450.046875]
 [ 159877.375   ]
 [ 172325.109375]
 [ 147189.125   ]
 [ 163046.796875]
 [ 165847.      ]
 [ 181825.203125]
 [ 168470.5625  ]
 [ 153460.40625 ]
 [ 147047.90625 ]]
DEBUG:root:training time = %d0.21532
INFO:root:frame =5721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000409841537476
INFO:root:frame =5722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486135482788
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.954843333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =5725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =5726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.954811666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:training error  = [[ 204303.5625  ]
 [ 204048.0625  ]
 [ 176862.953125]
 [ 191431.890625]
 [ 154237.984375]
 [ 163480.84375 ]
 [ 157949.96875 ]
 [ 196172.      ]
 [ 160916.546875]
 [ 163200.609375]
 [ 150389.453125]
 [ 207286.796875]
 [ 176301.984375]
 [ 162123.40625 ]
 [ 165568.328125]
 [ 195215.96875 ]]
DEBUG:root:training time = %d0.220086
INFO:root:frame =5729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =5730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:player has been killed for 6 times 
INFO:root:frame = 5731 State into memory, numbers recorded 160 action = -1, reward = -1
DEBUG:root: save sample needs time = 0.000415086746216
INFO:root:random_action_porb = 0.95478
DEBUG:root: dqn, choose action rondomly, need time 0.000280000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5732current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =5733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =5734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428915023804
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.954748333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 155242.15625 ]
 [ 191985.171875]
 [ 163591.8125  ]
 [ 171496.28125 ]
 [ 158895.65625 ]
 [ 188430.59375 ]
 [ 167805.4375  ]
 [ 155242.15625 ]
 [ 153206.109375]
 [ 156398.625   ]
 [ 163357.265625]
 [ 156239.546875]
 [ 154460.890625]
 [ 153206.109375]
 [ 203457.375   ]
 [ 154246.046875]]
DEBUG:root:training time = %d0.233306
INFO:root:frame =5737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =5738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.954716666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =5741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000633955001831
INFO:root:frame =5742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000311851501465
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.954685
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 178727.46875 ]
 [ 196636.390625]
 [ 157305.578125]
 [ 166677.234375]
 [ 165324.4375  ]
 [ 149304.890625]
 [ 188364.90625 ]
 [ 155704.234375]
 [ 217185.125   ]
 [ 138074.296875]
 [ 138074.296875]
 [ 158608.5     ]
 [ 196057.390625]
 [ 152292.78125 ]
 [ 166677.234375]
 [ 153478.78125 ]]
DEBUG:root:training time = %d0.224335
INFO:root:frame =5745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =5746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.954653333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =5749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root:frame =5750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481843948364
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.954621666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999983
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0003662109375
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 212910.59375 ]
 [ 211770.28125 ]
 [ 207719.640625]
 [ 152973.421875]
 [ 205651.171875]
 [ 181096.375   ]
 [ 196855.125   ]
 [ 191197.8125  ]
 [ 202991.171875]
 [ 162773.234375]
 [ 206011.375   ]
 [ 190955.34375 ]
 [ 154331.96875 ]
 [ 213296.046875]
 [ 193044.8125  ]
 [ 189099.703125]]
DEBUG:root:training time = %d0.232073
INFO:root:frame =5753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =5754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.95459
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000022
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =5757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =5758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000418901443481
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.954558333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 184219.515625]
 [ 183321.125   ]
 [ 184219.515625]
 [ 193768.046875]
 [ 187420.921875]
 [ 194498.234375]
 [ 188575.1875  ]
 [ 179234.40625 ]
 [ 180393.484375]
 [ 182992.203125]
 [ 185784.15625 ]
 [ 186466.671875]
 [ 189542.03125 ]
 [ 159572.15625 ]
 [ 143701.703125]
 [ 180418.375   ]]
DEBUG:root:training time = %d0.212954
INFO:root:frame =5761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =5762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031304359436
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.954526666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =5765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438213348389
INFO:root:frame =5766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464200973511
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.954495
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 166028.796875]
 [ 184888.25    ]
 [ 232416.265625]
 [ 178419.203125]
 [ 201865.921875]
 [ 178419.203125]
 [ 181158.71875 ]
 [ 197119.53125 ]
 [ 195052.90625 ]
 [ 174479.984375]
 [ 183587.984375]
 [ 156121.84375 ]
 [ 169901.75    ]
 [ 185182.296875]
 [ 197119.53125 ]
 [ 186112.609375]]
DEBUG:root:training time = %d0.23169
INFO:root:frame =5769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =5770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.954463333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =5773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =5774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.954431666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 179918.875   ]
 [ 181212.75    ]
 [ 219645.09375 ]
 [ 171269.875   ]
 [ 183248.796875]
 [ 182544.234375]
 [ 166731.453125]
 [ 165304.1875  ]
 [ 202084.046875]
 [ 198901.625   ]
 [ 145950.859375]
 [ 171529.84375 ]
 [ 202718.90625 ]
 [ 199967.484375]
 [ 167540.3125  ]
 [ 178764.625   ]]
DEBUG:root:training time = %d0.22114
INFO:root:frame =5777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:frame =5778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469207763672
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.9544
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999981
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =5781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =5782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.954368333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332832336426
INFO:root:training error  = [[ 182322.328125]
 [ 182228.109375]
 [ 182303.984375]
 [ 177178.921875]
 [ 193697.984375]
 [ 223453.78125 ]
 [ 161697.84375 ]
 [ 174507.71875 ]
 [ 190284.671875]
 [ 206595.109375]
 [ 192054.5     ]
 [ 217636.828125]
 [ 182228.109375]
 [ 212475.078125]
 [ 195811.4375  ]
 [ 161448.96875 ]]
DEBUG:root:training time = %d0.214517
INFO:root:frame =5785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =5786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame = 5787 State into memory, numbers recorded 161 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000517129898071
INFO:root:random_action_porb = 0.954336666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000015
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5788current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =5789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =5790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047492980957
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.954305
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 174495.484375]
 [ 193092.015625]
 [ 179453.171875]
 [ 178311.140625]
 [ 198219.296875]
 [ 163420.4375  ]
 [ 177639.609375]
 [ 172545.3125  ]
 [ 163374.640625]
 [ 176466.859375]
 [ 178976.515625]
 [ 173389.28125 ]
 [ 183173.96875 ]
 [ 181241.03125 ]
 [ 165178.34375 ]
 [ 184313.      ]]
DEBUG:root:training time = %d0.222214
INFO:root:frame =5793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =5794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:frame = 5795 State into memory, numbers recorded 162 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.00059700012207
INFO:root:random_action_porb = 0.954273333333
DEBUG:root: dqn, choose action rondomly, need time 0.000493000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5796current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =5797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =5798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.954241666667
INFO:root:dqn select action Tensor("ArgMax_31:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012787
INFO:root:action choosen by dqn [1]
INFO:root:frame =5800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 188417.03125 ]
 [ 184740.46875 ]
 [ 175792.265625]
 [ 193372.765625]
 [ 190224.609375]
 [ 189724.046875]
 [ 203697.078125]
 [ 181227.3125  ]
 [ 173963.9375  ]
 [ 181565.875   ]
 [ 179841.84375 ]
 [ 177749.53125 ]
 [ 189934.65625 ]
 [ 177391.5     ]
 [ 199000.5     ]
 [ 211676.375   ]]
DEBUG:root:training time = %d0.221991
INFO:root:frame =5801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265836715698
INFO:root:frame =5802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308036804199
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.95421
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root:frame =5805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491142272949
INFO:root:frame =5806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.954178333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:training error  = [[ 213296.046875]
 [ 177477.484375]
 [ 178460.453125]
 [ 192199.1875  ]
 [ 192035.25    ]
 [ 177818.703125]
 [ 179018.65625 ]
 [ 200729.375   ]
 [ 186469.203125]
 [ 170749.734375]
 [ 204342.84375 ]
 [ 191371.21875 ]
 [ 214072.9375  ]
 [ 176077.359375]
 [ 176398.765625]
 [ 200448.140625]]
DEBUG:root:training time = %d0.218983
INFO:root:frame =5809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:frame =5810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227928161621
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.954146666667
DEBUG:root: dqn, choose action rondomly, need time 0.000168000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:frame =5813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002281665802
INFO:root:frame =5814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000216007232666
DEBUG:root: save sample needs time = 9.29832458496e-05
INFO:root:random_action_porb = 0.954115
DEBUG:root: dqn, choose action rondomly, need time 0.000178000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 211165.375   ]
 [ 180478.109375]
 [ 244774.65625 ]
 [ 222330.203125]
 [ 186607.125   ]
 [ 190054.703125]
 [ 176824.765625]
 [ 192956.      ]
 [ 215322.28125 ]
 [ 176796.84375 ]
 [ 190491.75    ]
 [ 204584.390625]
 [ 224874.15625 ]
 [ 192956.      ]
 [ 199614.796875]
 [ 171365.28125 ]]
DEBUG:root:training time = %d0.223924
INFO:root:frame =5817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =5818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.954083333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =5821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =5822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.954051666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:training error  = [[ 214229.3125  ]
 [ 221969.34375 ]
 [ 226189.875   ]
 [ 218058.453125]
 [ 239413.34375 ]
 [ 206682.5625  ]
 [ 206947.6875  ]
 [ 176455.78125 ]
 [ 205009.09375 ]
 [ 221969.34375 ]
 [ 216697.0625  ]
 [ 213837.15625 ]
 [ 242377.84375 ]
 [ 181426.5     ]
 [ 193363.75    ]
 [ 189044.921875]]
DEBUG:root:training time = %d0.216511
INFO:root:frame =5825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:frame =5826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.95402
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =5829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000498056411743
INFO:root:frame =5830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root:frame = 5831 State into memory, numbers recorded 163 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000554084777832
INFO:root:random_action_porb = 0.953988333333
DEBUG:root: dqn, choose action rondomly, need time 0.000333999999981
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5832current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 183885.1875  ]
 [ 236433.84375 ]
 [ 239886.625   ]
 [ 194792.0625  ]
 [ 217227.453125]
 [ 218588.671875]
 [ 175899.140625]
 [ 202627.90625 ]
 [ 178801.796875]
 [ 240833.640625]
 [ 201159.703125]
 [ 232770.4375  ]
 [ 224341.453125]
 [ 201159.703125]
 [ 191904.3125  ]
 [ 182799.671875]]
DEBUG:root:training time = %d0.214441
INFO:root:frame =5833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =5834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.953956666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000337839126587
INFO:root:frame =5837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000389814376831
INFO:root:frame =5838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000585794448853
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.953925
DEBUG:root: dqn, choose action rondomly, need time 0.000337000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 223917.5     ]
 [ 225561.921875]
 [ 194444.828125]
 [ 186602.484375]
 [ 187915.484375]
 [ 186360.      ]
 [ 193766.328125]
 [ 176916.359375]
 [ 186453.59375 ]
 [ 166147.796875]
 [ 196089.828125]
 [ 235767.140625]
 [ 191406.25    ]
 [ 186602.484375]
 [ 218169.265625]
 [ 235954.015625]]
DEBUG:root:training time = %d0.216617
INFO:root:frame =5841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =5842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.953893333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =5845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =5846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481128692627
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.953861666667
DEBUG:root: dqn, choose action rondomly, need time 0.000573000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:training error  = [[ 201598.375   ]
 [ 199296.84375 ]
 [ 195481.421875]
 [ 207629.734375]
 [ 208914.15625 ]
 [ 198253.65625 ]
 [ 206008.71875 ]
 [ 198947.359375]
 [ 194697.25    ]
 [ 190801.75    ]
 [ 210793.078125]
 [ 211399.703125]
 [ 198588.609375]
 [ 190420.578125]
 [ 193659.296875]
 [ 195120.625   ]]
DEBUG:root:training time = %d0.231368
INFO:root:frame =5849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =5850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame = 5851 State into memory, numbers recorded 164 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:random_action_porb = 0.95383
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5852current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =5853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =5854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486850738525
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.953798333333
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000011
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:training error  = [[ 190610.6875  ]
 [ 201915.078125]
 [ 256566.      ]
 [ 191460.9375  ]
 [ 185780.359375]
 [ 198420.65625 ]
 [ 199652.75    ]
 [ 196953.9375  ]
 [ 188049.265625]
 [ 196104.53125 ]
 [ 198420.65625 ]
 [ 203110.421875]
 [ 214425.0625  ]
 [ 201356.40625 ]
 [ 201356.40625 ]
 [ 255353.546875]]
DEBUG:root:training time = %d0.225754
INFO:root:frame =5857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =5858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000363111495972
DEBUG:root: save sample needs time = 0.000146150588989
INFO:root:random_action_porb = 0.953766666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =5861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488996505737
INFO:root:frame =5862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame = 5863 State into memory, numbers recorded 165 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:random_action_porb = 0.953735
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5864current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 219855.671875]
 [ 201104.953125]
 [ 241228.703125]
 [ 208479.640625]
 [ 233078.671875]
 [ 204091.296875]
 [ 200256.25    ]
 [ 198690.453125]
 [ 241957.34375 ]
 [ 189609.21875 ]
 [ 233213.53125 ]
 [ 200934.1875  ]
 [ 264111.6875  ]
 [ 199240.171875]
 [ 202393.671875]
 [ 236418.171875]]
DEBUG:root:training time = %d0.218158
INFO:root:frame =5865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =5866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275850296021
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:random_action_porb = 0.953703333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000341892242432
INFO:root:frame =5869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =5870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488996505737
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.953671666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 255896.671875]
 [ 242513.921875]
 [ 242513.921875]
 [ 219905.125   ]
 [ 219905.125   ]
 [ 196731.234375]
 [ 200791.515625]
 [ 196199.6875  ]
 [ 192716.71875 ]
 [ 195082.671875]
 [ 198295.390625]
 [ 219905.125   ]
 [ 250023.4375  ]
 [ 201822.9375  ]
 [ 195082.671875]
 [ 250023.4375  ]]
DEBUG:root:training time = %d0.224612
INFO:root:frame =5873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =5874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000280857086182
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.95364
DEBUG:root: dqn, choose action rondomly, need time 0.000354999999985
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =5877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049090385437
INFO:root:frame =5878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470161437988
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.953608333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000015
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 246451.15625 ]
 [ 259704.703125]
 [ 250327.25    ]
 [ 198165.828125]
 [ 224734.328125]
 [ 198911.640625]
 [ 275966.5625  ]
 [ 201759.765625]
 [ 228462.53125 ]
 [ 248728.1875  ]
 [ 244367.046875]
 [ 206244.59375 ]
 [ 250000.984375]
 [ 246243.703125]
 [ 244367.046875]
 [ 245396.390625]]
DEBUG:root:training time = %d0.215951
INFO:root:frame =5881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =5882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.953576666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =5885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =5886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.953545
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 230679.453125]
 [ 240670.734375]
 [ 221289.390625]
 [ 186075.96875 ]
 [ 221289.390625]
 [ 222301.203125]
 [ 202407.71875 ]
 [ 188782.609375]
 [ 219561.796875]
 [ 203815.21875 ]
 [ 211080.125   ]
 [ 237419.21875 ]
 [ 189975.09375 ]
 [ 214108.640625]
 [ 178365.171875]
 [ 192729.578125]]
DEBUG:root:training time = %d0.222301
INFO:root:frame =5889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =5890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.953513333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =5893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =5894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.953481666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 242616.859375]
 [ 219992.140625]
 [ 269779.8125  ]
 [ 219562.71875 ]
 [ 257058.90625 ]
 [ 221114.859375]
 [ 231785.828125]
 [ 206940.578125]
 [ 216216.828125]
 [ 211305.421875]
 [ 266283.21875 ]
 [ 228797.796875]
 [ 237581.984375]
 [ 197610.640625]
 [ 201254.75    ]
 [ 225744.6875  ]]
DEBUG:root:training time = %d0.224397
INFO:root:frame =5897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =5898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.95345
DEBUG:root: dqn, choose action rondomly, need time 0.000151999999986
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =5901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =5902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.953418333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 197142.9375  ]
 [ 206561.375   ]
 [ 264341.59375 ]
 [ 232275.046875]
 [ 203657.40625 ]
 [ 213835.796875]
 [ 227554.15625 ]
 [ 267959.90625 ]
 [ 236914.15625 ]
 [ 175011.5     ]
 [ 292080.09375 ]
 [ 262390.0625  ]
 [ 269263.6875  ]
 [ 209239.234375]
 [ 211111.53125 ]
 [ 229014.59375 ]]
DEBUG:root:training time = %d0.207028
INFO:root:frame =5905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270843505859
INFO:root:frame =5906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 0.000101804733276
INFO:root:random_action_porb = 0.953386666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =5909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =5910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000586032867432
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.953355
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:training error  = [[ 254310.40625 ]
 [ 273091.96875 ]
 [ 258669.59375 ]
 [ 254454.234375]
 [ 225971.171875]
 [ 222102.328125]
 [ 232043.546875]
 [ 251395.5     ]
 [ 221105.671875]
 [ 208670.515625]
 [ 253670.609375]
 [ 255108.84375 ]
 [ 258165.21875 ]
 [ 231669.25    ]
 [ 265835.90625 ]
 [ 253670.609375]]
DEBUG:root:training time = %d0.201116
INFO:root:frame =5913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =5914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.953323333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =5917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =5918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.953291666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 252334.53125 ]
 [ 207211.65625 ]
 [ 238391.875   ]
 [ 226571.359375]
 [ 266912.5     ]
 [ 252334.53125 ]
 [ 235084.828125]
 [ 210097.796875]
 [ 232045.421875]
 [ 210097.796875]
 [ 246186.53125 ]
 [ 251944.1875  ]
 [ 234492.390625]
 [ 226571.359375]
 [ 246780.9375  ]
 [ 227178.84375 ]]
DEBUG:root:training time = %d0.215567
INFO:root:frame =5921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =5922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:random_action_porb = 0.95326
DEBUG:root: dqn, choose action rondomly, need time 0.000381000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =5925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =5926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.953228333333
DEBUG:root: dqn, choose action rondomly, need time 0.000323000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 225853.28125 ]
 [ 234109.5     ]
 [ 224405.75    ]
 [ 228082.734375]
 [ 219895.96875 ]
 [ 230627.875   ]
 [ 206962.796875]
 [ 271457.28125 ]
 [ 229653.421875]
 [ 205660.484375]
 [ 233313.53125 ]
 [ 237459.203125]
 [ 219895.96875 ]
 [ 222772.015625]
 [ 219895.96875 ]
 [ 212203.28125 ]]
DEBUG:root:training time = %d0.216478
INFO:root:frame =5929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249147415161
INFO:root:frame =5930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.953196666667
DEBUG:root: dqn, choose action rondomly, need time 0.000323000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =5933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =5934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264883041382
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.953165
INFO:root:dqn select action Tensor("ArgMax_32:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.009241
INFO:root:action choosen by dqn [2]
INFO:root:frame =5936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 219920.703125]
 [ 270676.3125  ]
 [ 256934.140625]
 [ 232180.921875]
 [ 239394.234375]
 [ 274083.9375  ]
 [ 258682.5     ]
 [ 211461.65625 ]
 [ 253231.078125]
 [ 290478.90625 ]
 [ 217358.109375]
 [ 262145.      ]
 [ 230328.75    ]
 [ 214846.734375]
 [ 249112.125   ]
 [ 244737.953125]]
DEBUG:root:training time = %d0.208222
INFO:root:frame =5937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =5938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
DEBUG:root: save sample needs time = 0.000151872634888
INFO:root:random_action_porb = 0.953133333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999983
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =5941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =5942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame = 5943 State into memory, numbers recorded 166 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000540971755981
INFO:root:random_action_porb = 0.953101666667
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000018
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5944current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000387191772461
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 218998.40625 ]
 [ 245229.03125 ]
 [ 231720.953125]
 [ 249887.703125]
 [ 230321.25    ]
 [ 245229.03125 ]
 [ 278921.1875  ]
 [ 242803.53125 ]
 [ 229662.78125 ]
 [ 229203.4375  ]
 [ 273315.5625  ]
 [ 264283.34375 ]
 [ 225631.5     ]
 [ 242803.53125 ]
 [ 244973.765625]
 [ 266555.40625 ]]
DEBUG:root:training time = %d0.2269
INFO:root:frame =5945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000320196151733
INFO:root:player has been killed for 7 times 
INFO:root:frame =5946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000331163406372
INFO:root:frame = 5947 State into memory, numbers recorded 167 action = 0, reward = -1
DEBUG:root: save sample needs time = 0.000554084777832
INFO:root:random_action_porb = 0.95307
DEBUG:root: dqn, choose action rondomly, need time 0.000318000000021
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5948current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =5949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000486135482788
INFO:root:frame =5950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.953038333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 260269.359375]
 [ 270868.40625 ]
 [ 225009.40625 ]
 [ 240154.546875]
 [ 258856.375   ]
 [ 258851.40625 ]
 [ 232373.890625]
 [ 275222.15625 ]
 [ 271005.65625 ]
 [ 259948.609375]
 [ 277707.375   ]
 [ 225900.625   ]
 [ 218045.21875 ]
 [ 278586.03125 ]
 [ 298316.53125 ]
 [ 275222.15625 ]]
DEBUG:root:training time = %d0.224525
INFO:root:frame =5953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =5954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000314950942993
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.953006666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =5957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =5958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.952975
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 263562.90625 ]
 [ 235474.203125]
 [ 276291.90625 ]
 [ 237599.125   ]
 [ 242912.28125 ]
 [ 226043.609375]
 [ 231687.109375]
 [ 233626.84375 ]
 [ 258559.34375 ]
 [ 257310.484375]
 [ 269585.0625  ]
 [ 258932.890625]
 [ 248168.40625 ]
 [ 264449.03125 ]
 [ 277370.90625 ]
 [ 214444.0625  ]]
DEBUG:root:training time = %d0.212605
INFO:root:frame =5961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =5962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000351905822754
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:random_action_porb = 0.952943333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999986
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =5965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =5966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000521898269653
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:random_action_porb = 0.952911666667
INFO:root:dqn select action Tensor("ArgMax_33:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013766
INFO:root:action choosen by dqn [1]
INFO:root:frame =5968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root:training error  = [[ 239467.8125  ]
 [ 206375.      ]
 [ 280028.03125 ]
 [ 245669.3125  ]
 [ 232036.015625]
 [ 275103.3125  ]
 [ 247048.796875]
 [ 298570.46875 ]
 [ 275103.3125  ]
 [ 301168.375   ]
 [ 269603.3125  ]
 [ 294685.6875  ]
 [ 234194.5625  ]
 [ 235856.296875]
 [ 236471.359375]
 [ 296692.96875 ]]
DEBUG:root:training time = %d0.213002
INFO:root:frame =5969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274181365967
INFO:root:frame =5970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00040602684021
INFO:root:frame = 5971 State into memory, numbers recorded 168 action = [1], reward = 0
DEBUG:root: save sample needs time = 0.0012059211731
INFO:root:random_action_porb = 0.95288
DEBUG:root: dqn, choose action rondomly, need time 0.000157999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5972current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =5973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000424861907959
INFO:root:frame =5974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.952848333333
INFO:root:dqn select action Tensor("ArgMax_34:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013293
INFO:root:action choosen by dqn [0]
INFO:root:frame =5976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:training error  = [[ 257273.828125]
 [ 276051.71875 ]
 [ 245049.171875]
 [ 231343.15625 ]
 [ 235294.15625 ]
 [ 232561.296875]
 [ 315868.15625 ]
 [ 249724.6875  ]
 [ 269481.625   ]
 [ 297023.9375  ]
 [ 272471.78125 ]
 [ 272112.      ]
 [ 262835.46875 ]
 [ 228128.4375  ]
 [ 274871.84375 ]
 [ 267837.59375 ]]
DEBUG:root:training time = %d0.204909
INFO:root:frame =5977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240802764893
INFO:root:frame =5978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:frame = 5979 State into memory, numbers recorded 169 action = [0], reward = 0
DEBUG:root: save sample needs time = 0.00111603736877
INFO:root:random_action_porb = 0.952816666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5980current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000366926193237
INFO:root:frame =5981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000842094421387
INFO:root:frame =5982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.952785
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 241612.5625  ]
 [ 292277.5     ]
 [ 279273.03125 ]
 [ 237510.59375 ]
 [ 290820.0625  ]
 [ 228371.046875]
 [ 297981.65625 ]
 [ 227575.578125]
 [ 237510.59375 ]
 [ 244695.4375  ]
 [ 254023.875   ]
 [ 277654.90625 ]
 [ 279544.5625  ]
 [ 290653.65625 ]
 [ 255377.234375]
 [ 289493.375   ]]
DEBUG:root:training time = %d0.228316
INFO:root:frame =5985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =5986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000278949737549
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.952753333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =5989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =5990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:random_action_porb = 0.952721666667
DEBUG:root: dqn, choose action rondomly, need time 0.000340000000023
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 252051.0625  ]
 [ 292454.9375  ]
 [ 268131.8125  ]
 [ 236612.890625]
 [ 255253.875   ]
 [ 250324.328125]
 [ 262738.34375 ]
 [ 264603.75    ]
 [ 282533.78125 ]
 [ 286428.78125 ]
 [ 238184.03125 ]
 [ 259664.890625]
 [ 256124.953125]
 [ 236612.890625]
 [ 276539.375   ]
 [ 286427.75    ]]
DEBUG:root:training time = %d0.219696
INFO:root:frame =5993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:frame =5994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
DEBUG:root: save sample needs time = 0.000134229660034
INFO:root:random_action_porb = 0.95269
DEBUG:root: dqn, choose action rondomly, need time 0.000519999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =5997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =5998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root:one frame running time = 0.00646399999999
DEBUG:root:total training time = 156.147206
INFO:root:frame num = 6000 frame round: 0
INFO:root:random_action_porb = 0.952658333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 265770.46875 ]
 [ 247905.765625]
 [ 321646.28125 ]
 [ 242765.03125 ]
 [ 288796.03125 ]
 [ 272004.      ]
 [ 288796.03125 ]
 [ 267053.78125 ]
 [ 251973.609375]
 [ 307424.75    ]
 [ 318099.3125  ]
 [ 265770.46875 ]
 [ 224846.375   ]
 [ 233745.8125  ]
 [ 329913.375   ]
 [ 241527.140625]]
DEBUG:root:training time = %d0.236472
INFO:root:frame =6001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00036883354187
INFO:root:frame =6002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042986869812
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.952626666667
DEBUG:root: dqn, choose action rondomly, need time 0.000368999999978
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =6005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =6006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.952595
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 254793.265625]
 [ 246427.890625]
 [ 260947.375   ]
 [ 290642.0625  ]
 [ 233766.578125]
 [ 313602.1875  ]
 [ 256749.046875]
 [ 298895.      ]
 [ 246138.078125]
 [ 245461.21875 ]
 [ 267752.6875  ]
 [ 265396.03125 ]
 [ 237730.515625]
 [ 275990.15625 ]
 [ 256495.75    ]
 [ 258866.3125  ]]
DEBUG:root:training time = %d0.224617
INFO:root:frame =6009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =6010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000121831893921
INFO:root:random_action_porb = 0.952563333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =6013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449180603027
INFO:root:frame =6014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000243186950684
INFO:root:random_action_porb = 0.952531666667
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 248606.4375  ]
 [ 300901.53125 ]
 [ 269573.90625 ]
 [ 299866.40625 ]
 [ 253344.109375]
 [ 248389.328125]
 [ 275642.4375  ]
 [ 263233.125   ]
 [ 275965.53125 ]
 [ 262455.09375 ]
 [ 276842.46875 ]
 [ 270149.1875  ]
 [ 306116.90625 ]
 [ 275143.28125 ]
 [ 268808.84375 ]
 [ 240561.515625]]
DEBUG:root:training time = %d0.215983
INFO:root:frame =6017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000326156616211
INFO:root:frame =6018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000260829925537
INFO:root:frame = 6019 State into memory, numbers recorded 170 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000540971755981
INFO:root:random_action_porb = 0.9525
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6020current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000385046005249
INFO:root:frame =6021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =6022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.952468333333
DEBUG:root: dqn, choose action rondomly, need time 0.000256000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 320930.      ]
 [ 250747.625   ]
 [ 251367.09375 ]
 [ 277094.28125 ]
 [ 243859.46875 ]
 [ 239191.6875  ]
 [ 321432.53125 ]
 [ 255494.703125]
 [ 221850.203125]
 [ 253306.765625]
 [ 252597.53125 ]
 [ 252597.53125 ]
 [ 253390.328125]
 [ 265936.625   ]
 [ 285189.375   ]
 [ 265142.53125 ]]
DEBUG:root:training time = %d0.207098
INFO:root:frame =6025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =6026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.952436666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =6029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =6030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000251054763794
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.952405
DEBUG:root: dqn, choose action rondomly, need time 0.00029600000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000348806381226
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 267264.78125 ]
 [ 313152.8125  ]
 [ 315383.15625 ]
 [ 274387.71875 ]
 [ 262029.015625]
 [ 325675.3125  ]
 [ 326189.34375 ]
 [ 260784.765625]
 [ 322742.71875 ]
 [ 329184.59375 ]
 [ 273322.6875  ]
 [ 303651.59375 ]
 [ 319130.09375 ]
 [ 305203.375   ]
 [ 334111.09375 ]
 [ 315795.71875 ]]
DEBUG:root:training time = %d0.218678
INFO:root:frame =6033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =6034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000301122665405
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.952373333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =6037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =6038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433206558228
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:random_action_porb = 0.952341666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:training error  = [[ 262566.15625 ]
 [ 353513.84375 ]
 [ 309466.21875 ]
 [ 296862.15625 ]
 [ 299852.5     ]
 [ 330342.0625  ]
 [ 256659.      ]
 [ 257204.484375]
 [ 306056.375   ]
 [ 259989.453125]
 [ 269327.5625  ]
 [ 248656.109375]
 [ 321073.84375 ]
 [ 319381.71875 ]
 [ 333138.65625 ]
 [ 260310.21875 ]]
DEBUG:root:training time = %d0.214063
INFO:root:frame =6041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =6042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame = 6043 State into memory, numbers recorded 171 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000643014907837
INFO:root:random_action_porb = 0.95231
DEBUG:root: dqn, choose action rondomly, need time 0.00031199999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6044current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =6045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =6046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.952278333333
DEBUG:root: dqn, choose action rondomly, need time 0.000327000000027
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:training error  = [[ 294541.53125 ]
 [ 265745.28125 ]
 [ 322185.9375  ]
 [ 299183.375   ]
 [ 317450.8125  ]
 [ 334231.90625 ]
 [ 331723.125   ]
 [ 340271.6875  ]
 [ 317993.5625  ]
 [ 247082.78125 ]
 [ 294345.46875 ]
 [ 260787.765625]
 [ 300618.75    ]
 [ 260787.765625]
 [ 255427.578125]
 [ 251105.71875 ]]
DEBUG:root:training time = %d0.227981
INFO:root:frame =6049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =6050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.952246666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =6053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =6054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00053882598877
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.952215
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000356912612915
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 313944.625  ]
 [ 277034.65625]
 [ 278445.84375]
 [ 274614.90625]
 [ 313027.125  ]
 [ 310229.40625]
 [ 296001.875  ]
 [ 268739.96875]
 [ 308543.375  ]
 [ 277995.65625]
 [ 308925.375  ]
 [ 298540.59375]
 [ 299836.46875]
 [ 307093.46875]
 [ 287647.84375]
 [ 277995.65625]]
DEBUG:root:training time = %d0.228989
INFO:root:frame =6057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =6058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000334024429321
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.952183333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =6061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =6062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.952151666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 301274.5    ]
 [ 287643.65625]
 [ 262887.53125]
 [ 290090.59375]
 [ 337608.65625]
 [ 285287.4375 ]
 [ 296996.25   ]
 [ 338892.25   ]
 [ 273713.90625]
 [ 372574.34375]
 [ 293429.59375]
 [ 271764.6875 ]
 [ 300523.46875]
 [ 329350.4375 ]
 [ 313544.21875]
 [ 310556.9375 ]]
DEBUG:root:training time = %d0.22661
INFO:root:frame =6065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =6066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000253915786743
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.95212
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =6069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000365972518921
INFO:root:frame =6070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000206232070923
INFO:root:random_action_porb = 0.952088333333
DEBUG:root: dqn, choose action rondomly, need time 0.000330999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 292443.3125 ]
 [ 298822.375  ]
 [ 359440.0625 ]
 [ 311095.96875]
 [ 280434.375  ]
 [ 313055.5625 ]
 [ 306352.53125]
 [ 304023.     ]
 [ 286796.84375]
 [ 307499.5    ]
 [ 366610.15625]
 [ 304339.6875 ]
 [ 263300.28125]
 [ 306307.125  ]
 [ 299403.46875]
 [ 307480.     ]]
DEBUG:root:training time = %d0.217922
INFO:root:frame =6073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:frame =6074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.952056666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =6077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00044584274292
INFO:root:frame =6078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.952025
INFO:root:dqn select action Tensor("ArgMax_35:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010704
INFO:root:action choosen by dqn [1]
INFO:root:frame =6080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 305221.71875 ]
 [ 263710.34375 ]
 [ 348406.59375 ]
 [ 361796.375   ]
 [ 333207.40625 ]
 [ 272574.75    ]
 [ 339758.0625  ]
 [ 333268.3125  ]
 [ 278957.28125 ]
 [ 350553.03125 ]
 [ 272888.90625 ]
 [ 352396.4375  ]
 [ 242581.265625]
 [ 332953.78125 ]
 [ 335299.8125  ]
 [ 275640.375   ]]
DEBUG:root:training time = %d0.218775
INFO:root:frame =6081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000369071960449
INFO:root:frame =6082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000340938568115
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:random_action_porb = 0.951993333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =6085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =6086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480175018311
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.951961666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:training error  = [[ 342727.90625]
 [ 359826.59375]
 [ 323931.0625 ]
 [ 344996.78125]
 [ 289367.3125 ]
 [ 370926.1875 ]
 [ 333510.75   ]
 [ 265390.     ]
 [ 317521.25   ]
 [ 361118.84375]
 [ 318879.6875 ]
 [ 353797.25   ]
 [ 338671.71875]
 [ 357780.375  ]
 [ 288778.1875 ]
 [ 268644.8125 ]]
DEBUG:root:training time = %d0.226114
INFO:root:frame =6089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =6090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.95193
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =6093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =6094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.951898333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294000000025
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 383018.34375]
 [ 294822.5    ]
 [ 293659.21875]
 [ 332620.28125]
 [ 311366.1875 ]
 [ 296276.09375]
 [ 342086.75   ]
 [ 296276.09375]
 [ 346550.6875 ]
 [ 286103.8125 ]
 [ 317140.5625 ]
 [ 244923.5    ]
 [ 285550.375  ]
 [ 338747.875  ]
 [ 334348.21875]
 [ 294822.5    ]]
DEBUG:root:training time = %d0.228103
INFO:root:frame =6097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =6098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.951866666667
DEBUG:root: dqn, choose action rondomly, need time 0.000168000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:frame =6101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =6102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.951835
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 284850.5    ]
 [ 311932.0625 ]
 [ 302337.8125 ]
 [ 335357.5    ]
 [ 346504.6875 ]
 [ 321566.53125]
 [ 305772.28125]
 [ 253167.1875 ]
 [ 368989.8125 ]
 [ 275312.34375]
 [ 307507.0625 ]
 [ 357254.875  ]
 [ 323802.125  ]
 [ 305559.5625 ]
 [ 295243.65625]
 [ 365063.78125]]
DEBUG:root:training time = %d0.231987
INFO:root:frame =6105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =6106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000385999679565
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.951803333333
DEBUG:root: dqn, choose action rondomly, need time 0.000329000000022
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =6109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488996505737
INFO:root:frame =6110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.951771666667
DEBUG:root: dqn, choose action rondomly, need time 0.000280000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 309794.4375 ]
 [ 295086.625  ]
 [ 347049.84375]
 [ 357602.84375]
 [ 351148.84375]
 [ 268694.40625]
 [ 327043.25   ]
 [ 310945.625  ]
 [ 301881.5625 ]
 [ 295281.875  ]
 [ 280024.9375 ]
 [ 357602.84375]
 [ 326418.0625 ]
 [ 268694.40625]
 [ 355296.3125 ]
 [ 292910.34375]]
DEBUG:root:training time = %d0.230712
INFO:root:frame =6113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:frame =6114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000256061553955
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.95174
INFO:root:dqn select action Tensor("ArgMax_36:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015048
INFO:root:action choosen by dqn [1]
INFO:root:frame =6116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:frame =6117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:frame =6118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248908996582
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.951708333333
DEBUG:root: dqn, choose action rondomly, need time 0.000174000000015
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000156879425049
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 297707.71875]
 [ 282606.4375 ]
 [ 304697.53125]
 [ 374032.59375]
 [ 380161.34375]
 [ 356374.03125]
 [ 316893.125  ]
 [ 369166.59375]
 [ 345622.28125]
 [ 340136.125  ]
 [ 344039.53125]
 [ 380161.34375]
 [ 350849.125  ]
 [ 338734.21875]
 [ 364972.90625]
 [ 373737.59375]]
DEBUG:root:training time = %d0.225814
INFO:root:frame =6121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =6122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288963317871
DEBUG:root: save sample needs time = 0.000111103057861
INFO:root:random_action_porb = 0.951676666667
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =6125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =6126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488996505737
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.951645
DEBUG:root: dqn, choose action rondomly, need time 0.00043500000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 327506.9375 ]
 [ 288975.53125]
 [ 390000.25   ]
 [ 349955.4375 ]
 [ 357959.15625]
 [ 331038.40625]
 [ 328392.78125]
 [ 283279.65625]
 [ 367530.78125]
 [ 385562.15625]
 [ 327506.9375 ]
 [ 378437.625  ]
 [ 334519.90625]
 [ 369337.5    ]
 [ 331352.     ]
 [ 304068.25   ]]
DEBUG:root:training time = %d0.209673
INFO:root:frame =6129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =6130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000317096710205
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:random_action_porb = 0.951613333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000023
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =6133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441789627075
INFO:root:frame =6134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.951581666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:training error  = [[ 348923.25   ]
 [ 346059.90625]
 [ 312333.625  ]
 [ 289815.03125]
 [ 322921.375  ]
 [ 307090.21875]
 [ 344434.875  ]
 [ 354620.25   ]
 [ 360847.75   ]
 [ 346917.5625 ]
 [ 323235.5625 ]
 [ 347613.875  ]
 [ 363102.75   ]
 [ 347570.125  ]
 [ 293016.0625 ]
 [ 342631.875  ]]
DEBUG:root:training time = %d0.21775
INFO:root:frame =6137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =6138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.95155
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =6141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =6142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00048303604126
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.951518333333
DEBUG:root: dqn, choose action rondomly, need time 0.000325000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 346834.71875]
 [ 302996.5    ]
 [ 366431.59375]
 [ 352762.90625]
 [ 344544.9375 ]
 [ 375692.375  ]
 [ 383310.9375 ]
 [ 346397.78125]
 [ 355346.375  ]
 [ 395923.59375]
 [ 364540.     ]
 [ 369084.71875]
 [ 361003.8125 ]
 [ 271943.90625]
 [ 342647.875  ]
 [ 342949.78125]]
DEBUG:root:training time = %d0.219653
INFO:root:frame =6145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =6146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.951486666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999985
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =6149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =6150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.951455
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 346980.8125 ]
 [ 353373.34375]
 [ 319354.125  ]
 [ 318281.09375]
 [ 314511.75   ]
 [ 324869.9375 ]
 [ 336320.71875]
 [ 331090.09375]
 [ 331531.90625]
 [ 307682.5625 ]
 [ 355519.875  ]
 [ 361982.03125]
 [ 376820.9375 ]
 [ 357699.78125]
 [ 375903.09375]
 [ 315311.875  ]]
DEBUG:root:training time = %d0.232658
INFO:root:frame =6153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =6154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000112771987915
INFO:root:random_action_porb = 0.951423333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =6158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.951391666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 307810.40625]
 [ 337681.28125]
 [ 397584.4375 ]
 [ 390880.15625]
 [ 324714.09375]
 [ 328414.0625 ]
 [ 295173.625  ]
 [ 354100.53125]
 [ 314177.78125]
 [ 338585.34375]
 [ 401355.65625]
 [ 333602.125  ]
 [ 339476.9375 ]
 [ 353456.96875]
 [ 393941.34375]
 [ 436686.0625 ]]
DEBUG:root:training time = %d0.244729
INFO:root:frame =6161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =6162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449180603027
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.95136
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =6166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame = 6167 State into memory, numbers recorded 172 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000568866729736
INFO:root:random_action_porb = 0.951328333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000018
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6168current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[ 302178.90625]
 [ 348578.375  ]
 [ 347263.90625]
 [ 387185.34375]
 [ 335462.6875 ]
 [ 354106.34375]
 [ 354865.71875]
 [ 330335.3125 ]
 [ 382304.3125 ]
 [ 304508.875  ]
 [ 344672.1875 ]
 [ 316991.     ]
 [ 378056.84375]
 [ 349143.65625]
 [ 326567.59375]
 [ 326867.90625]]
DEBUG:root:training time = %d0.210265
INFO:root:frame =6169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =6170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000176906585693
INFO:root:random_action_porb = 0.951296666667
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =6173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462770462036
INFO:root:frame =6174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.951265
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:training error  = [[ 337019.9375 ]
 [ 320265.34375]
 [ 375344.09375]
 [ 347128.09375]
 [ 403653.     ]
 [ 399943.84375]
 [ 318620.5625 ]
 [ 339498.5625 ]
 [ 384489.625  ]
 [ 330757.53125]
 [ 374412.53125]
 [ 337929.90625]
 [ 278476.78125]
 [ 315902.1875 ]
 [ 318620.5625 ]
 [ 327348.25   ]]
DEBUG:root:training time = %d0.208889
INFO:root:frame =6177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =6178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229120254517
DEBUG:root: save sample needs time = 9.17911529541e-05
INFO:root:random_action_porb = 0.951233333333
DEBUG:root: dqn, choose action rondomly, need time 0.000170000000026
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000130176544189
INFO:root:frame =6181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =6182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000451803207397
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.951201666667
DEBUG:root: dqn, choose action rondomly, need time 0.000449000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304222106934
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 326128.     ]
 [ 319456.78125]
 [ 322574.09375]
 [ 370989.25   ]
 [ 425461.90625]
 [ 319454.5625 ]
 [ 321692.8125 ]
 [ 420927.25   ]
 [ 376174.96875]
 [ 285048.59375]
 [ 322574.09375]
 [ 324030.     ]
 [ 324770.875  ]
 [ 393717.03125]
 [ 330783.375  ]
 [ 346770.3125 ]]
DEBUG:root:training time = %d0.203832
INFO:root:frame =6185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000359058380127
INFO:root:frame =6186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241041183472
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.95117
INFO:root:dqn select action Tensor("ArgMax_37:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012031
INFO:root:action choosen by dqn [4]
INFO:root:frame =6188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =6189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375032424927
INFO:root:frame =6190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.951138333333
DEBUG:root: dqn, choose action rondomly, need time 0.000162999999986
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000130891799927
INFO:root:training error  = [[ 390128.34375]
 [ 310252.25   ]
 [ 317369.375  ]
 [ 415382.78125]
 [ 364580.09375]
 [ 353300.21875]
 [ 392882.90625]
 [ 412433.625  ]
 [ 375317.78125]
 [ 400869.53125]
 [ 346985.4375 ]
 [ 315428.125  ]
 [ 351447.5    ]
 [ 313804.5625 ]
 [ 420059.6875 ]
 [ 412921.71875]]
DEBUG:root:training time = %d0.235414
INFO:root:frame =6193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =6194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000254154205322
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.951106666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290999999976
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =6197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =6198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.951075
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 338068.4375 ]
 [ 404980.59375]
 [ 347724.4375 ]
 [ 331588.15625]
 [ 323918.8125 ]
 [ 395969.09375]
 [ 377676.25   ]
 [ 324940.09375]
 [ 330346.53125]
 [ 377676.25   ]
 [ 374112.625  ]
 [ 374112.625  ]
 [ 393083.6875 ]
 [ 342493.5625 ]
 [ 387918.53125]
 [ 404980.59375]]
DEBUG:root:training time = %d0.238136
INFO:root:frame =6201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000220775604248
INFO:root:frame =6202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.951043333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =6205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000509977340698
INFO:root:frame =6206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000250101089478
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.951011666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:training error  = [[ 374750.8125 ]
 [ 371358.125  ]
 [ 341057.15625]
 [ 352251.53125]
 [ 379531.8125 ]
 [ 350762.375  ]
 [ 327623.1875 ]
 [ 415742.875  ]
 [ 394774.15625]
 [ 340107.65625]
 [ 359198.875  ]
 [ 383616.9375 ]
 [ 322129.40625]
 [ 369721.     ]
 [ 368023.5    ]
 [ 383578.21875]]
DEBUG:root:training time = %d0.215537
INFO:root:frame =6209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =6210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
DEBUG:root: save sample needs time = 0.000121116638184
INFO:root:random_action_porb = 0.95098
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =6213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =6214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449180603027
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.950948333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:training error  = [[ 362205.3125 ]
 [ 350544.9375 ]
 [ 435400.21875]
 [ 433025.6875 ]
 [ 377509.4375 ]
 [ 372916.5625 ]
 [ 364307.71875]
 [ 365395.46875]
 [ 358054.96875]
 [ 434776.6875 ]
 [ 421365.8125 ]
 [ 369924.09375]
 [ 434094.375  ]
 [ 368647.     ]
 [ 361735.28125]
 [ 366501.34375]]
DEBUG:root:training time = %d0.206528
INFO:root:frame =6217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =6218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.950916666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =6221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =6222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.950885
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 415268.21875]
 [ 416017.4375 ]
 [ 449909.5    ]
 [ 353398.90625]
 [ 407526.375  ]
 [ 356217.8125 ]
 [ 408534.4375 ]
 [ 379933.78125]
 [ 362253.5    ]
 [ 463819.53125]
 [ 344942.84375]
 [ 416516.46875]
 [ 435081.9375 ]
 [ 412899.125  ]
 [ 416725.71875]
 [ 416725.71875]]
DEBUG:root:training time = %d0.222748
INFO:root:frame =6225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =6226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
INFO:root:frame = 6227 State into memory, numbers recorded 173 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00054407119751
INFO:root:random_action_porb = 0.950853333333
DEBUG:root: dqn, choose action rondomly, need time 0.000168000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6228current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =6229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046181678772
INFO:root:frame =6230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000420093536377
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.950821666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 400703.84375]
 [ 339073.0625 ]
 [ 406403.75   ]
 [ 350141.46875]
 [ 337294.375  ]
 [ 441186.5625 ]
 [ 393083.6875 ]
 [ 398459.3125 ]
 [ 346342.59375]
 [ 356749.5625 ]
 [ 404199.15625]
 [ 338438.75   ]
 [ 448214.5625 ]
 [ 438082.40625]
 [ 430816.59375]
 [ 329042.28125]]
DEBUG:root:training time = %d0.241115
INFO:root:frame =6233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000640153884888
INFO:root:frame =6234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475883483887
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:random_action_porb = 0.95079
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =6237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000509023666382
INFO:root:frame =6238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.950758333333
DEBUG:root: dqn, choose action rondomly, need time 0.000562000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000509977340698
INFO:root:training error  = [[ 378592.65625]
 [ 389168.84375]
 [ 346073.6875 ]
 [ 306170.9375 ]
 [ 409525.     ]
 [ 380969.84375]
 [ 401344.53125]
 [ 422463.1875 ]
 [ 349983.15625]
 [ 416582.     ]
 [ 370444.59375]
 [ 391174.5    ]
 [ 404909.75   ]
 [ 364400.875  ]
 [ 394098.25   ]
 [ 361712.96875]]
DEBUG:root:training time = %d0.204574
INFO:root:frame =6241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =6242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000398874282837
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.950726666667
DEBUG:root: dqn, choose action rondomly, need time 0.000324000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =6245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000501155853271
INFO:root:frame =6246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.950695
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:training error  = [[ 433347.0625 ]
 [ 379216.625  ]
 [ 412867.75   ]
 [ 441923.71875]
 [ 398040.21875]
 [ 337114.0625 ]
 [ 395057.65625]
 [ 409306.3125 ]
 [ 343626.09375]
 [ 399973.5    ]
 [ 421296.0625 ]
 [ 457718.3125 ]
 [ 397921.9375 ]
 [ 411983.46875]
 [ 361441.6875 ]
 [ 384699.15625]]
DEBUG:root:training time = %d0.209755
INFO:root:frame =6249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =6250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000253915786743
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.950663333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root:frame =6253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =6254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.950631666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 365469.84375]
 [ 386516.     ]
 [ 356672.5625 ]
 [ 396650.25   ]
 [ 353343.15625]
 [ 357911.25   ]
 [ 366681.09375]
 [ 407705.9375 ]
 [ 359365.125  ]
 [ 429403.75   ]
 [ 347631.15625]
 [ 350904.65625]
 [ 390158.84375]
 [ 363122.75   ]
 [ 365977.75   ]
 [ 405467.96875]]
DEBUG:root:training time = %d0.213715
INFO:root:frame =6257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:frame =6258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9506
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =6261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =6262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.950568333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 345132.15625]
 [ 367475.125  ]
 [ 429667.4375 ]
 [ 317960.53125]
 [ 393231.875  ]
 [ 457931.09375]
 [ 425705.28125]
 [ 363676.125  ]
 [ 385837.5    ]
 [ 359219.96875]
 [ 473675.96875]
 [ 430528.21875]
 [ 434834.625  ]
 [ 417020.8125 ]
 [ 363579.5625 ]
 [ 362054.875  ]]
DEBUG:root:training time = %d0.200435
INFO:root:frame =6265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000368118286133
INFO:root:frame =6266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000380039215088
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.950536666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =6269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =6270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000181913375854
INFO:root:random_action_porb = 0.950505
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000019
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:training error  = [[ 469670.625  ]
 [ 486043.1875 ]
 [ 368964.90625]
 [ 395730.6875 ]
 [ 478659.9375 ]
 [ 464326.46875]
 [ 368023.5    ]
 [ 398556.71875]
 [ 486043.1875 ]
 [ 384328.5625 ]
 [ 415661.     ]
 [ 375916.28125]
 [ 491305.15625]
 [ 437387.1875 ]
 [ 369119.125  ]
 [ 389411.34375]]
DEBUG:root:training time = %d0.222958
INFO:root:frame =6273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =6274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000281095504761
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.950473333333
DEBUG:root: dqn, choose action rondomly, need time 0.000182999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:frame =6277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =6278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame = 6279 State into memory, numbers recorded 174 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.00056791305542
INFO:root:random_action_porb = 0.950441666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6280current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:training error  = [[ 454693.40625]
 [ 407854.375  ]
 [ 369439.59375]
 [ 441945.78125]
 [ 423756.5    ]
 [ 403939.6875 ]
 [ 423756.5    ]
 [ 382857.59375]
 [ 383312.125  ]
 [ 383451.21875]
 [ 376438.5625 ]
 [ 427976.625  ]
 [ 372731.71875]
 [ 429545.84375]
 [ 432186.84375]
 [ 388372.40625]]
DEBUG:root:training time = %d0.219173
INFO:root:frame =6281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =6282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.95041
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =6285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =6286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.950378333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:training error  = [[ 412091.28125]
 [ 427865.46875]
 [ 415183.90625]
 [ 409700.     ]
 [ 416724.46875]
 [ 377432.65625]
 [ 416323.625  ]
 [ 388332.21875]
 [ 389132.28125]
 [ 413256.875  ]
 [ 399857.375  ]
 [ 368457.3125 ]
 [ 426258.53125]
 [ 403737.375  ]
 [ 399857.375  ]
 [ 383427.03125]]
DEBUG:root:training time = %d0.2345
INFO:root:frame =6289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =6290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000296115875244
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.950346666667
DEBUG:root: dqn, choose action rondomly, need time 0.00029600000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =6293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224828720093
INFO:root:frame =6294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:random_action_porb = 0.950315
DEBUG:root: dqn, choose action rondomly, need time 0.000160999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 414986.34375]
 [ 434828.1875 ]
 [ 378960.46875]
 [ 383597.5625 ]
 [ 415936.8125 ]
 [ 434524.3125 ]
 [ 477456.71875]
 [ 415936.8125 ]
 [ 363159.25   ]
 [ 477456.71875]
 [ 378108.5    ]
 [ 387451.53125]
 [ 363824.5625 ]
 [ 386445.5625 ]
 [ 483706.65625]
 [ 481927.46875]]
DEBUG:root:training time = %d0.222758
INFO:root:frame =6297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:player has been killed for 8 times 
INFO:root:frame =6298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000184059143066
INFO:root:frame = 6299 State into memory, numbers recorded 175 action = 4, reward = -1
DEBUG:root: save sample needs time = 0.000606775283813
INFO:root:random_action_porb = 0.950283333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000018
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6300current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =6301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =6302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049901008606
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.950251666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 390778.8125 ]
 [ 401915.125  ]
 [ 464279.875  ]
 [ 424881.1875 ]
 [ 477664.5625 ]
 [ 388371.1875 ]
 [ 470399.0625 ]
 [ 442408.15625]
 [ 479648.21875]
 [ 391290.5625 ]
 [ 400173.625  ]
 [ 407359.3125 ]
 [ 445406.34375]
 [ 446096.15625]
 [ 378943.65625]
 [ 371374.78125]]
DEBUG:root:training time = %d0.219692
INFO:root:frame =6305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =6306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.95022
DEBUG:root: dqn, choose action rondomly, need time 0.000203999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000194072723389
INFO:root:frame =6309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =6310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428915023804
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.950188333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 332651.8125 ]
 [ 436065.46875]
 [ 415390.3125 ]
 [ 469880.78125]
 [ 406371.375  ]
 [ 493129.     ]
 [ 457744.75   ]
 [ 412614.28125]
 [ 400859.625  ]
 [ 399304.28125]
 [ 469880.78125]
 [ 413280.71875]
 [ 440478.5    ]
 [ 440478.5    ]
 [ 544528.6875 ]
 [ 410939.84375]]
DEBUG:root:training time = %d0.223751
INFO:root:frame =6313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =6314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
INFO:root:frame = 6315 State into memory, numbers recorded 176 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000545978546143
INFO:root:random_action_porb = 0.950156666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6316current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =6317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame =6318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.950125
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:training error  = [[ 447033.28125]
 [ 398466.6875 ]
 [ 472912.75   ]
 [ 418922.4375 ]
 [ 418922.4375 ]
 [ 494360.03125]
 [ 546147.     ]
 [ 418922.4375 ]
 [ 492724.46875]
 [ 497288.03125]
 [ 417509.0625 ]
 [ 418127.6875 ]
 [ 408927.78125]
 [ 476957.5    ]
 [ 478414.03125]
 [ 396452.25   ]]
DEBUG:root:training time = %d0.211553
INFO:root:frame =6321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =6322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.950093333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =6325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =6326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame = 6327 State into memory, numbers recorded 177 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root:random_action_porb = 0.950061666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6328current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000312805175781
INFO:root:training error  = [[ 467713.0625 ]
 [ 451185.09375]
 [ 400806.46875]
 [ 411518.5    ]
 [ 490774.125  ]
 [ 360784.40625]
 [ 529394.0625 ]
 [ 476648.65625]
 [ 462283.125  ]
 [ 428854.875  ]
 [ 432874.03125]
 [ 434261.6875 ]
 [ 402865.40625]
 [ 493680.53125]
 [ 541204.5    ]
 [ 386078.96875]]
DEBUG:root:training time = %d0.218487
INFO:root:frame =6329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =6330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000361919403076
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:random_action_porb = 0.95003
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000327825546265
INFO:root:frame =6333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =6334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.949998333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[ 494516.625  ]
 [ 464996.125  ]
 [ 528445.25   ]
 [ 409571.25   ]
 [ 414674.375  ]
 [ 466376.9375 ]
 [ 487847.6875 ]
 [ 457347.09375]
 [ 491977.5625 ]
 [ 425334.53125]
 [ 453152.5    ]
 [ 498001.75   ]
 [ 386901.     ]
 [ 498001.75   ]
 [ 492242.     ]
 [ 502546.6875 ]]
DEBUG:root:training time = %d0.235541
INFO:root:frame =6337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =6338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000284910202026
DEBUG:root: save sample needs time = 0.000123977661133
INFO:root:random_action_porb = 0.949966666667
DEBUG:root: dqn, choose action rondomly, need time 0.000191000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180959701538
INFO:root:frame =6341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000451803207397
INFO:root:frame =6342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.949935
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 540156.125  ]
 [ 412432.375  ]
 [ 468755.53125]
 [ 424140.5625 ]
 [ 471704.6875 ]
 [ 410788.375  ]
 [ 446060.9375 ]
 [ 485604.8125 ]
 [ 479717.21875]
 [ 412087.5    ]
 [ 403876.375  ]
 [ 449432.75   ]
 [ 398104.3125 ]
 [ 484165.90625]
 [ 390374.78125]
 [ 495554.125  ]]
DEBUG:root:training time = %d0.211393
INFO:root:frame =6345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =6346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:random_action_porb = 0.949903333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =6349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =6350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:random_action_porb = 0.949871666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000404119491577
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 403110.90625]
 [ 495827.78125]
 [ 361817.53125]
 [ 504731.15625]
 [ 410232.75   ]
 [ 480655.125  ]
 [ 502751.625  ]
 [ 432558.     ]
 [ 385289.34375]
 [ 443186.65625]
 [ 528885.4375 ]
 [ 403110.90625]
 [ 420564.90625]
 [ 498099.59375]
 [ 416704.28125]
 [ 504124.96875]]
DEBUG:root:training time = %d0.192756
INFO:root:frame =6353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255823135376
INFO:root:frame =6354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.94984
DEBUG:root: dqn, choose action rondomly, need time 0.00035299999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000360012054443
INFO:root:frame =6357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =6358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:random_action_porb = 0.949808333333
DEBUG:root: dqn, choose action rondomly, need time 0.000336000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:training error  = [[ 525053.0625 ]
 [ 510793.5625 ]
 [ 501582.09375]
 [ 500139.03125]
 [ 507725.84375]
 [ 439442.09375]
 [ 457355.     ]
 [ 419671.15625]
 [ 443321.875  ]
 [ 498571.15625]
 [ 525053.0625 ]
 [ 416258.09375]
 [ 498571.15625]
 [ 572440.     ]
 [ 416386.625  ]
 [ 545517.8125 ]]
DEBUG:root:training time = %d0.204988
INFO:root:frame =6361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000356197357178
INFO:root:frame =6362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247001647949
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.949776666667
DEBUG:root: dqn, choose action rondomly, need time 0.00029600000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000673055648804
INFO:root:frame =6365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =6366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000613212585449
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:random_action_porb = 0.949745
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:training error  = [[ 519587.5625 ]
 [ 476283.3125 ]
 [ 542812.0625 ]
 [ 489569.4375 ]
 [ 461358.     ]
 [ 495288.8125 ]
 [ 465620.96875]
 [ 473065.875  ]
 [ 521385.53125]
 [ 524398.0625 ]
 [ 518844.46875]
 [ 474186.90625]
 [ 495288.8125 ]
 [ 482536.4375 ]
 [ 496723.5    ]
 [ 481614.3125 ]]
DEBUG:root:training time = %d0.216881
INFO:root:frame =6369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:frame =6370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00059700012207
DEBUG:root: save sample needs time = 0.000256776809692
INFO:root:random_action_porb = 0.949713333333
DEBUG:root: dqn, choose action rondomly, need time 0.000464999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =6373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =6374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.949681666667
DEBUG:root: dqn, choose action rondomly, need time 0.000551000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 433394.625  ]
 [ 449995.96875]
 [ 429854.375  ]
 [ 452463.8125 ]
 [ 462740.0625 ]
 [ 438904.96875]
 [ 432175.28125]
 [ 435958.4375 ]
 [ 429876.15625]
 [ 460239.     ]
 [ 445371.15625]
 [ 452463.8125 ]
 [ 511603.53125]
 [ 478196.5625 ]
 [ 433356.0625 ]
 [ 445905.71875]]
DEBUG:root:training time = %d0.236374
INFO:root:frame =6377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =6378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494003295898
DEBUG:root: save sample needs time = 0.0002281665802
INFO:root:random_action_porb = 0.94965
DEBUG:root: dqn, choose action rondomly, need time 0.000158999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142812728882
INFO:root:frame =6381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000476121902466
INFO:root:frame =6382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.949618333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000018
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:training error  = [[ 616168.25   ]
 [ 544174.1875 ]
 [ 435761.15625]
 [ 497759.1875 ]
 [ 447570.15625]
 [ 551647.125  ]
 [ 480400.59375]
 [ 429346.15625]
 [ 523156.96875]
 [ 515022.09375]
 [ 441148.9375 ]
 [ 428857.4375 ]
 [ 442671.90625]
 [ 440022.34375]
 [ 478823.46875]
 [ 477906.21875]]
DEBUG:root:training time = %d0.223339
INFO:root:frame =6385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285148620605
INFO:root:frame =6386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000304937362671
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:random_action_porb = 0.949586666667
DEBUG:root: dqn, choose action rondomly, need time 0.000331000000017
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =6389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =6390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.949555
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:training error  = [[ 521013.28125]
 [ 630671.75   ]
 [ 524014.8125 ]
 [ 536749.4375 ]
 [ 542981.875  ]
 [ 451215.25   ]
 [ 476162.     ]
 [ 522445.21875]
 [ 435900.40625]
 [ 447682.53125]
 [ 448064.1875 ]
 [ 475011.71875]
 [ 517742.09375]
 [ 572964.75   ]
 [ 496983.6875 ]
 [ 517272.8125 ]]
DEBUG:root:training time = %d0.220109
INFO:root:frame =6393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249147415161
INFO:root:frame =6394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319004058838
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.949523333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999983
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =6397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =6398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.949491666667
DEBUG:root: dqn, choose action rondomly, need time 0.000370000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:training error  = [[ 428977.65625]
 [ 582209.25   ]
 [ 542897.     ]
 [ 606048.5625 ]
 [ 446815.21875]
 [ 498754.59375]
 [ 619333.625  ]
 [ 578502.875  ]
 [ 518241.09375]
 [ 542182.     ]
 [ 497968.65625]
 [ 468143.28125]
 [ 507659.03125]
 [ 548678.75   ]
 [ 578502.875  ]
 [ 536802.375  ]]
DEBUG:root:training time = %d0.20772
INFO:root:frame =6401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =6402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.94946
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame =6406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.949428333333
DEBUG:root: dqn, choose action rondomly, need time 0.000194000000022
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 489253.8125 ]
 [ 542766.     ]
 [ 462127.78125]
 [ 497868.0625 ]
 [ 534184.     ]
 [ 500708.25   ]
 [ 528073.3125 ]
 [ 467893.40625]
 [ 536258.6875 ]
 [ 445481.9375 ]
 [ 461365.96875]
 [ 536258.6875 ]
 [ 513661.96875]
 [ 504559.09375]
 [ 531730.0625 ]
 [ 529053.0625 ]]
DEBUG:root:training time = %d0.214493
INFO:root:frame =6409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =6410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.949396666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =6413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =6414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.949365
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 521307.96875]
 [ 500173.5625 ]
 [ 496482.625  ]
 [ 483193.34375]
 [ 472112.59375]
 [ 495088.125  ]
 [ 488520.46875]
 [ 481167.125  ]
 [ 487978.65625]
 [ 545763.125  ]
 [ 486573.     ]
 [ 471437.8125 ]
 [ 505343.25   ]
 [ 458203.40625]
 [ 479922.84375]
 [ 527528.4375 ]]
DEBUG:root:training time = %d0.214556
INFO:root:frame =6417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =6418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000261068344116
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.949333333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =6421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =6422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.949301666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 458765.4375 ]
 [ 558591.3125 ]
 [ 477154.4375 ]
 [ 476726.875  ]
 [ 574558.0625 ]
 [ 474134.46875]
 [ 476606.84375]
 [ 550264.0625 ]
 [ 470113.78125]
 [ 575517.8125 ]
 [ 565985.875  ]
 [ 457780.4375 ]
 [ 573667.1875 ]
 [ 448962.8125 ]
 [ 522925.3125 ]
 [ 466124.90625]]
DEBUG:root:training time = %d0.22087
INFO:root:frame =6425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =6426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.94927
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =6429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =6430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.949238333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 454810.625  ]
 [ 473082.     ]
 [ 463581.46875]
 [ 492935.625  ]
 [ 563725.25   ]
 [ 498546.3125 ]
 [ 569876.0625 ]
 [ 560967.375  ]
 [ 538397.6875 ]
 [ 498230.5625 ]
 [ 513939.15625]
 [ 514369.125  ]
 [ 450386.46875]
 [ 524942.6875 ]
 [ 521640.84375]
 [ 530275.5    ]]
DEBUG:root:training time = %d0.221451
INFO:root:frame =6433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000276803970337
INFO:root:frame =6434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264883041382
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.949206666667
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =6437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =6438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.949175
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 581229.0625 ]
 [ 512867.1875 ]
 [ 500063.0625 ]
 [ 583408.0625 ]
 [ 578511.75   ]
 [ 559585.8125 ]
 [ 555757.125  ]
 [ 535662.4375 ]
 [ 524792.6875 ]
 [ 564039.125  ]
 [ 509726.28125]
 [ 522102.21875]
 [ 504718.65625]
 [ 579608.625  ]
 [ 574966.75   ]
 [ 440001.625  ]]
DEBUG:root:training time = %d0.213622
INFO:root:frame =6441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274181365967
INFO:root:frame =6442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000355005264282
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:random_action_porb = 0.949143333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:frame =6445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =6446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.949111666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999986
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000370979309082
INFO:root:training error  = [[ 505558.5    ]
 [ 594397.3125 ]
 [ 543164.6875 ]
 [ 574689.875  ]
 [ 556408.1875 ]
 [ 493647.59375]
 [ 546603.1875 ]
 [ 603868.625  ]
 [ 479181.65625]
 [ 485044.25   ]
 [ 581844.1875 ]
 [ 495123.875  ]
 [ 556408.1875 ]
 [ 488852.25   ]
 [ 463266.34375]
 [ 562459.     ]]
DEBUG:root:training time = %d0.232086
INFO:root:frame =6449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =6450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.94908
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =6453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =6454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.949048333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:training error  = [[ 560430.625  ]
 [ 513598.96875]
 [ 473874.9375 ]
 [ 547864.5    ]
 [ 480695.75   ]
 [ 500293.75   ]
 [ 500279.90625]
 [ 460694.9375 ]
 [ 584988.9375 ]
 [ 503472.     ]
 [ 482769.84375]
 [ 583610.9375 ]
 [ 557254.9375 ]
 [ 500293.75   ]
 [ 430824.28125]
 [ 549036.125  ]]
DEBUG:root:training time = %d0.231474
INFO:root:frame =6457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =6458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000280141830444
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.949016666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000015
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame =6462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000201225280762
INFO:root:random_action_porb = 0.948985
DEBUG:root: dqn, choose action rondomly, need time 0.000173999999987
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 456144.59375]
 [ 489654.15625]
 [ 518854.3125 ]
 [ 470746.0625 ]
 [ 537260.375  ]
 [ 484083.     ]
 [ 487868.15625]
 [ 540766.3125 ]
 [ 452177.4375 ]
 [ 556523.3125 ]
 [ 492828.6875 ]
 [ 484613.125  ]
 [ 452177.4375 ]
 [ 542397.75   ]
 [ 507947.125  ]
 [ 476953.4375 ]]
DEBUG:root:training time = %d0.207588
INFO:root:frame =6465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:frame =6466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277996063232
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.948953333333
DEBUG:root: dqn, choose action rondomly, need time 0.000175000000013
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root:frame =6469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =6470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.948921666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 550890.125  ]
 [ 618359.5    ]
 [ 574595.0625 ]
 [ 540968.875  ]
 [ 524846.5    ]
 [ 628376.6875 ]
 [ 439210.375  ]
 [ 491714.59375]
 [ 583078.375  ]
 [ 469170.15625]
 [ 587095.6875 ]
 [ 524846.5    ]
 [ 607799.9375 ]
 [ 623572.4375 ]
 [ 685289.6875 ]
 [ 563171.125  ]]
DEBUG:root:training time = %d0.224027
INFO:root:frame =6473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =6474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.94889
DEBUG:root: dqn, choose action rondomly, need time 0.000337000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =6477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =6478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.948858333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 576470.9375 ]
 [ 590689.8125 ]
 [ 506282.28125]
 [ 595619.1875 ]
 [ 520784.9375 ]
 [ 587469.875  ]
 [ 503286.3125 ]
 [ 557813.5    ]
 [ 577647.5    ]
 [ 525547.125  ]
 [ 501298.5625 ]
 [ 554895.5    ]
 [ 517413.28125]
 [ 474325.4375 ]
 [ 567535.625  ]
 [ 633382.8125 ]]
DEBUG:root:training time = %d0.220625
INFO:root:frame =6481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =6482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000278949737549
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.948826666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283000000024
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =6485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =6486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000197172164917
INFO:root:random_action_porb = 0.948795
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000023
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 552490.25   ]
 [ 597581.8125 ]
 [ 651373.5    ]
 [ 637789.4375 ]
 [ 619199.9375 ]
 [ 517989.46875]
 [ 518952.8125 ]
 [ 564582.     ]
 [ 480973.40625]
 [ 533206.5625 ]
 [ 492757.375  ]
 [ 506729.875  ]
 [ 536614.9375 ]
 [ 640260.9375 ]
 [ 562106.     ]
 [ 578327.5625 ]]
DEBUG:root:training time = %d0.207524
INFO:root:frame =6489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =6490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.948763333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =6494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.948731666667
DEBUG:root: dqn, choose action rondomly, need time 0.000274000000019
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 547352.875  ]
 [ 646227.5625 ]
 [ 487757.65625]
 [ 629496.5625 ]
 [ 519071.     ]
 [ 515411.8125 ]
 [ 644741.5625 ]
 [ 515291.25   ]
 [ 547594.25   ]
 [ 525044.625  ]
 [ 617070.0625 ]
 [ 544494.125  ]
 [ 544494.125  ]
 [ 516224.     ]
 [ 618018.625  ]
 [ 502426.25   ]]
DEBUG:root:training time = %d0.209643
INFO:root:frame =6497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:frame =6498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000410079956055
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9487
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =6501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root:frame =6502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475883483887
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.948668333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 539336.75  ]
 [ 585736.125 ]
 [ 608835.75  ]
 [ 666847.6875]
 [ 607385.8125]
 [ 543910.5625]
 [ 622756.8125]
 [ 636306.875 ]
 [ 558954.8125]
 [ 635616.875 ]
 [ 613150.1875]
 [ 615900.    ]
 [ 602645.9375]
 [ 585574.6875]
 [ 558954.8125]
 [ 624005.875 ]]
DEBUG:root:training time = %d0.234952
INFO:root:frame =6505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =6506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000349044799805
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:random_action_porb = 0.948636666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000366926193237
INFO:root:frame =6509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =6510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288009643555
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.948605
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 626167.75   ]
 [ 507988.90625]
 [ 623163.75   ]
 [ 652490.0625 ]
 [ 464872.28125]
 [ 613402.5625 ]
 [ 626526.375  ]
 [ 641399.1875 ]
 [ 636986.375  ]
 [ 658885.75   ]
 [ 672147.     ]
 [ 641996.875  ]
 [ 622329.9375 ]
 [ 684859.6875 ]
 [ 607052.5    ]
 [ 639559.4375 ]]
DEBUG:root:training time = %d0.224662
INFO:root:frame =6513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =6514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000289916992188
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.948573333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330209732056
INFO:root:frame =6517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =6518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000201225280762
INFO:root:random_action_porb = 0.948541666667
DEBUG:root: dqn, choose action rondomly, need time 0.000579000000016
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:training error  = [[ 530945.625  ]
 [ 543196.375  ]
 [ 555189.4375 ]
 [ 560174.75   ]
 [ 559742.1875 ]
 [ 539441.5    ]
 [ 603868.625  ]
 [ 600732.5    ]
 [ 555642.125  ]
 [ 591933.375  ]
 [ 553896.4375 ]
 [ 580594.875  ]
 [ 515296.84375]
 [ 532919.9375 ]
 [ 616317.     ]
 [ 588464.3125 ]]
DEBUG:root:training time = %d0.207003
INFO:root:frame =6521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =6522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.94851
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =6525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame =6526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.948478333333
DEBUG:root: dqn, choose action rondomly, need time 0.000623000000019
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 481901.71875]
 [ 594194.0625 ]
 [ 558614.625  ]
 [ 546783.6875 ]
 [ 546783.6875 ]
 [ 667249.6875 ]
 [ 584824.625  ]
 [ 546362.0625 ]
 [ 613127.25   ]
 [ 581872.5    ]
 [ 525674.5625 ]
 [ 602053.25   ]
 [ 562904.375  ]
 [ 593261.     ]
 [ 536746.5625 ]
 [ 553631.9375 ]]
DEBUG:root:training time = %d0.21222
INFO:root:frame =6529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =6530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255107879639
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.948446666667
DEBUG:root: dqn, choose action rondomly, need time 0.00027799999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =6533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000420808792114
INFO:root:frame =6534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.948415
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 572917.4375]
 [ 543268.3125]
 [ 683846.625 ]
 [ 722252.6875]
 [ 631438.1875]
 [ 535422.3125]
 [ 660481.625 ]
 [ 588768.5   ]
 [ 637973.5   ]
 [ 564733.1875]
 [ 679381.625 ]
 [ 654272.4375]
 [ 646610.75  ]
 [ 666801.4375]
 [ 697578.9375]
 [ 683846.625 ]]
DEBUG:root:training time = %d0.218157
INFO:root:frame =6537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =6538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00036096572876
DEBUG:root: save sample needs time = 0.000229835510254
INFO:root:random_action_porb = 0.948383333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =6541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =6542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.948351666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000315189361572
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 652799.3125]
 [ 656356.3125]
 [ 582231.5625]
 [ 622017.1875]
 [ 635648.0625]
 [ 682989.25  ]
 [ 546138.3125]
 [ 605581.875 ]
 [ 686646.875 ]
 [ 635316.4375]
 [ 546138.3125]
 [ 620682.375 ]
 [ 691137.3125]
 [ 691137.3125]
 [ 613941.125 ]
 [ 634989.5625]]
DEBUG:root:training time = %d0.234232
INFO:root:frame =6545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =6546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.94832
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =6549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:frame =6550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.948288333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 567940.3125]
 [ 649909.9375]
 [ 581571.5625]
 [ 623049.6875]
 [ 570904.1875]
 [ 578660.3125]
 [ 633449.6875]
 [ 579132.875 ]
 [ 609930.5   ]
 [ 615699.25  ]
 [ 568576.375 ]
 [ 601886.5625]
 [ 593629.625 ]
 [ 647679.125 ]
 [ 639290.8125]
 [ 567940.3125]]
DEBUG:root:training time = %d0.228395
INFO:root:frame =6553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root:frame =6554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame = 6555 State into memory, numbers recorded 178 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000570058822632
INFO:root:random_action_porb = 0.948256666667
DEBUG:root: dqn, choose action rondomly, need time 0.00023299999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6556current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =6557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =6558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.948225
INFO:root:dqn select action Tensor("ArgMax_38:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011826
INFO:root:action choosen by dqn [1]
INFO:root:frame =6560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 659359.875 ]
 [ 607119.4375]
 [ 551233.75  ]
 [ 564325.1875]
 [ 626735.0625]
 [ 630547.6875]
 [ 564325.1875]
 [ 605697.375 ]
 [ 579119.5   ]
 [ 559892.6875]
 [ 644531.4375]
 [ 620060.875 ]
 [ 607119.4375]
 [ 673370.875 ]
 [ 644473.4375]
 [ 615506.125 ]]
DEBUG:root:training time = %d0.234276
INFO:root:frame =6561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame =6562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000312089920044
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.948193333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =6565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =6566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.948161666667
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 613433.125 ]
 [ 571797.375 ]
 [ 600908.0625]
 [ 590371.625 ]
 [ 577435.25  ]
 [ 579726.0625]
 [ 583554.25  ]
 [ 665875.125 ]
 [ 621030.1875]
 [ 569419.125 ]
 [ 595911.625 ]
 [ 591554.75  ]
 [ 659291.6875]
 [ 553161.1875]
 [ 630525.9375]
 [ 642097.    ]]
DEBUG:root:training time = %d0.212886
INFO:root:frame =6569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00027322769165
INFO:root:frame =6570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294923782349
DEBUG:root: save sample needs time = 0.000122785568237
INFO:root:random_action_porb = 0.94813
DEBUG:root: dqn, choose action rondomly, need time 0.000187000000011
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174045562744
INFO:root:frame =6573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =6574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000111103057861
INFO:root:random_action_porb = 0.948098333333
DEBUG:root: dqn, choose action rondomly, need time 0.000313999999975
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:training error  = [[ 647025.4375]
 [ 619602.6875]
 [ 587001.375 ]
 [ 536414.625 ]
 [ 724624.875 ]
 [ 610070.8125]
 [ 559077.5   ]
 [ 634135.375 ]
 [ 694896.4375]
 [ 708169.9375]
 [ 579082.375 ]
 [ 575288.1875]
 [ 626738.1875]
 [ 603082.6875]
 [ 573698.25  ]
 [ 644848.1875]]
DEBUG:root:training time = %d0.233573
INFO:root:frame =6577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =6578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.948066666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002281665802
INFO:root:frame =6582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.948035
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 716391.9375]
 [ 706929.5625]
 [ 626497.    ]
 [ 751595.875 ]
 [ 568831.1875]
 [ 616589.9375]
 [ 742316.875 ]
 [ 630363.125 ]
 [ 610289.    ]
 [ 567076.625 ]
 [ 706929.5625]
 [ 708600.625 ]
 [ 721962.1875]
 [ 727725.625 ]
 [ 676594.625 ]
 [ 709951.0625]]
DEBUG:root:training time = %d0.223438
INFO:root:frame =6585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =6586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000391960144043
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.948003333333
INFO:root:dqn select action Tensor("ArgMax_39:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00927200000001
INFO:root:action choosen by dqn [3]
INFO:root:frame =6588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000346899032593
INFO:root:frame =6589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =6590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.947971666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 721401.375 ]
 [ 597752.4375]
 [ 648578.5625]
 [ 691351.625 ]
 [ 686779.625 ]
 [ 659015.75  ]
 [ 624796.0625]
 [ 590323.625 ]
 [ 724013.1875]
 [ 711943.75  ]
 [ 581377.9375]
 [ 603248.    ]
 [ 617654.75  ]
 [ 675883.0625]
 [ 707749.1875]
 [ 607356.875 ]]
DEBUG:root:training time = %d0.213873
INFO:root:frame =6593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =6594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042200088501
DEBUG:root: save sample needs time = 0.000157117843628
INFO:root:random_action_porb = 0.94794
DEBUG:root: dqn, choose action rondomly, need time 0.000226999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =6597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444173812866
INFO:root:frame =6598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.947908333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 683589.8125]
 [ 737834.    ]
 [ 632077.8125]
 [ 690153.6875]
 [ 760516.875 ]
 [ 659336.0625]
 [ 710403.6875]
 [ 731796.6875]
 [ 690202.375 ]
 [ 695350.75  ]
 [ 705350.625 ]
 [ 690202.375 ]
 [ 708807.75  ]
 [ 618932.5625]
 [ 696814.0625]
 [ 577540.625 ]]
DEBUG:root:training time = %d0.217382
INFO:root:frame =6601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =6602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:frame = 6603 State into memory, numbers recorded 179 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000593185424805
INFO:root:random_action_porb = 0.947876666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6604current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =6605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =6606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466823577881
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.947845
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 648823.9375]
 [ 610678.125 ]
 [ 621033.25  ]
 [ 640439.125 ]
 [ 693274.125 ]
 [ 587475.8125]
 [ 680373.625 ]
 [ 719748.4375]
 [ 598992.875 ]
 [ 596981.0625]
 [ 693466.0625]
 [ 604047.75  ]
 [ 634348.5   ]
 [ 655250.75  ]
 [ 577208.1875]
 [ 693466.0625]]
DEBUG:root:training time = %d0.232032
INFO:root:frame =6609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =6610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259876251221
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.947813333333
DEBUG:root: dqn, choose action rondomly, need time 0.000168000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000130176544189
INFO:root:frame =6613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =6614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.947781666667
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999977
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 783842.1875]
 [ 684859.6875]
 [ 757234.8125]
 [ 721590.5   ]
 [ 724965.75  ]
 [ 599328.5   ]
 [ 648525.0625]
 [ 682235.6875]
 [ 705537.6875]
 [ 645692.3125]
 [ 696797.75  ]
 [ 751201.375 ]
 [ 618646.75  ]
 [ 610496.5   ]
 [ 627570.3125]
 [ 724116.25  ]]
DEBUG:root:training time = %d0.216087
INFO:root:frame =6617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:frame =6618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.94775
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =6621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =6622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.947718333333
INFO:root:dqn select action Tensor("ArgMax_40:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013107
INFO:root:action choosen by dqn [3]
INFO:root:frame =6624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000385046005249
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 716426.6875]
 [ 654323.    ]
 [ 655794.6875]
 [ 598090.75  ]
 [ 755811.1875]
 [ 587270.75  ]
 [ 607108.8125]
 [ 656479.75  ]
 [ 712334.375 ]
 [ 762645.75  ]
 [ 623268.625 ]
 [ 769142.6875]
 [ 597036.9375]
 [ 780781.0625]
 [ 669606.5625]
 [ 715045.3125]]
DEBUG:root:training time = %d0.202526
INFO:root:frame =6625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =6626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.947686666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =6629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =6630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:random_action_porb = 0.947655
DEBUG:root: dqn, choose action rondomly, need time 0.00041299999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 721054.75  ]
 [ 628252.8125]
 [ 678742.6875]
 [ 668702.3125]
 [ 704970.125 ]
 [ 666686.625 ]
 [ 623987.375 ]
 [ 746553.375 ]
 [ 624811.5   ]
 [ 671409.    ]
 [ 795104.875 ]
 [ 595662.875 ]
 [ 616611.4375]
 [ 710183.125 ]
 [ 632416.375 ]
 [ 816264.625 ]]
DEBUG:root:training time = %d0.20048
INFO:root:frame =6633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =6634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.947623333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =6637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =6638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000250101089478
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.947591666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 681260.    ]
 [ 680447.75  ]
 [ 698308.3125]
 [ 738423.    ]
 [ 659507.375 ]
 [ 731367.375 ]
 [ 640532.9375]
 [ 613171.5625]
 [ 688760.5625]
 [ 534899.375 ]
 [ 686692.25  ]
 [ 683202.3125]
 [ 664183.625 ]
 [ 778618.375 ]
 [ 811046.25  ]
 [ 725325.    ]]
DEBUG:root:training time = %d0.213882
INFO:root:frame =6641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =6642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.94756
DEBUG:root: dqn, choose action rondomly, need time 0.000170999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:frame =6645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:frame =6646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.947528333333
INFO:root:dqn select action Tensor("ArgMax_41:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012565
INFO:root:action choosen by dqn [2]
INFO:root:frame =6648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333786010742
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 704234.    ]
 [ 735075.125 ]
 [ 783688.3125]
 [ 690200.75  ]
 [ 689349.125 ]
 [ 764036.5   ]
 [ 735443.5625]
 [ 652843.5   ]
 [ 658787.4375]
 [ 731434.1875]
 [ 680384.9375]
 [ 789508.625 ]
 [ 743958.5   ]
 [ 727027.6875]
 [ 660613.375 ]
 [ 635708.75  ]]
DEBUG:root:training time = %d0.23717
INFO:root:frame =6649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000380992889404
INFO:root:frame =6650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.947496666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000358819961548
INFO:root:frame =6653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =6654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.947465
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000016
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:training error  = [[ 713299.    ]
 [ 760031.5   ]
 [ 767588.1875]
 [ 656440.1875]
 [ 754945.4375]
 [ 778337.5   ]
 [ 695023.4375]
 [ 738317.25  ]
 [ 773473.875 ]
 [ 725779.1875]
 [ 695645.5625]
 [ 718680.0625]
 [ 745962.875 ]
 [ 673175.375 ]
 [ 749519.6875]
 [ 740246.8125]]
DEBUG:root:training time = %d0.196463
INFO:root:frame =6657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =6658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.947433333333
DEBUG:root: dqn, choose action rondomly, need time 0.000167000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:frame =6661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =6662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.947401666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00035285949707
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 658741.5   ]
 [ 671799.5625]
 [ 795951.5   ]
 [ 827430.0625]
 [ 610931.5625]
 [ 646131.8125]
 [ 666600.5   ]
 [ 719942.3125]
 [ 634782.5625]
 [ 730866.375 ]
 [ 732747.6875]
 [ 751467.1875]
 [ 654172.9375]
 [ 773946.3125]
 [ 714066.25  ]
 [ 700954.875 ]]
DEBUG:root:training time = %d0.235827
INFO:root:frame =6665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:frame =6666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000216007232666
DEBUG:root: save sample needs time = 0.000108957290649
INFO:root:random_action_porb = 0.94737
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =6669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame =6670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame = 6671 State into memory, numbers recorded 180 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000538110733032
INFO:root:random_action_porb = 0.947338333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000018
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6672current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 631888.375 ]
 [ 692191.5   ]
 [ 674292.75  ]
 [ 689381.5625]
 [ 770189.625 ]
 [ 686494.75  ]
 [ 729371.0625]
 [ 838637.4375]
 [ 841657.5   ]
 [ 762940.8125]
 [ 665951.625 ]
 [ 648361.5   ]
 [ 652591.    ]
 [ 826234.8125]
 [ 826025.375 ]
 [ 698215.3125]]
DEBUG:root:training time = %d0.227865
INFO:root:frame =6673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =6674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000325918197632
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.947306666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336170196533
INFO:root:frame =6677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =6678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.947275
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:training error  = [[ 814192.5   ]
 [ 689167.5   ]
 [ 703870.1875]
 [ 682742.3125]
 [ 812052.6875]
 [ 765479.75  ]
 [ 793018.0625]
 [ 720418.    ]
 [ 692575.0625]
 [ 784902.5625]
 [ 752627.4375]
 [ 803052.25  ]
 [ 719776.625 ]
 [ 713467.25  ]
 [ 662934.6875]
 [ 760343.125 ]]
DEBUG:root:training time = %d0.213842
INFO:root:frame =6681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =6682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.947243333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =6685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000519990921021
INFO:root:frame =6686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000541925430298
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.947211666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 739084.4375]
 [ 729704.6875]
 [ 690742.8125]
 [ 758814.5   ]
 [ 740564.4375]
 [ 762173.3125]
 [ 729704.6875]
 [ 723948.375 ]
 [ 678047.6875]
 [ 742712.375 ]
 [ 735378.25  ]
 [ 721736.5   ]
 [ 767049.25  ]
 [ 837725.4375]
 [ 848629.5625]
 [ 758164.75  ]]
DEBUG:root:training time = %d0.203359
INFO:root:frame =6689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =6690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308036804199
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.94718
DEBUG:root: dqn, choose action rondomly, need time 0.000205999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:frame =6693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =6694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.947148333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 664791.8125]
 [ 730943.1875]
 [ 723117.6875]
 [ 717437.125 ]
 [ 777595.    ]
 [ 654597.9375]
 [ 715332.6875]
 [ 666704.125 ]
 [ 708947.5625]
 [ 727845.5625]
 [ 781614.875 ]
 [ 724006.5625]
 [ 717503.3125]
 [ 720495.9375]
 [ 666704.125 ]
 [ 776642.875 ]]
DEBUG:root:training time = %d0.22982
INFO:root:frame =6697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =6698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000365972518921
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:random_action_porb = 0.947116666667
DEBUG:root: dqn, choose action rondomly, need time 0.00031199999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322818756104
INFO:root:frame =6701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000487089157104
INFO:root:frame =6702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.947085
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 693714.9375]
 [ 831701.25  ]
 [ 689246.9375]
 [ 704978.3125]
 [ 695596.75  ]
 [ 780051.1875]
 [ 751468.875 ]
 [ 768534.75  ]
 [ 669016.9375]
 [ 822484.25  ]
 [ 791662.    ]
 [ 747481.8125]
 [ 768534.75  ]
 [ 776217.8125]
 [ 667830.5   ]
 [ 717033.5   ]]
DEBUG:root:training time = %d0.241507
INFO:root:frame =6705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =6706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.947053333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =6709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =6710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:random_action_porb = 0.947021666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 782967.5   ]
 [ 695888.3125]
 [ 785799.125 ]
 [ 759859.5   ]
 [ 770093.6875]
 [ 719589.375 ]
 [ 926613.0625]
 [ 759176.9375]
 [ 759176.9375]
 [ 694243.75  ]
 [ 880622.8125]
 [ 790772.5   ]
 [ 706775.1875]
 [ 849648.25  ]
 [ 758540.625 ]
 [ 759176.9375]]
DEBUG:root:training time = %d0.222696
INFO:root:frame =6713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000318765640259
INFO:root:frame =6714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288963317871
DEBUG:root: save sample needs time = 0.00017786026001
INFO:root:random_action_porb = 0.94699
DEBUG:root: dqn, choose action rondomly, need time 0.000407999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =6717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000554084777832
INFO:root:frame =6718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.946958333333
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:training error  = [[ 888541.875 ]
 [ 845442.5625]
 [ 839274.25  ]
 [ 685803.9375]
 [ 700144.    ]
 [ 827083.6875]
 [ 762019.875 ]
 [ 614489.125 ]
 [ 887984.125 ]
 [ 864222.625 ]
 [ 816820.5625]
 [ 614489.125 ]
 [ 705775.5625]
 [ 703640.8125]
 [ 831672.75  ]
 [ 816820.5625]]
DEBUG:root:training time = %d0.209155
INFO:root:frame =6721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =6722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.946926666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000022
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =6725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000484943389893
INFO:root:frame =6726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000385046005249
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.946895
DEBUG:root: dqn, choose action rondomly, need time 0.000317999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 855018.0625]
 [ 915776.125 ]
 [ 827135.1875]
 [ 795897.5   ]
 [ 865915.6875]
 [ 804998.    ]
 [ 852473.5   ]
 [ 797131.625 ]
 [ 908946.25  ]
 [ 604137.3125]
 [ 857389.1875]
 [ 958825.375 ]
 [ 814709.    ]
 [ 803433.875 ]
 [ 803243.0625]
 [ 843714.    ]]
DEBUG:root:training time = %d0.207569
INFO:root:frame =6729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =6730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.946863333333
DEBUG:root: dqn, choose action rondomly, need time 0.000187000000011
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00017786026001
INFO:root:frame =6733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000497817993164
INFO:root:frame =6734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame = 6735 State into memory, numbers recorded 181 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.00057315826416
INFO:root:random_action_porb = 0.946831666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6736current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[ 737800.5   ]
 [ 857271.625 ]
 [ 709436.0625]
 [ 755858.75  ]
 [ 706441.875 ]
 [ 789753.3125]
 [ 776997.5   ]
 [ 840185.25  ]
 [ 742419.5   ]
 [ 797797.875 ]
 [ 881064.5625]
 [ 640770.5625]
 [ 781110.75  ]
 [ 691936.375 ]
 [ 723735.6875]
 [ 723190.8125]]
DEBUG:root:training time = %d0.215049
INFO:root:frame =6737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =6738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.9468
DEBUG:root: dqn, choose action rondomly, need time 0.000342999999987
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =6741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =6742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00052285194397
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.946768333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 803087.25  ]
 [ 785695.25  ]
 [ 837192.8125]
 [ 775970.    ]
 [ 806702.1875]
 [ 721023.1875]
 [ 783935.5625]
 [ 704155.375 ]
 [ 729104.1875]
 [ 836762.1875]
 [ 775658.625 ]
 [ 868806.0625]
 [ 734408.8125]
 [ 633446.5625]
 [ 865201.5625]
 [ 724267.5   ]]
DEBUG:root:training time = %d0.251092
INFO:root:frame =6745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312805175781
INFO:root:frame =6746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.946736666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =6749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =6750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root:random_action_porb = 0.946705
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:training error  = [[ 816352.8125]
 [ 892801.6875]
 [ 736088.5625]
 [ 761256.25  ]
 [ 716611.875 ]
 [ 744217.9375]
 [ 783437.625 ]
 [ 936706.375 ]
 [ 804721.125 ]
 [ 888287.8125]
 [ 930384.5625]
 [ 752452.875 ]
 [ 802803.75  ]
 [ 782792.9375]
 [ 804721.125 ]
 [ 791079.9375]]
DEBUG:root:training time = %d0.218295
INFO:root:frame =6753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =6754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:frame = 6755 State into memory, numbers recorded 182 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000550985336304
INFO:root:random_action_porb = 0.946673333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6756current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:frame =6757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =6758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.946641666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 717270.0625]
 [ 798714.    ]
 [ 853476.4375]
 [ 846493.4375]
 [ 878194.125 ]
 [ 801189.3125]
 [ 843140.    ]
 [ 856987.75  ]
 [ 734509.25  ]
 [ 821777.6875]
 [ 915650.875 ]
 [ 765929.25  ]
 [ 743795.0625]
 [ 913633.5625]
 [ 851532.4375]
 [ 919452.5   ]]
DEBUG:root:training time = %d0.209742
INFO:root:frame =6761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =6762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000409126281738
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:random_action_porb = 0.94661
DEBUG:root: dqn, choose action rondomly, need time 0.000330999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332832336426
INFO:root:frame =6765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000484943389893
INFO:root:frame =6766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.946578333333
INFO:root:dqn select action Tensor("ArgMax_42:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013968
INFO:root:action choosen by dqn [3]
INFO:root:frame =6768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 787493.3125]
 [ 789519.    ]
 [ 870653.    ]
 [ 962575.625 ]
 [ 847018.25  ]
 [ 819983.3125]
 [ 850325.3125]
 [ 848993.0625]
 [ 774633.75  ]
 [ 654247.1875]
 [ 715937.4375]
 [ 945327.    ]
 [ 931786.75  ]
 [ 775851.3125]
 [ 779723.5   ]
 [ 784041.0625]]
DEBUG:root:training time = %d0.2235
INFO:root:frame =6769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =6770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.946546666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =6773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =6774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.946515
DEBUG:root: dqn, choose action rondomly, need time 0.000162000000017
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 794302.1875]
 [ 893519.6875]
 [ 779354.4375]
 [ 764046.6875]
 [ 897497.1875]
 [ 820570.5625]
 [ 977846.75  ]
 [ 907226.5   ]
 [ 764046.6875]
 [ 779530.375 ]
 [ 700945.0625]
 [ 977846.75  ]
 [ 819838.3125]
 [ 806589.9375]
 [ 851510.8125]
 [ 730821.3125]]
DEBUG:root:training time = %d0.213031
INFO:root:frame =6777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:frame =6778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000353097915649
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.946483333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =6781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =6782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046181678772
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.946451666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:training error  = [[ 869417.8125]
 [ 764606.8125]
 [ 935334.5625]
 [ 872330.4375]
 [ 942738.5625]
 [ 905980.5   ]
 [ 869275.8125]
 [ 959324.625 ]
 [ 923074.3125]
 [ 816735.8125]
 [ 968363.625 ]
 [ 863999.3125]
 [ 770129.625 ]
 [ 669015.375 ]
 [ 949368.5625]
 [ 907044.1875]]
DEBUG:root:training time = %d0.233564
INFO:root:frame =6785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =6786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000356197357178
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.94642
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =6790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000518798828125
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.946388333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000343799591064
INFO:root:training error  = [[ 803540.6875]
 [ 859665.8125]
 [ 800577.5625]
 [ 801014.5   ]
 [ 787219.5   ]
 [ 985261.75  ]
 [ 747954.6875]
 [ 918681.0625]
 [ 847075.75  ]
 [ 918681.0625]
 [ 898774.375 ]
 [ 909456.5   ]
 [ 847597.125 ]
 [ 807211.    ]
 [ 923918.9375]
 [ 842232.8125]]
DEBUG:root:training time = %d0.213862
INFO:root:frame =6793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =6794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
DEBUG:root: save sample needs time = 0.000278234481812
INFO:root:random_action_porb = 0.946356666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000015
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =6797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =6798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.946325
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  916035.9375]
 [  927045.5   ]
 [  875229.6875]
 [  749049.6875]
 [  925083.3125]
 [  799731.9375]
 [  924459.6875]
 [  811688.375 ]
 [  840892.5625]
 [  922519.    ]
 [ 1037179.125 ]
 [  905701.6875]
 [  852008.3125]
 [  808457.375 ]
 [  945072.5625]
 [  877610.3125]]
DEBUG:root:training time = %d0.222912
INFO:root:frame =6801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =6802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000378131866455
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.946293333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =6805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =6806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.946261666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 973216.9375]
 [ 870124.5625]
 [ 922271.375 ]
 [ 900363.75  ]
 [ 984784.875 ]
 [ 906571.75  ]
 [ 942306.25  ]
 [ 881200.25  ]
 [ 867081.0625]
 [ 948455.3125]
 [ 864329.75  ]
 [ 876319.0625]
 [ 905028.9375]
 [ 740026.6875]
 [ 830209.25  ]
 [ 964201.25  ]]
DEBUG:root:training time = %d0.205288
INFO:root:frame =6809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =6810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.94623
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =6813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466823577881
INFO:root:frame =6814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000522136688232
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.946198333333
DEBUG:root: dqn, choose action rondomly, need time 0.000257000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:training error  = [[ 778361.625 ]
 [ 784625.75  ]
 [ 902852.5625]
 [ 839231.3125]
 [ 791783.6875]
 [ 829707.5   ]
 [ 872720.875 ]
 [ 964945.5   ]
 [ 951200.1875]
 [ 839249.25  ]
 [ 964523.5   ]
 [ 994231.    ]
 [ 850192.0625]
 [ 988909.8125]
 [ 850192.0625]
 [ 968909.5625]]
DEBUG:root:training time = %d0.216817
INFO:root:frame =6817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =6818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame = 6819 State into memory, numbers recorded 183 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000558853149414
INFO:root:random_action_porb = 0.946166666667
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6820current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =6821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =6822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.946135
DEBUG:root: dqn, choose action rondomly, need time 0.000320999999985
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  855473.25  ]
 [  935995.8125]
 [  933340.9375]
 [  940695.375 ]
 [  946774.625 ]
 [  813093.1875]
 [  833298.    ]
 [  979508.4375]
 [  961445.375 ]
 [  809462.1875]
 [  791686.3125]
 [  912972.8125]
 [  776990.625 ]
 [  833711.6875]
 [  906103.1875]
 [ 1020478.8125]]
DEBUG:root:training time = %d0.190091
INFO:root:frame =6825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =6826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000312805175781
DEBUG:root: save sample needs time = 0.000136137008667
INFO:root:random_action_porb = 0.946103333333
INFO:root:dqn select action Tensor("ArgMax_43:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012223
INFO:root:action choosen by dqn [2]
INFO:root:frame =6828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000417947769165
INFO:root:frame =6829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =6830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486135482788
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.946071666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 804595.    ]
 [ 887338.25  ]
 [ 946413.5625]
 [ 927252.375 ]
 [ 954479.375 ]
 [ 810186.3125]
 [ 990114.375 ]
 [ 841035.875 ]
 [ 966043.25  ]
 [ 794570.3125]
 [ 946413.5625]
 [ 920456.625 ]
 [ 910745.875 ]
 [ 984827.5   ]
 [ 824297.3125]
 [ 940218.0625]]
DEBUG:root:training time = %d0.216433
INFO:root:frame =6833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =6834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000419139862061
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.94604
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =6837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =6838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:random_action_porb = 0.946008333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1048956.    ]
 [  912409.25  ]
 [  899919.0625]
 [  963388.25  ]
 [ 1041472.0625]
 [  912409.25  ]
 [  832100.3125]
 [  938204.125 ]
 [  977607.25  ]
 [  888692.875 ]
 [  899985.75  ]
 [  877749.375 ]
 [  899111.375 ]
 [  899919.0625]
 [  869636.375 ]
 [  953483.5625]]
DEBUG:root:training time = %d0.212304
INFO:root:frame =6841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =6842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025200843811
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:random_action_porb = 0.945976666667
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999983
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =6845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00052285194397
INFO:root:frame =6846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000526905059814
INFO:root:frame = 6847 State into memory, numbers recorded 184 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000591039657593
INFO:root:random_action_porb = 0.945945
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6848current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000411033630371
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 835388.875 ]
 [ 880844.5625]
 [ 862845.0625]
 [ 858449.3125]
 [ 979407.875 ]
 [ 862732.5625]
 [ 880844.5625]
 [ 979407.875 ]
 [ 860259.875 ]
 [ 860785.3125]
 [ 785314.4375]
 [ 877299.3125]
 [ 838254.6875]
 [ 892770.3125]
 [ 921067.5625]
 [ 828775.5   ]]
DEBUG:root:training time = %d0.214843
INFO:root:frame =6849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =6850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.945913333333
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0003821849823
INFO:root:frame =6853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =6854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.945881666667
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:training error  = [[  845523.375 ]
 [ 1011961.3125]
 [  809384.875 ]
 [ 1032545.75  ]
 [  872972.6875]
 [  890453.9375]
 [ 1008879.    ]
 [  906002.8125]
 [  982712.0625]
 [  926857.5   ]
 [ 1134720.125 ]
 [  888976.4375]
 [  853180.5625]
 [  858141.6875]
 [  951261.125 ]
 [  863476.5   ]]
DEBUG:root:training time = %d0.209213
INFO:root:frame =6857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =6858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000290155410767
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.94585
DEBUG:root: dqn, choose action rondomly, need time 0.000280000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =6861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =6862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.945818333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:training error  = [[  936279.25  ]
 [ 1062944.875 ]
 [ 1049884.375 ]
 [  918520.0625]
 [ 1036312.0625]
 [  881666.    ]
 [ 1017076.1875]
 [  910682.5   ]
 [  854721.9375]
 [  789060.9375]
 [  988777.75  ]
 [  880276.4375]
 [  950613.5625]
 [  946064.    ]
 [  927109.4375]
 [  982406.1875]]
DEBUG:root:training time = %d0.220391
INFO:root:frame =6865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =6866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame = 6867 State into memory, numbers recorded 185 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000534057617188
INFO:root:random_action_porb = 0.945786666667
DEBUG:root: dqn, choose action rondomly, need time 0.000333999999981
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6868current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =6869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000818014144897
INFO:root:frame =6870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000383853912354
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:random_action_porb = 0.945755
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 877215.1875]
 [ 897363.9375]
 [ 931862.1875]
 [ 915056.625 ]
 [ 880115.1875]
 [ 862816.    ]
 [ 901105.25  ]
 [ 911159.75  ]
 [ 918879.5   ]
 [ 862445.9375]
 [ 950110.9375]
 [ 950697.375 ]
 [ 950110.9375]
 [ 896875.5625]
 [ 901646.6875]
 [ 978982.6875]]
DEBUG:root:training time = %d0.225996
INFO:root:frame =6873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =6874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:player has been killed for 9 times 
INFO:root:frame = 6875 State into memory, numbers recorded 186 action = -1, reward = -1
DEBUG:root: save sample needs time = 0.000428915023804
INFO:root:random_action_porb = 0.945723333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6876current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =6877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =6878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433206558228
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.945691666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1122759.625 ]
 [  940396.125 ]
 [ 1125596.625 ]
 [ 1001641.3125]
 [ 1096442.125 ]
 [ 1074757.375 ]
 [  964308.6875]
 [  929352.5   ]
 [ 1035147.25  ]
 [  931726.4375]
 [  911625.875 ]
 [  992284.5   ]
 [  816912.3125]
 [  816912.3125]
 [ 1179922.125 ]
 [ 1014800.4375]]
DEBUG:root:training time = %d0.231926
INFO:root:frame =6881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =6882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000391960144043
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.94566
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999985
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =6885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470876693726
INFO:root:frame =6886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.945628333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  928893.125 ]
 [ 1055780.375 ]
 [ 1022263.1875]
 [ 1089601.625 ]
 [  865812.0625]
 [  936124.25  ]
 [ 1009169.375 ]
 [ 1000390.6875]
 [  944150.    ]
 [  924985.625 ]
 [  867433.9375]
 [ 1058680.25  ]
 [  924440.9375]
 [ 1099303.125 ]
 [ 1079228.75  ]
 [ 1170973.375 ]]
DEBUG:root:training time = %d0.217862
INFO:root:frame =6889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =6890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000211000442505
DEBUG:root: save sample needs time = 9.29832458496e-05
INFO:root:random_action_porb = 0.945596666667
DEBUG:root: dqn, choose action rondomly, need time 0.000168000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:frame =6893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =6894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.945565
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:training error  = [[ 1119450.75  ]
 [  973872.125 ]
 [  938109.5625]
 [ 1089687.25  ]
 [  951908.9375]
 [  879583.875 ]
 [  974832.25  ]
 [ 1040678.9375]
 [  955975.9375]
 [  890435.5   ]
 [  927124.5   ]
 [ 1036725.6875]
 [ 1084327.625 ]
 [  866822.8125]
 [ 1016355.375 ]
 [  895248.625 ]]
DEBUG:root:training time = %d0.232811
INFO:root:frame =6897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =6898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame = 6899 State into memory, numbers recorded 187 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000565767288208
INFO:root:random_action_porb = 0.945533333333
INFO:root:dqn select action Tensor("ArgMax_44:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00926799999999
INFO:root:action choosen by dqn [2]
INFO:root:frame =6900current_observation done, NOT record action [2], reward = 0
DEBUG:root: save sample needs time = 0.000372886657715
INFO:root:frame =6901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:frame =6902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.945501666667
DEBUG:root: dqn, choose action rondomly, need time 0.000337000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1006408.6875]
 [ 1197413.    ]
 [  838505.0625]
 [  986914.1875]
 [ 1023997.75  ]
 [ 1055471.25  ]
 [ 1073490.25  ]
 [ 1088464.25  ]
 [ 1028580.25  ]
 [ 1012334.6875]
 [  908022.875 ]
 [ 1022749.    ]
 [ 1023997.75  ]
 [ 1055471.25  ]
 [ 1036431.375 ]
 [  958968.8125]]
DEBUG:root:training time = %d0.221549
INFO:root:frame =6905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =6906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000451803207397
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:random_action_porb = 0.94547
DEBUG:root: dqn, choose action rondomly, need time 0.000427000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =6909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444173812866
INFO:root:frame =6910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root:random_action_porb = 0.945438333333
INFO:root:dqn select action Tensor("ArgMax_45:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015013
INFO:root:action choosen by dqn [1]
INFO:root:frame =6912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:training error  = [[ 1194256.25  ]
 [  893774.5   ]
 [ 1039161.25  ]
 [  893844.6875]
 [  961112.1875]
 [  934718.875 ]
 [  987690.4375]
 [ 1027253.5   ]
 [  886591.4375]
 [ 1035198.9375]
 [ 1128412.375 ]
 [  949600.75  ]
 [ 1156452.375 ]
 [  881581.625 ]
 [  909884.9375]
 [ 1047148.5   ]]
DEBUG:root:training time = %d0.201632
INFO:root:frame =6913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =6914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame = 6915 State into memory, numbers recorded 188 action = [1], reward = 0
DEBUG:root: save sample needs time = 0.00127100944519
INFO:root:random_action_porb = 0.945406666667
DEBUG:root: dqn, choose action rondomly, need time 0.000203999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6916current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =6917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =6918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:random_action_porb = 0.945375
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:training error  = [[ 1023511.625 ]
 [ 1025563.6875]
 [  990285.4375]
 [  941510.125 ]
 [ 1003417.    ]
 [  960802.    ]
 [  968632.75  ]
 [ 1020032.9375]
 [  949661.6875]
 [ 1016044.3125]
 [  930365.75  ]
 [  918422.75  ]
 [ 1023551.125 ]
 [ 1036153.    ]
 [  933291.875 ]
 [ 1037234.8125]]
DEBUG:root:training time = %d0.228362
INFO:root:frame =6921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root:frame =6922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000328063964844
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.945343333333
DEBUG:root: dqn, choose action rondomly, need time 0.000252999999987
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =6925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =6926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481128692627
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.945311666667
DEBUG:root: dqn, choose action rondomly, need time 0.000360000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000341176986694
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  977016.4375]
 [ 1029158.75  ]
 [ 1080556.25  ]
 [  973610.0625]
 [ 1035886.625 ]
 [  923746.25  ]
 [ 1091914.75  ]
 [ 1041511.9375]
 [ 1019070.5625]
 [ 1124797.    ]
 [ 1053702.25  ]
 [ 1008843.6875]
 [  977016.4375]
 [ 1125737.625 ]
 [ 1023061.125 ]
 [ 1083376.    ]]
DEBUG:root:training time = %d0.222539
INFO:root:frame =6929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =6930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.94528
DEBUG:root: dqn, choose action rondomly, need time 0.000337999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =6934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000514984130859
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.945248333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999981
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:training error  = [[  928735.    ]
 [ 1109936.375 ]
 [ 1054139.375 ]
 [  869268.5   ]
 [  960951.3125]
 [ 1046333.1875]
 [  928735.    ]
 [ 1136809.875 ]
 [ 1143349.875 ]
 [  949547.5   ]
 [ 1083302.875 ]
 [ 1003479.5625]
 [ 1093535.875 ]
 [ 1018309.625 ]
 [ 1142414.375 ]
 [ 1147015.875 ]]
DEBUG:root:training time = %d0.227568
INFO:root:frame =6937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =6938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.945216666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =6942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.00017786026001
INFO:root:random_action_porb = 0.945185
DEBUG:root: dqn, choose action rondomly, need time 0.000308999999987
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  830590.125 ]
 [ 1044368.25  ]
 [  953983.3125]
 [ 1135827.25  ]
 [ 1077460.25  ]
 [  889477.375 ]
 [  956197.5   ]
 [ 1116291.25  ]
 [  937844.6875]
 [ 1057362.375 ]
 [ 1144394.375 ]
 [ 1009067.3125]
 [ 1080012.125 ]
 [ 1097301.25  ]
 [  936657.25  ]
 [  848330.9375]]
DEBUG:root:training time = %d0.232134
INFO:root:frame =6945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =6946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.945153333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =6949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =6950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.945121666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1182104.125 ]
 [ 1222328.875 ]
 [ 1231831.125 ]
 [  938639.3125]
 [ 1069515.5   ]
 [  996386.0625]
 [ 1004775.1875]
 [ 1129088.875 ]
 [  919272.75  ]
 [ 1173104.75  ]
 [ 1061342.625 ]
 [ 1103484.625 ]
 [ 1096241.75  ]
 [ 1112229.75  ]
 [ 1023653.875 ]
 [ 1023653.875 ]]
DEBUG:root:training time = %d0.219824
INFO:root:frame =6953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:frame =6954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame = 6955 State into memory, numbers recorded 189 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000514984130859
INFO:root:random_action_porb = 0.94509
DEBUG:root: dqn, choose action rondomly, need time 0.000426000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6956current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =6957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =6958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.945058333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  981484.9375]
 [ 1016761.0625]
 [  944776.4375]
 [ 1026742.875 ]
 [  972122.8125]
 [ 1131992.125 ]
 [ 1000937.75  ]
 [ 1154814.75  ]
 [  948508.625 ]
 [ 1061205.75  ]
 [ 1081514.75  ]
 [  948508.625 ]
 [ 1039276.6875]
 [ 1016761.0625]
 [  982882.5   ]
 [  974600.875 ]]
DEBUG:root:training time = %d0.210755
INFO:root:frame =6961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =6962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456809997559
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.945026666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:frame =6965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =6966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000261068344116
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.944995
DEBUG:root: dqn, choose action rondomly, need time 0.000268000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1215588.125 ]
 [ 1112971.375 ]
 [ 1139397.75  ]
 [ 1072316.875 ]
 [  961441.5625]
 [ 1052195.125 ]
 [ 1119789.75  ]
 [ 1078161.75  ]
 [ 1025330.25  ]
 [  998020.5   ]
 [  866451.9375]
 [ 1195447.5   ]
 [ 1135269.5   ]
 [  874539.125 ]
 [  953807.8125]
 [  858518.0625]]
DEBUG:root:training time = %d0.187043
INFO:root:frame =6969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =6970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231981277466
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:random_action_porb = 0.944963333333
DEBUG:root: dqn, choose action rondomly, need time 0.000212000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000183820724487
INFO:root:frame =6973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000391960144043
INFO:root:frame =6974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00032901763916
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:random_action_porb = 0.944931666667
DEBUG:root: dqn, choose action rondomly, need time 0.000232000000011
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1225453.375]
 [ 1125082.875]
 [  895086.   ]
 [ 1100843.625]
 [ 1110401.375]
 [ 1022255.25 ]
 [ 1228538.375]
 [ 1054444.125]
 [  998262.5  ]
 [ 1071119.875]
 [ 1175750.5  ]
 [ 1188700.375]
 [ 1088835.125]
 [ 1110401.375]
 [ 1170018.25 ]
 [ 1190016.75 ]]
DEBUG:root:training time = %d0.177719
INFO:root:frame =6977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =6978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00052809715271
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.9449
DEBUG:root: dqn, choose action rondomly, need time 0.000349
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =6981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042986869812
INFO:root:frame =6982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame = 6983 State into memory, numbers recorded 190 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:random_action_porb = 0.944868333333
DEBUG:root: dqn, choose action rondomly, need time 0.000357000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6984current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1043246.8125]
 [ 1083851.75  ]
 [ 1035266.5   ]
 [ 1067012.375 ]
 [ 1098496.375 ]
 [ 1162964.25  ]
 [ 1087844.875 ]
 [ 1004963.1875]
 [ 1135127.875 ]
 [ 1141504.375 ]
 [ 1090148.125 ]
 [ 1176246.125 ]
 [ 1302264.375 ]
 [ 1048912.    ]
 [ 1114422.5   ]
 [ 1202308.    ]]
DEBUG:root:training time = %d0.226427
INFO:root:frame =6985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =6986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame = 6987 State into memory, numbers recorded 191 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000574111938477
INFO:root:random_action_porb = 0.944836666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6988current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000370979309082
INFO:root:frame =6989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =6990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000525951385498
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.944805
DEBUG:root: dqn, choose action rondomly, need time 0.000589000000019
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:training error  = [[ 1167931.875 ]
 [ 1115144.25  ]
 [ 1285145.5   ]
 [ 1017659.3125]
 [ 1181305.75  ]
 [ 1047424.3125]
 [ 1230686.875 ]
 [ 1234633.5   ]
 [ 1098099.375 ]
 [ 1251400.5   ]
 [ 1232806.875 ]
 [ 1110459.    ]
 [ 1033184.875 ]
 [ 1027641.5625]
 [ 1140820.125 ]
 [ 1191939.375 ]]
DEBUG:root:training time = %d0.224488
INFO:root:frame =6993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =6994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000112771987915
INFO:root:random_action_porb = 0.944773333333
DEBUG:root: dqn, choose action rondomly, need time 0.000186999999983
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00018310546875
INFO:root:frame =6997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =6998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000203132629395
DEBUG:root:one frame running time = 0.00615299999998
DEBUG:root:total training time = 189.474138
INFO:root:frame num = 7000 frame round: 0
INFO:root:random_action_porb = 0.944741666667
DEBUG:root: dqn, choose action rondomly, need time 0.000212000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1183268.   ]
 [ 1178615.625]
 [ 1109516.625]
 [ 1161418.75 ]
 [ 1129657.625]
 [ 1129657.625]
 [ 1091469.875]
 [ 1231181.   ]
 [ 1143554.5  ]
 [ 1109948.625]
 [ 1195708.125]
 [ 1169312.75 ]
 [ 1206063.   ]
 [ 1117971.625]
 [  997638.125]
 [ 1057920.75 ]]
DEBUG:root:training time = %d0.217285
INFO:root:frame =7001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =7002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277996063232
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.94471
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =7005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =7006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:random_action_porb = 0.944678333333
DEBUG:root: dqn, choose action rondomly, need time 0.000357000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:training error  = [[ 1316536.625]
 [ 1217108.875]
 [ 1123968.5  ]
 [ 1196626.625]
 [ 1108151.   ]
 [ 1258625.375]
 [ 1285052.5  ]
 [ 1284096.25 ]
 [ 1134266.625]
 [ 1303503.875]
 [ 1250151.125]
 [ 1232551.   ]
 [ 1177937.125]
 [ 1296805.   ]
 [ 1272379.625]
 [ 1042979.5  ]]
DEBUG:root:training time = %d0.23376
INFO:root:frame =7009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =7010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000312805175781
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.944646666667
DEBUG:root: dqn, choose action rondomly, need time 0.000170999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000141143798828
INFO:root:frame =7013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =7014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root:random_action_porb = 0.944615
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1197477.125]
 [ 1323115.5  ]
 [ 1314699.625]
 [  915460.25 ]
 [ 1167986.75 ]
 [ 1216415.125]
 [ 1123090.75 ]
 [ 1256334.5  ]
 [ 1199469.875]
 [ 1179192.375]
 [ 1188466.25 ]
 [ 1216802.875]
 [ 1418467.   ]
 [ 1178882.75 ]
 [ 1279952.   ]
 [ 1407634.   ]]
DEBUG:root:training time = %d0.205912
INFO:root:frame =7017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =7018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000508069992065
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.944583333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =7021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame =7022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000591993331909
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.944551666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999983
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1242166.875 ]
 [ 1256036.75  ]
 [ 1068239.375 ]
 [ 1042177.8125]
 [ 1251081.625 ]
 [ 1267106.375 ]
 [ 1137580.625 ]
 [ 1052175.125 ]
 [ 1050528.875 ]
 [ 1246053.25  ]
 [ 1137580.625 ]
 [ 1305025.125 ]
 [ 1188640.75  ]
 [ 1229911.375 ]
 [ 1272225.375 ]
 [ 1177178.375 ]]
DEBUG:root:training time = %d0.235556
INFO:root:frame =7025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =7026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438213348389
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.94452
DEBUG:root: dqn, choose action rondomly, need time 0.000195999999988
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =7029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =7030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.944488333333
INFO:root:dqn select action Tensor("ArgMax_46:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015252
INFO:root:action choosen by dqn [0]
INFO:root:frame =7032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1136922.375 ]
 [ 1020368.3125]
 [ 1096867.625 ]
 [ 1288819.125 ]
 [ 1159113.    ]
 [ 1072980.375 ]
 [ 1196878.75  ]
 [ 1062630.75  ]
 [ 1173938.375 ]
 [ 1174310.875 ]
 [ 1213310.875 ]
 [ 1140336.125 ]
 [ 1193663.    ]
 [ 1238486.375 ]
 [ 1072681.    ]
 [ 1278286.375 ]]
DEBUG:root:training time = %d0.218406
INFO:root:frame =7033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =7034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.944456666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =7037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =7038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.944425
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000315189361572
INFO:root:training error  = [[ 1125190.5  ]
 [ 1167801.   ]
 [ 1461307.875]
 [  994429.625]
 [ 1206114.5  ]
 [ 1234711.625]
 [ 1074000.25 ]
 [ 1085072.125]
 [ 1064806.375]
 [ 1134645.25 ]
 [ 1136526.75 ]
 [ 1117059.125]
 [ 1351292.75 ]
 [ 1200171.625]
 [ 1135823.   ]
 [ 1200492.625]]
DEBUG:root:training time = %d0.215487
INFO:root:frame =7041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =7042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000420808792114
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.944393333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =7045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =7046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.944361666667
INFO:root:dqn select action Tensor("ArgMax_47:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014915
INFO:root:action choosen by dqn [2]
INFO:root:frame =7048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1292369.25 ]
 [ 1068651.125]
 [ 1117620.625]
 [ 1117282.   ]
 [ 1321067.375]
 [ 1336354.125]
 [ 1065173.125]
 [ 1208011.375]
 [ 1099974.875]
 [ 1184862.   ]
 [ 1224865.25 ]
 [ 1286372.375]
 [ 1099774.125]
 [ 1175801.375]
 [ 1126541.75 ]
 [ 1152293.25 ]]
DEBUG:root:training time = %d0.227978
INFO:root:frame =7049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =7050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000217199325562
INFO:root:random_action_porb = 0.94433
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =7053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449180603027
INFO:root:frame =7054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.944298333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999983
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000346183776855
INFO:root:training error  = [[ 1220429.375]
 [ 1097186.75 ]
 [ 1186686.875]
 [ 1186712.375]
 [ 1182486.375]
 [ 1178386.625]
 [ 1130787.125]
 [ 1292653.5  ]
 [ 1281689.375]
 [ 1238238.625]
 [ 1238238.625]
 [ 1349422.5  ]
 [ 1270675.   ]
 [ 1206033.   ]
 [ 1080385.625]
 [ 1156087.   ]]
DEBUG:root:training time = %d0.22543
INFO:root:frame =7057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =7058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249147415161
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.944266666667
DEBUG:root: dqn, choose action rondomly, need time 0.000174999999984
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:frame =7061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235795974731
INFO:root:frame =7062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235080718994
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.944235
DEBUG:root: dqn, choose action rondomly, need time 0.000170999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:training error  = [[ 1254767.5  ]
 [ 1204124.75 ]
 [ 1269121.125]
 [ 1119322.625]
 [ 1092212.75 ]
 [ 1128026.5  ]
 [ 1391040.625]
 [ 1389925.875]
 [ 1168958.   ]
 [ 1083058.875]
 [ 1227581.75 ]
 [ 1199273.125]
 [ 1263446.25 ]
 [ 1218496.875]
 [ 1078612.125]
 [ 1125087.   ]]
DEBUG:root:training time = %d0.220639
INFO:root:frame =7065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =7066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049901008606
DEBUG:root: save sample needs time = 0.000194787979126
INFO:root:random_action_porb = 0.944203333333
DEBUG:root: dqn, choose action rondomly, need time 0.000183000000021
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:frame =7069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =7070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000546932220459
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.944171666667
DEBUG:root: dqn, choose action rondomly, need time 0.000400000000013
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:training error  = [[ 1195170.   ]
 [ 1123546.125]
 [ 1442579.25 ]
 [ 1106338.25 ]
 [ 1181900.25 ]
 [ 1157536.375]
 [ 1147488.75 ]
 [ 1309755.125]
 [ 1134416.375]
 [ 1325983.75 ]
 [ 1325983.75 ]
 [ 1230119.25 ]
 [ 1249290.875]
 [ 1157780.25 ]
 [ 1267603.25 ]
 [ 1325983.75 ]]
DEBUG:root:training time = %d0.216924
INFO:root:frame =7073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253200531006
INFO:root:frame =7074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame = 7075 State into memory, numbers recorded 192 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000604152679443
INFO:root:random_action_porb = 0.94414
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7076current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:frame =7077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =7078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame = 7079 State into memory, numbers recorded 193 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000504970550537
INFO:root:random_action_porb = 0.944108333333
DEBUG:root: dqn, choose action rondomly, need time 0.000324000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7080current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1292831.125]
 [ 1253844.375]
 [ 1457438.375]
 [ 1380368.   ]
 [ 1310604.625]
 [ 1133863.125]
 [ 1278017.   ]
 [ 1120935.   ]
 [ 1140891.   ]
 [ 1380368.   ]
 [ 1271207.75 ]
 [ 1199957.625]
 [ 1186499.625]
 [ 1059206.75 ]
 [ 1308807.5  ]
 [ 1176991.875]]
DEBUG:root:training time = %d0.217835
INFO:root:frame =7081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =7082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265836715698
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.944076666667
DEBUG:root: dqn, choose action rondomly, need time 0.000191000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:frame =7085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame =7086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000125169754028
INFO:root:random_action_porb = 0.944045
DEBUG:root: dqn, choose action rondomly, need time 0.000323999999978
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1268175.125]
 [ 1211642.   ]
 [ 1297192.   ]
 [ 1339991.625]
 [ 1196199.375]
 [ 1209136.5  ]
 [ 1339991.625]
 [ 1304235.375]
 [ 1125480.625]
 [ 1139351.875]
 [ 1198789.75 ]
 [ 1426242.375]
 [ 1112275.125]
 [ 1255227.   ]
 [ 1099761.875]
 [ 1361788.75 ]]
DEBUG:root:training time = %d0.213205
INFO:root:frame =7089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000353097915649
INFO:root:frame =7090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
DEBUG:root: save sample needs time = 0.000180006027222
INFO:root:random_action_porb = 0.944013333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =7093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042986869812
INFO:root:frame =7094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000553131103516
INFO:root:frame = 7095 State into memory, numbers recorded 194 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000530958175659
INFO:root:random_action_porb = 0.943981666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7096current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1204600.625]
 [ 1349558.75 ]
 [ 1245586.75 ]
 [ 1254141.875]
 [ 1178984.5  ]
 [ 1178984.5  ]
 [ 1246755.375]
 [ 1380317.5  ]
 [ 1174446.375]
 [ 1208105.875]
 [ 1347177.375]
 [ 1249046.375]
 [ 1223525.5  ]
 [ 1279222.875]
 [ 1476694.875]
 [ 1362677.75 ]]
DEBUG:root:training time = %d0.215887
INFO:root:frame =7097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:frame =7098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.94395
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999985
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =7101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =7102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.943918333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999981
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1404873.125]
 [ 1159773.375]
 [ 1402943.125]
 [ 1053834.625]
 [ 1210283.625]
 [ 1301404.125]
 [ 1149770.375]
 [ 1427922.25 ]
 [ 1309755.125]
 [ 1256255.625]
 [ 1341099.75 ]
 [ 1358822.75 ]
 [ 1164574.   ]
 [ 1298589.375]
 [ 1381846.125]
 [ 1369156.   ]]
DEBUG:root:training time = %d0.230067
INFO:root:frame =7105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =7106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274896621704
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.943886666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999983
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =7109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =7110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame = 7111 State into memory, numbers recorded 195 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000531911849976
INFO:root:random_action_porb = 0.943855
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7112current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1298771.875]
 [ 1057382.375]
 [ 1227789.5  ]
 [ 1244322.875]
 [ 1334873.375]
 [ 1289542.125]
 [ 1489567.75 ]
 [ 1298771.875]
 [ 1283737.625]
 [ 1518339.   ]
 [ 1289542.125]
 [ 1260848.25 ]
 [ 1284994.875]
 [ 1481787.875]
 [ 1302304.5  ]
 [ 1350157.75 ]]
DEBUG:root:training time = %d0.217065
INFO:root:frame =7113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =7114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000297784805298
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.943823333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =7117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =7118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000369071960449
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.943791666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999985
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1226963.   ]
 [ 1431808.5  ]
 [ 1359893.125]
 [ 1356779.   ]
 [ 1349731.125]
 [ 1382333.   ]
 [ 1381814.   ]
 [ 1301747.25 ]
 [ 1247309.375]
 [ 1291694.375]
 [ 1228884.875]
 [ 1552073.125]
 [ 1223724.25 ]
 [ 1232139.   ]
 [ 1417629.75 ]
 [ 1299787.   ]]
DEBUG:root:training time = %d0.216481
INFO:root:frame =7121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:frame =7122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
DEBUG:root: save sample needs time = 0.000115156173706
INFO:root:random_action_porb = 0.94376
DEBUG:root: dqn, choose action rondomly, need time 0.000169999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:frame =7125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =7126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.943728333333
DEBUG:root: dqn, choose action rondomly, need time 0.000357999999977
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1325493.5  ]
 [ 1541031.25 ]
 [ 1356428.75 ]
 [ 1083278.5  ]
 [ 1281485.875]
 [ 1268289.5  ]
 [ 1187333.75 ]
 [ 1111212.5  ]
 [ 1262761.375]
 [ 1335406.   ]
 [ 1369096.5  ]
 [ 1221012.   ]
 [ 1247483.875]
 [ 1209097.875]
 [ 1310801.375]
 [ 1414552.5  ]]
DEBUG:root:training time = %d0.219552
INFO:root:frame =7129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =7130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:random_action_porb = 0.943696666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =7133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =7134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.943665
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999983
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:training error  = [[ 1319536.875]
 [ 1320681.25 ]
 [ 1165995.   ]
 [ 1319536.875]
 [ 1317756.   ]
 [ 1430602.875]
 [ 1300905.125]
 [ 1244383.875]
 [ 1300905.125]
 [ 1320681.25 ]
 [ 1238351.625]
 [ 1217307.125]
 [ 1267506.5  ]
 [ 1413275.125]
 [ 1266046.875]
 [ 1399050.   ]]
DEBUG:root:training time = %d0.211392
INFO:root:frame =7137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =7138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000763177871704
DEBUG:root: save sample needs time = 0.000141143798828
INFO:root:random_action_porb = 0.943633333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =7141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000513076782227
INFO:root:frame =7142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:random_action_porb = 0.943601666667
DEBUG:root: dqn, choose action rondomly, need time 0.000152000000014
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000130891799927
INFO:root:training error  = [[ 1204574.875]
 [ 1302950.875]
 [ 1283135.875]
 [ 1507120.625]
 [ 1272833.5  ]
 [ 1421772.125]
 [ 1283392.5  ]
 [ 1505145.625]
 [ 1371973.   ]
 [ 1314126.375]
 [ 1362135.125]
 [ 1257898.   ]
 [ 1283392.5  ]
 [ 1368612.125]
 [ 1470530.5  ]
 [ 1345427.875]]
DEBUG:root:training time = %d0.21594
INFO:root:frame =7145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =7146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000278949737549
DEBUG:root: save sample needs time = 0.000125169754028
INFO:root:random_action_porb = 0.94357
DEBUG:root: dqn, choose action rondomly, need time 0.000459999999975
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =7149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =7150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482082366943
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.943538333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999986
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1365766.5  ]
 [ 1290398.375]
 [ 1489577.375]
 [ 1377757.875]
 [ 1196015.625]
 [ 1322805.5  ]
 [ 1298678.375]
 [ 1220990.5  ]
 [ 1385687.625]
 [ 1449268.   ]
 [ 1213870.25 ]
 [ 1291179.5  ]
 [ 1463518.75 ]
 [ 1351696.875]
 [ 1236409.375]
 [ 1354150.375]]
DEBUG:root:training time = %d0.220397
INFO:root:frame =7153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =7154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.943506666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999981
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =7157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470161437988
INFO:root:frame =7158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:random_action_porb = 0.943475
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999986
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:training error  = [[ 1335559.375]
 [ 1265102.125]
 [ 1399424.25 ]
 [ 1399424.25 ]
 [ 1376323.125]
 [ 1321619.625]
 [ 1360503.5  ]
 [ 1447007.   ]
 [ 1301578.   ]
 [ 1314825.   ]
 [ 1245996.625]
 [ 1382305.375]
 [ 1446922.375]
 [ 1308530.5  ]
 [ 1371350.75 ]
 [ 1470980.5  ]]
DEBUG:root:training time = %d0.211547
INFO:root:frame =7161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =7162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.943443333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =7165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =7166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042986869812
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.943411666667
DEBUG:root: dqn, choose action rondomly, need time 0.000159999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1345328.125]
 [ 1480052.875]
 [ 1426988.875]
 [ 1431565.5  ]
 [ 1403475.25 ]
 [ 1479373.375]
 [ 1330197.25 ]
 [ 1302237.625]
 [ 1345350.75 ]
 [ 1543010.375]
 [ 1290771.125]
 [ 1429565.875]
 [ 1540173.125]
 [ 1357989.625]
 [ 1595736.375]
 [ 1691589.875]]
DEBUG:root:training time = %d0.228505
INFO:root:frame =7169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =7170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000451803207397
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.94338
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999983
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =7173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =7174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049901008606
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:random_action_porb = 0.943348333333
DEBUG:root: dqn, choose action rondomly, need time 0.000362000000024
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1488509.625]
 [ 1444667.875]
 [ 1643313.625]
 [ 1430425.375]
 [ 1605704.75 ]
 [ 1392980.875]
 [ 1373515.375]
 [ 1239551.75 ]
 [ 1556509.625]
 [ 1382833.625]
 [ 1418290.25 ]
 [ 1430425.375]
 [ 1371556.625]
 [ 1556066.25 ]
 [ 1457169.625]
 [ 1362012.125]]
DEBUG:root:training time = %d0.222245
INFO:root:frame =7177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000359058380127
INFO:root:frame =7178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame = 7179 State into memory, numbers recorded 196 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000560998916626
INFO:root:random_action_porb = 0.943316666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7180current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:frame =7181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =7182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000425100326538
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.943285
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1247750.125]
 [ 1642307.375]
 [ 1618525.625]
 [ 1587915.   ]
 [ 1450528.5  ]
 [ 1616106.375]
 [ 1576329.25 ]
 [ 1426116.5  ]
 [ 1305275.   ]
 [ 1617502.125]
 [ 1399036.125]
 [ 1348138.75 ]
 [ 1413553.75 ]
 [ 1453541.   ]
 [ 1654358.625]
 [ 1178814.875]]
DEBUG:root:training time = %d0.221774
INFO:root:frame =7185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:frame =7186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.943253333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =7189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000487089157104
INFO:root:frame =7190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000243186950684
INFO:root:random_action_porb = 0.943221666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1408741.75 ]
 [ 1576692.25 ]
 [ 1562045.875]
 [ 1601604.   ]
 [ 1364643.75 ]
 [ 1465490.   ]
 [ 1592476.375]
 [ 1640906.   ]
 [ 1465130.625]
 [ 1523643.125]
 [ 1555087.   ]
 [ 1326519.125]
 [ 1614348.875]
 [ 1564947.25 ]
 [ 1472601.25 ]
 [ 1325156.25 ]]
DEBUG:root:training time = %d0.224218
INFO:root:frame =7193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =7194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324964523315
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:random_action_porb = 0.94319
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =7197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =7198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.943158333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[ 1281428.375]
 [ 1341791.875]
 [ 1519138.125]
 [ 1262739.5  ]
 [ 1342199.125]
 [ 1352927.875]
 [ 1402110.375]
 [ 1290531.5  ]
 [ 1452015.625]
 [ 1351892.125]
 [ 1329035.25 ]
 [ 1491399.125]
 [ 1312564.   ]
 [ 1338301.   ]
 [ 1369850.75 ]
 [ 1440426.625]]
DEBUG:root:training time = %d0.203113
INFO:root:frame =7201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285148620605
INFO:root:frame =7202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.943126666667
DEBUG:root: dqn, choose action rondomly, need time 0.000169
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000136852264404
INFO:root:frame =7205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =7206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame = 7207 State into memory, numbers recorded 197 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000356912612915
INFO:root:random_action_porb = 0.943095
DEBUG:root: dqn, choose action rondomly, need time 0.000561000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7208current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000529050827026
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1546141.625]
 [ 1496474.375]
 [ 1438055.375]
 [ 1430958.   ]
 [ 1342927.875]
 [ 1556071.125]
 [ 1538404.125]
 [ 1441866.25 ]
 [ 1353818.625]
 [ 1487113.5  ]
 [ 1491389.5  ]
 [ 1419574.5  ]
 [ 1344888.75 ]
 [ 1506133.   ]
 [ 1477084.125]
 [ 1433253.25 ]]
DEBUG:root:training time = %d0.210631
INFO:root:frame =7209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =7210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229835510254
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.943063333333
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =7213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =7214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000224828720093
INFO:root:random_action_porb = 0.943031666667
DEBUG:root: dqn, choose action rondomly, need time 0.000330999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000368118286133
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1493885.5  ]
 [ 1421078.25 ]
 [ 1231111.625]
 [ 1523146.5  ]
 [ 1395180.875]
 [ 1460118.25 ]
 [ 1378445.625]
 [ 1322751.625]
 [ 1414199.375]
 [ 1515495.625]
 [ 1397539.625]
 [ 1505912.5  ]
 [ 1300905.125]
 [ 1727068.25 ]
 [ 1378230.125]
 [ 1648124.375]]
DEBUG:root:training time = %d0.221689
INFO:root:frame =7217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =7218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025486946106
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.943
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =7221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =7222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509977340698
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:random_action_porb = 0.942968333333
DEBUG:root: dqn, choose action rondomly, need time 0.000331000000017
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:training error  = [[ 1356988.375]
 [ 1620857.25 ]
 [ 1557713.625]
 [ 1682599.125]
 [ 1652183.875]
 [ 1604274.625]
 [ 1384326.875]
 [ 1414111.125]
 [ 1652063.375]
 [ 1260479.875]
 [ 1655906.5  ]
 [ 1551951.5  ]
 [ 1352164.75 ]
 [ 1416834.5  ]
 [ 1438495.75 ]
 [ 1508511.75 ]]
DEBUG:root:training time = %d0.217499
INFO:root:frame =7225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame =7226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.942936666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =7229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000490188598633
INFO:root:frame =7230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:random_action_porb = 0.942905
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1440478.125]
 [ 1682406.625]
 [ 1453804.75 ]
 [ 1620852.25 ]
 [ 1428291.125]
 [ 1555247.75 ]
 [ 1747369.   ]
 [ 1569181.875]
 [ 1635741.125]
 [ 1378620.   ]
 [ 1396653.125]
 [ 1453781.25 ]
 [ 1630833.75 ]
 [ 1639820.25 ]
 [ 1567792.5  ]
 [ 1632270.75 ]]
DEBUG:root:training time = %d0.212058
INFO:root:frame =7233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame =7234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428915023804
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.942873333333
DEBUG:root: dqn, choose action rondomly, need time 0.000400000000013
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =7237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =7238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000224828720093
INFO:root:random_action_porb = 0.942841666667
DEBUG:root: dqn, choose action rondomly, need time 0.000387999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1514750.375]
 [ 1650662.875]
 [ 1640805.875]
 [ 1640735.875]
 [ 1640805.875]
 [ 1729769.5  ]
 [ 1952078.375]
 [ 1579479.5  ]
 [ 1508809.125]
 [ 1762536.25 ]
 [ 1629043.375]
 [ 1588279.25 ]
 [ 1462077.75 ]
 [ 1494487.125]
 [ 1725918.5  ]
 [ 1462077.75 ]]
DEBUG:root:training time = %d0.21913
INFO:root:frame =7241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:frame =7242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000301122665405
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:random_action_porb = 0.94281
DEBUG:root: dqn, choose action rondomly, need time 0.00036399999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =7245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047779083252
INFO:root:frame =7246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000510931015015
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.942778333333
DEBUG:root: dqn, choose action rondomly, need time 0.000413000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 1572555.25 ]
 [ 1579798.625]
 [ 1575324.   ]
 [ 1631746.75 ]
 [ 1670924.875]
 [ 1516318.   ]
 [ 1652560.5  ]
 [ 1415979.125]
 [ 1617581.5  ]
 [ 1718674.875]
 [ 1567552.875]
 [ 1374907.375]
 [ 1702770.125]
 [ 1754295.125]
 [ 1583807.5  ]
 [ 1479078.75 ]]
DEBUG:root:training time = %d0.233212
INFO:root:frame =7249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =7250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000295162200928
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:random_action_porb = 0.942746666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =7253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =7254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.942715
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999986
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1533364.625]
 [ 1635531.25 ]
 [ 1382994.375]
 [ 1428865.375]
 [ 1460538.375]
 [ 1529826.   ]
 [ 1533524.25 ]
 [ 1616667.5  ]
 [ 1667488.   ]
 [ 1802699.625]
 [ 1695458.25 ]
 [ 1761297.   ]
 [ 1696022.875]
 [ 1523397.125]
 [ 1533364.625]
 [ 1695458.25 ]]
DEBUG:root:training time = %d0.21792
INFO:root:frame =7257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =7258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255107879639
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.942683333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =7261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =7262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:random_action_porb = 0.942651666667
DEBUG:root: dqn, choose action rondomly, need time 0.000192999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1737067.375]
 [ 1344879.625]
 [ 1742183.5  ]
 [ 1459098.875]
 [ 1596180.5  ]
 [ 1526716.   ]
 [ 1611610.375]
 [ 1461199.375]
 [ 1780280.375]
 [ 1671606.625]
 [ 1443344.125]
 [ 1506233.625]
 [ 1449028.125]
 [ 1566902.5  ]
 [ 1435817.125]
 [ 1728952.75 ]]
DEBUG:root:training time = %d0.196107
INFO:root:frame =7265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =7266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000592947006226
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.94262
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =7269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =7270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000389099121094
INFO:root:frame = 7271 State into memory, numbers recorded 198 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000656127929688
INFO:root:random_action_porb = 0.942588333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7272current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:training error  = [[ 1657706.5  ]
 [ 1461053.   ]
 [ 1555856.625]
 [ 1833839.625]
 [ 1470549.375]
 [ 1626133.   ]
 [ 1576108.625]
 [ 1563115.25 ]
 [ 1470549.375]
 [ 1532982.5  ]
 [ 1303530.625]
 [ 1448821.25 ]
 [ 1431154.25 ]
 [ 1920590.   ]
 [ 1540265.25 ]
 [ 1474170.625]]
DEBUG:root:training time = %d0.215521
INFO:root:frame =7273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =7274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:random_action_porb = 0.942556666667
DEBUG:root: dqn, choose action rondomly, need time 0.000323000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =7277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:frame =7278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.942525
DEBUG:root: dqn, choose action rondomly, need time 0.000339999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000401020050049
INFO:root:training error  = [[ 1715429.75 ]
 [ 1751719.5  ]
 [ 1766666.75 ]
 [ 1791781.   ]
 [ 1723948.5  ]
 [ 1779118.25 ]
 [ 1489820.5  ]
 [ 1690299.625]
 [ 1723948.5  ]
 [ 1503923.75 ]
 [ 1567332.875]
 [ 1867642.5  ]
 [ 1762629.625]
 [ 1709760.5  ]
 [ 1700502.625]
 [ 1662246.125]]
DEBUG:root:training time = %d0.228388
INFO:root:frame =7281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =7282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.942493333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =7285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =7286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000640869140625
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:random_action_porb = 0.942461666667
DEBUG:root: dqn, choose action rondomly, need time 0.000327999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:training error  = [[ 1512179.375]
 [ 1983063.5  ]
 [ 1686051.5  ]
 [ 1599642.   ]
 [ 1623962.   ]
 [ 1671187.375]
 [ 1390206.75 ]
 [ 1598915.75 ]
 [ 1420766.25 ]
 [ 1769393.625]
 [ 1595558.75 ]
 [ 1653836.25 ]
 [ 1737587.375]
 [ 1563237.375]
 [ 1445184.375]
 [ 1445184.375]]
DEBUG:root:training time = %d0.227537
INFO:root:frame =7289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =7290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475883483887
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.94243
DEBUG:root: dqn, choose action rondomly, need time 0.000323000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =7293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00048303604126
INFO:root:frame =7294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.942398333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1569186.875]
 [ 1687456.875]
 [ 1689710.5  ]
 [ 1822341.75 ]
 [ 1550321.625]
 [ 1645157.   ]
 [ 1697488.375]
 [ 1747358.625]
 [ 1611526.125]
 [ 1623583.625]
 [ 1671702.5  ]
 [ 1508641.25 ]
 [ 1698175.5  ]
 [ 1571796.   ]
 [ 1717784.   ]
 [ 1611526.125]]
DEBUG:root:training time = %d0.221119
INFO:root:frame =7297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =7298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324010848999
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.942366666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999983
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =7301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =7302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.942335
INFO:root:dqn select action Tensor("ArgMax_48:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013412
INFO:root:action choosen by dqn [4]
INFO:root:frame =7304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000191926956177
INFO:root:training error  = [[ 1454723.375]
 [ 1605224.625]
 [ 1556928.75 ]
 [ 1523966.125]
 [ 1703264.625]
 [ 1755050.5  ]
 [ 1594710.25 ]
 [ 1507576.25 ]
 [ 1763075.625]
 [ 1598980.   ]
 [ 1555189.25 ]
 [ 1565196.5  ]
 [ 1830054.125]
 [ 1498907.625]
 [ 1538694.875]
 [ 1644861.375]]
DEBUG:root:training time = %d0.219702
INFO:root:frame =7305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =7306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234842300415
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.942303333333
DEBUG:root: dqn, choose action rondomly, need time 0.000321000000014
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =7309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =7310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441789627075
INFO:root:frame = 7311 State into memory, numbers recorded 199 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000566005706787
INFO:root:random_action_porb = 0.942271666667
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7312current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:training error  = [[ 1604205.25 ]
 [ 1625007.5  ]
 [ 1614507.75 ]
 [ 1488838.5  ]
 [ 1652902.   ]
 [ 1816509.   ]
 [ 1311548.375]
 [ 1591939.125]
 [ 1590618.5  ]
 [ 1557162.75 ]
 [ 1721892.375]
 [ 1603136.75 ]
 [ 1584304.   ]
 [ 1746868.125]
 [ 1627747.375]
 [ 1684722.875]]
DEBUG:root:training time = %d0.203756
INFO:root:frame =7313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =7314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000326871871948
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:random_action_porb = 0.94224
INFO:root:dqn select action Tensor("ArgMax_49:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012141
INFO:root:action choosen by dqn [2]
INFO:root:frame =7316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =7317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame =7318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
INFO:root:frame = 7319 State into memory, numbers recorded 200 action = [2], reward = 0
DEBUG:root: save sample needs time = 0.0013599395752
INFO:root:random_action_porb = 0.942208333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7320current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000400066375732
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1637755.125]
 [ 1718198.75 ]
 [ 1781599.25 ]
 [ 1833569.875]
 [ 1563383.875]
 [ 1556305.   ]
 [ 1691920.125]
 [ 1497516.25 ]
 [ 1740436.   ]
 [ 1773771.375]
 [ 1746326.125]
 [ 1739895.   ]
 [ 1777295.125]
 [ 1671404.5  ]
 [ 1629128.125]
 [ 1567557.75 ]]
DEBUG:root:training time = %d0.221078
INFO:root:frame =7321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =7322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.942176666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000385046005249
INFO:root:frame =7325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =7326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424861907959
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.942145
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:training error  = [[ 1791592.75 ]
 [ 1930422.625]
 [ 1930422.625]
 [ 1757468.   ]
 [ 1556943.375]
 [ 1610509.75 ]
 [ 1644736.125]
 [ 1601267.75 ]
 [ 1978313.625]
 [ 1558976.625]
 [ 1676397.75 ]
 [ 1654333.5  ]
 [ 1670132.125]
 [ 1638710.   ]
 [ 1695361.625]
 [ 1831031.875]]
DEBUG:root:training time = %d0.236503
INFO:root:frame =7329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =7330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000352144241333
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.942113333333
INFO:root:dqn select action Tensor("ArgMax_50:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012917
INFO:root:action choosen by dqn [1]
INFO:root:frame =7332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000359058380127
INFO:root:frame =7333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271797180176
INFO:root:frame =7334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000603914260864
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.942081666667
DEBUG:root: dqn, choose action rondomly, need time 0.000534000000016
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[ 1582097.25 ]
 [ 2016283.5  ]
 [ 1858093.75 ]
 [ 1509538.625]
 [ 1733794.5  ]
 [ 1508847.5  ]
 [ 1538326.625]
 [ 1572359.25 ]
 [ 1572359.25 ]
 [ 1813341.   ]
 [ 1756147.75 ]
 [ 1590993.   ]
 [ 1683825.625]
 [ 1726416.375]
 [ 1781641.   ]
 [ 1853948.125]]
DEBUG:root:training time = %d0.211601
INFO:root:frame =7337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000370025634766
INFO:root:frame =7338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000371932983398
DEBUG:root: save sample needs time = 0.000157117843628
INFO:root:random_action_porb = 0.94205
INFO:root:dqn select action Tensor("ArgMax_51:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012736
INFO:root:action choosen by dqn [4]
INFO:root:frame =7340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:frame =7341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000192165374756
INFO:root:frame =7342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame = 7343 State into memory, numbers recorded 201 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00115299224854
INFO:root:random_action_porb = 0.942018333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7344current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1480480.5  ]
 [ 1426764.875]
 [ 1892602.125]
 [ 1678507.5  ]
 [ 1678811.125]
 [ 2044280.   ]
 [ 1937326.875]
 [ 1443048.5  ]
 [ 2053304.25 ]
 [ 1670298.75 ]
 [ 1695951.75 ]
 [ 1630055.625]
 [ 1882952.125]
 [ 1788822.625]
 [ 1603290.125]
 [ 1739699.125]]
DEBUG:root:training time = %d0.214025
INFO:root:frame =7345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root:frame =7346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00029993057251
DEBUG:root: save sample needs time = 0.000103950500488
INFO:root:random_action_porb = 0.941986666667
DEBUG:root: dqn, choose action rondomly, need time 0.000268000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =7349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =7350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485897064209
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:random_action_porb = 0.941955
INFO:root:dqn select action Tensor("ArgMax_52:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011132
INFO:root:action choosen by dqn [2]
INFO:root:frame =7352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1896172.   ]
 [ 1633264.   ]
 [ 1639810.25 ]
 [ 1860250.875]
 [ 1892763.25 ]
 [ 1839212.75 ]
 [ 1815287.875]
 [ 1815287.875]
 [ 1858285.5  ]
 [ 1643328.75 ]
 [ 1993666.75 ]
 [ 1921808.25 ]
 [ 1977868.625]
 [ 1917105.25 ]
 [ 1699646.875]
 [ 1569779.   ]]
DEBUG:root:training time = %d0.221248
INFO:root:frame =7353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =7354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.941923333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =7357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000771999359131
INFO:root:frame =7358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.941891666667
DEBUG:root: dqn, choose action rondomly, need time 0.000318000000021
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1886829.5  ]
 [ 1903327.375]
 [ 1978214.75 ]
 [ 1834008.875]
 [ 1961088.375]
 [ 1807291.625]
 [ 1802856.875]
 [ 1818473.375]
 [ 1903861.   ]
 [ 1702994.375]
 [ 1581080.25 ]
 [ 1715230.25 ]
 [ 1978214.75 ]
 [ 1798584.875]
 [ 1578851.125]
 [ 1854065.25 ]]
DEBUG:root:training time = %d0.219132
INFO:root:frame =7361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =7362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482797622681
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.94186
DEBUG:root: dqn, choose action rondomly, need time 0.000319999999988
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =7365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00048303604126
INFO:root:frame =7366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:random_action_porb = 0.941828333333
INFO:root:dqn select action Tensor("ArgMax_53:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013549
INFO:root:action choosen by dqn [1]
INFO:root:frame =7368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174045562744
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1686097.125]
 [ 1813162.125]
 [ 1653519.75 ]
 [ 1737391.75 ]
 [ 1663077.25 ]
 [ 1653665.375]
 [ 1531546.5  ]
 [ 1724743.5  ]
 [ 1572956.875]
 [ 1744014.25 ]
 [ 1755267.875]
 [ 1719038.5  ]
 [ 1585853.25 ]
 [ 1600803.25 ]
 [ 1902228.25 ]
 [ 1732056.5  ]]
DEBUG:root:training time = %d0.229123
INFO:root:frame =7369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =7370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000498056411743
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.941796666667
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =7373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466823577881
INFO:root:frame =7374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.941765
DEBUG:root: dqn, choose action rondomly, need time 0.000194999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2072891.25 ]
 [ 1711390.25 ]
 [ 1711390.25 ]
 [ 1834760.25 ]
 [ 1834760.25 ]
 [ 1997446.75 ]
 [ 1827148.875]
 [ 2028922.   ]
 [ 1945153.25 ]
 [ 1680335.   ]
 [ 1733403.625]
 [ 1978154.375]
 [ 1738782.25 ]
 [ 1640580.75 ]
 [ 1802264.25 ]
 [ 1956665.5  ]]
DEBUG:root:training time = %d0.203295
INFO:root:frame =7377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270843505859
INFO:root:frame =7378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame = 7379 State into memory, numbers recorded 202 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000391960144043
INFO:root:random_action_porb = 0.941733333333
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7380current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =7381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440835952759
INFO:root:frame =7382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame = 7383 State into memory, numbers recorded 203 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.00055193901062
INFO:root:random_action_porb = 0.941701666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7384current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:training error  = [[ 2111339.5  ]
 [ 1954846.375]
 [ 1648109.375]
 [ 1662890.875]
 [ 1564663.875]
 [ 1646229.375]
 [ 1758519.5  ]
 [ 2015496.   ]
 [ 2194900.   ]
 [ 1603740.25 ]
 [ 1783414.125]
 [ 1951128.75 ]
 [ 1693485.375]
 [ 1888767.   ]
 [ 2172774.   ]
 [ 1893462.   ]]
DEBUG:root:training time = %d0.222097
INFO:root:frame =7385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =7386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.94167
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =7389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =7390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480890274048
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:random_action_porb = 0.941638333333
DEBUG:root: dqn, choose action rondomly, need time 0.000204999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:training error  = [[ 1699478.875]
 [ 1724948.75 ]
 [ 1769887.25 ]
 [ 2016749.5  ]
 [ 1719863.25 ]
 [ 2060374.25 ]
 [ 1775113.875]
 [ 2041181.5  ]
 [ 2114559.   ]
 [ 1757654.5  ]
 [ 1990728.125]
 [ 1733640.25 ]
 [ 1759151.5  ]
 [ 1797086.875]
 [ 1938039.25 ]
 [ 1667089.5  ]]
DEBUG:root:training time = %d0.212417
INFO:root:frame =7393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =7394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000563859939575
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.941606666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
