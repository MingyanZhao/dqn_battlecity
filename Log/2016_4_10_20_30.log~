INFO:root:enemies_left [0]
INFO:root:frame =0 recording current_observation no.0
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =1 recording current_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =2 recording current_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =3 recording current_observation no.3
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =4current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =5 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427961349487
INFO:root:frame =6 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =8 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =9 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000549077987671
INFO:root:frame =10 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000238180160522
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:frame =12 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =13 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =14 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227928161621
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:frame =16 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =17 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000388145446777
INFO:root:frame =18 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9999905
DEBUG:root: dqn, choose action rondomly, need time 0.000171
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =20 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:frame =21 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:frame =22 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
DEBUG:root: save sample needs time = 0.000126838684082
INFO:root:random_action_porb = 0.999981
DEBUG:root: dqn, choose action rondomly, need time 0.000293
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =24 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =25 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =26 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9999715
DEBUG:root: dqn, choose action rondomly, need time 0.000337
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =28 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =29 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000706911087036
INFO:root:frame =30 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000520944595337
DEBUG:root: save sample needs time = 0.00010085105896
INFO:root:random_action_porb = 0.999962
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =32 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =33 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame =34 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9999525
DEBUG:root: dqn, choose action rondomly, need time 0.000591
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =36 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root:frame =37 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root:frame =38 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:random_action_porb = 0.999943
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =40 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =41 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =42 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.9999335
DEBUG:root: dqn, choose action rondomly, need time 0.000735
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =44 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =45 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =46 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000209808349609
INFO:root:random_action_porb = 0.999924
DEBUG:root: dqn, choose action rondomly, need time 0.00031
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =48 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000383853912354
INFO:root:frame =49 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000504970550537
INFO:root:frame =50 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000370025634766
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:random_action_porb = 0.9999145
DEBUG:root: dqn, choose action rondomly, need time 0.00017
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =52 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000187158584595
INFO:root:frame =53 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =54 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000604867935181
DEBUG:root: save sample needs time = 9.51290130615e-05
INFO:root:random_action_porb = 0.999905
DEBUG:root: dqn, choose action rondomly, need time 0.000204
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =56 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =57 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000391006469727
INFO:root:frame =58 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00037693977356
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:random_action_porb = 0.9998955
DEBUG:root: dqn, choose action rondomly, need time 0.000241
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =60 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000566005706787
INFO:root:frame =61 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =62 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:random_action_porb = 0.999886
DEBUG:root: dqn, choose action rondomly, need time 0.000265
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =64 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =65 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root:frame =66 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000307083129883
DEBUG:root: save sample needs time = 0.000178098678589
INFO:root:random_action_porb = 0.9998765
DEBUG:root: dqn, choose action rondomly, need time 0.000253
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =68 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =69 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000388860702515
INFO:root:frame =70 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000311851501465
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.999867
DEBUG:root: dqn, choose action rondomly, need time 0.000149
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =72 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:frame =73 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =74 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000220060348511
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.9998575
DEBUG:root: dqn, choose action rondomly, need time 0.000183
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =76 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root:frame =77 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029182434082
INFO:root:frame =78 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294923782349
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:random_action_porb = 0.999848
DEBUG:root: dqn, choose action rondomly, need time 0.000174
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =80 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:frame =81 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =82 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:random_action_porb = 0.9998385
DEBUG:root: dqn, choose action rondomly, need time 0.00016
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =84 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000147104263306
INFO:root:frame =85 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =86 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame = 87 State into memory, numbers recorded 1 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000386953353882
INFO:root:random_action_porb = 0.999829
DEBUG:root: dqn, choose action rondomly, need time 0.000178
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =88current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =89 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =90 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000314950942993
DEBUG:root: save sample needs time = 0.000146150588989
INFO:root:random_action_porb = 0.9998195
DEBUG:root: dqn, choose action rondomly, need time 0.000186
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =92 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =93 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286817550659
INFO:root:frame =94 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:random_action_porb = 0.99981
DEBUG:root: dqn, choose action rondomly, need time 0.000155
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =96 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142812728882
INFO:root:frame =97 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =98 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
DEBUG:root: save sample needs time = 0.00010085105896
INFO:root:random_action_porb = 0.9998005
DEBUG:root: dqn, choose action rondomly, need time 0.000164
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:frame =101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255107879639
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.999791
DEBUG:root: dqn, choose action rondomly, need time 0.000203
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000187158584595
INFO:root:frame =105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232219696045
INFO:root:frame =106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000370979309082
DEBUG:root: save sample needs time = 0.0001060962677
INFO:root:random_action_porb = 0.9997815
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000428915023804
INFO:root:frame =110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.999772
DEBUG:root: dqn, choose action rondomly, need time 0.000279
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.9997625
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000620126724243
INFO:root:frame =118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:random_action_porb = 0.999753
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root:frame =121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000529050827026
INFO:root:frame =122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:random_action_porb = 0.9997435
DEBUG:root: dqn, choose action rondomly, need time 0.000247
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:frame =125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:frame =126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294208526611
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.999734
DEBUG:root: dqn, choose action rondomly, need time 0.00022
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00032901763916
DEBUG:root: save sample needs time = 0.000146865844727
INFO:root:random_action_porb = 0.9997245
DEBUG:root: dqn, choose action rondomly, need time 0.0002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000312089920044
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root:random_action_porb = 0.999715
DEBUG:root: dqn, choose action rondomly, need time 0.000335
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000187158584595
INFO:root:frame =137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
DEBUG:root: save sample needs time = 0.00017786026001
INFO:root:random_action_porb = 0.9997055
DEBUG:root: dqn, choose action rondomly, need time 0.000329
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441789627075
INFO:root:frame =142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229120254517
DEBUG:root: save sample needs time = 0.000145196914673
INFO:root:random_action_porb = 0.999696
DEBUG:root: dqn, choose action rondomly, need time 0.000189
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:frame =145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000285863876343
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root:random_action_porb = 0.9996865
DEBUG:root: dqn, choose action rondomly, need time 0.000168
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:frame =149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000339031219482
DEBUG:root: save sample needs time = 0.000101804733276
INFO:root:random_action_porb = 0.999677
DEBUG:root: dqn, choose action rondomly, need time 0.000161
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root:frame =153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000329971313477
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.9996675
DEBUG:root: dqn, choose action rondomly, need time 0.000187
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:frame =157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame =158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000389814376831
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.999658
DEBUG:root: dqn, choose action rondomly, need time 0.000209
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000147104263306
INFO:root:frame =161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9996485
DEBUG:root: dqn, choose action rondomly, need time 0.000335
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00100088119507
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.999639
DEBUG:root: dqn, choose action rondomly, need time 0.000332
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.9996295
DEBUG:root: dqn, choose action rondomly, need time 0.000163
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root:frame =173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000322818756104
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.99962
DEBUG:root: dqn, choose action rondomly, need time 0.000244
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000413179397583
INFO:root:frame = 179 State into memory, numbers recorded 2 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000577926635742
INFO:root:random_action_porb = 0.9996105
DEBUG:root: dqn, choose action rondomly, need time 0.000211
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =180current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000290155410767
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.999601
DEBUG:root: dqn, choose action rondomly, need time 0.000316
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000364780426025
INFO:root:frame =185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame =186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000508069992065
INFO:root:frame = 187 State into memory, numbers recorded 3 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000597953796387
INFO:root:random_action_porb = 0.9995915
DEBUG:root: dqn, choose action rondomly, need time 0.000196
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =188current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000194072723389
INFO:root:frame =189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame =190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486850738525
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.999582
DEBUG:root: dqn, choose action rondomly, need time 0.000182
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:frame =193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229120254517
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:random_action_porb = 0.9995725
DEBUG:root: dqn, choose action rondomly, need time 0.000351
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237226486206
INFO:root:frame =198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.999563
DEBUG:root: dqn, choose action rondomly, need time 0.000306
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000224828720093
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:random_action_porb = 0.9995535
DEBUG:root: dqn, choose action rondomly, need time 0.000317
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449180603027
INFO:root:frame =206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047492980957
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.999544
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465154647827
INFO:root:frame =210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9995345
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000581979751587
DEBUG:root: save sample needs time = 0.000101804733276
INFO:root:random_action_porb = 0.999525
DEBUG:root: dqn, choose action rondomly, need time 0.000281
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000516176223755
INFO:root:frame =218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9995155
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000418901443481
INFO:root:frame =221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.999506
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9994965
DEBUG:root: dqn, choose action rondomly, need time 0.000311
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000484943389893
INFO:root:frame =230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.999487
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9994775
DEBUG:root: dqn, choose action rondomly, need time 0.000269
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.999468
DEBUG:root: dqn, choose action rondomly, need time 0.000311
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000111103057861
INFO:root:random_action_porb = 0.9994585
DEBUG:root: dqn, choose action rondomly, need time 0.000314
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000370979309082
INFO:root:frame =246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449180603027
DEBUG:root: save sample needs time = 0.000157117843628
INFO:root:random_action_porb = 0.999449
DEBUG:root: dqn, choose action rondomly, need time 0.000221
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:frame =249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000521183013916
INFO:root:frame =250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000595092773438
DEBUG:root: save sample needs time = 0.000168085098267
INFO:root:random_action_porb = 0.9994395
DEBUG:root: dqn, choose action rondomly, need time 0.000413
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.99943
DEBUG:root: dqn, choose action rondomly, need time 0.000465
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000482797622681
INFO:root:frame =257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9994205
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.999411
DEBUG:root: dqn, choose action rondomly, need time 0.0003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000414848327637
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9994015
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000296115875244
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.999392
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000495910644531
INFO:root:frame =274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000418901443481
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:random_action_porb = 0.9993825
DEBUG:root: dqn, choose action rondomly, need time 0.000543
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000490188598633
INFO:root:frame =278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469207763672
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.999373
DEBUG:root: dqn, choose action rondomly, need time 0.000313
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029182434082
INFO:root:frame =281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433206558228
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9993635
DEBUG:root: dqn, choose action rondomly, need time 0.000159
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000146150588989
INFO:root:frame =285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame = 287 State into memory, numbers recorded 4 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000523090362549
INFO:root:random_action_porb = 0.999354
DEBUG:root: dqn, choose action rondomly, need time 0.000293
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =288current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000379085540771
INFO:root:frame =289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000550031661987
INFO:root:frame =290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9993445
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0002281665802
INFO:root:frame =293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433206558228
INFO:root:frame =294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427007675171
DEBUG:root: save sample needs time = 0.000201225280762
INFO:root:random_action_porb = 0.999335
DEBUG:root: dqn, choose action rondomly, need time 0.000281
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000571012496948
INFO:root:frame =298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:frame = 299 State into memory, numbers recorded 5 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.00053596496582
INFO:root:random_action_porb = 0.9993255
DEBUG:root: dqn, choose action rondomly, need time 0.000242
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =300current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000261783599854
INFO:root:frame =301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.999316
DEBUG:root: dqn, choose action rondomly, need time 0.000172
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:frame =305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000256061553955
DEBUG:root: save sample needs time = 0.000147104263306
INFO:root:random_action_porb = 0.9993065
DEBUG:root: dqn, choose action rondomly, need time 0.000207
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185012817383
INFO:root:frame =309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame = 311 State into memory, numbers recorded 6 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000383853912354
INFO:root:random_action_porb = 0.999297
DEBUG:root: dqn, choose action rondomly, need time 0.000324
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =312current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:frame =313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000250101089478
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:random_action_porb = 0.9992875
DEBUG:root: dqn, choose action rondomly, need time 0.000326
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255823135376
INFO:root:frame =318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000503063201904
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.999278
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000480175018311
INFO:root:frame =322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.9992685
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000492095947266
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.999259
DEBUG:root: dqn, choose action rondomly, need time 0.000306
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:random_action_porb = 0.9992495
DEBUG:root: dqn, choose action rondomly, need time 0.000306
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494003295898
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:random_action_porb = 0.99924
DEBUG:root: dqn, choose action rondomly, need time 0.000316
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame =338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000587224960327
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:random_action_porb = 0.9992305
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:random_action_porb = 0.999221
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000373840332031
INFO:root:frame =345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00032114982605
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.9992115
DEBUG:root: dqn, choose action rondomly, need time 0.000332
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000401020050049
INFO:root:frame =349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.999202
DEBUG:root: dqn, choose action rondomly, need time 0.000321
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000527143478394
INFO:root:frame =353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481843948364
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.9991925
DEBUG:root: dqn, choose action rondomly, need time 0.000379
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.999183
DEBUG:root: dqn, choose action rondomly, need time 0.000313
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000266790390015
INFO:root:frame =361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.9991735
DEBUG:root: dqn, choose action rondomly, need time 0.000291
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427007675171
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.999164
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00061297416687
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.9991545
DEBUG:root: dqn, choose action rondomly, need time 0.000293
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000670909881592
INFO:root:frame =373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root: ememy has been killed for 1 times 
INFO:root:enemies_left [0]
INFO:root:frame =374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000363111495972
INFO:root:frame = 375 State into memory, numbers recorded 7 action = 2, reward = 255
DEBUG:root: save sample needs time = 0.000552892684937
INFO:root:random_action_porb = 0.999145
DEBUG:root: dqn, choose action rondomly, need time 0.00033
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =376current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.000110149383545
INFO:root:random_action_porb = 0.9991355
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.999126
DEBUG:root: dqn, choose action rondomly, need time 0.000274
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000146150588989
INFO:root:random_action_porb = 0.9991165
DEBUG:root: dqn, choose action rondomly, need time 0.00044
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root:frame =389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame = 391 State into memory, numbers recorded 8 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000586986541748
INFO:root:random_action_porb = 0.999107
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =392current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000327825546265
INFO:root:frame =393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:random_action_porb = 0.9990975
DEBUG:root: dqn, choose action rondomly, need time 0.000292
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000209808349609
INFO:root:random_action_porb = 0.999088
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.9990785
DEBUG:root: dqn, choose action rondomly, need time 0.00032
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000392913818359
INFO:root:frame =405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308990478516
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.999069
DEBUG:root: dqn, choose action rondomly, need time 0.000192
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:frame =409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444173812866
INFO:root:frame =410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame = 411 State into memory, numbers recorded 9 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000571012496948
INFO:root:random_action_porb = 0.9990595
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =412current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446796417236
INFO:root:frame =414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234127044678
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:random_action_porb = 0.99905
DEBUG:root: dqn, choose action rondomly, need time 0.000328
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame =417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
INFO:root:frame = 419 State into memory, numbers recorded 10 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.00056004524231
INFO:root:random_action_porb = 0.9990405
DEBUG:root: dqn, choose action rondomly, need time 0.000176
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =420current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.00017786026001
INFO:root:frame =421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame = 423 State into memory, numbers recorded 11 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000615835189819
INFO:root:random_action_porb = 0.999031
DEBUG:root: dqn, choose action rondomly, need time 0.000295
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =424current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471830368042
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:random_action_porb = 0.9990215
DEBUG:root: dqn, choose action rondomly, need time 0.000312
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000496864318848
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.999012
DEBUG:root: dqn, choose action rondomly, need time 0.000324
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000362873077393
INFO:root:frame =433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482082366943
INFO:root:frame = 435 State into memory, numbers recorded 12 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.00053596496582
INFO:root:random_action_porb = 0.9990025
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =436current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:player has been killed for 1 times 
INFO:root:frame = 439 State into memory, numbers recorded 13 action = None, reward = -255
DEBUG:root: save sample needs time = 0.000518083572388
INFO:root:random_action_porb = 0.998993
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =440current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000327825546265
INFO:root:frame =441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:random_action_porb = 0.9989835
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000482082366943
INFO:root:frame =446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:random_action_porb = 0.998974
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9989645
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000415086746216
INFO:root:frame =454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.998955
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9989455
DEBUG:root: dqn, choose action rondomly, need time 0.000449
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000199794769287
INFO:root:random_action_porb = 0.998936
DEBUG:root: dqn, choose action rondomly, need time 0.000319
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000493049621582
INFO:root:frame =466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9989265
DEBUG:root: dqn, choose action rondomly, need time 0.000291
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.998917
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9989075
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449180603027
INFO:root:frame =478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:player has been killed for 2 times 
INFO:root:frame = 479 State into memory, numbers recorded 14 action = None, reward = -255
DEBUG:root: save sample needs time = 0.000422954559326
INFO:root:random_action_porb = 0.998898
DEBUG:root: dqn, choose action rondomly, need time 0.000293
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =480current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9988885
DEBUG:root: dqn, choose action rondomly, need time 0.000292
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.998879
DEBUG:root: dqn, choose action rondomly, need time 0.000153
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:frame =489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000361919403076
INFO:root:frame =490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482082366943
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.9988695
DEBUG:root: dqn, choose action rondomly, need time 0.000305
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame = 495 State into memory, numbers recorded 15 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.00053596496582
INFO:root:random_action_porb = 0.99886
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =496current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
INFO:root:frame = 499 State into memory, numbers recorded 16 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00054407119751
INFO:root:random_action_porb = 0.9988505
DEBUG:root: dqn, choose action rondomly, need time 0.000280999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =500current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.998841
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464200973511
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9988315
DEBUG:root: dqn, choose action rondomly, need time 0.000295
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.998822
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044322013855
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.9988125
DEBUG:root: dqn, choose action rondomly, need time 0.000237
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:frame =517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000508069992065
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.998803
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame = 523 State into memory, numbers recorded 17 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000633955001831
INFO:root:random_action_porb = 0.9987935
DEBUG:root: dqn, choose action rondomly, need time 0.000341
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =524current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.998784
DEBUG:root: dqn, choose action rondomly, need time 0.000291
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000372886657715
INFO:root:frame =529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000253915786743
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:random_action_porb = 0.9987745
DEBUG:root: dqn, choose action rondomly, need time 0.000324
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487089157104
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.998765
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root:frame =537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.9987555
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000419139862061
INFO:root:frame =542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000417947769165
DEBUG:root: save sample needs time = 0.000123977661133
INFO:root:random_action_porb = 0.998746
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root:frame =546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9987365
DEBUG:root: dqn, choose action rondomly, need time 0.000382
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000488996505737
INFO:root:frame =549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:frame = 551 State into memory, numbers recorded 18 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:random_action_porb = 0.998727
DEBUG:root: dqn, choose action rondomly, need time 0.000251
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =552current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:frame =553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame = 555 State into memory, numbers recorded 19 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000578880310059
INFO:root:random_action_porb = 0.9987175
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =556current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494956970215
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.998708
DEBUG:root: dqn, choose action rondomly, need time 0.0007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9986985
DEBUG:root: dqn, choose action rondomly, need time 0.000513
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000429153442383
INFO:root:frame =566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430822372437
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.998689
DEBUG:root: dqn, choose action rondomly, need time 0.000278000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424861907959
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.9986795
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000361919403076
INFO:root:frame =574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000121116638184
INFO:root:random_action_porb = 0.99867
DEBUG:root: dqn, choose action rondomly, need time 0.000224
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000146150588989
INFO:root:frame =577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263214111328
INFO:root:frame =578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9986605
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000645875930786
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:random_action_porb = 0.998651
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.9986415
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:random_action_porb = 0.998632
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000416040420532
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9986225
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.998613
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9986035
DEBUG:root: dqn, choose action rondomly, need time 0.000281
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029182434082
INFO:root:frame =605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.998594
DEBUG:root: dqn, choose action rondomly, need time 0.000281
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000591993331909
INFO:root:frame =610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000318050384521
DEBUG:root: save sample needs time = 0.000166177749634
INFO:root:random_action_porb = 0.9985845
DEBUG:root: dqn, choose action rondomly, need time 0.000247
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000184059143066
INFO:root:frame =613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.998575
DEBUG:root: dqn, choose action rondomly, need time 0.000305
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9985655
DEBUG:root: dqn, choose action rondomly, need time 0.000271000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224828720093
INFO:root:frame =622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.998556
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root:frame =625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9985465
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.998537
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000403165817261
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9985275
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000580072402954
INFO:root:frame =638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:random_action_porb = 0.998518
DEBUG:root: dqn, choose action rondomly, need time 0.000191
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180959701538
INFO:root:frame =641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9985085
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.998499
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000584840774536
INFO:root:frame =650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294923782349
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.9984895
DEBUG:root: dqn, choose action rondomly, need time 0.00055
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000504970550537
INFO:root:frame =654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.99848
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame = 659 State into memory, numbers recorded 20 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000540018081665
INFO:root:random_action_porb = 0.9984705
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =660current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.998461
DEBUG:root: dqn, choose action rondomly, need time 0.0003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000519037246704
DEBUG:root: save sample needs time = 0.000115156173706
INFO:root:random_action_porb = 0.9984515
DEBUG:root: dqn, choose action rondomly, need time 0.000173
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000158071517944
INFO:root:frame =669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame = 671 State into memory, numbers recorded 21 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000567197799683
INFO:root:random_action_porb = 0.998442
DEBUG:root: dqn, choose action rondomly, need time 0.000296
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =672current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000351190567017
INFO:root:frame =673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame =674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.9984325
DEBUG:root: dqn, choose action rondomly, need time 0.000314
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.998423
DEBUG:root: dqn, choose action rondomly, need time 0.000315
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000500917434692
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:random_action_porb = 0.9984135
DEBUG:root: dqn, choose action rondomly, need time 0.000291
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame =685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.998404
DEBUG:root: dqn, choose action rondomly, need time 0.000168
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000150918960571
INFO:root:frame =689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.9983945
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355958938599
INFO:root:frame =693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.998385
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000558853149414
INFO:root:frame =698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9983755
DEBUG:root: dqn, choose action rondomly, need time 0.000306
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320196151733
INFO:root:frame =701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466823577881
INFO:root:frame =702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.998366
DEBUG:root: dqn, choose action rondomly, need time 0.000324
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.9983565
DEBUG:root: dqn, choose action rondomly, need time 0.000385000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:frame =709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:random_action_porb = 0.998347
DEBUG:root: dqn, choose action rondomly, need time 0.000307
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.9983375
DEBUG:root: dqn, choose action rondomly, need time 0.000328
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root: ememy has been killed for 2 times 
INFO:root:enemies_left [0]
INFO:root:frame =716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000363111495972
INFO:root:frame =717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root:frame = 719 State into memory, numbers recorded 22 action = 2, reward = 255
DEBUG:root: save sample needs time = 0.000578165054321
INFO:root:random_action_porb = 0.998328
DEBUG:root: dqn, choose action rondomly, need time 0.000304000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =720current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000327110290527
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.9983185
DEBUG:root: dqn, choose action rondomly, need time 0.000293
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247001647949
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.998309
DEBUG:root: dqn, choose action rondomly, need time 0.000656
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000364065170288
INFO:root:frame =729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000115156173706
INFO:root:random_action_porb = 0.9982995
DEBUG:root: dqn, choose action rondomly, need time 0.000307
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.99829
DEBUG:root: dqn, choose action rondomly, need time 0.000209999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:frame =737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9982805
DEBUG:root: dqn, choose action rondomly, need time 0.000274999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame =741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000392913818359
INFO:root:frame =742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.998271
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446796417236
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.9982615
DEBUG:root: dqn, choose action rondomly, need time 0.000305
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000481128692627
INFO:root:frame =750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470161437988
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.998252
DEBUG:root: dqn, choose action rondomly, need time 0.00031
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476837158203
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9982425
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame =758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame = 759 State into memory, numbers recorded 23 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000564098358154
INFO:root:random_action_porb = 0.998233
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =760current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000108957290649
INFO:root:random_action_porb = 0.9982235
DEBUG:root: dqn, choose action rondomly, need time 0.000317000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000804901123047
INFO:root:frame =766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.998214
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000496864318848
INFO:root:frame =770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000516176223755
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:random_action_porb = 0.9982045
DEBUG:root: dqn, choose action rondomly, need time 0.000344
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000514030456543
INFO:root:frame =774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475883483887
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:random_action_porb = 0.998195
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042986869812
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9981855
DEBUG:root: dqn, choose action rondomly, need time 0.000293
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000511884689331
INFO:root:frame =782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame = 783 State into memory, numbers recorded 24 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000584125518799
INFO:root:random_action_porb = 0.998176
DEBUG:root: dqn, choose action rondomly, need time 0.000293
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =784current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488042831421
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.9981665
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000372171401978
INFO:root:frame =789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465154647827
INFO:root:frame =790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481128692627
DEBUG:root: save sample needs time = 0.000109910964966
INFO:root:random_action_porb = 0.998157
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame =793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.9981475
DEBUG:root: dqn, choose action rondomly, need time 0.000292
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root:frame =797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000626087188721
INFO:root:frame =798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.998138
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00023889541626
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9981285
DEBUG:root: dqn, choose action rondomly, need time 0.000415
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:frame =805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:random_action_porb = 0.998119
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000507831573486
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:random_action_porb = 0.9981095
DEBUG:root: dqn, choose action rondomly, need time 0.000316
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.9981
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444173812866
INFO:root:frame =818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000325918197632
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.9980905
DEBUG:root: dqn, choose action rondomly, need time 0.000309
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:random_action_porb = 0.998081
DEBUG:root: dqn, choose action rondomly, need time 0.000292
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338792800903
INFO:root:frame =825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:random_action_porb = 0.9980715
DEBUG:root: dqn, choose action rondomly, need time 0.000309
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000475168228149
INFO:root:frame =830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00053596496582
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.998062
DEBUG:root: dqn, choose action rondomly, need time 0.000189
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000146865844727
INFO:root:frame =833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.9980525
DEBUG:root: dqn, choose action rondomly, need time 0.000398000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000411987304688
INFO:root:frame =837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root:frame =838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444173812866
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.998043
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9980335
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000598907470703
INFO:root:frame =846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000316143035889
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.998024
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486850738525
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.9980145
DEBUG:root: dqn, choose action rondomly, need time 0.000306
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame = 855 State into memory, numbers recorded 25 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000623941421509
INFO:root:random_action_porb = 0.998005
DEBUG:root: dqn, choose action rondomly, need time 0.000324
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =856current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.9979955
DEBUG:root: dqn, choose action rondomly, need time 0.000328000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.997986
DEBUG:root: dqn, choose action rondomly, need time 0.000317
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:random_action_porb = 0.9979765
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.997967
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.9979575
DEBUG:root: dqn, choose action rondomly, need time 0.00032
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00030517578125
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.997948
DEBUG:root: dqn, choose action rondomly, need time 0.000318999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame =881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000495910644531
INFO:root:frame =882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.9979385
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000315189361572
INFO:root:frame =885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame =886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000375032424927
DEBUG:root: save sample needs time = 0.000168085098267
INFO:root:random_action_porb = 0.997929
DEBUG:root: dqn, choose action rondomly, need time 0.000293
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00044584274292
INFO:root:frame =890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486135482788
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.9979195
DEBUG:root: dqn, choose action rondomly, need time 0.000324
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root:frame =893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.99791
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440835952759
INFO:root:frame =898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9979005
DEBUG:root: dqn, choose action rondomly, need time 0.00033
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338792800903
INFO:root:frame =901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.997891
DEBUG:root: dqn, choose action rondomly, need time 0.000296
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365972518921
INFO:root:frame =905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame =906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:random_action_porb = 0.9978815
DEBUG:root: dqn, choose action rondomly, need time 0.000315
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root:frame =909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000496864318848
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.997872
DEBUG:root: dqn, choose action rondomly, need time 0.000315
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000519990921021
INFO:root:frame =914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000665903091431
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:random_action_porb = 0.9978625
DEBUG:root: dqn, choose action rondomly, need time 0.000313
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame =918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.997853
DEBUG:root: dqn, choose action rondomly, need time 0.000291
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00048303604126
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.9978435
DEBUG:root: dqn, choose action rondomly, need time 0.000323
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000493049621582
INFO:root:frame =926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000523090362549
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.997834
DEBUG:root: dqn, choose action rondomly, need time 0.00041
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000503063201904
INFO:root:frame =930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame = 931 State into memory, numbers recorded 26 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:random_action_porb = 0.9978245
DEBUG:root: dqn, choose action rondomly, need time 0.000305
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =932current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root:frame =934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000507116317749
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.997815
DEBUG:root: dqn, choose action rondomly, need time 0.000306
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000486850738525
INFO:root:frame =938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000505924224854
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.9978055
DEBUG:root: dqn, choose action rondomly, need time 0.00032
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.997796
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9977865
DEBUG:root: dqn, choose action rondomly, need time 0.000286
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304222106934
INFO:root:frame =949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame =950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:random_action_porb = 0.997777
DEBUG:root: dqn, choose action rondomly, need time 0.000279
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame = 955 State into memory, numbers recorded 27 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000420093536377
INFO:root:random_action_porb = 0.9977675
DEBUG:root: dqn, choose action rondomly, need time 0.000217
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =956current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000193119049072
INFO:root:frame =957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000507831573486
INFO:root:frame =958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.997758
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000376224517822
INFO:root:frame =961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000487089157104
INFO:root:frame =962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9977485
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.997739
DEBUG:root: dqn, choose action rondomly, need time 0.000293
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000592947006226
INFO:root:frame =970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame = 971 State into memory, numbers recorded 28 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:random_action_porb = 0.9977295
DEBUG:root: dqn, choose action rondomly, need time 0.000314
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =972current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000507831573486
INFO:root:frame =974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000276803970337
INFO:root:random_action_porb = 0.99772
DEBUG:root: dqn, choose action rondomly, need time 0.000292
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9977105
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000126123428345
INFO:root:random_action_porb = 0.997701
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000510931015015
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9976915
DEBUG:root: dqn, choose action rondomly, need time 0.000293
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448226928711
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.997682
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000420093536377
INFO:root:frame =994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000418901443481
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9976725
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:frame =998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000205993652344
DEBUG:root:one frame running time = 0.006006
DEBUG:root:total training time = 6.028438
INFO:root:frame num = 1000 frame round: 0
INFO:root:random_action_porb = 0.997663
DEBUG:root: dqn, choose action rondomly, need time 0.000288
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000360012054443
INFO:root:frame =1001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =1002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.9976535
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000418901443481
INFO:root:frame =1006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.997644
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =1009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame =1010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.9976345
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =1013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =1014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:random_action_porb = 0.997625
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =1018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9976155
DEBUG:root: dqn, choose action rondomly, need time 0.000352
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427961349487
INFO:root:frame =1022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.997606
DEBUG:root: dqn, choose action rondomly, need time 0.000446
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =1025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =1026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9975965
DEBUG:root: dqn, choose action rondomly, need time 0.000280999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =1029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =1030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame = 1031 State into memory, numbers recorded 29 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000578165054321
INFO:root:random_action_porb = 0.997587
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1032current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =1033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =1034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 9.51290130615e-05
INFO:root:random_action_porb = 0.9975775
DEBUG:root: dqn, choose action rondomly, need time 0.000151
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:frame =1037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =1038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231981277466
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.997568
DEBUG:root: dqn, choose action rondomly, need time 0.000150000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:frame =1041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:frame =1042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00021505355835
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.9975585
DEBUG:root: dqn, choose action rondomly, need time 0.000175
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root:frame =1045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =1046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.997549
DEBUG:root: dqn, choose action rondomly, need time 0.0003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =1049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =1050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9975395
DEBUG:root: dqn, choose action rondomly, need time 0.000197
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:frame =1053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =1054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.99753
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =1057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =1058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9975205
DEBUG:root: dqn, choose action rondomly, need time 0.000281
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =1061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =1062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.997511
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =1065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000504016876221
INFO:root:frame =1066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000297069549561
DEBUG:root: save sample needs time = 0.000206232070923
INFO:root:random_action_porb = 0.9975015
DEBUG:root: dqn, choose action rondomly, need time 0.000581
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471115112305
INFO:root:frame =1070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.997492
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =1073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000500917434692
INFO:root:frame =1074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.9974825
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000378847122192
INFO:root:frame =1077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000487089157104
INFO:root:frame =1078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.997473
DEBUG:root: dqn, choose action rondomly, need time 0.000171
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:frame =1081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =1082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488996505737
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:random_action_porb = 0.9974635
DEBUG:root: dqn, choose action rondomly, need time 0.000251
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =1085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000415802001953
INFO:root:frame =1086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324964523315
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.997454
DEBUG:root: dqn, choose action rondomly, need time 0.000186999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174045562744
INFO:root:frame =1089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446796417236
INFO:root:frame =1090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.9974445
DEBUG:root: dqn, choose action rondomly, need time 0.000368000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =1093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000553131103516
INFO:root:frame =1094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002281665802
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.997435
DEBUG:root: dqn, choose action rondomly, need time 0.000316
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =1097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =1098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000280857086182
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:random_action_porb = 0.9974255
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336170196533
INFO:root:frame =1101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =1102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:random_action_porb = 0.997416
DEBUG:root: dqn, choose action rondomly, need time 0.000242999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:frame =1105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =1106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476121902466
DEBUG:root: save sample needs time = 0.000145196914673
INFO:root:random_action_porb = 0.9974065
DEBUG:root: dqn, choose action rondomly, need time 0.000402
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =1109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =1110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000519990921021
DEBUG:root: save sample needs time = 0.000105142593384
INFO:root:random_action_porb = 0.997397
DEBUG:root: dqn, choose action rondomly, need time 0.000277
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:frame =1113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000492811203003
INFO:root:frame =1114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000254154205322
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9973875
DEBUG:root: dqn, choose action rondomly, need time 0.000337
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427961349487
INFO:root:frame =1118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:player has been killed for 3 times 
INFO:root:frame = 1119 State into memory, numbers recorded 30 action = None, reward = -255
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:random_action_porb = 0.997378
DEBUG:root: dqn, choose action rondomly, need time 0.000163
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1120current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000150918960571
INFO:root:frame =1121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =1122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.9973685
DEBUG:root: dqn, choose action rondomly, need time 0.000352
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =1125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000295162200928
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.997359
DEBUG:root: dqn, choose action rondomly, need time 0.000316
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =1129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491857528687
INFO:root:frame =1130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047492980957
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.9973495
DEBUG:root: dqn, choose action rondomly, need time 0.000183
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:frame =1133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =1134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000242948532104
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.99734
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =1138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:random_action_porb = 0.9973305
DEBUG:root: dqn, choose action rondomly, need time 0.000196000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000194072723389
INFO:root:frame =1141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame =1142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.997321
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =1145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =1146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000104904174805
INFO:root:random_action_porb = 0.9973115
DEBUG:root: dqn, choose action rondomly, need time 0.000181999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root:frame =1149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:frame =1150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275135040283
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.997302
DEBUG:root: dqn, choose action rondomly, need time 0.000188999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:frame =1153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =1154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame = 1155 State into memory, numbers recorded 31 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000560998916626
INFO:root:random_action_porb = 0.9972925
DEBUG:root: dqn, choose action rondomly, need time 0.000290999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1156current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =1157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000385999679565
INFO:root:frame =1158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.997283
DEBUG:root: dqn, choose action rondomly, need time 0.000328000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000689029693604
INFO:root:frame =1161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000494003295898
INFO:root:frame =1162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9972735
DEBUG:root: dqn, choose action rondomly, need time 0.000499999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =1165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:frame =1166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.997264
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =1169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =1170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231981277466
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9972545
DEBUG:root: dqn, choose action rondomly, need time 0.000171999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000157117843628
INFO:root:frame =1173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =1174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame = 1175 State into memory, numbers recorded 32 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:random_action_porb = 0.997245
DEBUG:root: dqn, choose action rondomly, need time 0.000183000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1176current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:frame =1177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =1178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255107879639
DEBUG:root: save sample needs time = 9.91821289062e-05
INFO:root:random_action_porb = 0.9972355
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =1181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449180603027
INFO:root:frame =1182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000498056411743
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.997226
DEBUG:root: dqn, choose action rondomly, need time 0.000342
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root: ememy has been killed for 3 times 
INFO:root:enemies_left [0]
INFO:root:frame =1184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =1185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =1186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476837158203
INFO:root:frame = 1187 State into memory, numbers recorded 33 action = 4, reward = 255
DEBUG:root: save sample needs time = 0.000546932220459
INFO:root:random_action_porb = 0.9972165
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1188current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =1189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =1190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.997207
DEBUG:root: dqn, choose action rondomly, need time 0.000197
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:frame =1193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000419139862061
INFO:root:frame =1194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9971975
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =1197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =1198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.997188
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =1201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000482082366943
INFO:root:frame =1202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:random_action_porb = 0.9971785
DEBUG:root: dqn, choose action rondomly, need time 0.000278
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =1205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046181678772
INFO:root:frame =1206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288963317871
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:random_action_porb = 0.997169
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =1210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000581026077271
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9971595
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =1213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000420093536377
INFO:root:frame =1214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000180959701538
INFO:root:random_action_porb = 0.99715
DEBUG:root: dqn, choose action rondomly, need time 0.000278
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =1218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000842094421387
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:random_action_porb = 0.9971405
DEBUG:root: dqn, choose action rondomly, need time 0.000205999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185012817383
INFO:root:frame =1221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =1222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:random_action_porb = 0.997131
DEBUG:root: dqn, choose action rondomly, need time 0.000279000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =1225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:frame =1226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.9971215
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:frame =1229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =1230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.997112
DEBUG:root: dqn, choose action rondomly, need time 0.000166999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000141143798828
INFO:root:frame =1233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000638008117676
INFO:root:frame =1234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000336885452271
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:random_action_porb = 0.9971025
DEBUG:root: dqn, choose action rondomly, need time 0.000275
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =1237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =1238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame = 1239 State into memory, numbers recorded 34 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000560998916626
INFO:root:random_action_porb = 0.997093
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1240current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root:frame =1241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =1242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00055193901062
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:random_action_porb = 0.9970835
DEBUG:root: dqn, choose action rondomly, need time 0.000203999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180006027222
INFO:root:frame =1245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =1246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:random_action_porb = 0.997074
DEBUG:root: dqn, choose action rondomly, need time 0.00033
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =1249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000502109527588
INFO:root:frame =1250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:random_action_porb = 0.9970645
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000385999679565
INFO:root:frame =1253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =1254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000253200531006
INFO:root:random_action_porb = 0.997055
DEBUG:root: dqn, choose action rondomly, need time 0.000313
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =1257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000482082366943
INFO:root:frame =1258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:random_action_porb = 0.9970455
DEBUG:root: dqn, choose action rondomly, need time 0.000255000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:frame =1261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240802764893
INFO:root:frame =1262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000505208969116
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.997036
DEBUG:root: dqn, choose action rondomly, need time 0.000271
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root:frame =1265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =1266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.9970265
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =1269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =1270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.997017
DEBUG:root: dqn, choose action rondomly, need time 0.000449000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =1273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame =1274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000250101089478
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:random_action_porb = 0.9970075
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000315189361572
INFO:root:frame =1277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =1278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.996998
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000315189361572
INFO:root:frame =1281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000411033630371
INFO:root:frame =1282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:random_action_porb = 0.9969885
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root:frame =1285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000480890274048
INFO:root:frame =1286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
DEBUG:root: save sample needs time = 0.000107049942017
INFO:root:random_action_porb = 0.996979
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =1289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =1290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.9969695
DEBUG:root: dqn, choose action rondomly, need time 0.000183
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000176191329956
INFO:root:frame =1293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =1294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root: ememy has been killed for 4 times 
INFO:root:enemies_left [0]
INFO:root:frame = 1295 State into memory, numbers recorded 35 action = 4, reward = 255
DEBUG:root: save sample needs time = 0.000466823577881
INFO:root:random_action_porb = 0.99696
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1296current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =1297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame =1298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.9969505
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =1301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =1302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.996941
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =1305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =1306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239133834839
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.9969315
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =1309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =1310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000420093536377
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:random_action_porb = 0.996922
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =1313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =1314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.9969125
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =1317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =1318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.996903
DEBUG:root: dqn, choose action rondomly, need time 0.000327
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =1321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =1322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480890274048
DEBUG:root: save sample needs time = 0.000209808349609
INFO:root:random_action_porb = 0.9968935
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326156616211
INFO:root:frame =1325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436782836914
INFO:root:frame =1326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.996884
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =1329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =1330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.9968745
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =1333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =1334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446796417236
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:random_action_porb = 0.996865
DEBUG:root: dqn, choose action rondomly, need time 0.00019
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000178098678589
INFO:root:frame =1337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =1338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.9968555
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =1341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame =1342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.996846
DEBUG:root: dqn, choose action rondomly, need time 0.000431000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320196151733
INFO:root:frame =1345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =1346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.9968365
DEBUG:root: dqn, choose action rondomly, need time 0.000525999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =1349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =1350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.996827
DEBUG:root: dqn, choose action rondomly, need time 0.000529999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000419855117798
INFO:root:frame =1354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00051212310791
DEBUG:root: save sample needs time = 0.000150918960571
INFO:root:random_action_porb = 0.9968175
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =1357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =1358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:random_action_porb = 0.996808
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =1361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =1362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.9967985
DEBUG:root: dqn, choose action rondomly, need time 0.000271
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =1365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =1366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.996789
DEBUG:root: dqn, choose action rondomly, need time 0.000359
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =1369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000482082366943
INFO:root:frame =1370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.9967795
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =1373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =1374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000500917434692
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.99677
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =1378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.9967605
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =1381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049614906311
INFO:root:frame =1382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470876693726
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.996751
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =1385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =1386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000224828720093
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9967415
DEBUG:root: dqn, choose action rondomly, need time 0.000275
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =1389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =1390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.996732
DEBUG:root: dqn, choose action rondomly, need time 0.000293000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =1393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =1394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9967225
DEBUG:root: dqn, choose action rondomly, need time 0.000292
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =1397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =1398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.996713
DEBUG:root: dqn, choose action rondomly, need time 0.000293000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =1401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =1402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: ememy has been killed for 5 times 
INFO:root:enemies_left [0]
INFO:root:frame = 1403 State into memory, numbers recorded 36 action = 2, reward = 255
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:random_action_porb = 0.9967035
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1404current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000362873077393
INFO:root:frame =1405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:player has been killed for 4 times 
INFO:root:frame =1406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame = 1407 State into memory, numbers recorded 37 action = 1, reward = -255
DEBUG:root: save sample needs time = 0.000548839569092
INFO:root:random_action_porb = 0.996694
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1408current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =1410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430822372437
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9966845
DEBUG:root: dqn, choose action rondomly, need time 0.000214
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000191926956177
INFO:root:frame =1413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =1414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:random_action_porb = 0.996675
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =1417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =1418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9966655
DEBUG:root: dqn, choose action rondomly, need time 0.000278
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =1421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =1422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:random_action_porb = 0.996656
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =1425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =1426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430822372437
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9966465
DEBUG:root: dqn, choose action rondomly, need time 0.000347
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000411987304688
INFO:root:frame =1429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =1430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.996637
DEBUG:root: dqn, choose action rondomly, need time 0.000311999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =1433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000429153442383
INFO:root:frame =1434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000418901443481
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9966275
DEBUG:root: dqn, choose action rondomly, need time 0.000223
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000140190124512
INFO:root:frame =1437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =1438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:random_action_porb = 0.996618
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =1441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000474214553833
INFO:root:frame =1442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9966085
DEBUG:root: dqn, choose action rondomly, need time 0.000293000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000405073165894
INFO:root:frame =1445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame =1446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.996599
DEBUG:root: dqn, choose action rondomly, need time 0.000293000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =1449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281810760498
INFO:root:frame =1450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.9965895
DEBUG:root: dqn, choose action rondomly, need time 0.000150999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142812728882
INFO:root:frame =1453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =1454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.99658
DEBUG:root: dqn, choose action rondomly, need time 0.000280999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000337839126587
INFO:root:frame =1457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =1458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9965705
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029182434082
INFO:root:frame =1461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =1462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000123977661133
INFO:root:random_action_porb = 0.996561
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =1465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =1466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9965515
DEBUG:root: dqn, choose action rondomly, need time 0.000306
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =1469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =1470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.996542
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =1474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9965325
DEBUG:root: dqn, choose action rondomly, need time 0.000375999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =1477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =1478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000497102737427
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.996523
DEBUG:root: dqn, choose action rondomly, need time 0.000313
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =1481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488996505737
INFO:root:frame =1482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9965135
DEBUG:root: dqn, choose action rondomly, need time 0.000359
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =1485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000416040420532
INFO:root:frame =1486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:random_action_porb = 0.996504
DEBUG:root: dqn, choose action rondomly, need time 0.000154
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:frame =1489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472784042358
INFO:root:frame =1490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249147415161
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9964945
DEBUG:root: dqn, choose action rondomly, need time 0.000278000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =1493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448226928711
INFO:root:frame =1494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.996485
DEBUG:root: dqn, choose action rondomly, need time 0.000290999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =1497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =1498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9964755
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =1501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =1502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.00013279914856
INFO:root:random_action_porb = 0.996466
DEBUG:root: dqn, choose action rondomly, need time 0.000192999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:frame =1505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:frame =1506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame = 1507 State into memory, numbers recorded 38 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000540971755981
INFO:root:random_action_porb = 0.9964565
DEBUG:root: dqn, choose action rondomly, need time 0.000292
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1508current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =1509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433206558228
INFO:root:frame =1510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.996447
DEBUG:root: dqn, choose action rondomly, need time 0.000280999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =1513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =1514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9964375
DEBUG:root: dqn, choose action rondomly, need time 0.000324000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =1517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000352144241333
INFO:root:frame =1518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.996428
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =1521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446796417236
INFO:root:frame =1522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000280857086182
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.9964185
DEBUG:root: dqn, choose action rondomly, need time 0.000318999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =1525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =1526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.996409
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =1529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame =1530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240087509155
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:random_action_porb = 0.9963995
DEBUG:root: dqn, choose action rondomly, need time 0.000342
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =1533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root:frame =1534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466823577881
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.99639
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00061821937561
INFO:root:frame =1537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000423908233643
INFO:root:frame =1538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.9963805
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =1541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =1542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481128692627
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:random_action_porb = 0.996371
DEBUG:root: dqn, choose action rondomly, need time 0.000200999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000194072723389
INFO:root:frame =1545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000511884689331
INFO:root:frame =1546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.9963615
DEBUG:root: dqn, choose action rondomly, need time 0.000313999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =1549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471115112305
INFO:root:frame =1550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.996352
DEBUG:root: dqn, choose action rondomly, need time 0.000349
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =1553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =1554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470876693726
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.9963425
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =1557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471115112305
INFO:root:frame =1558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00022292137146
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.996333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =1562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444173812866
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:random_action_porb = 0.9963235
DEBUG:root: dqn, choose action rondomly, need time 0.000188999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000145196914673
INFO:root:frame =1565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:frame =1566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482082366943
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.996314
DEBUG:root: dqn, choose action rondomly, need time 0.000326999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =1569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =1570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000107049942017
INFO:root:random_action_porb = 0.9963045
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =1573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =1574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.996295
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =1578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.9962855
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =1581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =1582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:random_action_porb = 0.996276
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =1585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =1586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.9962665
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =1589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =1590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.996257
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:frame =1593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =1594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.9962475
DEBUG:root: dqn, choose action rondomly, need time 0.000316000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =1597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =1598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249147415161
INFO:root: ememy has been killed for 6 times 
INFO:root:enemies_left [0]
INFO:root:frame = 1599 State into memory, numbers recorded 39 action = 0, reward = 255
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:random_action_porb = 0.996238
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1600current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =1601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =1602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.9962285
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =1605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =1606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.996219
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.47088672e+03]
 [  1.44637324e+04]
 [  2.21185730e+02]
 [  3.99586945e+01]
 [  2.21185730e+02]
 [  2.45445142e+03]
 [  1.53906799e+03]
 [  3.86014102e+04]
 [  1.17750269e+03]
 [  5.61006016e+04]
 [  1.77373825e+02]
 [  2.92234473e+03]
 [  2.40419507e+03]
 [  2.31228076e+03]
 [  3.97946582e+03]
 [  2.45445142e+03]]
DEBUG:root:training time = %d0.203765
INFO:root:frame =1609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229120254517
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9962095
DEBUG:root: dqn, choose action rondomly, need time 0.000266
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root:frame =1613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =1614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9962
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.75384844e+04]
 [  1.85991094e+05]
 [  1.98310488e+04]
 [  1.98310488e+04]
 [  2.14720020e+03]
 [  1.78625566e+04]
 [  1.48787812e+05]
 [  1.10986943e+04]
 [  3.77787930e+04]
 [  2.24486133e+04]
 [  1.10986943e+04]
 [  2.43332578e+04]
 [  1.71370935e+03]
 [  9.31894238e+03]
 [  1.82302734e+02]
 [  8.84224316e+03]]
DEBUG:root:training time = %d0.206594
INFO:root:frame =1617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =1618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255823135376
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9961905
DEBUG:root: dqn, choose action rondomly, need time 0.000181999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:frame =1621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =1622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047492980957
DEBUG:root: save sample needs time = 0.000280141830444
INFO:root:random_action_porb = 0.996181
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   5739.54199219]
 [  13913.02636719]
 [   9251.21289062]
 [  44317.39453125]
 [   9885.87402344]
 [   8206.20996094]
 [ 132962.078125  ]
 [   7800.64990234]
 [   9885.87402344]
 [  78192.6640625 ]
 [  10282.73242188]
 [   5965.39404297]
 [  17323.05273438]
 [   7164.36621094]
 [   3186.52807617]
 [  34029.3046875 ]]
DEBUG:root:training time = %d0.196334
INFO:root:frame =1625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =1626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9961715
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =1629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000429153442383
INFO:root:frame =1630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487089157104
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.996162
DEBUG:root: dqn, choose action rondomly, need time 0.000207000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000166177749634
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   452.13336182]
 [  3680.6171875 ]
 [   593.02832031]
 [  5277.18359375]
 [ 38060.09375   ]
 [  4155.40917969]
 [  4155.40917969]
 [  1469.48498535]
 [ 65317.05859375]
 [   185.3230896 ]
 [ 57589.5703125 ]
 [  1090.98278809]
 [ 81246.921875  ]
 [  3511.56787109]
 [ 81246.921875  ]
 [  3033.57958984]]
DEBUG:root:training time = %d0.187549
INFO:root:frame =1633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =1634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame = 1635 State into memory, numbers recorded 40 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000370025634766
INFO:root:random_action_porb = 0.9961525
DEBUG:root: dqn, choose action rondomly, need time 0.000199
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1636current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:frame =1637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =1638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000320911407471
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.996143
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312805175781
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.32763375e+05]
 [  1.79127109e+04]
 [  6.93635625e+04]
 [  9.82923516e+04]
 [  3.30063705e+01]
 [  4.79550117e+04]
 [  3.38976992e+04]
 [  3.38198906e+04]
 [  5.30681406e+04]
 [  3.30063705e+01]
 [  4.79550117e+04]
 [  3.38976992e+04]
 [  4.04559805e+04]
 [  4.16809688e+04]
 [  5.55143086e+04]
 [  3.61984062e+04]]
DEBUG:root:training time = %d0.211508
INFO:root:frame =1641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:frame =1642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235795974731
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:random_action_porb = 0.9961335
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =1645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =1646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000370979309082
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.996124
DEBUG:root: dqn, choose action rondomly, need time 0.00032
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.77257538e+00]
 [  1.14736267e+03]
 [  2.04667740e+02]
 [  1.14736267e+03]
 [  8.36931094e+04]
 [  5.77257538e+00]
 [  6.97294336e+03]
 [  6.14792695e+04]
 [  4.54914570e+04]
 [  2.04667740e+02]
 [  3.34959335e+01]
 [  1.76220862e+03]
 [  1.76220862e+03]
 [  1.42471692e+03]
 [  3.34959335e+01]
 [  1.15458105e+03]]
DEBUG:root:training time = %d0.192136
INFO:root:frame =1649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =1650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000365972518921
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9961145
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =1653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =1654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.996105
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00039005279541
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 37405.03125   ]
 [ 11784.91503906]
 [   591.91705322]
 [  7746.64257812]
 [  1393.38891602]
 [ 56610.65234375]
 [ 10144.53710938]
 [ 10737.86230469]
 [ 37405.03125   ]
 [ 10737.86230469]
 [  3983.20922852]
 [ 38355.828125  ]
 [  4266.95068359]
 [ 99284.3046875 ]
 [ 38355.828125  ]
 [ 10737.86230469]]
DEBUG:root:training time = %d0.197716
INFO:root:frame =1657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =1658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000502824783325
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9960955
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =1661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =1662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:random_action_porb = 0.996086
DEBUG:root: dqn, choose action rondomly, need time 0.00046
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.88118866e+02]
 [  6.72338281e+04]
 [  1.32050928e+04]
 [  3.00187188e+04]
 [  9.92106406e+04]
 [  4.79158203e+03]
 [  2.37102197e+03]
 [  1.74752594e+02]
 [  1.63152649e+03]
 [  1.88118866e+02]
 [  1.15837059e+01]
 [  3.20149268e+03]
 [  2.28582001e+01]
 [  1.15837059e+01]
 [  1.15837059e+01]
 [  2.59605884e+03]]
DEBUG:root:training time = %d0.185463
INFO:root:frame =1665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =1666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9960765
DEBUG:root: dqn, choose action rondomly, need time 0.000311
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =1669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =1670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.996067
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.18361771e+02]
 [  4.35484009e+01]
 [  1.44120732e+04]
 [  5.79365918e+03]
 [  1.54705071e+00]
 [  2.18361771e+02]
 [  1.27653333e+03]
 [  6.67167082e-03]
 [  4.42517609e+02]
 [  2.55891270e+04]
 [  2.08423782e+02]
 [  2.55452344e+04]
 [  8.43502014e+02]
 [  3.14785791e+03]
 [  7.10563782e+02]
 [  2.66869727e+04]]
DEBUG:root:training time = %d0.198519
INFO:root:frame =1673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =1674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470876693726
INFO:root:frame = 1675 State into memory, numbers recorded 41 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000562906265259
INFO:root:random_action_porb = 0.9960575
DEBUG:root: dqn, choose action rondomly, need time 0.000292
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1676current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =1677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =1678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.996048
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.53097916e+01]
 [  1.49641565e+03]
 [  9.57779541e+01]
 [  7.45435791e+03]
 [  2.78120410e+03]
 [  1.26446570e+03]
 [  2.92062759e+00]
 [  2.92752075e+03]
 [  2.53097916e+01]
 [  3.50371655e+03]
 [  4.52563047e+04]
 [  9.89153198e+02]
 [  1.46327441e+04]
 [  1.39264624e+03]
 [  5.37488633e+04]
 [  5.37488633e+04]]
DEBUG:root:training time = %d0.1974
INFO:root:frame =1681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =1682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9960385
DEBUG:root: dqn, choose action rondomly, need time 0.000369000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root:frame =1685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =1686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.996029
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.31969766e+04]
 [  3.32053471e+00]
 [  7.87120361e+03]
 [  1.11209004e+04]
 [  6.55332422e+04]
 [  7.91223999e+02]
 [  6.55332422e+04]
 [  1.04492175e+03]
 [  7.82954636e+01]
 [  5.27556328e+04]
 [  6.55332422e+04]
 [  5.88437109e+03]
 [  2.15251152e+04]
 [  1.11209004e+04]
 [  1.32675262e+02]
 [  1.16367639e+03]]
DEBUG:root:training time = %d0.191991
INFO:root:frame =1689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =1690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275850296021
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9960195
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =1693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000429153442383
INFO:root:frame =1694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277996063232
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.99601
DEBUG:root: dqn, choose action rondomly, need time 0.000503999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.19050586e+03]
 [  3.69454193e+00]
 [  3.74445190e+02]
 [  2.16243164e+03]
 [  2.16243164e+03]
 [  5.59775049e+03]
 [  5.90668799e+03]
 [  6.37416650e+03]
 [  3.69454193e+00]
 [  1.71634316e+04]
 [  3.74445190e+02]
 [  1.15622344e+04]
 [  2.96740996e+04]
 [  3.45997266e+03]
 [  1.83065000e+04]
 [  1.33268311e+04]]
DEBUG:root:training time = %d0.19699
INFO:root:frame =1697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =1698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.9960005
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =1701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000422954559326
INFO:root:frame =1702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:random_action_porb = 0.995991
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.19747656e+03]
 [  2.63349561e+03]
 [  2.19688066e+04]
 [  6.50283447e+02]
 [  6.72464697e+03]
 [  7.93404358e+02]
 [  1.49351025e+04]
 [  5.41291443e+02]
 [  3.07286954e+00]
 [  1.67151641e+04]
 [  1.57421699e+04]
 [  6.39607227e+03]
 [  7.60721302e+00]
 [  1.67151641e+04]
 [  6.19747656e+03]
 [  1.49351025e+04]]
DEBUG:root:training time = %d0.198085
INFO:root:frame =1705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =1706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481128692627
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.9959815
DEBUG:root: dqn, choose action rondomly, need time 0.000311
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =1709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =1710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:random_action_porb = 0.995972
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.73650574e+02]
 [  1.25626196e+03]
 [  6.08797791e+02]
 [  1.47375504e+02]
 [  2.22389624e+03]
 [  4.41407684e+02]
 [  4.67075897e+02]
 [  5.13787256e+03]
 [  7.73650574e+02]
 [  2.57478809e+03]
 [  1.27879227e+05]
 [  7.67696472e+02]
 [  2.85408691e+02]
 [  1.81015869e+03]
 [  7.60783463e+01]
 [  3.84257739e+03]]
DEBUG:root:training time = %d0.198122
INFO:root:frame =1713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248193740845
INFO:root:frame =1714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9959625
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =1717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =1718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000243186950684
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.995953
DEBUG:root: dqn, choose action rondomly, need time 0.000156
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.56148779e+03]
 [  2.54963665e+01]
 [  8.71013641e+00]
 [  3.64636564e+00]
 [  6.38806030e+02]
 [  4.40915381e+03]
 [  5.41709557e+01]
 [  3.82292651e+03]
 [  4.24197731e+01]
 [  1.30286292e+03]
 [  1.48296680e+03]
 [  9.94564247e+00]
 [  3.12794566e-01]
 [  1.82707727e+03]
 [  9.02913761e+00]
 [  3.12794566e-01]]
DEBUG:root:training time = %d0.211385
INFO:root:frame =1721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:frame =1722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000261068344116
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9959435
DEBUG:root: dqn, choose action rondomly, need time 0.000316
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =1725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449180603027
INFO:root:frame =1726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:player has been killed for 5 times 
INFO:root:frame =1728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.50037079e+02]
 [  1.04395596e+04]
 [  3.35123047e+02]
 [  3.59996641e+04]
 [  2.11844254e+02]
 [  4.58063087e+01]
 [  1.88122644e+03]
 [  1.21842402e+04]
 [  4.50484039e+02]
 [  4.24912384e+02]
 [  1.60783760e+04]
 [  5.73585977e+04]
 [  4.78912231e+02]
 [  6.45372070e+02]
 [  6.58875977e+02]
 [  4.50484039e+02]]
DEBUG:root:training time = %d0.201452
INFO:root:frame =1729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =1730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame = 1731 State into memory, numbers recorded 42 action = 0, reward = -255
DEBUG:root: save sample needs time = 0.000539064407349
INFO:root:random_action_porb = 0.995934
DEBUG:root: dqn, choose action rondomly, need time 0.000280999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1732current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =1733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =1734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486135482788
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9959245
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  997.96063232]
 [  654.01568604]
 [ 2093.50366211]
 [  573.83117676]
 [    8.3684206 ]
 [  615.54205322]
 [ 7982.46923828]
 [  615.54205322]
 [ 6447.65673828]
 [   67.1001358 ]
 [ 6499.66210938]
 [   67.1001358 ]
 [  121.3897171 ]
 [ 3999.75952148]
 [    8.66156769]
 [ 7343.35205078]]
DEBUG:root:training time = %d0.209509
INFO:root:frame =1737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224828720093
INFO:root:frame =1738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000224828720093
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.995915
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =1741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000485897064209
INFO:root:frame =1742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000152111053467
INFO:root:random_action_porb = 0.9959055
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.03225517e-01]
 [  1.21716828e+05]
 [  4.58324219e+02]
 [  1.28072156e+03]
 [  2.38041351e+02]
 [  1.22348094e+05]
 [  1.26877539e+03]
 [  1.21402734e+03]
 [  7.80616455e+02]
 [  1.13290344e+03]
 [  1.22348094e+05]
 [  3.12765210e+03]
 [  2.19316147e+02]
 [  2.38041351e+02]
 [  6.91156201e+03]
 [  4.15590479e+03]]
DEBUG:root:training time = %d0.184034
INFO:root:frame =1745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:frame =1746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233888626099
DEBUG:root: save sample needs time = 9.51290130615e-05
INFO:root:random_action_porb = 0.995896
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:frame =1749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:frame =1750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000375986099243
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.9958865
DEBUG:root: dqn, choose action rondomly, need time 0.000292
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.74974121e+02]
 [  2.88946953e+01]
 [  3.61574316e+03]
 [  1.25560486e+02]
 [  5.10525312e+04]
 [  3.19402026e+03]
 [  7.83426941e+02]
 [  1.25560486e+02]
 [  2.70933154e+03]
 [  4.31252060e+01]
 [  5.74974121e+02]
 [  6.58356140e+02]
 [  6.29756396e+03]
 [  1.83903574e+04]
 [  1.25560486e+02]
 [  9.39431030e+02]]
DEBUG:root:training time = %d0.182998
INFO:root:frame =1753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =1754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248908996582
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.995877
DEBUG:root: dqn, choose action rondomly, need time 0.000290999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =1757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =1758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9958675
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.84626038e+03]
 [  3.05377881e+03]
 [  2.37605194e+02]
 [  2.59886217e+00]
 [  5.81152881e+03]
 [  1.61848086e+04]
 [  1.95477368e+03]
 [  1.16365615e+04]
 [  2.96781226e+03]
 [  1.72406592e+03]
 [  1.95477368e+03]
 [  1.61848086e+04]
 [  5.81152881e+03]
 [  5.99507275e+03]
 [  1.84626038e+03]
 [  1.48905350e+02]]
DEBUG:root:training time = %d0.194463
INFO:root:frame =1761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =1762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.995858
DEBUG:root: dqn, choose action rondomly, need time 0.000268
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =1765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =1766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9958485
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.10209990e+01]
 [  2.09972285e+04]
 [  1.82483633e+04]
 [  5.94986328e+04]
 [  6.06688261e+00]
 [  1.41123718e+03]
 [  1.67435632e+03]
 [  6.69838623e+02]
 [  3.44749219e+04]
 [  2.95821533e+02]
 [  1.34442920e+03]
 [  6.69838623e+02]
 [  2.31138730e+00]
 [  7.38323441e+01]
 [  1.93321609e+01]
 [  1.67435632e+03]]
DEBUG:root:training time = %d0.197545
INFO:root:frame =1769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =1770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233173370361
DEBUG:root: save sample needs time = 0.000105142593384
INFO:root:random_action_porb = 0.995839
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =1773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =1774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:random_action_porb = 0.9958295
DEBUG:root: dqn, choose action rondomly, need time 0.000313999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.17860317e+00]
 [  5.02767029e+01]
 [  6.17860317e+00]
 [  1.29235706e+03]
 [  6.17860317e+00]
 [  2.65757629e+02]
 [  1.34063095e+02]
 [  3.28872566e+01]
 [  5.98627197e+03]
 [  1.92214941e+04]
 [  1.73055840e+04]
 [  2.28773848e+04]
 [  5.77542053e+02]
 [  2.64170746e+02]
 [  4.15521631e+03]
 [  1.32493668e+02]]
DEBUG:root:training time = %d0.209426
INFO:root:frame =1777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =1778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.99582
DEBUG:root: dqn, choose action rondomly, need time 0.000325999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =1781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =1782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476121902466
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9958105
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   94.89059448]
 [ 6323.06445312]
 [  666.78466797]
 [ 2887.96362305]
 [    6.979671  ]
 [   24.58244705]
 [    6.979671  ]
 [ 2251.88305664]
 [  994.83569336]
 [ 1410.75109863]
 [  117.75640869]
 [  330.16159058]
 [  217.01548767]
 [ 1891.33813477]
 [  217.01548767]
 [ 2887.96362305]]
DEBUG:root:training time = %d0.204323
INFO:root:frame =1785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =1786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.995801
DEBUG:root: dqn, choose action rondomly, need time 0.000352000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =1790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.9957915
DEBUG:root: dqn, choose action rondomly, need time 0.000501
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   30.20285416]
 [  262.33758545]
 [  899.78027344]
 [   96.13189697]
 [  698.63482666]
 [ 6660.58837891]
 [ 7321.22363281]
 [ 2224.89501953]
 [ 3816.13110352]
 [ 2352.57568359]
 [ 7321.22363281]
 [ 6660.58837891]
 [ 6660.58837891]
 [ 2352.57568359]
 [   19.38815498]
 [  348.68450928]]
DEBUG:root:training time = %d0.204574
INFO:root:frame =1793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:frame =1794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000258207321167
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:random_action_porb = 0.995782
DEBUG:root: dqn, choose action rondomly, need time 0.000268999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame =1797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =1798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.9957725
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.26954944e+03]
 [  7.40468323e+02]
 [  3.74740273e+04]
 [  6.48563965e+02]
 [  1.03472754e+04]
 [  5.04649994e+02]
 [  1.07746143e+03]
 [  2.93878448e+02]
 [  1.26954944e+03]
 [  3.74740273e+04]
 [  7.40468323e+02]
 [  1.14056374e+02]
 [  1.79459583e+03]
 [  3.17478047e+04]
 [  3.50151300e-01]
 [  6.11206726e+02]]
DEBUG:root:training time = %d0.193412
INFO:root:frame =1801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =1802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423192977905
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.995763
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =1805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000424861907959
INFO:root:frame =1806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.9957535
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.58442285e+03]
 [  2.77342944e+03]
 [  3.71190987e+01]
 [  1.15097107e+03]
 [  2.91896631e+03]
 [  2.20234985e+03]
 [  1.44444916e+02]
 [  5.09413483e+02]
 [  1.85691772e+02]
 [  9.69851660e+03]
 [  9.70744228e+00]
 [  1.85691772e+02]
 [  3.71190987e+01]
 [  2.89245645e+04]
 [  1.99167480e+02]
 [  5.37565369e+02]]
DEBUG:root:training time = %d0.191563
INFO:root:frame =1809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =1810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.995744
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =1813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454187393188
INFO:root:frame =1814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame = 1815 State into memory, numbers recorded 43 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000555992126465
INFO:root:random_action_porb = 0.9957345
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1816current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 20685.296875  ]
 [   364.06744385]
 [  3637.41455078]
 [ 20685.296875  ]
 [   763.45428467]
 [  3637.41455078]
 [    77.10016632]
 [    77.10016632]
 [   763.45428467]
 [  1413.59863281]
 [  1087.60266113]
 [ 60940.34765625]
 [  1413.59863281]
 [    71.96209717]
 [ 20685.296875  ]
 [    71.96209717]]
DEBUG:root:training time = %d0.209972
INFO:root:frame =1817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:frame =1818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.995725
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =1821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454187393188
INFO:root:frame =1822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9957155
DEBUG:root: dqn, choose action rondomly, need time 0.000185999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5671.0546875 ]
 [  1485.90270996]
 [   411.30435181]
 [  2128.17456055]
 [  2120.19873047]
 [ 31882.46289062]
 [    43.16311646]
 [  1273.95214844]
 [  3247.37207031]
 [   441.52822876]
 [  2128.17456055]
 [   490.55767822]
 [  3443.64697266]
 [   490.55767822]
 [    58.75422668]
 [   205.81954956]]
DEBUG:root:training time = %d0.188445
INFO:root:frame =1825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =1826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.995706
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =1829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449180603027
INFO:root:frame =1830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9956965
DEBUG:root: dqn, choose action rondomly, need time 0.000280999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5295.88427734]
 [  5667.65234375]
 [   747.91430664]
 [ 15025.72558594]
 [  2451.45874023]
 [ 15025.72558594]
 [   585.76763916]
 [ 11692.49414062]
 [    89.93484497]
 [ 15025.72558594]
 [  7394.57226562]
 [  5667.65234375]
 [  7026.31542969]
 [   260.40945435]
 [ 12116.38769531]
 [  1685.3170166 ]]
DEBUG:root:training time = %d0.190474
INFO:root:frame =1833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =1834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame = 1835 State into memory, numbers recorded 44 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000584125518799
INFO:root:random_action_porb = 0.995687
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1836current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =1837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =1838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000503063201904
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:random_action_porb = 0.9956775
DEBUG:root: dqn, choose action rondomly, need time 0.000332
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.00247375e+02]
 [  1.24118166e+01]
 [  1.30605527e+04]
 [  2.47112686e+02]
 [  5.67914605e-01]
 [  9.75077930e+03]
 [  5.03206445e+04]
 [  5.67127578e+04]
 [  5.35910840e+03]
 [  2.44250357e-01]
 [  3.37425327e+00]
 [  8.09141650e+03]
 [  6.47568652e+03]
 [  2.47112686e+02]
 [  5.35910840e+03]
 [  1.54911951e+03]]
DEBUG:root:training time = %d0.201969
INFO:root:frame =1841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000209808349609
INFO:root:frame =1842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.995668
DEBUG:root: dqn, choose action rondomly, need time 0.000219000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180959701538
INFO:root:frame =1845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000498056411743
INFO:root:frame =1846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9956585
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.52920532e+02]
 [  2.74770264e+03]
 [  2.27043633e+04]
 [  1.09706172e+04]
 [  1.05381805e+02]
 [  2.86488271e+00]
 [  1.36040723e+04]
 [  9.33681030e+02]
 [  4.57434177e+00]
 [  2.10131424e+02]
 [  6.94628750e+04]
 [  1.36167344e+04]
 [  2.34478958e+02]
 [  5.59967995e+01]
 [  5.26313242e+04]
 [  1.51599350e+02]]
DEBUG:root:training time = %d0.197566
INFO:root:frame =1849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =1850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000220060348511
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.995649
DEBUG:root: dqn, choose action rondomly, need time 0.000157999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000130176544189
INFO:root:frame =1853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249147415161
INFO:root:frame =1854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
DEBUG:root: save sample needs time = 0.000110149383545
INFO:root:random_action_porb = 0.9956395
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.43482971e+02]
 [  6.84407109e+04]
 [  2.43173608e+03]
 [  4.63914795e+02]
 [  9.77050842e+02]
 [  2.35020044e+03]
 [  1.63697607e+04]
 [  2.35020044e+03]
 [  8.30429395e+03]
 [  3.35594775e+03]
 [  2.59174146e+03]
 [  1.84450851e+02]
 [  5.00916443e+01]
 [  1.84450851e+02]
 [  8.43482971e+02]
 [  3.42841553e+03]]
DEBUG:root:training time = %d0.194574
INFO:root:frame =1857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =1858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000287055969238
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.99563
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =1861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042986869812
INFO:root:frame =1862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.9956205
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332832336426
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4900.73486328]
 [  1930.74389648]
 [  3204.60742188]
 [  3064.94335938]
 [ 19212.35546875]
 [  1461.9765625 ]
 [   439.20513916]
 [   439.20513916]
 [    43.41474152]
 [ 23469.70117188]
 [    43.41474152]
 [   156.08029175]
 [   379.70269775]
 [  2809.35742188]
 [  1930.74389648]
 [   994.0982666 ]]
DEBUG:root:training time = %d0.207381
INFO:root:frame =1865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =1866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308990478516
DEBUG:root: save sample needs time = 0.000104188919067
INFO:root:random_action_porb = 0.995611
DEBUG:root: dqn, choose action rondomly, need time 0.000167000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:frame =1869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =1870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453233718872
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9956015
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[    7.4990201 ]
 [ 1579.58947754]
 [   18.2007637 ]
 [  131.38465881]
 [  416.61871338]
 [ 1189.30578613]
 [  131.38465881]
 [  303.5451355 ]
 [ 1000.33172607]
 [ 1579.58947754]
 [  220.98153687]
 [  202.16374207]
 [  303.5451355 ]
 [   18.2007637 ]
 [ 1971.75109863]
 [ 4085.85888672]]
DEBUG:root:training time = %d0.204537
INFO:root:frame =1873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =1874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.995592
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000493049621582
INFO:root:frame =1878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:random_action_porb = 0.9955825
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.98621063e+01]
 [  3.52456848e+02]
 [  7.20113464e+02]
 [  2.57914710e+00]
 [  3.56349030e+01]
 [  2.07532275e+03]
 [  9.09840234e+03]
 [  1.43012561e+03]
 [  5.20352554e+01]
 [  2.29217972e+02]
 [  4.86722260e+02]
 [  3.24978516e+02]
 [  1.28180523e+01]
 [  3.65697937e+02]
 [  2.57914710e+00]
 [  5.74089966e+02]]
DEBUG:root:training time = %d0.194798
INFO:root:frame =1881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame =1882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.995573
DEBUG:root: dqn, choose action rondomly, need time 0.000313999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =1885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427961349487
INFO:root:frame =1886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441789627075
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.9955635
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.64586121e+02]
 [  7.64365158e+01]
 [  2.23026800e+00]
 [  4.64586121e+02]
 [  4.80451047e-01]
 [  2.13721954e+02]
 [  1.30855913e+01]
 [  3.26621127e+00]
 [  3.26621127e+00]
 [  2.17529190e+02]
 [  2.62452965e+01]
 [  2.13721954e+02]
 [  2.58813843e+02]
 [  8.96800000e+03]
 [  2.58813843e+02]
 [  8.96800000e+03]]
DEBUG:root:training time = %d0.201157
INFO:root:frame =1889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =1890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476121902466
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.995554
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =1893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =1894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000498056411743
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.9955445
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.29438330e+03]
 [  9.40771389e+00]
 [  9.43420231e-01]
 [  1.29438330e+03]
 [  1.63968623e+00]
 [  1.78877905e+03]
 [  1.29438330e+03]
 [  3.96565033e+02]
 [  2.48528717e+02]
 [  9.30715918e+03]
 [  1.13907705e+04]
 [  7.73217773e+02]
 [  7.72293472e+01]
 [  1.29438330e+03]
 [  1.12629595e+01]
 [  7.73217773e+02]]
DEBUG:root:training time = %d0.182998
INFO:root:frame =1897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =1898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000256061553955
DEBUG:root: save sample needs time = 0.000111103057861
INFO:root:random_action_porb = 0.995535
DEBUG:root: dqn, choose action rondomly, need time 0.000167000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000158071517944
INFO:root:frame =1901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438213348389
INFO:root:frame =1902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:random_action_porb = 0.9955255
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.93073389e+03]
 [  6.75455928e-01]
 [  1.71800480e+01]
 [  4.66177393e+03]
 [  9.62345764e+02]
 [  3.26946094e+03]
 [  1.06030249e+03]
 [  8.13183670e+01]
 [  3.84621024e-01]
 [  1.42744067e+03]
 [  6.19376416e+03]
 [  1.14118309e+02]
 [  5.01216766e+02]
 [  6.69703552e+02]
 [  1.85903528e+03]
 [  1.93073389e+03]]
DEBUG:root:training time = %d0.214052
INFO:root:frame =1905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =1906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000332117080688
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root:random_action_porb = 0.995516
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =1909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame =1910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.9955065
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.00611296e+01]
 [  1.04147667e+02]
 [  4.23562109e+03]
 [  2.01207066e+01]
 [  6.41963633e+04]
 [  5.69646045e+03]
 [  9.65626526e+01]
 [  5.03863287e+00]
 [  1.37789398e+02]
 [  9.65626526e+01]
 [  4.58457680e+01]
 [  2.33383594e+03]
 [  2.97998096e+03]
 [  2.97998096e+03]
 [  5.03863287e+00]
 [  5.45284538e+01]]
DEBUG:root:training time = %d0.196442
INFO:root:frame =1913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000196218490601
INFO:root:frame =1914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.995497
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =1917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =1918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000296115875244
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.9954875
DEBUG:root: dqn, choose action rondomly, need time 0.000293000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.09212585e+02]
 [  1.13387779e+02]
 [  5.74399231e+02]
 [  2.75417041e+03]
 [  2.74751258e+00]
 [  1.25661487e+03]
 [  3.34852070e+04]
 [  2.75417041e+03]
 [  4.73056610e+02]
 [  2.06854272e+03]
 [  5.91758643e+03]
 [  6.86121460e+02]
 [  3.88082062e+02]
 [  1.78503857e+01]
 [  1.81949677e+02]
 [  8.22684250e+01]]
DEBUG:root:training time = %d0.197346
INFO:root:frame =1921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =1922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.995478
DEBUG:root: dqn, choose action rondomly, need time 0.000164000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000134944915771
INFO:root:frame =1925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =1926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248193740845
DEBUG:root: save sample needs time = 9.41753387451e-05
INFO:root:random_action_porb = 0.9954685
DEBUG:root: dqn, choose action rondomly, need time 0.000181999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000192880630493
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.58681946e+01]
 [  2.72387482e+02]
 [  1.14775647e+03]
 [  1.57498264e+01]
 [  2.72387482e+02]
 [  4.62104805e+04]
 [  2.37561938e+03]
 [  3.97501245e+03]
 [  4.71635475e+01]
 [  1.85262427e+03]
 [  5.69916931e+02]
 [  3.59118423e+01]
 [  2.26551071e+02]
 [  1.30999927e+03]
 [  1.99754500e+00]
 [  5.11650146e+03]]
DEBUG:root:training time = %d0.201984
INFO:root:frame =1929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =1930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:random_action_porb = 0.995459
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =1933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000416994094849
INFO:root:frame =1934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:random_action_porb = 0.9954495
DEBUG:root: dqn, choose action rondomly, need time 0.000329999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.91061406e+04]
 [  1.07812158e+03]
 [  1.02951920e+02]
 [  5.93019371e+01]
 [  4.64230461e+01]
 [  4.70948792e+00]
 [  1.71391754e+02]
 [  3.82245674e+01]
 [  2.05203568e+02]
 [  4.76690887e+02]
 [  5.49690125e+02]
 [  1.77321106e+03]
 [  5.57685509e+01]
 [  3.19307227e+04]
 [  3.19307227e+04]
 [  5.96120834e+01]]
DEBUG:root:training time = %d0.196757
INFO:root:frame =1937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =1938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288963317871
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.99544
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =1941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000475168228149
INFO:root:frame =1942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000240802764893
INFO:root:random_action_porb = 0.9954305
DEBUG:root: dqn, choose action rondomly, need time 0.000271000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.05140918e+03]
 [  2.14460516e+00]
 [  1.67170691e+03]
 [  3.90347046e+02]
 [  1.35188403e+03]
 [  1.68635803e+02]
 [  3.51471167e+03]
 [  3.62709625e+02]
 [  1.69746641e+04]
 [  2.14460516e+00]
 [  8.37438965e+02]
 [  1.19951260e+04]
 [  3.90347046e+02]
 [  1.11602676e+02]
 [  9.70558777e+01]
 [  1.35188403e+03]]
DEBUG:root:training time = %d0.192992
INFO:root:frame =1945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =1946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00048303604126
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.995421
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =1949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000545024871826
INFO:root:frame =1950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000295877456665
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.9954115
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.61741791e+01]
 [  2.72874316e+03]
 [  2.84914734e+02]
 [  5.20368408e+02]
 [  2.27319629e+03]
 [  4.20895863e+00]
 [  7.87662354e+02]
 [  1.40949059e+01]
 [  5.20368408e+02]
 [  1.50719116e+02]
 [  1.17124561e+03]
 [  1.09911973e+04]
 [  8.30688867e+03]
 [  1.57528784e+03]
 [  6.60722217e+03]
 [  1.08547900e+04]]
DEBUG:root:training time = %d0.189658
INFO:root:frame =1953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:frame =1954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000417947769165
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.995402
DEBUG:root: dqn, choose action rondomly, need time 0.000321
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00044584274292
INFO:root:frame =1958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame = 1959 State into memory, numbers recorded 45 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000586986541748
INFO:root:random_action_porb = 0.9953925
INFO:root:dqn select action Tensor("ArgMax:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015152
INFO:root:action choosen by dqn [1]
INFO:root:frame =1960current_observation done, NOT record action [1], reward = 0
DEBUG:root: save sample needs time = 0.000988006591797
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.00781140e+03]
 [  1.69060936e+01]
 [  1.31867386e+02]
 [  4.60419570e+04]
 [  7.09783264e+02]
 [  7.23220581e+02]
 [  5.26417389e+01]
 [  4.62338593e+02]
 [  1.52599341e+03]
 [  3.35191484e+04]
 [  2.52175879e+03]
 [  1.01455698e+01]
 [  1.03462561e+03]
 [  4.85704102e+03]
 [  5.11180687e+00]
 [  4.35102637e+03]]
DEBUG:root:training time = %d0.21377
INFO:root:frame =1961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =1962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000403881072998
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:random_action_porb = 0.995383
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =1965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame =1966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9953735
DEBUG:root: dqn, choose action rondomly, need time 0.000268999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.02422034e+03]
 [  3.28615479e+02]
 [  9.23079758e+01]
 [  6.84158997e+02]
 [  9.70160522e+02]
 [  6.49416443e+02]
 [  1.05633516e+04]
 [  6.49416443e+02]
 [  6.49416443e+02]
 [  6.62782211e+01]
 [  2.21567173e+01]
 [  1.96323328e+03]
 [  7.39154935e-01]
 [  3.19008808e+01]
 [  6.84158997e+02]
 [  1.70255591e+03]]
DEBUG:root:training time = %d0.187523
INFO:root:frame =1969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =1970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249862670898
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.995364
DEBUG:root: dqn, choose action rondomly, need time 0.000156
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:frame =1973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000476837158203
INFO:root:frame =1974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486850738525
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.9953545
DEBUG:root: dqn, choose action rondomly, need time 0.000361000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.01527368e+03]
 [  2.76052952e+01]
 [  9.34526520e+01]
 [  1.01527368e+03]
 [  3.03155914e+02]
 [  1.25883331e+01]
 [  1.20575720e+03]
 [  2.18829842e+01]
 [  5.52846094e+03]
 [  5.37578064e+02]
 [  6.10719788e+02]
 [  3.10569458e+03]
 [  2.50994482e+03]
 [  2.50994482e+03]
 [  1.19597229e+03]
 [  2.79200363e+00]]
DEBUG:root:training time = %d0.210989
INFO:root:frame =1977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =1978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:frame = 1979 State into memory, numbers recorded 46 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:random_action_porb = 0.995345
DEBUG:root: dqn, choose action rondomly, need time 0.000208000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1980current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =1981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000415086746216
INFO:root:frame =1982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.9953355
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4626.96777344]
 [  154.1182251 ]
 [ 1421.21154785]
 [   30.25461578]
 [  118.55196381]
 [ 8974.26953125]
 [  677.76483154]
 [  101.44192505]
 [ 6168.41552734]
 [  905.89093018]
 [  677.76483154]
 [ 7779.86132812]
 [  810.44744873]
 [ 7779.86132812]
 [   65.16116333]
 [  856.9619751 ]]
DEBUG:root:training time = %d0.189659
INFO:root:frame =1985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253200531006
INFO:root:frame =1986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:frame = 1987 State into memory, numbers recorded 47 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:random_action_porb = 0.995326
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1988current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =1989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =1990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame = 1991 State into memory, numbers recorded 48 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:random_action_porb = 0.9953165
DEBUG:root: dqn, choose action rondomly, need time 0.000168000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1992current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.81201813e+02]
 [  2.73717725e+03]
 [  1.36011560e+03]
 [  3.31535980e+02]
 [  3.31535980e+02]
 [  6.53362503e+01]
 [  2.26367798e+03]
 [  3.38880493e+02]
 [  1.78435889e+03]
 [  8.55040741e+01]
 [  2.03522668e+03]
 [  1.05697197e+02]
 [  5.72889404e+02]
 [  2.86695251e+01]
 [  2.99378931e+03]
 [  2.63363719e+00]]
DEBUG:root:training time = %d0.211093
INFO:root:frame =1993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =1994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233173370361
DEBUG:root: save sample needs time = 9.29832458496e-05
INFO:root:random_action_porb = 0.995307
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =1997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =1998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235080718994
DEBUG:root: save sample needs time = 0.000204801559448
DEBUG:root:one frame running time = 0.006624
DEBUG:root:total training time = 21.502143
INFO:root:frame num = 2000 frame round: 0
INFO:root:random_action_porb = 0.9952975
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.53089385e+04]
 [  3.82378882e+03]
 [  1.87901947e+02]
 [  1.69748631e+01]
 [  1.47584534e+00]
 [  3.15939545e+02]
 [  1.51939023e+00]
 [  1.04827600e+03]
 [  1.51939023e+00]
 [  6.18249512e+02]
 [  2.34980542e+03]
 [  2.61294186e-01]
 [  1.16377533e+02]
 [  1.89651688e+02]
 [  1.53075302e+02]
 [  1.18387878e+03]]
DEBUG:root:training time = %d0.203507
INFO:root:frame =2001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:frame =2002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
DEBUG:root: save sample needs time = 9.29832458496e-05
INFO:root:random_action_porb = 0.995288
DEBUG:root: dqn, choose action rondomly, need time 0.000167999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:frame =2005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =2006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.9952785
DEBUG:root: dqn, choose action rondomly, need time 0.000264999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000358104705811
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.04632471e+03]
 [  1.23388574e+03]
 [  8.04632471e+03]
 [  3.65555649e+01]
 [  2.46001221e+03]
 [  3.08109741e+02]
 [  8.30313187e+01]
 [  1.10182076e+02]
 [  1.77229568e+02]
 [  1.78078555e+04]
 [  3.04132153e+03]
 [  1.64911743e+02]
 [  2.06651154e+02]
 [  2.13131641e+03]
 [  1.78078555e+04]
 [  1.67291927e+01]]
DEBUG:root:training time = %d0.192335
INFO:root:frame =2009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =2010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423192977905
DEBUG:root: save sample needs time = 0.000160217285156
INFO:root:random_action_porb = 0.995269
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =2013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =2014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame = 2015 State into memory, numbers recorded 49 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000592947006226
INFO:root:random_action_porb = 0.9952595
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2016current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1026.80664062]
 [   289.67068481]
 [  1026.80664062]
 [  1405.27514648]
 [  3731.6484375 ]
 [  1553.80871582]
 [  1705.54284668]
 [  8083.74267578]
 [ 33187.83203125]
 [   692.50823975]
 [  1006.0345459 ]
 [   289.67068481]
 [   555.77832031]
 [  5197.90478516]
 [  2146.98510742]
 [  3293.08129883]]
DEBUG:root:training time = %d0.212532
INFO:root:frame =2017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255823135376
INFO:root:frame =2018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000110864639282
INFO:root:random_action_porb = 0.99525
DEBUG:root: dqn, choose action rondomly, need time 0.000171999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root:frame =2021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =2022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.9952405
DEBUG:root: dqn, choose action rondomly, need time 0.000274999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.06041797e+03]
 [  7.36604309e+01]
 [  2.18644458e+03]
 [  1.44016113e+03]
 [  2.04401465e+04]
 [  1.65539697e+03]
 [  8.87500954e+00]
 [  1.15835430e+04]
 [  1.65539697e+03]
 [  7.36604309e+01]
 [  6.51611755e+02]
 [  8.99761536e+02]
 [  2.12596488e+00]
 [  1.73169235e+02]
 [  7.78853027e+02]
 [  2.18644458e+03]]
DEBUG:root:training time = %d0.203387
INFO:root:frame =2025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =2026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000350952148438
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.995231
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =2029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =2030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:random_action_porb = 0.9952215
DEBUG:root: dqn, choose action rondomly, need time 0.000333999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.12031746e+01]
 [  5.16842880e+01]
 [  9.20419067e+02]
 [  1.73911023e+03]
 [  7.89165771e+02]
 [  1.56124829e+03]
 [  7.33549561e+03]
 [  2.81795084e-01]
 [  9.55832812e+03]
 [  4.30156067e+02]
 [  5.16842880e+01]
 [  3.16653320e+03]
 [  5.16842880e+01]
 [  3.42794604e+03]
 [  3.42794604e+03]
 [  9.38240051e+01]]
DEBUG:root:training time = %d0.197851
INFO:root:frame =2033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =2034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025486946106
DEBUG:root: save sample needs time = 0.000111103057861
INFO:root:random_action_porb = 0.995212
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =2037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =2038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:random_action_porb = 0.9952025
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  262.37533569]
 [  195.58366394]
 [  639.14855957]
 [ 4204.55859375]
 [ 1532.79968262]
 [ 1610.62915039]
 [ 1610.62915039]
 [ 1271.71960449]
 [   21.51952362]
 [   21.51952362]
 [ 1153.51806641]
 [   21.51952362]
 [  262.37533569]
 [ 1271.71960449]
 [  735.96844482]
 [ 1538.42907715]]
DEBUG:root:training time = %d0.204754
INFO:root:frame =2041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000428915023804
INFO:root:frame =2042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000524044036865
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.995193
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =2045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000419139862061
INFO:root:frame =2046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000417947769165
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.9951835
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6815.45019531]
 [   580.81231689]
 [   146.52033997]
 [   488.60552979]
 [   372.73443604]
 [    72.00675964]
 [   481.34622192]
 [    69.66146088]
 [   924.03436279]
 [ 35681.234375  ]
 [   146.52033997]
 [  5519.78759766]
 [   423.40774536]
 [   887.29003906]
 [   393.00933838]
 [    72.00675964]]
DEBUG:root:training time = %d0.19758
INFO:root:frame =2049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =2050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame = 2051 State into memory, numbers recorded 50 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000559091567993
INFO:root:random_action_porb = 0.995174
DEBUG:root: dqn, choose action rondomly, need time 0.000167000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2052current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root:frame =2053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449180603027
INFO:root:frame =2054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.9951645
DEBUG:root: dqn, choose action rondomly, need time 0.000291999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.80438013e+03]
 [  5.78598193e+03]
 [  2.87051904e+03]
 [  1.33796814e+03]
 [  6.68259888e+02]
 [  6.14827441e+03]
 [  2.30229224e+03]
 [  5.85437695e+03]
 [  6.14827441e+03]
 [  1.32076508e+02]
 [  4.82733002e+01]
 [  4.76501416e+03]
 [  1.44404619e+04]
 [  5.78598193e+03]
 [  4.06563568e+00]
 [  6.10302441e+03]]
DEBUG:root:training time = %d0.200415
INFO:root:frame =2057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =2058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.995155
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =2061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =2062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root:random_action_porb = 0.9951455
DEBUG:root: dqn, choose action rondomly, need time 0.000316000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  182.40586853]
 [  161.59896851]
 [  267.62515259]
 [ 6662.28417969]
 [ 1317.95385742]
 [ 6491.39208984]
 [   62.94384766]
 [  182.40586853]
 [  143.69374084]
 [  463.30465698]
 [ 2729.78198242]
 [ 3186.87963867]
 [  182.40586853]
 [ 2232.97412109]
 [  130.56765747]
 [ 1317.95385742]]
DEBUG:root:training time = %d0.203819
INFO:root:frame =2065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:frame =2066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame = 2067 State into memory, numbers recorded 51 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000541925430298
INFO:root:random_action_porb = 0.995136
DEBUG:root: dqn, choose action rondomly, need time 0.000280999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2068current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000312805175781
INFO:root:frame =2069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =2070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9951265
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.31644604e+03]
 [  2.09573770e+04]
 [  8.39085938e+02]
 [  4.66508301e+03]
 [  5.97662842e+02]
 [  4.01045239e+03]
 [  1.43390771e+03]
 [  3.15103320e+03]
 [  3.44808912e+00]
 [  4.66508301e+03]
 [  6.94309937e+02]
 [  2.09573770e+04]
 [  5.87804993e+02]
 [  2.39680859e+04]
 [  1.59669312e+02]
 [  8.39085938e+02]]
DEBUG:root:training time = %d0.197144
INFO:root:frame =2073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =2074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000284910202026
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:random_action_porb = 0.995117
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =2077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =2078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00048303604126
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.9951075
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 15479.08691406]
 [  1559.78894043]
 [  3376.09301758]
 [  1092.62243652]
 [   394.11965942]
 [  5271.98388672]
 [   636.21936035]
 [  1477.05908203]
 [  1772.90393066]
 [   292.28707886]
 [ 20475.68164062]
 [  1896.47521973]
 [   522.95782471]
 [   398.92773438]
 [  1092.62243652]
 [   741.28900146]]
DEBUG:root:training time = %d0.201418
INFO:root:frame =2081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:frame =2082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227928161621
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.995098
DEBUG:root: dqn, choose action rondomly, need time 0.000208000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000137805938721
INFO:root:frame =2085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000503063201904
INFO:root:frame =2086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.9950885
DEBUG:root: dqn, choose action rondomly, need time 0.000325
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.24089038e+03]
 [  1.72020398e+03]
 [  1.25137769e+03]
 [  1.85251196e+03]
 [  4.56434453e+04]
 [  5.68867920e+02]
 [  1.72020398e+03]
 [  3.52370215e+03]
 [  1.85251196e+03]
 [  6.19706917e+01]
 [  2.02069836e+03]
 [  1.82792263e+01]
 [  1.30654626e+03]
 [  1.96135895e+02]
 [  1.67247754e+03]
 [  1.25137769e+03]]
DEBUG:root:training time = %d0.186707
INFO:root:frame =2089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =2090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.000217199325562
INFO:root:random_action_porb = 0.995079
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =2093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =2094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000103950500488
INFO:root:random_action_porb = 0.9950695
DEBUG:root: dqn, choose action rondomly, need time 0.000188999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00018310546875
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.16176379e+03]
 [  3.88546655e+03]
 [  4.03833716e+03]
 [  1.71675566e+04]
 [  3.30562891e+03]
 [  4.03833716e+03]
 [  2.21026807e+03]
 [  1.66725476e+03]
 [  1.50515966e+01]
 [  1.29702545e+02]
 [  8.30696594e+02]
 [  1.50515966e+01]
 [  6.87394257e+01]
 [  1.85056458e+03]
 [  1.71452520e+04]
 [  1.17240198e+03]]
DEBUG:root:training time = %d0.192
INFO:root:frame =2097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:frame =2098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.99506
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =2101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =2102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.9950505
DEBUG:root: dqn, choose action rondomly, need time 0.000634000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.70569539e+00]
 [  1.14857582e+02]
 [  7.27793762e+02]
 [  5.57227516e+01]
 [  8.35100281e+02]
 [  1.83371506e+02]
 [  2.22110205e+03]
 [  7.13674316e+03]
 [  1.14857582e+02]
 [  6.45089905e+02]
 [  1.60531445e+03]
 [  9.72924744e+02]
 [  9.38003711e+03]
 [  5.57227516e+01]
 [  6.87253564e+03]
 [  2.05466099e+01]]
DEBUG:root:training time = %d0.191054
INFO:root:frame =2105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =2106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.995041
DEBUG:root: dqn, choose action rondomly, need time 0.000188000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000177145004272
INFO:root:frame =2109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =2110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.9950315
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 8729.96484375]
 [  103.02237701]
 [  103.02237701]
 [  840.25408936]
 [ 2581.31616211]
 [  134.57270813]
 [ 3102.14453125]
 [ 2003.78149414]
 [ 3102.14453125]
 [  103.02237701]
 [  175.89382935]
 [  840.25408936]
 [  774.3973999 ]
 [ 1746.37927246]
 [  128.10871887]
 [ 8729.96484375]]
DEBUG:root:training time = %d0.206486
INFO:root:frame =2113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =2114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234127044678
DEBUG:root: save sample needs time = 0.000105142593384
INFO:root:random_action_porb = 0.995022
DEBUG:root: dqn, choose action rondomly, need time 0.000329000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =2117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =2118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.9950125
DEBUG:root: dqn, choose action rondomly, need time 0.000534999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000341892242432
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.42328398e+04]
 [  5.01266403e+01]
 [  4.64685936e+01]
 [  1.94518555e+02]
 [  5.46653516e+03]
 [  5.19669922e+03]
 [  7.10499878e+01]
 [  1.12986298e+01]
 [  1.22798359e+04]
 [  5.46653516e+03]
 [  1.09678748e+03]
 [  8.44157104e+02]
 [  1.09678748e+03]
 [  5.38614441e+02]
 [  1.94338684e+01]
 [  6.61348915e+00]]
DEBUG:root:training time = %d0.205431
INFO:root:frame =2121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =2122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.995003
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =2125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =2126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000514030456543
DEBUG:root: save sample needs time = 0.000136137008667
INFO:root:random_action_porb = 0.9949935
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.01380249e+02]
 [  9.21356750e+02]
 [  4.48406944e+01]
 [  3.01155090e+02]
 [  4.74948047e+03]
 [  2.85469398e+01]
 [  5.26600075e+01]
 [  1.06583389e+02]
 [  4.38396790e+02]
 [  3.87956116e+02]
 [  4.09189148e+02]
 [  1.77018726e+03]
 [  2.37752368e+03]
 [  2.96439123e+00]
 [  3.57841034e+02]
 [  2.90850513e+03]]
DEBUG:root:training time = %d0.20084
INFO:root:frame =2129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =2130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000297069549561
DEBUG:root: save sample needs time = 0.000121116638184
INFO:root:random_action_porb = 0.994984
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =2133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =2134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.9949745
DEBUG:root: dqn, choose action rondomly, need time 0.000365000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000351190567017
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.92752151e+01]
 [  1.01539996e+03]
 [  3.48741486e+02]
 [  5.04781628e+00]
 [  2.08366959e+02]
 [  9.30261078e+01]
 [  5.92756201e+03]
 [  4.57154751e-01]
 [  1.05840317e+02]
 [  6.92752151e+01]
 [  4.94732819e+02]
 [  3.03623943e+01]
 [  2.12853745e+02]
 [  1.80293594e+02]
 [  1.46100000e+03]
 [  8.15073967e+00]]
DEBUG:root:training time = %d0.195492
INFO:root:frame =2137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =2138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.994965
DEBUG:root: dqn, choose action rondomly, need time 0.000157999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00015115737915
INFO:root:frame =2141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =2142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482082366943
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.9949555
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000315189361572
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.46909326e+03]
 [  4.10729866e+01]
 [  4.60820099e+02]
 [  2.04944641e+02]
 [  2.81460846e+02]
 [  3.21859207e+01]
 [  1.62116945e+00]
 [  1.88821198e+02]
 [  9.76752319e+02]
 [  1.62116945e+00]
 [  1.42159351e+03]
 [  7.10975098e+02]
 [  2.04944641e+02]
 [  1.13273389e+03]
 [  1.25695605e+04]
 [  6.08885132e+02]]
DEBUG:root:training time = %d0.193732
INFO:root:frame =2145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =2146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000352144241333
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.994946
DEBUG:root: dqn, choose action rondomly, need time 0.000311
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =2149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000519990921021
INFO:root:frame =2150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9949365
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.35952484e+02]
 [  6.40569000e+01]
 [  2.22922455e+02]
 [  2.74785675e+02]
 [  5.96536804e+02]
 [  4.27161169e+00]
 [  3.12357727e+02]
 [  2.22922455e+02]
 [  1.50853284e+03]
 [  6.97780090e+02]
 [  5.82710840e-02]
 [  1.05966064e+03]
 [  2.80338257e+02]
 [  9.05982227e+03]
 [  2.58642029e+02]
 [  3.49834082e+03]]
DEBUG:root:training time = %d0.216961
INFO:root:frame =2153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:frame =2154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.994927
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root:frame =2157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =2158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.9949175
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00036096572876
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.00289551e+02]
 [  5.20708936e+03]
 [  1.57990961e+01]
 [  1.12057549e+02]
 [  1.33905315e+01]
 [  3.00289551e+02]
 [  1.33905315e+01]
 [  1.02572487e+02]
 [  1.54982532e+03]
 [  3.89313690e+02]
 [  1.33905315e+01]
 [  1.82539225e-03]
 [  2.77062416e-01]
 [  9.30246353e+01]
 [  1.47329437e+02]
 [  1.54982532e+03]]
DEBUG:root:training time = %d0.19755
INFO:root:frame =2161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00019383430481
INFO:root:frame =2162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.994908
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:frame =2165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000536918640137
INFO:root:frame =2166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.9948985
DEBUG:root: dqn, choose action rondomly, need time 0.000207999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.72312105e-01]
 [  1.95216354e+02]
 [  1.38943863e+02]
 [  3.84101855e+03]
 [  4.08787117e+01]
 [  1.91295120e+02]
 [  1.38418808e+02]
 [  4.97581451e+02]
 [  6.02580190e-01]
 [  1.27342346e+03]
 [  1.79966736e+01]
 [  2.10664697e+03]
 [  4.97581451e+02]
 [  6.02580190e-01]
 [  3.03147324e+04]
 [  1.55149124e+02]]
DEBUG:root:training time = %d0.202921
INFO:root:frame =2169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000197172164917
INFO:root:frame =2170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279188156128
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.994889
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =2173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000524997711182
INFO:root:frame =2174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475883483887
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.9948795
DEBUG:root: dqn, choose action rondomly, need time 0.000245
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.46659851e+01]
 [  6.59858763e-01]
 [  1.43209741e+03]
 [  2.38412628e+01]
 [  3.65354346e+03]
 [  3.21885147e+01]
 [  1.47771711e+01]
 [  5.39020691e+02]
 [  3.02602356e+02]
 [  1.88715051e+03]
 [  1.06541290e+02]
 [  5.39020691e+02]
 [  7.95062184e-01]
 [  1.43210010e+03]
 [  6.92409180e+03]
 [  2.38412628e+01]]
DEBUG:root:training time = %d0.203496
INFO:root:frame =2177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000369071960449
INFO:root:frame =2178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:random_action_porb = 0.99487
DEBUG:root: dqn, choose action rondomly, need time 0.000523000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =2181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =2182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9948605
DEBUG:root: dqn, choose action rondomly, need time 0.000313999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  366.22860718]
 [   12.35661507]
 [   49.01805115]
 [  176.83265686]
 [  176.83265686]
 [ 1983.39343262]
 [  122.67279816]
 [    5.3919611 ]
 [   32.15285873]
 [  938.55334473]
 [   32.15285873]
 [  268.30331421]
 [   33.54390335]
 [  475.36090088]
 [    6.09171343]
 [  268.30331421]]
DEBUG:root:training time = %d0.207665
INFO:root:frame =2185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259160995483
INFO:root:frame =2186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:random_action_porb = 0.994851
DEBUG:root: dqn, choose action rondomly, need time 0.000482999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =2189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame =2190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9948415
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.57271557e+01]
 [  3.87163391e+02]
 [  2.27699928e+01]
 [  7.08343079e+02]
 [  1.20271301e+02]
 [  6.28429222e+01]
 [  3.87163391e+02]
 [  7.75799438e+02]
 [  1.79787285e+04]
 [  1.49454605e+02]
 [  7.75799438e+02]
 [  2.84477305e+00]
 [  8.09675217e+01]
 [  6.60744762e+00]
 [  1.91803650e+02]
 [  1.20271301e+02]]
DEBUG:root:training time = %d0.19528
INFO:root:frame =2193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =2194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.994832
DEBUG:root: dqn, choose action rondomly, need time 0.000319999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =2197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488996505737
INFO:root:frame =2198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame = 2199 State into memory, numbers recorded 52 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000606060028076
INFO:root:random_action_porb = 0.9948225
DEBUG:root: dqn, choose action rondomly, need time 0.000176
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2200current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   96.89941406]
 [  406.73034668]
 [  442.46157837]
 [   19.10972977]
 [ 1396.84387207]
 [ 2982.03393555]
 [ 1875.84448242]
 [  189.53086853]
 [  896.0435791 ]
 [   56.71030426]
 [  223.98902893]
 [   12.66652203]
 [   18.03870773]
 [  163.82249451]
 [  156.87901306]
 [   72.64196014]]
DEBUG:root:training time = %d0.198935
INFO:root:frame =2201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =2202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.994813
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =2205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000417947769165
INFO:root:frame =2206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000419139862061
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9948035
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.73062805e+02]
 [  3.11323023e+00]
 [  1.55647858e+02]
 [  2.62560791e+02]
 [  6.56035840e+03]
 [  2.82849243e+02]
 [  1.78907776e+02]
 [  3.11323023e+00]
 [  7.98220276e+02]
 [  6.97326660e+03]
 [  1.78907776e+02]
 [  1.88921951e+02]
 [  2.62560791e+02]
 [  5.04610176e+01]
 [  1.11691565e+03]
 [  3.64065361e+01]]
DEBUG:root:training time = %d0.218619
INFO:root:frame =2209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =2210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.994794
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =2213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =2214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame = 2215 State into memory, numbers recorded 53 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000578165054321
INFO:root:random_action_porb = 0.9947845
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2216current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.04099023e+03]
 [  9.35404358e+02]
 [  2.04487896e+00]
 [  1.38524158e+03]
 [  9.13983105e+03]
 [  6.85390425e+00]
 [  1.38524158e+03]
 [  8.01570557e+02]
 [  2.54129162e+01]
 [  6.26378601e+02]
 [  1.76555640e+03]
 [  1.68925428e+00]
 [  1.86158661e+02]
 [  1.38524158e+03]
 [  4.07156982e+02]
 [  4.50095490e+02]]
DEBUG:root:training time = %d0.200228
INFO:root:frame =2217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:frame =2218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.994775
DEBUG:root: dqn, choose action rondomly, need time 0.000321
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000347852706909
INFO:root:frame =2221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =2222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:random_action_porb = 0.9947655
DEBUG:root: dqn, choose action rondomly, need time 0.000520999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1281.93908691]
 [  172.45433044]
 [  603.90722656]
 [ 2438.21679688]
 [ 2359.91723633]
 [  168.80050659]
 [ 2031.70996094]
 [  603.90722656]
 [  315.8991394 ]
 [ 2564.49145508]
 [  643.84259033]
 [   16.42243004]
 [  665.77246094]
 [ 2359.91723633]
 [    4.61198187]
 [  525.61383057]]
DEBUG:root:training time = %d0.204437
INFO:root:frame =2225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240802764893
INFO:root:frame =2226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.994756
DEBUG:root: dqn, choose action rondomly, need time 0.000333000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =2229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =2230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.9947465
DEBUG:root: dqn, choose action rondomly, need time 0.000327000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.15373497e+01]
 [  3.85345306e+01]
 [  9.68474487e+02]
 [  7.64169971e+03]
 [  1.00996735e+02]
 [  1.73472961e+02]
 [  3.79562964e+03]
 [  7.64169971e+03]
 [  1.74464531e+01]
 [  2.87294626e+00]
 [  9.43098927e+00]
 [  1.33362710e-01]
 [  7.05249609e+03]
 [  1.96014538e+01]
 [  4.36772430e+02]
 [  7.83517761e+01]]
DEBUG:root:training time = %d0.198797
INFO:root:frame =2233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:frame =2234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430822372437
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.994737
DEBUG:root: dqn, choose action rondomly, need time 0.000571999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =2237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =2238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.9947275
DEBUG:root: dqn, choose action rondomly, need time 0.000167000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.88218384e+01]
 [  2.84765625e+00]
 [  1.60640228e+02]
 [  5.20785461e+02]
 [  2.84765625e+00]
 [  7.04339661e+02]
 [  2.42626643e+00]
 [  5.20785461e+02]
 [  1.52334686e+02]
 [  4.92976379e+02]
 [  4.32980299e-01]
 [  2.38716333e+03]
 [  7.41427795e+02]
 [  1.01488655e+02]
 [  1.29248792e+03]
 [  1.01488655e+02]]
DEBUG:root:training time = %d0.199573
INFO:root:frame =2241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:frame =2242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.994718
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =2245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =2246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.9947085
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.01298486e+03]
 [  8.87688522e+01]
 [  2.66786591e+02]
 [  4.38566666e+01]
 [  1.26540213e+01]
 [  6.04780518e+02]
 [  4.94007202e+02]
 [  5.21427079e-04]
 [  4.45974023e+03]
 [  1.24358093e+02]
 [  1.25930710e+01]
 [  8.87688522e+01]
 [  8.16185608e+02]
 [  1.01298486e+03]
 [  8.87688522e+01]
 [  4.33508105e+03]]
DEBUG:root:training time = %d0.214486
INFO:root:frame =2249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:frame =2250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227928161621
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.994699
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =2253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000487089157104
INFO:root:frame =2254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.9946895
DEBUG:root: dqn, choose action rondomly, need time 0.000351999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000391006469727
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.00493355e+01]
 [  7.20393906e+01]
 [  1.80288074e+03]
 [  8.11289734e+02]
 [  3.04506149e+01]
 [  8.38727051e+02]
 [  1.96208477e+01]
 [  3.24108765e+02]
 [  1.88817520e+02]
 [  7.80236206e+02]
 [  2.98726482e+01]
 [  9.12636230e+02]
 [  9.48964214e+00]
 [  3.16542554e+03]
 [  5.61447571e+02]
 [  1.06723760e+04]]
DEBUG:root:training time = %d0.199184
INFO:root:frame =2257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:frame =2258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255823135376
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.99468
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =2261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =2262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.9946705
DEBUG:root: dqn, choose action rondomly, need time 0.000322999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.71667690e+01]
 [  1.58900824e+01]
 [  2.84891663e+01]
 [  1.38254944e+02]
 [  8.49100426e-02]
 [  8.55607117e+02]
 [  5.37937212e+00]
 [  2.17841553e+03]
 [  2.17070996e+03]
 [  4.02819275e+02]
 [  2.84891663e+01]
 [  9.91057373e+02]
 [  3.47198761e+02]
 [  8.55607117e+02]
 [  2.72955414e+02]
 [  9.73190842e+01]]
DEBUG:root:training time = %d0.204874
INFO:root:frame =2265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =2266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249147415161
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.994661
DEBUG:root: dqn, choose action rondomly, need time 0.000173999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000157117843628
INFO:root:frame =2269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =2270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000253915786743
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9946515
DEBUG:root: dqn, choose action rondomly, need time 0.000311999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.96614624e+02]
 [  1.23613892e+01]
 [  7.16989899e+01]
 [  2.32916336e+02]
 [  1.26718335e+03]
 [  5.09138079e-03]
 [  7.40122656e+03]
 [  1.80987756e+03]
 [  1.59129114e+03]
 [  1.59129114e+03]
 [  6.48891504e+03]
 [  7.36071960e+02]
 [  1.52910400e+03]
 [  2.50688004e+00]
 [  3.64249535e+01]
 [  5.68922485e+02]]
DEBUG:root:training time = %d0.203406
INFO:root:frame =2273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =2274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229120254517
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.994642
DEBUG:root: dqn, choose action rondomly, need time 0.000343999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =2277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491857528687
INFO:root:frame =2278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000242948532104
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9946325
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000396966934204
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2776.08691406]
 [   15.14646339]
 [   17.47246552]
 [   32.34054184]
 [  830.12762451]
 [   36.30119324]
 [  686.8996582 ]
 [  196.8644104 ]
 [   14.6355629 ]
 [  169.72480774]
 [ 2184.06054688]
 [ 2474.93945312]
 [  196.8644104 ]
 [  103.7640152 ]
 [  121.07302094]
 [  686.8996582 ]]
DEBUG:root:training time = %d0.197277
INFO:root:frame =2281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =2282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288009643555
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.994623
DEBUG:root: dqn, choose action rondomly, need time 0.000183
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =2285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =2286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame = 2287 State into memory, numbers recorded 54 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000607967376709
INFO:root:random_action_porb = 0.9946135
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2288current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[    3.6038332 ]
 [   92.3166275 ]
 [  488.67132568]
 [  931.69140625]
 [   92.3166275 ]
 [  476.95910645]
 [  561.72167969]
 [   26.41724014]
 [   92.3166275 ]
 [  101.42990112]
 [  476.95910645]
 [  647.30047607]
 [ 3570.84106445]
 [   12.91196823]
 [ 2269.64086914]
 [   12.91196823]]
DEBUG:root:training time = %d0.206684
INFO:root:frame =2289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002281665802
INFO:root:frame =2290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.994604
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root:frame =2293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248193740845
INFO:root:frame =2294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9945945
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.60016590e-01]
 [  2.02831128e+03]
 [  4.78599731e+02]
 [  1.27361641e+02]
 [  2.35994396e+01]
 [  1.46841833e+03]
 [  9.41173935e+00]
 [  5.03630400e+00]
 [  3.43190098e+00]
 [  4.55530243e+01]
 [  6.99948669e+02]
 [  8.37899780e+01]
 [  1.68229407e+03]
 [  4.70407410e+01]
 [  7.77220230e+01]
 [  4.70407410e+01]]
DEBUG:root:training time = %d0.20121
INFO:root:frame =2297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =2298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000261068344116
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:random_action_porb = 0.994585
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =2301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000545978546143
INFO:root:frame =2302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.9945755
DEBUG:root: dqn, choose action rondomly, need time 0.000484999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.87291312e+00]
 [  2.79581787e+02]
 [  5.51148987e+00]
 [  7.27059174e+00]
 [  2.62760864e+02]
 [  6.08964233e+02]
 [  4.46151520e+02]
 [  3.90921655e+03]
 [  1.53438440e+03]
 [  1.53405571e+01]
 [  2.99758587e+01]
 [  7.27059174e+00]
 [  6.08964233e+02]
 [  2.57291656e+02]
 [  2.20710278e+03]
 [  2.57291656e+02]]
DEBUG:root:training time = %d0.199035
INFO:root:frame =2305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =2306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.994566
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =2309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =2310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9945565
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.85014129e+00]
 [  1.40676624e+03]
 [  5.66174965e+01]
 [  3.88048706e+03]
 [  1.61319360e+03]
 [  1.26484656e+03]
 [  2.55257614e+02]
 [  6.40487137e+01]
 [  5.85864844e+03]
 [  2.55257614e+02]
 [  1.65341211e+03]
 [  1.10138782e+03]
 [  2.14057593e+03]
 [  4.42687744e+02]
 [  8.12264786e+01]
 [  2.44223511e+03]]
DEBUG:root:training time = %d0.186267
INFO:root:frame =2313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =2314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000402212142944
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.994547
DEBUG:root: dqn, choose action rondomly, need time 0.000342000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =2317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame =2318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.9945375
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000315189361572
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.51324606e+00]
 [  1.32099655e+02]
 [  8.81629181e+01]
 [  1.51324606e+00]
 [  1.53271667e+03]
 [  9.60750520e-01]
 [  2.46482715e-02]
 [  2.43244049e+02]
 [  8.89551392e+02]
 [  2.69736279e+03]
 [  3.40457001e+02]
 [  1.71302600e+03]
 [  3.55391754e+02]
 [  3.98129639e+02]
 [  2.66421844e+02]
 [  1.53271667e+03]]
DEBUG:root:training time = %d0.209526
INFO:root:frame =2321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000260829925537
INFO:root:frame =2322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:random_action_porb = 0.994528
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =2325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =2326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.9945185
DEBUG:root: dqn, choose action rondomly, need time 0.000453
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.69625977e+02]
 [  5.24040479e+03]
 [  3.57692981e+00]
 [  1.85577423e+02]
 [  1.58425342e+03]
 [  4.23733398e+02]
 [  7.65568829e+00]
 [  2.82666321e+02]
 [  1.58425342e+03]
 [  6.62982368e+00]
 [  3.57692981e+00]
 [  4.93975311e+02]
 [  5.04264116e+00]
 [  5.24040479e+03]
 [  2.37791397e+02]
 [  2.78036389e-02]]
DEBUG:root:training time = %d0.198317
INFO:root:frame =2329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =2330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000123977661133
INFO:root:random_action_porb = 0.994509
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =2333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =2334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479221343994
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.9944995
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.44549365e+04]
 [  1.81264209e+03]
 [  7.57163644e-01]
 [  1.87336166e+02]
 [  1.13443127e+03]
 [  8.04048682e+03]
 [  2.15708588e+02]
 [  3.27874847e+02]
 [  8.04048682e+03]
 [  3.25941437e+02]
 [  1.92810040e+01]
 [  1.00353687e+03]
 [  7.15252924e+00]
 [  6.35739565e-01]
 [  3.23281342e+02]
 [  1.62973035e+03]]
DEBUG:root:training time = %d0.210764
INFO:root:frame =2337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =2338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:random_action_porb = 0.99449
DEBUG:root: dqn, choose action rondomly, need time 0.000326000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =2341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =2342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.9944805
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.83449268e+03]
 [  5.52102539e+03]
 [  3.81130646e+02]
 [  1.50434275e+01]
 [  5.02576269e-02]
 [  6.17829590e+02]
 [  5.24046021e+02]
 [  3.64002762e+01]
 [  9.49199524e+02]
 [  1.51291199e+02]
 [  1.51291199e+02]
 [  9.68959412e+02]
 [  9.49199524e+02]
 [  5.95228418e+03]
 [  8.62362289e+01]
 [  3.55815315e+00]]
DEBUG:root:training time = %d0.191346
INFO:root:frame =2345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =2346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241041183472
DEBUG:root: save sample needs time = 0.000104188919067
INFO:root:random_action_porb = 0.994471
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =2349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =2350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9944615
INFO:root:dqn select action Tensor("ArgMax_1:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013568
INFO:root:action choosen by dqn [1]
INFO:root:frame =2352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365972518921
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.71587207e+03]
 [  3.99505768e+02]
 [  2.67265148e+01]
 [  6.13335419e+01]
 [  6.42003555e+01]
 [  1.61894333e+02]
 [  6.03982605e+02]
 [  1.19282684e+02]
 [  1.00584679e+01]
 [  1.83361568e+01]
 [  9.20476501e+02]
 [  6.03982605e+02]
 [  1.78726032e-01]
 [  3.44450867e+02]
 [  4.44739349e+02]
 [  1.38250160e+01]]
DEBUG:root:training time = %d0.206753
INFO:root:frame =2353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =2354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000250101089478
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.994452
DEBUG:root: dqn, choose action rondomly, need time 0.000325000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =2357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame =2358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485897064209
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9944425
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.40718338e+02]
 [  4.85994720e+00]
 [  3.41608953e+00]
 [  1.02168037e+02]
 [  1.20847641e+02]
 [  5.25931519e+02]
 [  6.00154297e+02]
 [  1.34137278e+01]
 [  2.29887700e+00]
 [  1.38742493e+02]
 [  2.83488613e+04]
 [  3.36905615e+03]
 [  2.91739488e+00]
 [  1.76981360e+03]
 [  5.48803345e+02]
 [  1.20847641e+02]]
DEBUG:root:training time = %d0.192159
INFO:root:frame =2361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =2362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000225067138672
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.994433
DEBUG:root: dqn, choose action rondomly, need time 0.000197999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:frame =2365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =2366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476121902466
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:random_action_porb = 0.9944235
DEBUG:root: dqn, choose action rondomly, need time 0.000337999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.04316696e+02]
 [  3.70915649e+02]
 [  1.24210098e+02]
 [  9.74680176e+01]
 [  7.34936774e-01]
 [  4.84599609e+01]
 [  5.58258398e+03]
 [  3.98073626e+00]
 [  3.57273221e+00]
 [  1.59235413e+03]
 [  1.80906525e+02]
 [  1.09530535e+01]
 [  1.42827502e+03]
 [  2.62050928e+03]
 [  2.55648308e+01]
 [  3.18516045e+01]]
DEBUG:root:training time = %d0.205554
INFO:root:frame =2369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =2370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259876251221
DEBUG:root: save sample needs time = 0.000120162963867
INFO:root:random_action_porb = 0.994414
DEBUG:root: dqn, choose action rondomly, need time 0.000176999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000173091888428
INFO:root:frame =2373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =2374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.9944045
DEBUG:root: dqn, choose action rondomly, need time 0.000550000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.78025293e+03]
 [  6.27489700e+01]
 [  2.46446289e+03]
 [  8.61971558e+02]
 [  5.11874580e+01]
 [  4.68508196e+00]
 [  2.16872005e+01]
 [  5.11874580e+01]
 [  7.07463745e+02]
 [  1.72020376e+00]
 [  2.98232483e+02]
 [  9.20198364e+01]
 [  4.68171358e+00]
 [  1.15462661e-01]
 [  9.20198364e+01]
 [  2.46446289e+03]]
DEBUG:root:training time = %d0.197394
INFO:root:frame =2377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:frame =2378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.994395
DEBUG:root: dqn, choose action rondomly, need time 0.000499000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =2381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427961349487
INFO:root:frame =2382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469207763672
DEBUG:root: save sample needs time = 0.000104904174805
INFO:root:random_action_porb = 0.9943855
DEBUG:root: dqn, choose action rondomly, need time 0.000249999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000147104263306
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.10369816e+01]
 [  1.00939240e+02]
 [  1.76466995e+02]
 [  1.04700272e+02]
 [  8.69302979e+02]
 [  3.52522736e+02]
 [  1.32002869e+03]
 [  6.96949625e+00]
 [  6.96949625e+00]
 [  1.83311920e+01]
 [  4.95129623e+01]
 [  4.96483673e+02]
 [  8.56403137e+02]
 [  6.79976273e+00]
 [  6.02818750e+03]
 [  5.20062113e+00]]
DEBUG:root:training time = %d0.212582
INFO:root:frame =2385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =2386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.994376
DEBUG:root: dqn, choose action rondomly, need time 0.000276999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312805175781
INFO:root:frame =2389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame =2390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
DEBUG:root: save sample needs time = 0.000121116638184
INFO:root:random_action_porb = 0.9943665
DEBUG:root: dqn, choose action rondomly, need time 0.000166
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  105.325737  ]
 [  360.05432129]
 [   86.98921967]
 [ 2235.30737305]
 [ 1161.13244629]
 [   81.01593018]
 [  783.73083496]
 [ 1159.99609375]
 [ 3890.92797852]
 [ 4777.14892578]
 [  454.31640625]
 [  105.325737  ]
 [  816.58056641]
 [  855.02520752]
 [  454.31640625]
 [ 2235.30737305]]
DEBUG:root:training time = %d0.208193
INFO:root:frame =2393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =2394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002281665802
INFO:root:frame = 2395 State into memory, numbers recorded 55 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:random_action_porb = 0.994357
DEBUG:root: dqn, choose action rondomly, need time 0.000197999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2396current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:frame =2397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281810760498
INFO:root:frame =2398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438213348389
DEBUG:root: save sample needs time = 0.000193119049072
INFO:root:random_action_porb = 0.9943475
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.58849380e+02]
 [  2.05874238e+04]
 [  8.56849731e+02]
 [  5.88841295e+00]
 [  2.26172485e+02]
 [  5.76103455e+02]
 [  3.25603676e+01]
 [  3.38101730e+01]
 [  2.26172485e+02]
 [  1.15527637e+03]
 [  4.91329651e+01]
 [  3.47018896e+03]
 [  4.95724762e+02]
 [  3.53047791e+02]
 [  2.40889606e+01]
 [  3.25603676e+01]]
DEBUG:root:training time = %d0.190737
INFO:root:frame =2401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:frame =2402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.994338
DEBUG:root: dqn, choose action rondomly, need time 0.000484
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =2405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000428915023804
INFO:root:frame =2406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9943285
DEBUG:root: dqn, choose action rondomly, need time 0.000419000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000176906585693
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.52268143e+01]
 [  4.78796158e+01]
 [  4.88601761e+01]
 [  1.64298515e+01]
 [  5.67980957e+02]
 [  4.78796158e+01]
 [  3.89056816e+01]
 [  1.64298515e+01]
 [  1.75568494e+03]
 [  1.27445984e+03]
 [  6.85132385e+02]
 [  1.64298515e+01]
 [  6.80919588e-02]
 [  4.78796158e+01]
 [  4.01847191e+01]
 [  4.13692398e+01]]
DEBUG:root:training time = %d0.18772
INFO:root:frame =2409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =2410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.994319
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =2413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000411987304688
INFO:root:frame =2414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428915023804
DEBUG:root: save sample needs time = 0.000270843505859
INFO:root:random_action_porb = 0.9943095
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.89867462e+02]
 [  1.00134014e+04]
 [  2.39962488e-02]
 [  1.37659393e+02]
 [  1.81863611e+03]
 [  7.17086609e+02]
 [  2.34214287e+01]
 [  1.37659393e+02]
 [  1.18163513e+03]
 [  1.81925705e+02]
 [  1.39733856e+02]
 [  1.82852005e+02]
 [  2.69297905e+01]
 [  1.33184462e+01]
 [  2.42193408e+03]
 [  4.08900909e+02]]
DEBUG:root:training time = %d0.200679
INFO:root:frame =2417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000395059585571
INFO:root:frame =2418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9943
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =2421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446796417236
INFO:root:frame =2422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9942905
DEBUG:root: dqn, choose action rondomly, need time 0.000283000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.83092712e+02]
 [  1.38827332e+02]
 [  8.36157532e+01]
 [  5.40827217e+01]
 [  2.58062988e+03]
 [  3.17445526e+02]
 [  5.40827217e+01]
 [  1.44687103e+02]
 [  2.03572578e+01]
 [  2.88767749e+03]
 [  5.86635017e+01]
 [  2.58062988e+03]
 [  1.26307861e+03]
 [  1.10039258e+00]
 [  1.07126465e+01]
 [  4.73546777e+03]]
DEBUG:root:training time = %d0.202297
INFO:root:frame =2425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:frame =2426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000172853469849
INFO:root:random_action_porb = 0.994281
DEBUG:root: dqn, choose action rondomly, need time 0.00027
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =2429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =2430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9942715
DEBUG:root: dqn, choose action rondomly, need time 0.000325000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.60279942e+00]
 [  1.69851742e+01]
 [  7.64887146e+02]
 [  2.04027087e+03]
 [  1.29162827e+02]
 [  2.13873787e+01]
 [  3.01075352e+04]
 [  3.28513908e+01]
 [  5.17713867e+02]
 [  8.08231544e+00]
 [  1.09157667e+01]
 [  1.29162827e+02]
 [  8.76679871e+02]
 [  2.97685695e+00]
 [  4.23896436e+03]
 [  2.13873787e+01]]
DEBUG:root:training time = %d0.202952
INFO:root:frame =2433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000371217727661
INFO:root:frame =2434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.994262
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =2437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =2438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.9942525
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:training error  = [[  2.96139160e+02]
 [  9.31524902e+02]
 [  1.25719333e+00]
 [  2.67972255e+00]
 [  6.85181885e+02]
 [  7.28806396e+02]
 [  1.25719333e+00]
 [  3.40780306e+00]
 [  1.44124768e+03]
 [  1.28178552e+03]
 [  4.03406029e+01]
 [  4.42127991e+00]
 [  9.75590286e+01]
 [  7.41158142e+02]
 [  4.32028999e+01]
 [  3.31763077e+01]]
DEBUG:root:training time = %d0.1925
INFO:root:frame =2441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:frame =2442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.994243
INFO:root:dqn select action Tensor("ArgMax_2:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.008311
INFO:root:action choosen by dqn [1]
INFO:root:frame =2444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =2445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000561952590942
INFO:root:frame =2446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000115156173706
INFO:root:random_action_porb = 0.9942335
DEBUG:root: dqn, choose action rondomly, need time 0.000269000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.06659448e+00]
 [  1.35485239e+01]
 [  5.48762741e+01]
 [  1.15480289e+01]
 [  2.42327850e+02]
 [  1.35485239e+01]
 [  3.81260452e+01]
 [  6.51545715e+01]
 [  1.87632645e+02]
 [  6.90777874e+00]
 [  8.45450745e+01]
 [  1.87632645e+02]
 [  1.06659448e+00]
 [  3.81260452e+01]
 [  2.93480542e+03]
 [  8.45450745e+01]]
DEBUG:root:training time = %d0.206596
INFO:root:frame =2449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028920173645
INFO:root:frame =2450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000245094299316
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:random_action_porb = 0.994224
DEBUG:root: dqn, choose action rondomly, need time 0.000267999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =2453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000501871109009
INFO:root:frame =2454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000217914581299
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9942145
DEBUG:root: dqn, choose action rondomly, need time 0.000324999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.04002487e+02]
 [  1.39964831e+00]
 [  9.97763977e+02]
 [  5.02516060e+01]
 [  1.06730785e+01]
 [  1.87781296e+01]
 [  4.96050964e+02]
 [  1.61880249e+03]
 [  1.87781296e+01]
 [  2.06459141e+01]
 [  9.97763977e+02]
 [  2.53506445e+03]
 [  2.06459141e+01]
 [  3.85365844e+00]
 [  2.33907185e+01]
 [  3.20898865e+02]]
DEBUG:root:training time = %d0.208442
INFO:root:frame =2457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:frame =2458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame = 2459 State into memory, numbers recorded 56 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000555992126465
INFO:root:random_action_porb = 0.994205
DEBUG:root: dqn, choose action rondomly, need time 0.000179999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2460current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:frame =2461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =2462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.9941955
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000404834747314
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.69116653e+02]
 [  9.04907913e+01]
 [  5.75059204e+02]
 [  9.50134338e+02]
 [  5.10390937e-01]
 [  3.72045868e+02]
 [  9.04907913e+01]
 [  4.26261368e+01]
 [  3.72045868e+02]
 [  4.04033875e+02]
 [  2.09044766e+04]
 [  4.51226562e+03]
 [  1.03987335e+02]
 [  2.23350562e+03]
 [  1.29626808e+01]
 [  1.39453156e+02]]
DEBUG:root:training time = %d0.20456
INFO:root:frame =2465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000260829925537
INFO:root:frame =2466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269174575806
DEBUG:root: save sample needs time = 0.000111103057861
INFO:root:random_action_porb = 0.994186
DEBUG:root: dqn, choose action rondomly, need time 0.000166
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000155925750732
INFO:root:frame =2469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =2470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255823135376
DEBUG:root: save sample needs time = 0.000101804733276
INFO:root:random_action_porb = 0.9941765
DEBUG:root: dqn, choose action rondomly, need time 0.000162000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  353.73046875]
 [ 2185.02905273]
 [  207.47981262]
 [  380.26785278]
 [   25.65084839]
 [  140.28959656]
 [   66.09449768]
 [  106.3712616 ]
 [  796.08428955]
 [  468.43487549]
 [   25.65084839]
 [   35.56552887]
 [   22.27466583]
 [   55.71660233]
 [ 2438.29663086]
 [   35.56552887]]
DEBUG:root:training time = %d0.204049
INFO:root:frame =2473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:frame =2474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.994167
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =2477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =2478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.9941575
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1243.13378906]
 [ 1213.13916016]
 [  159.70420837]
 [   10.74633408]
 [   15.09745121]
 [  385.91931152]
 [   10.74633408]
 [  557.45733643]
 [  540.52349854]
 [   50.72279739]
 [   18.96811485]
 [  282.32162476]
 [   92.36296082]
 [  282.32162476]
 [   18.96811485]
 [  483.74020386]]
DEBUG:root:training time = %d0.190681
INFO:root:frame =2481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =2482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.994148
DEBUG:root: dqn, choose action rondomly, need time 0.000323999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =2485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame =2486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame = 2487 State into memory, numbers recorded 57 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000595808029175
INFO:root:random_action_porb = 0.9941385
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2488current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 199.20280457]
 [ 213.29631042]
 [  93.1693573 ]
 [ 504.28262329]
 [  30.71858215]
 [ 492.85681152]
 [  39.5194931 ]
 [   2.81294966]
 [ 117.64516449]
 [  93.1693573 ]
 [   3.33654785]
 [  69.68247223]
 [  40.77234268]
 [ 353.55773926]
 [  30.71858215]
 [  92.24187469]]
DEBUG:root:training time = %d0.185051
INFO:root:frame =2489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:frame =2490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.994129
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332832336426
INFO:root:frame =2493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =2494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9941195
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.62128555e+02]
 [  2.96054565e+02]
 [  8.63552988e-01]
 [  3.02946198e+02]
 [  3.24199268e+03]
 [  9.57298756e-01]
 [  2.97098694e+01]
 [  4.01972321e+02]
 [  1.66603790e+02]
 [  1.66603790e+02]
 [  3.50324921e+02]
 [  3.90206451e+01]
 [  1.50216377e+00]
 [  5.19175491e+01]
 [  2.29874756e+02]
 [  4.43061920e+02]]
DEBUG:root:training time = %d0.212077
INFO:root:frame =2497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =2498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.99411
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =2501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =2502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227928161621
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9941005
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.67451123e+03]
 [  4.11605568e+01]
 [  3.54662269e-01]
 [  1.72277039e+02]
 [  9.16463852e+01]
 [  1.29668016e+01]
 [  2.88855804e+02]
 [  1.30522728e+01]
 [  1.24088599e+03]
 [  1.13651947e+02]
 [  1.25174046e+01]
 [  3.77787354e+02]
 [  1.41675234e+01]
 [  2.96436176e+01]
 [  2.42524986e+01]
 [  2.40902740e+02]]
DEBUG:root:training time = %d0.201124
INFO:root:frame =2505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =2506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.994091
DEBUG:root: dqn, choose action rondomly, need time 0.000169
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root:frame =2509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =2510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000250101089478
DEBUG:root: save sample needs time = 0.000115871429443
INFO:root:random_action_porb = 0.9940815
DEBUG:root: dqn, choose action rondomly, need time 0.000172999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  338.07226562]
 [   64.26541138]
 [ 3158.35644531]
 [    5.73948097]
 [  113.20731354]
 [  263.90829468]
 [   72.00637054]
 [    7.51407003]
 [ 3158.35644531]
 [    7.94942951]
 [ 3158.35644531]
 [  119.86032867]
 [ 1405.95019531]
 [ 1223.94067383]
 [  151.13508606]
 [  263.90829468]]
DEBUG:root:training time = %d0.221708
INFO:root:frame =2513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =2514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000414848327637
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.994072
DEBUG:root: dqn, choose action rondomly, need time 0.000290999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =2517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =2518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00060510635376
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9940625
DEBUG:root: dqn, choose action rondomly, need time 0.000279999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.69677138e+00]
 [  3.73975250e+02]
 [  5.12580261e+02]
 [  2.39996643e+02]
 [  5.22674756e+03]
 [  8.55091286e+00]
 [  1.31971490e+00]
 [  1.36129647e-01]
 [  1.64051575e+02]
 [  2.06401382e+02]
 [  9.84295273e+01]
 [  6.56460114e+01]
 [  9.84295273e+01]
 [  2.40756321e+01]
 [  4.24991669e+02]
 [  1.22297144e+01]]
DEBUG:root:training time = %d0.185478
INFO:root:frame =2521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =2522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 9.29832458496e-05
INFO:root:random_action_porb = 0.994053
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =2525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =2526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9940435
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029182434082
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  214.15403748]
 [ 1786.85522461]
 [ 1786.85522461]
 [  426.61761475]
 [   58.60951996]
 [  136.70158386]
 [  149.57302856]
 [   52.14769745]
 [    4.73968649]
 [  251.90324402]
 [  115.37115479]
 [    4.73968649]
 [  426.61761475]
 [   29.00393867]
 [  176.04603577]
 [  237.84552002]]
DEBUG:root:training time = %d0.20511
INFO:root:frame =2529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =2530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.994034
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =2533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =2534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root:random_action_porb = 0.9940245
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000563859939575
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.75582123e+02]
 [  1.02000294e+01]
 [  1.76707474e+02]
 [  1.31519117e+01]
 [  4.82087088e+00]
 [  7.33281631e+01]
 [  2.02648342e-01]
 [  1.02000294e+01]
 [  3.73683786e+00]
 [  1.49350146e+03]
 [  2.15431348e+03]
 [  5.52537231e+01]
 [  2.15431348e+03]
 [  2.02648342e-01]
 [  3.73683786e+00]
 [  5.52537231e+01]]
DEBUG:root:training time = %d0.203654
INFO:root:frame =2537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =2538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.994015
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =2541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =2542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000416994094849
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.9940055
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.70021411e+03]
 [  8.56638718e+01]
 [  1.06143188e+00]
 [  1.20021820e+01]
 [  7.42961693e+00]
 [  5.18873828e+04]
 [  2.60627174e+00]
 [  1.98871069e+03]
 [  4.02734473e+03]
 [  8.19354248e+01]
 [  8.56638718e+01]
 [  2.80418365e+02]
 [  9.79234619e+02]
 [  5.18873828e+04]
 [  5.44306946e+01]
 [  1.12254443e+03]]
DEBUG:root:training time = %d0.205638
INFO:root:frame =2545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =2546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231981277466
DEBUG:root: save sample needs time = 0.000174999237061
INFO:root:random_action_porb = 0.993996
DEBUG:root: dqn, choose action rondomly, need time 0.000211999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000391960144043
INFO:root:frame =2549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =2550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9939865
DEBUG:root: dqn, choose action rondomly, need time 0.000546999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.72366821e+02]
 [  1.06689911e+01]
 [  1.37299774e+02]
 [  4.61525078e+01]
 [  4.61525078e+01]
 [  1.35145093e+03]
 [  2.21568614e-01]
 [  3.62623177e+01]
 [  2.35494354e+02]
 [  8.51576157e+01]
 [  4.61525078e+01]
 [  1.06879785e+03]
 [  2.35494354e+02]
 [  1.25550818e+03]
 [  9.35895157e+01]
 [  7.03306580e+02]]
DEBUG:root:training time = %d0.191576
INFO:root:frame =2553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =2554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
DEBUG:root: save sample needs time = 9.51290130615e-05
INFO:root:random_action_porb = 0.993977
DEBUG:root: dqn, choose action rondomly, need time 0.000247000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000126838684082
INFO:root:frame =2557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =2558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488996505737
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9939675
DEBUG:root: dqn, choose action rondomly, need time 0.000329000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.36138260e+02]
 [  1.92608960e+03]
 [  2.06033920e+02]
 [  1.61173569e+02]
 [  2.03367200e+03]
 [  1.71837927e+03]
 [  1.71837927e+03]
 [  4.17708862e+02]
 [  8.17638867e+03]
 [  4.06802034e+00]
 [  3.23942871e+02]
 [  9.78896713e+01]
 [  4.99663300e+02]
 [  4.51871338e+01]
 [  8.88695240e+00]
 [  1.12040649e+03]]
DEBUG:root:training time = %d0.19686
INFO:root:frame =2561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:frame =2562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.993958
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =2565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =2566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.9939485
DEBUG:root: dqn, choose action rondomly, need time 0.000179000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  230.07376099]
 [  192.52748108]
 [  488.30709839]
 [   38.58958435]
 [   49.99104691]
 [ 2181.03540039]
 [  234.01118469]
 [   81.24903107]
 [   57.34798813]
 [ 1304.28369141]
 [ 1118.41235352]
 [ 1793.68322754]
 [  212.20697021]
 [   38.58958435]
 [  478.77868652]
 [ 1793.68322754]]
DEBUG:root:training time = %d0.202015
INFO:root:frame =2569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =2570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025486946106
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.993939
DEBUG:root: dqn, choose action rondomly, need time 0.000278999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =2573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000401020050049
INFO:root:frame =2574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.9939295
DEBUG:root: dqn, choose action rondomly, need time 0.000449000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.68438934e+02]
 [  8.89294739e+02]
 [  1.42282381e+01]
 [  1.09915686e+03]
 [  1.64674280e+03]
 [  3.68438934e+02]
 [  8.89294739e+02]
 [  7.76278839e+01]
 [  1.64674280e+03]
 [  2.89288578e+01]
 [  6.96344604e+01]
 [  2.95083561e+01]
 [  9.50815439e-01]
 [  1.53722839e+03]
 [  8.89294739e+02]
 [  1.41670869e+04]]
DEBUG:root:training time = %d0.186147
INFO:root:frame =2577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =2578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.99392
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =2581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =2582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:random_action_porb = 0.9939105
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000377893447876
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.16861829e+03]
 [  9.42294159e+01]
 [  1.90318223e+04]
 [  2.51058984e+03]
 [  3.39972839e+01]
 [  4.78338789e+04]
 [  9.42294159e+01]
 [  6.93937607e+01]
 [  4.26656885e+03]
 [  8.41545296e+00]
 [  1.93682251e+02]
 [  2.19287329e+03]
 [  2.19287329e+03]
 [  1.90318223e+04]
 [  1.75915283e+02]
 [  2.25998560e+03]]
DEBUG:root:training time = %d0.20606
INFO:root:frame =2585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =2586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480175018311
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:random_action_porb = 0.993901
DEBUG:root: dqn, choose action rondomly, need time 0.000316000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =2589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =2590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9938915
DEBUG:root: dqn, choose action rondomly, need time 0.000280000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  148.68395996]
 [   44.73265839]
 [ 1573.57250977]
 [  154.49200439]
 [  584.48907471]
 [   44.73265839]
 [   50.89638901]
 [  339.64016724]
 [  283.29879761]
 [  657.8885498 ]
 [  847.64886475]
 [  262.41690063]
 [  154.49200439]
 [  283.29879761]
 [   50.89638901]
 [    7.76649046]]
DEBUG:root:training time = %d0.197471
INFO:root:frame =2593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =2594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000387191772461
INFO:root:frame = 2595 State into memory, numbers recorded 58 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000545024871826
INFO:root:random_action_porb = 0.993882
DEBUG:root: dqn, choose action rondomly, need time 0.000178999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2596current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:frame =2597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000394105911255
INFO:root:frame =2598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431776046753
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9938725
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.17931885e+02]
 [  7.80087036e+02]
 [  3.62882843e+02]
 [  4.93314886e+00]
 [  2.63055688e+03]
 [  3.72375757e+03]
 [  2.01504321e+03]
 [  2.05967749e+03]
 [  4.12157654e+02]
 [  3.15541809e+02]
 [  4.93314886e+00]
 [  2.16876278e+01]
 [  5.43416992e+02]
 [  4.20174316e+02]
 [  2.16876278e+01]
 [  8.81531738e+03]]
DEBUG:root:training time = %d0.219055
INFO:root:frame =2601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =2602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000245094299316
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.993863
DEBUG:root: dqn, choose action rondomly, need time 0.000171999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:frame =2605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436782836914
INFO:root:frame =2606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000502109527588
INFO:root:frame = 2607 State into memory, numbers recorded 59 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000416994094849
INFO:root:random_action_porb = 0.9938535
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2608current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.10768013e+01]
 [  4.74621484e+03]
 [  2.87069672e+02]
 [  2.89692407e+03]
 [  4.00759735e+01]
 [  9.17426819e+02]
 [  5.28541803e-01]
 [  2.44158752e+02]
 [  1.77125301e+01]
 [  9.99002136e+02]
 [  4.65189514e+02]
 [  3.53721313e+02]
 [  2.37501129e+02]
 [  5.94582581e+02]
 [  4.03146410e+00]
 [  1.88066391e+02]]
DEBUG:root:training time = %d0.190075
INFO:root:frame =2609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =2610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000502109527588
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.993844
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =2613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000487089157104
INFO:root:frame =2614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:random_action_porb = 0.9938345
DEBUG:root: dqn, choose action rondomly, need time 0.000179000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.11791077e+02]
 [  2.90263557e+01]
 [  1.04479927e+02]
 [  3.42811546e+01]
 [  3.05062866e+02]
 [  9.48024750e+01]
 [  1.88625708e+03]
 [  9.79200256e+02]
 [  5.13704796e+01]
 [  1.41966858e+01]
 [  1.65712190e+00]
 [  1.04479927e+02]
 [  2.04252747e+02]
 [  1.81408577e+01]
 [  2.40121597e+02]
 [  2.20448132e+01]]
DEBUG:root:training time = %d0.191019
INFO:root:frame =2617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =2618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484228134155
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.993825
DEBUG:root: dqn, choose action rondomly, need time 0.000291999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =2621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =2622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471830368042
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9938155
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1383.45263672]
 [  124.29148865]
 [  597.50354004]
 [  597.50354004]
 [  910.0869751 ]
 [  397.47729492]
 [  126.06654358]
 [  973.01855469]
 [  861.6270752 ]
 [   10.22055626]
 [  780.10028076]
 [  973.01855469]
 [   28.15460587]
 [  973.01855469]
 [   97.00894165]
 [   41.59163666]]
DEBUG:root:training time = %d0.213865
INFO:root:frame =2625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =2626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259876251221
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.993806
DEBUG:root: dqn, choose action rondomly, need time 0.000365000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =2629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =2630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227212905884
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9937965
DEBUG:root: dqn, choose action rondomly, need time 0.000446000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.93767773e+03]
 [  9.78745728e+02]
 [  1.33743858e+01]
 [  3.66252490e+03]
 [  2.57768188e+02]
 [  5.87969238e+02]
 [  2.80902905e+03]
 [  1.23927930e+03]
 [  2.21859951e+01]
 [  1.23927930e+03]
 [  9.71618500e+01]
 [  6.02165955e+02]
 [  6.03006661e-01]
 [  6.08320475e+00]
 [  2.21859951e+01]
 [  2.57768188e+02]]
DEBUG:root:training time = %d0.213277
INFO:root:frame =2633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:frame =2634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:random_action_porb = 0.993787
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =2637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =2638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457763671875
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9937775
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.32007828e+01]
 [  5.38231432e-03]
 [  6.20360840e+02]
 [  1.99008743e+02]
 [  1.78750241e+00]
 [  6.23631401e+01]
 [  5.19778175e+01]
 [  8.11255310e+02]
 [  1.78750241e+00]
 [  4.00577202e+01]
 [  1.54061194e+03]
 [  3.46271439e+01]
 [  1.29029160e+02]
 [  3.59645767e+01]
 [  1.82379077e+03]
 [  2.27891312e+02]]
DEBUG:root:training time = %d0.212026
INFO:root:frame =2641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =2642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255107879639
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.993768
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =2645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =2646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000416994094849
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:random_action_porb = 0.9937585
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.94868341e-03]
 [  2.58421338e+03]
 [  2.01189270e+01]
 [  9.67385498e+02]
 [  1.37438684e+03]
 [  1.87276478e+01]
 [  3.33913513e+02]
 [  5.58821023e-01]
 [  3.80383797e+01]
 [  1.53961992e+00]
 [  3.54039154e+01]
 [  8.43652710e+02]
 [  4.76444550e+01]
 [  1.87276478e+01]
 [  2.58421338e+03]
 [  1.53961992e+00]]
DEBUG:root:training time = %d0.197643
INFO:root:frame =2649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000373125076294
INFO:root:frame =2650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.993749
DEBUG:root: dqn, choose action rondomly, need time 0.000279999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000385046005249
INFO:root:frame =2653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000493049621582
INFO:root:frame =2654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.9937395
DEBUG:root: dqn, choose action rondomly, need time 0.000326000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.61032178e+03]
 [  1.36805313e+02]
 [  8.18785324e+01]
 [  7.14274883e+00]
 [  1.81979835e+00]
 [  9.14508896e+01]
 [  1.81979835e+00]
 [  9.16609883e-01]
 [  1.37292261e+03]
 [  5.11124512e+02]
 [  9.14508896e+01]
 [  8.76606201e+02]
 [  4.89818420e+01]
 [  7.14274883e+00]
 [  5.11124512e+02]
 [  1.81979835e+00]]
DEBUG:root:training time = %d0.195241
INFO:root:frame =2657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =2658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248193740845
DEBUG:root: save sample needs time = 0.000225782394409
INFO:root:random_action_porb = 0.99373
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =2661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466823577881
INFO:root:frame =2662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319957733154
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9937205
DEBUG:root: dqn, choose action rondomly, need time 0.000346
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.63040863e+02]
 [  1.89717590e+03]
 [  5.22960091e+01]
 [  1.06630455e+02]
 [  2.66663971e+02]
 [  1.12862097e+03]
 [  7.63965368e+00]
 [  5.36259270e+00]
 [  2.45977264e+02]
 [  6.75493538e-01]
 [  1.11042883e+03]
 [  4.93323700e+02]
 [  2.69256725e+01]
 [  1.12862097e+03]
 [  1.30254895e+03]
 [  2.90078552e+02]]
DEBUG:root:training time = %d0.190185
INFO:root:frame =2665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266790390015
INFO:root:frame =2666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:random_action_porb = 0.993711
DEBUG:root: dqn, choose action rondomly, need time 0.000363
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root:frame =2669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =2670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000111818313599
INFO:root:random_action_porb = 0.9937015
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000400066375732
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  122.98497009]
 [   44.35209274]
 [ 4300.70751953]
 [  187.15931702]
 [  109.23018646]
 [  307.44934082]
 [  307.44934082]
 [  261.02786255]
 [  122.98497009]
 [ 1695.62841797]
 [  277.13034058]
 [  311.7711792 ]
 [  662.11376953]
 [ 6364.12988281]
 [  228.67378235]
 [  109.23018646]]
DEBUG:root:training time = %d0.198789
INFO:root:frame =2673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:frame =2674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:random_action_porb = 0.993692
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =2677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =2678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000300884246826
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.9936825
DEBUG:root: dqn, choose action rondomly, need time 0.000178000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.30096179e+03]
 [  2.05407120e+02]
 [  4.91763926e+00]
 [  2.05407120e+02]
 [  6.06260620e+02]
 [  3.07885864e+03]
 [  1.26136284e+02]
 [  2.68637085e+00]
 [  8.29829395e-01]
 [  2.40307709e+02]
 [  5.57727600e+02]
 [  2.42679806e+01]
 [  4.97620941e+02]
 [  3.04046826e+03]
 [  3.07885864e+03]
 [  3.07885864e+03]]
DEBUG:root:training time = %d0.198961
INFO:root:frame =2681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270843505859
INFO:root:frame =2682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
DEBUG:root: save sample needs time = 0.000150918960571
INFO:root:random_action_porb = 0.993673
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =2685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =2686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000417947769165
INFO:root:frame = 2687 State into memory, numbers recorded 60 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:random_action_porb = 0.9936635
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2688current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.09763062e+03]
 [  1.09763062e+03]
 [  1.19079041e+02]
 [  2.04201294e+02]
 [  1.68364233e+03]
 [  1.68364233e+03]
 [  2.58755933e+03]
 [  4.54022675e+02]
 [  4.54022675e+02]
 [  6.18166745e-01]
 [  8.45437402e+03]
 [  2.28600044e+01]
 [  1.09763062e+03]
 [  8.58859497e+02]
 [  6.33567627e+02]
 [  4.76198137e-01]]
DEBUG:root:training time = %d0.185625
INFO:root:frame =2689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000197172164917
INFO:root:frame =2690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049877166748
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.993654
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =2693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =2694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame = 2695 State into memory, numbers recorded 61 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000540018081665
INFO:root:random_action_porb = 0.9936445
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2696current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.47893333e+00]
 [  5.23603577e+02]
 [  1.94758682e+02]
 [  1.07383167e+03]
 [  4.65780783e+00]
 [  4.01293152e+02]
 [  1.94758682e+02]
 [  4.11719627e+01]
 [  2.44422340e+01]
 [  1.26800916e+03]
 [  1.29504514e+00]
 [  2.55356918e+02]
 [  2.63882694e+01]
 [  1.98432343e+02]
 [  3.79778345e+03]
 [  5.53484375e+03]]
DEBUG:root:training time = %d0.20058
INFO:root:frame =2697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:frame =2698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237226486206
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:random_action_porb = 0.993635
DEBUG:root: dqn, choose action rondomly, need time 0.000280000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =2701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =2702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:random_action_porb = 0.9936255
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:training error  = [[  471.78015137]
 [   67.77509308]
 [   35.13984299]
 [   15.67730331]
 [   20.265522  ]
 [ 1853.18786621]
 [  819.79821777]
 [   18.52810097]
 [   22.13043785]
 [ 1208.22509766]
 [  419.75012207]
 [   11.72416592]
 [   67.77509308]
 [  315.66311646]
 [   27.30754662]
 [  189.00837708]]
DEBUG:root:training time = %d0.19805
INFO:root:frame =2705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =2706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.993616
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =2709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =2710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002281665802
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9936065
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.99697400e+03]
 [  1.41285370e+02]
 [  5.25959778e+02]
 [  8.39183140e+00]
 [  1.68272119e+03]
 [  6.38982353e+01]
 [  2.29537344e+00]
 [  5.41951074e+03]
 [  2.32611481e+02]
 [  3.40552185e+02]
 [  9.21485996e+00]
 [  4.90626282e+02]
 [  1.99697400e+03]
 [  1.40656723e+02]
 [  4.15782867e+02]
 [  1.32893152e+03]]
DEBUG:root:training time = %d0.189854
INFO:root:frame =2713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:frame =2714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428915023804
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.993597
DEBUG:root: dqn, choose action rondomly, need time 0.000351000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =2717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =2718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000199794769287
INFO:root:random_action_porb = 0.9935875
DEBUG:root: dqn, choose action rondomly, need time 0.000221999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.80137653e+01]
 [  1.07532678e+03]
 [  1.31393659e+00]
 [  1.62709122e+01]
 [  1.86653656e+02]
 [  2.63123077e+02]
 [  1.62709122e+01]
 [  1.97234766e+03]
 [  7.37909119e+02]
 [  5.61072693e+02]
 [  1.62709122e+01]
 [  4.08537407e+01]
 [  4.08537407e+01]
 [  7.99130154e+00]
 [  1.63060928e+02]
 [  2.70619507e+01]]
DEBUG:root:training time = %d0.182475
INFO:root:frame =2721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =2722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000245094299316
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:random_action_porb = 0.993578
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:frame =2725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =2726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298023223877
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.9935685
DEBUG:root: dqn, choose action rondomly, need time 0.000339000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.21819496e+00]
 [  6.84346161e+01]
 [  3.87796191e+03]
 [  5.51349592e+00]
 [  3.87796191e+03]
 [  1.00837927e-02]
 [  8.44222128e-01]
 [  1.96126294e+03]
 [  1.96126294e+03]
 [  1.08614528e+00]
 [  1.26072510e+03]
 [  1.50164200e+02]
 [  6.29210891e-03]
 [  1.50164200e+02]
 [  3.19940704e+02]
 [  7.30817200e+02]]
DEBUG:root:training time = %d0.192528
INFO:root:frame =2729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000372886657715
INFO:root:frame =2730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000398874282837
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:random_action_porb = 0.993559
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =2733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000485897064209
INFO:root:frame =2734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9935495
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  208.03450012]
 [  394.83673096]
 [   38.05287552]
 [   45.05450058]
 [   19.66824722]
 [  215.88494873]
 [  128.25727844]
 [  440.74624634]
 [  151.88523865]
 [  993.71173096]
 [   34.00404739]
 [ 5942.22998047]
 [ 4996.55859375]
 [  161.6047821 ]
 [  850.4286499 ]
 [  161.6047821 ]]
DEBUG:root:training time = %d0.206127
INFO:root:frame =2737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =2738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293016433716
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.99354
DEBUG:root: dqn, choose action rondomly, need time 0.00047
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:frame =2741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000486135482788
INFO:root:frame =2742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9935305
DEBUG:root: dqn, choose action rondomly, need time 0.000529
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  62.28989792]
 [ 175.35957336]
 [ 142.18203735]
 [ 107.98918915]
 [  91.8232193 ]
 [   0.35874498]
 [  23.9610672 ]
 [  51.10735703]
 [   1.46267653]
 [ 174.52565002]
 [ 158.71440125]
 [ 158.71440125]
 [  91.8232193 ]
 [   9.2355299 ]
 [ 103.27838898]
 [   1.36231601]]
DEBUG:root:training time = %d0.191626
INFO:root:frame =2745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =2746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319004058838
DEBUG:root: save sample needs time = 0.000174999237061
INFO:root:random_action_porb = 0.993521
DEBUG:root: dqn, choose action rondomly, need time 0.000194
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000187873840332
INFO:root:frame =2749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =2750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9935115
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.86384773e+01]
 [  1.73279053e+03]
 [  5.61619690e+02]
 [  1.39963794e+03]
 [  4.47701187e+01]
 [  2.07616547e+02]
 [  1.73279053e+03]
 [  1.05695227e+03]
 [  7.01907158e+00]
 [  1.27914066e+01]
 [  2.85141692e-02]
 [  3.84956093e+01]
 [  7.64598083e+00]
 [  1.86384773e+01]
 [  1.75240402e+01]
 [  1.43969849e+03]]
DEBUG:root:training time = %d0.181259
INFO:root:frame =2753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =2754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame = 2755 State into memory, numbers recorded 62 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000542879104614
INFO:root:random_action_porb = 0.993502
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2756current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =2757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =2758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.9934925
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.82475739e+02]
 [  1.76038000e+03]
 [  1.26558801e+03]
 [  2.08240533e+00]
 [  6.66098175e+01]
 [  6.57243500e+01]
 [  8.95775223e+00]
 [  2.82475739e+02]
 [  3.50710440e+00]
 [  6.35155663e-03]
 [  2.04592645e-02]
 [  2.67715025e+00]
 [  8.95775223e+00]
 [  3.34131569e-02]
 [  1.66958828e+01]
 [  3.43578491e+01]]
DEBUG:root:training time = %d0.206534
INFO:root:frame =2761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =2762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.993483
DEBUG:root: dqn, choose action rondomly, need time 0.000294000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =2765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =2766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
DEBUG:root: save sample needs time = 0.000108957290649
INFO:root:random_action_porb = 0.9934735
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.26640618e+00]
 [  1.20451427e+00]
 [  5.41797161e-01]
 [  3.88763733e+01]
 [  2.47767700e+02]
 [  8.81858276e+02]
 [  1.92038712e+02]
 [  6.21074638e+01]
 [  8.81858276e+02]
 [  3.88763733e+01]
 [  9.95771094e+03]
 [  9.13065910e+00]
 [  8.48826355e+02]
 [  9.75255676e+02]
 [  6.09578125e+02]
 [  1.17182112e+01]]
DEBUG:root:training time = %d0.21738
INFO:root:frame =2769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =2770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000389099121094
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:random_action_porb = 0.993464
DEBUG:root: dqn, choose action rondomly, need time 0.000217999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00018310546875
INFO:root:frame =2773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =2774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:random_action_porb = 0.9934545
DEBUG:root: dqn, choose action rondomly, need time 0.000184000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000156164169312
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  16.79544449]
 [ 340.91156006]
 [  92.30841827]
 [  26.64996338]
 [ 678.68774414]
 [ 401.37997437]
 [  35.34918976]
 [ 423.83392334]
 [  26.64996338]
 [ 271.61816406]
 [ 423.83392334]
 [  86.91075134]
 [ 204.96800232]
 [  16.80692291]
 [  19.76935005]
 [  16.42830467]]
DEBUG:root:training time = %d0.208156
INFO:root:frame =2777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =2778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.993445
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =2781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =2782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226020812988
DEBUG:root: save sample needs time = 0.000152111053467
INFO:root:random_action_porb = 0.9934355
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.49074340e+00]
 [  3.10853058e+02]
 [  4.08525705e-01]
 [  9.54536629e+00]
 [  1.19735742e+00]
 [  9.44807720e+00]
 [  1.60863101e+00]
 [  1.29119682e+01]
 [  8.96716213e+00]
 [  4.08525705e-01]
 [  4.65250580e+02]
 [  4.65250580e+02]
 [  4.66003723e+01]
 [  3.34506561e+02]
 [  8.71509075e+00]
 [  4.28933289e+02]]
DEBUG:root:training time = %d0.218418
INFO:root:frame =2785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root:frame =2786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249862670898
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.993426
DEBUG:root: dqn, choose action rondomly, need time 0.000436999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =2789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =2790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.9934165
DEBUG:root: dqn, choose action rondomly, need time 0.000499000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:training error  = [[ 1168.87597656]
 [   37.20672226]
 [    3.9800663 ]
 [   15.83022594]
 [  167.43615723]
 [ 1168.87597656]
 [    7.2412858 ]
 [   85.98277283]
 [    6.70910883]
 [   39.95792389]
 [   48.20727158]
 [   39.95792389]
 [ 1168.87597656]
 [   24.83418465]
 [  986.69616699]
 [    4.35314083]]
DEBUG:root:training time = %d0.205928
INFO:root:frame =2793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000217199325562
INFO:root:frame =2794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame = 2795 State into memory, numbers recorded 63 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:random_action_porb = 0.993407
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2796current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000280857086182
INFO:root:frame =2797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =2798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.9933975
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  219.97576904]
 [   13.91218472]
 [   64.91613007]
 [   23.84453964]
 [ 1086.03210449]
 [  795.99816895]
 [  171.96157837]
 [   64.91613007]
 [ 5203.06347656]
 [  171.2709198 ]
 [ 4549.50634766]
 [   13.91218472]
 [   15.99743652]
 [  113.32781219]
 [ 1086.03210449]
 [  809.49609375]]
DEBUG:root:training time = %d0.190249
INFO:root:frame =2801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root:frame =2802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame = 2803 State into memory, numbers recorded 64 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000531911849976
INFO:root:random_action_porb = 0.993388
DEBUG:root: dqn, choose action rondomly, need time 0.000348000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2804current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000410079956055
INFO:root:frame =2805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =2806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000391006469727
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9933785
DEBUG:root: dqn, choose action rondomly, need time 0.000271999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000382900238037
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.90380005e+02]
 [  3.58448944e+01]
 [  3.87477142e+02]
 [  2.10341187e+03]
 [  4.14668182e+02]
 [  2.47227120e+00]
 [  1.47798109e+01]
 [  1.34495173e+01]
 [  3.87477142e+02]
 [  8.71049613e-02]
 [  2.79465271e+02]
 [  1.21806669e+00]
 [  7.00368958e+01]
 [  1.92738419e+02]
 [  2.47227120e+00]
 [  3.45431689e+03]]
DEBUG:root:training time = %d0.213073
INFO:root:frame =2809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =2810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.993369
DEBUG:root: dqn, choose action rondomly, need time 0.000425
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =2813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000486850738525
INFO:root:frame =2814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9933595
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.23661642e+01]
 [  3.36110115e+01]
 [  4.43784485e+02]
 [  1.50838104e+02]
 [  2.04935253e-01]
 [  1.13610626e+02]
 [  3.10533051e+02]
 [  7.34518230e-01]
 [  3.10533051e+02]
 [  2.36307316e+01]
 [  7.81590271e+02]
 [  4.02463501e+02]
 [  1.65619095e+02]
 [  5.06338501e+02]
 [  9.68940926e+00]
 [  3.87681610e+02]]
DEBUG:root:training time = %d0.197754
INFO:root:frame =2817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =2818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259160995483
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.99335
DEBUG:root: dqn, choose action rondomly, need time 0.000323999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:frame =2821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root:frame =2822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9933405
DEBUG:root: dqn, choose action rondomly, need time 0.000250999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00028920173645
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1654.10583496]
 [    8.81809807]
 [   39.77025223]
 [   32.1390152 ]
 [  326.671875  ]
 [  818.77752686]
 [    9.99751282]
 [  272.5562439 ]
 [   17.39951324]
 [  326.671875  ]
 [    6.74186373]
 [  271.50878906]
 [  818.77752686]
 [   48.31086349]
 [  827.06402588]
 [  435.14059448]]
DEBUG:root:training time = %d0.193676
INFO:root:frame =2825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:frame =2826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.993331
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =2829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =2830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233888626099
DEBUG:root: save sample needs time = 9.58442687988e-05
INFO:root:random_action_porb = 0.9933215
DEBUG:root: dqn, choose action rondomly, need time 0.000193999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0002281665802
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.49640732e+02]
 [  5.54787350e+00]
 [  1.96402023e+02]
 [  1.40195267e+02]
 [  3.79238892e+01]
 [  3.88718224e+00]
 [  5.13589172e+02]
 [  1.33454391e+02]
 [  3.58464081e+02]
 [  3.58464081e+02]
 [  3.88718224e+00]
 [  4.32373871e+02]
 [  1.13848862e+02]
 [  1.49640732e+02]
 [  2.22353630e+01]
 [  1.10110557e+04]]
DEBUG:root:training time = %d0.200572
INFO:root:frame =2833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000364065170288
INFO:root:frame =2834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000610113143921
DEBUG:root: save sample needs time = 0.000122785568237
INFO:root:random_action_porb = 0.993312
DEBUG:root: dqn, choose action rondomly, need time 0.000165000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:frame =2837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =2838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235795974731
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:random_action_porb = 0.9933025
DEBUG:root: dqn, choose action rondomly, need time 0.000785
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.27849561e+03]
 [  1.55214310e+02]
 [  6.34978333e+02]
 [  1.81402991e+03]
 [  1.46421600e+02]
 [  8.98007202e+01]
 [  3.28918953e+01]
 [  1.69273682e+01]
 [  1.55214310e+02]
 [  1.55214310e+02]
 [  1.68333960e+00]
 [  1.68333960e+00]
 [  2.69965607e+02]
 [  1.69273682e+01]
 [  2.66744766e+01]
 [  4.39968811e+02]]
DEBUG:root:training time = %d0.185641
INFO:root:frame =2841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =2842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279188156128
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:random_action_porb = 0.993293
DEBUG:root: dqn, choose action rondomly, need time 0.000267999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =2845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =2846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255107879639
DEBUG:root: save sample needs time = 0.0001060962677
INFO:root:random_action_porb = 0.9932835
DEBUG:root: dqn, choose action rondomly, need time 0.000247000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.10543045e+02]
 [  7.64961853e+02]
 [  2.10543045e+02]
 [  3.69653229e+02]
 [  1.09509361e+02]
 [  3.98996849e+01]
 [  1.00768204e+02]
 [  2.38513367e+02]
 [  1.64148819e+02]
 [  3.06727200e+01]
 [  1.74491776e+02]
 [  1.87501099e+02]
 [  6.97350860e-01]
 [  3.66138000e+01]
 [  1.69376862e+02]
 [  1.69376862e+02]]
DEBUG:root:training time = %d0.182148
INFO:root:frame =2849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =2850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000343799591064
DEBUG:root: save sample needs time = 0.0001060962677
INFO:root:random_action_porb = 0.993274
DEBUG:root: dqn, choose action rondomly, need time 0.000188999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =2853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =2854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286817550659
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.9932645
DEBUG:root: dqn, choose action rondomly, need time 0.000182000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[    7.54911995]
 [  706.30566406]
 [  665.79052734]
 [   25.61504173]
 [  313.55300903]
 [ 6650.43554688]
 [  117.73521423]
 [   82.38520813]
 [  448.91986084]
 [ 1267.22143555]
 [   13.41022396]
 [  471.16308594]
 [  706.30566406]
 [   46.9214859 ]
 [  141.42108154]
 [ 1267.22143555]]
DEBUG:root:training time = %d0.187508
INFO:root:frame =2857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:frame =2858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279188156128
DEBUG:root: save sample needs time = 0.000177145004272
INFO:root:random_action_porb = 0.993255
DEBUG:root: dqn, choose action rondomly, need time 0.000410000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00037407875061
INFO:root:frame =2861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488996505737
INFO:root:frame =2862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.9932455
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.29131958e+02]
 [  2.33750038e+01]
 [  1.87623032e+02]
 [  7.31713379e+02]
 [  7.97035170e+00]
 [  5.68150085e+02]
 [  1.45388501e+03]
 [  7.99274597e+01]
 [  4.46689941e+02]
 [  4.26650009e+01]
 [  1.45388501e+03]
 [  1.24819824e+03]
 [  4.60516834e+00]
 [  1.61204651e+03]
 [  8.82344544e-02]
 [  1.53648239e+02]]
DEBUG:root:training time = %d0.199071
INFO:root:frame =2865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =2866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.993236
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =2869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000407934188843
INFO:root:frame =2870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000348091125488
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9932265
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000425100326538
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.09291428e+02]
 [  1.00128365e+02]
 [  2.99644348e+02]
 [  2.60491699e+02]
 [  4.66820717e+01]
 [  2.57612695e+03]
 [  1.59122971e+02]
 [  2.03834286e+01]
 [  9.20180231e-04]
 [  9.00062027e+01]
 [  1.85317688e+02]
 [  4.49399090e+00]
 [  4.40180893e+01]
 [  1.52657042e+01]
 [  4.06363457e-01]
 [  2.48455834e+00]]
DEBUG:root:training time = %d0.197279
INFO:root:frame =2873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =2874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.993217
DEBUG:root: dqn, choose action rondomly, need time 0.000219999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =2877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =2878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000296115875244
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:random_action_porb = 0.9932075
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.05410316e+02]
 [  2.29961753e+00]
 [  7.12645264e+03]
 [  6.27353943e+02]
 [  7.12645264e+03]
 [  5.82129002e+00]
 [  1.60918369e+01]
 [  2.68460541e+02]
 [  9.60047760e+01]
 [  8.94805481e+02]
 [  3.67058969e+00]
 [  1.30182785e+02]
 [  1.84001141e+01]
 [  3.50237366e+02]
 [  5.82129002e+00]
 [  1.60918369e+01]]
DEBUG:root:training time = %d0.20178
INFO:root:frame =2881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:frame =2882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000228881835938
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.993198
DEBUG:root: dqn, choose action rondomly, need time 0.000202000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:frame =2885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame =2886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:random_action_porb = 0.9931885
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  103.78733063]
 [ 1593.0970459 ]
 [ 8367.890625  ]
 [  531.53759766]
 [   81.7052002 ]
 [  163.9744873 ]
 [  290.02398682]
 [  120.98825073]
 [ 3736.53051758]
 [   48.71437454]
 [  502.57354736]
 [  218.01737976]
 [   86.47303009]
 [  117.94524384]
 [  970.41052246]
 [  290.02398682]]
DEBUG:root:training time = %d0.204985
INFO:root:frame =2889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame =2890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:random_action_porb = 0.993179
DEBUG:root: dqn, choose action rondomly, need time 0.000214
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000187158584595
INFO:root:frame =2893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =2894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00053882598877
INFO:root:frame = 2895 State into memory, numbers recorded 65 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000613927841187
INFO:root:random_action_porb = 0.9931695
DEBUG:root: dqn, choose action rondomly, need time 0.00027
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2896current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.11798592e+01]
 [  4.93671973e+03]
 [  1.13487053e+02]
 [  3.81845331e+00]
 [  9.68744751e+02]
 [  3.74766205e+02]
 [  2.32759872e+02]
 [  1.96950626e+01]
 [  9.62270737e+01]
 [  3.81845331e+00]
 [  1.91633301e+01]
 [  2.32759872e+02]
 [  7.31034994e+00]
 [  2.59760773e+02]
 [  3.03918285e+01]
 [  3.21193329e+02]]
DEBUG:root:training time = %d0.202386
INFO:root:frame =2897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:frame =2898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241041183472
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.99316
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =2901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =2902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9931505
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   74.99229431]
 [   10.11943913]
 [   29.59022331]
 [ 1376.94006348]
 [  404.99182129]
 [   64.34078217]
 [  257.58203125]
 [  794.65771484]
 [ 2568.94335938]
 [  404.99182129]
 [ 4294.83886719]
 [  221.71299744]
 [ 4966.23193359]
 [   43.35517883]
 [ 4966.23193359]
 [   76.22441864]]
DEBUG:root:training time = %d0.203004
INFO:root:frame =2905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =2906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame = 2907 State into memory, numbers recorded 66 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000560998916626
INFO:root:random_action_porb = 0.993141
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2908current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =2909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =2910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9931315
DEBUG:root: dqn, choose action rondomly, need time 0.000233000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.20599133e+03]
 [  1.41408240e+03]
 [  3.87350769e+02]
 [  3.06029987e+01]
 [  5.09595337e+02]
 [  1.76385641e-01]
 [  5.52754974e+00]
 [  4.41360092e+01]
 [  1.14548719e+00]
 [  3.42776672e+02]
 [  2.30446802e+03]
 [  5.71468735e+01]
 [  5.58696655e+02]
 [  5.12266846e+02]
 [  7.65623718e+02]
 [  7.17882309e+01]]
DEBUG:root:training time = %d0.177294
INFO:root:frame =2913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =2914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233173370361
DEBUG:root: save sample needs time = 9.10758972168e-05
INFO:root:random_action_porb = 0.993122
DEBUG:root: dqn, choose action rondomly, need time 0.000177999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:frame =2917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =2918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259876251221
DEBUG:root: save sample needs time = 9.10758972168e-05
INFO:root:random_action_porb = 0.9931125
DEBUG:root: dqn, choose action rondomly, need time 0.000159000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000130176544189
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  151.31222534]
 [    2.72041583]
 [    3.90915203]
 [  190.47840881]
 [  362.25787354]
 [   29.60807228]
 [ 1684.66992188]
 [   17.28227806]
 [  197.97207642]
 [   51.51636505]
 [  166.10015869]
 [  459.90078735]
 [ 1146.984375  ]
 [  397.63198853]
 [ 1146.984375  ]
 [  323.30548096]]
DEBUG:root:training time = %d0.203904
INFO:root:frame =2921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =2922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000296115875244
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.993103
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000607013702393
INFO:root:frame =2925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000485897064209
INFO:root:frame =2926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9930935
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.84663677e+01]
 [  8.20882511e+00]
 [  1.98557234e+00]
 [  2.84663677e+01]
 [  5.25167175e+02]
 [  7.49028076e+02]
 [  1.01900010e+04]
 [  2.92782927e+00]
 [  6.60117371e+02]
 [  4.28973828e+03]
 [  1.67869629e+02]
 [  2.77894440e+02]
 [  4.56387482e+01]
 [  7.49028076e+02]
 [  2.24237720e+03]
 [  2.24237720e+03]]
DEBUG:root:training time = %d0.220567
INFO:root:frame =2929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =2930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame = 2931 State into memory, numbers recorded 67 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000549077987671
INFO:root:random_action_porb = 0.993084
DEBUG:root: dqn, choose action rondomly, need time 0.000380999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2932current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =2933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =2934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9930745
DEBUG:root: dqn, choose action rondomly, need time 0.000169
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000137805938721
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.08429395e+03]
 [  2.09389057e+01]
 [  4.15882912e+01]
 [  3.39228333e+02]
 [  5.71683311e+01]
 [  9.37419951e-01]
 [  8.91782776e+02]
 [  1.56256775e+03]
 [  7.43347704e-02]
 [  1.75639435e+02]
 [  2.47573662e+01]
 [  1.75639435e+02]
 [  1.49486731e+03]
 [  9.60153381e+02]
 [  2.99301196e+03]
 [  3.85012460e+00]]
DEBUG:root:training time = %d0.201119
INFO:root:frame =2937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =2938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame = 2939 State into memory, numbers recorded 68 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:random_action_porb = 0.993065
DEBUG:root: dqn, choose action rondomly, need time 0.000172999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2940current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000151872634888
INFO:root:frame =2941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =2942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.9930555
DEBUG:root: dqn, choose action rondomly, need time 0.000451999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:training error  = [[  7.89526215e+01]
 [  7.77307816e+01]
 [  1.48740771e+03]
 [  5.43563721e+02]
 [  1.22027039e+02]
 [  4.27848938e+02]
 [  7.76399536e+01]
 [  1.78168076e+02]
 [  3.33672089e+02]
 [  3.27170685e+02]
 [  1.74917984e+02]
 [  2.92844751e+03]
 [  1.79662287e+00]
 [  1.79662287e+00]
 [  4.00424622e+02]
 [  1.30593765e+02]]
DEBUG:root:training time = %d0.209553
INFO:root:frame =2945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:frame =2946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000309944152832
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.993046
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =2949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000476121902466
INFO:root:frame =2950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:random_action_porb = 0.9930365
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000357151031494
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.19999611e-01]
 [  3.17788773e+01]
 [  1.89895308e+00]
 [  2.86228104e+01]
 [  1.81610535e+02]
 [  8.59183289e+02]
 [  1.09868517e+01]
 [  2.00177088e-01]
 [  3.49685547e+02]
 [  3.32074699e+01]
 [  3.32074699e+01]
 [  3.32074699e+01]
 [  3.26453613e+02]
 [  5.16605949e+01]
 [  5.14920715e+02]
 [  1.58968155e+02]]
DEBUG:root:training time = %d0.201857
INFO:root:frame =2953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =2954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000595092773438
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:random_action_porb = 0.993027
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =2957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049614906311
INFO:root:frame =2958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.9930175
DEBUG:root: dqn, choose action rondomly, need time 0.000368000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.47082443e+01]
 [  3.65969348e+00]
 [  5.82121648e-02]
 [  7.63623762e+00]
 [  1.75627731e+02]
 [  4.95376625e+01]
 [  4.34601364e+01]
 [  6.48171570e+02]
 [  2.67399597e+02]
 [  8.05446386e-01]
 [  9.28855371e+03]
 [  5.27563286e+01]
 [  1.25355501e+01]
 [  1.19337273e+02]
 [  7.63623762e+00]
 [  8.14394470e+02]]
DEBUG:root:training time = %d0.19933
INFO:root:frame =2961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =2962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275135040283
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:random_action_porb = 0.993008
DEBUG:root: dqn, choose action rondomly, need time 0.000275000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294208526611
INFO:root:frame =2965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =2966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031304359436
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:random_action_porb = 0.9929985
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[    6.32769966]
 [  208.40032959]
 [  421.88192749]
 [    8.90922642]
 [  304.09246826]
 [   10.28279877]
 [  126.16216278]
 [  273.65631104]
 [   71.09200287]
 [ 1531.81652832]
 [   30.89669228]
 [   49.78847885]
 [   17.91365242]
 [  103.78760529]
 [  306.64440918]
 [   44.3355217 ]]
DEBUG:root:training time = %d0.209582
INFO:root:frame =2969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:frame =2970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000492095947266
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.992989
DEBUG:root: dqn, choose action rondomly, need time 0.000332999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =2973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440835952759
INFO:root:frame =2974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.9929795
DEBUG:root: dqn, choose action rondomly, need time 0.000323999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:training error  = [[  3.92418335e+02]
 [  3.25006217e-01]
 [  5.67653015e+02]
 [  6.56717224e+01]
 [  3.92418335e+02]
 [  3.14002419e+01]
 [  6.56717224e+01]
 [  4.47490082e+02]
 [  5.28188372e+00]
 [  5.45903282e+01]
 [  5.45903282e+01]
 [  5.45903282e+01]
 [  2.31773145e+03]
 [  1.55364275e+01]
 [  3.92418335e+02]
 [  8.27563033e-02]]
DEBUG:root:training time = %d0.199246
INFO:root:frame =2977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =2978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:random_action_porb = 0.99297
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =2981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000487089157104
INFO:root:frame =2982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:random_action_porb = 0.9929605
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  493.32336426]
 [ 2284.12402344]
 [   17.52030373]
 [  117.50585175]
 [  376.50335693]
 [ 3323.69238281]
 [   21.51628494]
 [  368.1625061 ]
 [   88.04182434]
 [  605.41558838]
 [  117.50585175]
 [   31.20491409]
 [  999.92346191]
 [  112.24402618]
 [ 7783.53857422]
 [  259.40039062]]
DEBUG:root:training time = %d0.212138
INFO:root:frame =2985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245809555054
INFO:root:frame =2986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.992951
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =2989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000482082366943
INFO:root:frame =2990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000281810760498
INFO:root:random_action_porb = 0.9929415
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  53.60987473]
 [ 184.72180176]
 [ 303.39041138]
 [ 134.96914673]
 [ 123.8403244 ]
 [  24.21148682]
 [ 660.93341064]
 [  83.19546509]
 [  94.16677094]
 [   1.0245322 ]
 [ 339.11029053]
 [ 504.05581665]
 [  13.30914783]
 [  84.51813507]
 [  36.48944473]
 [  24.39789581]]
DEBUG:root:training time = %d0.209714
INFO:root:frame =2993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =2994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000537157058716
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.992932
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =2997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =2998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000211000442505
DEBUG:root:one frame running time = 0.006413
DEBUG:root:total training time = 51.817378
INFO:root:frame num = 3000 frame round: 0
INFO:root:random_action_porb = 0.9929225
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.04137085e+03]
 [  3.33579559e+01]
 [  8.62594795e+00]
 [  3.61109085e+01]
 [  9.73730225e+02]
 [  2.31987972e+01]
 [  1.52261017e+02]
 [  2.19863911e+01]
 [  6.12157726e+00]
 [  3.33579559e+01]
 [  7.89808197e+01]
 [  9.07980499e+01]
 [  7.89808197e+01]
 [  2.31987972e+01]
 [  2.80778259e-02]
 [  2.27136627e+02]]
DEBUG:root:training time = %d0.205199
INFO:root:frame =3001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =3002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.992913
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =3005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00064492225647
INFO:root:frame =3006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame = 3007 State into memory, numbers recorded 69 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.00035285949707
INFO:root:random_action_porb = 0.9929035
DEBUG:root: dqn, choose action rondomly, need time 0.000438000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3008current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 659.03656006]
 [ 659.03656006]
 [  11.36766815]
 [ 171.40393066]
 [ 413.33129883]
 [ 131.92771912]
 [  30.17703056]
 [  11.36766815]
 [ 131.92771912]
 [ 149.66816711]
 [ 127.44809723]
 [ 150.23750305]
 [   6.11423635]
 [  57.85731506]
 [ 659.03656006]
 [  17.09101868]]
DEBUG:root:training time = %d0.206939
INFO:root:frame =3009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =3010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000162839889526
INFO:root:random_action_porb = 0.992894
DEBUG:root: dqn, choose action rondomly, need time 0.000351999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =3013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000391960144043
INFO:root:frame =3014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000346183776855
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.9928845
DEBUG:root: dqn, choose action rondomly, need time 0.000194
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.69389252e+02]
 [  1.89754257e+01]
 [  3.31130564e-01]
 [  2.42736450e+02]
 [  3.28730896e+02]
 [  3.21691772e+02]
 [  7.14074097e+01]
 [  1.15214851e+02]
 [  2.06593666e+01]
 [  7.49782372e+00]
 [  5.81300974e+00]
 [  3.31130564e-01]
 [  5.38455820e+00]
 [  7.58836212e+01]
 [  5.15140076e+02]
 [  1.14542834e+03]]
DEBUG:root:training time = %d0.196645
INFO:root:frame =3017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304222106934
INFO:root:frame =3018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.992875
DEBUG:root: dqn, choose action rondomly, need time 0.000537999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000485897064209
INFO:root:frame =3021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000500917434692
INFO:root:frame =3022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000520944595337
DEBUG:root: save sample needs time = 0.000115871429443
INFO:root:random_action_porb = 0.9928655
DEBUG:root: dqn, choose action rondomly, need time 0.000602000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000718116760254
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.10918846e+01]
 [  1.31180668e+01]
 [  1.76346558e+03]
 [  8.44846191e+02]
 [  8.05254150e+02]
 [  1.73861267e+02]
 [  1.76346558e+03]
 [  4.97450371e+01]
 [  1.21967993e+01]
 [  2.19341442e-02]
 [  2.81999023e+03]
 [  2.67210922e+01]
 [  1.78387356e+01]
 [  3.32753448e+01]
 [  6.12165260e+00]
 [  6.12165260e+00]]
DEBUG:root:training time = %d0.200273
INFO:root:frame =3025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =3026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00034499168396
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:random_action_porb = 0.992856
INFO:root:dqn select action Tensor("ArgMax_3:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.009576
INFO:root:action choosen by dqn [1]
INFO:root:frame =3028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000186204910278
INFO:root:frame =3029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:frame =3030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00073504447937
DEBUG:root: save sample needs time = 0.000131130218506
INFO:root:random_action_porb = 0.9928465
DEBUG:root: dqn, choose action rondomly, need time 0.000384000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000255823135376
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.43221569e+00]
 [  2.39553142e+00]
 [  8.65730941e-01]
 [  4.50507317e+01]
 [  4.82785988e+01]
 [  6.41458359e+01]
 [  1.53333858e-01]
 [  6.23726135e+02]
 [  1.09839584e+02]
 [  3.89563843e+03]
 [  5.43221569e+00]
 [  5.43221569e+00]
 [  1.42667526e+02]
 [  3.35249451e+02]
 [  9.70893631e+01]
 [  2.95037866e+00]]
DEBUG:root:training time = %d0.209636
INFO:root:frame =3033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =3034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249862670898
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:random_action_porb = 0.992837
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000393867492676
INFO:root:frame =3037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000549077987671
INFO:root:frame =3038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:random_action_porb = 0.9928275
DEBUG:root: dqn, choose action rondomly, need time 0.000540000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.53286475e+03]
 [  8.52218363e-05]
 [  5.91311340e+02]
 [  8.44156265e+01]
 [  8.90649700e+00]
 [  5.65434998e+02]
 [  2.80212708e+02]
 [  2.79090729e+02]
 [  8.90649700e+00]
 [  7.04132767e+01]
 [  3.11218023e+00]
 [  2.80290103e+00]
 [  2.79090729e+02]
 [  1.69592440e+00]
 [  9.90926445e-01]
 [  3.51090027e+02]]
DEBUG:root:training time = %d0.214349
INFO:root:frame =3041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =3042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000391006469727
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.992818
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =3045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028920173645
INFO:root:frame =3046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:random_action_porb = 0.9928085
DEBUG:root: dqn, choose action rondomly, need time 0.000324999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000387191772461
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 980.18481445]
 [  52.43999863]
 [ 893.59906006]
 [  47.06274796]
 [   7.70076036]
 [ 145.62614441]
 [ 201.65940857]
 [ 619.11029053]
 [ 149.41906738]
 [  92.40395355]
 [ 386.08560181]
 [ 142.12928772]
 [   4.57959747]
 [   4.57959747]
 [ 215.35705566]
 [   7.70076036]]
DEBUG:root:training time = %d0.208116
INFO:root:frame =3049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =3050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.992799
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =3053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =3054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.9927895
DEBUG:root: dqn, choose action rondomly, need time 0.000176000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.05184570e+03]
 [  1.25241173e+02]
 [  1.60005646e+01]
 [  8.02535594e-01]
 [  3.33635283e+00]
 [  1.72145081e+02]
 [  5.55802490e+02]
 [  3.57963028e+01]
 [  2.11481953e+01]
 [  5.55802490e+02]
 [  2.91147060e+01]
 [  1.75889801e+02]
 [  3.04268330e-01]
 [  9.58433688e-01]
 [  4.18152283e+02]
 [  1.23496370e+01]]
DEBUG:root:training time = %d0.194517
INFO:root:frame =3057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =3058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486135482788
DEBUG:root: save sample needs time = 0.000174999237061
INFO:root:random_action_porb = 0.99278
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =3061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00048303604126
INFO:root:frame =3062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000608921051025
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.9927705
DEBUG:root: dqn, choose action rondomly, need time 0.000331000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.01284752e+01]
 [  5.53139353e+00]
 [  3.38828230e+00]
 [  3.28002129e+01]
 [  3.36207449e-07]
 [  5.40861267e+02]
 [  1.85065811e+02]
 [  1.44167700e+03]
 [  2.37540215e-01]
 [  3.38828230e+00]
 [  5.75823584e+03]
 [  1.42477676e+02]
 [  5.53139353e+00]
 [  3.01284752e+01]
 [  2.12406030e+03]
 [  8.20977356e+02]]
DEBUG:root:training time = %d0.215613
INFO:root:frame =3065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =3066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000284910202026
DEBUG:root: save sample needs time = 0.000126838684082
INFO:root:random_action_porb = 0.992761
DEBUG:root: dqn, choose action rondomly, need time 0.000188999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000186920166016
INFO:root:frame =3069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =3070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491142272949
DEBUG:root: save sample needs time = 0.000263214111328
INFO:root:random_action_porb = 0.9927515
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.21106199e-04]
 [  3.27638672e+02]
 [  4.50090302e+02]
 [  9.33737671e+02]
 [  3.55193701e+03]
 [  8.54530096e-01]
 [  3.55193701e+03]
 [  1.55557831e+02]
 [  2.81929951e+01]
 [  1.42163122e-02]
 [  3.10307892e+02]
 [  1.14143738e+02]
 [  2.37395973e+01]
 [  1.41080868e+00]
 [  3.10307892e+02]
 [  6.79734039e+01]]
DEBUG:root:training time = %d0.199492
INFO:root:frame =3073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275850296021
INFO:root:frame =3074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.992742
DEBUG:root: dqn, choose action rondomly, need time 0.000188000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root:frame =3077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000482082366943
INFO:root:frame =3078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00055193901062
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:random_action_porb = 0.9927325
DEBUG:root: dqn, choose action rondomly, need time 0.000294000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 235.2015686 ]
 [  13.69215107]
 [ 985.6774292 ]
 [ 148.62870789]
 [   3.54725289]
 [  22.25572205]
 [  23.623703  ]
 [  32.51316833]
 [  24.53888893]
 [   7.11570644]
 [  21.14658165]
 [ 100.5375061 ]
 [ 273.58007812]
 [  26.07921219]
 [  21.14658165]
 [  50.76403427]]
DEBUG:root:training time = %d0.20791
INFO:root:frame =3081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =3082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000281095504761
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:random_action_porb = 0.992723
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =3085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =3086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025200843811
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.9927135
DEBUG:root: dqn, choose action rondomly, need time 0.000177999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 116.00870514]
 [  72.99378967]
 [ 153.48249817]
 [   2.01382804]
 [  80.14038086]
 [ 222.44700623]
 [ 250.21711731]
 [ 153.48249817]
 [ 250.21711731]
 [ 153.48249817]
 [   2.81411743]
 [ 104.00733185]
 [  41.77881622]
 [   8.73683834]
 [ 130.57524109]
 [ 104.00733185]]
DEBUG:root:training time = %d0.198693
INFO:root:frame =3089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:frame =3090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000289916992188
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.992704
DEBUG:root: dqn, choose action rondomly, need time 0.000323999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =3093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471830368042
INFO:root:frame =3094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509023666382
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9926945
DEBUG:root: dqn, choose action rondomly, need time 0.000363999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.01748535e+02]
 [  2.03150094e-01]
 [  6.17189169e+00]
 [  6.03000122e+02]
 [  6.03000122e+02]
 [  2.03150094e-01]
 [  6.45580978e+01]
 [  3.98986282e+01]
 [  1.25178366e+01]
 [  3.58002716e+02]
 [  3.95674706e+01]
 [  8.18705273e+00]
 [  5.25192017e+02]
 [  6.03000122e+02]
 [  2.03150094e-01]
 [  1.00272253e+03]]
DEBUG:root:training time = %d0.198357
INFO:root:frame =3097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:frame =3098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
DEBUG:root: save sample needs time = 0.0001060962677
INFO:root:random_action_porb = 0.992685
DEBUG:root: dqn, choose action rondomly, need time 0.000264000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =3101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =3102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249147415161
DEBUG:root: save sample needs time = 0.00010085105896
INFO:root:random_action_porb = 0.9926755
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  231.64657593]
 [   78.92062378]
 [  625.4708252 ]
 [  231.64657593]
 [ 2039.96032715]
 [  159.60491943]
 [ 2039.96032715]
 [   38.76932144]
 [  317.84558105]
 [  471.81677246]
 [ 2039.96032715]
 [   54.89571762]
 [  212.55198669]
 [ 1022.30444336]
 [  136.83406067]
 [  195.40060425]]
DEBUG:root:training time = %d0.194769
INFO:root:frame =3105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:frame =3106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000116109848022
INFO:root:random_action_porb = 0.992666
DEBUG:root: dqn, choose action rondomly, need time 0.000329000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =3109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame =3110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.9926565
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 296.26312256]
 [ 689.18505859]
 [  13.65014744]
 [ 808.66973877]
 [   9.69399261]
 [  33.48392487]
 [   1.23460937]
 [ 653.44299316]
 [   6.5306778 ]
 [ 848.33581543]
 [ 848.33581543]
 [  27.58237076]
 [ 126.05625916]
 [ 141.55828857]
 [ 416.09500122]
 [ 404.60177612]]
DEBUG:root:training time = %d0.200127
INFO:root:frame =3113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:frame =3114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.992647
DEBUG:root: dqn, choose action rondomly, need time 0.000883999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =3117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =3118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000290870666504
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.9926375
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.55246811e+01]
 [  4.88381006e+03]
 [  5.12739563e+01]
 [  9.79608688e+01]
 [  2.86838696e+03]
 [  1.77200256e+03]
 [  8.55246811e+01]
 [  1.61156235e+02]
 [  2.13302326e+00]
 [  1.25620127e+00]
 [  8.35647156e+02]
 [  1.86363373e+02]
 [  5.79159973e+02]
 [  1.67058655e+02]
 [  7.99094558e-01]
 [  2.20893250e+01]]
DEBUG:root:training time = %d0.1892
INFO:root:frame =3121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =3122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.992628
DEBUG:root: dqn, choose action rondomly, need time 0.000174999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000150918960571
INFO:root:frame =3125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000475883483887
INFO:root:frame =3126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.9926185
DEBUG:root: dqn, choose action rondomly, need time 0.000413000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000411987304688
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.23316193e+00]
 [  1.45587358e+01]
 [  7.18197823e-01]
 [  3.74402390e+01]
 [  2.50608047e+02]
 [  1.50586334e+02]
 [  4.24734375e+02]
 [  3.02410095e+02]
 [  4.49142933e-01]
 [  1.46595354e+01]
 [  1.58772075e+00]
 [  1.27517737e+03]
 [  5.94128845e+02]
 [  1.87748511e+03]
 [  1.58772075e+00]
 [  1.93994770e+01]]
DEBUG:root:training time = %d0.210437
INFO:root:frame =3129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =3130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:random_action_porb = 0.992609
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =3133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029182434082
INFO:root:frame =3134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.9925995
DEBUG:root: dqn, choose action rondomly, need time 0.000321
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.21508728e+02]
 [  9.54426944e-01]
 [  3.21508728e+02]
 [  2.05159637e+02]
 [  4.79369125e+01]
 [  4.14258301e+02]
 [  1.21270889e+02]
 [  4.79369125e+01]
 [  3.76114648e+03]
 [  4.79369125e+01]
 [  2.08756668e+02]
 [  8.76779480e+01]
 [  8.68910522e+01]
 [  1.37360931e+02]
 [  7.13562842e+03]
 [  5.38728498e-02]]
DEBUG:root:training time = %d0.206376
INFO:root:frame =3137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =3138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000375986099243
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.99259
DEBUG:root: dqn, choose action rondomly, need time 0.000362000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =3141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =3142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.9925805
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.87577979e+03]
 [  3.02016846e+02]
 [  6.06902527e+02]
 [  1.19649426e+03]
 [  1.11872816e+00]
 [  3.71634674e+01]
 [  8.00547256e+01]
 [  7.67884207e+00]
 [  3.02016846e+02]
 [  6.14660225e+01]
 [  4.02659424e+02]
 [  3.71634674e+01]
 [  1.47276443e+02]
 [  4.79196787e+00]
 [  1.14328413e+01]
 [  2.85427246e+02]]
DEBUG:root:training time = %d0.211447
INFO:root:frame =3145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =3146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241041183472
DEBUG:root: save sample needs time = 9.20295715332e-05
INFO:root:random_action_porb = 0.992571
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000158071517944
INFO:root:frame =3149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =3150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:random_action_porb = 0.9925615
DEBUG:root: dqn, choose action rondomly, need time 0.000328000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000352144241333
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  351.94540405]
 [  576.99945068]
 [  218.05838013]
 [   30.95176125]
 [ 1438.06518555]
 [  207.90950012]
 [  207.90950012]
 [   16.03859711]
 [  985.11602783]
 [   51.0373497 ]
 [  961.23840332]
 [  143.34230042]
 [   21.3039093 ]
 [   30.77594757]
 [ 1008.36340332]
 [   63.57942963]]
DEBUG:root:training time = %d0.198218
INFO:root:frame =3153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =3154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000266075134277
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.992552
DEBUG:root: dqn, choose action rondomly, need time 0.000371999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =3157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000580787658691
INFO:root:frame =3158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494956970215
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.9925425
DEBUG:root: dqn, choose action rondomly, need time 0.000483000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000374794006348
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.33896851e+02]
 [  1.88438110e+03]
 [  4.00067676e+03]
 [  1.86648849e+02]
 [  4.38708153e+01]
 [  9.80446594e+02]
 [  5.01400232e+00]
 [  1.89171612e+00]
 [  3.62234222e+02]
 [  1.39275909e+02]
 [  6.61592712e+01]
 [  1.55633240e+01]
 [  2.12867279e+01]
 [  1.95331711e+02]
 [  1.33896851e+02]
 [  3.43068008e+01]]
DEBUG:root:training time = %d0.197498
INFO:root:frame =3161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =3162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031304359436
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:random_action_porb = 0.992533
DEBUG:root: dqn, choose action rondomly, need time 0.000318999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =3165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000475168228149
INFO:root:frame =3166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000492095947266
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.9925235
DEBUG:root: dqn, choose action rondomly, need time 0.000379000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320196151733
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 220.73301697]
 [ 318.20993042]
 [ 414.97354126]
 [ 404.19522095]
 [ 297.58093262]
 [  33.77229691]
 [   5.51636267]
 [  85.45751953]
 [  88.87815094]
 [ 441.75012207]
 [   2.43364   ]
 [ 441.75012207]
 [ 459.89257812]
 [ 113.70563507]
 [  33.43621826]
 [  33.30932617]]
DEBUG:root:training time = %d0.197823
INFO:root:frame =3169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root:frame =3170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000244140625
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.992514
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =3173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000590085983276
INFO:root:frame =3174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464200973511
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.9925045
DEBUG:root: dqn, choose action rondomly, need time 0.000188000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000172138214111
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  728.96624756]
 [  604.93060303]
 [   27.93432808]
 [   38.92338943]
 [  561.4909668 ]
 [  490.86764526]
 [   30.39822197]
 [ 3558.828125  ]
 [  107.25137329]
 [   57.10005188]
 [  639.29205322]
 [   27.93432808]
 [  607.60864258]
 [  324.58721924]
 [   30.39822197]
 [  271.25491333]]
DEBUG:root:training time = %d0.209934
INFO:root:frame =3177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:frame =3178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000251054763794
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.992495
DEBUG:root: dqn, choose action rondomly, need time 0.000377999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000414133071899
INFO:root:frame =3181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000571966171265
INFO:root:frame =3182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277996063232
DEBUG:root: save sample needs time = 0.000165224075317
INFO:root:random_action_porb = 0.9924855
DEBUG:root: dqn, choose action rondomly, need time 0.000336000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.70000610e+01]
 [  5.69135857e+01]
 [  2.58314301e+02]
 [  6.11402245e+01]
 [  1.87943359e+02]
 [  8.87408218e+01]
 [  1.59533405e+00]
 [  5.59582336e+02]
 [  1.16296339e+01]
 [  2.59542176e-05]
 [  2.70206958e+03]
 [  1.44333130e+02]
 [  3.47703285e+01]
 [  4.12365387e+02]
 [  2.35814047e+00]
 [  2.31547966e+01]]
DEBUG:root:training time = %d0.207225
INFO:root:frame =3185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:frame =3186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.992476
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =3189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =3190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:random_action_porb = 0.9924665
DEBUG:root: dqn, choose action rondomly, need time 0.000343999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.10146469e+02]
 [  4.95976868e+02]
 [  4.68484863e+03]
 [  3.07365479e+03]
 [  5.32158852e-01]
 [  1.42685747e+00]
 [  3.04381123e+01]
 [  4.33030516e-01]
 [  9.40521484e+02]
 [  9.78872553e-03]
 [  2.84179871e+02]
 [  1.83818713e+03]
 [  6.61367798e+02]
 [  7.42544189e+02]
 [  1.05058441e+01]
 [  1.60789566e+02]]
DEBUG:root:training time = %d0.206415
INFO:root:frame =3193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =3194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293016433716
DEBUG:root: save sample needs time = 0.000125885009766
INFO:root:random_action_porb = 0.992457
DEBUG:root: dqn, choose action rondomly, need time 0.000181999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174999237061
INFO:root:frame =3197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =3198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000474214553833
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.9924475
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000488996505737
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:***************************check point loaded*******************************************
INFO:root:training error  = [[  4.33801880e+02]
 [  4.33801880e+02]
 [  1.34105938e+05]
 [  8.96447983e+01]
 [  9.84747543e+01]
 [  2.15395825e+03]
 [  9.84747543e+01]
 [  2.15395825e+03]
 [  2.59721934e+04]
 [  4.10679169e+02]
 [  3.29700220e+03]
 [  1.07036592e+04]
 [  1.33245825e+03]
 [  6.21792542e+02]
 [  3.31196523e+04]
 [  8.96447983e+01]]
DEBUG:root:training time = %d0.42585
INFO:root:frame =3201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:frame =3202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.992438
DEBUG:root: dqn, choose action rondomly, need time 0.000340999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =3205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047779083252
INFO:root:frame =3206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00048303604126
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.9924285
DEBUG:root: dqn, choose action rondomly, need time 0.000577999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000488042831421
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.17540635e+04]
 [  2.02125996e+04]
 [  3.39613739e+02]
 [  5.26172668e+02]
 [  5.61400859e+04]
 [  1.00539594e+03]
 [  5.25293945e+02]
 [  6.65107227e+03]
 [  4.28935945e-01]
 [  9.63748627e+01]
 [  7.48834106e+02]
 [  1.22876746e+03]
 [  4.04146729e+03]
 [  4.12033142e+02]
 [  4.46431641e+02]
 [  7.30851013e+02]]
DEBUG:root:training time = %d0.198841
INFO:root:frame =3209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =3210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.992419
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =3213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =3214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000510931015015
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.9924095
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 33886.0546875 ]
 [   204.97564697]
 [  1554.92834473]
 [   115.90229797]
 [ 35905.1015625 ]
 [    81.85642242]
 [  2623.07519531]
 [ 33886.0546875 ]
 [  1124.17053223]
 [  8858.06835938]
 [ 34560.69140625]
 [ 23517.1875    ]
 [ 23517.1875    ]
 [  1663.26403809]
 [   598.25366211]
 [    53.28594971]]
DEBUG:root:training time = %d0.224101
INFO:root:frame =3217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =3218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000370025634766
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9924
DEBUG:root: dqn, choose action rondomly, need time 0.000343999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =3221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =3222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.9923905
DEBUG:root: dqn, choose action rondomly, need time 0.000220000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 6724.00488281]
 [  199.75709534]
 [  353.078125  ]
 [  431.82913208]
 [  979.54193115]
 [  689.59112549]
 [  376.19268799]
 [ 4553.30273438]
 [ 1614.24853516]
 [ 1007.20904541]
 [  349.3536377 ]
 [  199.75709534]
 [  199.75709534]
 [  376.19268799]
 [  207.74040222]
 [  726.21862793]]
DEBUG:root:training time = %d0.198771
INFO:root:frame =3225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =3226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root:random_action_porb = 0.992381
DEBUG:root: dqn, choose action rondomly, need time 0.000197
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =3229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =3230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame = 3231 State into memory, numbers recorded 70 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000617027282715
INFO:root:random_action_porb = 0.9923715
DEBUG:root: dqn, choose action rondomly, need time 0.000416000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root: ememy has been killed for 7 times 
INFO:root:enemies_left [0]
INFO:root:frame =3232current_observation done, NOT record action 2, reward = 255
DEBUG:root: save sample needs time = 0.000351905822754
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.78910089e+00]
 [  9.52568176e+02]
 [  5.58031738e+02]
 [  2.08367754e+04]
 [  2.89301709e+03]
 [  9.99786250e+04]
 [  6.50372500e+04]
 [  3.49170532e+02]
 [  1.39827240e+02]
 [  2.89301709e+03]
 [  9.33494727e+03]
 [  4.35226465e+03]
 [  1.44919995e+03]
 [  1.92909561e+02]
 [  1.80118750e+03]
 [  7.45478439e+01]]
DEBUG:root:training time = %d0.214154
INFO:root:frame =3233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =3234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame = 3235 State into memory, numbers recorded 71 action = 2, reward = 255
DEBUG:root: save sample needs time = 0.000602960586548
INFO:root:random_action_porb = 0.992362
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3236current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =3237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000480175018311
INFO:root:frame =3238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000607013702393
DEBUG:root: save sample needs time = 0.000110149383545
INFO:root:random_action_porb = 0.9923525
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000229835510254
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.64007263e+02]
 [  7.28493604e+03]
 [  1.57975684e+03]
 [  5.36885010e+03]
 [  9.08731079e+02]
 [  1.64222126e+01]
 [  1.64007263e+02]
 [  5.10474426e+02]
 [  9.56896680e+03]
 [  9.56896680e+03]
 [  6.19400208e+02]
 [  9.39441490e+00]
 [  2.82843555e+04]
 [  2.24680138e+01]
 [  3.24448315e+03]
 [  2.08067566e+02]]
DEBUG:root:training time = %d0.213384
INFO:root:frame =3241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =3242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame = 3243 State into memory, numbers recorded 72 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000655889511108
INFO:root:random_action_porb = 0.992343
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3244current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =3245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =3246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000760078430176
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.9923335
DEBUG:root: dqn, choose action rondomly, need time 0.000405000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00049614906311
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.12199878e+03]
 [  1.00767148e+04]
 [  5.59322949e+03]
 [  2.59403086e+00]
 [  2.76189362e+02]
 [  9.41300964e+00]
 [  1.02790092e+02]
 [  1.80647773e+04]
 [  2.76189362e+02]
 [  2.15742920e+03]
 [  6.10850281e+02]
 [  6.00835986e+03]
 [  2.13775986e+02]
 [  6.09973755e+02]
 [  9.41300964e+00]
 [  1.04584326e+03]]
DEBUG:root:training time = %d0.19994
INFO:root:frame =3249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =3250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.992324
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =3253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =3254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000383853912354
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.9923145
DEBUG:root: dqn, choose action rondomly, need time 0.000189000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.14093140e+02]
 [  9.26238574e+03]
 [  6.60788393e+00]
 [  1.35971222e+01]
 [  2.26690765e+02]
 [  1.17808643e+04]
 [  1.98522072e+01]
 [  7.76957245e+01]
 [  5.69228516e+01]
 [  3.02014435e+02]
 [  1.75567688e+03]
 [  9.33010788e+01]
 [  3.84014606e+00]
 [  5.57991504e+03]
 [  1.35971222e+01]
 [  1.38573778e+00]]
DEBUG:root:training time = %d0.218527
INFO:root:frame =3257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =3258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.992305
DEBUG:root: dqn, choose action rondomly, need time 0.000307999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =3261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =3262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame = 3263 State into memory, numbers recorded 73 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000572204589844
INFO:root:random_action_porb = 0.9922955
DEBUG:root: dqn, choose action rondomly, need time 0.000332999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3264current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000385999679565
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.87785461e+02]
 [  4.30051680e+04]
 [  5.55099487e+02]
 [  1.85322464e-02]
 [  8.41001968e+01]
 [  1.07504063e+01]
 [  4.64646959e+00]
 [  2.04395776e+03]
 [  4.30418777e+01]
 [  1.79270984e+03]
 [  1.12449665e+01]
 [  1.85322464e-02]
 [  1.05060646e+02]
 [  2.45519196e+02]
 [  6.99634229e+03]
 [  4.30418777e+01]]
DEBUG:root:training time = %d0.21543
INFO:root:frame =3265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =3266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
INFO:root:frame = 3267 State into memory, numbers recorded 74 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000564098358154
INFO:root:random_action_porb = 0.992286
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3268current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =3269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000416994094849
INFO:root:frame =3270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9922765
DEBUG:root: dqn, choose action rondomly, need time 0.000321
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.15667754e+04]
 [  2.37661377e+03]
 [  4.60303268e+01]
 [  2.18559122e+00]
 [  5.06766052e+02]
 [  7.09673730e+03]
 [  1.93719234e+01]
 [  2.15667754e+04]
 [  2.18559122e+00]
 [  1.35431995e+03]
 [  2.25373691e+04]
 [  1.70580119e-01]
 [  5.06766052e+02]
 [  1.34144053e+04]
 [  3.50423145e+03]
 [  2.26014862e+02]]
DEBUG:root:training time = %d0.220552
INFO:root:frame =3273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:frame =3274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249862670898
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.992267
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =3277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000481843948364
INFO:root:frame =3278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.9922575
DEBUG:root: dqn, choose action rondomly, need time 0.000161000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.86056946e+02]
 [  1.87428385e-01]
 [  6.90589539e+02]
 [  7.29161453e+01]
 [  8.86056946e+02]
 [  1.81894989e+02]
 [  1.13555336e+02]
 [  1.71416919e+03]
 [  3.35336035e+03]
 [  8.29621460e+02]
 [  5.76659082e+03]
 [  4.97546234e+02]
 [  2.53989136e+03]
 [  1.13994589e+01]
 [  7.35826874e+01]
 [  2.69931488e+02]]
DEBUG:root:training time = %d0.206676
INFO:root:frame =3281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =3282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000115871429443
INFO:root:random_action_porb = 0.992248
DEBUG:root: dqn, choose action rondomly, need time 0.000196000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root:frame =3285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =3286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.9922385
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.42380188e+02]
 [  4.13035088e+01]
 [  5.32561035e+02]
 [  1.78056482e+03]
 [  8.85195410e+03]
 [  3.25018823e+03]
 [  1.58652393e+04]
 [  4.13035088e+01]
 [  6.36175049e+02]
 [  2.15004913e+02]
 [  4.44561432e+02]
 [  3.04355359e+00]
 [  6.22550537e+02]
 [  6.36175049e+02]
 [  3.04355359e+00]
 [  8.85195410e+03]]
DEBUG:root:training time = %d0.204122
INFO:root:frame =3289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =3290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248908996582
DEBUG:root: save sample needs time = 0.000125169754028
INFO:root:random_action_porb = 0.992229
DEBUG:root: dqn, choose action rondomly, need time 0.000174000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000156879425049
INFO:root:frame =3293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =3294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264167785645
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.9922195
DEBUG:root: dqn, choose action rondomly, need time 0.000185000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000181913375854
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.58545761e+02]
 [  2.94860083e+03]
 [  3.15927291e+00]
 [  1.89646091e+01]
 [  3.54889131e+00]
 [  2.94860083e+03]
 [  2.68797729e+03]
 [  5.95057715e+03]
 [  5.85076318e+03]
 [  2.14927222e+03]
 [  1.19583870e+02]
 [  6.36658945e+04]
 [  1.80415273e-01]
 [  1.59617981e+02]
 [  1.01767540e+02]
 [  4.64169922e+01]]
DEBUG:root:training time = %d0.212928
INFO:root:frame =3297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =3298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000310897827148
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.99221
DEBUG:root: dqn, choose action rondomly, need time 0.000388999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:frame =3301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =3302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9922005
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.48243797e+00]
 [  5.31906992e+04]
 [  6.69627953e+00]
 [  9.35891663e+02]
 [  4.04413128e+00]
 [  9.35891663e+02]
 [  9.64541016e+02]
 [  5.11818390e+02]
 [  6.69627953e+00]
 [  4.18582535e+00]
 [  1.43369336e+03]
 [  9.64541016e+02]
 [  2.50870502e-03]
 [  4.82329407e+01]
 [  6.69627953e+00]
 [  1.17403717e+02]]
DEBUG:root:training time = %d0.190716
INFO:root:frame =3305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =3306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.992191
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =3309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00044584274292
INFO:root:frame =3310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9921815
DEBUG:root: dqn, choose action rondomly, need time 0.000170000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.51203110e+02]
 [  1.23751111e+03]
 [  3.15855664e+03]
 [  1.52138806e+03]
 [  1.48464079e+01]
 [  5.59934753e+02]
 [  2.65675240e+01]
 [  2.65675240e+01]
 [  7.23938049e+02]
 [  1.22459480e+02]
 [  5.46256775e+02]
 [  3.35387329e+02]
 [  2.14388931e+02]
 [  9.97642365e+01]
 [  1.93513135e+03]
 [  1.46768928e-01]]
DEBUG:root:training time = %d0.195371
INFO:root:frame =3313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =3314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000242948532104
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.992172
DEBUG:root: dqn, choose action rondomly, need time 0.000180999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:frame =3317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =3318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.9921625
DEBUG:root: dqn, choose action rondomly, need time 0.000325000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.28424180e+04]
 [  3.75135791e+03]
 [  3.47430511e+02]
 [  1.73854095e+02]
 [  1.28111038e+02]
 [  8.45973434e+01]
 [  1.81727173e+03]
 [  6.28424180e+04]
 [  5.05170508e+03]
 [  3.16932172e-01]
 [  8.21822643e+00]
 [  1.81727173e+03]
 [  1.99553691e+04]
 [  2.56613008e+04]
 [  5.34814160e+03]
 [  6.28424180e+04]]
DEBUG:root:training time = %d0.205895
INFO:root:frame =3321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =3322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.992153
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =3325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =3326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:random_action_porb = 0.9921435
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.34757137e+00]
 [  3.59182148e+04]
 [  8.19004541e+03]
 [  7.47420532e+02]
 [  2.68899170e+03]
 [  7.47420532e+02]
 [  4.34757137e+00]
 [  6.93673248e+01]
 [  3.41112757e+00]
 [  3.71161011e+03]
 [  4.29805156e+04]
 [  8.57888336e+01]
 [  5.88090637e+02]
 [  1.05153076e+02]
 [  1.33049911e+02]
 [  4.51214905e+02]]
DEBUG:root:training time = %d0.200948
INFO:root:frame =3329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =3330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.992134
DEBUG:root: dqn, choose action rondomly, need time 0.000174000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:frame =3333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =3334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9921245
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.07406799e+02]
 [  6.79928589e+01]
 [  1.61565881e+03]
 [  5.81261253e+01]
 [  2.86944668e+04]
 [  2.62721039e+02]
 [  2.67739453e+03]
 [  1.01513248e-02]
 [  5.73115479e+02]
 [  5.07406799e+02]
 [  2.67739453e+03]
 [  3.53072876e+02]
 [  5.35448189e+01]
 [  8.55438672e+03]
 [  4.75035919e+02]
 [  4.48254004e+03]]
DEBUG:root:training time = %d0.20366
INFO:root:frame =3337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =3338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000313997268677
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.992115
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =3341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000514984130859
INFO:root:frame =3342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.9921055
DEBUG:root: dqn, choose action rondomly, need time 0.000336000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.73825952e+03]
 [  1.18403052e+03]
 [  2.25014019e+00]
 [  1.76221301e+03]
 [  2.57061182e+03]
 [  1.31962732e+03]
 [  5.08367062e+00]
 [  1.73825952e+03]
 [  9.86469238e+02]
 [  1.25720968e+01]
 [  3.55566406e+02]
 [  4.19733203e+03]
 [  3.12993336e+01]
 [  7.08745178e+02]
 [  1.25720968e+01]
 [  1.00409656e+03]]
DEBUG:root:training time = %d0.209061
INFO:root:frame =3345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:frame =3346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame = 3347 State into memory, numbers recorded 75 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000575065612793
INFO:root:random_action_porb = 0.992096
DEBUG:root: dqn, choose action rondomly, need time 0.000537999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3348current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =3349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =3350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.9920865
DEBUG:root: dqn, choose action rondomly, need time 0.000242999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.90787613e+02]
 [  3.75554047e+01]
 [  3.64964638e+01]
 [  1.47255392e+01]
 [  4.36819305e+02]
 [  3.76842749e+03]
 [  3.76842749e+03]
 [  1.68763031e+02]
 [  3.52725716e+01]
 [  6.31081238e+02]
 [  7.77329102e+02]
 [  3.76842749e+03]
 [  1.61429902e+04]
 [  1.53934723e+02]
 [  7.77329102e+02]
 [  6.20723438e+00]]
DEBUG:root:training time = %d0.213342
INFO:root:frame =3353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =3354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.992077
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =3357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =3358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9920675
DEBUG:root: dqn, choose action rondomly, need time 0.000247999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.05357870e-01]
 [  9.82647324e+01]
 [  1.52971216e+03]
 [  8.34588965e+03]
 [  6.15642334e+02]
 [  5.05207178e+03]
 [  1.07528620e+01]
 [  3.36333313e+01]
 [  4.67147278e+02]
 [  6.40802813e+00]
 [  3.56484528e+01]
 [  1.66114769e+01]
 [  7.29764648e+02]
 [  3.56484528e+01]
 [  5.70139465e+02]
 [  1.76561084e+03]]
DEBUG:root:training time = %d0.20504
INFO:root:frame =3361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =3362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000243186950684
DEBUG:root: save sample needs time = 9.51290130615e-05
INFO:root:random_action_porb = 0.992058
DEBUG:root: dqn, choose action rondomly, need time 0.000176999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:frame =3365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =3366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:random_action_porb = 0.9920485
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.62471252e+02]
 [  1.74582947e+02]
 [  1.58958607e+01]
 [  4.97183591e-01]
 [  1.90872900e+03]
 [  5.54001045e+01]
 [  1.93530918e+04]
 [  1.60553674e+03]
 [  9.02062607e+01]
 [  1.93530918e+04]
 [  3.18095239e+03]
 [  4.97183591e-01]
 [  4.50373291e+02]
 [  5.48982056e+02]
 [  2.07598066e+00]
 [  1.30760742e+02]]
DEBUG:root:training time = %d0.19654
INFO:root:frame =3369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =3370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:random_action_porb = 0.992039
DEBUG:root: dqn, choose action rondomly, need time 0.000228000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:frame =3373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000497102737427
INFO:root:frame =3374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.00013279914856
INFO:root:random_action_porb = 0.9920295
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.77990586e+04]
 [  5.81511378e-01]
 [  1.28660166e+04]
 [  1.73116821e+02]
 [  4.52083887e+03]
 [  1.20371890e+00]
 [  1.86415558e+01]
 [  3.82139551e+03]
 [  7.16756363e+01]
 [  2.60854297e+03]
 [  6.75111115e-01]
 [  7.16756363e+01]
 [  3.09179858e+03]
 [  1.29177515e+03]
 [  1.62958557e+03]
 [  1.29177515e+03]]
DEBUG:root:training time = %d0.199888
INFO:root:frame =3377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame =3378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000346899032593
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.99202
DEBUG:root: dqn, choose action rondomly, need time 0.000324000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =3381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00048303604126
INFO:root:frame =3382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9920105
DEBUG:root: dqn, choose action rondomly, need time 0.000318000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.06371460e+02]
 [  5.12466895e+03]
 [  7.99341455e+03]
 [  8.79931450e+00]
 [  7.67856018e+02]
 [  3.36800909e+00]
 [  1.59214282e+03]
 [  1.78440140e+02]
 [  7.03164990e+03]
 [  2.22623975e+03]
 [  4.98433075e+02]
 [  4.42138519e+02]
 [  8.87076111e+02]
 [  2.93089331e+03]
 [  3.36800909e+00]
 [  7.67856018e+02]]
DEBUG:root:training time = %d0.200626
INFO:root:frame =3385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =3386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.992001
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root:frame =3389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =3390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9919915
DEBUG:root: dqn, choose action rondomly, need time 0.000327999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.90274121e+03]
 [  7.09877380e+02]
 [  1.23520105e+03]
 [  9.96220551e+01]
 [  7.72116852e+01]
 [  3.38745392e+02]
 [  1.68379617e+00]
 [  1.37943481e+02]
 [  4.78898712e+02]
 [  3.30803467e+02]
 [  1.11408432e+02]
 [  8.34514746e+03]
 [  5.35316406e+03]
 [  4.92594659e-01]
 [  1.34298462e+02]
 [  3.56663757e+02]]
DEBUG:root:training time = %d0.214073
INFO:root:frame =3393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:frame =3394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:random_action_porb = 0.991982
DEBUG:root: dqn, choose action rondomly, need time 0.000211999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:frame =3397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000480890274048
INFO:root:frame =3398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000531911849976
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:random_action_porb = 0.9919725
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.15137646e+03]
 [  6.60160461e+02]
 [  5.74369873e+03]
 [  6.49178101e+02]
 [  1.14184135e+02]
 [  7.52298355e+01]
 [  3.51985626e+02]
 [  3.34113306e+03]
 [  6.77291992e+02]
 [  8.84962320e-01]
 [  1.09020532e+03]
 [  6.48361921e+00]
 [  9.53920105e+02]
 [  4.85300391e+04]
 [  5.74369873e+03]
 [  2.48333420e+02]]
DEBUG:root:training time = %d0.198671
INFO:root:frame =3401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:frame =3402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.991963
DEBUG:root: dqn, choose action rondomly, need time 0.000316000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =3405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =3406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000126838684082
INFO:root:random_action_porb = 0.9919535
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.41158691e+03]
 [  1.47436462e+02]
 [  1.26841040e+03]
 [  3.25368628e+03]
 [  4.55483704e+02]
 [  7.02362000e+02]
 [  2.40813892e+03]
 [  6.09373516e+04]
 [  7.02362000e+02]
 [  3.99193408e+03]
 [  9.48048477e+01]
 [  1.47436462e+02]
 [  1.03318968e+01]
 [  4.82106201e+02]
 [  6.19439850e+01]
 [  1.61388580e+02]]
DEBUG:root:training time = %d0.193183
INFO:root:frame =3409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:frame =3410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.991944
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =3413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =3414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9919345
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13637.04785156]
 [    26.78989601]
 [  5437.81689453]
 [   786.35162354]
 [   863.9185791 ]
 [   628.56195068]
 [   363.3237915 ]
 [   299.60351562]
 [  1596.86865234]
 [    44.22566605]
 [   215.65414429]
 [  1411.4630127 ]
 [   241.85646057]
 [  3533.33569336]
 [   411.74295044]
 [   863.9185791 ]]
DEBUG:root:training time = %d0.198946
INFO:root:frame =3417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:frame =3418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229120254517
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.991925
DEBUG:root: dqn, choose action rondomly, need time 0.000169
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000151872634888
INFO:root:frame =3421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =3422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000105142593384
INFO:root:random_action_porb = 0.9919155
DEBUG:root: dqn, choose action rondomly, need time 0.000197
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.87467313e+00]
 [  5.98597839e+02]
 [  3.91367073e+01]
 [  1.93394070e+01]
 [  5.19639549e+01]
 [  4.97046204e+01]
 [  3.88364160e+03]
 [  1.15349209e+00]
 [  1.04491514e+04]
 [  1.05085154e+01]
 [  2.08089844e+02]
 [  2.88556159e-01]
 [  3.91367073e+01]
 [  1.02987122e+03]
 [  1.04468291e+04]
 [  4.68590759e+02]]
DEBUG:root:training time = %d0.208111
INFO:root:frame =3425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259160995483
INFO:root:frame =3426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.991906
DEBUG:root: dqn, choose action rondomly, need time 0.000212000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:frame =3429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00048303604126
INFO:root:frame =3430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247001647949
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.9918965
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   89.71300507]
 [  944.8840332 ]
 [  239.11283875]
 [  711.18463135]
 [  227.28762817]
 [ 3559.18359375]
 [ 1501.90075684]
 [ 1149.39526367]
 [   56.53997803]
 [  682.66833496]
 [  389.35342407]
 [   56.53997803]
 [   23.53870392]
 [  389.35342407]
 [ 3436.93994141]
 [   23.53870392]]
DEBUG:root:training time = %d0.212954
INFO:root:frame =3433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =3434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000285148620605
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.991887
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =3437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =3438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470161437988
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9918775
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.19162158e+03]
 [  3.54136536e+02]
 [  1.64158447e+02]
 [  3.22749186e+00]
 [  3.54136536e+02]
 [  1.71135345e+02]
 [  2.85567505e+02]
 [  3.81064534e+00]
 [  7.78566360e+01]
 [  6.41670990e+01]
 [  2.20452133e+02]
 [  3.22749186e+00]
 [  1.14049125e+00]
 [  6.62321396e+01]
 [  2.85567505e+02]
 [  1.64158447e+02]]
DEBUG:root:training time = %d0.203607
INFO:root:frame =3441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261783599854
INFO:root:frame =3442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:player has been killed for 6 times 
INFO:root:frame =3444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000173807144165
INFO:root:frame =3445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =3446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame = 3447 State into memory, numbers recorded 76 action = 4, reward = -255
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:random_action_porb = 0.991868
DEBUG:root: dqn, choose action rondomly, need time 0.000158999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3448current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000156879425049
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.39517197e+02]
 [  5.86080225e+03]
 [  9.15419312e+01]
 [  8.68468933e+01]
 [  1.99560095e+03]
 [  1.14596903e+00]
 [  1.85163177e+02]
 [  7.69648242e+03]
 [  6.82214294e+02]
 [  2.31479683e+01]
 [  1.73183487e+02]
 [  3.36571617e+01]
 [  5.47663460e+01]
 [  7.42337280e+02]
 [  2.50259842e+02]
 [  3.06071436e+03]]
DEBUG:root:training time = %d0.195387
INFO:root:frame =3449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =3450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000570058822632
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.9918585
DEBUG:root: dqn, choose action rondomly, need time 0.000156000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:frame =3453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =3454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000346899032593
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.991849
DEBUG:root: dqn, choose action rondomly, need time 0.000179000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.67818642e+00]
 [  3.76792084e+02]
 [  5.94830322e+01]
 [  1.41725952e+03]
 [  2.40232129e+04]
 [  9.62101758e+03]
 [  3.80352356e+02]
 [  2.87594967e+01]
 [  2.87594967e+01]
 [  9.49054733e-02]
 [  3.93741602e+03]
 [  4.14538037e+03]
 [  1.32450417e-01]
 [  4.14490204e+01]
 [  1.51403770e+01]
 [  4.83357324e+03]]
DEBUG:root:training time = %d0.198703
INFO:root:frame =3457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =3458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000507116317749
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.9918395
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =3461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =3462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000199794769287
INFO:root:random_action_porb = 0.99183
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.63236359e+02]
 [  1.09058325e+03]
 [  2.18494189e+03]
 [  2.41142151e+02]
 [  4.51867714e+01]
 [  2.25789307e+02]
 [  5.81401901e+01]
 [  2.54793579e+03]
 [  4.56077271e+01]
 [  5.81401901e+01]
 [  6.89748779e+02]
 [  3.97724727e+04]
 [  1.09058325e+03]
 [  3.59579444e-01]
 [  2.71372533e+00]
 [  1.14133704e+03]]
DEBUG:root:training time = %d0.231219
INFO:root:frame =3465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:frame =3466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231981277466
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.9918205
DEBUG:root: dqn, choose action rondomly, need time 0.000161000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:frame =3469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =3470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame = 3471 State into memory, numbers recorded 77 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000726938247681
INFO:root:random_action_porb = 0.991811
DEBUG:root: dqn, choose action rondomly, need time 0.000405000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3472current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.31110693e+03]
 [  4.04721802e+02]
 [  4.48429230e+02]
 [  3.36768628e+03]
 [  9.18013477e+03]
 [  3.60812073e+01]
 [  2.49487519e+00]
 [  9.18013477e+03]
 [  5.01454878e+00]
 [  1.38897995e+02]
 [  8.11601746e+02]
 [  6.80819702e+02]
 [  1.41735544e+01]
 [  2.02832298e+01]
 [  2.94751596e+00]
 [  4.56493927e+02]]
DEBUG:root:training time = %d0.216855
INFO:root:frame =3473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =3474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466823577881
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9918015
DEBUG:root: dqn, choose action rondomly, need time 0.000326999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =3477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =3478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 0.0001060962677
INFO:root:random_action_porb = 0.991792
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.05481812e+02]
 [  1.40994543e+03]
 [  1.55100048e-01]
 [  8.57545624e+01]
 [  2.16844215e+01]
 [  6.67649512e+03]
 [  1.31243267e+01]
 [  6.76747742e+01]
 [  1.46149931e+01]
 [  2.42180222e+02]
 [  1.73699341e+02]
 [  6.67649512e+03]
 [  2.16844215e+01]
 [  1.02893860e+03]
 [  3.74874438e+03]
 [  1.46149931e+01]]
DEBUG:root:training time = %d0.200265
INFO:root:frame =3481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:frame =3482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293016433716
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9917825
DEBUG:root: dqn, choose action rondomly, need time 0.000331000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =3485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433206558228
INFO:root:frame =3486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456809997559
DEBUG:root: save sample needs time = 0.000147819519043
INFO:root:random_action_porb = 0.991773
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   493.78695679]
 [    19.48291969]
 [  3635.71777344]
 [   880.9730835 ]
 [  1097.65234375]
 [  1097.65234375]
 [  3803.99047852]
 [ 10921.42382812]
 [   308.88305664]
 [  4249.10498047]
 [  2805.67626953]
 [   239.55722046]
 [ 10921.42382812]
 [   105.26967621]
 [   418.70458984]
 [  4736.05371094]]
DEBUG:root:training time = %d0.202511
INFO:root:frame =3489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000414848327637
INFO:root:frame =3490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000295877456665
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:random_action_porb = 0.9917635
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =3493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =3494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.991754
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.21159883e+04]
 [  2.47623577e+01]
 [  2.82987854e+02]
 [  3.17938354e+02]
 [  3.58439789e+01]
 [  1.13638487e+01]
 [  1.58668655e+02]
 [  5.02883514e+02]
 [  9.86628151e+00]
 [  1.11145554e+01]
 [  2.84017220e+01]
 [  2.42173433e-01]
 [  2.16917358e+03]
 [  6.26917603e+02]
 [  1.00974066e+03]
 [  6.89018066e+02]]
DEBUG:root:training time = %d0.20343
INFO:root:frame =3497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:frame =3498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00023889541626
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.9917445
DEBUG:root: dqn, choose action rondomly, need time 0.000162000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:frame =3501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488042831421
INFO:root:frame =3502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049901008606
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.991735
DEBUG:root: dqn, choose action rondomly, need time 0.000323000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.91618210e+02]
 [  8.34539509e+00]
 [  4.66571381e+02]
 [  1.06555510e+01]
 [  1.57881262e+03]
 [  7.48009033e+02]
 [  1.58956707e+00]
 [  2.82861719e+03]
 [  3.26439185e+03]
 [  9.47009863e+03]
 [  1.44210083e+03]
 [  8.05621567e+01]
 [  3.43369690e+02]
 [  2.23610234e+04]
 [  1.38391187e+03]
 [  1.12153191e+02]]
DEBUG:root:training time = %d0.209198
INFO:root:frame =3505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =3506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.9917255
DEBUG:root: dqn, choose action rondomly, need time 0.000185999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000156879425049
INFO:root:frame =3509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:frame =3510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.991716
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.59717480e+03]
 [  1.68105377e+02]
 [  1.00979408e+02]
 [  2.53813940e+03]
 [  1.10646650e+04]
 [  8.44458008e+00]
 [  1.62599060e+02]
 [  1.47696797e+04]
 [  2.31607886e+03]
 [  7.99101074e+02]
 [  1.50968103e+03]
 [  5.31634521e+02]
 [  1.68105377e+02]
 [  8.66303558e+01]
 [  9.17169476e+00]
 [  1.54947662e+02]]
DEBUG:root:training time = %d0.212424
INFO:root:frame =3513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:frame =3514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.9917065
DEBUG:root: dqn, choose action rondomly, need time 0.000330000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =3517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000576019287109
INFO:root:frame =3518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.991697
DEBUG:root: dqn, choose action rondomly, need time 0.000332999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.77896833e-01]
 [  1.46007458e+03]
 [  1.36075048e+01]
 [  3.00124512e+02]
 [  1.16605377e+00]
 [  1.28407059e+01]
 [  3.62783447e+02]
 [  6.39157776e+02]
 [  1.03661613e+02]
 [  1.08553735e+03]
 [  5.34729064e-01]
 [  3.88057544e+03]
 [  1.28407059e+01]
 [  2.27039478e+03]
 [  1.36075048e+01]
 [  1.72573962e+03]]
DEBUG:root:training time = %d0.202989
INFO:root:frame =3521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =3522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.9916875
DEBUG:root: dqn, choose action rondomly, need time 0.000169999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:frame =3525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =3526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 0.000108003616333
INFO:root:random_action_porb = 0.991678
DEBUG:root: dqn, choose action rondomly, need time 0.000165999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000131130218506
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.66861534e+00]
 [  1.32397278e+03]
 [  1.32397278e+03]
 [  2.43617878e+01]
 [  9.44320068e+01]
 [  2.29078339e+02]
 [  1.04507507e+03]
 [  2.29078339e+02]
 [  3.49245758e+02]
 [  1.66570093e+03]
 [  2.49004507e+00]
 [  2.57273193e+02]
 [  4.66861534e+00]
 [  1.03469973e+01]
 [  4.62562370e-04]
 [  1.64713593e+01]]
DEBUG:root:training time = %d0.216483
INFO:root:frame =3529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =3530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:random_action_porb = 0.9916685
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =3533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000481128692627
INFO:root:frame =3534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:random_action_porb = 0.991659
DEBUG:root: dqn, choose action rondomly, need time 0.000158999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.70000820e+01]
 [  3.23291351e+02]
 [  1.86104824e+04]
 [  5.39325439e+02]
 [  1.21991980e+00]
 [  4.98283863e+00]
 [  4.09522949e+03]
 [  3.99781372e+02]
 [  2.71828194e+01]
 [  6.96343470e+00]
 [  6.79224060e+02]
 [  3.23291351e+02]
 [  4.81067467e+00]
 [  7.36889551e+03]
 [  1.47259460e+02]
 [  3.30669746e+01]]
DEBUG:root:training time = %d0.220422
INFO:root:frame =3537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:frame =3538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000191926956177
INFO:root:random_action_porb = 0.9916495
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:frame =3541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:frame =3542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
DEBUG:root: save sample needs time = 0.000206232070923
INFO:root:random_action_porb = 0.99164
DEBUG:root: dqn, choose action rondomly, need time 0.000576000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.76792358e+02]
 [  3.58434677e+00]
 [  1.12644629e+03]
 [  3.20406914e+00]
 [  1.65302408e+00]
 [  1.65302408e+00]
 [  2.25897314e+03]
 [  4.82893066e+03]
 [  1.91039062e+03]
 [  9.20993729e+01]
 [  6.76986633e+02]
 [  4.03280304e+02]
 [  1.03711800e+02]
 [  2.62893585e+02]
 [  2.49413345e+02]
 [  2.63192596e+02]]
DEBUG:root:training time = %d0.202268
INFO:root:frame =3545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =3546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:random_action_porb = 0.9916305
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =3549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000508069992065
INFO:root:frame =3550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000451803207397
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.991621
DEBUG:root: dqn, choose action rondomly, need time 0.000170999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000141859054565
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.47382660e+01]
 [  2.08093052e+01]
 [  1.97906763e+03]
 [  1.30449696e+01]
 [  3.89548035e+02]
 [  2.73933777e+02]
 [  4.19290558e+02]
 [  1.50991821e+03]
 [  1.62605881e+02]
 [  3.95699646e+02]
 [  2.15169678e+02]
 [  4.89886383e+02]
 [  7.33648062e+00]
 [  1.23140845e+03]
 [  3.62636268e-01]
 [  8.17484314e+02]]
DEBUG:root:training time = %d0.20754
INFO:root:frame =3553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =3554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233888626099
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9916115
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000351905822754
INFO:root:frame =3557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =3558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame = 3559 State into memory, numbers recorded 78 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000838994979858
INFO:root:random_action_porb = 0.991602
DEBUG:root: dqn, choose action rondomly, need time 0.000205999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3560current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4435.484375  ]
 [  250.85424805]
 [   57.74294662]
 [  775.02862549]
 [   90.4283905 ]
 [ 1323.83117676]
 [  551.17297363]
 [  188.73960876]
 [   22.23881721]
 [  422.17126465]
 [  794.39581299]
 [  205.48454285]
 [  551.17297363]
 [  451.91275024]
 [ 5361.29150391]
 [  446.82345581]]
DEBUG:root:training time = %d0.219445
INFO:root:frame =3561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000196218490601
INFO:root:frame =3562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000292062759399
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:random_action_porb = 0.9915925
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =3565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =3566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:random_action_porb = 0.991583
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.29854736e+02]
 [  2.78404938e+02]
 [  6.46686935e+00]
 [  1.25989766e+04]
 [  4.36732483e+01]
 [  2.40708105e+03]
 [  4.29853859e+01]
 [  2.54965652e+02]
 [  1.23383312e+01]
 [  9.37521744e+00]
 [  5.60912451e+03]
 [  1.57802994e+02]
 [  3.29854736e+02]
 [  1.57802994e+02]
 [  2.51099121e+02]
 [  1.89593063e+02]]
DEBUG:root:training time = %d0.22031
INFO:root:frame =3569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:frame =3570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:random_action_porb = 0.9915735
DEBUG:root: dqn, choose action rondomly, need time 0.000547999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =3573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000536918640137
INFO:root:frame =3574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000393152236938
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.991564
DEBUG:root: dqn, choose action rondomly, need time 0.000368999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333786010742
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  858.32745361]
 [ 1034.60083008]
 [  170.13470459]
 [  284.95440674]
 [    6.83401966]
 [  429.00045776]
 [ 1034.60083008]
 [  104.77694702]
 [ 1034.60083008]
 [  495.73596191]
 [    1.35456192]
 [   30.76151657]
 [  517.30444336]
 [   29.3419857 ]
 [  392.96734619]
 [  858.32745361]]
DEBUG:root:training time = %d0.199493
INFO:root:frame =3577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =3578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264883041382
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.9915545
DEBUG:root: dqn, choose action rondomly, need time 0.000326000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =3581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =3582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000648975372314
DEBUG:root: save sample needs time = 0.000107049942017
INFO:root:random_action_porb = 0.991545
DEBUG:root: dqn, choose action rondomly, need time 0.000179000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000188112258911
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.73585632e+02]
 [  3.23606055e+03]
 [  4.93361778e+01]
 [  1.78487991e+02]
 [  3.08016016e+03]
 [  5.64960876e+02]
 [  1.67852783e+03]
 [  8.95806026e+00]
 [  7.41261414e+02]
 [  6.88103760e+02]
 [  3.99374056e+00]
 [  9.86621704e+01]
 [  6.65613365e+00]
 [  2.07291885e+02]
 [  5.04240572e-01]
 [  2.07291885e+02]]
DEBUG:root:training time = %d0.211225
INFO:root:frame =3585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:frame =3586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231981277466
DEBUG:root: save sample needs time = 0.000116109848022
INFO:root:random_action_porb = 0.9915355
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =3589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =3590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.991526
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:training error  = [[  1.88444165e+03]
 [  7.73076233e+02]
 [  2.71055328e+02]
 [  7.52879000e+00]
 [  3.89738464e+02]
 [  2.71055328e+02]
 [  1.00808142e+03]
 [  1.20862103e+01]
 [  1.59008453e+02]
 [  4.37047668e+02]
 [  2.19977969e+04]
 [  2.22502425e-02]
 [  4.12363818e+03]
 [  3.89738464e+02]
 [  5.01270752e+03]
 [  1.25442228e+01]]
DEBUG:root:training time = %d0.22736
INFO:root:frame =3593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:frame =3594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000228881835938
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.9915165
DEBUG:root: dqn, choose action rondomly, need time 0.000324000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root:frame =3597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =3598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.991507
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  684.01782227]
 [ 2957.26049805]
 [  136.73890686]
 [ 3073.37939453]
 [   12.32726574]
 [  536.07733154]
 [  367.00167847]
 [  168.27209473]
 [   10.92382145]
 [ 6659.58056641]
 [  276.95065308]
 [   62.13840103]
 [   71.26641846]
 [ 2182.61889648]
 [ 7821.78808594]
 [  197.1031189 ]]
DEBUG:root:training time = %d0.202418
INFO:root:frame =3601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =3602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
DEBUG:root: save sample needs time = 0.000126838684082
INFO:root:random_action_porb = 0.9914975
DEBUG:root: dqn, choose action rondomly, need time 0.000195000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000187158584595
INFO:root:frame =3605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =3606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.991488
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326156616211
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.67941055e+02]
 [  4.40127411e+02]
 [  2.04646699e+04]
 [  3.26967798e+03]
 [  2.67793457e+03]
 [  1.42914948e+02]
 [  1.49285477e+02]
 [  3.98792572e+01]
 [  2.59042871e+03]
 [  2.55926001e+03]
 [  2.67793457e+03]
 [  1.00886658e+02]
 [  1.49285477e+02]
 [  1.13908257e+02]
 [  8.00913715e+00]
 [  1.06682694e+00]]
DEBUG:root:training time = %d0.202179
INFO:root:frame =3609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =3610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000415086746216
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9914785
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330209732056
INFO:root:frame =3613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =3614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.991469
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.58383557e+03]
 [  5.12060165e+01]
 [  4.43050537e+01]
 [  3.93801575e+01]
 [  1.55770102e+01]
 [  1.70923924e+00]
 [  1.55632690e+03]
 [  2.90073586e+01]
 [  6.51547119e+02]
 [  5.12060165e+01]
 [  3.32933884e+01]
 [  1.37066376e+00]
 [  2.90361237e+02]
 [  1.55770102e+01]
 [  6.51547119e+02]
 [  5.12567505e+02]]
DEBUG:root:training time = %d0.208871
INFO:root:frame =3617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:frame =3618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9914595
DEBUG:root: dqn, choose action rondomly, need time 0.000368999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =3621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =3622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:random_action_porb = 0.99145
DEBUG:root: dqn, choose action rondomly, need time 0.000168000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000158071517944
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.81509638e+00]
 [  2.61569751e+03]
 [  4.55324554e+01]
 [  2.92630363e+00]
 [  2.54869824e+03]
 [  1.35754716e+00]
 [  1.80054581e+02]
 [  4.92924170e+03]
 [  9.02960840e+03]
 [  1.31799102e+00]
 [  4.59863377e+00]
 [  2.92630363e+00]
 [  7.81509638e+00]
 [  7.61023499e+02]
 [  2.88711090e+01]
 [  4.79324226e+01]]
DEBUG:root:training time = %d0.185327
INFO:root:frame =3625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =3626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9914405
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =3629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000546216964722
INFO:root:frame =3630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.991431
DEBUG:root: dqn, choose action rondomly, need time 0.000326999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.60164452e+00]
 [  1.31522357e+00]
 [  6.66393089e+00]
 [  2.38335510e+02]
 [  1.69131737e-02]
 [  4.35467529e+02]
 [  1.75245190e+03]
 [  3.43507552e+00]
 [  6.22647559e+03]
 [  9.15280396e+02]
 [  8.29452344e+03]
 [  1.26756601e+01]
 [  4.11849030e+02]
 [  3.11769116e+03]
 [  7.22636819e-01]
 [  1.63434662e+02]]
DEBUG:root:training time = %d0.221375
INFO:root:frame =3633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =3634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.9914215
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =3637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =3638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:random_action_porb = 0.991412
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 8128.87304688]
 [  421.09561157]
 [ 7647.80908203]
 [  516.49041748]
 [  131.34729004]
 [ 1029.66162109]
 [  372.89013672]
 [  257.52642822]
 [  870.46362305]
 [  577.65423584]
 [  257.52642822]
 [ 2697.12988281]
 [  242.11637878]
 [  102.00222778]
 [  811.90911865]
 [   12.17131615]]
DEBUG:root:training time = %d0.199181
INFO:root:frame =3641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =3642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.9914025
DEBUG:root: dqn, choose action rondomly, need time 0.000197
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root:frame =3645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:frame =3646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294208526611
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.991393
DEBUG:root: dqn, choose action rondomly, need time 0.000338999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.66202606e+02]
 [  3.99661133e+03]
 [  1.37421021e+02]
 [  3.03641968e+03]
 [  4.21895081e+02]
 [  1.19320935e+03]
 [  7.57020187e+00]
 [  6.82355785e+00]
 [  4.03460078e+04]
 [  7.26893082e+01]
 [  1.02304125e+01]
 [  5.04965771e+03]
 [  1.86202049e+01]
 [  6.82355785e+00]
 [  1.69009800e+01]
 [  4.10787811e+01]]
DEBUG:root:training time = %d0.217848
INFO:root:frame =3649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =3650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame = 3651 State into memory, numbers recorded 79 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:random_action_porb = 0.9913835
DEBUG:root: dqn, choose action rondomly, need time 0.000170999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3652current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000135183334351
INFO:root:frame =3653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =3654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame = 3655 State into memory, numbers recorded 80 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000627994537354
INFO:root:random_action_porb = 0.991374
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3656current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.54752002e+03]
 [  5.04612198e+01]
 [  1.50093975e+04]
 [  8.43505859e+01]
 [  2.68989531e+04]
 [  1.13328406e+03]
 [  7.57955246e+01]
 [  2.23572731e+01]
 [  2.23572731e+01]
 [  2.93913354e+03]
 [  1.20728325e+02]
 [  2.02460434e+02]
 [  6.93916992e+02]
 [  8.74787629e-01]
 [  2.21161682e+02]
 [  2.02460434e+02]]
DEBUG:root:training time = %d0.187652
INFO:root:frame =3657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000327825546265
INFO:root:frame =3658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:player has been killed for 7 times 
INFO:root:frame = 3659 State into memory, numbers recorded 81 action = None, reward = -255
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.9913645
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3660current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =3661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =3662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.991355
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.81698847e-01]
 [  4.74259473e+03]
 [  3.29577393e+02]
 [  7.76745117e+02]
 [  8.61434082e+02]
 [  7.42564774e+00]
 [  1.12608301e+03]
 [  2.99190015e+03]
 [  3.29036475e+03]
 [  1.86075281e+03]
 [  1.55924658e+03]
 [  4.64223114e+02]
 [  1.96410681e+03]
 [  7.10486206e+02]
 [  1.45286328e+03]
 [  2.59433794e+00]]
DEBUG:root:training time = %d0.204397
INFO:root:frame =3665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:frame =3666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241041183472
DEBUG:root: save sample needs time = 9.20295715332e-05
INFO:root:random_action_porb = 0.9913455
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =3669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =3670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470876693726
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.991336
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.06958875e+03]
 [  2.08762894e+02]
 [  2.62434967e+02]
 [  3.14990942e+03]
 [  9.73034668e+00]
 [  9.53852722e+02]
 [  3.11608398e+02]
 [  7.03249435e+01]
 [  2.76697144e+02]
 [  4.03014570e-01]
 [  1.77221813e+01]
 [  2.06048608e+03]
 [  5.27400146e+02]
 [  5.27400146e+02]
 [  8.93599167e+01]
 [  3.79459724e+01]]
DEBUG:root:training time = %d0.211103
INFO:root:frame =3673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002281665802
INFO:root:frame =3674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000502109527588
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9913265
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000359058380127
INFO:root:frame =3677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =3678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509977340698
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:random_action_porb = 0.991317
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330209732056
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.12150488e+03]
 [  2.97509164e-01]
 [  2.48669682e+01]
 [  3.52772751e+01]
 [  3.25215546e+02]
 [  6.66662048e+02]
 [  2.48669682e+01]
 [  1.12398628e+02]
 [  2.39345215e+03]
 [  2.82491772e+03]
 [  4.62818384e+00]
 [  8.81381653e+02]
 [  4.62818384e+00]
 [  1.83058325e+03]
 [  9.57403243e-01]
 [  1.63967171e+01]]
DEBUG:root:training time = %d0.224409
INFO:root:frame =3681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =3682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000227212905884
INFO:root:random_action_porb = 0.9913075
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294208526611
INFO:root:frame =3685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =3686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:random_action_porb = 0.991298
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.66405016e-02]
 [  3.83881226e+03]
 [  2.33169613e+01]
 [  1.54869431e+02]
 [  2.37120636e+02]
 [  2.89602075e+03]
 [  1.15143591e+03]
 [  5.53099442e+00]
 [  1.70213464e+03]
 [  3.83881226e+03]
 [  1.24505409e+02]
 [  8.21001434e+01]
 [  9.54005188e+02]
 [  4.67351532e+01]
 [  9.31592083e+00]
 [  8.57554565e+02]]
DEBUG:root:training time = %d0.19341
INFO:root:frame =3689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =3690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000270843505859
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9912885
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =3693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000476837158203
INFO:root:frame =3694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.991279
DEBUG:root: dqn, choose action rondomly, need time 0.000202999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000194787979126
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.01888855e+02]
 [  2.27597013e-01]
 [  1.28985437e+03]
 [  1.69736061e+01]
 [  1.29033704e+03]
 [  5.63835449e+01]
 [  5.63835449e+01]
 [  7.12105942e+01]
 [  1.81663803e+02]
 [  1.45289317e-01]
 [  5.63835449e+01]
 [  3.54137939e+03]
 [  3.77925563e+00]
 [  3.60516919e+03]
 [  7.12383438e+04]
 [  1.69736061e+01]]
DEBUG:root:training time = %d0.194722
INFO:root:frame =3697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:frame =3698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000354766845703
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.9912695
DEBUG:root: dqn, choose action rondomly, need time 0.000340999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =3701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =3702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.99126
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.43085669e+03]
 [  1.06246997e+03]
 [  3.93233008e+03]
 [  1.80426240e+00]
 [  2.18125562e+03]
 [  1.24634228e+01]
 [  2.50779236e+02]
 [  1.59573837e+02]
 [  1.70216568e+02]
 [  4.95975830e+03]
 [  3.97615265e+02]
 [  2.53394485e+00]
 [  7.51688995e+01]
 [  5.04912354e+02]
 [  3.59626343e+03]
 [  5.71442184e+01]]
DEBUG:root:training time = %d0.210136
INFO:root:frame =3705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261783599854
INFO:root:frame =3706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.9912505
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000388145446777
INFO:root:frame =3709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000476121902466
INFO:root:frame =3710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.991241
DEBUG:root: dqn, choose action rondomly, need time 0.000311999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:training error  = [[  2.84769177e+00]
 [  1.08276543e+02]
 [  3.79615664e+00]
 [  3.58890747e+02]
 [  4.04963989e+01]
 [  1.95355505e+03]
 [  1.75508276e+03]
 [  1.40245743e+01]
 [  9.20918655e+00]
 [  1.30345234e+04]
 [  1.06076489e+03]
 [  9.20918655e+00]
 [  5.14692688e+02]
 [  1.75508276e+03]
 [  4.95558319e+02]
 [  4.78077454e+02]]
DEBUG:root:training time = %d0.217322
INFO:root:frame =3713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =3714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:random_action_porb = 0.9912315
DEBUG:root: dqn, choose action rondomly, need time 0.000248999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174999237061
INFO:root:frame =3717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =3718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494003295898
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.991222
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.91642647e+01]
 [  3.47984595e+03]
 [  8.79673279e+02]
 [  4.81762598e+03]
 [  7.57848755e+02]
 [  1.74373462e+03]
 [  1.76349609e+02]
 [  3.89929922e+04]
 [  2.71916797e+03]
 [  1.38963623e+03]
 [  8.62665400e-02]
 [  2.34488190e+02]
 [  2.68769913e+01]
 [  2.19455600e+00]
 [  1.98482654e+03]
 [  7.57848755e+02]]
DEBUG:root:training time = %d0.208484
INFO:root:frame =3721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =3722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9912125
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =3725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441789627075
INFO:root:frame =3726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.991203
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.42492218e+01]
 [  1.06762943e+01]
 [  9.24820801e+03]
 [  6.83234930e+00]
 [  4.62493807e-01]
 [  2.00136612e+02]
 [  1.27876959e+01]
 [  8.05901550e+02]
 [  1.06762943e+01]
 [  8.01843452e+00]
 [  3.18612915e+02]
 [  1.30466858e+02]
 [  7.64951294e+02]
 [  9.34240845e+02]
 [  6.22492432e+02]
 [  6.89057678e+02]]
DEBUG:root:training time = %d0.194457
INFO:root:frame =3729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:frame =3730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9911935
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =3733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00048303604126
INFO:root:frame =3734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame = 3735 State into memory, numbers recorded 82 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000632047653198
INFO:root:random_action_porb = 0.991184
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3736current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000325202941895
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.85770798e+02]
 [  9.23500595e+01]
 [  1.84196252e+03]
 [  8.25093460e+01]
 [  3.36620392e+02]
 [  9.09163025e+02]
 [  2.20088634e+01]
 [  1.84196252e+03]
 [  7.27213144e-01]
 [  2.55767896e+03]
 [  8.07826416e+02]
 [  1.16972168e+03]
 [  6.95953796e+02]
 [  7.28837967e+01]
 [  8.25093460e+01]
 [  1.06077759e+03]]
DEBUG:root:training time = %d0.213864
INFO:root:frame =3737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:frame =3738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000295877456665
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.9911745
DEBUG:root: dqn, choose action rondomly, need time 0.000197999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000183820724487
INFO:root:frame =3741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =3742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame = 3743 State into memory, numbers recorded 83 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000355958938599
INFO:root:random_action_porb = 0.991165
DEBUG:root: dqn, choose action rondomly, need time 0.000191999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3744current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3201.71020508]
 [ 1032.46716309]
 [ 3120.51269531]
 [   80.22238159]
 [   83.44777679]
 [  240.05090332]
 [   10.34721756]
 [ 2497.09399414]
 [  171.15750122]
 [   83.44777679]
 [  694.65917969]
 [ 1125.65930176]
 [  152.66967773]
 [  723.79193115]
 [ 1378.33447266]
 [ 2466.82446289]]
DEBUG:root:training time = %d0.215605
INFO:root:frame =3745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =3746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:random_action_porb = 0.9911555
DEBUG:root: dqn, choose action rondomly, need time 0.000228000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000209808349609
INFO:root:frame =3749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =3750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:random_action_porb = 0.991146
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.40387848e+02]
 [  3.36068878e+01]
 [  6.15789246e+02]
 [  1.63080664e+03]
 [  1.28624420e+02]
 [  1.19262028e+00]
 [  1.33093872e+02]
 [  1.44548035e+01]
 [  1.28826843e+03]
 [  2.20869965e+02]
 [  5.30903870e+02]
 [  9.82512951e+00]
 [  3.61717300e+01]
 [  3.68128548e+01]
 [  7.27848938e+02]
 [  4.56681335e+02]]
DEBUG:root:training time = %d0.195347
INFO:root:frame =3753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =3754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
DEBUG:root: save sample needs time = 0.000121831893921
INFO:root:random_action_porb = 0.9911365
DEBUG:root: dqn, choose action rondomly, need time 0.000211000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180006027222
INFO:root:frame =3757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =3758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000108003616333
INFO:root:random_action_porb = 0.991127
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000346899032593
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.34899163e-01]
 [  5.98860741e+01]
 [  2.76340393e+02]
 [  1.95258530e+02]
 [  1.63892868e+02]
 [  8.44606201e+02]
 [  5.98860741e+01]
 [  3.24354095e+01]
 [  1.83304211e+03]
 [  5.96799316e+01]
 [  4.67503023e+00]
 [  2.39827776e+00]
 [  1.10381737e+02]
 [  6.67309189e+01]
 [  2.61523516e+04]
 [  2.76340393e+02]]
DEBUG:root:training time = %d0.210611
INFO:root:frame =3761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =3762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000309944152832
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.9911175
DEBUG:root: dqn, choose action rondomly, need time 0.000362999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =3765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000550985336304
INFO:root:frame =3766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.991108
DEBUG:root: dqn, choose action rondomly, need time 0.000311999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.71660645e+02]
 [  8.45441589e+01]
 [  2.62111950e+01]
 [  1.01144844e+02]
 [  1.15074120e-01]
 [  2.37518654e+01]
 [  2.62111950e+01]
 [  1.35623436e+01]
 [  2.73312402e+03]
 [  2.80681091e+02]
 [  2.37518654e+01]
 [  3.41702026e+02]
 [  2.70657690e+03]
 [  3.47963371e+01]
 [  4.57147837e+00]
 [  4.57147837e+00]]
DEBUG:root:training time = %d0.224755
INFO:root:frame =3769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:frame =3770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:random_action_porb = 0.9910985
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root:frame =3773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =3774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.991089
DEBUG:root: dqn, choose action rondomly, need time 0.000396999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000691175460815
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.89661694e+01]
 [  1.48781525e+02]
 [  3.58662994e+02]
 [  2.56189722e+03]
 [  9.13674011e+02]
 [  3.50882007e+03]
 [  7.31858704e+02]
 [  1.63452225e+01]
 [  5.53602344e+03]
 [  4.91682129e+03]
 [  1.97296051e+02]
 [  3.35864570e+04]
 [  1.35996704e+03]
 [  4.69472443e+02]
 [  2.89661694e+01]
 [  9.79718149e-01]]
DEBUG:root:training time = %d0.204773
INFO:root:frame =3777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =3778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000333070755005
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:random_action_porb = 0.9910795
DEBUG:root: dqn, choose action rondomly, need time 0.000334999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =3781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =3782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476121902466
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:random_action_porb = 0.99107
DEBUG:root: dqn, choose action rondomly, need time 0.000225
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000545978546143
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.84455776e+00]
 [  1.20921004e+00]
 [  6.82944536e-01]
 [  2.15069183e+02]
 [  2.73910141e+01]
 [  8.56586243e+02]
 [  5.96138672e+02]
 [  2.15069183e+02]
 [  4.37365150e+00]
 [  1.91141093e+00]
 [  3.05978652e+04]
 [  2.56621216e+02]
 [  2.82248810e+02]
 [  3.38687256e+02]
 [  4.72898895e+02]
 [  3.64018402e+01]]
DEBUG:root:training time = %d0.20452
INFO:root:frame =3785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =3786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000331163406372
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:random_action_porb = 0.9910605
DEBUG:root: dqn, choose action rondomly, need time 0.000583000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =3789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000648975372314
INFO:root:frame =3790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:random_action_porb = 0.991051
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.62480652e+02]
 [  7.97089040e-01]
 [  5.01994049e+02]
 [  7.62480652e+02]
 [  5.01994049e+02]
 [  7.30333374e+02]
 [  6.26880737e+02]
 [  6.26880737e+02]
 [  8.68498039e+00]
 [  1.49678818e+02]
 [  2.39915228e+00]
 [  4.29782422e+03]
 [  6.00851011e+00]
 [  1.83935510e+03]
 [  2.88484717e+03]
 [  2.57271042e+01]]
DEBUG:root:training time = %d0.206997
INFO:root:frame =3793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =3794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000318765640259
DEBUG:root: save sample needs time = 0.000147104263306
INFO:root:random_action_porb = 0.9910415
DEBUG:root: dqn, choose action rondomly, need time 0.000352000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:frame =3797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =3798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
DEBUG:root: save sample needs time = 0.000150918960571
INFO:root:random_action_porb = 0.991032
DEBUG:root: dqn, choose action rondomly, need time 0.000349999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.41999141e+04]
 [  4.59748627e+02]
 [  6.26903057e+00]
 [  7.64083415e-02]
 [  4.38747978e+00]
 [  7.34122559e+02]
 [  1.05566492e+01]
 [  2.18472217e+03]
 [  2.14658223e+04]
 [  8.00983238e+00]
 [  1.01786011e+02]
 [  1.68661602e+04]
 [  1.53924652e+02]
 [  6.00908142e+02]
 [  4.35683403e+01]
 [  2.39862158e+03]]
DEBUG:root:training time = %d0.19149
INFO:root:frame =3801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =3802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000244855880737
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.9910225
INFO:root:dqn select action Tensor("ArgMax_4:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013801
INFO:root:action choosen by dqn [2]
INFO:root:frame =3804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:frame =3805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =3806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000297069549561
DEBUG:root: save sample needs time = 0.000105142593384
INFO:root:random_action_porb = 0.991013
DEBUG:root: dqn, choose action rondomly, need time 0.000205999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000178098678589
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.40117126e+02]
 [  4.32965240e+01]
 [  2.92915285e-01]
 [  3.58015039e+03]
 [  8.42761841e+01]
 [  2.64996606e+03]
 [  1.02732338e+02]
 [  4.51211005e-01]
 [  2.02062439e+02]
 [  1.98735391e+04]
 [  2.51759253e+03]
 [  1.70177650e+01]
 [  1.90820776e+03]
 [  6.07604492e+02]
 [  7.95657883e+01]
 [  8.42761841e+01]]
DEBUG:root:training time = %d0.196197
INFO:root:frame =3809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:frame =3810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491142272949
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9910035
DEBUG:root: dqn, choose action rondomly, need time 0.000363000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =3813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =3814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000372171401978
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.990994
DEBUG:root: dqn, choose action rondomly, need time 0.000322999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.46416611e+02]
 [  1.79585190e+02]
 [  5.12920288e+02]
 [  6.72555923e-01]
 [  2.34560871e+00]
 [  7.08836317e-01]
 [  1.86051464e+01]
 [  4.71795225e+00]
 [  1.80070312e-03]
 [  3.77060089e+01]
 [  1.05472046e+02]
 [  2.51884253e+03]
 [  2.67780256e+00]
 [  1.62144882e+02]
 [  1.30452148e+04]
 [  1.84660530e+01]]
DEBUG:root:training time = %d0.206403
INFO:root:frame =3817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000191211700439
INFO:root:frame =3818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000253915786743
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.9909845
DEBUG:root: dqn, choose action rondomly, need time 0.00033599999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =3821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000559091567993
INFO:root:frame =3822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000500917434692
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:random_action_porb = 0.990975
DEBUG:root: dqn, choose action rondomly, need time 0.000325999999987
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.34720361e+03]
 [  9.34022999e+00]
 [  2.01291323e+00]
 [  1.33536353e+03]
 [  1.35265793e+02]
 [  1.35265793e+02]
 [  3.30286926e+02]
 [  3.44454813e+00]
 [  1.12197188e+04]
 [  3.72042632e+00]
 [  4.46981697e+01]
 [  5.56945374e+02]
 [  3.44454813e+00]
 [  3.24656725e-01]
 [  1.21088839e+01]
 [  7.59729691e+01]]
DEBUG:root:training time = %d0.209248
INFO:root:frame =3825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =3826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259160995483
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.9909655
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =3829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =3830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000528812408447
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:random_action_porb = 0.990956
DEBUG:root: dqn, choose action rondomly, need time 0.000243999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000275850296021
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.22313759e+02]
 [  3.24823120e+02]
 [  3.63851715e+02]
 [  3.51219368e+01]
 [  4.96617126e+00]
 [  2.02360672e+02]
 [  9.23025977e+03]
 [  2.27351343e+03]
 [  9.76681709e+00]
 [  6.12600470e+00]
 [  3.78879547e+01]
 [  5.24577751e+01]
 [  1.66910010e+03]
 [  9.76681709e+00]
 [  1.13100134e+03]
 [  2.64468323e+02]]
DEBUG:root:training time = %d0.208837
INFO:root:frame =3833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:frame =3834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:random_action_porb = 0.9909465
DEBUG:root: dqn, choose action rondomly, need time 0.000157999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000186920166016
INFO:root:frame =3837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =3838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249862670898
DEBUG:root: save sample needs time = 0.00016713142395
INFO:root:random_action_porb = 0.990937
DEBUG:root: dqn, choose action rondomly, need time 0.000242
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.16015869e+03]
 [  7.24759827e+01]
 [  2.37557278e+01]
 [  1.92624146e+02]
 [  1.43567055e-01]
 [  3.53917509e-01]
 [  6.55494812e+02]
 [  1.77141211e+03]
 [  4.40357697e+02]
 [  2.02679262e-01]
 [  1.36285477e+02]
 [  4.40357697e+02]
 [  1.75509933e+02]
 [  5.60834473e+02]
 [  3.13354309e+02]
 [  7.81447296e+01]]
DEBUG:root:training time = %d0.19053
INFO:root:frame =3841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =3842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000218152999878
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.9909275
DEBUG:root: dqn, choose action rondomly, need time 0.000244999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000189065933228
INFO:root:frame =3845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =3846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame = 3847 State into memory, numbers recorded 84 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000409126281738
INFO:root:random_action_porb = 0.990918
DEBUG:root: dqn, choose action rondomly, need time 0.000199999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3848current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.22737335e+02]
 [  2.11074731e+03]
 [  1.67387244e+03]
 [  2.71258301e+02]
 [  8.53766403e+01]
 [  3.47700659e+03]
 [  3.33808655e+02]
 [  1.11158972e+03]
 [  1.40185437e+03]
 [  1.22302747e+03]
 [  1.78196182e+02]
 [  1.11137299e+02]
 [  6.62233496e+03]
 [  9.96380273e+03]
 [  4.53094244e+00]
 [  5.60855560e+01]]
DEBUG:root:training time = %d0.194142
INFO:root:frame =3849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000385999679565
INFO:root:frame =3850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293016433716
DEBUG:root: save sample needs time = 0.000121116638184
INFO:root:random_action_porb = 0.9909085
DEBUG:root: dqn, choose action rondomly, need time 0.000148999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:frame =3853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =3854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000219821929932
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.990899
DEBUG:root: dqn, choose action rondomly, need time 0.000331000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000356912612915
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  726.43231201]
 [   28.24073601]
 [    8.48738098]
 [ 1084.12670898]
 [  316.45129395]
 [  125.21888733]
 [  245.12043762]
 [   62.31302261]
 [   96.57674408]
 [ 3920.46508789]
 [   22.14235497]
 [    4.76100397]
 [  316.45129395]
 [   35.61777878]
 [  105.83850861]
 [   42.93241119]]
DEBUG:root:training time = %d0.200185
INFO:root:frame =3857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =3858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000380992889404
INFO:root:frame = 3859 State into memory, numbers recorded 85 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000561952590942
INFO:root:random_action_porb = 0.9908895
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3860current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =3861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =3862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame = 3863 State into memory, numbers recorded 86 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000560998916626
INFO:root:random_action_porb = 0.99088
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3864current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.09947327e+02]
 [  8.66819214e+02]
 [  4.50216293e+01]
 [  1.55872192e+02]
 [  6.40162354e+02]
 [  3.45373535e+02]
 [  9.77698364e+01]
 [  1.20237439e+03]
 [  3.70195084e+01]
 [  7.63716553e+02]
 [  1.15492065e+03]
 [  2.24560761e+00]
 [  2.74251068e+02]
 [  7.55580615e+03]
 [  9.77698364e+01]
 [  1.87855377e+01]]
DEBUG:root:training time = %d0.202745
INFO:root:frame =3865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:frame =3866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9908705
DEBUG:root: dqn, choose action rondomly, need time 0.000492999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =3869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =3870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.990861
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  17.93768501]
 [  29.88837051]
 [ 171.37736511]
 [  18.96844673]
 [ 643.58441162]
 [   2.7659564 ]
 [ 786.76885986]
 [   6.28631115]
 [   2.7659564 ]
 [  30.02586365]
 [ 371.39553833]
 [  29.88837051]
 [  27.91699219]
 [  63.99609375]
 [ 613.17901611]
 [ 176.14819336]]
DEBUG:root:training time = %d0.20443
INFO:root:frame =3873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:frame =3874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.9908515
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =3877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =3878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:random_action_porb = 0.990842
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.85765076e+02]
 [  3.48023653e-01]
 [  3.35614288e+02]
 [  2.36366943e+03]
 [  1.85752289e+02]
 [  1.99330475e+02]
 [  3.52604675e+02]
 [  3.61249817e+02]
 [  6.41018152e+00]
 [  3.48023653e-01]
 [  4.12866882e+02]
 [  1.13855049e+02]
 [  3.34328638e+03]
 [  1.56419873e+04]
 [  1.08974976e+02]
 [  4.02346954e+01]]
DEBUG:root:training time = %d0.191115
INFO:root:frame =3881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =3882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294923782349
DEBUG:root: save sample needs time = 9.51290130615e-05
INFO:root:random_action_porb = 0.9908325
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =3885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000683784484863
INFO:root:frame =3886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000703096389771
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:random_action_porb = 0.990823
DEBUG:root: dqn, choose action rondomly, need time 0.000349999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000351190567017
INFO:root:training error  = [[  736.51245117]
 [  203.2277832 ]
 [   41.84566498]
 [  106.99608612]
 [   41.34098053]
 [  600.01751709]
 [   76.47386932]
 [  676.59124756]
 [   93.04242706]
 [   48.0454216 ]
 [   37.78321075]
 [  145.91667175]
 [ 4390.31005859]
 [  259.71554565]
 [ 2470.59057617]
 [    9.27633572]]
DEBUG:root:training time = %d0.19536
INFO:root:frame =3889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249147415161
INFO:root:frame =3890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248908996582
DEBUG:root: save sample needs time = 0.000105857849121
INFO:root:random_action_porb = 0.9908135
DEBUG:root: dqn, choose action rondomly, need time 0.000171999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:frame =3893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =3894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000418186187744
INFO:root:frame = 3895 State into memory, numbers recorded 87 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000600099563599
INFO:root:random_action_porb = 0.990804
DEBUG:root: dqn, choose action rondomly, need time 0.000348000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3896current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:training error  = [[  4.01428650e+02]
 [  1.58385086e+02]
 [  2.15614197e+02]
 [  1.83454361e+01]
 [  9.34273145e+03]
 [  1.15097705e+03]
 [  1.47722731e+01]
 [  1.99626740e+02]
 [  9.16954727e+01]
 [  3.86694702e+02]
 [  7.51147278e+02]
 [  9.20436001e+00]
 [  3.86694702e+02]
 [  4.01428650e+02]
 [  1.47722731e+01]
 [  9.16954727e+01]]
DEBUG:root:training time = %d0.206852
INFO:root:frame =3897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =3898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9907945
DEBUG:root: dqn, choose action rondomly, need time 0.000442000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =3901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248193740845
INFO:root:frame =3902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000180006027222
INFO:root:random_action_porb = 0.990785
DEBUG:root: dqn, choose action rondomly, need time 0.000355999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.28374313e+02]
 [  7.05101990e+02]
 [  5.04246140e+00]
 [  3.79089266e-04]
 [  5.40901709e+00]
 [  6.57819824e+01]
 [  3.67716455e+03]
 [  3.93612579e+02]
 [  1.38440883e+00]
 [  1.68861562e+04]
 [  1.75894775e+01]
 [  7.26884317e+00]
 [  7.05101990e+02]
 [  7.26884317e+00]
 [  2.77581501e+01]
 [  1.75894775e+01]]
DEBUG:root:training time = %d0.200839
INFO:root:frame =3905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =3906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000350952148438
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:random_action_porb = 0.9907755
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =3909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000484943389893
INFO:root:frame =3910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.990766
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.09048325e+02]
 [  2.29436108e+03]
 [  2.09048325e+02]
 [  1.37984375e+03]
 [  5.73710537e+00]
 [  6.94242706e+01]
 [  7.89208298e+01]
 [  1.07913055e+01]
 [  3.15672731e+00]
 [  1.87080872e+03]
 [  4.36330223e+00]
 [  1.37254276e+01]
 [  4.66952393e+03]
 [  2.63433895e+01]
 [  5.77792854e+01]
 [  5.45481641e+03]]
DEBUG:root:training time = %d0.204646
INFO:root:frame =3913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =3914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.9907565
DEBUG:root: dqn, choose action rondomly, need time 0.000187999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:frame =3917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =3918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000282049179077
DEBUG:root: save sample needs time = 0.000150918960571
INFO:root:random_action_porb = 0.990747
DEBUG:root: dqn, choose action rondomly, need time 0.000186999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000172138214111
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.63795161e+00]
 [  1.52581628e+03]
 [  6.64922667e+00]
 [  3.83983521e+02]
 [  2.43750049e+03]
 [  8.95598755e+01]
 [  7.59114504e+00]
 [  1.32034073e+02]
 [  2.66457582e+00]
 [  2.91017456e+03]
 [  9.62389282e+02]
 [  8.30274200e+01]
 [  1.63795161e+00]
 [  7.09504211e+02]
 [  8.87607765e+00]
 [  1.32034073e+02]]
DEBUG:root:training time = %d0.205223
INFO:root:frame =3921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =3922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9907375
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =3925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =3926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494956970215
DEBUG:root: save sample needs time = 0.000120878219604
INFO:root:random_action_porb = 0.990728
DEBUG:root: dqn, choose action rondomly, need time 0.000328999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000353097915649
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.25441132e+01]
 [  2.17826025e+03]
 [  4.05705185e+01]
 [  3.90778076e+03]
 [  2.03467676e+03]
 [  2.52549341e+03]
 [  1.68066406e+02]
 [  2.46998882e+01]
 [  2.03467676e+03]
 [  7.16143195e-03]
 [  3.94244629e+02]
 [  1.99354980e+02]
 [  1.40011948e+02]
 [  9.04547668e+02]
 [  2.52549341e+03]
 [  6.99206055e+02]]
DEBUG:root:training time = %d0.21743
INFO:root:frame =3929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:frame =3930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.9907185
DEBUG:root: dqn, choose action rondomly, need time 0.000155000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000147104263306
INFO:root:frame =3933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =3934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.990709
DEBUG:root: dqn, choose action rondomly, need time 0.000324000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.23917090e+03]
 [  9.23917090e+03]
 [  7.35118637e+01]
 [  2.57732525e+01]
 [  1.16196973e+03]
 [  1.62107735e+01]
 [  3.07069855e+02]
 [  1.74246952e-01]
 [  1.09220612e+02]
 [  6.03484802e+01]
 [  6.85974121e+01]
 [  5.89806480e+01]
 [  1.35913496e+01]
 [  2.31073761e+00]
 [  1.06446055e+04]
 [  1.54815173e+00]]
DEBUG:root:training time = %d0.199608
INFO:root:frame =3937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:frame =3938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000407934188843
INFO:root:frame = 3939 State into memory, numbers recorded 88 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.00053596496582
INFO:root:random_action_porb = 0.9906995
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3940current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =3941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =3942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.99069
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   15.36483097]
 [ 8876.44140625]
 [ 2433.27075195]
 [  120.46331787]
 [   36.11026764]
 [  362.01004028]
 [   27.55822372]
 [   18.34360695]
 [ 2801.13012695]
 [  583.85137939]
 [  266.07626343]
 [ 1963.50158691]
 [   27.01172829]
 [  345.75479126]
 [  162.06648254]
 [   23.22099876]]
DEBUG:root:training time = %d0.192496
INFO:root:frame =3945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =3946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00036096572876
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:random_action_porb = 0.9906805
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320196151733
INFO:root:frame =3949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000504970550537
INFO:root:frame =3950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:random_action_porb = 0.990671
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.08536613e+00]
 [  8.67114334e+01]
 [  1.93057300e+03]
 [  1.69629150e+02]
 [  1.34249171e-02]
 [  4.90917725e+03]
 [  5.93423386e+01]
 [  1.69629150e+02]
 [  8.15768921e+02]
 [  1.12513680e+02]
 [  1.93057300e+03]
 [  3.84550439e+03]
 [  3.26925586e+03]
 [  1.91358185e+01]
 [  5.61058617e+00]
 [  8.67114334e+01]]
DEBUG:root:training time = %d0.208364
INFO:root:frame =3953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:frame =3954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298976898193
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9906615
DEBUG:root: dqn, choose action rondomly, need time 0.000358999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000395059585571
INFO:root:frame =3957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000580072402954
INFO:root:frame =3958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000542879104614
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:random_action_porb = 0.990652
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.57708015e+01]
 [  2.80246687e+00]
 [  1.07875986e+04]
 [  9.36887573e+02]
 [  2.86162793e+03]
 [  1.72445878e-01]
 [  4.04573708e+01]
 [  5.75814366e-01]
 [  6.08290970e-01]
 [  7.28824524e+02]
 [  7.74681824e+02]
 [  1.72445878e-01]
 [  5.75814366e-01]
 [  6.90434113e+01]
 [  1.68029221e+02]
 [  1.44967682e+02]]
DEBUG:root:training time = %d0.200268
INFO:root:frame =3961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =3962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00029182434082
DEBUG:root: save sample needs time = 0.000152826309204
INFO:root:random_action_porb = 0.9906425
DEBUG:root: dqn, choose action rondomly, need time 0.000232000000011
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =3965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =3966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000515937805176
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:random_action_porb = 0.990633
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0003662109375
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.66123505e+01]
 [  2.39397537e+02]
 [  7.58511901e-01]
 [  8.56051331e+01]
 [  3.24042847e+02]
 [  3.45263786e+01]
 [  4.15465179e+02]
 [  1.84468353e+02]
 [  2.41978455e+02]
 [  1.02176113e+04]
 [  4.17354828e+02]
 [  2.88580179e+00]
 [  4.17354828e+02]
 [  7.09624231e-01]
 [  7.09624231e-01]
 [  5.32307251e+02]]
DEBUG:root:training time = %d0.199874
INFO:root:frame =3969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:frame =3970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:frame = 3971 State into memory, numbers recorded 89 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.00066089630127
INFO:root:random_action_porb = 0.9906235
DEBUG:root: dqn, choose action rondomly, need time 0.00047099999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3972current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:frame =3973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000529050827026
INFO:root:frame =3974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000555038452148
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:random_action_porb = 0.990614
DEBUG:root: dqn, choose action rondomly, need time 0.000175999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.98674744e+03]
 [  3.40901423e+00]
 [  7.25086426e+02]
 [  4.49715793e-01]
 [  1.69985840e+03]
 [  3.66875824e+02]
 [  3.42960052e+02]
 [  5.01589508e+01]
 [  2.80059009e+03]
 [  6.52248001e+01]
 [  6.68425964e+02]
 [  3.17299957e+01]
 [  7.84106384e+02]
 [  2.63747144e+03]
 [  2.91925983e+01]
 [  7.25086426e+02]]
DEBUG:root:training time = %d0.202735
INFO:root:frame =3977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =3978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000270128250122
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9906045
DEBUG:root: dqn, choose action rondomly, need time 0.000182000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:frame =3981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000576019287109
INFO:root:frame =3982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00056791305542
DEBUG:root: save sample needs time = 0.00017786026001
INFO:root:random_action_porb = 0.990595
DEBUG:root: dqn, choose action rondomly, need time 0.000485999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:training error  = [[    6.49421072]
 [  840.85528564]
 [  455.90829468]
 [  794.41040039]
 [  455.90829468]
 [ 1257.33959961]
 [  662.82098389]
 [ 1944.4942627 ]
 [  135.15220642]
 [ 2128.20043945]
 [   25.42584038]
 [   20.52173615]
 [  787.15002441]
 [   39.88788223]
 [ 1445.64868164]
 [ 1752.42126465]]
DEBUG:root:training time = %d0.205587
INFO:root:frame =3985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000416994094849
INFO:root:frame =3986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.9905855
DEBUG:root: dqn, choose action rondomly, need time 0.000156000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =3989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =3990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476121902466
INFO:root:frame = 3991 State into memory, numbers recorded 90 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000384092330933
INFO:root:random_action_porb = 0.990576
DEBUG:root: dqn, choose action rondomly, need time 0.000215999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3992current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.00036883354187
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.43000487e-06]
 [  8.37976608e+01]
 [  1.10621858e+00]
 [  7.77087708e+01]
 [  1.03301033e+02]
 [  2.52868042e+02]
 [  1.70881729e+02]
 [  1.92754837e+02]
 [  7.12663330e+02]
 [  3.07811424e-02]
 [  2.69908386e+02]
 [  1.02358746e+03]
 [  9.43000487e-06]
 [  1.67914563e+03]
 [  2.41310028e+02]
 [  1.28904346e+03]]
DEBUG:root:training time = %d0.197118
INFO:root:frame =3993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =3994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00040078163147
DEBUG:root: save sample needs time = 0.000180006027222
INFO:root:random_action_porb = 0.9905665
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000178098678589
INFO:root:frame =3997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =3998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000228881835938
DEBUG:root: save sample needs time = 0.000220775604248
DEBUG:root:one frame running time = 0.006581
DEBUG:root:total training time = 82.916816
INFO:root:frame num = 4000 frame round: 0
INFO:root:random_action_porb = 0.990557
DEBUG:root: dqn, choose action rondomly, need time 0.000169999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.15779289e+02]
 [  4.36648788e+01]
 [  4.50339447e+02]
 [  2.56962323e+00]
 [  1.25276733e+02]
 [  4.15578613e+03]
 [  5.58558167e+02]
 [  4.22455750e+02]
 [  4.73389209e+03]
 [  2.56646271e+02]
 [  2.58805752e+01]
 [  3.05952332e+02]
 [  1.75200293e+03]
 [  4.83453308e+02]
 [  4.60783184e-01]
 [  6.06495321e-01]]
DEBUG:root:training time = %d0.189611
INFO:root:frame =4001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:frame =4002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025200843811
DEBUG:root: save sample needs time = 9.29832458496e-05
INFO:root:random_action_porb = 0.9905475
DEBUG:root: dqn, choose action rondomly, need time 0.000152999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:frame =4005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =4006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045919418335
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:random_action_porb = 0.990538
DEBUG:root: dqn, choose action rondomly, need time 0.000236000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.21472900e+02]
 [  3.44294024e+00]
 [  9.34851440e+02]
 [  8.05275726e+00]
 [  1.13788788e+02]
 [  4.34526733e+02]
 [  2.00858822e+01]
 [  2.57247974e+03]
 [  5.57004404e+00]
 [  2.96491027e-01]
 [  9.91497650e+01]
 [  6.05428047e+01]
 [  7.39861393e+00]
 [  1.65886765e+02]
 [  3.71243683e+02]
 [  9.91497650e+01]]
DEBUG:root:training time = %d0.223682
INFO:root:frame =4009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000355958938599
INFO:root:frame =4010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000111103057861
INFO:root:random_action_porb = 0.9905285
DEBUG:root: dqn, choose action rondomly, need time 0.000263000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000181913375854
INFO:root:frame =4013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000570058822632
INFO:root:frame =4014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308036804199
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:random_action_porb = 0.990519
DEBUG:root: dqn, choose action rondomly, need time 0.000332999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000315189361572
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.31739532e+02]
 [  3.17775764e+01]
 [  1.67744083e+01]
 [  4.28071451e+00]
 [  1.47551544e+02]
 [  2.07179031e+02]
 [  3.25675926e+01]
 [  5.10046094e+03]
 [  1.77139668e+04]
 [  3.35194824e+02]
 [  3.57259094e+02]
 [  3.80948669e+02]
 [  2.81531181e+01]
 [  7.61710052e+01]
 [  2.07179031e+02]
 [  7.03913193e+01]]
DEBUG:root:training time = %d0.196251
INFO:root:frame =4017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =4018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298023223877
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:random_action_porb = 0.9905095
DEBUG:root: dqn, choose action rondomly, need time 0.000294000000011
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =4021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =4022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000287055969238
DEBUG:root: save sample needs time = 0.000362157821655
INFO:root:random_action_porb = 0.9905
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312805175781
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.33147240e+00]
 [  5.71395850e+03]
 [  5.71395850e+03]
 [  6.13868994e+03]
 [  1.35074112e+02]
 [  1.79403549e+02]
 [  1.46286488e+01]
 [  1.28875256e+01]
 [  1.44731274e+03]
 [  1.78245117e+03]
 [  9.57003174e+01]
 [  1.41370483e+03]
 [  2.16437943e+02]
 [  1.72632904e+01]
 [  5.64690735e+02]
 [  1.41370483e+03]]
DEBUG:root:training time = %d0.206686
INFO:root:frame =4025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250816345215
INFO:root:frame =4026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235080718994
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:random_action_porb = 0.9904905
DEBUG:root: dqn, choose action rondomly, need time 0.000254000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:frame =4029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =4030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00023889541626
DEBUG:root: save sample needs time = 0.000259160995483
INFO:root:random_action_porb = 0.990481
DEBUG:root: dqn, choose action rondomly, need time 0.00016500000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.67861526e+02]
 [  1.08517539e-02]
 [  4.10758638e+00]
 [  2.74709412e+02]
 [  1.44061530e+00]
 [  5.02629974e+02]
 [  1.02398743e+02]
 [  2.04439926e+01]
 [  7.59153900e+01]
 [  1.36973129e+02]
 [  7.27986023e+02]
 [  1.95275497e+01]
 [  1.99016556e-02]
 [  1.53760788e+02]
 [  1.57478256e+02]
 [  1.76652405e+03]]
DEBUG:root:training time = %d0.199002
INFO:root:frame =4033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259160995483
INFO:root:frame =4034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.9904715
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =4037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000514984130859
INFO:root:frame =4038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491857528687
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root:random_action_porb = 0.990462
DEBUG:root: dqn, choose action rondomly, need time 0.000376000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:training error  = [[  1.15477073e+00]
 [  1.22534927e+02]
 [  2.18253098e+02]
 [  1.56523647e+01]
 [  4.28959923e+01]
 [  1.59088464e+03]
 [  9.40670532e+02]
 [  2.70321140e+01]
 [  2.50010986e+03]
 [  9.21530838e+01]
 [  2.35540039e+03]
 [  6.38823776e+01]
 [  9.97099152e+01]
 [  4.28959923e+01]
 [  1.25953479e+03]
 [  4.80256462e+01]]
DEBUG:root:training time = %d0.210309
INFO:root:frame =4041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =4042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.9904525
DEBUG:root: dqn, choose action rondomly, need time 0.000327000000013
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326156616211
INFO:root:frame =4045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000519037246704
INFO:root:frame =4046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:random_action_porb = 0.990443
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326156616211
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.23054886e+01]
 [  1.48775293e+03]
 [  1.41291181e-02]
 [  3.03286774e+02]
 [  1.70553906e+03]
 [  5.06127258e+02]
 [  1.42778000e+02]
 [  1.52477045e+01]
 [  3.69458667e+03]
 [  3.07275452e+02]
 [  1.50251836e-01]
 [  7.64506104e+02]
 [  3.12468170e+02]
 [  2.24718466e-01]
 [  4.00424614e+01]
 [  1.89701904e+02]]
DEBUG:root:training time = %d0.221002
INFO:root:frame =4049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =4050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000266075134277
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.9904335
DEBUG:root: dqn, choose action rondomly, need time 0.000157999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:frame =4053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =4054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.990424
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.69306221e+01]
 [  1.85577431e+01]
 [  1.67966652e+01]
 [  3.34875610e+03]
 [  1.16271387e+03]
 [  7.40149689e+01]
 [  5.58992310e+01]
 [  3.01238599e+03]
 [  3.57539185e+02]
 [  1.32796097e+00]
 [  3.34875610e+03]
 [  3.01238599e+03]
 [  8.03681183e+01]
 [  2.78441162e+03]
 [  3.44345436e+01]
 [  2.51611618e+02]]
DEBUG:root:training time = %d0.2099
INFO:root:frame =4057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =4058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255107879639
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.9904145
DEBUG:root: dqn, choose action rondomly, need time 0.000205000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =4061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000671863555908
INFO:root:frame =4062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249862670898
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.990405
DEBUG:root: dqn, choose action rondomly, need time 0.000257000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000501871109009
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.37794342e+01]
 [  7.89142418e+00]
 [  5.72541992e+03]
 [  2.36579990e+01]
 [  1.73887577e+01]
 [  6.64591125e+02]
 [  9.11853516e+03]
 [  7.00944841e-01]
 [  6.09103501e-01]
 [  1.60695450e+02]
 [  1.11273289e+00]
 [  1.54727844e+02]
 [  1.67762894e+02]
 [  6.20100098e+02]
 [  2.28665674e+03]
 [  1.00363052e+02]]
DEBUG:root:training time = %d0.194654
INFO:root:frame =4065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:player has been killed for 8 times 
INFO:root:frame =4066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame = 4067 State into memory, numbers recorded 91 action = 2, reward = -255
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:random_action_porb = 0.9903955
DEBUG:root: dqn, choose action rondomly, need time 0.000366
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4068current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =4069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265836715698
INFO:root:frame =4070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294923782349
DEBUG:root: save sample needs time = 0.000142812728882
INFO:root:random_action_porb = 0.990386
DEBUG:root: dqn, choose action rondomly, need time 0.000182999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00207591056824
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   28.51177216]
 [  303.6199646 ]
 [  174.80467224]
 [    6.54144478]
 [  160.22039795]
 [   90.82504272]
 [  206.42111206]
 [  580.79888916]
 [  440.42404175]
 [ 1002.546875  ]
 [    6.54144478]
 [  841.88525391]
 [   22.2416954 ]
 [   28.51177216]
 [ 1787.76245117]
 [  133.05947876]]
DEBUG:root:training time = %d0.190609
INFO:root:frame =4073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =4074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000281095504761
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:random_action_porb = 0.9903765
DEBUG:root: dqn, choose action rondomly, need time 0.000247000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =4077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =4078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000312089920044
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:random_action_porb = 0.990367
DEBUG:root: dqn, choose action rondomly, need time 0.000214999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.57371328e+04]
 [  4.37559242e+01]
 [  1.44183350e+02]
 [  2.27044418e+02]
 [  5.39059717e+03]
 [  4.26498532e-01]
 [  4.63414856e+02]
 [  9.87149292e+02]
 [  2.81639038e+02]
 [  2.81639038e+02]
 [  1.27643384e+03]
 [  2.39708667e+03]
 [  3.01148468e+02]
 [  8.58218506e+02]
 [  4.33914423e+00]
 [  8.40043716e+01]]
DEBUG:root:training time = %d0.191272
INFO:root:frame =4081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:frame =4082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000245094299316
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.9903575
DEBUG:root: dqn, choose action rondomly, need time 0.000367999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =4085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000484943389893
INFO:root:frame =4086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000403881072998
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.990348
DEBUG:root: dqn, choose action rondomly, need time 0.000180999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016713142395
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.70380554e+01]
 [  5.96907104e+02]
 [  2.79849609e+02]
 [  1.38149475e+02]
 [  3.16150532e+01]
 [  2.04032776e+02]
 [  2.88816428e+00]
 [  3.40527405e+02]
 [  8.77109558e+02]
 [  4.10136490e+01]
 [  1.88896787e+00]
 [  3.88885071e+02]
 [  3.16150532e+01]
 [  9.73430859e+03]
 [  1.24851282e+03]
 [  9.83978500e+01]]
DEBUG:root:training time = %d0.186911
INFO:root:frame =4089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =4090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000260829925537
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.9903385
DEBUG:root: dqn, choose action rondomly, need time 0.000236999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174045562744
INFO:root:frame =4093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000540018081665
INFO:root:frame =4094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264167785645
DEBUG:root: save sample needs time = 0.000150918960571
INFO:root:random_action_porb = 0.990329
DEBUG:root: dqn, choose action rondomly, need time 0.000253000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.00023291e+03]
 [  1.58328972e+01]
 [  4.41265411e+01]
 [  4.41265411e+01]
 [  4.46064911e+01]
 [  7.18818665e+01]
 [  1.96978119e+02]
 [  1.75032483e+03]
 [  1.07553253e+02]
 [  3.00209717e+02]
 [  3.00209717e+02]
 [  4.41265411e+01]
 [  2.54686325e+02]
 [  1.08171741e+03]
 [  3.06370139e+00]
 [  1.24891162e+03]]
DEBUG:root:training time = %d0.194489
INFO:root:frame =4097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:frame =4098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229835510254
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.9903195
DEBUG:root: dqn, choose action rondomly, need time 0.000160000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:frame =4101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =4102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000327825546265
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.99031
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000388860702515
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.89167857e-01]
 [  2.20008621e+02]
 [  6.80083707e-02]
 [  9.43425415e+02]
 [  1.05125449e+04]
 [  2.57985449e+03]
 [  1.52815831e+00]
 [  1.01212151e+02]
 [  5.85236670e+03]
 [  3.29061623e+01]
 [  8.69444458e+02]
 [  4.17178383e+01]
 [  1.45540070e+02]
 [  2.26242477e+02]
 [  1.23504419e+03]
 [  8.99935303e+01]]
DEBUG:root:training time = %d0.217269
INFO:root:frame =4105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:frame =4106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000155925750732
INFO:root:random_action_porb = 0.9903005
DEBUG:root: dqn, choose action rondomly, need time 0.000326999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =4109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root:frame =4110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame = 4111 State into memory, numbers recorded 92 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000594854354858
INFO:root:random_action_porb = 0.990291
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4112current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.23469916e-02]
 [  3.34333496e+03]
 [  2.12029297e+02]
 [  8.63990479e+02]
 [  1.29033493e+02]
 [  3.36352577e+01]
 [  2.44607568e+03]
 [  1.93162323e+02]
 [  1.16286232e+02]
 [  1.22050740e-01]
 [  1.04823965e+04]
 [  3.35477028e+01]
 [  4.23469916e-02]
 [  8.92050266e+00]
 [  1.90660675e+02]
 [  6.67865217e-01]]
DEBUG:root:training time = %d0.21258
INFO:root:frame =4113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:frame =4114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000136137008667
INFO:root:random_action_porb = 0.9902815
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root:frame =4117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =4118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000388145446777
DEBUG:root: save sample needs time = 0.0001060962677
INFO:root:random_action_porb = 0.990272
DEBUG:root: dqn, choose action rondomly, need time 0.000238999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000155925750732
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  512.71606445]
 [   56.81195068]
 [   56.1516304 ]
 [   55.52246475]
 [  843.18652344]
 [  153.97525024]
 [   63.78726959]
 [  800.02954102]
 [ 5396.82226562]
 [  139.14213562]
 [   48.68019485]
 [   55.83212662]
 [    9.36395836]
 [  154.13243103]
 [ 4804.79785156]
 [  592.03436279]]
DEBUG:root:training time = %d0.19409
INFO:root:frame =4121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =4122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000310897827148
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.9902625
DEBUG:root: dqn, choose action rondomly, need time 0.000329000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =4125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000611066818237
INFO:root:frame =4126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000360012054443
DEBUG:root: save sample needs time = 0.000180959701538
INFO:root:random_action_porb = 0.990253
DEBUG:root: dqn, choose action rondomly, need time 0.000461000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000828981399536
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.72396011e+01]
 [  5.50735742e+03]
 [  5.54472208e-01]
 [  1.63527222e+01]
 [  1.93821484e+03]
 [  4.25484406e+02]
 [  3.16760254e+02]
 [  4.20539284e+01]
 [  1.68754272e+02]
 [  3.48226855e+03]
 [  7.40199414e+03]
 [  4.85696631e+03]
 [  1.63527222e+01]
 [  4.41723267e+02]
 [  2.11601620e+01]
 [  1.06616614e+03]]
DEBUG:root:training time = %d0.202278
INFO:root:frame =4129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =4130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00041389465332
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.9902435
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =4133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000601053237915
INFO:root:frame =4134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000313997268677
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:random_action_porb = 0.990234
DEBUG:root: dqn, choose action rondomly, need time 0.000236000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000157117843628
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.45914507e+00]
 [  1.16370764e+01]
 [  2.18012981e+01]
 [  1.84521411e+03]
 [  4.01262703e+01]
 [  1.38684644e+03]
 [  6.56823933e-01]
 [  5.09048510e+00]
 [  1.83184063e+00]
 [  1.28828589e+03]
 [  1.47305757e-01]
 [  1.52469238e+03]
 [  2.99311390e+01]
 [  5.20233688e+01]
 [  1.24619250e+03]
 [  3.48979663e+03]]
DEBUG:root:training time = %d0.209503
INFO:root:frame =4137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =4138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00029993057251
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:random_action_porb = 0.9902245
DEBUG:root: dqn, choose action rondomly, need time 0.000409000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =4141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000617027282715
INFO:root:frame =4142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000520944595337
DEBUG:root: save sample needs time = 0.000396013259888
INFO:root:random_action_porb = 0.990215
INFO:root:dqn select action Tensor("ArgMax_5:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013772
INFO:root:action choosen by dqn [2]
INFO:root:frame =4144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000158071517944
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.35198806e-03]
 [  9.77836060e+02]
 [  8.56050488e+03]
 [  3.76407776e+01]
 [  1.48571177e+01]
 [  1.15396355e+02]
 [  1.28680664e+02]
 [  7.42200317e+01]
 [  2.82023529e+02]
 [  2.05433941e+00]
 [  1.36140203e+01]
 [  1.70110941e-01]
 [  6.86178665e+01]
 [  3.23967041e+02]
 [  1.70110941e-01]
 [  9.67656517e+00]]
DEBUG:root:training time = %d0.203953
INFO:root:frame =4145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =4146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000323057174683
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.9902055
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000396966934204
INFO:root:frame =4149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =4150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491857528687
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.990196
DEBUG:root: dqn, choose action rondomly, need time 0.000321
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  180.95864868]
 [  257.60040283]
 [ 1026.55090332]
 [ 3485.47045898]
 [ 1915.33374023]
 [   28.39737129]
 [ 1915.33374023]
 [  315.28259277]
 [    8.38598537]
 [  271.34613037]
 [  989.3394165 ]
 [  721.06335449]
 [ 1019.85040283]
 [   34.103508  ]
 [ 1647.36291504]
 [   21.4676609 ]]
DEBUG:root:training time = %d0.217035
INFO:root:frame =4153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:frame =4154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9901865
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =4157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =4158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298023223877
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.990177
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.53980041e+00]
 [  4.89752626e+00]
 [  3.90507520e+03]
 [  2.70095166e+03]
 [  3.18162048e+02]
 [  1.35335706e+03]
 [  1.72293457e+03]
 [  7.08750427e-01]
 [  3.38808563e+02]
 [  3.18162048e+02]
 [  7.06353369e+03]
 [  7.57406473e+00]
 [  2.51805401e+00]
 [  2.92981903e+02]
 [  2.70329376e+02]
 [  7.27418594e+01]]
DEBUG:root:training time = %d0.205559
INFO:root:frame =4161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =4162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame = 4163 State into memory, numbers recorded 93 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:random_action_porb = 0.9901675
DEBUG:root: dqn, choose action rondomly, need time 0.000384999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4164current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000337839126587
INFO:root:frame =4165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444173812866
INFO:root:frame =4166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.990158
DEBUG:root: dqn, choose action rondomly, need time 0.000525999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.29917946e+01]
 [  8.55369531e+03]
 [  9.73038852e-01]
 [  2.86406918e+01]
 [  2.62756836e+02]
 [  8.55369531e+03]
 [  3.67239288e+02]
 [  2.62243652e+02]
 [  9.52187561e+02]
 [  2.24192762e+00]
 [  9.73799706e+00]
 [  1.38609695e+02]
 [  5.71072461e+03]
 [  3.02310729e+00]
 [  9.11731262e+01]
 [  2.19952035e+00]]
DEBUG:root:training time = %d0.186893
INFO:root:frame =4169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =4170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000406980514526
INFO:root:frame = 4171 State into memory, numbers recorded 94 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000607967376709
INFO:root:random_action_porb = 0.9901485
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4172current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =4173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =4174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:random_action_porb = 0.990139
DEBUG:root: dqn, choose action rondomly, need time 0.000486999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.11593895e+01]
 [  7.54278600e-01]
 [  1.49119287e+03]
 [  2.67435974e+02]
 [  1.12860268e+02]
 [  6.78355835e+02]
 [  5.04025482e+02]
 [  5.62406641e+03]
 [  6.77382141e+02]
 [  4.44601965e+00]
 [  6.77382141e+02]
 [  1.74253006e+02]
 [  3.88506203e+01]
 [  6.44622803e+02]
 [  2.13847534e+03]
 [  1.28199921e+02]]
DEBUG:root:training time = %d0.213961
INFO:root:frame =4177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:frame =4178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9901295
DEBUG:root: dqn, choose action rondomly, need time 0.000334000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =4181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =4182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.99012
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.49151465e+03]
 [  6.46503525e+01]
 [  1.68019485e+01]
 [  7.77924011e+02]
 [  4.83401306e+02]
 [  1.22602501e+02]
 [  1.37187073e+03]
 [  4.53910679e-01]
 [  6.98399963e+01]
 [  7.14270782e+01]
 [  1.63743607e+02]
 [  6.46503525e+01]
 [  1.64406586e+00]
 [  1.38580060e+00]
 [  2.02928802e+02]
 [  5.93565125e+02]]
DEBUG:root:training time = %d0.205648
INFO:root:frame =4185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:frame =4186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000420093536377
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9901105
DEBUG:root: dqn, choose action rondomly, need time 0.000360999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =4189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000341892242432
INFO:root:frame =4190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233888626099
DEBUG:root: save sample needs time = 0.00016713142395
INFO:root:random_action_porb = 0.990101
DEBUG:root: dqn, choose action rondomly, need time 0.000291999999988
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.65890454e+03]
 [  1.00859993e+02]
 [  6.37789990e+03]
 [  1.96728401e+01]
 [  8.06998718e+02]
 [  5.29717827e+01]
 [  5.04519119e+01]
 [  5.29838753e+00]
 [  9.56813110e+02]
 [  6.79934143e+02]
 [  7.49121729e+03]
 [  1.64949805e+03]
 [  4.26138611e+01]
 [  8.52902527e+02]
 [  1.59239626e+00]
 [  5.30701399e+00]]
DEBUG:root:training time = %d0.196616
INFO:root:frame =4193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000217199325562
INFO:root:frame =4194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000245094299316
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:random_action_porb = 0.9900915
DEBUG:root: dqn, choose action rondomly, need time 0.00053299999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =4197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =4198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000140190124512
INFO:root:random_action_porb = 0.990082
DEBUG:root: dqn, choose action rondomly, need time 0.000344000000013
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  469.17559814]
 [   60.33242416]
 [   51.48636246]
 [   51.48636246]
 [ 5873.36914062]
 [    9.59065342]
 [   99.83306122]
 [   29.18432808]
 [   28.3220253 ]
 [  283.88876343]
 [   49.65954971]
 [  683.90118408]
 [   49.65954971]
 [   52.02877808]
 [    8.78894138]
 [  353.43725586]]
DEBUG:root:training time = %d0.196409
INFO:root:frame =4201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:frame =4202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9900725
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =4205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488042831421
INFO:root:frame =4206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.990063
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.62974731e+02]
 [  6.11272202e+01]
 [  2.60671753e+02]
 [  2.24428501e+01]
 [  3.72396484e+02]
 [  1.81862521e+00]
 [  1.12519989e+02]
 [  3.32033203e+03]
 [  2.75651337e+02]
 [  9.90540600e+00]
 [  1.37783060e+01]
 [  1.80783463e+01]
 [  5.53246918e+01]
 [  2.24428501e+01]
 [  5.88239746e+02]
 [  1.81862521e+00]]
DEBUG:root:training time = %d0.195565
INFO:root:frame =4209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =4210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000495910644531
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9900535
DEBUG:root: dqn, choose action rondomly, need time 0.000181999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =4213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456809997559
INFO:root:frame =4214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:random_action_porb = 0.990044
DEBUG:root: dqn, choose action rondomly, need time 0.000357000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   17.40299797]
 [  289.20431519]
 [ 1141.80004883]
 [   35.3327713 ]
 [  769.42492676]
 [ 3836.44897461]
 [ 2104.43725586]
 [ 7025.27441406]
 [   10.21241093]
 [   55.6044693 ]
 [ 3662.34228516]
 [ 5121.54541016]
 [   55.6044693 ]
 [ 2337.93994141]
 [ 2147.91577148]
 [ 2586.12207031]]
DEBUG:root:training time = %d0.219747
INFO:root:frame =4217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270128250122
INFO:root:frame =4218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.9900345
DEBUG:root: dqn, choose action rondomly, need time 0.000225
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =4221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =4222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000307083129883
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.990025
DEBUG:root: dqn, choose action rondomly, need time 0.000332
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.25092712e+02]
 [  5.38459717e+02]
 [  1.99922620e+03]
 [  3.40660889e+02]
 [  2.89474243e+03]
 [  3.56235687e+02]
 [  3.86903286e+00]
 [  2.08518951e+02]
 [  1.95096985e+02]
 [  5.38459717e+02]
 [  1.00622915e-01]
 [  1.84250671e+03]
 [  5.80307274e+01]
 [  4.61478729e+02]
 [  1.18363074e+03]
 [  4.62433624e+01]]
DEBUG:root:training time = %d0.216875
INFO:root:frame =4225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:frame =4226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9900155
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =4229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =4230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000495910644531
DEBUG:root: save sample needs time = 0.000173091888428
INFO:root:random_action_porb = 0.990006
DEBUG:root: dqn, choose action rondomly, need time 0.000333999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.02636881e+01]
 [  7.14626465e+02]
 [  2.45410324e+02]
 [  7.26250559e-03]
 [  7.52985840e+02]
 [  3.61557446e+03]
 [  2.39245472e+01]
 [  1.55879483e-02]
 [  4.35748720e+00]
 [  5.95548296e+00]
 [  4.96879785e+03]
 [  3.48755035e+02]
 [  8.16721039e+01]
 [  9.23652649e+00]
 [  2.25908852e+01]
 [  1.53562987e+00]]
DEBUG:root:training time = %d0.192784
INFO:root:frame =4233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =4234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame = 4235 State into memory, numbers recorded 95 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:random_action_porb = 0.9899965
DEBUG:root: dqn, choose action rondomly, need time 0.000279000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4236current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000359058380127
INFO:root:frame =4237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =4238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.989987
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.19746037e+01]
 [  8.20154762e+00]
 [  9.06344891e+00]
 [  2.16377716e+01]
 [  1.70062169e-01]
 [  2.81572083e+02]
 [  1.04867241e+02]
 [  7.79570484e+00]
 [  6.04411583e+01]
 [  5.01302862e+00]
 [  1.85073975e+03]
 [  1.92840538e+01]
 [  7.81977844e+00]
 [  2.28717114e+03]
 [  4.61494446e+02]
 [  6.49833143e-01]]
DEBUG:root:training time = %d0.206663
INFO:root:frame =4241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:frame =4242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000224113464355
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:random_action_porb = 0.9899775
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000156164169312
INFO:root:frame =4245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:frame =4246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame = 4247 State into memory, numbers recorded 96 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:random_action_porb = 0.989968
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4248current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.47554398e+01]
 [  3.64354057e+01]
 [  2.25651646e+00]
 [  1.75717888e+01]
 [  2.21359604e+02]
 [  1.81580042e+03]
 [  2.75380135e+00]
 [  1.62436646e+02]
 [  5.26710999e+02]
 [  9.28882263e+02]
 [  9.83070908e+01]
 [  1.75717888e+01]
 [  5.18441820e+00]
 [  5.25899887e+01]
 [  5.95963013e+02]
 [  2.75522470e-01]]
DEBUG:root:training time = %d0.202312
INFO:root:frame =4249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:frame =4250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000292062759399
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.9899585
DEBUG:root: dqn, choose action rondomly, need time 0.000416999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =4253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =4254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231981277466
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.989949
DEBUG:root: dqn, choose action rondomly, need time 0.000311999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.10684195e+01]
 [  3.54034615e+01]
 [  1.64892149e+00]
 [  6.24929810e+02]
 [  8.64191895e+01]
 [  1.59688263e+01]
 [  3.51083717e+01]
 [  1.31899979e+02]
 [  6.52101059e+01]
 [  2.54902539e+03]
 [  3.45912361e+01]
 [  1.00565374e+00]
 [  2.61791473e+02]
 [  7.06054993e+01]
 [  1.57223148e+01]
 [  1.53083789e+00]]
DEBUG:root:training time = %d0.204777
INFO:root:frame =4257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =4258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame = 4259 State into memory, numbers recorded 97 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:random_action_porb = 0.9899395
DEBUG:root: dqn, choose action rondomly, need time 0.00023800000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4260current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =4261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000486135482788
INFO:root:frame =4262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.98993
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.59846466e+02]
 [  9.60228157e+00]
 [  7.10715103e+00]
 [  1.27781387e+02]
 [  7.61788635e+01]
 [  7.70472527e+00]
 [  9.97072168e+03]
 [  9.97072168e+03]
 [  9.05414307e+02]
 [  3.04482819e+02]
 [  2.49177704e+01]
 [  5.25905640e+02]
 [  5.52819099e+01]
 [  7.37523880e+01]
 [  6.16422272e+01]
 [  5.53379639e+02]]
DEBUG:root:training time = %d0.205515
INFO:root:frame =4265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =4266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.9899205
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =4269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame =4270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000429153442383
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.989911
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000357866287231
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.44368362e+00]
 [  1.10812920e+02]
 [  1.17448130e+01]
 [  6.82851746e+02]
 [  3.62424634e+03]
 [  6.82851746e+02]
 [  3.89723779e+03]
 [  8.87298679e+00]
 [  4.61313867e+03]
 [  2.39406509e+02]
 [  2.47410679e+00]
 [  3.78906281e+02]
 [  1.56606932e+01]
 [  1.75326431e+02]
 [  1.24058968e+02]
 [  6.44921511e-03]]
DEBUG:root:training time = %d0.207563
INFO:root:frame =4273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =4274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame = 4275 State into memory, numbers recorded 98 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000545024871826
INFO:root:random_action_porb = 0.9899015
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4276current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000356912612915
INFO:root:frame =4277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000522136688232
INFO:root:frame =4278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000627040863037
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:random_action_porb = 0.989892
DEBUG:root: dqn, choose action rondomly, need time 0.000369000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.30830455e-01]
 [  2.52503910e+01]
 [  5.25691175e+00]
 [  2.56128809e+03]
 [  1.67821198e+02]
 [  4.55386086e+01]
 [  8.49023987e+02]
 [  9.81241577e+02]
 [  4.44226416e+03]
 [  2.55349289e+02]
 [  2.05723755e+03]
 [  4.54870453e+02]
 [  9.68364868e+01]
 [  9.81241577e+02]
 [  9.66765320e+02]
 [  7.24010742e+02]]
DEBUG:root:training time = %d0.196512
INFO:root:frame =4281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =4282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259876251221
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.9898825
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =4285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =4286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame = 4287 State into memory, numbers recorded 99 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000602006912231
INFO:root:random_action_porb = 0.989873
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4288current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  407.58352661]
 [ 2901.03564453]
 [ 1147.70556641]
 [  608.49963379]
 [    8.64164066]
 [  284.30926514]
 [ 1874.02746582]
 [ 1693.20300293]
 [ 1643.6685791 ]
 [  284.30926514]
 [   22.5143261 ]
 [ 1188.9284668 ]
 [ 1357.58837891]
 [   10.096735  ]
 [ 1357.58837891]
 [   32.83235931]]
DEBUG:root:training time = %d0.206765
INFO:root:frame =4289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:frame =4290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494003295898
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:random_action_porb = 0.9898635
DEBUG:root: dqn, choose action rondomly, need time 0.000339000000011
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:frame =4293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =4294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.989854
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.92747574e+01]
 [  1.19368579e+03]
 [  8.56464160e+03]
 [  6.31529140e+00]
 [  2.60495880e+02]
 [  1.04459030e+02]
 [  3.65135694e+00]
 [  1.31054565e+02]
 [  1.31054565e+02]
 [  1.46144275e+03]
 [  1.05721226e+01]
 [  1.06783728e+03]
 [  3.30491219e+01]
 [  7.15860901e+01]
 [  8.91743591e+02]
 [  4.17291222e+01]]
DEBUG:root:training time = %d0.204739
INFO:root:frame =4297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =4298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000311136245728
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:random_action_porb = 0.9898445
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =4301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000429153442383
INFO:root:frame =4302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000607967376709
INFO:root:frame = 4303 State into memory, numbers recorded 100 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000725030899048
INFO:root:random_action_porb = 0.989835
DEBUG:root: dqn, choose action rondomly, need time 0.000336000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4304current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000342845916748
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   16.89223099]
 [ 3568.78808594]
 [  698.56268311]
 [    3.98673391]
 [  192.08132935]
 [   16.55663872]
 [  583.41790771]
 [  180.71939087]
 [  735.99951172]
 [   59.08053207]
 [   59.08053207]
 [  250.6831665 ]
 [    4.82271385]
 [ 1468.86791992]
 [  958.25463867]
 [   58.1593895 ]]
DEBUG:root:training time = %d0.214386
INFO:root:frame =4305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =4306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame = 4307 State into memory, numbers recorded 101 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000632047653198
INFO:root:random_action_porb = 0.9898255
DEBUG:root: dqn, choose action rondomly, need time 0.000571000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4308current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =4309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000547885894775
INFO:root:frame =4310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000536918640137
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:random_action_porb = 0.989816
DEBUG:root: dqn, choose action rondomly, need time 0.000339000000011
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000357151031494
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.32029190e+01]
 [  1.84211804e+03]
 [  2.64303803e-01]
 [  4.63121094e+02]
 [  5.17009621e+01]
 [  2.24385853e+01]
 [  5.17009621e+01]
 [  6.05877441e+02]
 [  1.18543994e+03]
 [  2.44234937e+03]
 [  1.21454537e+00]
 [  1.89718361e+01]
 [  2.24385853e+01]
 [  8.52041435e+00]
 [  3.90658379e+01]
 [  3.90658379e+01]]
DEBUG:root:training time = %d0.20059
INFO:root:frame =4313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =4314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000174999237061
INFO:root:random_action_porb = 0.9898065
DEBUG:root: dqn, choose action rondomly, need time 0.000247000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180006027222
INFO:root:frame =4317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =4318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247955322266
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.989797
DEBUG:root: dqn, choose action rondomly, need time 0.000479999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:training error  = [[  4.74275970e+00]
 [  2.10247787e+02]
 [  3.76435034e+03]
 [  5.41263723e+00]
 [  4.85893130e-01]
 [  2.88488678e+02]
 [  2.72736282e+01]
 [  1.60944226e+03]
 [  7.58641357e+01]
 [  8.05179688e+02]
 [  3.68555808e+00]
 [  4.72753239e+00]
 [  1.00908463e+02]
 [  3.51330469e+03]
 [  2.43759537e+02]
 [  2.08547821e+02]]
DEBUG:root:training time = %d0.205781
INFO:root:frame =4321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =4322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000311136245728
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root:random_action_porb = 0.9897875
DEBUG:root: dqn, choose action rondomly, need time 0.000205999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000191926956177
INFO:root:frame =4325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000481843948364
INFO:root:frame =4326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.989778
DEBUG:root: dqn, choose action rondomly, need time 0.000366999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000397920608521
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.73569855e+02]
 [  5.31520801e+03]
 [  2.04041004e+01]
 [  5.00630737e+02]
 [  1.47495193e+02]
 [  8.59356873e+02]
 [  8.36021233e+00]
 [  1.11505287e+02]
 [  5.00630737e+02]
 [  6.50713867e+02]
 [  1.29283789e+03]
 [  2.39765579e+02]
 [  4.99512529e+00]
 [  1.31876278e+01]
 [  4.26357536e+01]
 [  1.73569855e+02]]
DEBUG:root:training time = %d0.196291
INFO:root:frame =4329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000387907028198
INFO:root:frame =4330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000292062759399
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:random_action_porb = 0.9897685
DEBUG:root: dqn, choose action rondomly, need time 0.000328999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =4333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =4334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:random_action_porb = 0.989759
DEBUG:root: dqn, choose action rondomly, need time 0.000270999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000217199325562
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.35115204e+02]
 [  2.41199854e+03]
 [  4.29610291e+01]
 [  2.02114822e+02]
 [  9.39092896e+02]
 [  1.33523405e+00]
 [  1.62319791e+00]
 [  7.93192078e+02]
 [  1.62319791e+00]
 [  3.45052986e+01]
 [  3.15534821e+01]
 [  1.79367081e+02]
 [  1.73844318e+01]
 [  2.79313086e+03]
 [  2.83240820e+03]
 [  3.23452954e+03]]
DEBUG:root:training time = %d0.192557
INFO:root:frame =4337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =4338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000356912612915
DEBUG:root: save sample needs time = 0.000151872634888
INFO:root:random_action_porb = 0.9897495
DEBUG:root: dqn, choose action rondomly, need time 0.000394999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =4341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000342845916748
INFO:root:frame =4342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00059986114502
DEBUG:root: save sample needs time = 0.000157117843628
INFO:root:random_action_porb = 0.98974
DEBUG:root: dqn, choose action rondomly, need time 0.000204999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000227212905884
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  565.86560059]
 [  958.44073486]
 [   22.1158638 ]
 [   55.6974678 ]
 [  935.53692627]
 [ 4059.1496582 ]
 [    8.42808342]
 [   84.16024017]
 [  566.355896  ]
 [  442.29663086]
 [  422.66769409]
 [   70.80081177]
 [   88.06852722]
 [  206.86222839]
 [  679.33581543]
 [  238.44892883]]
DEBUG:root:training time = %d0.195134
INFO:root:frame =4345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =4346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000385046005249
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root:random_action_porb = 0.9897305
DEBUG:root: dqn, choose action rondomly, need time 0.000247000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =4349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00143098831177
INFO:root:frame =4350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000380039215088
DEBUG:root: save sample needs time = 0.000155925750732
INFO:root:random_action_porb = 0.989721
DEBUG:root: dqn, choose action rondomly, need time 0.000214
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.10993309e+01]
 [  6.30235596e+02]
 [  2.07806076e+02]
 [  8.37697601e+01]
 [  3.17980444e+03]
 [  2.99757593e+03]
 [  4.42825508e+00]
 [  6.32489586e+00]
 [  7.24487925e+00]
 [  1.48676522e-02]
 [  1.69497261e+01]
 [  6.82742767e+01]
 [  1.50675476e+02]
 [  5.28256409e+02]
 [  1.48167908e+02]
 [  2.45876367e+03]]
DEBUG:root:training time = %d0.196843
INFO:root:frame =4353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000379085540771
INFO:root:frame =4354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324010848999
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:random_action_porb = 0.9897115
DEBUG:root: dqn, choose action rondomly, need time 0.000185999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163793563843
INFO:root:frame =4357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000423192977905
INFO:root:frame =4358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000686168670654
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.989702
DEBUG:root: dqn, choose action rondomly, need time 0.00034500000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.31877327e+01]
 [  1.56320810e-01]
 [  3.66114120e+01]
 [  1.63250397e+02]
 [  9.16266251e+01]
 [  2.14223719e+00]
 [  1.24612684e+01]
 [  1.74739594e+02]
 [  2.33921570e+02]
 [  1.08479749e+03]
 [  4.03939697e+02]
 [  3.78545403e+00]
 [  5.20902466e+02]
 [  1.16641052e+02]
 [  7.46996918e+01]
 [  2.24246231e+02]]
DEBUG:root:training time = %d0.199337
INFO:root:frame =4361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =4362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002601146698
DEBUG:root: save sample needs time = 0.000120162963867
INFO:root:random_action_porb = 0.9896925
DEBUG:root: dqn, choose action rondomly, need time 0.000210999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:frame =4365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =4366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000136852264404
INFO:root:random_action_porb = 0.989683
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.43505890e+02]
 [  9.92229797e+02]
 [  6.64580017e+02]
 [  8.28238606e-01]
 [  9.64367371e+01]
 [  1.09853210e+03]
 [  3.69733057e+03]
 [  2.43505890e+02]
 [  2.89411545e+00]
 [  6.20061340e+02]
 [  9.31937313e+00]
 [  5.76396675e+01]
 [  9.63549435e-01]
 [  7.86640024e+00]
 [  1.03110832e+02]
 [  5.76396675e+01]]
DEBUG:root:training time = %d0.198206
INFO:root:frame =4369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =4370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.9896735
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =4373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000482082366943
INFO:root:frame =4374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000505924224854
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:random_action_porb = 0.989664
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.05557625e+02]
 [  3.28043556e+01]
 [  5.10819141e+03]
 [  2.68723059e+00]
 [  9.70809860e+01]
 [  1.45696449e+01]
 [  4.17603760e+01]
 [  4.99486230e+03]
 [  3.98820251e-01]
 [  5.66396777e+03]
 [  2.53325867e+02]
 [  2.18907275e+03]
 [  7.52986816e+02]
 [  1.33564413e+00]
 [  1.24176430e+02]
 [  2.05877457e+02]]
DEBUG:root:training time = %d0.206631
INFO:root:frame =4377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =4378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000507831573486
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:random_action_porb = 0.9896545
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =4381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000405073165894
INFO:root:frame =4382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame = 4383 State into memory, numbers recorded 102 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000643014907837
INFO:root:random_action_porb = 0.989645
DEBUG:root: dqn, choose action rondomly, need time 0.000467999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4384current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000332832336426
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.35131958e+02]
 [  2.76438951e+00]
 [  1.65716272e+03]
 [  6.01288223e+00]
 [  3.78925872e+00]
 [  3.16621118e+03]
 [  2.31817285e+03]
 [  3.83756012e+02]
 [  8.09065918e+02]
 [  3.33540955e+02]
 [  6.19126844e+00]
 [  7.82846240e+03]
 [  1.02725159e+03]
 [  3.16621118e+03]
 [  1.65716272e+03]
 [  3.80774384e+01]]
DEBUG:root:training time = %d0.204227
INFO:root:frame =4385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =4386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00029182434082
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9896355
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =4389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =4390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000587940216064
DEBUG:root: save sample needs time = 0.000194072723389
INFO:root:random_action_porb = 0.989626
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.30502885e-05]
 [  6.85456161e+01]
 [  4.91028229e+02]
 [  3.65581836e+03]
 [  1.90846920e+00]
 [  1.05482397e+03]
 [  6.57559824e+00]
 [  1.49507996e+02]
 [  1.41433508e+03]
 [  4.06961861e+01]
 [  4.06961861e+01]
 [  6.74802734e+02]
 [  8.71983643e+02]
 [  4.51184418e+02]
 [  6.24426956e+01]
 [  2.83894043e+01]]
DEBUG:root:training time = %d0.197652
INFO:root:frame =4393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =4394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000367879867554
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.9896165
DEBUG:root: dqn, choose action rondomly, need time 0.000164999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000146865844727
INFO:root:frame =4397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:frame =4398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000256061553955
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:random_action_porb = 0.989607
DEBUG:root: dqn, choose action rondomly, need time 0.00021799999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000181913375854
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.99202057e+02]
 [  5.48307764e+03]
 [  3.40036072e+02]
 [  5.97020630e+02]
 [  5.48111877e+02]
 [  6.36666260e+02]
 [  1.67812897e+02]
 [  2.37036697e+02]
 [  6.11674927e+02]
 [  5.97020630e+02]
 [  6.54522400e+01]
 [  1.08759756e+01]
 [  4.77390442e+02]
 [  4.66723108e+00]
 [  2.24219653e+03]
 [  3.23330597e+02]]
DEBUG:root:training time = %d0.199822
INFO:root:frame =4401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029182434082
INFO:root:frame =4402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.000101804733276
INFO:root:random_action_porb = 0.9895975
INFO:root:dqn select action Tensor("ArgMax_6:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.008903
INFO:root:action choosen by dqn [2]
INFO:root:frame =4404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root:frame =4405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002281665802
INFO:root:frame =4406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227928161621
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.989588
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032377243042
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   36.14727402]
 [  716.05444336]
 [    4.8867774 ]
 [  795.02471924]
 [ 3146.95141602]
 [  266.96456909]
 [   14.9929285 ]
 [  123.88516235]
 [  300.70959473]
 [    6.65135145]
 [ 1601.43713379]
 [  333.08380127]
 [ 1536.76416016]
 [ 3146.95141602]
 [  266.96456909]
 [  342.14282227]]
DEBUG:root:training time = %d0.197157
INFO:root:frame =4409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249147415161
INFO:root:frame =4410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000191926956177
INFO:root:random_action_porb = 0.9895785
DEBUG:root: dqn, choose action rondomly, need time 0.000326999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =4413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =4414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446796417236
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.989569
DEBUG:root: dqn, choose action rondomly, need time 0.000294000000011
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.10889153e+02]
 [  3.46725535e+00]
 [  1.64923309e+02]
 [  3.99456978e+00]
 [  1.02601166e+01]
 [  1.69907045e+00]
 [  4.64314850e+02]
 [  1.21156990e+02]
 [  4.54886742e+01]
 [  2.50018628e+03]
 [  1.99888403e+03]
 [  1.99888403e+03]
 [  1.21156990e+02]
 [  1.13231262e+02]
 [  2.23927368e+02]
 [  2.81853600e+01]]
DEBUG:root:training time = %d0.195639
INFO:root:frame =4417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:frame =4418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9895595
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =4421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000492095947266
INFO:root:frame =4422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.98955
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  999.62365723]
 [   60.12672806]
 [  457.94961548]
 [  277.30981445]
 [  148.85662842]
 [    2.12860203]
 [    3.73677516]
 [  205.14083862]
 [   24.78437805]
 [  299.49658203]
 [  119.24019623]
 [    2.63038039]
 [   12.9906044 ]
 [   24.40558434]
 [ 1127.99157715]
 [    2.840554  ]]
DEBUG:root:training time = %d0.207081
INFO:root:frame =4425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:frame =4426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame = 4427 State into memory, numbers recorded 103 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:random_action_porb = 0.9895405
DEBUG:root: dqn, choose action rondomly, need time 0.000330999999989
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4428current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =4429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =4430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000684022903442
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.989531
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.02945733e-01]
 [  1.71569383e+00]
 [  7.23312195e+02]
 [  7.23312195e+02]
 [  2.75160561e+01]
 [  1.29708260e-01]
 [  4.29468269e+01]
 [  9.02776146e+00]
 [  1.62810059e+02]
 [  3.36918115e+03]
 [  9.83289185e+01]
 [  1.51974548e+03]
 [  2.58202240e+02]
 [  2.50777539e+03]
 [  1.48990222e+03]
 [  2.23338086e+03]]
DEBUG:root:training time = %d0.200569
INFO:root:frame =4433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =4434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.9895215
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =4437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =4438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241041183472
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.989512
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.01471643e+03]
 [  2.86079049e+00]
 [  5.30833496e+03]
 [  1.22111678e+00]
 [  4.41812347e+02]
 [  8.10542011e+00]
 [  1.53990295e+02]
 [  3.95369165e+03]
 [  7.91398315e+01]
 [  5.74315549e-04]
 [  1.44439954e+03]
 [  1.79058521e+03]
 [  2.91219189e+03]
 [  1.79058521e+03]
 [  2.84734741e+02]
 [  1.79058521e+03]]
DEBUG:root:training time = %d0.200636
INFO:root:frame =4441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000342845916748
INFO:root:frame =4442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000221014022827
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.9895025
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =4445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =4446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.989493
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312805175781
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 429.43988037]
 [ 997.37457275]
 [ 431.43157959]
 [   4.38672876]
 [ 764.69433594]
 [ 705.45861816]
 [ 764.69433594]
 [ 349.88879395]
 [ 883.06988525]
 [ 426.07382202]
 [ 726.94647217]
 [ 429.43988037]
 [   3.78617048]
 [  27.21023369]
 [   2.27069831]
 [ 121.10517883]]
DEBUG:root:training time = %d0.207081
INFO:root:frame =4449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000358104705811
INFO:root:frame =4450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000188112258911
INFO:root:random_action_porb = 0.9894835
DEBUG:root: dqn, choose action rondomly, need time 0.000321
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =4453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =4454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464200973511
DEBUG:root: save sample needs time = 0.000245809555054
INFO:root:random_action_porb = 0.989474
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.32203007e+00]
 [  2.36297474e+01]
 [  5.12922180e+02]
 [  8.17519775e+02]
 [  9.82134155e+02]
 [  1.29892090e+02]
 [  2.39729590e+03]
 [  1.91933525e+00]
 [  6.88424377e+01]
 [  9.76682842e-01]
 [  2.36297474e+01]
 [  7.96531296e+01]
 [  1.28781769e+02]
 [  8.56873322e+01]
 [  6.88424377e+01]
 [  3.32255493e+02]]
DEBUG:root:training time = %d0.217103
INFO:root:frame =4457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000370025634766
INFO:root:frame =4458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9894645
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =4461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000485897064209
INFO:root:frame =4462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.989455
DEBUG:root: dqn, choose action rondomly, need time 0.000316000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.66156097e+02]
 [  1.48805679e+02]
 [  1.64654572e+02]
 [  3.02319336e+03]
 [  2.09475384e+01]
 [  4.00430412e+01]
 [  2.42999382e+01]
 [  1.37811548e+03]
 [  1.31597729e+03]
 [  5.86036797e+01]
 [  3.02319336e+03]
 [  3.17678899e-01]
 [  3.02319336e+03]
 [  5.38371704e+02]
 [  2.43454468e+02]
 [  5.47786140e+01]]
DEBUG:root:training time = %d0.21287
INFO:root:frame =4465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =4466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9894455
DEBUG:root: dqn, choose action rondomly, need time 0.000508999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =4469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =4470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000467777252197
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.989436
DEBUG:root: dqn, choose action rondomly, need time 0.000323999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.29183594e+02]
 [  7.66544678e+03]
 [  5.93758362e+02]
 [  1.00783920e+01]
 [  1.21585274e+02]
 [  1.78800869e+01]
 [  1.48596710e+02]
 [  4.48151559e-01]
 [  3.29183594e+02]
 [  1.24210100e+01]
 [  1.31505737e+02]
 [  8.90308838e+02]
 [  1.00783920e+01]
 [  3.66625671e+01]
 [  1.09712966e-02]
 [  1.25559759e+01]]
DEBUG:root:training time = %d0.21388
INFO:root:frame =4473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =4474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000311851501465
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.9894265
DEBUG:root: dqn, choose action rondomly, need time 0.000349999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root:frame =4477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =4478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame = 4479 State into memory, numbers recorded 104 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:random_action_porb = 0.989417
DEBUG:root: dqn, choose action rondomly, need time 0.00016699999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4480current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.39920752e+03]
 [  5.96644104e+02]
 [  7.54277878e+01]
 [  6.26312523e+01]
 [  7.54277878e+01]
 [  2.39793274e+02]
 [  1.65960632e+03]
 [  7.39329407e+02]
 [  4.62011397e-01]
 [  4.58475828e+00]
 [  1.69502907e+01]
 [  1.24160446e+02]
 [  1.15779163e+03]
 [  1.96172638e+02]
 [  6.26312523e+01]
 [  1.06521606e+02]]
DEBUG:root:training time = %d0.203491
INFO:root:frame =4481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =4482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame = 4483 State into memory, numbers recorded 105 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000637054443359
INFO:root:random_action_porb = 0.9894075
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4484current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =4485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:frame =4486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.989398
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   13.37968731]
 [   65.88848877]
 [    4.41335869]
 [   45.76779556]
 [ 3044.6328125 ]
 [   33.20170975]
 [  235.4934082 ]
 [  768.86169434]
 [    4.41335869]
 [ 1315.359375  ]
 [  129.44390869]
 [  427.82998657]
 [   46.188591  ]
 [ 1141.3203125 ]
 [    6.27856636]
 [   99.84899139]]
DEBUG:root:training time = %d0.212163
INFO:root:frame =4489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root:frame =4490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9893885
DEBUG:root: dqn, choose action rondomly, need time 0.000415000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =4493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =4494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486850738525
INFO:root:frame = 4495 State into memory, numbers recorded 106 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000612020492554
INFO:root:random_action_porb = 0.989379
DEBUG:root: dqn, choose action rondomly, need time 0.000274000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4496current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.27935046e+03]
 [  4.52793549e+02]
 [  6.60563583e+01]
 [  9.77530518e+01]
 [  6.39759243e-01]
 [  2.78227258e+00]
 [  6.89756927e+01]
 [  2.20862427e+01]
 [  8.84201355e+01]
 [  5.10484695e+01]
 [  1.23887047e+02]
 [  7.51059113e+01]
 [  5.10484695e+01]
 [  6.10748108e+02]
 [  1.71769312e+03]
 [  1.05443726e+02]]
DEBUG:root:training time = %d0.20976
INFO:root:frame =4497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root:frame =4498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000400066375732
DEBUG:root: save sample needs time = 0.000134944915771
INFO:root:random_action_porb = 0.9893695
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =4501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =4502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame = 4503 State into memory, numbers recorded 107 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000545978546143
INFO:root:random_action_porb = 0.98936
DEBUG:root: dqn, choose action rondomly, need time 0.000416000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4504current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.84730530e+02]
 [  3.85438354e+02]
 [  6.88013489e+02]
 [  4.52845154e+02]
 [  1.83214493e+02]
 [  8.52893219e+01]
 [  5.61470509e-01]
 [  3.09127243e-03]
 [  2.20900130e+00]
 [  4.37701367e+03]
 [  1.03232399e+02]
 [  1.29449821e+00]
 [  6.38556123e-01]
 [  2.44496269e+01]
 [  2.86000269e+03]
 [  3.14976215e+01]]
DEBUG:root:training time = %d0.215724
INFO:root:frame =4505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =4506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227928161621
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9893505
DEBUG:root: dqn, choose action rondomly, need time 0.000447999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =4509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =4510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000332832336426
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.989341
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[  4.60992493e+02]
 [  3.83567715e+00]
 [  9.92652740e+01]
 [  4.15961609e+01]
 [  5.67888618e-02]
 [  4.67614441e+01]
 [  1.17344507e+03]
 [  2.75963364e+01]
 [  4.06223297e+00]
 [  5.09117822e+03]
 [  2.23257227e+03]
 [  1.67304096e+01]
 [  2.12929592e+01]
 [  7.94345032e+02]
 [  8.47558677e-01]
 [  4.01195648e+02]]
DEBUG:root:training time = %d0.199361
INFO:root:frame =4513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =4514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9893315
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =4517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =4518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000522136688232
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.989322
DEBUG:root: dqn, choose action rondomly, need time 0.000338000000013
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.14571714e+00]
 [  6.22263298e+01]
 [  5.14571714e+00]
 [  1.44259367e+01]
 [  3.21256965e-01]
 [  3.77001587e+02]
 [  6.61467361e+01]
 [  3.55116768e+01]
 [  1.68697862e-03]
 [  2.78522563e+00]
 [  8.54135156e-01]
 [  2.34715233e+01]
 [  1.14984595e+03]
 [  6.05741577e+02]
 [  5.99968147e+00]
 [  1.14984595e+03]]
DEBUG:root:training time = %d0.207955
INFO:root:frame =4521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =4522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000297069549561
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.9893125
DEBUG:root: dqn, choose action rondomly, need time 0.000183000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000168085098267
INFO:root:frame =4525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =4526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000639200210571
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.989303
DEBUG:root: dqn, choose action rondomly, need time 0.000338999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.62970062e+02]
 [  1.96915417e+01]
 [  1.82826829e+00]
 [  3.20052612e+02]
 [  7.16513824e+01]
 [  1.97625183e+02]
 [  2.88440735e+02]
 [  2.07087231e+00]
 [  3.08827698e+02]
 [  3.81542236e-01]
 [  3.77809584e-01]
 [  1.97625183e+02]
 [  2.45342026e+01]
 [  4.79503143e+02]
 [  2.49308789e+03]
 [  8.66274902e+02]]
DEBUG:root:training time = %d0.211736
INFO:root:frame =4529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root: ememy has been killed for 8 times 
INFO:root:enemies_left [0]
INFO:root:frame =4530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:frame = 4531 State into memory, numbers recorded 108 action = 1, reward = 255
DEBUG:root: save sample needs time = 0.000549077987671
INFO:root:random_action_porb = 0.9892935
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4532current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =4533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =4534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame = 4535 State into memory, numbers recorded 109 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000609159469604
INFO:root:random_action_porb = 0.989284
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4536current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  253.53962708]
 [   87.57126617]
 [  580.49298096]
 [   26.89577103]
 [   16.07785416]
 [   77.90211487]
 [   33.72602463]
 [ 1458.09228516]
 [ 4126.62841797]
 [  252.1318512 ]
 [  529.5255127 ]
 [  529.5255127 ]
 [  121.579216  ]
 [  580.49298096]
 [   10.83389759]
 [  344.51400757]]
DEBUG:root:training time = %d0.213412
INFO:root:frame =4537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =4538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000116109848022
INFO:root:random_action_porb = 0.9892745
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =4541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245809555054
INFO:root:frame =4542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame = 4543 State into memory, numbers recorded 110 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000581979751587
INFO:root:random_action_porb = 0.989265
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4544current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   18.72030258]
 [    1.57344341]
 [   99.66596222]
 [   66.31680298]
 [  207.82040405]
 [   11.28861046]
 [   85.34457397]
 [  538.52630615]
 [   18.72030258]
 [   50.36654282]
 [   71.27846527]
 [   85.34457397]
 [ 1540.64160156]
 [   91.19789886]
 [    9.92013073]
 [   16.58241463]]
DEBUG:root:training time = %d0.195856
INFO:root:frame =4545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =4546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456809997559
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.9892555
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =4550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:random_action_porb = 0.989246
DEBUG:root: dqn, choose action rondomly, need time 0.000202000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000186204910278
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.08365063e+03]
 [  7.48637695e+02]
 [  4.85488027e-01]
 [  6.13407776e+02]
 [  2.29098083e+02]
 [  9.05046973e+03]
 [  1.61352673e+03]
 [  4.88101349e+02]
 [  1.38790045e+01]
 [  1.12649927e+03]
 [  1.11300061e+03]
 [  7.06227207e+00]
 [  2.78358936e+01]
 [  7.91582203e+00]
 [  1.97465100e+03]
 [  3.12568340e+01]]
DEBUG:root:training time = %d0.20179
INFO:root:frame =4553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:frame =4554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000221014022827
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9892365
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =4557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =4558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 9.51290130615e-05
INFO:root:random_action_porb = 0.989227
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   55.50881958]
 [  137.81231689]
 [ 1193.53613281]
 [    3.49303079]
 [    3.76937675]
 [  137.81231689]
 [   11.1913681 ]
 [   11.1913681 ]
 [  413.82843018]
 [   11.1913681 ]
 [ 2086.14379883]
 [ 1193.53613281]
 [  407.33758545]
 [  384.11178589]
 [   49.40494156]
 [  248.36708069]]
DEBUG:root:training time = %d0.205871
INFO:root:frame =4561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:frame =4562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000327110290527
DEBUG:root: save sample needs time = 0.000201225280762
INFO:root:random_action_porb = 0.9892175
DEBUG:root: dqn, choose action rondomly, need time 0.000336999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:frame =4565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454187393188
INFO:root:frame =4566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.989208
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.67330132e+01]
 [  4.94252815e+01]
 [  1.44189763e+00]
 [  7.14527344e+02]
 [  8.10525330e+02]
 [  4.11755867e+01]
 [  8.94899048e+02]
 [  1.03523865e+03]
 [  3.07821747e+02]
 [  1.55906868e+00]
 [  4.67330132e+01]
 [  9.91970508e+03]
 [  1.55906868e+00]
 [  6.28812885e+00]
 [  6.17045898e+02]
 [  5.51206303e+00]]
DEBUG:root:training time = %d0.201972
INFO:root:frame =4569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:frame =4570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9891985
DEBUG:root: dqn, choose action rondomly, need time 0.000366
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:frame =4573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000411033630371
INFO:root:frame =4574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.989189
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  651.67010498]
 [  682.33782959]
 [   76.14910126]
 [  107.06404114]
 [   45.23931885]
 [    3.66275907]
 [   77.38716125]
 [ 1379.35119629]
 [   42.48106384]
 [    7.4192977 ]
 [ 1068.79394531]
 [  797.39709473]
 [   46.33201981]
 [   13.0900135 ]
 [   24.36982918]
 [   13.0900135 ]]
DEBUG:root:training time = %d0.205906
INFO:root:frame =4577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =4578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000380992889404
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9891795
DEBUG:root: dqn, choose action rondomly, need time 0.000579999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =4581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470876693726
INFO:root:frame =4582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00048303604126
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.98917
DEBUG:root: dqn, choose action rondomly, need time 0.000184000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.29483475e+02]
 [  8.88257921e-01]
 [  7.93416595e+01]
 [  1.38633545e+02]
 [  8.47585388e+02]
 [  2.57661133e+02]
 [  2.31108795e+02]
 [  7.93416595e+01]
 [  5.16643257e+01]
 [  4.56488251e+02]
 [  1.08417107e+02]
 [  5.00816650e+02]
 [  8.38777125e-01]
 [  2.33919693e+02]
 [  4.05277295e+03]
 [  6.41704834e+02]]
DEBUG:root:training time = %d0.1919
INFO:root:frame =4585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000385999679565
INFO:root:frame =4586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000258922576904
DEBUG:root: save sample needs time = 0.00010085105896
INFO:root:random_action_porb = 0.9891605
DEBUG:root: dqn, choose action rondomly, need time 0.000563
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =4589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000482082366943
INFO:root:frame =4590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.989151
DEBUG:root: dqn, choose action rondomly, need time 0.000360000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000346899032593
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.30512280e+03]
 [  7.00623095e-01]
 [  1.62134119e+03]
 [  6.70415926e+00]
 [  1.69850807e+01]
 [  4.42181587e+01]
 [  7.17537964e+02]
 [  1.96093578e+01]
 [  6.11594353e+01]
 [  8.68151169e+01]
 [  5.55490379e+01]
 [  5.57902031e+01]
 [  2.17014160e+01]
 [  1.43661165e+01]
 [  9.54656887e+00]
 [  8.93519497e+00]]
DEBUG:root:training time = %d0.209015
INFO:root:frame =4593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =4594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000500202178955
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.9891415
INFO:root:dqn select action Tensor("ArgMax_7:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011091
INFO:root:action choosen by dqn [2]
INFO:root:frame =4596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00038480758667
INFO:root:frame =4597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000772953033447
INFO:root:frame =4598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.989132
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   42.02357483]
 [ 1696.14367676]
 [  718.95330811]
 [  531.91516113]
 [  357.83331299]
 [ 2097.56347656]
 [  253.73609924]
 [    6.1473093 ]
 [    2.41024971]
 [ 2142.73657227]
 [   42.02357483]
 [    8.19296265]
 [   19.32369995]
 [  317.20281982]
 [   35.82890701]
 [   61.81543732]]
DEBUG:root:training time = %d0.205257
INFO:root:frame =4601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:frame =4602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000310897827148
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.9891225
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =4605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =4606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.989113
DEBUG:root: dqn, choose action rondomly, need time 0.000181000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000168085098267
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.39922095e+03]
 [  4.16652756e+01]
 [  1.26331128e+03]
 [  8.46514206e+01]
 [  2.21516266e-02]
 [  9.26246834e+00]
 [  4.64401642e+02]
 [  4.82498596e+02]
 [  4.32105217e+01]
 [  9.34772778e+00]
 [  4.70328027e+03]
 [  2.20422510e+03]
 [  5.01897478e+00]
 [  1.50745346e+02]
 [  1.74790924e+02]
 [  4.26213379e+02]]
DEBUG:root:training time = %d0.197085
INFO:root:frame =4609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =4610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame = 4611 State into memory, numbers recorded 111 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000408172607422
INFO:root:random_action_porb = 0.9891035
DEBUG:root: dqn, choose action rondomly, need time 0.000223000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4612current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000229835510254
INFO:root:frame =4613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000364065170288
INFO:root:frame =4614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000291109085083
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.989094
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.33213270e+00]
 [  1.51601608e+02]
 [  7.12248862e-01]
 [  2.67567754e+00]
 [  2.38274059e+01]
 [  5.74655701e+02]
 [  1.67384930e+01]
 [  2.49695874e+03]
 [  6.27934631e+02]
 [  1.11314624e+03]
 [  5.80541626e+02]
 [  1.15724963e+03]
 [  9.72253704e+00]
 [  5.60166699e+03]
 [  1.84827789e+02]
 [  1.78863281e+02]]
DEBUG:root:training time = %d0.215504
INFO:root:frame =4617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:frame =4618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9890845
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =4621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =4622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.989075
DEBUG:root: dqn, choose action rondomly, need time 0.000489999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   5.23501873]
 [ 471.9546814 ]
 [ 229.57331848]
 [ 464.69146729]
 [  22.42713165]
 [ 318.31787109]
 [ 458.0534668 ]
 [ 960.39746094]
 [  48.75559998]
 [ 229.57331848]
 [   1.20593822]
 [ 605.20684814]
 [ 562.01318359]
 [  22.42713165]
 [   1.04944766]
 [  51.5015831 ]]
DEBUG:root:training time = %d0.193097
INFO:root:frame =4625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:frame =4626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:random_action_porb = 0.9890655
DEBUG:root: dqn, choose action rondomly, need time 0.000237000000013
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000224828720093
INFO:root:frame =4629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =4630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:random_action_porb = 0.989056
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.44980347e-01]
 [  2.03859726e+02]
 [  3.51997498e+02]
 [  2.19672925e+03]
 [  1.71300766e+02]
 [  3.45260010e+01]
 [  3.47049225e+02]
 [  5.69650664e+04]
 [  5.05559616e+01]
 [  3.28057773e+04]
 [  3.08956738e+01]
 [  1.24298048e+01]
 [  2.67298071e+03]
 [  1.17906021e+02]
 [  5.62973118e+00]
 [  3.05061703e+01]]
DEBUG:root:training time = %d0.200819
INFO:root:frame =4633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:frame =4634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000245094299316
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.9890465
DEBUG:root: dqn, choose action rondomly, need time 0.000347000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000391006469727
INFO:root:frame =4637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000660181045532
INFO:root:frame =4638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.989037
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.42222949e+03]
 [  8.30228613e+03]
 [  4.37672329e+00]
 [  7.31490707e+01]
 [  2.49174536e+03]
 [  3.27770020e+02]
 [  1.02389941e+03]
 [  4.88808777e+02]
 [  1.02389941e+03]
 [  5.10006714e+02]
 [  3.25381351e+00]
 [  7.75097733e+01]
 [  7.92414001e+02]
 [  2.19826260e+01]
 [  9.12573975e+02]
 [  3.05032501e+02]]
DEBUG:root:training time = %d0.207123
INFO:root:frame =4641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:frame =4642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000221014022827
DEBUG:root: save sample needs time = 0.000107049942017
INFO:root:random_action_porb = 0.9890275
DEBUG:root: dqn, choose action rondomly, need time 0.00035299999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000407934188843
INFO:root:frame =4645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =4646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.989018
DEBUG:root: dqn, choose action rondomly, need time 0.000338999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.72654224e+03]
 [  4.54132568e+02]
 [  2.74733826e+02]
 [  2.31519871e+01]
 [  3.46593861e-03]
 [  3.33817285e+03]
 [  1.31926575e+02]
 [  7.46689653e+00]
 [  5.35374207e+02]
 [  5.91575195e+02]
 [  8.34870224e+01]
 [  1.69615625e+03]
 [  1.72654224e+03]
 [  3.73750076e+01]
 [  1.53734398e+00]
 [  8.30564575e+02]]
DEBUG:root:training time = %d0.190672
INFO:root:frame =4649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:frame =4650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000338077545166
DEBUG:root: save sample needs time = 0.000121831893921
INFO:root:random_action_porb = 0.9890085
DEBUG:root: dqn, choose action rondomly, need time 0.000226000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =4653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =4654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000134944915771
INFO:root:random_action_porb = 0.988999
DEBUG:root: dqn, choose action rondomly, need time 0.000219000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000147104263306
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.74719715e+01]
 [  1.24581985e+01]
 [  1.01237476e+00]
 [  1.18178979e+03]
 [  1.73896484e+01]
 [  1.87751025e+03]
 [  1.59947845e+02]
 [  2.85715393e+02]
 [  4.96254547e+02]
 [  1.70723801e+02]
 [  2.22625635e+03]
 [  7.91204453e+00]
 [  2.19124951e+03]
 [  7.26614141e+00]
 [  2.84967529e+02]
 [  3.59474220e+01]]
DEBUG:root:training time = %d0.201588
INFO:root:frame =4657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =4658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00036096572876
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.9889895
DEBUG:root: dqn, choose action rondomly, need time 0.000219999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =4661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000353097915649
INFO:root:frame =4662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504016876221
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root:random_action_porb = 0.98898
DEBUG:root: dqn, choose action rondomly, need time 0.000493999999989
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.96265583e+01]
 [  1.16423860e-01]
 [  1.80503983e+02]
 [  9.37456116e+02]
 [  2.64091522e+02]
 [  1.80503983e+02]
 [  3.96156738e+02]
 [  5.60657494e-02]
 [  2.14548111e+02]
 [  4.39490448e+02]
 [  8.65454078e-01]
 [  7.24944611e+01]
 [  7.13379932e+03]
 [  1.42229321e+03]
 [  5.83473389e+02]
 [  1.60268784e+01]]
DEBUG:root:training time = %d0.197408
INFO:root:frame =4665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =4666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411987304688
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:random_action_porb = 0.9889705
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000391006469727
INFO:root:frame =4669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =4670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.988961
DEBUG:root: dqn, choose action rondomly, need time 0.000185000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.61969528e-01]
 [  6.12217407e+01]
 [  4.39275055e+01]
 [  3.19475830e+03]
 [  4.05046997e+01]
 [  5.42848396e+01]
 [  2.44209564e+02]
 [  9.07739014e+02]
 [  4.85242859e+02]
 [  3.15209869e+02]
 [  7.13795006e-01]
 [  1.07618782e+02]
 [  3.49658928e+01]
 [  9.95049095e+00]
 [  2.64486194e-01]
 [  4.17314911e+01]]
DEBUG:root:training time = %d0.218304
INFO:root:frame =4673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285148620605
INFO:root:frame =4674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424861907959
INFO:root:frame = 4675 State into memory, numbers recorded 112 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000514030456543
INFO:root:random_action_porb = 0.9889515
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4676current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =4677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =4678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000420808792114
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.988942
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.62689877e+00]
 [  2.51541528e+03]
 [  1.02307733e+03]
 [  3.25916910e+00]
 [  8.85935822e+01]
 [  1.41243851e+02]
 [  1.59032120e+02]
 [  1.45719922e+03]
 [  4.09299512e+03]
 [  8.65112915e+02]
 [  8.90965698e+02]
 [  2.07985878e-01]
 [  8.09727966e+02]
 [  2.51541528e+03]
 [  1.45719922e+03]
 [  1.85984462e-01]]
DEBUG:root:training time = %d0.193904
INFO:root:frame =4681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =4682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255823135376
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9889325
DEBUG:root: dqn, choose action rondomly, need time 0.000332999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =4685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000484943389893
INFO:root:frame =4686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000682830810547
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.988923
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000360012054443
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.69171509e+02]
 [  1.14600716e+01]
 [  3.39180542e+02]
 [  2.23786057e+02]
 [  1.72568323e+03]
 [  1.03889209e+03]
 [  8.12976868e+02]
 [  7.65694427e+01]
 [  8.96405578e-02]
 [  3.41954370e+03]
 [  8.96501953e+02]
 [  7.49351549e+00]
 [  1.14600716e+01]
 [  1.92158337e+01]
 [  9.20180231e-04]
 [  9.20180231e-04]]
DEBUG:root:training time = %d0.202866
INFO:root:frame =4689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =4690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000107049942017
INFO:root:random_action_porb = 0.9889135
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =4693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =4694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.988904
DEBUG:root: dqn, choose action rondomly, need time 0.000350999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.38890045e+02]
 [  1.34548676e+02]
 [  4.69090820e+03]
 [  6.00065327e+00]
 [  2.26423242e+03]
 [  6.65638611e+02]
 [  1.65543015e+02]
 [  7.66021912e+02]
 [  6.65638611e+02]
 [  3.58042419e+02]
 [  4.20849264e-01]
 [  1.47752352e+01]
 [  2.44014038e+02]
 [  6.91799463e+03]
 [  5.87642848e-01]
 [  2.74146576e+01]]
DEBUG:root:training time = %d0.211349
INFO:root:frame =4697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =4698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00149893760681
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:random_action_porb = 0.9888945
DEBUG:root: dqn, choose action rondomly, need time 0.000230999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:frame =4701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000373840332031
INFO:root:frame =4702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000338077545166
DEBUG:root: save sample needs time = 0.000134944915771
INFO:root:random_action_porb = 0.988885
DEBUG:root: dqn, choose action rondomly, need time 0.000194999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.05567093e+01]
 [  7.97384491e+01]
 [  2.43923931e+01]
 [  2.84484106e+03]
 [  5.68568802e+00]
 [  6.38115906e+02]
 [  2.94533105e+03]
 [  1.17213711e+04]
 [  1.58380661e+02]
 [  1.82334251e+01]
 [  2.30920720e+00]
 [  1.78156223e+01]
 [  1.08156140e+03]
 [  2.52429047e+02]
 [  4.80305878e+02]
 [  3.53202963e+00]]
DEBUG:root:training time = %d0.187786
INFO:root:frame =4705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root: ememy has been killed for 9 times 
INFO:root:enemies_left [0]
INFO:root:frame =4706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame = 4707 State into memory, numbers recorded 113 action = 4, reward = 255
DEBUG:root: save sample needs time = 0.00042986869812
INFO:root:random_action_porb = 0.9888755
DEBUG:root: dqn, choose action rondomly, need time 0.000226999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4708current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000155925750732
INFO:root:frame =4709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =4710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264883041382
DEBUG:root: save sample needs time = 0.000152826309204
INFO:root:random_action_porb = 0.988866
DEBUG:root: dqn, choose action rondomly, need time 0.000239000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 350.1640625 ]
 [ 610.15600586]
 [ 278.77728271]
 [  98.98178864]
 [   9.60089874]
 [   3.28647017]
 [   9.15298843]
 [  25.19152069]
 [   4.16443682]
 [ 219.58399963]
 [ 121.69167328]
 [  19.36122131]
 [   1.29023957]
 [   9.15298843]
 [   2.48369932]
 [  39.08823013]]
DEBUG:root:training time = %d0.189773
INFO:root:frame =4713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:frame =4714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.9888565
DEBUG:root: dqn, choose action rondomly, need time 0.000160999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000136852264404
INFO:root:frame =4717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =4718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.988847
DEBUG:root: dqn, choose action rondomly, need time 0.000183000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000147104263306
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.15442459e+02]
 [  3.56595001e+01]
 [  2.36427051e+03]
 [  2.44369555e+00]
 [  3.09999268e+02]
 [  9.43750367e-02]
 [  8.52095093e+02]
 [  7.12058945e+01]
 [  2.25976151e+02]
 [  9.11203537e+01]
 [  1.46305025e+00]
 [  3.20738411e+01]
 [  7.12058945e+01]
 [  1.53780472e+02]
 [  8.95708501e-01]
 [  1.25765881e+03]]
DEBUG:root:training time = %d0.196135
INFO:root:frame =4721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =4722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229835510254
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.9888375
DEBUG:root: dqn, choose action rondomly, need time 0.000275999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:frame =4725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =4726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.988828
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000248193740845
INFO:root:training error  = [[  9.57032104e+02]
 [  6.74219971e+01]
 [  1.59634912e+03]
 [  4.88681885e+03]
 [  2.17563400e+02]
 [  8.26204967e+00]
 [  5.91281128e+00]
 [  3.72191505e+01]
 [  5.11817598e+00]
 [  1.43939342e+01]
 [  2.06400220e+03]
 [  1.30034149e+02]
 [  1.84510124e+00]
 [  5.91281128e+00]
 [  1.92474548e+02]
 [  3.09899747e-01]]
DEBUG:root:training time = %d0.208414
INFO:root:frame =4729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =4730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049090385437
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9888185
DEBUG:root: dqn, choose action rondomly, need time 0.000270999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =4733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444173812866
INFO:root:frame =4734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.988809
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.07982727e+02]
 [  1.02965527e+03]
 [  6.83011627e+00]
 [  3.64187683e+02]
 [  2.19666260e+02]
 [  1.07881348e+02]
 [  6.83011627e+00]
 [  1.02965527e+03]
 [  4.31226397e+00]
 [  2.76638660e+01]
 [  5.93634892e+00]
 [  6.50076953e+03]
 [  3.30446930e+01]
 [  4.24388075e+00]
 [  2.65189800e+01]
 [  6.02558228e+02]]
DEBUG:root:training time = %d0.206572
INFO:root:frame =4737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000416994094849
INFO:root:frame =4738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000223159790039
DEBUG:root: save sample needs time = 9.67979431152e-05
INFO:root:random_action_porb = 0.9887995
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:frame =4741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =4742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00023889541626
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.98879
DEBUG:root: dqn, choose action rondomly, need time 0.000311999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.62410869e+04]
 [  1.32692520e+02]
 [  3.11543830e-02]
 [  2.33689423e+02]
 [  7.16034851e+02]
 [  1.38329148e+00]
 [  4.98507843e+01]
 [  8.63173008e+00]
 [  9.91275501e+00]
 [  2.01738510e+02]
 [  1.69478149e+02]
 [  6.59874854e+03]
 [  1.32692520e+02]
 [  3.54394165e+03]
 [  3.18659760e+02]
 [  2.12475854e+03]]
DEBUG:root:training time = %d0.207998
INFO:root:frame =4745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =4746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000367879867554
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9887805
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:frame =4749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =4750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.988771
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.08787439e+03]
 [  4.00332909e+01]
 [  1.59675913e+01]
 [  2.39081402e+01]
 [  1.64447693e+02]
 [  1.19526474e+02]
 [  6.86694183e+01]
 [  3.29361359e+02]
 [  2.77105789e+01]
 [  1.68631042e+02]
 [  1.65584366e+02]
 [  7.20723328e+02]
 [  1.73131445e+04]
 [  1.28254004e+01]
 [  6.86694183e+01]
 [  1.16482363e+01]]
DEBUG:root:training time = %d0.208083
INFO:root:frame =4753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:frame =4754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.9887615
DEBUG:root: dqn, choose action rondomly, need time 0.000192999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:frame =4757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root:frame =4758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000347852706909
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.988752
DEBUG:root: dqn, choose action rondomly, need time 0.000167000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000193119049072
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.28563269e+03]
 [  1.46378159e+02]
 [  4.39763904e-01]
 [  3.29924866e+02]
 [  5.47425293e+02]
 [  2.82409332e+02]
 [  7.42815351e+00]
 [  5.84121704e+02]
 [  4.60391083e+02]
 [  6.51579346e+02]
 [  5.47425293e+02]
 [  6.11191101e+01]
 [  9.88318348e+00]
 [  3.72696698e-01]
 [  2.02592667e+02]
 [  9.30698242e+02]]
DEBUG:root:training time = %d0.189449
INFO:root:frame =4761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261783599854
INFO:root:frame =4762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9887425
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =4765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000582933425903
INFO:root:frame =4766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:random_action_porb = 0.988733
DEBUG:root: dqn, choose action rondomly, need time 0.000190000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174999237061
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.24561989e+02]
 [  4.35966003e+02]
 [  1.29690384e+02]
 [  2.45948999e+03]
 [  9.50378906e+02]
 [  9.50378906e+02]
 [  1.24561989e+02]
 [  1.16223833e-02]
 [  4.43881493e+01]
 [  5.48201904e+02]
 [  1.24561989e+02]
 [  5.87959180e+03]
 [  5.13348312e+01]
 [  2.04489426e+02]
 [  9.49930370e-01]
 [  5.27667332e+00]]
DEBUG:root:training time = %d0.185345
INFO:root:frame =4769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =4770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000419855117798
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9887235
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000540018081665
INFO:root:frame =4774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000498056411743
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root:random_action_porb = 0.988714
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000292778015137
INFO:root:training error  = [[  4.09729462e+02]
 [  2.75470795e+02]
 [  4.11898804e+01]
 [  2.96961884e+02]
 [  6.45911426e+03]
 [  1.01581940e+03]
 [  2.67964745e+00]
 [  3.57232833e+00]
 [  3.28044952e+02]
 [  2.72570553e+01]
 [  1.89322948e+01]
 [  1.63050256e+03]
 [  1.25954941e-01]
 [  1.49749136e+01]
 [  2.45566559e+01]
 [  8.18563700e-01]]
DEBUG:root:training time = %d0.223219
INFO:root:frame =4777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:frame =4778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9887045
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =4781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000331163406372
INFO:root:frame =4782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.988695
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.98167229e+01]
 [  1.08277161e+03]
 [  3.17785454e+00]
 [  1.93434509e+02]
 [  2.08457178e+03]
 [  1.15306129e+01]
 [  1.02948486e+03]
 [  4.55279358e+02]
 [  3.04973602e+00]
 [  4.22754936e+01]
 [  6.16533220e-01]
 [  3.04973602e+00]
 [  1.21407032e+00]
 [  1.24160408e+02]
 [  1.02948486e+03]
 [  4.62857269e+02]]
DEBUG:root:training time = %d0.201368
INFO:root:frame =4785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:frame =4786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000287055969238
DEBUG:root: save sample needs time = 0.000107049942017
INFO:root:random_action_porb = 0.9886855
DEBUG:root: dqn, choose action rondomly, need time 0.000191000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =4789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =4790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480175018311
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.988676
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.44700747e+01]
 [  6.26373367e+01]
 [  3.02491832e+00]
 [  1.31913650e+00]
 [  7.73192261e+02]
 [  3.02491832e+00]
 [  3.94213593e+02]
 [  1.60885930e-01]
 [  3.31485840e+02]
 [  6.76844482e+02]
 [  3.43177246e+02]
 [  1.67143799e+03]
 [  5.59773193e+02]
 [  1.07286938e+03]
 [  1.97713049e+03]
 [  3.67047548e-01]]
DEBUG:root:training time = %d0.209171
INFO:root:frame =4793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:frame =4794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000228881835938
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.9886665
DEBUG:root: dqn, choose action rondomly, need time 0.000174999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000182151794434
INFO:root:frame =4797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049901008606
INFO:root:frame =4798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000296115875244
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.988657
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.85669037e+02]
 [  1.33517683e+00]
 [  2.64129736e+03]
 [  9.41346467e-01]
 [  8.50435181e+02]
 [  2.40466213e+00]
 [  4.09340790e+02]
 [  1.58479767e+02]
 [  1.82880890e+02]
 [  3.27423325e+01]
 [  7.03982544e+02]
 [  8.65251839e-01]
 [  8.50435181e+02]
 [  3.35407764e+03]
 [  1.19555176e+03]
 [  1.57052307e+02]]
DEBUG:root:training time = %d0.210165
INFO:root:frame =4801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =4802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000290870666504
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.9886475
DEBUG:root: dqn, choose action rondomly, need time 0.000165999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:frame =4805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000486850738525
INFO:root:frame =4806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.988638
DEBUG:root: dqn, choose action rondomly, need time 0.000400999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000428915023804
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.36899353e+02]
 [  4.19255249e+02]
 [  6.60467896e+02]
 [  2.38219131e+02]
 [  5.04754210e+00]
 [  6.09260798e+00]
 [  6.03042114e+02]
 [  2.96360302e+00]
 [  9.67198563e+01]
 [  7.01416377e-03]
 [  2.74043030e+02]
 [  5.04754210e+00]
 [  1.54429242e-01]
 [  7.29120026e+01]
 [  3.67309387e+02]
 [  4.97808887e+03]]
DEBUG:root:training time = %d0.20542
INFO:root:frame =4809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:frame =4810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9886285
DEBUG:root: dqn, choose action rondomly, need time 0.000222999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000280141830444
INFO:root:frame =4813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =4814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457763671875
DEBUG:root: save sample needs time = 0.000276803970337
INFO:root:random_action_porb = 0.988619
DEBUG:root: dqn, choose action rondomly, need time 0.000216000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000187158584595
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.21318855e+01]
 [  1.77734721e+00]
 [  7.69740723e+02]
 [  2.07653046e+02]
 [  4.30694855e+02]
 [  6.02101379e+02]
 [  2.07653046e+02]
 [  3.63968140e+03]
 [  2.96420990e+02]
 [  1.27786072e+03]
 [  7.83356384e+02]
 [  7.66958084e+01]
 [  6.95527363e+00]
 [  6.26600159e+02]
 [  8.58872681e+02]
 [  2.21169815e+01]]
DEBUG:root:training time = %d0.197077
INFO:root:frame =4817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =4818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000311136245728
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9886095
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =4821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =4822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494003295898
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9886
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.31146507e+01]
 [  3.25576115e+00]
 [  1.22669031e+03]
 [  5.97848267e+02]
 [  1.98223251e+02]
 [  3.02566650e+02]
 [  1.34220839e-01]
 [  2.10096482e-02]
 [  2.20521212e-01]
 [  9.05930099e+01]
 [  6.46072449e+02]
 [  8.06129227e+01]
 [  7.34323425e+01]
 [  6.24572449e+02]
 [  3.19266235e+02]
 [  9.05930099e+01]]
DEBUG:root:training time = %d0.193467
INFO:root:frame =4825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:frame =4826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.9885905
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =4829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =4830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.988581
DEBUG:root: dqn, choose action rondomly, need time 0.000254999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.37460632e+03]
 [  7.44880310e+02]
 [  2.47210884e+01]
 [  1.44106264e+01]
 [  2.39500147e-03]
 [  4.21837717e-01]
 [  5.75686218e+02]
 [  1.31502509e-01]
 [  7.44880310e+02]
 [  1.02689041e+02]
 [  7.44880310e+02]
 [  2.55838135e+03]
 [  2.44802685e+01]
 [  5.11773720e+01]
 [  1.48238495e+02]
 [  2.59801102e+01]]
DEBUG:root:training time = %d0.20488
INFO:root:frame =4833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =4834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319957733154
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:random_action_porb = 0.9885715
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =4837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000546932220459
INFO:root:frame =4838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.988562
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000181913375854
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.16255890e+02]
 [  1.62993134e+02]
 [  1.08722687e+00]
 [  4.01992828e+02]
 [  3.66935028e+02]
 [  8.95487518e+01]
 [  3.84023323e+01]
 [  2.43914215e+02]
 [  1.71333649e+02]
 [  1.54914355e+03]
 [  1.54914355e+03]
 [  2.81089282e+03]
 [  3.66935028e+02]
 [  2.72375244e+03]
 [  3.09346924e+03]
 [  3.66935028e+02]]
DEBUG:root:training time = %d0.187861
INFO:root:frame =4841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =4842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame = 4843 State into memory, numbers recorded 114 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.00056791305542
INFO:root:random_action_porb = 0.9885525
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4844current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root:frame =4845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =4846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.988543
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.77158752e+02]
 [  3.87286682e+01]
 [  1.11959648e+02]
 [  1.21982544e+02]
 [  1.05206372e+03]
 [  5.56819839e+01]
 [  4.36951111e+02]
 [  4.74235303e+03]
 [  4.34228745e+01]
 [  1.77080364e+01]
 [  1.13872284e+02]
 [  3.12559932e-01]
 [  3.15456055e+03]
 [  1.82577881e+02]
 [  3.12559932e-01]
 [  1.59375610e+01]]
DEBUG:root:training time = %d0.200262
INFO:root:frame =4849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:frame =4850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9885335
DEBUG:root: dqn, choose action rondomly, need time 0.000174000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:frame =4853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =4854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234127044678
DEBUG:root: save sample needs time = 0.000110149383545
INFO:root:random_action_porb = 0.988524
DEBUG:root: dqn, choose action rondomly, need time 0.000164999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.33799381e+01]
 [  8.66755600e+01]
 [  9.83650665e+01]
 [  2.14686707e+02]
 [  6.96217299e-01]
 [  1.02186508e+02]
 [  6.68186522e+00]
 [  5.21936493e+01]
 [  4.91711473e+00]
 [  2.32894087e+00]
 [  1.68113281e+02]
 [  9.83650665e+01]
 [  2.73980835e+03]
 [  2.32894087e+00]
 [  4.21775284e+01]
 [  2.73615784e+02]]
DEBUG:root:training time = %d0.216907
INFO:root:frame =4857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =4858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000179052352905
INFO:root:random_action_porb = 0.9885145
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =4861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =4862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.988505
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:training error  = [[  1.01930723e+04]
 [  1.17500557e+02]
 [  1.57825485e+02]
 [  2.42892334e+03]
 [  6.42284790e+02]
 [  8.91468353e+01]
 [  1.34809675e+01]
 [  6.60673370e+01]
 [  8.86546860e+01]
 [  2.33174896e+02]
 [  6.60673370e+01]
 [  1.49216110e+02]
 [  5.56149380e-03]
 [  5.30626831e+01]
 [  1.62588501e+01]
 [  1.84948889e+03]]
DEBUG:root:training time = %d0.212958
INFO:root:frame =4865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:frame =4866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.9884955
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =4869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =4870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00023078918457
INFO:root:frame = 4871 State into memory, numbers recorded 115 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000569105148315
INFO:root:random_action_porb = 0.988486
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4872current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.85981964e+02]
 [  3.35041473e+02]
 [  4.44356171e+02]
 [  1.40212799e+02]
 [  6.63935547e+01]
 [  1.56689007e-02]
 [  1.10198898e+02]
 [  2.43616501e+02]
 [  3.43807959e+03]
 [  3.43807959e+03]
 [  2.60071716e+02]
 [  6.15897217e+01]
 [  5.68499660e+00]
 [  1.89061615e+02]
 [  2.15991226e+02]
 [  3.96909142e+01]]
DEBUG:root:training time = %d0.209803
INFO:root:frame =4873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:frame =4874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.9884765
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =4877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000487089157104
INFO:root:frame =4878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240087509155
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.988467
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.62933719e+00]
 [  1.14107849e+03]
 [  7.03821411e+02]
 [  6.24161720e-01]
 [  1.05516875e+00]
 [  3.19002502e+02]
 [  4.88700317e+02]
 [  2.17497676e+04]
 [  4.05033875e+01]
 [  4.03828764e+00]
 [  2.69541931e+02]
 [  1.46383997e+03]
 [  7.84585037e+01]
 [  2.83590049e-01]
 [  9.17808899e+02]
 [  3.56091055e+04]]
DEBUG:root:training time = %d0.196538
INFO:root:frame =4881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =4882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 9.51290130615e-05
INFO:root:random_action_porb = 0.9884575
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =4885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =4886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.988448
DEBUG:root: dqn, choose action rondomly, need time 0.000339000000011
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000351190567017
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.21356384e+02]
 [  1.04993690e+02]
 [  3.76654053e+01]
 [  2.72452698e+02]
 [  9.83206665e+02]
 [  1.52975250e+02]
 [  1.69747620e+03]
 [  1.52214185e+03]
 [  1.26873291e+00]
 [  5.23484834e-02]
 [  1.01355118e+02]
 [  2.98889136e+03]
 [  1.14909840e+01]
 [  1.22575808e+00]
 [  1.17878761e+01]
 [  2.53102005e+02]]
DEBUG:root:training time = %d0.20178
INFO:root:frame =4889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =4890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234127044678
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9884385
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000292778015137
INFO:root:frame =4893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =4894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00035285949707
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.988429
DEBUG:root: dqn, choose action rondomly, need time 0.000334999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.27018616e+02]
 [  2.21210388e+02]
 [  1.41638184e+02]
 [  2.85530901e+00]
 [  8.07819189e+03]
 [  1.70928478e-01]
 [  6.86977768e+01]
 [  3.30009949e+02]
 [  7.21312943e+01]
 [  6.07535124e+00]
 [  4.55130768e+01]
 [  7.30753662e+02]
 [  1.47697628e+00]
 [  7.21312943e+01]
 [  2.31313202e+02]
 [  4.48833227e+00]]
DEBUG:root:training time = %d0.207029
INFO:root:frame =4897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =4898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9884195
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000011
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =4901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000365972518921
INFO:root:frame =4902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.000103950500488
INFO:root:random_action_porb = 0.98841
DEBUG:root: dqn, choose action rondomly, need time 0.000163999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142812728882
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.73141212e+01]
 [  9.11553467e+02]
 [  6.54575806e+02]
 [  6.68020782e+01]
 [  2.44014282e+02]
 [  1.59465576e+02]
 [  1.50350180e+01]
 [  4.62257233e+01]
 [  1.74811203e+02]
 [  2.38970757e+00]
 [  2.76356641e+03]
 [  2.44014282e+02]
 [  4.73084373e+01]
 [  7.88296265e+02]
 [  4.56759766e+02]
 [  2.36889210e+01]]
DEBUG:root:training time = %d0.215029
INFO:root:frame =4905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =4906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000168800354004
INFO:root:random_action_porb = 0.9884005
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =4909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =4910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480175018311
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.988391
DEBUG:root: dqn, choose action rondomly, need time 0.00027200000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.77640076e+01]
 [  1.75563755e+01]
 [  2.42559090e+01]
 [  2.05345078e+01]
 [  1.20402870e+02]
 [  9.72738419e+01]
 [  4.94356346e+01]
 [  2.77850075e+01]
 [  1.62062488e+03]
 [  3.33514481e+01]
 [  7.53487354e+03]
 [  9.61116943e+02]
 [  3.88573494e+01]
 [  1.07626297e+02]
 [  3.47000480e+00]
 [  1.68682156e+01]]
DEBUG:root:training time = %d0.202134
INFO:root:frame =4913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =4914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.9883815
DEBUG:root: dqn, choose action rondomly, need time 0.000313999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =4917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000485181808472
INFO:root:frame =4918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491142272949
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.988372
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355958938599
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.44173857e+04]
 [  3.28543640e+02]
 [  4.25741524e-01]
 [  5.69536743e+02]
 [  2.04871567e+02]
 [  6.80178955e+02]
 [  1.46562897e+02]
 [  7.26117310e+02]
 [  1.19470909e+02]
 [  1.87236984e+02]
 [  7.71340714e+01]
 [  1.14829810e+03]
 [  3.03485718e+03]
 [  6.80417603e+02]
 [  1.27474146e+03]
 [  2.61450592e+02]]
DEBUG:root:training time = %d0.217326
INFO:root:frame =4921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:frame =4922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000302076339722
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.9883625
DEBUG:root: dqn, choose action rondomly, need time 0.000436000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =4925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000386953353882
INFO:root:frame =4926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.988353
DEBUG:root: dqn, choose action rondomly, need time 0.000185000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000135183334351
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.39908371e+01]
 [  2.83176941e+02]
 [  1.53000168e+02]
 [  5.41305786e+02]
 [  3.74823213e+00]
 [  4.23421240e+00]
 [  1.62876591e-01]
 [  9.63788147e+02]
 [  1.91730251e+01]
 [  1.71997522e+03]
 [  2.59950459e-01]
 [  9.63788147e+02]
 [  5.97908325e+02]
 [  2.68464539e+02]
 [  1.59826874e+02]
 [  4.06398364e+03]]
DEBUG:root:training time = %d0.189336
INFO:root:frame =4929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame =4930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234127044678
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.9883435
DEBUG:root: dqn, choose action rondomly, need time 0.000241000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =4933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =4934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.988334
DEBUG:root: dqn, choose action rondomly, need time 0.000323999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029182434082
INFO:root:training error  = [[  1.79138072e-02]
 [  1.55202675e+01]
 [  2.05438553e+02]
 [  5.35748787e-02]
 [  8.75793648e+00]
 [  3.30551880e+03]
 [  9.81074905e+01]
 [  6.88139572e+01]
 [  6.31668640e+02]
 [  3.84225440e+00]
 [  1.16130798e+03]
 [  9.10975266e+01]
 [  1.02471590e+01]
 [  3.35668518e+02]
 [  9.41107910e+02]
 [  2.45058914e+02]]
DEBUG:root:training time = %d0.208521
INFO:root:frame =4937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =4938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame = 4939 State into memory, numbers recorded 116 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:random_action_porb = 0.9883245
DEBUG:root: dqn, choose action rondomly, need time 0.000165999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4940current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:frame =4941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =4942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248908996582
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:random_action_porb = 0.988315
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.71284286e+02]
 [  8.47311249e+01]
 [  1.94521866e+01]
 [  6.65184402e+01]
 [  1.43228195e+02]
 [  4.97059593e+01]
 [  8.47311249e+01]
 [  6.45720020e+03]
 [  3.12820166e-01]
 [  5.35446838e+02]
 [  4.73715935e+01]
 [  7.27174139e+00]
 [  3.34504858e+03]
 [  7.88160034e+02]
 [  3.52494678e+03]
 [  4.81393852e+01]]
DEBUG:root:training time = %d0.216271
INFO:root:frame =4945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =4946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000320911407471
DEBUG:root: save sample needs time = 9.91821289062e-05
INFO:root:random_action_porb = 0.9883055
DEBUG:root: dqn, choose action rondomly, need time 0.00016699999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000156879425049
INFO:root:frame =4949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =4950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000550985336304
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.988296
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  259.06369019]
 [ 3914.52026367]
 [ 2238.26757812]
 [  981.52978516]
 [   49.60031891]
 [ 1976.78076172]
 [   14.257967  ]
 [   40.17775345]
 [   80.69960022]
 [    3.93294644]
 [   44.71831894]
 [  134.01747131]
 [  458.58068848]
 [ 1249.33166504]
 [  134.01747131]
 [  108.78954315]]
DEBUG:root:training time = %d0.206699
INFO:root:frame =4953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =4954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000530004501343
INFO:root:frame = 4955 State into memory, numbers recorded 117 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000597953796387
INFO:root:random_action_porb = 0.9882865
DEBUG:root: dqn, choose action rondomly, need time 0.000579000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4956current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =4957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =4958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.988277
DEBUG:root: dqn, choose action rondomly, need time 0.000279999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.24318962e+01]
 [  1.29636698e+01]
 [  3.82063629e+02]
 [  2.90432125e-01]
 [  1.69228592e+02]
 [  3.71854134e+01]
 [  9.52800179e+00]
 [  3.28446075e+02]
 [  2.98779640e+01]
 [  1.33924927e+02]
 [  3.26510668e-01]
 [  3.48746277e+02]
 [  9.48776489e+02]
 [  2.77008942e+02]
 [  9.52800179e+00]
 [  3.74310913e+01]]
DEBUG:root:training time = %d0.196665
INFO:root:frame =4961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000192165374756
INFO:root:frame =4962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000586986541748
DEBUG:root: save sample needs time = 0.000125885009766
INFO:root:random_action_porb = 0.9882675
DEBUG:root: dqn, choose action rondomly, need time 0.000540999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =4965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446796417236
INFO:root:frame =4966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.988258
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.11489700e+02]
 [  8.26312207e+03]
 [  4.96516418e+02]
 [  1.75382233e+01]
 [  3.07776413e+01]
 [  3.61070126e-01]
 [  9.03588963e+00]
 [  8.28211487e+02]
 [  1.97551738e+04]
 [  6.03117798e+02]
 [  1.15007277e+01]
 [  7.51790588e+02]
 [  3.37003618e-02]
 [  2.87338806e+02]
 [  1.29051868e+03]
 [  4.27416016e+02]]
DEBUG:root:training time = %d0.19552
INFO:root:frame =4969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:frame =4970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00048303604126
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.9882485
DEBUG:root: dqn, choose action rondomly, need time 0.000163999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:frame =4973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =4974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:random_action_porb = 0.988239
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.69413788e+02]
 [  8.87436914e+03]
 [  5.28616982e+01]
 [  3.35076660e+03]
 [  2.42509720e+02]
 [  6.01764030e+01]
 [  3.51322479e+01]
 [  3.23005629e+00]
 [  1.27594093e+02]
 [  3.34754486e+01]
 [  2.69596497e+02]
 [  3.85483582e+02]
 [  2.36345352e+02]
 [  2.48785377e+00]
 [  4.50410217e+02]
 [  1.23572861e+02]]
DEBUG:root:training time = %d0.210817
INFO:root:frame =4977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =4978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319957733154
DEBUG:root: save sample needs time = 0.00019383430481
INFO:root:random_action_porb = 0.9882295
DEBUG:root: dqn, choose action rondomly, need time 0.000254999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000194072723389
INFO:root:frame =4981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root:frame =4982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000357151031494
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root:random_action_porb = 0.98822
DEBUG:root: dqn, choose action rondomly, need time 0.000371999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.14757729e+02]
 [  5.59322205e+02]
 [  6.99255371e+01]
 [  5.38728600e+01]
 [  1.48364853e+02]
 [  1.33264435e+02]
 [  2.07298877e+03]
 [  4.33703766e+01]
 [  3.03828918e+02]
 [  1.24870697e+02]
 [  1.42000418e+01]
 [  8.32363319e+00]
 [  3.84683204e+00]
 [  5.60373901e+02]
 [  3.15815759e+00]
 [  7.77849928e-03]]
DEBUG:root:training time = %d0.200041
INFO:root:frame =4985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =4986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
DEBUG:root: save sample needs time = 0.000146150588989
INFO:root:random_action_porb = 0.9882105
DEBUG:root: dqn, choose action rondomly, need time 0.000254999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000191926956177
INFO:root:frame =4989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =4990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:random_action_porb = 0.988201
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.96258148e+02]
 [  4.52130356e+01]
 [  9.44693115e+02]
 [  1.61022142e-01]
 [  1.83505476e+00]
 [  1.34987762e+02]
 [  6.48896332e+01]
 [  9.32411914e+03]
 [  1.11203259e+03]
 [  2.02551633e-02]
 [  1.02163734e+01]
 [  5.89439819e+02]
 [  1.66273071e+02]
 [  5.83096848e+01]
 [  1.04581226e+03]
 [  3.71708527e+01]]
DEBUG:root:training time = %d0.193802
INFO:root:frame =4993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =4994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.9881915
DEBUG:root: dqn, choose action rondomly, need time 0.000192000000013
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:frame =4997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =4998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000260829925537
DEBUG:root: save sample needs time = 0.000110864639282
DEBUG:root:one frame running time = 0.002886
DEBUG:root:total training time = 113.587767
INFO:root:frame num = 5000 frame round: 0
INFO:root:random_action_porb = 0.988182
DEBUG:root: dqn, choose action rondomly, need time 0.000161000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.57194397e+02]
 [  1.51913727e+02]
 [  1.37153471e+00]
 [  2.42414260e+00]
 [  2.23223667e+01]
 [  9.51152420e+00]
 [  4.37305145e+02]
 [  2.59612923e+01]
 [  2.02955527e+04]
 [  1.29930737e+03]
 [  1.15225684e+03]
 [  1.59403601e+03]
 [  9.87079680e-01]
 [  2.05458488e+01]
 [  1.55303772e+03]
 [  7.32531494e+02]]
DEBUG:root:training time = %d0.19086
INFO:root:frame =5001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =5002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002601146698
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.9881725
DEBUG:root: dqn, choose action rondomly, need time 0.000201000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =5005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =5006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049090385437
DEBUG:root: save sample needs time = 0.00011682510376
INFO:root:random_action_porb = 0.988163
DEBUG:root: dqn, choose action rondomly, need time 0.000326000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.17628747e-01]
 [  4.37095070e+01]
 [  1.58058411e+02]
 [  1.37319431e+01]
 [  2.68344788e+02]
 [  8.40193054e+02]
 [  5.39961662e+01]
 [  2.38182861e+02]
 [  1.56591835e+01]
 [  8.40193054e+02]
 [  5.78801215e-01]
 [  2.25090422e-02]
 [  9.76093674e+01]
 [  6.46346998e+00]
 [  2.13348950e+03]
 [  9.46042090e+03]]
DEBUG:root:training time = %d0.195463
INFO:root:frame =5009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:frame =5010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame = 5011 State into memory, numbers recorded 118 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:random_action_porb = 0.9881535
DEBUG:root: dqn, choose action rondomly, need time 0.000167000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5012current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:frame =5013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =5014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249862670898
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:random_action_porb = 0.988144
DEBUG:root: dqn, choose action rondomly, need time 0.000173000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000137805938721
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.59819565e+01]
 [  2.36005386e+02]
 [  1.59702686e+03]
 [  5.14341888e+01]
 [  1.63035202e+02]
 [  1.05160599e+01]
 [  4.24049988e+02]
 [  1.88246346e+01]
 [  4.60437279e+01]
 [  3.69677138e+00]
 [  3.29312611e+00]
 [  1.12675591e+02]
 [  7.58585266e+02]
 [  1.88246346e+01]
 [  2.36005386e+02]
 [  8.05190869e+03]]
DEBUG:root:training time = %d0.198399
INFO:root:frame =5017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =5018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9881345
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =5021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =5022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.988125
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.99102139e+00]
 [  7.19139282e+02]
 [  3.36293915e+02]
 [  1.40571457e+02]
 [  2.64527416e+01]
 [  1.27675085e+03]
 [  1.98825775e+02]
 [  7.88584137e+01]
 [  7.69115662e+02]
 [  1.20001782e+03]
 [  9.77048950e+01]
 [  2.20996735e+02]
 [  6.21374951e+03]
 [  2.64527416e+01]
 [  2.73008118e+02]
 [  7.88584137e+01]]
DEBUG:root:training time = %d0.202344
INFO:root:frame =5025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =5026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9881155
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =5029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =5030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.988106
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.48564819e+02]
 [  7.84823074e+01]
 [  1.37653656e+02]
 [  5.30501604e-01]
 [  7.57671692e+02]
 [  1.94046326e+03]
 [  7.53394394e+01]
 [  1.15166292e+01]
 [  1.68413293e+03]
 [  2.02856665e+03]
 [  7.86999588e+01]
 [  3.20232821e+00]
 [  1.15166292e+01]
 [  5.26642370e+00]
 [  5.08759270e+01]
 [  8.25323677e+00]]
DEBUG:root:training time = %d0.197756
INFO:root:frame =5033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =5034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.9880965
DEBUG:root: dqn, choose action rondomly, need time 0.000206999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:frame =5037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:frame =5038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.988087
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.57387793e+03]
 [  1.56701050e+02]
 [  1.63831284e+02]
 [  3.23932251e+03]
 [  1.59108789e+03]
 [  7.82870102e+01]
 [  4.57018799e+02]
 [  5.64009326e+03]
 [  6.78876495e+01]
 [  7.05157104e+02]
 [  1.53572947e-01]
 [  2.34057404e+02]
 [  7.03887329e+01]
 [  2.24255466e+00]
 [  6.45054688e+02]
 [  4.57018799e+02]]
DEBUG:root:training time = %d0.212519
INFO:root:frame =5041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =5042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249862670898
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:random_action_porb = 0.9880775
DEBUG:root: dqn, choose action rondomly, need time 0.000174999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:frame =5045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =5046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000451803207397
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:random_action_porb = 0.988068
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000635862350464
INFO:root:training error  = [[  6.13674805e+02]
 [  7.98212097e+02]
 [  3.69156575e+00]
 [  1.04784033e+03]
 [  4.24239845e+01]
 [  8.76416937e-02]
 [  1.34368181e+01]
 [  1.85775970e+02]
 [  3.25875244e+02]
 [  1.14769165e+03]
 [  3.78829765e+01]
 [  9.60794830e+01]
 [  9.59847412e+01]
 [  1.85775970e+02]
 [  3.05108472e+03]
 [  4.37011604e+01]]
DEBUG:root:training time = %d0.221306
INFO:root:frame =5049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =5050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.9880585
DEBUG:root: dqn, choose action rondomly, need time 0.000181000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:frame =5053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =5054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234127044678
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.988049
DEBUG:root: dqn, choose action rondomly, need time 0.00042599999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.81455994e+01]
 [  1.23028219e-01]
 [  3.01997070e+02]
 [  6.18665039e+02]
 [  1.01970081e+01]
 [  1.13582764e+03]
 [  2.54104355e+02]
 [  1.43842484e+02]
 [  7.46580124e+01]
 [  1.25441986e+02]
 [  7.38855762e+03]
 [  1.32818985e+02]
 [  1.32818985e+02]
 [  3.20867706e+02]
 [  5.88282178e+03]
 [  1.22036292e+03]]
DEBUG:root:training time = %d0.217454
INFO:root:frame =5057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:frame =5058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9880395
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =5061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =5062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.98803
DEBUG:root: dqn, choose action rondomly, need time 0.000361999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.44293562e-01]
 [  4.55214767e+01]
 [  1.71783508e+02]
 [  6.32429733e+01]
 [  5.76102448e+01]
 [  8.39790642e-01]
 [  2.06442773e+03]
 [  5.08002052e+01]
 [  1.13818872e+03]
 [  4.67463104e+02]
 [  1.98474159e+01]
 [  2.31735010e+03]
 [  3.72832715e+03]
 [  6.32429733e+01]
 [  6.96873153e-03]
 [  2.30718269e+01]]
DEBUG:root:training time = %d0.189691
INFO:root:frame =5065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =5066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.0001060962677
INFO:root:random_action_porb = 0.9880205
DEBUG:root: dqn, choose action rondomly, need time 0.00016500000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:frame =5069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000717163085938
INFO:root:frame =5070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:random_action_porb = 0.988011
DEBUG:root: dqn, choose action rondomly, need time 0.000732999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[  9.29838196e+02]
 [  1.02999802e+01]
 [  1.35690880e+01]
 [  8.71608658e+01]
 [  1.77789185e+03]
 [  2.31880676e+02]
 [  1.36163223e+02]
 [  4.14258209e+02]
 [  1.20433969e+01]
 [  7.93642700e+02]
 [  1.86336098e+01]
 [  1.32490509e+02]
 [  6.24020752e+02]
 [  2.23924406e-02]
 [  2.13880981e+03]
 [  2.13880981e+03]]
DEBUG:root:training time = %d0.221672
INFO:root:frame =5073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =5074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root:random_action_porb = 0.9880015
DEBUG:root: dqn, choose action rondomly, need time 0.000369000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =5077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427961349487
INFO:root:frame =5078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047779083252
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:random_action_porb = 0.987992
DEBUG:root: dqn, choose action rondomly, need time 0.000180999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.55364563e+02]
 [  3.85706787e+02]
 [  2.07305603e+02]
 [  1.78293562e+00]
 [  3.98482880e+02]
 [  2.07305603e+02]
 [  2.30916895e+03]
 [  6.01829453e+01]
 [  4.43923676e+02]
 [  2.25392399e+01]
 [  1.68291891e+00]
 [  7.86290970e+01]
 [  2.97967613e-01]
 [  8.91879333e+02]
 [  2.69067676e+03]
 [  1.17650986e+01]]
DEBUG:root:training time = %d0.200382
INFO:root:frame =5081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000373125076294
INFO:root:frame =5082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000552177429199
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9879825
DEBUG:root: dqn, choose action rondomly, need time 0.000326999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000542163848877
INFO:root:frame =5085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00072193145752
INFO:root:frame =5086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000553131103516
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:random_action_porb = 0.987973
DEBUG:root: dqn, choose action rondomly, need time 0.000204999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.09885986e+02]
 [  1.21944727e+03]
 [  5.52998047e+02]
 [  5.63578564e+03]
 [  2.17731972e+01]
 [  2.81340446e+01]
 [  2.94008850e+02]
 [  2.19088116e+01]
 [  2.29279190e+02]
 [  1.59983265e+00]
 [  8.04410828e+02]
 [  6.08312988e+02]
 [  3.52941437e+01]
 [  1.54368753e+01]
 [  6.68049500e+02]
 [  1.47409430e+01]]
DEBUG:root:training time = %d0.204642
INFO:root:frame =5089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root:frame =5090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root:random_action_porb = 0.9879635
DEBUG:root: dqn, choose action rondomly, need time 0.000163999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:frame =5093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =5094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:random_action_porb = 0.987954
DEBUG:root: dqn, choose action rondomly, need time 0.000329000000008
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000485181808472
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.26165771e+03]
 [  2.19030591e+03]
 [  1.62760830e+01]
 [  2.34713699e+02]
 [  7.76491318e+01]
 [  1.58545971e+01]
 [  4.30460167e+01]
 [  4.56912140e+02]
 [  1.03326154e+00]
 [  2.67060303e+02]
 [  1.20969620e+02]
 [  1.13649756e+03]
 [  3.26003227e+01]
 [  2.50081921e+01]
 [  1.03326154e+00]
 [  1.32949231e+03]]
DEBUG:root:training time = %d0.20668
INFO:root:frame =5097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =5098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042986869812
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.9879445
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =5101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375032424927
INFO:root:frame =5102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 0.000186920166016
INFO:root:random_action_porb = 0.987935
DEBUG:root: dqn, choose action rondomly, need time 0.000346000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.56561127e+01]
 [  1.12700732e+03]
 [  2.98678314e+02]
 [  4.94799004e+01]
 [  1.07263647e+03]
 [  2.11356827e+02]
 [  3.14016113e+01]
 [  3.16449799e+02]
 [  5.28320789e+00]
 [  1.17822319e+02]
 [  5.27601318e+02]
 [  3.04586563e+01]
 [  3.05323578e+02]
 [  2.39923877e+03]
 [  5.24920702e-01]
 [  1.12700732e+03]]
DEBUG:root:training time = %d0.211359
INFO:root:frame =5105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249147415161
INFO:root:frame =5106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000341892242432
DEBUG:root: save sample needs time = 0.000101804733276
INFO:root:random_action_porb = 0.9879255
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =5109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049901008606
INFO:root:frame =5110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000578165054321
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root:random_action_porb = 0.987916
DEBUG:root: dqn, choose action rondomly, need time 0.000354999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.43598328e+01]
 [  8.76057053e+01]
 [  2.54528344e-01]
 [  4.71331848e+02]
 [  1.23374634e+03]
 [  2.42046547e+01]
 [  2.32325912e+02]
 [  1.00387164e+03]
 [  3.13893555e+02]
 [  1.15009026e+02]
 [  9.99617386e+00]
 [  3.47443275e+01]
 [  3.33022842e+01]
 [  7.46125174e+00]
 [  3.32901025e+00]
 [  9.99617386e+00]]
DEBUG:root:training time = %d0.21572
INFO:root:frame =5113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:frame =5114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame = 5115 State into memory, numbers recorded 119 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:random_action_porb = 0.9879065
DEBUG:root: dqn, choose action rondomly, need time 0.000167999999988
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5116current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:frame =5117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =5118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264883041382
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:random_action_porb = 0.987897
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.57102051e+02]
 [  5.95824003e-01]
 [  5.81031067e+02]
 [  2.91584511e+01]
 [  8.32178444e-02]
 [  2.79934631e+02]
 [  1.48216602e+03]
 [  2.79934631e+02]
 [  5.12830371e+03]
 [  5.53997576e-01]
 [  2.91924438e+02]
 [  1.48169403e+02]
 [  2.14518723e+02]
 [  3.33281746e+01]
 [  8.64640884e+01]
 [  5.71710400e+03]]
DEBUG:root:training time = %d0.209582
INFO:root:frame =5121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =5122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame = 5123 State into memory, numbers recorded 120 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000615835189819
INFO:root:random_action_porb = 0.9878875
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5124current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =5125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =5126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000625133514404
DEBUG:root: save sample needs time = 0.00013279914856
INFO:root:random_action_porb = 0.987878
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.04591904e+01]
 [  1.56458902e+01]
 [  8.12249660e-01]
 [  8.59274268e-01]
 [  1.68415176e+02]
 [  8.06161865e+02]
 [  1.96682288e+03]
 [  1.30491868e-01]
 [  7.74885712e+01]
 [  4.96021194e+01]
 [  1.96682288e+03]
 [  1.96682288e+03]
 [  2.24662292e+02]
 [  7.07729912e+00]
 [  1.14041986e+01]
 [  2.63918008e+04]]
DEBUG:root:training time = %d0.19375
INFO:root:frame =5129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:frame =5130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227928161621
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9878685
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =5133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =5134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.987859
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.51782978e-01]
 [  9.80532227e+01]
 [  3.03990906e+02]
 [  1.48286255e+03]
 [  5.69148438e+02]
 [  5.16907166e+02]
 [  1.34262390e+02]
 [  3.19050751e+02]
 [  7.28662109e+01]
 [  2.91701843e+02]
 [  7.45129395e+01]
 [  2.36371479e+01]
 [  1.66288940e+03]
 [  4.17655602e+01]
 [  1.77603101e+03]
 [  8.71370087e+01]]
DEBUG:root:training time = %d0.209988
INFO:root:frame =5137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =5138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319957733154
DEBUG:root: save sample needs time = 9.58442687988e-05
INFO:root:random_action_porb = 0.9878495
DEBUG:root: dqn, choose action rondomly, need time 0.000269000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =5141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000423908233643
INFO:root:frame =5142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469207763672
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.98784
DEBUG:root: dqn, choose action rondomly, need time 0.00031700000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.05974274e+01]
 [  6.15110168e+02]
 [  1.37547165e+02]
 [  9.11506641e+03]
 [  7.56425714e+00]
 [  3.36902833e+00]
 [  1.03661454e+00]
 [  5.92053871e+01]
 [  8.15523300e+01]
 [  1.02816452e+02]
 [  3.94726074e+03]
 [  3.78549927e+02]
 [  6.47515202e+00]
 [  8.21772079e+01]
 [  7.48699045e+00]
 [  1.75278723e-01]]
DEBUG:root:training time = %d0.198639
INFO:root:frame =5145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =5146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:random_action_porb = 0.9878305
DEBUG:root: dqn, choose action rondomly, need time 0.000574
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =5149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =5150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000495910644531
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.987821
DEBUG:root: dqn, choose action rondomly, need time 0.000552999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.31900635e+02]
 [  2.98315048e+01]
 [  1.93952441e+03]
 [  9.46306534e+01]
 [  8.15577576e+02]
 [  4.38021790e+02]
 [  9.98645898e+03]
 [  1.52089262e+01]
 [  1.06176346e+02]
 [  7.77360153e+01]
 [  7.44685303e+02]
 [  7.18312744e+02]
 [  8.50288879e+02]
 [  1.06176346e+02]
 [  1.15712109e+03]
 [  5.55276251e+00]]
DEBUG:root:training time = %d0.21302
INFO:root:frame =5153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:frame =5154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:frame = 5155 State into memory, numbers recorded 121 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000541925430298
INFO:root:random_action_porb = 0.9878115
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5156current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =5157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:frame =5158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:random_action_porb = 0.987802
DEBUG:root: dqn, choose action rondomly, need time 0.000259999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000191926956177
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.21045837e+02]
 [  6.15452409e-01]
 [  1.87548096e+03]
 [  4.10025421e+02]
 [  7.42357922e+00]
 [  3.38772678e+00]
 [  8.53086304e+02]
 [  2.37376511e+02]
 [  8.05467102e+02]
 [  4.30089617e+00]
 [  1.02139225e+01]
 [  4.75051971e+02]
 [  4.30089617e+00]
 [  3.10339905e+02]
 [  8.74518661e+01]
 [  5.47215462e+01]]
DEBUG:root:training time = %d0.194907
INFO:root:frame =5161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:frame =5162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231981277466
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.9877925
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =5165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =5166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.987783
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.65899200e+02]
 [  5.61536827e+01]
 [  1.10341660e+02]
 [  1.03874807e+01]
 [  3.74961639e+02]
 [  1.99870491e+01]
 [  1.28743830e+01]
 [  3.21739746e+03]
 [  2.05186749e+00]
 [  4.87788086e+03]
 [  4.97241486e+02]
 [  7.75122452e+01]
 [  2.24077637e+02]
 [  1.46196899e+03]
 [  5.69228411e-01]
 [  6.31637306e+01]]
DEBUG:root:training time = %d0.197428
INFO:root:frame =5169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =5170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000197172164917
INFO:root:random_action_porb = 0.9877735
DEBUG:root: dqn, choose action rondomly, need time 0.000332
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =5173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =5174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:random_action_porb = 0.987764
DEBUG:root: dqn, choose action rondomly, need time 0.000163999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.39326172e+01]
 [  3.26761230e+02]
 [  5.08687973e+01]
 [  2.69737053e+00]
 [  1.43595679e+03]
 [  6.21947975e+01]
 [  5.15320206e+01]
 [  1.01448500e+00]
 [  6.60577850e+01]
 [  2.81640778e+01]
 [  1.96706024e+02]
 [  7.55038208e+02]
 [  1.06914337e+02]
 [  2.84874054e+02]
 [  4.33090942e+02]
 [  1.31387955e+02]]
DEBUG:root:training time = %d0.213322
INFO:root:frame =5177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:frame =5178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000244855880737
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.9877545
DEBUG:root: dqn, choose action rondomly, need time 0.000219999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185012817383
INFO:root:frame =5181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root:frame =5182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.987745
DEBUG:root: dqn, choose action rondomly, need time 0.000179000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3382.38549805]
 [  107.5166626 ]
 [   51.15263748]
 [  792.01049805]
 [   10.09011173]
 [    6.11568928]
 [  270.93798828]
 [   31.39130211]
 [  825.18121338]
 [ 1516.69165039]
 [  109.88180542]
 [  130.8656311 ]
 [   17.02658653]
 [  583.9074707 ]
 [   20.96097565]
 [   92.89369965]]
DEBUG:root:training time = %d0.217587
INFO:root:frame =5185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:frame =5186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000281810760498
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:random_action_porb = 0.9877355
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =5189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =5190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424861907959
DEBUG:root: save sample needs time = 0.000103950500488
INFO:root:random_action_porb = 0.987726
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:training error  = [[   50.8598175 ]
 [   73.08950806]
 [   78.08511353]
 [   20.11468315]
 [  449.51556396]
 [  356.35491943]
 [  936.54992676]
 [   37.26529694]
 [   29.58233833]
 [ 1358.14648438]
 [    1.48509121]
 [  131.6255188 ]
 [  633.50531006]
 [  156.82347107]
 [  824.35388184]
 [   43.83342743]]
DEBUG:root:training time = %d0.214809
INFO:root:frame =5193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:frame =5194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9877165
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =5197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =5198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444173812866
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.987707
DEBUG:root: dqn, choose action rondomly, need time 0.000360999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000420093536377
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.28717153e-02]
 [  5.71531011e-03]
 [  5.12776184e+02]
 [  1.66130841e+00]
 [  8.30512142e+00]
 [  8.89481812e+01]
 [  5.55524826e+01]
 [  2.31285334e+00]
 [  2.94709015e+00]
 [  1.21956396e+01]
 [  1.68982601e+01]
 [  8.31187973e+01]
 [  3.01622528e+02]
 [  5.71531011e-03]
 [  7.16158152e+00]
 [  7.21167847e+02]]
DEBUG:root:training time = %d0.193238
INFO:root:frame =5201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =5202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9876975
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =5205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =5206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.987688
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.50641138e+03]
 [  9.52182949e-01]
 [  4.12925262e+01]
 [  9.19250488e-01]
 [  4.50900497e+01]
 [  1.45740330e+00]
 [  4.46141472e+01]
 [  1.19524889e+01]
 [  1.48324823e+01]
 [  2.21752529e+01]
 [  2.07384430e+02]
 [  9.52182949e-01]
 [  3.44271126e+01]
 [  8.81926441e+00]
 [  6.51015377e+00]
 [  1.89341049e+01]]
DEBUG:root:training time = %d0.198632
INFO:root:frame =5209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:frame =5210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.00010085105896
INFO:root:random_action_porb = 0.9876785
DEBUG:root: dqn, choose action rondomly, need time 0.000322999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =5213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =5214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.987669
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.84474349e-01]
 [  5.20106506e+00]
 [  3.03750793e+02]
 [  6.23741770e+00]
 [  2.42653259e+02]
 [  2.07166077e+02]
 [  1.51302795e+02]
 [  3.03750793e+02]
 [  1.25647491e+02]
 [  9.98157349e+02]
 [  5.49645615e+01]
 [  3.56219840e+00]
 [  9.98157349e+02]
 [  1.03094795e+04]
 [  5.33587219e+02]
 [  1.05797625e+00]]
DEBUG:root:training time = %d0.208455
INFO:root:frame =5217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =5218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame = 5219 State into memory, numbers recorded 122 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000331163406372
INFO:root:random_action_porb = 0.9876595
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5220current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =5221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =5222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000364065170288
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.98765
DEBUG:root: dqn, choose action rondomly, need time 0.000578000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.50903308e+03]
 [  1.09845581e+02]
 [  1.32788599e+03]
 [  1.40179033e+01]
 [  5.57811813e+01]
 [  7.06568298e+02]
 [  2.51219543e+02]
 [  2.75007233e+02]
 [  3.09446621e+00]
 [  9.36260581e-01]
 [  2.38779736e+00]
 [  3.77553711e+01]
 [  5.56898956e+01]
 [  3.09446621e+00]
 [  1.17972876e+03]
 [  3.98689880e+02]]
DEBUG:root:training time = %d0.221838
INFO:root:frame =5225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:frame =5226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.9876405
DEBUG:root: dqn, choose action rondomly, need time 0.000170999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:frame =5229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =5230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00023889541626
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.987631
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.42047930e+04]
 [  2.40148895e+02]
 [  5.17492485e+01]
 [  1.90134823e+00]
 [  1.38186064e+01]
 [  1.22253098e+02]
 [  1.42047930e+04]
 [  6.81907227e+02]
 [  4.93008661e+00]
 [  1.25654028e+03]
 [  1.12769699e+01]
 [  4.57037163e+01]
 [  5.79808159e+01]
 [  1.37078235e+03]
 [  2.86918182e+02]
 [  1.15490501e+02]]
DEBUG:root:training time = %d0.205413
INFO:root:frame =5233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =5234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486850738525
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:random_action_porb = 0.9876215
DEBUG:root: dqn, choose action rondomly, need time 0.000313999999989
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =5237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =5238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.987612
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.03338562e+02]
 [  1.01656213e+03]
 [  9.93778229e+00]
 [  1.50276978e+02]
 [  1.35202713e+02]
 [  9.18469360e+02]
 [  6.12559242e+01]
 [  1.62370288e+03]
 [  7.06851013e+02]
 [  4.30477966e+02]
 [  1.37549126e+00]
 [  6.16097183e+01]
 [  8.83133316e+00]
 [  6.29251465e+02]
 [  4.00475708e+03]
 [  2.14503979e+03]]
DEBUG:root:training time = %d0.198545
INFO:root:frame =5241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =5242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000325202941895
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9876025
DEBUG:root: dqn, choose action rondomly, need time 0.000279000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000258207321167
INFO:root:frame =5245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000490188598633
INFO:root:frame =5246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame = 5247 State into memory, numbers recorded 123 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000731945037842
INFO:root:random_action_porb = 0.987593
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5248current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:training error  = [[  3.97759186e+02]
 [  2.54201447e+02]
 [  5.71166534e+01]
 [  1.57335251e+02]
 [  4.35282631e+01]
 [  9.13077383e-04]
 [  1.21583252e+02]
 [  3.50919203e-03]
 [  6.04038635e+02]
 [  2.90425476e+02]
 [  1.21583252e+02]
 [  1.03023950e+03]
 [  2.31350854e-01]
 [  3.97105664e-01]
 [  1.21583252e+02]
 [  1.18924789e+01]]
DEBUG:root:training time = %d0.198959
INFO:root:frame =5249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =5250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000222206115723
INFO:root:random_action_porb = 0.9875835
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =5253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =5254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.987574
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.78021121e+00]
 [  6.01526221e+03]
 [  2.62758514e+02]
 [  1.76368028e-01]
 [  3.36123993e+02]
 [  4.11702545e+02]
 [  2.05042343e+01]
 [  3.15449104e+01]
 [  3.60702553e+01]
 [  2.61339081e+02]
 [  1.52751850e-03]
 [  2.07134991e+01]
 [  1.17102341e+02]
 [  9.62360650e-02]
 [  4.95635406e+02]
 [  4.59358459e+02]]
DEBUG:root:training time = %d0.210731
INFO:root:frame =5257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =5258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000246047973633
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.9875645
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =5261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame =5262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481128692627
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.987555
DEBUG:root: dqn, choose action rondomly, need time 0.000394
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.94218102e+01]
 [  8.85672729e+02]
 [  1.90167701e+00]
 [  1.45026672e+02]
 [  4.56992052e-02]
 [  5.95579605e+01]
 [  2.69594055e+02]
 [  2.51233813e+03]
 [  4.92628937e+01]
 [  1.31296749e+01]
 [  5.63169670e+01]
 [  6.04403000e+01]
 [  5.48790869e+03]
 [  1.00944603e+02]
 [  1.57793913e+01]
 [  1.59597977e+02]]
DEBUG:root:training time = %d0.192389
INFO:root:frame =5265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:frame =5266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9875455
DEBUG:root: dqn, choose action rondomly, need time 0.000197
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =5269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =5270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.987536
DEBUG:root: dqn, choose action rondomly, need time 0.000277999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.23013639e+00]
 [  5.69390808e+02]
 [  1.29373001e+02]
 [  3.15365434e+00]
 [  3.43470305e-01]
 [  5.40073812e-01]
 [  4.51354504e-01]
 [  3.15365434e+00]
 [  6.56253967e+01]
 [  5.68183422e-01]
 [  1.27111983e+00]
 [  9.07400429e-01]
 [  1.19170132e+01]
 [  1.11015167e+01]
 [  1.36689661e+03]
 [  6.67820358e+01]]
DEBUG:root:training time = %d0.210314
INFO:root:frame =5273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root:frame =5274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000224113464355
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:random_action_porb = 0.9875265
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =5277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491142272949
INFO:root:frame =5278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:random_action_porb = 0.987517
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.53998375e+00]
 [  2.02759981e-01]
 [  2.40825122e+03]
 [  1.53529663e+03]
 [  2.30193424e+01]
 [  4.19099976e+02]
 [  1.08025850e+04]
 [  2.30193424e+01]
 [  7.26972461e-01]
 [  1.11598310e+01]
 [  2.46218033e+01]
 [  8.65738403e+02]
 [  1.00349736e+00]
 [  2.92315887e+02]
 [  1.01464134e+02]
 [  2.02759981e-01]]
DEBUG:root:training time = %d0.23216
INFO:root:frame =5281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =5282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000103950500488
INFO:root:random_action_porb = 0.9875075
DEBUG:root: dqn, choose action rondomly, need time 0.000168000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:frame =5285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =5286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.987498
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.23602798e+02]
 [  2.67647559e+03]
 [  4.00789948e+01]
 [  1.82152271e+00]
 [  3.49325895e+00]
 [  1.38458911e+03]
 [  4.22286804e+02]
 [  4.51137199e+01]
 [  6.67875830e+03]
 [  7.22649155e+01]
 [  6.54334259e+00]
 [  1.70036831e+01]
 [  9.27187741e-01]
 [  1.71528015e+02]
 [  3.16631165e+01]
 [  5.54692125e+00]]
DEBUG:root:training time = %d0.204421
INFO:root:frame =5289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275850296021
INFO:root:frame =5290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488042831421
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9874885
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000372886657715
INFO:root:frame =5293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =5294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000235795974731
INFO:root:random_action_porb = 0.987479
DEBUG:root: dqn, choose action rondomly, need time 0.000251000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.99750671e+02]
 [  7.09469974e-01]
 [  1.25174156e+02]
 [  9.97188263e+01]
 [  7.07072070e+03]
 [  3.30342865e+02]
 [  7.18245483e+02]
 [  2.04631433e-01]
 [  8.03367615e+01]
 [  9.32536426e+03]
 [  6.55950089e+01]
 [  1.23620166e+03]
 [  8.17190735e+02]
 [  1.13164082e+01]
 [  3.20433083e+01]
 [  2.18420410e+00]]
DEBUG:root:training time = %d0.204912
INFO:root:frame =5297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =5298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234842300415
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9874695
DEBUG:root: dqn, choose action rondomly, need time 0.000174999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:frame =5301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame =5302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:random_action_porb = 0.98746
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   10.9755497 ]
 [  132.29527283]
 [  654.1854248 ]
 [   58.37495422]
 [  132.29527283]
 [  655.49310303]
 [  835.17016602]
 [    6.50617361]
 [  137.37640381]
 [ 1411.27380371]
 [  116.77256012]
 [  282.34881592]
 [  507.1756897 ]
 [  766.63293457]
 [   27.11324883]
 [   85.7604599 ]]
DEBUG:root:training time = %d0.19683
INFO:root:frame =5305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =5306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame = 5307 State into memory, numbers recorded 124 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.0003981590271
INFO:root:random_action_porb = 0.9874505
DEBUG:root: dqn, choose action rondomly, need time 0.00022100000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5308current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:frame =5309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =5310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000451803207397
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.987441
DEBUG:root: dqn, choose action rondomly, need time 0.000270999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:training error  = [[  1.63074951e+02]
 [  5.41711235e+01]
 [  1.14421558e+01]
 [  5.51442947e+01]
 [  5.17194580e+02]
 [  3.02710991e+01]
 [  3.20332229e-01]
 [  9.46667671e+00]
 [  1.93985498e+03]
 [  3.08284668e+02]
 [  1.66508675e+01]
 [  3.04473901e+03]
 [  1.69506104e+02]
 [  1.54031639e+01]
 [  1.09978867e+01]
 [  1.12035385e+02]]
DEBUG:root:training time = %d0.219514
INFO:root:frame =5313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =5314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
DEBUG:root: save sample needs time = 0.000115156173706
INFO:root:random_action_porb = 0.9874315
DEBUG:root: dqn, choose action rondomly, need time 0.000185000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:frame =5317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =5318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.987422
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.31989765e+00]
 [  1.01555853e+01]
 [  2.23459082e+03]
 [  4.90944733e+02]
 [  1.02576587e+03]
 [  7.50504881e-02]
 [  8.09601822e+01]
 [  1.17820950e+01]
 [  2.11823822e+02]
 [  4.40361112e-01]
 [  3.19705353e+02]
 [  8.43691254e+00]
 [  1.05878259e+03]
 [  7.55214062e+03]
 [  3.48761444e+02]
 [  1.24711510e+02]]
DEBUG:root:training time = %d0.195933
INFO:root:frame =5321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000227212905884
INFO:root:frame =5322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277996063232
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9874125
INFO:root:dqn select action Tensor("ArgMax_8:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01399
INFO:root:action choosen by dqn [2]
INFO:root:frame =5324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000160217285156
INFO:root:frame =5325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290155410767
INFO:root:frame =5326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000495195388794
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.987403
DEBUG:root: dqn, choose action rondomly, need time 0.000317999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.77487854e+02]
 [  3.81155591e+03]
 [  2.30958104e+00]
 [  4.57038184e+03]
 [  1.39760156e+03]
 [  6.32361770e-01]
 [  2.26939654e+00]
 [  7.09881363e+01]
 [  2.30958104e+00]
 [  2.24549789e+01]
 [  1.10609993e-01]
 [  2.71520805e+01]
 [  1.39760156e+03]
 [  7.82936951e+02]
 [  3.43345032e+02]
 [  2.50767258e+02]]
DEBUG:root:training time = %d0.200655
INFO:root:frame =5329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =5330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame = 5331 State into memory, numbers recorded 125 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000545978546143
INFO:root:random_action_porb = 0.9873935
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5332current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =5333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =5334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504016876221
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.987384
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.00853096e+04]
 [  9.19994202e+01]
 [  4.29426422e+02]
 [  1.29484543e+02]
 [  4.54118385e+01]
 [  9.75546539e-01]
 [  2.55172901e+01]
 [  1.44273389e+03]
 [  5.06039802e-03]
 [  7.26989365e+01]
 [  6.97517334e+02]
 [  6.88113953e+02]
 [  1.24332882e-01]
 [  6.55537476e+02]
 [  1.56005478e+00]
 [  1.23179520e+02]]
DEBUG:root:training time = %d0.212087
INFO:root:frame =5337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:frame =5338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000182151794434
INFO:root:random_action_porb = 0.9873745
DEBUG:root: dqn, choose action rondomly, need time 0.000355999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =5341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =5342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.987365
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:training error  = [[  2.81154308e+01]
 [  9.27973938e+01]
 [  3.77558411e+02]
 [  2.95248890e+00]
 [  6.53555298e+00]
 [  3.92807678e+02]
 [  3.07173657e+03]
 [  3.50749658e+03]
 [  2.38105011e+01]
 [  2.79939990e+03]
 [  1.53184519e+01]
 [  3.10162109e+02]
 [  2.81154308e+01]
 [  2.74015579e+01]
 [  1.41983974e+00]
 [  9.27973938e+01]]
DEBUG:root:training time = %d0.209289
INFO:root:frame =5345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =5346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9873555
DEBUG:root: dqn, choose action rondomly, need time 0.000330999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =5349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =5350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.987346
DEBUG:root: dqn, choose action rondomly, need time 0.000587999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.87613964e+01]
 [  1.24036707e+03]
 [  5.23816719e+01]
 [  8.47077698e+02]
 [  3.65032928e+02]
 [  8.30785156e+03]
 [  3.86729950e+02]
 [  3.12656860e+02]
 [  3.86729950e+02]
 [  1.96306213e+03]
 [  5.20069075e+00]
 [  1.98210785e+02]
 [  2.19980942e+02]
 [  5.58372803e+02]
 [  2.73805943e+01]
 [  9.84269958e+02]]
DEBUG:root:training time = %d0.197603
INFO:root:frame =5353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =5354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:random_action_porb = 0.9873365
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =5357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000648021697998
INFO:root:frame =5358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000380992889404
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.987327
DEBUG:root: dqn, choose action rondomly, need time 0.00055900000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000280141830444
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.40688202e+02]
 [  3.03319716e+00]
 [  6.69661999e+00]
 [  2.17943401e+01]
 [  1.67997290e+03]
 [  2.50491870e+03]
 [  1.48397058e-01]
 [  1.20026941e+03]
 [  9.57839050e+02]
 [  4.38485832e+01]
 [  1.15629761e+02]
 [  2.96559143e+01]
 [  2.22714331e+03]
 [  2.89679480e+00]
 [  1.40460999e+03]
 [  1.67087288e+01]]
DEBUG:root:training time = %d0.191533
INFO:root:frame =5361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:frame =5362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319004058838
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9873175
DEBUG:root: dqn, choose action rondomly, need time 0.000174999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root:frame =5365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000486135482788
INFO:root:frame =5366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.987308
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.58260393e+00]
 [  9.30811340e+02]
 [  1.10947084e+00]
 [  2.15715714e+02]
 [  7.90474987e+00]
 [  4.09149097e+03]
 [  4.08575745e+02]
 [  6.09872007e+00]
 [  4.24974121e+02]
 [  1.55241547e+02]
 [  1.66873718e+02]
 [  3.40429955e+01]
 [  2.71796179e+00]
 [  1.55241547e+02]
 [  1.69797165e+02]
 [  2.07989597e+00]]
DEBUG:root:training time = %d0.200211
INFO:root:frame =5369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =5370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame = 5371 State into memory, numbers recorded 126 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:random_action_porb = 0.9872985
DEBUG:root: dqn, choose action rondomly, need time 0.000191999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5372current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000175952911377
INFO:root:frame =5373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =5374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:random_action_porb = 0.987289
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:training error  = [[  1.61685883e+02]
 [  4.32499552e+00]
 [  2.54250854e+02]
 [  1.68625104e+00]
 [  2.00249161e+02]
 [  5.69169861e+02]
 [  1.22879021e+02]
 [  3.73004150e+01]
 [  2.80032910e+03]
 [  3.38970520e+02]
 [  2.11119537e+02]
 [  4.81863983e+02]
 [  3.17277130e+02]
 [  6.63981628e+00]
 [  5.48233871e+01]
 [  3.16183128e+01]]
DEBUG:root:training time = %d0.212443
INFO:root:frame =5377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =5378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000316143035889
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:random_action_porb = 0.9872795
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =5381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =5382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.98727
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.89238739e+01]
 [  2.89294744e+00]
 [  2.23026800e+00]
 [  1.89656311e+02]
 [  3.62474871e+00]
 [  2.93498173e+01]
 [  8.85853577e+01]
 [  2.89294744e+00]
 [  1.19216516e+03]
 [  1.89656311e+02]
 [  1.49045654e+02]
 [  1.02708527e+02]
 [  2.89294744e+00]
 [  5.65777779e+01]
 [  1.72260818e+02]
 [  4.26259375e+03]]
DEBUG:root:training time = %d0.20808
INFO:root:frame =5385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =5386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.9872605
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:frame =5389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000485181808472
INFO:root:frame =5390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame = 5391 State into memory, numbers recorded 127 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000564098358154
INFO:root:random_action_porb = 0.987251
DEBUG:root: dqn, choose action rondomly, need time 0.000524999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5392current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 866.00549316]
 [ 376.84182739]
 [  35.56484604]
 [  35.56484604]
 [ 231.63842773]
 [  47.75932693]
 [  50.89110947]
 [ 208.84552002]
 [  52.60649872]
 [   6.47786999]
 [  25.00015259]
 [   7.45849895]
 [ 376.84182739]
 [   9.52348137]
 [ 308.54806519]
 [   9.89143562]]
DEBUG:root:training time = %d0.208352
INFO:root:frame =5393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259160995483
INFO:root:frame =5394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269174575806
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9872415
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000292778015137
INFO:root:frame =5397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000569105148315
INFO:root:frame =5398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488996505737
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.987232
DEBUG:root: dqn, choose action rondomly, need time 0.000443000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.59023532e-02]
 [  3.17550201e+02]
 [  8.99656152e+03]
 [  1.21986740e+02]
 [  1.14375372e+01]
 [  3.81321320e+02]
 [  3.07577576e+02]
 [  8.28021526e+00]
 [  1.59414520e+02]
 [  3.46471710e+01]
 [  2.11678024e+02]
 [  4.87239609e+01]
 [  4.87239609e+01]
 [  3.25350311e+02]
 [  8.43316193e+01]
 [  1.61920547e+01]]
DEBUG:root:training time = %d0.20901
INFO:root:frame =5401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =5402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000318050384521
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9872225
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =5405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =5406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.987213
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.33950296e-02]
 [  2.50845062e+02]
 [  1.62303516e+03]
 [  5.54790382e+01]
 [  2.26190373e-01]
 [  1.17536108e+03]
 [  1.81164951e+01]
 [  5.58409348e+01]
 [  6.79530716e+00]
 [  2.10627705e-01]
 [  3.77873659e+00]
 [  8.95516541e+02]
 [  1.15202161e+03]
 [  8.52024002e+01]
 [  3.18256714e+03]
 [  1.32906335e+03]]
DEBUG:root:training time = %d0.205905
INFO:root:frame =5409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000342845916748
INFO:root:frame =5410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame = 5411 State into memory, numbers recorded 128 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.00058388710022
INFO:root:random_action_porb = 0.9872035
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5412current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =5413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =5414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000379085540771
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:random_action_porb = 0.987194
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.70720596e+01]
 [  5.75678635e+01]
 [  8.66728613e+03]
 [  2.99347699e-01]
 [  2.89158618e+03]
 [  2.28066406e+02]
 [  5.48434982e+01]
 [  8.82716675e+02]
 [  1.99294885e+03]
 [  5.63900322e-02]
 [  1.78519272e+02]
 [  2.68862976e+02]
 [  1.06152153e+02]
 [  1.92239853e+02]
 [  1.23266077e+03]
 [  7.05201721e+01]]
DEBUG:root:training time = %d0.197037
INFO:root:frame =5417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000189781188965
INFO:root:frame =5418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255107879639
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.9871845
DEBUG:root: dqn, choose action rondomly, need time 0.000192999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:frame =5421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =5422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000242948532104
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.987175
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.58988375e-04]
 [  7.03439636e+01]
 [  8.99224777e+01]
 [  6.09805725e+02]
 [  5.64789772e+00]
 [  1.05533179e+03]
 [  1.38775421e+02]
 [  3.68512915e+03]
 [  5.02764244e+01]
 [  4.52319946e+02]
 [  8.04600334e+00]
 [  2.20359302e+03]
 [  1.11701660e+01]
 [  1.43525055e+02]
 [  6.19814148e+01]
 [  3.68512915e+03]]
DEBUG:root:training time = %d0.199366
INFO:root:frame =5425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:frame =5426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 9.58442687988e-05
INFO:root:random_action_porb = 0.9871655
DEBUG:root: dqn, choose action rondomly, need time 0.000233999999978
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:frame =5429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =5430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494956970215
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.987156
DEBUG:root: dqn, choose action rondomly, need time 0.000163000000015
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.35762299e+02]
 [  4.88096352e+01]
 [  3.06184998e+01]
 [  4.38654968e+02]
 [  5.59547710e+00]
 [  1.14586754e+01]
 [  2.20805054e+03]
 [  1.01611662e+00]
 [  4.46880569e+01]
 [  3.88229370e+02]
 [  2.31352393e+03]
 [  7.48077469e+01]
 [  4.46880569e+01]
 [  1.67809236e+00]
 [  1.02885938e+00]
 [  4.72067383e+03]]
DEBUG:root:training time = %d0.201484
INFO:root:frame =5433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =5434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.9871465
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =5437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =5438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.987137
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.36800766e+02]
 [  4.54890527e+03]
 [  6.40278320e+01]
 [  7.66840439e+01]
 [  6.13402319e+00]
 [  4.93942070e+00]
 [  3.55832601e+00]
 [  3.08626986e+00]
 [  1.05701227e+01]
 [  1.13868433e+03]
 [  3.55832601e+00]
 [  1.13868433e+03]
 [  2.23214555e+00]
 [  1.69587662e+02]
 [  5.43089962e+00]
 [  3.58089561e+01]]
DEBUG:root:training time = %d0.19513
INFO:root:frame =5441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =5442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame = 5443 State into memory, numbers recorded 129 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000565052032471
INFO:root:random_action_porb = 0.9871275
DEBUG:root: dqn, choose action rondomly, need time 0.000267000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5444current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =5445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =5446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.987118
INFO:root:dqn select action Tensor("ArgMax_9:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.009839
INFO:root:action choosen by dqn [2]
INFO:root:frame =5448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.86045410e+02]
 [  6.59871155e+02]
 [  3.10266388e+02]
 [  3.60706360e+02]
 [  6.78012939e+02]
 [  1.17008728e+03]
 [  1.95008907e+01]
 [  1.96249695e+01]
 [  3.45938414e-01]
 [  3.65645409e+00]
 [  1.95008907e+01]
 [  1.76275444e+01]
 [  1.37093704e+02]
 [  4.19120270e+02]
 [  9.49043701e+02]
 [  1.14670357e+02]]
DEBUG:root:training time = %d0.209501
INFO:root:frame =5449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =5450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.9871085
DEBUG:root: dqn, choose action rondomly, need time 0.000179000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:frame =5453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =5454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000338077545166
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.987099
INFO:root:dqn select action Tensor("ArgMax_10:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00953899999999
INFO:root:action choosen by dqn [2]
INFO:root:frame =5456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.06184721e+00]
 [  1.62230625e+01]
 [  1.89687256e+03]
 [  5.51425903e+02]
 [  1.51913452e+02]
 [  2.13127151e+02]
 [  4.21547272e+02]
 [  2.17326679e+01]
 [  1.76811133e+03]
 [  2.36678886e+01]
 [  3.10029907e+02]
 [  4.65585510e+02]
 [  1.00497107e+03]
 [  2.76484434e-03]
 [  4.21547272e+02]
 [  6.80477112e+02]]
DEBUG:root:training time = %d0.199359
INFO:root:frame =5457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =5458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.00042986869812
INFO:root:random_action_porb = 0.9870895
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =5461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =5462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root:frame = 5463 State into memory, numbers recorded 130 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.00053596496582
INFO:root:random_action_porb = 0.98708
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5464current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.44342957e+01]
 [  2.02090969e+01]
 [  1.26013672e+00]
 [  1.06671967e-01]
 [  1.29928553e+00]
 [  1.88527637e+03]
 [  3.08147046e+03]
 [  2.09122581e+01]
 [  3.97959766e+03]
 [  1.57436647e+01]
 [  1.02395386e+02]
 [  8.88820648e+01]
 [  4.73574219e+02]
 [  1.04949532e+02]
 [  7.02843750e+02]
 [  3.47477722e+02]]
DEBUG:root:training time = %d0.199551
INFO:root:frame =5465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =5466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000396013259888
INFO:root:frame = 5467 State into memory, numbers recorded 131 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000607013702393
INFO:root:random_action_porb = 0.9870705
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5468current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =5469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000396013259888
INFO:root:frame =5470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000572919845581
DEBUG:root: save sample needs time = 0.000280141830444
INFO:root:random_action_porb = 0.987061
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.81008972e+02]
 [  6.50578064e+02]
 [  9.59632492e+00]
 [  8.11389923e+00]
 [  6.77847366e+01]
 [  4.10860535e+02]
 [  4.36079102e+02]
 [  5.73279724e+02]
 [  2.98341312e+01]
 [  1.46400061e+03]
 [  1.29719696e+02]
 [  1.01852684e+01]
 [  1.89533634e+01]
 [  4.10860535e+02]
 [  4.94399658e+03]
 [  1.62424302e+00]]
DEBUG:root:training time = %d0.194745
INFO:root:frame =5473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274181365967
INFO:root:frame =5474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487089157104
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:random_action_porb = 0.9870515
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =5477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =5478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000396966934204
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:random_action_porb = 0.987042
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.25607874e+03]
 [  2.49450982e-01]
 [  1.23243332e+02]
 [  1.48361893e+02]
 [  3.68461426e+02]
 [  1.13526125e+01]
 [  4.41693664e-01]
 [  1.44265762e+02]
 [  2.46502243e+02]
 [  2.92666107e+02]
 [  1.02886023e+03]
 [  6.30644798e+01]
 [  1.44121110e+00]
 [  2.49584732e+02]
 [  1.73538684e+03]
 [  1.04146741e+03]]
DEBUG:root:training time = %d0.213463
INFO:root:frame =5481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:frame =5482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487804412842
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.9870325
DEBUG:root: dqn, choose action rondomly, need time 0.000478999999984
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000585079193115
INFO:root:frame =5485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000494003295898
INFO:root:frame =5486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root:random_action_porb = 0.987023
DEBUG:root: dqn, choose action rondomly, need time 0.00031199999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000517845153809
INFO:root:training error  = [[  7.26733246e+01]
 [  2.60066315e+02]
 [  1.59252045e+02]
 [  2.78863907e-02]
 [  1.59252045e+02]
 [  3.19196033e+00]
 [  1.79775822e+00]
 [  6.98697510e+03]
 [  8.37488632e+01]
 [  5.28630562e+01]
 [  8.10250244e+02]
 [  1.59252045e+02]
 [  3.20010185e+01]
 [  8.43364868e+02]
 [  1.55802673e+02]
 [  3.67862457e+02]]
DEBUG:root:training time = %d0.204752
INFO:root:frame =5489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:frame =5490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:random_action_porb = 0.9870135
DEBUG:root: dqn, choose action rondomly, need time 0.000280000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root: ememy has been killed for 10 times 
INFO:root:enemies_left [0]
INFO:root:frame =5493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:frame =5494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000397920608521
INFO:root:frame = 5495 State into memory, numbers recorded 132 action = 2, reward = 255
DEBUG:root: save sample needs time = 0.000565767288208
INFO:root:random_action_porb = 0.987004
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5496current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000356912612915
INFO:root:training error  = [[  3.17141388e+02]
 [  3.38831425e-01]
 [  1.19309759e+01]
 [  2.08618140e+03]
 [  6.12504150e+02]
 [  1.24489441e+03]
 [  5.01802124e+02]
 [  1.02490894e+03]
 [  1.79675385e+02]
 [  1.24489441e+03]
 [  1.80139523e+01]
 [  1.79675385e+02]
 [  2.60372486e+01]
 [  3.32265816e+01]
 [  3.06980518e+03]
 [  4.01588348e+02]]
DEBUG:root:training time = %d0.214651
INFO:root:frame =5497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =5498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000534057617188
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9869945
DEBUG:root: dqn, choose action rondomly, need time 0.000327999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =5501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =5502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.986985
DEBUG:root: dqn, choose action rondomly, need time 0.000200000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.75439644e+00]
 [  1.95761032e+02]
 [  3.56068665e+02]
 [  1.53752394e+01]
 [  3.11425873e+02]
 [  3.05191040e+03]
 [  9.75906372e+01]
 [  3.76244903e-01]
 [  8.26627014e+02]
 [  1.61831750e+03]
 [  1.76140796e+03]
 [  1.01290146e+02]
 [  8.26627014e+02]
 [  1.72802979e+02]
 [  6.33825731e+00]
 [  1.78286343e+01]]
DEBUG:root:training time = %d0.200061
INFO:root:frame =5505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270128250122
INFO:root:frame =5506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000201225280762
INFO:root:random_action_porb = 0.9869755
DEBUG:root: dqn, choose action rondomly, need time 0.000278999999978
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =5509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame =5510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame = 5511 State into memory, numbers recorded 133 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000576019287109
INFO:root:random_action_porb = 0.986966
DEBUG:root: dqn, choose action rondomly, need time 0.000336000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5512current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.29665432e+01]
 [  6.44323181e+02]
 [  7.06886292e+00]
 [  1.21315269e+01]
 [  9.08503052e+02]
 [  1.51398126e-05]
 [  4.38274365e+03]
 [  1.88052571e+00]
 [  5.01019335e+00]
 [  4.09162769e+03]
 [  1.74384567e+02]
 [  1.65508667e+02]
 [  7.53626343e+02]
 [  6.26415634e+01]
 [  6.26415634e+01]
 [  6.49613586e+02]]
DEBUG:root:training time = %d0.222619
INFO:root:frame =5513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =5514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000243186950684
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.9869565
DEBUG:root: dqn, choose action rondomly, need time 0.000320999999985
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =5517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =5518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485181808472
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:random_action_porb = 0.986947
DEBUG:root: dqn, choose action rondomly, need time 0.000201000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.24295630e+03]
 [  6.56925293e+02]
 [  2.38961502e+02]
 [  5.36016083e+01]
 [  9.60446243e+01]
 [  2.38961502e+02]
 [  2.60119965e+02]
 [  7.43586731e+00]
 [  4.89863281e+01]
 [  1.60068367e-03]
 [  2.71349030e+02]
 [  8.23507233e+01]
 [  9.60446243e+01]
 [  9.56883240e+02]
 [  9.50606632e+00]
 [  1.07536084e+03]]
DEBUG:root:training time = %d0.188034
INFO:root:frame =5521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =5522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308036804199
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9869375
DEBUG:root: dqn, choose action rondomly, need time 0.000490999999982
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000419139862061
INFO:root:frame =5525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =5526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00050687789917
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:random_action_porb = 0.986928
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332832336426
INFO:root:training error  = [[  3.12896967e-01]
 [  5.37877464e+01]
 [  2.29687164e+02]
 [  5.71974792e+02]
 [  3.99510498e+02]
 [  3.10650299e+02]
 [  2.90978394e+01]
 [  3.75405396e+02]
 [  1.09275681e+02]
 [  1.19349927e+03]
 [  2.13243457e+04]
 [  3.40463196e+02]
 [  2.64680266e+00]
 [  4.67576111e+02]
 [  2.25157104e+02]
 [  3.60115723e+02]]
DEBUG:root:training time = %d0.209063
INFO:root:frame =5529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =5530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.9869185
DEBUG:root: dqn, choose action rondomly, need time 0.000265000000013
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =5533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =5534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.986909
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000011
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.37450098e+03]
 [  1.65867996e+02]
 [  3.57823706e+03]
 [  5.37450098e+03]
 [  9.96128006e+01]
 [  2.63716217e+02]
 [  6.41086731e+02]
 [  2.76339508e+02]
 [  4.96744690e+01]
 [  1.15666687e+02]
 [  2.62654688e+03]
 [  2.23423755e+03]
 [  3.14651270e+03]
 [  5.21543789e+00]
 [  3.47694794e+02]
 [  3.47694794e+02]]
DEBUG:root:training time = %d0.193013
INFO:root:frame =5537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:frame =5538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9868995
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =5541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000521898269653
INFO:root:frame =5542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324010848999
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:random_action_porb = 0.98689
DEBUG:root: dqn, choose action rondomly, need time 0.000490999999982
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.95584679e+00]
 [  9.95584679e+00]
 [  1.31505371e+02]
 [  5.62393799e+02]
 [  7.51835556e+01]
 [  4.12646545e+02]
 [  9.85235046e+02]
 [  1.85413361e-02]
 [  4.02377441e+03]
 [  9.93527508e+00]
 [  1.81621301e+03]
 [  9.27477188e+01]
 [  2.77426001e+03]
 [  9.30178680e+01]
 [  2.77426001e+03]
 [  9.30178680e+01]]
DEBUG:root:training time = %d0.209998
INFO:root:frame =5545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =5546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000300168991089
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:random_action_porb = 0.9868805
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =5549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000525951385498
INFO:root:frame =5550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.986871
DEBUG:root: dqn, choose action rondomly, need time 0.000360000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.23017296e+02]
 [  2.39137077e+00]
 [  1.08447083e+03]
 [  1.83607758e+02]
 [  1.20858300e+00]
 [  2.76926147e+02]
 [  1.08447083e+03]
 [  5.39613965e+03]
 [  2.76926147e+02]
 [  1.07971626e+02]
 [  1.67338428e+01]
 [  4.86627333e-02]
 [  2.21316696e+02]
 [  3.77507172e+01]
 [  3.75720978e+01]
 [  9.47922974e+01]]
DEBUG:root:training time = %d0.240698
INFO:root:frame =5553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =5554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265836715698
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:random_action_porb = 0.9868615
DEBUG:root: dqn, choose action rondomly, need time 0.000202999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180959701538
INFO:root:frame =5557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =5558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:random_action_porb = 0.986852
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000385046005249
INFO:root:training error  = [[  5.84949188e+01]
 [  5.06706119e-01]
 [  4.02624054e+01]
 [  1.49805945e+03]
 [  5.00227261e+00]
 [  2.94942700e+03]
 [  8.12050415e+02]
 [  2.83047150e+02]
 [  4.39985561e+00]
 [  1.00691656e+03]
 [  8.75595215e+02]
 [  3.48348785e+02]
 [  4.43374842e-01]
 [  1.85417004e+01]
 [  1.49805945e+03]
 [  6.56356583e+01]]
DEBUG:root:training time = %d0.184833
INFO:root:frame =5561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =5562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324010848999
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9868425
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =5565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =5566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.986833
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.75204048e+01]
 [  1.00485814e+00]
 [  2.46344995e+00]
 [  1.42552063e+02]
 [  1.28965032e+00]
 [  1.69913692e+01]
 [  6.33689957e+01]
 [  1.06775026e+01]
 [  4.29980811e+03]
 [  1.75715375e+00]
 [  3.03223858e+01]
 [  1.93286719e+03]
 [  2.70429840e+01]
 [  2.70764795e+03]
 [  9.91336975e+02]
 [  1.21771564e+01]]
DEBUG:root:training time = %d0.214753
INFO:root:frame =5569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =5570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9868235
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =5573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =5574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.986814
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  122.37730408]
 [ 1013.2121582 ]
 [ 1134.83166504]
 [   10.65419388]
 [    8.45258713]
 [   24.06870079]
 [   19.68791008]
 [   88.88491058]
 [  741.39123535]
 [    2.4980576 ]
 [  975.76635742]
 [  394.93920898]
 [   19.06646347]
 [  100.86309814]
 [ 1160.53198242]
 [  127.91209412]]
DEBUG:root:training time = %d0.193084
INFO:root:frame =5577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =5578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9868045
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000011
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =5581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =5582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000215768814087
INFO:root:random_action_porb = 0.986795
DEBUG:root: dqn, choose action rondomly, need time 0.000185999999985
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000137805938721
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.27830322e+03]
 [  3.51004547e+02]
 [  9.26857147e+01]
 [  5.46168137e+01]
 [  8.17879105e+01]
 [  1.09960184e+01]
 [  9.26857147e+01]
 [  2.71334469e-01]
 [  2.05626607e-01]
 [  1.01608187e-01]
 [  1.27276754e+00]
 [  7.44253933e-01]
 [  1.91806775e+03]
 [  3.69060287e+01]
 [  4.25894318e+02]
 [  1.73179672e+02]]
DEBUG:root:training time = %d0.207078
INFO:root:frame =5585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:frame =5586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227928161621
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:random_action_porb = 0.9867855
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =5589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =5590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000328063964844
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:random_action_porb = 0.986776
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.53016453e+01]
 [  4.70550030e-01]
 [  6.27130175e+00]
 [  1.82903833e+03]
 [  2.41821021e+03]
 [  2.37086035e+03]
 [  1.48644037e+01]
 [  6.27517366e+00]
 [  2.43065205e+01]
 [  7.75509583e+02]
 [  8.68636727e-01]
 [  1.56190186e+03]
 [  5.51775856e+01]
 [  8.72198105e+00]
 [  7.04260874e+00]
 [  1.32734480e-03]]
DEBUG:root:training time = %d0.203437
INFO:root:frame =5593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =5594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame = 5595 State into memory, numbers recorded 134 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000541925430298
INFO:root:random_action_porb = 0.9867665
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5596current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =5597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =5598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.986757
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.10569702e+02]
 [  9.89009705e+01]
 [  2.42091919e+02]
 [  3.14465302e+02]
 [  5.65049553e+00]
 [  9.08010125e-01]
 [  3.28716431e+02]
 [  4.50284839e-01]
 [  1.04223376e+03]
 [  5.71341919e+02]
 [  2.41123438e+03]
 [  7.57010956e+01]
 [  2.18134448e+03]
 [  9.15359802e+02]
 [  1.04223376e+03]
 [  7.26562729e+01]]
DEBUG:root:training time = %d0.210995
INFO:root:frame =5601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265836715698
INFO:root:frame =5602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9867475
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =5605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =5606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.986738
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000360012054443
INFO:root:training error  = [[ 1169.00427246]
 [  901.83624268]
 [  447.42938232]
 [ 1169.00427246]
 [  108.1374588 ]
 [    3.10534668]
 [   28.07003975]
 [  155.52604675]
 [  320.82235718]
 [  123.92082977]
 [  630.97851562]
 [   25.86431503]
 [ 1081.39807129]
 [   65.46473694]
 [  279.87768555]
 [   50.73670959]]
DEBUG:root:training time = %d0.199048
INFO:root:frame =5609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =5610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
INFO:root:frame = 5611 State into memory, numbers recorded 135 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:random_action_porb = 0.9867285
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000015
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5612current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =5613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =5614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.986719
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000018
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.23685315e+03]
 [  1.63816870e+03]
 [  1.01200218e+01]
 [  2.46520596e+01]
 [  5.32601967e+01]
 [  2.94522949e+02]
 [  1.12119045e+01]
 [  2.86928925e+02]
 [  6.17943787e+02]
 [  3.06809807e+01]
 [  3.79312114e-04]
 [  1.12885193e+03]
 [  2.12589115e-01]
 [  2.46520596e+01]
 [  1.93888264e+01]
 [  3.79312114e-04]]
DEBUG:root:training time = %d0.202775
INFO:root:frame =5617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000346899032593
INFO:root:frame =5618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000540018081665
INFO:root:frame = 5619 State into memory, numbers recorded 136 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000615835189819
INFO:root:random_action_porb = 0.9867095
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5620current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =5621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284194946289
INFO:root:frame =5622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9867
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.90017567e+01]
 [  7.72075951e-02]
 [  2.37437881e+02]
 [  3.50819238e+03]
 [  3.42471222e+02]
 [  4.12550977e+03]
 [  3.85380816e+00]
 [  1.85456555e+03]
 [  2.71578445e+01]
 [  2.39065456e+00]
 [  4.68086517e+02]
 [  5.80991566e-01]
 [  3.25129390e+00]
 [  1.26809128e+02]
 [  4.99809967e+02]
 [  2.53278255e+01]]
DEBUG:root:training time = %d0.20541
INFO:root:frame =5625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:frame =5626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9866905
DEBUG:root: dqn, choose action rondomly, need time 0.000169
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000131845474243
INFO:root:frame =5629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame =5630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000317096710205
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.986681
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312805175781
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.05264587e+01]
 [  2.42570786e+02]
 [  6.73377395e-01]
 [  2.32377777e+02]
 [  1.24525309e+01]
 [  1.48047461e+03]
 [  1.86467113e+01]
 [  2.06819763e+02]
 [  1.56225171e+03]
 [  2.19380410e+04]
 [  7.51379132e-01]
 [  2.28008594e+03]
 [  8.45779061e-01]
 [  2.30936387e+04]
 [  1.77722168e+01]
 [  5.45711670e+01]]
DEBUG:root:training time = %d0.205651
INFO:root:frame =5633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =5634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00032901763916
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:random_action_porb = 0.9866715
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =5637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000494956970215
INFO:root:frame =5638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000179052352905
INFO:root:random_action_porb = 0.986662
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root: ememy has been killed for 11 times 
INFO:root:enemies_left [0]
INFO:root:frame =5640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000476121902466
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.23825348e+02]
 [  3.64165726e+01]
 [  1.56079006e+01]
 [  1.56079006e+01]
 [  1.37490265e+02]
 [  1.01989052e+02]
 [  1.48894943e+02]
 [  6.94130173e+01]
 [  4.76208282e+02]
 [  3.64165726e+01]
 [  8.27464771e+00]
 [  1.66464026e+03]
 [  1.46212537e+03]
 [  8.42636292e+02]
 [  1.02147639e+00]
 [  2.18620926e+02]]
DEBUG:root:training time = %d0.202956
INFO:root:frame =5641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000191926956177
INFO:root:frame =5642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame = 5643 State into memory, numbers recorded 137 action = 0, reward = 255
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:random_action_porb = 0.9866525
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5644current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000382900238037
INFO:root:frame =5645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =5646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000290155410767
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.986643
DEBUG:root: dqn, choose action rondomly, need time 0.000364000000019
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000485897064209
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  146.03964233]
 [ 1660.9206543 ]
 [    8.79364491]
 [   58.14597702]
 [  494.22851562]
 [    8.79364491]
 [ 5457.78173828]
 [   56.58147812]
 [    7.40895224]
 [ 1113.09069824]
 [   56.58147812]
 [    7.40895224]
 [   58.14597702]
 [ 4563.07421875]
 [   19.55270958]
 [  110.33557129]]
DEBUG:root:training time = %d0.190106
INFO:root:frame =5649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000322818756104
INFO:root:frame =5650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000287055969238
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9866335
DEBUG:root: dqn, choose action rondomly, need time 0.000495000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:frame =5653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =5654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000295877456665
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:random_action_porb = 0.986624
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.53272171e-02]
 [  2.01299648e+01]
 [  2.01299648e+01]
 [  1.32878577e+03]
 [  7.67290649e+02]
 [  1.77244714e+03]
 [  1.11931053e+02]
 [  5.34900208e+01]
 [  9.68881488e-01]
 [  3.42636414e+02]
 [  2.22080835e+03]
 [  8.31516953e+01]
 [  4.89181633e+01]
 [  7.50384521e+01]
 [  1.04568848e+02]
 [  1.90440079e+02]]
DEBUG:root:training time = %d0.218106
INFO:root:frame =5657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =5658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235080718994
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.9866145
DEBUG:root: dqn, choose action rondomly, need time 0.000201000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:frame =5661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000510931015015
INFO:root:frame =5662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:random_action_porb = 0.986605
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.42331333e+01]
 [  4.63872070e+02]
 [  4.05547363e+02]
 [  9.34227884e-01]
 [  2.00012894e+02]
 [  4.02820854e+01]
 [  2.38570404e+01]
 [  2.83562431e+01]
 [  2.78051147e+02]
 [  6.12996578e+00]
 [  2.83562431e+01]
 [  1.14109505e+02]
 [  3.50982086e+02]
 [  4.80697727e+00]
 [  1.64416968e+03]
 [  2.38570404e+01]]
DEBUG:root:training time = %d0.209485
INFO:root:frame =5665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =5666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264883041382
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:random_action_porb = 0.9865955
DEBUG:root: dqn, choose action rondomly, need time 0.000684000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =5669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000500917434692
INFO:root:frame =5670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487089157104
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.986586
INFO:root:dqn select action Tensor("ArgMax_11:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014554
INFO:root:action choosen by dqn [2]
INFO:root:frame =5672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000175952911377
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.58023389e+03]
 [  1.89327759e+03]
 [  2.54755688e+01]
 [  2.01653979e+03]
 [  2.19401688e+02]
 [  6.82030964e+00]
 [  6.04476929e+02]
 [  1.51335876e+02]
 [  2.54755688e+01]
 [  3.65369702e+03]
 [  5.12161987e+02]
 [  1.41455005e+03]
 [  2.40823166e+02]
 [  4.32583332e+00]
 [  6.04476929e+02]
 [  1.38472307e+00]]
DEBUG:root:training time = %d0.198265
INFO:root:frame =5673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =5674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.9865765
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =5677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =5678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.986567
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.20350085e+03]
 [  2.98649261e+02]
 [  2.52091751e+01]
 [  2.73468658e+02]
 [  2.01302204e+01]
 [  2.05445347e+01]
 [  4.87668953e+01]
 [  1.20350085e+03]
 [  2.38007569e+00]
 [  3.28533051e+02]
 [  1.65514832e+03]
 [  9.75436172e+01]
 [  2.36018970e+03]
 [  1.93820724e+02]
 [  4.23107207e-01]
 [  1.33411377e+02]]
DEBUG:root:training time = %d0.195351
INFO:root:frame =5681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =5682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 9.29832458496e-05
INFO:root:random_action_porb = 0.9865575
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000018
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =5685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =5686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.986548
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.82601166e+02]
 [  4.03739624e+02]
 [  1.30094193e+02]
 [  8.84529663e+02]
 [  3.05736465e+01]
 [  8.60605713e+02]
 [  7.17221436e+02]
 [  2.30202770e+01]
 [  8.75567780e+01]
 [  1.67437943e+02]
 [  3.40543506e+03]
 [  1.12841702e+01]
 [  1.38269484e+00]
 [  3.03925934e+02]
 [  2.56247540e+01]
 [  2.63294756e-01]]
DEBUG:root:training time = %d0.195858
INFO:root:frame =5689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:frame =5690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9865385
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999982
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =5693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =5694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00071907043457
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.986529
DEBUG:root: dqn, choose action rondomly, need time 0.000328999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.94984989e+01]
 [  7.30040207e+01]
 [  2.44818139e+00]
 [  9.50675583e+01]
 [  3.11238213e+01]
 [  1.80633044e+03]
 [  9.72737849e-01]
 [  2.56231506e+02]
 [  4.26549121e+03]
 [  8.82380772e+00]
 [  1.86010408e+00]
 [  9.03819031e+02]
 [  1.12965214e+00]
 [  1.16995190e+03]
 [  4.73706284e+01]
 [  3.93892578e+02]]
DEBUG:root:training time = %d0.195997
INFO:root:frame =5697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =5698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000245094299316
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.9865195
DEBUG:root: dqn, choose action rondomly, need time 0.000168000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:frame =5701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =5702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000243902206421
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:random_action_porb = 0.98651
DEBUG:root: dqn, choose action rondomly, need time 0.000209999999981
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000186920166016
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.70155396e+02]
 [  8.75878334e+00]
 [  1.16658112e+02]
 [  8.33755016e+00]
 [  1.78554285e+03]
 [  4.81966496e+00]
 [  5.19193053e-01]
 [  1.74817224e+03]
 [  1.08365798e+00]
 [  1.99894702e+00]
 [  8.14744202e+02]
 [  4.51147308e+02]
 [  4.32979317e+01]
 [  1.16658112e+02]
 [  1.54774734e+02]
 [  1.76394089e+02]]
DEBUG:root:training time = %d0.19038
INFO:root:frame =5705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255823135376
INFO:root:frame =5706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000523090362549
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9865005
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =5709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =5710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.986491
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000351905822754
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.17055216e+01]
 [  3.61335831e+01]
 [  1.65018518e+03]
 [  4.07077675e+01]
 [  3.35343475e+02]
 [  9.77093164e+03]
 [  2.38992462e+02]
 [  2.11906982e+03]
 [  1.38218822e+01]
 [  1.21033621e+01]
 [  4.78284760e+01]
 [  4.52291046e+02]
 [  1.32183999e-01]
 [  2.38992462e+02]
 [  3.09099674e-01]
 [  1.00788292e+02]]
DEBUG:root:training time = %d0.207317
INFO:root:frame =5713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =5714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9864815
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000018
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =5717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =5718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488996505737
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.986472
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.29217285e+02]
 [  3.48435516e+02]
 [  3.69861267e+02]
 [  1.67304836e-02]
 [  4.58686133e+03]
 [  1.41499536e+03]
 [  1.06301807e+03]
 [  2.47196751e+01]
 [  9.19964111e+02]
 [  6.56328430e+01]
 [  2.47812578e+04]
 [  1.51012619e+02]
 [  8.16417969e+02]
 [  1.96597641e+02]
 [  5.20961670e+02]
 [  3.66984215e+01]]
DEBUG:root:training time = %d0.204784
INFO:root:frame =5721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000197172164917
INFO:root:frame =5722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 9.29832458496e-05
INFO:root:random_action_porb = 0.9864625
DEBUG:root: dqn, choose action rondomly, need time 0.000171999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:frame =5725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224828720093
INFO:root:frame =5726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.986453
DEBUG:root: dqn, choose action rondomly, need time 0.000334999999978
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.05805098e+04]
 [  5.32278748e+02]
 [  4.54241669e+02]
 [  1.93912621e+01]
 [  1.22652521e+01]
 [  9.22744446e+02]
 [  2.64449482e+01]
 [  7.62207651e+00]
 [  2.84800323e+02]
 [  5.54063049e+02]
 [  5.45778015e+02]
 [  1.13246299e+04]
 [  7.72297821e+01]
 [  3.61337204e+01]
 [  1.05805098e+04]
 [  4.07663536e+01]]
DEBUG:root:training time = %d0.218479
INFO:root:frame =5729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =5730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025200843811
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:random_action_porb = 0.9864435
DEBUG:root: dqn, choose action rondomly, need time 0.000385999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =5733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000352144241333
INFO:root:frame =5734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482797622681
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.986434
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999985
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.31406754e+02]
 [  1.38591309e+02]
 [  1.58225049e+03]
 [  1.80861893e+02]
 [  1.12896461e+02]
 [  1.74441077e+03]
 [  9.98073730e+01]
 [  3.19005249e+02]
 [  4.41880341e+02]
 [  1.39090669e+00]
 [  8.91540833e+02]
 [  5.46041059e+00]
 [  4.94607666e+02]
 [  1.06327661e+03]
 [  1.77291656e+00]
 [  1.96474533e+01]]
DEBUG:root:training time = %d0.191606
INFO:root:frame =5737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =5738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00059700012207
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:random_action_porb = 0.9864245
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root:frame =5741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root: ememy has been killed for 12 times 
INFO:root:enemies_left [0]
INFO:root:frame =5742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame = 5743 State into memory, numbers recorded 138 action = 4, reward = 255
DEBUG:root: save sample needs time = 0.000555992126465
INFO:root:random_action_porb = 0.986415
INFO:root:dqn select action Tensor("ArgMax_12:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01225
INFO:root:action choosen by dqn [2]
INFO:root:frame =5744current_observation done, NOT record action [2], reward = 0
DEBUG:root: save sample needs time = 0.000380992889404
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.69717285e+03]
 [  2.29143887e+01]
 [  2.30144592e+02]
 [  2.68516663e+02]
 [  8.49103012e+01]
 [  1.65500183e+03]
 [  3.69287061e+03]
 [  1.45992813e+02]
 [  1.57393994e+03]
 [  3.05358691e+03]
 [  3.78636987e+03]
 [  1.48056674e+00]
 [  2.30144592e+02]
 [  1.46176590e+02]
 [  1.05073563e+02]
 [  1.69039001e+02]]
DEBUG:root:training time = %d0.213982
INFO:root:frame =5745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =5746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000327825546265
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9864055
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =5749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =5750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000206232070923
INFO:root:random_action_porb = 0.986396
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000021
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.51788147e+02]
 [  6.16829651e+02]
 [  7.93422165e+01]
 [  1.02535400e+03]
 [  1.88849342e+00]
 [  7.93422165e+01]
 [  6.57863388e+01]
 [  1.24716026e+02]
 [  2.38936591e+00]
 [  1.46031311e+03]
 [  4.88727905e+02]
 [  2.36864185e+03]
 [  1.19826920e+02]
 [  7.93422165e+01]
 [  1.40836725e+01]
 [  2.18546707e+02]]
DEBUG:root:training time = %d0.197542
INFO:root:frame =5753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =5754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00040602684021
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9863865
DEBUG:root: dqn, choose action rondomly, need time 0.000332000000014
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =5757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000424146652222
INFO:root:frame =5758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466823577881
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.986377
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  166.51850891]
 [   19.96413612]
 [  105.34992981]
 [  319.38116455]
 [ 1062.27893066]
 [ 1005.85455322]
 [    4.49457359]
 [  554.55792236]
 [   38.10409546]
 [   38.10409546]
 [  136.68478394]
 [   29.01493073]
 [  440.38754272]
 [  126.91877747]
 [  166.34529114]
 [   13.81112003]]
DEBUG:root:training time = %d0.220538
INFO:root:frame =5761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =5762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298023223877
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.9863675
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000134944915771
INFO:root:frame =5765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000492095947266
INFO:root:frame =5766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.986358
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.44797564e+00]
 [  3.87853333e+02]
 [  5.32989578e+01]
 [  2.47573662e+01]
 [  5.42703247e+01]
 [  1.15940228e+01]
 [  1.02500404e+02]
 [  2.69276714e+01]
 [  5.32989578e+01]
 [  4.33914423e+00]
 [  8.42661095e+00]
 [  7.06760437e+02]
 [  2.43994045e+00]
 [  3.94210076e+00]
 [  3.66168976e+00]
 [  4.05876222e-08]]
DEBUG:root:training time = %d0.218837
INFO:root:frame =5769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =5770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000402927398682
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.9863485
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =5773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000576972961426
INFO:root:frame =5774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000414848327637
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:random_action_porb = 0.986339
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.61489075e+02]
 [  2.70556412e+01]
 [  3.24572635e+00]
 [  6.60915771e+02]
 [  1.99855492e-01]
 [  6.94237000e+02]
 [  6.08130811e+03]
 [  2.94650604e+02]
 [  2.26780772e+00]
 [  3.40903664e+01]
 [  1.28914352e+02]
 [  6.29264145e+01]
 [  4.77320709e+01]
 [  1.25776917e+02]
 [  5.27197815e+02]
 [  1.58646941e+00]]
DEBUG:root:training time = %d0.206603
INFO:root:frame =5777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:frame =5778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9863295
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =5781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =5782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.98632
DEBUG:root: dqn, choose action rondomly, need time 0.000580999999983
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.87239897e-01]
 [  2.63346405e+02]
 [  2.45435759e-01]
 [  8.51700745e+01]
 [  2.85626292e+00]
 [  5.27864799e+01]
 [  6.89439087e+02]
 [  4.70738983e+01]
 [  6.36198148e-02]
 [  4.33752251e+01]
 [  4.56416100e-01]
 [  2.63346405e+02]
 [  5.08115172e-01]
 [  2.38737305e+02]
 [  9.33207397e+01]
 [  1.27134802e+03]]
DEBUG:root:training time = %d0.202114
INFO:root:frame =5785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =5786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229120254517
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9863105
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =5789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =5790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000399112701416
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.986301
DEBUG:root: dqn, choose action rondomly, need time 0.000326000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.12379189e+01]
 [  2.40744084e-01]
 [  1.58144363e+02]
 [  4.18115082e+02]
 [  3.68594177e+02]
 [  9.52583847e+01]
 [  1.09345789e+03]
 [  2.00231190e+01]
 [  2.12248215e+02]
 [  1.30080933e+03]
 [  9.66387253e+01]
 [  2.28970612e+02]
 [  2.50319922e+03]
 [  1.65453809e+03]
 [  1.57094612e+01]
 [  4.34562439e+02]]
DEBUG:root:training time = %d0.200159
INFO:root:frame =5793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265836715698
INFO:root:frame =5794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9862915
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root:frame =5797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000504016876221
INFO:root:frame =5798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000235795974731
INFO:root:random_action_porb = 0.986282
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.70756924e+00]
 [  8.72908020e+02]
 [  1.64357674e+00]
 [  9.36857147e+01]
 [  4.64808594e+03]
 [  3.00408900e-03]
 [  1.59896805e+02]
 [  3.40783386e+01]
 [  2.46982956e+01]
 [  1.23189476e+02]
 [  2.31705303e+01]
 [  7.33673620e+00]
 [  1.99250269e+03]
 [  1.06153015e+03]
 [  2.93325867e+02]
 [  2.64713440e+01]]
DEBUG:root:training time = %d0.206466
INFO:root:frame =5801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =5802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.9862725
DEBUG:root: dqn, choose action rondomly, need time 0.000203999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:frame =5805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440835952759
INFO:root:frame =5806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229835510254
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.986263
DEBUG:root: dqn, choose action rondomly, need time 0.000486999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.78185352e+04]
 [  1.28384914e+01]
 [  8.67918909e-01]
 [  2.45599072e+03]
 [  1.35307770e+02]
 [  3.23640594e+01]
 [  1.35456028e+01]
 [  1.46495187e+00]
 [  4.07164368e+02]
 [  1.73007116e-01]
 [  3.57755188e+02]
 [  1.04018211e+01]
 [  1.62011841e+03]
 [  1.52661810e+01]
 [  1.42033496e+03]
 [  4.43176603e+00]]
DEBUG:root:training time = %d0.20815
INFO:root:frame =5809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:frame =5810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000228881835938
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9862535
DEBUG:root: dqn, choose action rondomly, need time 0.000325999999973
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322818756104
INFO:root:frame =5813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =5814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000120162963867
INFO:root:random_action_porb = 0.986244
DEBUG:root: dqn, choose action rondomly, need time 0.000338999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000475168228149
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.51683716e+02]
 [  7.88160095e+01]
 [  1.37149990e+04]
 [  5.75619202e+02]
 [  6.14103470e+01]
 [  5.52453842e+01]
 [  1.06153430e+05]
 [  3.17490368e+01]
 [  2.43636150e+01]
 [  2.56926804e+01]
 [  2.18648682e+02]
 [  1.01409775e+02]
 [  1.51570349e+01]
 [  9.19571289e+02]
 [  1.16882739e+03]
 [  1.22279671e+02]]
DEBUG:root:training time = %d0.187646
INFO:root:frame =5817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =5818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226020812988
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.9862345
DEBUG:root: dqn, choose action rondomly, need time 0.000191999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000179052352905
INFO:root:frame =5821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =5822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438213348389
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.986225
DEBUG:root: dqn, choose action rondomly, need time 0.000582000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000491142272949
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.90076123e+03]
 [  8.55993423e+01]
 [  5.60265930e+02]
 [  6.62999023e+02]
 [  3.04492807e+00]
 [  9.29537773e-01]
 [  2.19296249e+02]
 [  8.63417587e+01]
 [  3.18116045e+00]
 [  1.29552107e+01]
 [  5.13003540e+02]
 [  6.96568176e+02]
 [  1.12345367e+02]
 [  1.50142883e+03]
 [  8.78530045e+01]
 [  7.38025757e+02]]
DEBUG:root:training time = %d0.196991
INFO:root:frame =5825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:frame =5826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485897064209
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9862155
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =5829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root:frame =5830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame = 5831 State into memory, numbers recorded 139 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000648975372314
INFO:root:random_action_porb = 0.986206
DEBUG:root: dqn, choose action rondomly, need time 0.00017600000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5832current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[    8.64921761]
 [  605.80609131]
 [  696.91094971]
 [  742.83239746]
 [    5.44207096]
 [ 1686.19030762]
 [   54.76013565]
 [    8.64921761]
 [  162.19335938]
 [   58.80394745]
 [  120.71457672]
 [  605.80609131]
 [   10.78603649]
 [  199.02973938]
 [  236.04116821]
 [   38.52116394]]
DEBUG:root:training time = %d0.205697
INFO:root:frame =5833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =5834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:random_action_porb = 0.9861965
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =5837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =5838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:random_action_porb = 0.986187
DEBUG:root: dqn, choose action rondomly, need time 0.000231000000014
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:training error  = [[  7.26882706e+01]
 [  5.68006287e+02]
 [  4.95099831e+01]
 [  1.09372986e+03]
 [  5.29148817e+00]
 [  2.85385864e+02]
 [  1.26231956e+01]
 [  2.12827854e+01]
 [  1.26498416e-01]
 [  6.89321976e+01]
 [  1.01212885e+03]
 [  8.90877319e+02]
 [  1.25374951e+03]
 [  4.23028047e+04]
 [  2.42279510e+02]
 [  1.03251171e+01]]
DEBUG:root:training time = %d0.200395
INFO:root:frame =5841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000191926956177
INFO:root:frame =5842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000341892242432
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9861775
DEBUG:root: dqn, choose action rondomly, need time 0.000588000000022
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000315189361572
INFO:root:frame =5845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000222206115723
INFO:root:frame =5846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.986168
DEBUG:root: dqn, choose action rondomly, need time 0.000279000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.83972607e+01]
 [  7.62472000e+01]
 [  3.10943532e+00]
 [  4.73819618e+01]
 [  2.22549019e+01]
 [  3.98325745e+02]
 [  8.65189062e+03]
 [  1.37364697e+03]
 [  1.33509644e+03]
 [  9.86601410e+01]
 [  3.98325745e+02]
 [  8.65189062e+03]
 [  3.89883385e+01]
 [  3.91584656e+02]
 [  2.90039642e+02]
 [  9.06292496e+01]]
DEBUG:root:training time = %d0.205013
INFO:root:frame =5849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:frame =5850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000217914581299
DEBUG:root: save sample needs time = 9.20295715332e-05
INFO:root:random_action_porb = 0.9861585
DEBUG:root: dqn, choose action rondomly, need time 0.000163000000015
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:frame =5853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =5854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000516176223755
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.986149
DEBUG:root: dqn, choose action rondomly, need time 0.000207000000017
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.72719849e+02]
 [  3.43788354e+03]
 [  3.43788354e+03]
 [  2.58570605e+03]
 [  4.91484528e+01]
 [  4.92854736e+03]
 [  3.93290091e+00]
 [  2.91180916e+01]
 [  1.65231285e+01]
 [  3.45120645e+00]
 [  1.78697742e+03]
 [  4.06816864e+01]
 [  5.64866877e+00]
 [  1.65231285e+01]
 [  1.29597733e+02]
 [  1.60584351e+02]]
DEBUG:root:training time = %d0.202488
INFO:root:frame =5857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =5858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.9861395
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000011
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =5861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =5862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000334978103638
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.98613
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.68179560e+00]
 [  1.67279422e+00]
 [  1.42042387e+00]
 [  5.70957617e+03]
 [  1.35590955e+03]
 [  5.00872467e+02]
 [  5.07848389e+02]
 [  9.55273895e+01]
 [  8.56399109e+02]
 [  1.71078064e+02]
 [  1.29794970e+01]
 [  2.72401595e+00]
 [  1.29794970e+01]
 [  1.52643570e+02]
 [  1.71078064e+02]
 [  7.49979309e+02]]
DEBUG:root:training time = %d0.198879
INFO:root:frame =5865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =5866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9861205
DEBUG:root: dqn, choose action rondomly, need time 0.000159999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:frame =5869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =5870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000221967697144
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.986111
DEBUG:root: dqn, choose action rondomly, need time 0.000167000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.00204449e+03]
 [  1.46945357e+00]
 [  2.59724102e+01]
 [  2.56695347e+01]
 [  5.14976624e+02]
 [  3.43951929e+03]
 [  3.17743187e+01]
 [  7.58352490e+03]
 [  1.37505382e-01]
 [  4.75046875e+03]
 [  2.24477997e+02]
 [  1.34693346e+01]
 [  7.73555847e+02]
 [  2.51993108e+00]
 [  1.46945357e+00]
 [  2.73712139e+01]]
DEBUG:root:training time = %d0.202225
INFO:root:frame =5873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =5874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000720024108887
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.9861015
DEBUG:root: dqn, choose action rondomly, need time 0.000193999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000197172164917
INFO:root:frame =5877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000428199768066
INFO:root:frame =5878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.986092
DEBUG:root: dqn, choose action rondomly, need time 0.00029600000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.01563549e+00]
 [  1.33164968e+01]
 [  5.40058472e+02]
 [  1.06718613e+02]
 [  2.68310986e+01]
 [  9.54530151e+02]
 [  3.68243469e+02]
 [  7.61902039e+02]
 [  4.29210052e+01]
 [  2.74901562e+03]
 [  6.24372721e-01]
 [  1.27496254e+02]
 [  2.00389051e+00]
 [  3.68243469e+02]
 [  4.16425171e+02]
 [  1.25547279e+02]]
DEBUG:root:training time = %d0.227691
INFO:root:frame =5881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =5882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9860825
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000377893447876
INFO:root:frame =5885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =5886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487089157104
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:random_action_porb = 0.986073
DEBUG:root: dqn, choose action rondomly, need time 0.00069000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.09803577e+03]
 [  8.59289734e+02]
 [  2.22981354e+02]
 [  2.59951229e+01]
 [  1.34976301e+01]
 [  2.04650417e-01]
 [  2.44893761e+01]
 [  1.85918659e-01]
 [  2.34776733e+03]
 [  2.03983307e+02]
 [  2.22981354e+02]
 [  8.41611099e+00]
 [  2.03983307e+02]
 [  2.60285079e-01]
 [  1.52816257e+01]
 [  3.43915787e+01]]
DEBUG:root:training time = %d0.201125
INFO:root:frame =5889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =5890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000405073165894
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9860635
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root:frame =5893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =5894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.986054
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.99837761e+01]
 [  1.61564346e+02]
 [  2.82277441e+03]
 [  9.63398740e-02]
 [  2.21879780e-02]
 [  1.26993433e-01]
 [  2.65149146e+03]
 [  1.75543900e+02]
 [  9.44593847e-01]
 [  9.44593847e-01]
 [  2.56496131e-01]
 [  2.98468262e+02]
 [  7.41485535e+02]
 [  4.36933125e+04]
 [  5.72602173e+02]
 [  4.99345839e-01]]
DEBUG:root:training time = %d0.194563
INFO:root:frame =5897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =5898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.9860445
DEBUG:root: dqn, choose action rondomly, need time 0.000327999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:frame =5901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =5902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000592947006226
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.986035
DEBUG:root: dqn, choose action rondomly, need time 0.000243000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000187873840332
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.84656572e+00]
 [  4.93784130e-01]
 [  1.74071274e+02]
 [  4.06089878e+00]
 [  5.91086060e+02]
 [  1.60725731e-02]
 [  1.00616333e+02]
 [  1.05301666e+01]
 [  3.93511938e+03]
 [  1.57128479e+03]
 [  1.10934222e+00]
 [  1.55123186e+01]
 [  1.25060143e+02]
 [  3.01225525e+02]
 [  1.60725731e-02]
 [  2.11980469e+03]]
DEBUG:root:training time = %d0.212782
INFO:root:frame =5905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:frame =5906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00041389465332
DEBUG:root: save sample needs time = 0.000162124633789
INFO:root:random_action_porb = 0.9860255
DEBUG:root: dqn, choose action rondomly, need time 0.000194999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000176906585693
INFO:root:frame =5909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000476121902466
INFO:root:frame =5910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000329971313477
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.986016
DEBUG:root: dqn, choose action rondomly, need time 0.00039799999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.68999988e+03]
 [  5.39728760e+02]
 [  1.94220734e+00]
 [  1.45026481e+00]
 [  9.33637466e+01]
 [  1.11847717e+03]
 [  1.20883574e+04]
 [  1.13798132e+01]
 [  7.67395401e+01]
 [  1.61362305e+02]
 [  1.61362305e+02]
 [  5.38449526e+00]
 [  1.97728378e+02]
 [  1.25938080e+02]
 [  1.36791046e+02]
 [  2.77811193e+00]]
DEBUG:root:training time = %d0.214201
INFO:root:frame =5913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =5914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000334024429321
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.9860065
DEBUG:root: dqn, choose action rondomly, need time 0.000227999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:frame =5917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =5918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000507116317749
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:random_action_porb = 0.985997
DEBUG:root: dqn, choose action rondomly, need time 0.000248999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.54295502e+02]
 [  3.54295502e+02]
 [  1.17330009e+02]
 [  2.44863091e+01]
 [  1.88641174e+03]
 [  2.44863091e+01]
 [  2.31822643e+01]
 [  9.67395496e+00]
 [  2.58835889e+03]
 [  3.41299171e+01]
 [  9.48876572e+01]
 [  9.51820755e+00]
 [  1.00833417e+03]
 [  5.93608879e-02]
 [  9.15839462e+01]
 [  4.55723877e+03]]
DEBUG:root:training time = %d0.209615
INFO:root:frame =5921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =5922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000355958938599
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9859875
DEBUG:root: dqn, choose action rondomly, need time 0.000358000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000416040420532
INFO:root:frame =5925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =5926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root:random_action_porb = 0.985978
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999983
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.13006485e+02]
 [  2.36285801e+01]
 [  1.20233364e+01]
 [  3.64798004e+02]
 [  1.09304924e+01]
 [  7.75962400e+00]
 [  6.16203186e+02]
 [  2.90015006e+00]
 [  2.84294824e+03]
 [  1.33529587e+02]
 [  3.09119781e+02]
 [  1.07308906e-02]
 [  2.00750305e+03]
 [  1.26092725e+03]
 [  4.35862457e+02]
 [  1.29357971e+03]]
DEBUG:root:training time = %d0.204253
INFO:root:frame =5929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =5930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000386953353882
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:random_action_porb = 0.9859685
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000146865844727
INFO:root:frame =5933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470876693726
INFO:root:frame =5934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame = 5935 State into memory, numbers recorded 140 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000776052474976
INFO:root:random_action_porb = 0.985959
DEBUG:root: dqn, choose action rondomly, need time 0.000205000000022
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5936current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000566005706787
INFO:root:training error  = [[  2.34311676e+01]
 [  4.45870410e+03]
 [  3.15135620e+02]
 [  2.89885120e+01]
 [  9.54070740e+01]
 [  3.68860321e+01]
 [  7.06014328e+01]
 [  1.17717338e+00]
 [  1.48007111e+02]
 [  4.11458160e+02]
 [  9.05450134e+02]
 [  7.35047302e+02]
 [  3.80162964e+02]
 [  3.62542847e+02]
 [  9.54070740e+01]
 [  7.31301514e+02]]
DEBUG:root:training time = %d0.213808
INFO:root:frame =5937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =5938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488996505737
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.9859495
DEBUG:root: dqn, choose action rondomly, need time 0.000211000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000179767608643
INFO:root:frame =5941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000416040420532
INFO:root:frame =5942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame = 5943 State into memory, numbers recorded 141 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000546932220459
INFO:root:random_action_porb = 0.98594
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5944current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000304222106934
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.05107635e+02]
 [  3.05107635e+02]
 [  9.23851624e+02]
 [  1.05048047e+04]
 [  4.40314026e+01]
 [  2.69920593e+02]
 [  5.23151817e+01]
 [  7.32212891e+02]
 [  4.70878754e+01]
 [  3.54471802e+02]
 [  1.87065887e+01]
 [  1.66721992e+01]
 [  2.21940704e+02]
 [  5.89176055e+04]
 [  5.89176055e+04]
 [  2.38551074e+03]]
DEBUG:root:training time = %d0.222239
INFO:root:frame =5945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275850296021
INFO:root:frame =5946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233888626099
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9859305
DEBUG:root: dqn, choose action rondomly, need time 0.000163999999984
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:frame =5949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =5950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.985921
DEBUG:root: dqn, choose action rondomly, need time 0.000178000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000157117843628
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.18632436e+00]
 [  6.97373211e-01]
 [  3.67125916e+02]
 [  3.64431458e+02]
 [  3.67125916e+02]
 [  1.42235905e-02]
 [  1.30500822e+01]
 [  9.62713867e+03]
 [  1.80280298e+03]
 [  1.91148663e+01]
 [  1.79547775e+02]
 [  9.17389450e+01]
 [  2.65425586e+03]
 [  2.83520825e+03]
 [  8.30067062e+01]
 [  2.54493286e+03]]
DEBUG:root:training time = %d0.226859
INFO:root:frame =5953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =5954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
INFO:root:frame = 5955 State into memory, numbers recorded 142 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000597953796387
INFO:root:random_action_porb = 0.9859115
DEBUG:root: dqn, choose action rondomly, need time 0.00035699999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5956current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =5957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =5958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.985902
DEBUG:root: dqn, choose action rondomly, need time 0.000341999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.67048874e+01]
 [  1.19260222e-01]
 [  9.59206772e+01]
 [  1.44698517e+02]
 [  2.48024536e+02]
 [  8.45674438e+02]
 [  9.26384521e+02]
 [  5.75134621e+01]
 [  1.10712830e+03]
 [  1.43898788e+02]
 [  1.56160254e+03]
 [  4.23633514e+02]
 [  1.95236771e+02]
 [  5.28074913e+01]
 [  5.20425659e+02]
 [  3.47498016e+02]]
DEBUG:root:training time = %d0.202727
INFO:root:frame =5961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =5962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9858925
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =5965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =5966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045919418335
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.985883
DEBUG:root: dqn, choose action rondomly, need time 0.000368000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.46619034e+02]
 [  6.94935760e+01]
 [  1.32635971e+02]
 [  2.56848877e+03]
 [  9.84284592e+00]
 [  8.88831787e+01]
 [  1.19991133e+04]
 [  7.46284637e+01]
 [  2.92488270e+01]
 [  3.19659405e+01]
 [  5.36044846e+01]
 [  3.14672333e+02]
 [  9.76724625e+00]
 [  6.33213139e+00]
 [  8.61798401e+01]
 [  1.45247449e+03]]
DEBUG:root:training time = %d0.194134
INFO:root:frame =5969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281810760498
INFO:root:frame =5970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000576972961426
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:random_action_porb = 0.9858735
DEBUG:root: dqn, choose action rondomly, need time 0.000154000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:frame =5973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =5974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000451803207397
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.985864
DEBUG:root: dqn, choose action rondomly, need time 0.000194999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000362873077393
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.24522686e+00]
 [  1.02964691e+02]
 [  5.14113135e+03]
 [  1.69313126e+01]
 [  5.61428772e+02]
 [  1.69313126e+01]
 [  1.34925723e+00]
 [  1.83597927e+01]
 [  2.20522652e+01]
 [  3.49026807e+03]
 [  6.99096322e-02]
 [  4.57249784e+00]
 [  2.02217340e+00]
 [  3.61717041e+02]
 [  3.49026807e+03]
 [  3.72709912e+03]]
DEBUG:root:training time = %d0.212499
INFO:root:frame =5977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000217199325562
INFO:root:frame =5978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000392913818359
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root:random_action_porb = 0.9858545
DEBUG:root: dqn, choose action rondomly, need time 0.00032299999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =5981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =5982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000574827194214
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.985845
DEBUG:root: dqn, choose action rondomly, need time 0.00035299999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:training error  = [[  4.58692513e+01]
 [  1.04595222e+02]
 [  1.08185898e+02]
 [  3.04760315e+02]
 [  2.73120300e+02]
 [  8.49169350e+00]
 [  8.65277946e-02]
 [  1.25603706e+02]
 [  4.91767303e+02]
 [  1.33759623e+01]
 [  2.72870264e+03]
 [  6.58273499e+02]
 [  2.88814399e-03]
 [  1.51621570e+03]
 [  5.77867676e+03]
 [  5.13876495e+01]]
DEBUG:root:training time = %d0.209654
INFO:root:frame =5985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =5986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.9858355
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =5989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =5990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:random_action_porb = 0.985826
DEBUG:root: dqn, choose action rondomly, need time 0.000528000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:training error  = [[  3.83115112e+03]
 [  2.89851855e+03]
 [  8.68637268e+02]
 [  1.61368607e+02]
 [  8.78025284e+01]
 [  5.35899506e+01]
 [  4.68318701e+00]
 [  3.60648499e+01]
 [  7.32770935e+02]
 [  4.12103027e-01]
 [  5.04240379e+01]
 [  9.92666260e+02]
 [  3.83882965e+02]
 [  9.92666260e+02]
 [  4.12103027e-01]
 [  1.95729645e+02]]
DEBUG:root:training time = %d0.198233
INFO:root:frame =5993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =5994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9858165
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000023
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =5997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =5998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000633955001831
DEBUG:root: save sample needs time = 0.000202894210815
DEBUG:root:one frame running time = 0.00651500000001
DEBUG:root:total training time = 144.714654
INFO:root:frame num = 6000 frame round: 0
INFO:root:random_action_porb = 0.985807
DEBUG:root: dqn, choose action rondomly, need time 0.000358999999975
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[    3.20096302]
 [  568.76092529]
 [    7.12004709]
 [  121.15123749]
 [   22.57801247]
 [   56.39007568]
 [    7.12004709]
 [   66.06324005]
 [  199.22261047]
 [   22.57801247]
 [   62.28749084]
 [   20.92921829]
 [  700.36474609]
 [ 1185.55969238]
 [   16.92736816]
 [   22.97167206]]
DEBUG:root:training time = %d0.194922
INFO:root:frame =6001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =6002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.000108957290649
INFO:root:random_action_porb = 0.9857975
DEBUG:root: dqn, choose action rondomly, need time 0.000252999999987
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:frame =6005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:frame =6006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
DEBUG:root: save sample needs time = 0.000104904174805
INFO:root:random_action_porb = 0.985788
DEBUG:root: dqn, choose action rondomly, need time 0.000249999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.68719238e+02]
 [  2.67796539e+02]
 [  7.16067932e+02]
 [  2.16167526e+02]
 [  1.97424603e+01]
 [  1.29510641e+01]
 [  3.21920662e+01]
 [  1.61193237e+02]
 [  7.19853271e+02]
 [  1.03478523e+02]
 [  1.06350317e+03]
 [  2.95423169e+03]
 [  2.95423169e+03]
 [  1.75086487e+02]
 [  1.85714751e-01]
 [  1.11209211e+01]]
DEBUG:root:training time = %d0.211717
INFO:root:frame =6009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =6010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9857785
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =6013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:frame =6014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame = 6015 State into memory, numbers recorded 143 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000564098358154
INFO:root:random_action_porb = 0.985769
DEBUG:root: dqn, choose action rondomly, need time 0.000169999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6016current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  380.15673828]
 [   91.42371368]
 [  170.86508179]
 [   21.85499382]
 [  379.68725586]
 [ 2183.71557617]
 [   15.68262005]
 [  523.00805664]
 [    9.68801975]
 [  597.71783447]
 [   91.42371368]
 [  303.43069458]
 [  380.09423828]
 [  597.71783447]
 [  571.91888428]
 [   22.82840729]]
DEBUG:root:training time = %d0.210665
INFO:root:frame =6017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =6018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274896621704
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.9857595
INFO:root:dqn select action Tensor("ArgMax_13:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014398
INFO:root:action choosen by dqn [2]
INFO:root:frame =6020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000171899795532
INFO:root:frame =6021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =6022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:random_action_porb = 0.98575
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.01603516e+02]
 [  3.59930695e+02]
 [  1.08262777e+01]
 [  8.33922744e-01]
 [  2.54500000e+02]
 [  1.60230087e+02]
 [  5.67975426e+00]
 [  3.04148808e+01]
 [  3.97102905e+02]
 [  2.42843408e+03]
 [  5.09761133e+04]
 [  3.11620541e+01]
 [  3.40047121e-01]
 [  1.60230087e+02]
 [  2.07609253e+03]
 [  2.40305042e+00]]
DEBUG:root:training time = %d0.198656
INFO:root:frame =6025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:frame =6026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000161170959473
INFO:root:random_action_porb = 0.9857405
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =6029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000485181808472
INFO:root:frame =6030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000184059143066
INFO:root:random_action_porb = 0.985731
DEBUG:root: dqn, choose action rondomly, need time 0.000394999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.81375778e+02]
 [  4.42880936e+01]
 [  9.37725220e+02]
 [  1.94029391e+00]
 [  2.00486633e+02]
 [  5.93818604e+02]
 [  3.35800591e+01]
 [  1.90604571e-02]
 [  1.90604571e-02]
 [  5.90929980e+03]
 [  1.32927948e+02]
 [  6.16592264e+00]
 [  2.03166719e+04]
 [  1.25257730e+01]
 [  6.16269897e+02]
 [  7.98600245e+00]]
DEBUG:root:training time = %d0.20282
INFO:root:frame =6033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:frame =6034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9857215
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =6037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00053882598877
INFO:root:frame =6038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000467777252197
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.985712
DEBUG:root: dqn, choose action rondomly, need time 0.000403000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000367879867554
INFO:root:training error  = [[  1.00020752e+02]
 [  3.01725883e+01]
 [  2.43267609e+02]
 [  7.07923431e+01]
 [  1.98980606e+02]
 [  1.10904366e-01]
 [  2.71032043e+02]
 [  9.52729126e+02]
 [  3.33841562e+00]
 [  1.91667761e+03]
 [  8.35781174e+01]
 [  5.09242744e+01]
 [  6.66232178e+03]
 [  7.51393661e+01]
 [  1.17499565e+02]
 [  1.18607168e+01]]
DEBUG:root:training time = %d0.214224
INFO:root:frame =6041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:frame =6042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259160995483
DEBUG:root: save sample needs time = 9.58442687988e-05
INFO:root:random_action_porb = 0.9857025
DEBUG:root: dqn, choose action rondomly, need time 0.00016500000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000140190124512
INFO:root:frame =6045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =6046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 0.000181913375854
INFO:root:random_action_porb = 0.985693
DEBUG:root: dqn, choose action rondomly, need time 0.000379999999979
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   55.95640564]
 [  695.52954102]
 [  177.48297119]
 [  147.03790283]
 [    6.75383425]
 [   18.53214073]
 [ 4230.85693359]
 [    5.51156139]
 [   33.7283287 ]
 [  268.98983765]
 [  444.70492554]
 [  246.25350952]
 [  268.98983765]
 [   44.7458992 ]
 [  368.67138672]
 [ 1003.74182129]]
DEBUG:root:training time = %d0.21302
INFO:root:frame =6049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:frame =6050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.9856835
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =6053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =6054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470876693726
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.985674
DEBUG:root: dqn, choose action rondomly, need time 0.000293000000028
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  198.44142151]
 [   58.57453918]
 [   37.72920227]
 [   45.03905106]
 [ 1053.38110352]
 [  400.47912598]
 [   13.31182003]
 [   49.43501663]
 [   16.54561996]
 [  375.19522095]
 [   13.13111305]
 [  697.49395752]
 [ 1291.68432617]
 [  453.81607056]
 [  298.33288574]
 [  133.40222168]]
DEBUG:root:training time = %d0.209416
INFO:root:frame =6057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =6058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000291109085083
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9856645
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =6061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000519037246704
INFO:root:frame =6062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000258922576904
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.985655
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.59125328e+00]
 [  3.65457520e+02]
 [  4.51349640e+01]
 [  2.29278126e+01]
 [  1.06217102e+03]
 [  2.29331172e+04]
 [  1.29419365e+01]
 [  3.12690338e+02]
 [  6.20134544e+00]
 [  1.07089510e+01]
 [  1.14956343e+00]
 [  4.53195457e+01]
 [  3.95124664e+02]
 [  1.06932178e+03]
 [  2.28408837e+00]
 [  5.45101833e+00]]
DEBUG:root:training time = %d0.20415
INFO:root:frame =6065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame =6066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame = 6067 State into memory, numbers recorded 144 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root:random_action_porb = 0.9856455
DEBUG:root: dqn, choose action rondomly, need time 0.000343000000015
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6068current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =6069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =6070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491142272949
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.985636
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:training error  = [[  4.75638151e+00]
 [  6.21440247e+02]
 [  2.63550964e+02]
 [  2.63550964e+02]
 [  2.95497772e+02]
 [  3.17963409e+01]
 [  1.16319397e+03]
 [  1.25706505e+02]
 [  1.46101606e+00]
 [  6.21440247e+02]
 [  1.49498945e+04]
 [  2.08984680e+02]
 [  5.12225220e+02]
 [  6.56216699e+03]
 [  1.80680933e+03]
 [  1.23490097e+02]]
DEBUG:root:training time = %d0.197725
INFO:root:frame =6073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =6074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000301122665405
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.9856265
DEBUG:root: dqn, choose action rondomly, need time 0.000173000000018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:frame =6077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =6078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000184059143066
INFO:root:random_action_porb = 0.985617
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.51260010e+03]
 [  3.04024902e+02]
 [  4.81415606e+00]
 [  2.88987823e+02]
 [  1.15668859e+01]
 [  1.29212256e+03]
 [  5.38833847e+01]
 [  1.19510437e+03]
 [  5.11891327e+02]
 [  2.78785187e+02]
 [  1.14949180e+04]
 [  1.83854294e+02]
 [  7.72568130e+00]
 [  1.26379517e+03]
 [  1.19510437e+03]
 [  4.70654480e+02]]
DEBUG:root:training time = %d0.208746
INFO:root:frame =6081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:frame =6082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 9.51290130615e-05
INFO:root:random_action_porb = 0.9856075
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =6085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000576019287109
INFO:root:frame =6086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:frame = 6087 State into memory, numbers recorded 145 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.00056004524231
INFO:root:random_action_porb = 0.985598
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000015
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6088current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.07381697e+01]
 [  1.66318506e-01]
 [  1.85483902e+02]
 [  1.33276355e+03]
 [  1.59332781e+01]
 [  3.85909106e+03]
 [  3.43650317e+00]
 [  9.34275806e-01]
 [  1.83560410e+02]
 [  6.40374805e+03]
 [  1.13909431e+02]
 [  1.66149429e+02]
 [  1.51385535e+03]
 [  1.52467728e+02]
 [  2.65430698e+01]
 [  1.52348375e+01]]
DEBUG:root:training time = %d0.197765
INFO:root:frame =6089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:frame =6090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00033712387085
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.9855885
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:frame =6093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =6094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000509023666382
INFO:root:random_action_porb = 0.985579
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.67911987e+01]
 [  5.72847070e+03]
 [  1.93703479e+03]
 [  1.26569214e+02]
 [  3.90048236e-01]
 [  2.93783760e+00]
 [  1.74731469e+00]
 [  6.17036858e+01]
 [  1.40324615e+02]
 [  1.12929214e+02]
 [  3.56255859e+03]
 [  6.64926624e+00]
 [  4.47715479e+03]
 [  5.19917755e+01]
 [  3.36685693e+03]
 [  3.59330719e+02]]
DEBUG:root:training time = %d0.20069
INFO:root:frame =6097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =6098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9855695
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000393152236938
INFO:root:frame =6101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =6102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.98556
DEBUG:root: dqn, choose action rondomly, need time 0.000225999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.48974304e+01]
 [  8.07252319e+02]
 [  7.42539444e+01]
 [  1.04596024e+01]
 [  4.07181152e+02]
 [  3.60788965e+00]
 [  2.42868137e+01]
 [  2.45108124e+02]
 [  2.54929688e+03]
 [  1.04596024e+01]
 [  2.54929688e+03]
 [  1.04639578e+01]
 [  4.44823669e+02]
 [  5.49219666e+02]
 [  1.02944179e-02]
 [  4.00363556e+02]]
DEBUG:root:training time = %d0.206209
INFO:root:frame =6105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:frame =6106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9855505
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =6109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =6110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.985541
DEBUG:root: dqn, choose action rondomly, need time 0.000191999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:training error  = [[  1.71488452e+00]
 [  1.80282116e+01]
 [  2.65945312e+03]
 [  6.47435303e+03]
 [  1.06946448e+03]
 [  1.72790742e+00]
 [  5.20694214e+02]
 [  9.30884933e+00]
 [  2.96950316e+00]
 [  7.14019318e+01]
 [  2.96950316e+00]
 [  4.90829200e-01]
 [  4.06528503e+02]
 [  6.05275488e+03]
 [  2.14196686e+02]
 [  2.65945312e+03]]
DEBUG:root:training time = %d0.200875
INFO:root:frame =6113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =6114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9855315
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =6117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =6118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.985522
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.79514648e+04]
 [  6.82684784e+01]
 [  1.15060510e+03]
 [  2.83623779e+02]
 [  6.35163696e+02]
 [  2.06792435e+02]
 [  1.53164215e+01]
 [  5.66351776e+01]
 [  4.74008904e+01]
 [  3.31277370e+00]
 [  3.21411230e+03]
 [  8.71394592e+02]
 [  6.28789902e+00]
 [  3.87448517e+02]
 [  6.82266092e+00]
 [  8.71394592e+02]]
DEBUG:root:training time = %d0.213839
INFO:root:frame =6121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:frame =6122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494956970215
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9855125
DEBUG:root: dqn, choose action rondomly, need time 0.000274999999988
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325202941895
INFO:root:frame =6125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =6126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485181808472
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.985503
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.10410652e+01]
 [  4.70186829e+02]
 [  5.71421242e+00]
 [  4.10410652e+01]
 [  1.36150574e+02]
 [  5.03252777e+02]
 [  2.48434906e+01]
 [  4.24438238e-01]
 [  1.83642641e-01]
 [  4.24438238e-01]
 [  9.07797318e+01]
 [  7.42451050e+02]
 [  8.21159744e+01]
 [  1.77857685e+00]
 [  1.43212549e+03]
 [  5.13259773e+01]]
DEBUG:root:training time = %d0.204218
INFO:root:frame =6129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000260829925537
INFO:root:frame =6130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:random_action_porb = 0.9854935
DEBUG:root: dqn, choose action rondomly, need time 0.00032299999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =6133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464200973511
INFO:root:frame =6134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00056791305542
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.985484
DEBUG:root: dqn, choose action rondomly, need time 0.000184000000019
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.03110413e+03]
 [  1.32086334e+02]
 [  1.99453711e+03]
 [  3.42444244e+02]
 [  6.70124463e+03]
 [  1.02577858e+02]
 [  5.94043579e+02]
 [  4.33396072e+01]
 [  1.39851303e+02]
 [  3.87487274e+02]
 [  4.33562088e+01]
 [  7.10536146e+00]
 [  3.53382492e+01]
 [  9.52929445e-03]
 [  1.39851303e+02]
 [  6.70124463e+03]]
DEBUG:root:training time = %d0.202802
INFO:root:frame =6137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:frame =6138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9854745
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =6142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.985465
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.92193260e+01]
 [  8.16628784e+02]
 [  1.40929382e+02]
 [  6.58099518e+01]
 [  7.90634918e+01]
 [  7.33718109e+01]
 [  2.50900650e+00]
 [  5.10706024e+01]
 [  4.67312927e+01]
 [  3.75044928e-03]
 [  5.50494957e+01]
 [  1.91784992e+01]
 [  3.55049477e+01]
 [  2.50900650e+00]
 [  3.55049477e+01]
 [  2.05383392e+02]]
DEBUG:root:training time = %d0.218354
INFO:root:frame =6145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:frame =6146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000108003616333
INFO:root:random_action_porb = 0.9854555
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =6150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000515937805176
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:random_action_porb = 0.985446
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999982
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   27.9545536 ]
 [  258.04605103]
 [   25.76153755]
 [  537.60443115]
 [  115.68099976]
 [  418.17352295]
 [  278.37945557]
 [    9.01786137]
 [  248.77774048]
 [   22.90589905]
 [  204.05097961]
 [   22.90589905]
 [ 1620.33520508]
 [  258.04605103]
 [   13.97223663]
 [    9.26790237]]
DEBUG:root:training time = %d0.191672
INFO:root:frame =6153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249147415161
INFO:root:frame =6154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274896621704
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9854365
DEBUG:root: dqn, choose action rondomly, need time 0.000161999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:frame =6157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =6158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame = 6159 State into memory, numbers recorded 146 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000543117523193
INFO:root:random_action_porb = 0.985427
DEBUG:root: dqn, choose action rondomly, need time 0.000188000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6160current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.03419421e+03]
 [  2.26800232e+01]
 [  2.72201440e+03]
 [  8.44992554e+02]
 [  2.26800232e+01]
 [  7.77327442e+00]
 [  7.29855537e+00]
 [  4.63454773e+02]
 [  3.51414490e+01]
 [  1.80809215e-01]
 [  4.96618881e+01]
 [  8.41652405e+02]
 [  5.03090881e+02]
 [  2.16576019e+02]
 [  6.00123711e+01]
 [  2.82796812e+00]]
DEBUG:root:training time = %d0.192095
INFO:root:frame =6161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =6162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9854175
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294208526611
INFO:root:frame =6165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470876693726
INFO:root:frame =6166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.985408
DEBUG:root: dqn, choose action rondomly, need time 0.00029600000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.47346924e+02]
 [  8.40371013e-01]
 [  2.79698560e+03]
 [  7.59093463e-02]
 [  5.00990295e+00]
 [  2.05117246e+04]
 [  6.04871887e+02]
 [  1.32361023e+03]
 [  3.71565674e+02]
 [  8.47346924e+02]
 [  1.79948334e+02]
 [  1.23229103e+02]
 [  5.75762701e+00]
 [  1.85142303e+02]
 [  2.20397614e+02]
 [  1.32361023e+03]]
DEBUG:root:training time = %d0.208481
INFO:root:frame =6169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =6170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000373840332031
DEBUG:root: save sample needs time = 0.000191211700439
INFO:root:random_action_porb = 0.9853985
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029182434082
INFO:root:frame =6173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000481843948364
INFO:root:frame =6174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.985389
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.58689362e+02]
 [  1.19881458e+03]
 [  3.70604801e+00]
 [  1.79812439e+02]
 [  3.92829018e+01]
 [  2.39814774e+02]
 [  1.85572235e+02]
 [  1.03745801e+03]
 [  1.40418213e+02]
 [  2.79096565e+01]
 [  3.04599457e+02]
 [  1.12184029e+01]
 [  1.94938367e+03]
 [  2.02706268e+02]
 [  1.44697511e+00]
 [  2.03988972e+01]]
DEBUG:root:training time = %d0.206473
INFO:root:frame =6177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =6178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9853795
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:frame =6181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =6182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.98537
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.33031738e+02]
 [  4.59890430e+04]
 [  1.51583130e+03]
 [  1.29887466e+02]
 [  8.74962463e+01]
 [  5.05267212e+02]
 [  1.14918266e+02]
 [  6.59082794e+00]
 [  1.57892723e+01]
 [  4.69207802e+01]
 [  4.70434357e+02]
 [  7.77894402e+00]
 [  1.47967621e+02]
 [  2.24746132e+01]
 [  2.18551546e-01]
 [  7.90807312e+02]]
DEBUG:root:training time = %d0.192114
INFO:root:frame =6185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =6186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame = 6187 State into memory, numbers recorded 147 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000607013702393
INFO:root:random_action_porb = 0.9853605
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6188current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =6189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000451803207397
INFO:root:frame =6190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.985351
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.99932404e+02]
 [  6.63541794e+01]
 [  1.25545914e+02]
 [  1.10907361e+03]
 [  4.38219607e-01]
 [  8.30850296e+01]
 [  3.25073838e+00]
 [  1.06302041e+04]
 [  3.99932404e+02]
 [  2.43327065e+01]
 [  1.44119186e+02]
 [  1.72162598e+02]
 [  3.65873242e+03]
 [  3.27929955e+01]
 [  1.47424423e+02]
 [  6.77332044e-01]]
DEBUG:root:training time = %d0.201355
INFO:root:frame =6193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =6194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000339031219482
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.9853415
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =6198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239849090576
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.985332
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000018
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[    51.30297089]
 [   174.78616333]
 [   155.6661377 ]
 [   984.77746582]
 [   146.24200439]
 [  1765.17297363]
 [   252.16001892]
 [   195.81195068]
 [   984.77746582]
 [  4000.65698242]
 [    46.96398544]
 [ 14463.62597656]
 [   111.3575058 ]
 [   808.54040527]
 [  2901.14550781]
 [   193.5499115 ]]
DEBUG:root:training time = %d0.202919
INFO:root:frame =6201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =6202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9853225
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =6205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =6206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame = 6207 State into memory, numbers recorded 148 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000643968582153
INFO:root:random_action_porb = 0.985313
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6208current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.54039047e+02]
 [  5.48848267e+02]
 [  9.01966629e+01]
 [  2.22969385e+03]
 [  2.81042358e+02]
 [  5.48848267e+02]
 [  4.14974136e+01]
 [  1.07344473e-02]
 [  1.72486115e+01]
 [  2.54039047e+02]
 [  9.55829086e+01]
 [  4.68046532e+01]
 [  1.05995646e+01]
 [  9.78789139e+01]
 [  1.43893665e+03]
 [  1.07344473e-02]]
DEBUG:root:training time = %d0.212628
INFO:root:frame =6209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =6210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9853035
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999981
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =6213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =6214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.985294
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:training error  = [[  2.49634613e+02]
 [  1.96854785e+03]
 [  2.30315918e+04]
 [  2.49634613e+02]
 [  3.77294846e+01]
 [  3.77294846e+01]
 [  8.95921143e+02]
 [  2.23551733e+03]
 [  1.31043091e+01]
 [  2.15364899e+02]
 [  2.56917896e+03]
 [  2.30315918e+04]
 [  5.26014465e+02]
 [  9.67970047e+01]
 [  5.86123238e+01]
 [  9.14558530e-01]]
DEBUG:root:training time = %d0.203752
INFO:root:frame =6217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255823135376
INFO:root:frame =6218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.9852845
INFO:root:dqn select action Tensor("ArgMax_14:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00982199999999
INFO:root:action choosen by dqn [2]
INFO:root:frame =6220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000346183776855
INFO:root:frame =6221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000514984130859
INFO:root:frame =6222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.985275
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000015
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.77360678e+00]
 [  2.92817657e+02]
 [  1.53951697e+03]
 [  1.11428688e+02]
 [  9.87238342e+02]
 [  1.02715797e+02]
 [  7.54458847e+01]
 [  1.59666794e+02]
 [  2.79758484e+02]
 [  2.96149139e+02]
 [  1.37564697e+02]
 [  4.70573700e+02]
 [  2.56997070e+02]
 [  2.76804047e+01]
 [  6.08540952e-01]
 [  3.46584082e+03]]
DEBUG:root:training time = %d0.210504
INFO:root:frame =6225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =6226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9852655
DEBUG:root: dqn, choose action rondomly, need time 0.000376000000017
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =6229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =6230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.985256
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   64.62505341]
 [ 2062.28173828]
 [  727.20153809]
 [  630.07617188]
 [   49.38356018]
 [ 1982.68603516]
 [   31.04970932]
 [ 2442.75561523]
 [   21.51469421]
 [   34.6486969 ]
 [   62.37495041]
 [  203.51235962]
 [    2.5891118 ]
 [  144.29055786]
 [   47.28707886]
 [  846.63751221]]
DEBUG:root:training time = %d0.235995
INFO:root:frame =6233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =6234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000502109527588
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9852465
DEBUG:root: dqn, choose action rondomly, need time 0.000275999999985
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =6237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =6238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000537872314453
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.985237
DEBUG:root: dqn, choose action rondomly, need time 0.000186000000014
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000150918960571
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.71272949e+02]
 [  3.82770660e+02]
 [  6.15923218e+02]
 [  4.32842773e+03]
 [  7.82475433e+01]
 [  1.31491165e+01]
 [  6.32990456e+00]
 [  6.63929565e+02]
 [  2.41526016e+02]
 [  4.18679382e+02]
 [  4.71353722e+01]
 [  2.76773363e-01]
 [  2.13221484e+03]
 [  6.54079712e+02]
 [  2.87832832e+01]
 [  4.52412750e+02]]
DEBUG:root:training time = %d0.200682
INFO:root:frame =6241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =6242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233888626099
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9852275
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999983
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =6245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =6246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.985218
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.62535667e+01]
 [  1.10443146e+02]
 [  2.79146504e+04]
 [  2.56964783e+02]
 [  4.77420360e-01]
 [  7.64954285e+02]
 [  1.23405623e+00]
 [  4.49918671e+01]
 [  4.27784979e-01]
 [  2.12294617e+02]
 [  2.12294617e+02]
 [  5.05529213e+01]
 [  2.21178482e+02]
 [  5.49131279e+01]
 [  3.99749786e+02]
 [  1.00042725e+00]]
DEBUG:root:training time = %d0.207709
INFO:root:frame =6249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =6250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000238180160522
DEBUG:root: save sample needs time = 9.58442687988e-05
INFO:root:random_action_porb = 0.9852085
DEBUG:root: dqn, choose action rondomly, need time 0.000377999999984
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =6253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =6254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000306844711304
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.985199
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:training error  = [[  2.00004810e+03]
 [  1.44205797e+00]
 [  6.96554718e+01]
 [  2.36132629e+02]
 [  3.46260840e+03]
 [  3.58993103e+02]
 [  4.55410538e+01]
 [  5.56079979e+01]
 [  5.55448074e+01]
 [  8.97448181e+02]
 [  3.55570641e+01]
 [  1.06776413e+02]
 [  3.69547814e-01]
 [  6.62184998e+02]
 [  3.33891749e+00]
 [  1.57531421e+03]]
DEBUG:root:training time = %d0.214282
INFO:root:frame =6257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:frame =6258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000242948532104
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:random_action_porb = 0.9851895
DEBUG:root: dqn, choose action rondomly, need time 0.00029600000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =6261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000501871109009
INFO:root:frame =6262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:random_action_porb = 0.98518
DEBUG:root: dqn, choose action rondomly, need time 0.000380000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000511884689331
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.52068436e+02]
 [  1.05640450e+01]
 [  2.57010956e+02]
 [  4.12039943e-02]
 [  1.85286401e+03]
 [  4.26040993e+01]
 [  2.76771545e+01]
 [  1.62238733e+03]
 [  1.03338269e+03]
 [  4.46048553e+02]
 [  1.77805725e+02]
 [  9.24387970e+01]
 [  1.54632874e+01]
 [  2.57010956e+02]
 [  1.57496933e+02]
 [  4.26040993e+01]]
DEBUG:root:training time = %d0.203404
INFO:root:frame =6265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:frame =6266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9851705
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =6269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =6270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame = 6271 State into memory, numbers recorded 149 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:random_action_porb = 0.985161
DEBUG:root: dqn, choose action rondomly, need time 0.000195999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6272current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000188112258911
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.13796265e+02]
 [  7.02327957e+01]
 [  4.22550195e+03]
 [  1.01461756e+00]
 [  4.92024841e+02]
 [  1.56298208e+01]
 [  7.00013199e+01]
 [  6.82087158e+02]
 [  2.88845947e+02]
 [  4.92024841e+02]
 [  2.24190497e+00]
 [  4.89324951e+03]
 [  1.76055069e+02]
 [  1.46936218e+03]
 [  6.07712841e+00]
 [  1.94871816e+04]]
DEBUG:root:training time = %d0.186644
INFO:root:frame =6273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002281665802
INFO:root:frame =6274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000270843505859
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9851515
DEBUG:root: dqn, choose action rondomly, need time 0.000571000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =6277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000550031661987
INFO:root:frame =6278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.985142
DEBUG:root: dqn, choose action rondomly, need time 0.000176999999979
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.28052483e+01]
 [  8.29803181e+00]
 [  1.10597525e+01]
 [  1.84552097e+00]
 [  6.70155762e+02]
 [  1.47532303e+02]
 [  1.10597525e+01]
 [  4.58140808e+02]
 [  6.82093811e+02]
 [  1.84552097e+00]
 [  2.64477661e+03]
 [  1.58937897e+02]
 [  3.73981018e+02]
 [  1.50664587e+01]
 [  2.82297516e+02]
 [  3.03853440e+00]]
DEBUG:root:training time = %d0.191676
INFO:root:frame =6281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =6282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000254154205322
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.9851325
DEBUG:root: dqn, choose action rondomly, need time 0.000275000000016
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =6285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =6286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.985123
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.41397324e+01]
 [  1.19551802e+01]
 [  1.65626685e+03]
 [  3.48872284e+02]
 [  1.58833122e+00]
 [  1.68429919e+03]
 [  3.54331665e+02]
 [  7.46978455e+01]
 [  2.88188229e+01]
 [  1.02890350e+02]
 [  5.03724992e-01]
 [  2.50361347e+00]
 [  9.81617554e+02]
 [  2.57748077e+02]
 [  7.25233521e+02]
 [  1.65626685e+03]]
DEBUG:root:training time = %d0.196773
INFO:root:frame =6289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =6290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000310897827148
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9851135
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =6293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =6294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:random_action_porb = 0.985104
DEBUG:root: dqn, choose action rondomly, need time 0.000212000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.06846962e+01]
 [  1.92280598e+01]
 [  2.08580460e+02]
 [  1.49164905e+03]
 [  7.64856006e+03]
 [  1.11151868e+03]
 [  7.04799414e-01]
 [  2.21140121e+02]
 [  1.83677998e+01]
 [  1.46081467e+01]
 [  6.91219091e+00]
 [  1.83677998e+01]
 [  4.30446191e+03]
 [  1.47923584e+02]
 [  2.85768681e+01]
 [  1.76460004e+00]]
DEBUG:root:training time = %d0.199799
INFO:root:frame =6297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =6298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298976898193
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.9850945
DEBUG:root: dqn, choose action rondomly, need time 0.000277000000011
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =6301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000841856002808
INFO:root:frame =6302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000345945358276
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root:random_action_porb = 0.985085
DEBUG:root: dqn, choose action rondomly, need time 0.000206999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.44204216e+01]
 [  3.43239838e+02]
 [  2.17754402e+01]
 [  2.97383545e+02]
 [  4.36444366e+02]
 [  5.29885803e+02]
 [  8.47327271e+02]
 [  2.85421715e+01]
 [  1.88856522e+02]
 [  3.18375993e+00]
 [  3.43239838e+02]
 [  6.11264551e+03]
 [  2.09087158e+02]
 [  5.17368793e+00]
 [  3.44204216e+01]
 [  1.02461824e+01]]
DEBUG:root:training time = %d0.199041
INFO:root:frame =6305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =6306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000334024429321
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:random_action_porb = 0.9850755
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000166177749634
INFO:root:frame =6309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =6310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.985066
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.90388703e-01]
 [  2.00926602e+04]
 [  3.45372986e+02]
 [  1.00043634e+03]
 [  6.00084019e+00]
 [  5.52402039e+02]
 [  2.17036182e+03]
 [  6.00084019e+00]
 [  2.22181732e+02]
 [  4.54968872e+01]
 [  4.63689026e+02]
 [  1.33201447e+01]
 [  2.97654934e+01]
 [  4.47533643e+03]
 [  7.82307434e+01]
 [  1.64503291e-01]]
DEBUG:root:training time = %d0.189895
INFO:root:frame =6313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =6314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame = 6315 State into memory, numbers recorded 150 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000407934188843
INFO:root:random_action_porb = 0.9850565
DEBUG:root: dqn, choose action rondomly, need time 0.000162000000017
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6316current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000142812728882
INFO:root:frame =6317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000424861907959
INFO:root:frame =6318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249147415161
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.985047
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.21869714e+03]
 [  1.64852524e+01]
 [  3.43710417e-06]
 [  1.17725867e+03]
 [  7.16329803e+01]
 [  3.17525482e+02]
 [  5.35237488e+02]
 [  2.88532349e+02]
 [  5.79142570e+01]
 [  2.54244556e+01]
 [  3.66157379e+01]
 [  2.21868027e+02]
 [  4.03641052e+02]
 [  1.55933914e+02]
 [  1.24319296e+01]
 [  4.23424877e-03]]
DEBUG:root:training time = %d0.207267
INFO:root:frame =6321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =6322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.9850375
DEBUG:root: dqn, choose action rondomly, need time 0.00029600000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =6325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000424861907959
INFO:root:frame =6326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000638008117676
DEBUG:root: save sample needs time = 0.000145196914673
INFO:root:random_action_porb = 0.985028
DEBUG:root: dqn, choose action rondomly, need time 0.000472000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.60265827e+00]
 [  1.00132952e+01]
 [  5.13143372e+02]
 [  1.35631982e+03]
 [  2.09193652e+03]
 [  1.66356623e-01]
 [  1.59224991e+02]
 [  4.04746875e+03]
 [  1.68242664e+03]
 [  5.41511475e+03]
 [  2.59234762e+00]
 [  1.18456189e+03]
 [  4.95117041e+03]
 [  3.98622971e+01]
 [  5.74435107e+03]
 [  3.89825171e+03]]
DEBUG:root:training time = %d0.207116
INFO:root:frame =6329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =6330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000345945358276
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.9850185
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000500917434692
INFO:root:frame =6334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:random_action_porb = 0.985009
DEBUG:root: dqn, choose action rondomly, need time 0.000358000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.58702344e+03]
 [  1.41782677e+00]
 [  3.47353369e-01]
 [  2.92896265e+03]
 [  1.18606003e+02]
 [  8.99270447e+02]
 [  2.13306812e+03]
 [  1.81357010e+02]
 [  1.59085229e+03]
 [  1.03512054e+02]
 [  8.75731812e+02]
 [  2.01426331e+02]
 [  3.47353369e-01]
 [  9.39922256e+01]
 [  9.58144592e+02]
 [  4.09007645e+01]]
DEBUG:root:training time = %d0.222087
INFO:root:frame =6337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =6338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:random_action_porb = 0.9849995
DEBUG:root: dqn, choose action rondomly, need time 0.000563999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =6341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =6342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:random_action_porb = 0.98499
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000011
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.72399426e+00]
 [  1.60304919e+03]
 [  1.16107822e+04]
 [  5.89203110e+01]
 [  1.46264050e+03]
 [  1.97135339e+03]
 [  4.63705111e+00]
 [  1.94346216e-02]
 [  5.02339569e+02]
 [  1.08475578e+02]
 [  2.92220630e+03]
 [  2.15792188e+03]
 [  1.08475578e+02]
 [  1.46264050e+03]
 [  4.82287140e+02]
 [  9.87658844e+01]]
DEBUG:root:training time = %d0.198588
INFO:root:frame =6345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:frame =6346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.9849805
DEBUG:root: dqn, choose action rondomly, need time 0.000174000000015
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000155925750732
INFO:root:frame =6349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000556945800781
INFO:root:frame =6350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000495910644531
INFO:root:frame = 6351 State into memory, numbers recorded 151 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000579118728638
INFO:root:random_action_porb = 0.984971
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6352current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:training error  = [[  6.99078552e+02]
 [  6.99078552e+02]
 [  5.41392273e+02]
 [  9.67312622e+01]
 [  8.38144684e+00]
 [  5.31349907e+01]
 [  2.71226501e+02]
 [  5.51437378e+02]
 [  2.10005808e+00]
 [  2.37761045e+00]
 [  9.43761841e+02]
 [  2.50739883e+02]
 [  3.40319023e+01]
 [  2.36200000e+03]
 [  5.51437378e+02]
 [  6.99078552e+02]]
DEBUG:root:training time = %d0.232097
INFO:root:frame =6353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =6354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000242948532104
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:random_action_porb = 0.9849615
DEBUG:root: dqn, choose action rondomly, need time 0.000218999999987
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =6357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =6358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:random_action_porb = 0.984952
DEBUG:root: dqn, choose action rondomly, need time 0.000222000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000206232070923
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.71112000e+02]
 [  1.67892857e+01]
 [  1.24090369e+03]
 [  6.36469910e+02]
 [  1.29724609e+02]
 [  4.98994303e+00]
 [  3.31631243e-01]
 [  1.43161869e+00]
 [  1.06207344e+02]
 [  3.49331932e+01]
 [  1.39419098e+01]
 [  1.91822872e+01]
 [  2.90084381e+01]
 [  6.19212830e+02]
 [  3.14684319e+00]
 [  6.89639425e+00]]
DEBUG:root:training time = %d0.194823
INFO:root:frame =6361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =6362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298023223877
DEBUG:root: save sample needs time = 0.000104188919067
INFO:root:random_action_porb = 0.9849425
DEBUG:root: dqn, choose action rondomly, need time 0.000237999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000136852264404
INFO:root:frame =6365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248193740845
INFO:root:frame =6366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000253915786743
DEBUG:root: save sample needs time = 0.000103950500488
INFO:root:random_action_porb = 0.984933
INFO:root:dqn select action Tensor("ArgMax_15:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01216
INFO:root:action choosen by dqn [2]
INFO:root:frame =6368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.68151703e+01]
 [  2.84102305e+04]
 [  4.38059273e+01]
 [  9.89516602e+01]
 [  7.39786606e+01]
 [  4.81447840e+00]
 [  9.31061840e+00]
 [  1.41344604e+01]
 [  7.07154083e+00]
 [  8.00399876e+00]
 [  1.49755335e+01]
 [  1.90236511e+02]
 [  1.70379852e+02]
 [  2.22090796e+03]
 [  2.63091236e-01]
 [  1.00935478e+01]]
DEBUG:root:training time = %d0.196469
INFO:root:frame =6369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =6370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239849090576
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.9849235
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =6373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =6374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000451803207397
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.984914
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000373125076294
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.32939968e+01]
 [  3.60076904e+02]
 [  2.41869420e-01]
 [  9.12745483e+02]
 [  1.90785789e+00]
 [  7.77930786e+02]
 [  3.60076904e+02]
 [  2.97936378e-03]
 [  6.17651367e+02]
 [  1.95990341e+02]
 [  2.80215515e+02]
 [  4.43168304e+02]
 [  1.21619941e+04]
 [  2.83304100e+01]
 [  1.75969818e+02]
 [  1.34505981e+02]]
DEBUG:root:training time = %d0.217325
INFO:root:frame =6377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =6378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226020812988
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:random_action_porb = 0.9849045
DEBUG:root: dqn, choose action rondomly, need time 0.000279000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =6381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000411033630371
INFO:root:frame =6382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000584125518799
INFO:root:frame = 6383 State into memory, numbers recorded 152 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000566959381104
INFO:root:random_action_porb = 0.984895
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6384current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.96963882e+01]
 [  3.17821289e+02]
 [  2.18921997e+02]
 [  3.10137630e-01]
 [  6.90049667e+01]
 [  7.10540222e+02]
 [  1.17568283e+01]
 [  6.90276566e+01]
 [  3.50059223e+00]
 [  3.49890790e-04]
 [  9.13380371e+02]
 [  2.49243423e+02]
 [  8.51748085e+00]
 [  4.30877924e+00]
 [  2.19569473e+02]
 [  8.51187256e+02]]
DEBUG:root:training time = %d0.225496
INFO:root:frame =6385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =6386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.9848855
INFO:root:dqn select action Tensor("ArgMax_16:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010849
INFO:root:action choosen by dqn [2]
INFO:root:frame =6388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:frame =6389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245809555054
INFO:root:frame =6390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame = 6391 State into memory, numbers recorded 153 action = [2], reward = 0
DEBUG:root: save sample needs time = 0.0012149810791
INFO:root:random_action_porb = 0.984876
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6392current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:training error  = [[  7.26198578e+01]
 [  1.46995651e+02]
 [  2.80999725e+02]
 [  1.54654179e+01]
 [  1.64564266e+01]
 [  6.21643005e+02]
 [  9.01983582e+02]
 [  7.41926880e+01]
 [  1.14086592e+04]
 [  1.91947365e+01]
 [  5.46658897e+00]
 [  3.49885082e+00]
 [  1.46995651e+02]
 [  1.64564266e+01]
 [  1.31080414e+02]
 [  3.20218239e+01]]
DEBUG:root:training time = %d0.19729
INFO:root:frame =6393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =6394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000110149383545
INFO:root:random_action_porb = 0.9848665
DEBUG:root: dqn, choose action rondomly, need time 0.000179000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =6397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =6398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame = 6399 State into memory, numbers recorded 154 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:random_action_porb = 0.984857
DEBUG:root: dqn, choose action rondomly, need time 0.000170999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6400current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.37767849e+01]
 [  8.11846497e+02]
 [  1.97798718e+03]
 [  2.20165234e+01]
 [  8.94333496e+01]
 [  2.98277974e-01]
 [  9.77690063e+02]
 [  1.25921230e+01]
 [  2.36650062e+00]
 [  1.07047305e+04]
 [  2.40602100e+03]
 [  2.85455155e+00]
 [  3.74758667e+02]
 [  9.68875793e+02]
 [  2.19172333e+02]
 [  5.01560638e+02]]
DEBUG:root:training time = %d0.211308
INFO:root:frame =6401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =6402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9848475
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =6405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =6406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.984838
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:training error  = [[  1.89138584e+01]
 [  7.06719360e+02]
 [  1.89138584e+01]
 [  4.35323620e+00]
 [  3.52294502e+01]
 [  1.32779646e+01]
 [  1.85053406e+03]
 [  5.83637595e-01]
 [  4.34836769e+01]
 [  1.83668747e+02]
 [  3.92539001e+02]
 [  3.17777300e+00]
 [  5.76115189e+01]
 [  3.58991802e-01]
 [  1.65776062e+03]
 [  5.94197510e+02]]
DEBUG:root:training time = %d0.206443
INFO:root:frame =6409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =6410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.9848285
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =6413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =6414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:random_action_porb = 0.984819
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.02098980e+01]
 [  4.41892548e+02]
 [  4.13323259e+00]
 [  1.06988274e+02]
 [  1.07632139e+04]
 [  3.23896751e+01]
 [  1.16226099e+03]
 [  3.28105316e+02]
 [  5.89894371e+01]
 [  3.21876488e+01]
 [  1.77990742e+01]
 [  1.12307007e+03]
 [  2.10789928e+01]
 [  2.41185059e+03]
 [  1.48264709e+03]
 [  7.70550370e-02]]
DEBUG:root:training time = %d0.209784
INFO:root:frame =6417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =6418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame = 6419 State into memory, numbers recorded 155 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000569105148315
INFO:root:random_action_porb = 0.9848095
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6420current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =6421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000492811203003
INFO:root:frame =6422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9848
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   54.31637955]
 [    1.71929336]
 [  145.84977722]
 [  116.92962646]
 [   33.71578979]
 [  993.10668945]
 [ 1469.32824707]
 [    1.71929336]
 [  492.5411377 ]
 [  187.99105835]
 [  574.59075928]
 [   25.01251411]
 [   14.28008652]
 [  126.38343811]
 [   71.38246155]
 [   22.08032608]]
DEBUG:root:training time = %d0.211306
INFO:root:frame =6425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =6426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.9847905
DEBUG:root: dqn, choose action rondomly, need time 0.000202000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:frame =6429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =6430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00023889541626
DEBUG:root: save sample needs time = 9.29832458496e-05
INFO:root:random_action_porb = 0.984781
DEBUG:root: dqn, choose action rondomly, need time 0.000173999999987
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.19233848e+04]
 [  5.55055481e+02]
 [  1.23753528e+03]
 [  3.33258575e+02]
 [  2.91414004e+04]
 [  1.66456396e+03]
 [  7.22905350e+01]
 [  3.78540344e+01]
 [  3.90403786e+01]
 [  8.87082863e+00]
 [  6.68002427e-01]
 [  4.81923340e+03]
 [  2.81404510e+02]
 [  7.87501343e+02]
 [  1.30393356e+02]
 [  2.44154968e+01]]
DEBUG:root:training time = %d0.219707
INFO:root:frame =6433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:frame =6434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000295162200928
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9847715
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000015
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =6437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000625848770142
INFO:root:frame =6438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.984762
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.95741669e+02]
 [  1.63308871e+00]
 [  1.07955054e+03]
 [  2.71672760e+02]
 [  1.17006885e+03]
 [  1.67014099e+02]
 [  1.38543955e+04]
 [  2.73950708e+03]
 [  3.15149724e-02]
 [  1.51386547e+01]
 [  3.56051373e+00]
 [  8.40024185e+01]
 [  7.75668762e+02]
 [  6.01764030e+01]
 [  4.42647934e-02]
 [  1.91677979e+02]]
DEBUG:root:training time = %d0.193889
INFO:root:frame =6441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:frame =6442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000261068344116
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.9847525
DEBUG:root: dqn, choose action rondomly, need time 0.000171000000023
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:frame =6445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =6446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.984743
DEBUG:root: dqn, choose action rondomly, need time 0.000308999999987
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000384092330933
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.16861328e+03]
 [  8.45808899e+02]
 [  1.64388977e+02]
 [  6.72278259e+02]
 [  1.00977535e+01]
 [  1.86368362e+02]
 [  1.82206133e+04]
 [  2.94237976e+02]
 [  2.16628342e+01]
 [  2.24846094e+03]
 [  1.57242157e+02]
 [  7.24150085e+01]
 [  2.12355080e+01]
 [  8.96922363e+02]
 [  2.16628342e+01]
 [  3.17362270e+01]]
DEBUG:root:training time = %d0.215864
INFO:root:frame =6449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =6450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.9847335
DEBUG:root: dqn, choose action rondomly, need time 0.000435999999979
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =6453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =6454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.984724
DEBUG:root: dqn, choose action rondomly, need time 0.000683000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.29205490e+02]
 [  7.10479279e+01]
 [  2.87918925e+00]
 [  4.62080078e+02]
 [  2.51907120e+02]
 [  1.89538956e+01]
 [  9.57970657e+01]
 [  4.93098946e+01]
 [  1.33013000e+01]
 [  1.29205490e+02]
 [  3.75809082e+02]
 [  2.15523243e+00]
 [  1.13989905e+03]
 [  7.56270325e+02]
 [  3.45014191e+01]
 [  2.55106986e-01]]
DEBUG:root:training time = %d0.203922
INFO:root:frame =6457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =6458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9847145
DEBUG:root: dqn, choose action rondomly, need time 0.000202999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:frame =6461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491142272949
INFO:root:frame =6462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.984705
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.59222485e+03]
 [  4.97395554e+01]
 [  9.99582520e+03]
 [  1.26037407e+01]
 [  6.57181025e-01]
 [  3.93314911e+02]
 [  1.31753845e+01]
 [  6.17414761e+00]
 [  1.63240623e+00]
 [  8.83314705e+00]
 [  1.26037407e+01]
 [  2.95456052e+00]
 [  8.84119263e+01]
 [  2.95456052e+00]
 [  8.63112305e+03]
 [  8.84119263e+01]]
DEBUG:root:training time = %d0.210656
INFO:root:frame =6465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =6466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000242948532104
DEBUG:root: save sample needs time = 0.000106811523438
INFO:root:random_action_porb = 0.9846955
DEBUG:root: dqn, choose action rondomly, need time 0.000191999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =6469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =6470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:random_action_porb = 0.984686
DEBUG:root: dqn, choose action rondomly, need time 0.000168000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.29837744e+03]
 [  9.20148611e-01]
 [  2.93254913e+02]
 [  1.89344883e+04]
 [  8.95499390e+02]
 [  3.38783455e+01]
 [  6.78560543e+00]
 [  5.99196960e+02]
 [  3.91925697e+01]
 [  4.24717426e+00]
 [  2.31848328e+02]
 [  9.13110046e+01]
 [  1.11136414e+03]
 [  3.38783455e+01]
 [  7.74636917e+01]
 [  9.75561365e-02]]
DEBUG:root:training time = %d0.194863
INFO:root:frame =6473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =6474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000392913818359
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9846765
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =6477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000618934631348
INFO:root:frame =6478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000307083129883
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.984667
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.48452441e+03]
 [  1.45282242e+02]
 [  4.35564972e+02]
 [  3.95294228e+01]
 [  9.41777897e+00]
 [  3.69739676e+00]
 [  1.47594360e+02]
 [  9.41777897e+00]
 [  3.06580811e+01]
 [  2.38476730e+02]
 [  5.34222350e-02]
 [  1.04632301e+01]
 [  2.46531006e+03]
 [  1.44036938e+03]
 [  3.71013451e+01]
 [  2.46531006e+03]]
DEBUG:root:training time = %d0.199776
INFO:root:frame =6481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =6482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.9846575
DEBUG:root: dqn, choose action rondomly, need time 0.000247000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =6485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =6486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247001647949
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.984648
DEBUG:root: dqn, choose action rondomly, need time 0.000189000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000158071517944
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.82440338e+01]
 [  7.82440338e+01]
 [  7.54583418e-01]
 [  2.53100439e+03]
 [  1.30069067e+03]
 [  7.55633057e+02]
 [  4.64010498e+03]
 [  1.46073578e+02]
 [  2.80771088e+02]
 [  1.30069067e+03]
 [  7.55633057e+02]
 [  7.84581177e+02]
 [  4.71960297e+02]
 [  8.04477811e-01]
 [  7.55321472e+02]
 [  9.78905201e+00]]
DEBUG:root:training time = %d0.217555
INFO:root:frame =6489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:frame =6490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240087509155
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9846385
DEBUG:root: dqn, choose action rondomly, need time 0.000235000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000249147415161
INFO:root:frame =6493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =6494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.984629
DEBUG:root: dqn, choose action rondomly, need time 0.000448000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.46886444e+02]
 [  3.74759857e+02]
 [  8.81884217e-01]
 [  6.12458611e+01]
 [  2.06544785e+02]
 [  8.72372437e+01]
 [  2.32650049e+03]
 [  4.65222510e+03]
 [  7.45932678e+02]
 [  1.40963440e+02]
 [  8.72372437e+01]
 [  2.32650049e+03]
 [  1.76020618e+03]
 [  6.48305588e+01]
 [  4.30111742e+00]
 [  7.15796204e+02]]
DEBUG:root:training time = %d0.209143
INFO:root:frame =6497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:frame =6498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274896621704
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.9846195
DEBUG:root: dqn, choose action rondomly, need time 0.000163999999984
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:frame =6501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =6502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000496864318848
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.98461
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   4.34402418]
 [ 161.49151611]
 [ 433.40441895]
 [  17.4446373 ]
 [ 246.08569336]
 [  86.65034485]
 [   4.48833227]
 [ 458.18411255]
 [ 161.49151611]
 [ 324.36087036]
 [ 141.37576294]
 [   4.48833227]
 [  38.22856903]
 [  47.4930954 ]
 [   0.48963264]
 [  10.6445713 ]]
DEBUG:root:training time = %d0.205096
INFO:root:frame =6505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:frame =6506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.9846005
INFO:root:dqn select action Tensor("ArgMax_17:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012963
INFO:root:action choosen by dqn [2]
INFO:root:frame =6508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:frame =6509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =6510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.984591
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.70090027e+02]
 [  2.54986279e+03]
 [  1.10096886e+02]
 [  9.00103455e+02]
 [  8.90288818e+02]
 [  6.05974388e+00]
 [  3.91786499e+01]
 [  3.12893127e+02]
 [  1.47833967e+00]
 [  1.55716406e+03]
 [  1.39890108e+01]
 [  1.09366370e+03]
 [  1.60614120e+02]
 [  6.57489502e+02]
 [  5.98437134e+02]
 [  1.62204147e+02]]
DEBUG:root:training time = %d0.196136
INFO:root:frame =6513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =6514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000211954116821
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9845815
DEBUG:root: dqn, choose action rondomly, need time 0.000326999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000356912612915
INFO:root:frame =6517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000370025634766
INFO:root:frame =6518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame = 6519 State into memory, numbers recorded 156 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000598907470703
INFO:root:random_action_porb = 0.984572
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6520current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000336170196533
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.35264124e+03]
 [  4.61203480e+00]
 [  3.58168457e+02]
 [  3.42516235e+02]
 [  2.44713882e+02]
 [  1.27481117e+01]
 [  6.13781982e+02]
 [  9.77659512e+00]
 [  1.59729087e+00]
 [  2.41157417e+01]
 [  2.51503540e+03]
 [  1.29917252e+00]
 [  2.89909229e+03]
 [  1.35264124e+03]
 [  1.09385704e+02]
 [  1.54102123e+00]]
DEBUG:root:training time = %d0.214842
INFO:root:frame =6521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =6522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000618934631348
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:random_action_porb = 0.9845625
DEBUG:root: dqn, choose action rondomly, need time 0.000557000000015
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame =6525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =6526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.984553
DEBUG:root: dqn, choose action rondomly, need time 0.000331999999986
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.69847336e+01]
 [  4.09416618e+01]
 [  2.61684180e+03]
 [  1.29043889e+00]
 [  1.16795902e+01]
 [  2.54186940e+00]
 [  1.86823521e+01]
 [  1.71940283e+03]
 [  7.39229858e+02]
 [  1.51484528e+02]
 [  3.07866573e+01]
 [  1.09271126e+01]
 [  3.00236938e+02]
 [  6.55318909e+02]
 [  2.34537766e+02]
 [  4.15553617e+00]]
DEBUG:root:training time = %d0.204665
INFO:root:frame =6529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:frame =6530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00022292137146
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.9845435
DEBUG:root: dqn, choose action rondomly, need time 0.000161999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:frame =6533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000585079193115
INFO:root:frame =6534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000334024429321
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.984534
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999983
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029182434082
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.83888916e+02]
 [  2.31505409e-02]
 [  5.23666525e-03]
 [  3.40424061e+00]
 [  1.18668205e+02]
 [  5.27819901e+01]
 [  2.42831146e+02]
 [  5.16381149e+01]
 [  1.33412313e+01]
 [  8.91715336e+00]
 [  4.88807583e+00]
 [  1.21156592e+03]
 [  9.40467224e+02]
 [  1.37824310e+02]
 [  1.60869336e+03]
 [  1.74014854e+01]]
DEBUG:root:training time = %d0.213686
INFO:root:frame =6537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =6538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9845245
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =6541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =6542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.984515
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   666.68383789]
 [   283.15960693]
 [    41.25184631]
 [    75.80760956]
 [   524.55090332]
 [   390.5847168 ]
 [    35.0033493 ]
 [   312.15386963]
 [ 13847.62207031]
 [  9838.484375  ]
 [   382.17739868]
 [   468.85751343]
 [   301.77185059]
 [    41.25184631]
 [  1526.56921387]
 [  3439.38598633]]
DEBUG:root:training time = %d0.202034
INFO:root:frame =6545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:frame =6546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame = 6547 State into memory, numbers recorded 157 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000597953796387
INFO:root:random_action_porb = 0.9845055
DEBUG:root: dqn, choose action rondomly, need time 0.00017299999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6548current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =6549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =6550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00055193901062
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.984496
DEBUG:root: dqn, choose action rondomly, need time 0.000326999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.32861900e+00]
 [  2.88533192e+01]
 [  1.37843103e+01]
 [  1.71890303e-01]
 [  7.93759033e+03]
 [  8.54629517e+01]
 [  6.75744400e+01]
 [  1.76731873e+01]
 [  1.68552844e+03]
 [  1.42359514e+01]
 [  3.22522644e+02]
 [  3.72617065e+02]
 [  5.31604652e+01]
 [  5.13063706e-02]
 [  6.45856857e+01]
 [  1.65765127e-03]]
DEBUG:root:training time = %d0.198938
INFO:root:frame =6553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000351905822754
INFO:root:frame =6554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.9844865
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =6557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =6558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.984477
DEBUG:root: dqn, choose action rondomly, need time 0.00029600000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.50916840e+02]
 [  9.16259348e-01]
 [  4.51548975e+03]
 [  4.28445637e-02]
 [  4.17051880e+02]
 [  6.73136673e+01]
 [  4.28445637e-02]
 [  5.71168335e+02]
 [  4.76092725e+03]
 [  1.66426270e+03]
 [  3.24820020e+03]
 [  1.13610268e+02]
 [  2.09327954e+03]
 [  1.22863960e+01]
 [  1.03300183e+03]
 [  3.24820020e+03]]
DEBUG:root:training time = %d0.216982
INFO:root:frame =6561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =6562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241041183472
DEBUG:root: save sample needs time = 0.000108957290649
INFO:root:random_action_porb = 0.9844675
DEBUG:root: dqn, choose action rondomly, need time 0.000356000000011
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:frame =6565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281810760498
INFO:root:frame =6566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240802764893
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.984458
DEBUG:root: dqn, choose action rondomly, need time 0.000170999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000141143798828
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.52425499e+01]
 [  3.91357178e+02]
 [  2.55226183e+00]
 [  3.77050257e+00]
 [  3.74764709e+02]
 [  2.62076321e+01]
 [  5.01553965e+00]
 [  1.17762814e+01]
 [  2.48840809e+00]
 [  1.24040766e+01]
 [  6.84020901e+00]
 [  3.67006874e+01]
 [  4.38733406e+01]
 [  1.13067637e+04]
 [  1.01605115e+03]
 [  3.80466644e+02]]
DEBUG:root:training time = %d0.194797
INFO:root:frame =6569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =6570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000224113464355
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9844485
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =6573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =6574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000222206115723
INFO:root:random_action_porb = 0.984439
DEBUG:root: dqn, choose action rondomly, need time 0.000182999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000145196914673
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.65014771e+02]
 [  1.49771576e+01]
 [  2.86657544e+03]
 [  1.37333708e+01]
 [  9.35183108e-01]
 [  8.65627197e+02]
 [  3.82256317e+02]
 [  1.77436417e+02]
 [  1.10915417e+03]
 [  5.83571191e+03]
 [  1.20017250e+02]
 [  9.61140919e+00]
 [  1.86048298e+01]
 [  4.19351387e+01]
 [  9.53893860e+02]
 [  2.86657544e+03]]
DEBUG:root:training time = %d0.207547
INFO:root:frame =6577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:frame =6578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.9844295
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =6582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.98442
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.47622070e+01]
 [  2.81008410e+00]
 [  1.09265907e+02]
 [  2.76073122e+00]
 [  1.34880457e+01]
 [  3.43621445e+01]
 [  1.90779572e+01]
 [  3.23049278e+01]
 [  3.75018311e+03]
 [  3.51572510e+02]
 [  2.44775940e+02]
 [  1.95276172e+03]
 [  3.51572510e+02]
 [  9.44008160e+00]
 [  2.50571766e+01]
 [  3.65589691e+02]]
DEBUG:root:training time = %d0.194284
INFO:root:frame =6585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =6586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265836715698
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.9844105
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =6589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000475168228149
INFO:root:frame =6590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.984401
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338792800903
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.03410339e+01]
 [  2.33259697e+01]
 [  1.98217880e+02]
 [  2.22269196e+02]
 [  2.92258358e+00]
 [  2.49728470e+01]
 [  1.07171982e+02]
 [  1.23719621e+00]
 [  5.61025238e+01]
 [  7.58556396e+02]
 [  6.59309769e+01]
 [  7.58556396e+02]
 [  3.31012459e+01]
 [  2.43206006e+03]
 [  2.29120801e+04]
 [  2.48888946e+00]]
DEBUG:root:training time = %d0.199981
INFO:root:frame =6593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:frame =6594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000406980514526
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9843915
DEBUG:root: dqn, choose action rondomly, need time 0.000211000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000182151794434
INFO:root:frame =6597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000849962234497
INFO:root:frame =6598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471830368042
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.984382
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.42201977e+01]
 [  1.62778914e+00]
 [  3.87550011e+01]
 [  2.84458350e+03]
 [  8.30183220e+00]
 [  9.21939514e+02]
 [  1.88930944e-01]
 [  1.11970483e+03]
 [  9.94585254e+03]
 [  2.15611830e-01]
 [  6.40738892e+02]
 [  5.58525658e+01]
 [  4.11874609e+03]
 [  1.57783340e+02]
 [  5.64943027e+00]
 [  3.92182129e+02]]
DEBUG:root:training time = %d0.216959
INFO:root:frame =6601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:frame =6602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame = 6603 State into memory, numbers recorded 158 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000588893890381
INFO:root:random_action_porb = 0.9843725
DEBUG:root: dqn, choose action rondomly, need time 0.00055500000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6604current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =6605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000407934188843
INFO:root:frame =6606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:random_action_porb = 0.984363
DEBUG:root: dqn, choose action rondomly, need time 0.000187000000011
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   0.89037681]
 [ 130.32289124]
 [ 788.06237793]
 [ 105.46433258]
 [  74.91521454]
 [  27.00078583]
 [ 120.230896  ]
 [  89.36777496]
 [   6.12426758]
 [   2.51332259]
 [ 368.96133423]
 [  12.23518467]
 [  30.7989769 ]
 [   6.531497  ]
 [ 105.46433258]
 [ 880.65197754]]
DEBUG:root:training time = %d0.214917
INFO:root:frame =6609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =6610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
DEBUG:root: save sample needs time = 0.00010085105896
INFO:root:random_action_porb = 0.9843535
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =6613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456809997559
INFO:root:frame =6614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294923782349
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.984344
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999981
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:training error  = [[  2.29051895e+02]
 [  4.40141010e+00]
 [  5.24724243e+02]
 [  1.77356040e+00]
 [  8.32588745e+02]
 [  3.44633240e+02]
 [  3.44633240e+02]
 [  2.62929320e+00]
 [  3.47130310e+02]
 [  1.30436920e+02]
 [  2.71901917e+00]
 [  1.49590775e+02]
 [  1.07518448e+02]
 [  1.91714691e+02]
 [  4.95748145e+03]
 [  1.04148417e+01]]
DEBUG:root:training time = %d0.202463
INFO:root:frame =6617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =6618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:random_action_porb = 0.9843345
DEBUG:root: dqn, choose action rondomly, need time 0.000308999999987
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =6621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =6622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486135482788
INFO:root:frame = 6623 State into memory, numbers recorded 159 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000562191009521
INFO:root:random_action_porb = 0.984325
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6624current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.05508709e+00]
 [  2.38540009e+02]
 [  3.06993027e+01]
 [  1.34541455e+04]
 [  2.23631323e+03]
 [  4.02133472e+03]
 [  1.68539333e+01]
 [  2.61637509e-01]
 [  3.20301080e+00]
 [  3.98082695e+01]
 [  1.52446301e+03]
 [  3.45224118e+00]
 [  7.42513721e+03]
 [  1.02713032e+01]
 [  1.09405835e+03]
 [  1.14069042e+01]]
DEBUG:root:training time = %d0.201151
INFO:root:frame =6625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:frame =6626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259160995483
INFO:root:frame = 6627 State into memory, numbers recorded 160 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000428915023804
INFO:root:random_action_porb = 0.9843155
DEBUG:root: dqn, choose action rondomly, need time 0.000192999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6628current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =6629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =6630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame = 6631 State into memory, numbers recorded 161 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000749111175537
INFO:root:random_action_porb = 0.984306
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999986
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6632current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   36.23374557]
 [   85.13480377]
 [   47.84152985]
 [   49.47646332]
 [   19.93048668]
 [  100.78660583]
 [  330.19140625]
 [  821.94213867]
 [   28.85612679]
 [    3.6084404 ]
 [ 1320.94970703]
 [ 2170.41088867]
 [   46.23132706]
 [   85.13480377]
 [ 1257.40454102]
 [   10.42762375]]
DEBUG:root:training time = %d0.228356
INFO:root:frame =6633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =6634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239133834839
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9842965
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =6637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =6638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.984287
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:training error  = [[  3.56045761e+01]
 [  4.17436028e+00]
 [  1.79443314e+02]
 [  4.99421143e+02]
 [  1.52158981e+02]
 [  4.61094952e+00]
 [  1.84209839e+03]
 [  3.04798393e+01]
 [  9.19534668e+02]
 [  1.44391382e+00]
 [  3.38110016e+02]
 [  8.46072510e+02]
 [  6.13953430e+02]
 [  6.05312309e+01]
 [  5.11364651e+00]
 [  1.44391382e+00]]
DEBUG:root:training time = %d0.193307
INFO:root:frame =6641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =6642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9842775
DEBUG:root: dqn, choose action rondomly, need time 0.000326999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =6645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =6646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.984268
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.33802031e+04]
 [  4.17631358e-01]
 [  5.62756470e+02]
 [  1.07031345e+01]
 [  1.16204095e+00]
 [  1.16204095e+00]
 [  2.41360149e+01]
 [  8.61924500e+02]
 [  2.10777321e+01]
 [  1.15666523e+04]
 [  4.03082085e+00]
 [  1.30250659e+03]
 [  2.39856885e+03]
 [  4.13382507e+02]
 [  3.89349731e+03]
 [  5.62756470e+02]]
DEBUG:root:training time = %d0.212979
INFO:root:frame =6649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000276803970337
INFO:root:frame =6650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9842585
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =6653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =6654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.984249
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.00731926e+02]
 [  4.58223633e+02]
 [  1.15565739e+01]
 [  9.77764511e+00]
 [  9.71280060e+01]
 [  3.81278366e-01]
 [  1.91797302e+02]
 [  5.20396385e+01]
 [  4.36684753e+02]
 [  2.68522797e+02]
 [  7.47296021e+02]
 [  3.28402233e+00]
 [  9.50381012e+01]
 [  3.23681412e+01]
 [  6.68782227e+02]
 [  7.71019745e+01]]
DEBUG:root:training time = %d0.216589
INFO:root:frame =6657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =6658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.9842395
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =6661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =6662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.98423
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.77261353e+01]
 [  1.83170957e+04]
 [  6.33190584e+00]
 [  8.76191044e+00]
 [  4.66975021e+01]
 [  8.37151051e+00]
 [  5.24424410e+00]
 [  2.43324432e+01]
 [  1.37107015e+00]
 [  1.92798309e+02]
 [  1.64508438e+02]
 [  3.65664363e+00]
 [  3.24184227e+01]
 [  8.85498941e-01]
 [  6.25177765e+01]
 [  2.02664352e+02]]
DEBUG:root:training time = %d0.204395
INFO:root:frame =6665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =6666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9842205
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =6669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =6670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.984211
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.28341246e+00]
 [  3.98557401e+00]
 [  1.00501947e-01]
 [  3.60341614e+02]
 [  8.88401222e+00]
 [  5.26391113e+02]
 [  2.09084595e+03]
 [  1.31415359e+02]
 [  1.00501947e-01]
 [  1.95007229e+01]
 [  4.65257683e+01]
 [  1.15826306e+03]
 [  1.31496983e+01]
 [  5.36633873e+00]
 [  5.26874695e+02]
 [  3.11346321e+01]]
DEBUG:root:training time = %d0.215392
INFO:root:frame =6673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249147415161
INFO:root:frame =6674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000349998474121
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9842015
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000018
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =6677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =6678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.984192
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000018
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.33669519e+00]
 [  5.89269876e-01]
 [  2.38842430e+01]
 [  6.78966797e+02]
 [  6.48816757e+01]
 [  4.49765930e+01]
 [  1.24671814e+02]
 [  8.16927795e+02]
 [  3.54429665e+01]
 [  1.24671814e+02]
 [  7.33669519e+00]
 [  4.36880722e+01]
 [  9.71100586e+02]
 [  6.05320978e+00]
 [  6.62240067e+01]
 [  2.78209424e+00]]
DEBUG:root:training time = %d0.197111
INFO:root:frame =6681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =6682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265836715698
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9841825
DEBUG:root: dqn, choose action rondomly, need time 0.000294000000025
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =6685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =6686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486135482788
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.984173
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.24382252e-01]
 [  3.58170748e+00]
 [  3.69641930e-04]
 [  1.70137939e+02]
 [  5.16309052e+01]
 [  8.01980667e+01]
 [  6.70182666e+03]
 [  1.01686508e+02]
 [  4.42910919e+01]
 [  8.50320605e+03]
 [  4.23431816e+01]
 [  1.09623885e+00]
 [  2.25157397e+03]
 [  1.12365949e+00]
 [  1.69160730e+03]
 [  1.92955397e-02]]
DEBUG:root:training time = %d0.213936
INFO:root:frame =6689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000194072723389
INFO:root:frame =6690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000633955001831
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.9841635
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =6693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =6694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271797180176
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.984154
DEBUG:root: dqn, choose action rondomly, need time 0.000318000000021
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000356912612915
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.20035667e+01]
 [  2.17418098e+01]
 [  3.92379022e+00]
 [  1.14348503e+02]
 [  2.49699116e+01]
 [  1.72288656e+00]
 [  1.45541453e+00]
 [  8.67318652e+03]
 [  3.85036865e+02]
 [  3.88891244e+00]
 [  5.46287918e+00]
 [  8.18724243e+02]
 [  4.04672861e+00]
 [  6.15066109e+01]
 [  5.34816399e+01]
 [  7.43641052e+02]]
DEBUG:root:training time = %d0.209775
INFO:root:frame =6697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:frame =6698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.9841445
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =6702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240087509155
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.984135
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.60681519e+02]
 [  4.48152580e+01]
 [  3.17809849e+01]
 [  2.18835156e+03]
 [  1.00513067e+01]
 [  6.45761353e+02]
 [  4.09064233e+03]
 [  3.15803585e+01]
 [  4.22434131e+03]
 [  1.27146820e+02]
 [  3.15805602e+00]
 [  6.67523575e+01]
 [  9.75757904e+01]
 [  2.54177017e+02]
 [  9.10025323e-04]
 [  4.54808617e+01]]
DEBUG:root:training time = %d0.202382
INFO:root:frame =6705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =6706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239849090576
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.9841255
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =6709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =6710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.984116
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000015
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.75788879e+01]
 [  3.90003723e+02]
 [  1.46330298e+03]
 [  1.14436707e+03]
 [  7.25543365e+01]
 [  6.18020386e+02]
 [  5.57284451e+00]
 [  1.51920975e+02]
 [  5.10256982e+03]
 [  3.29937671e+03]
 [  1.09077141e+02]
 [  6.70510254e+01]
 [  1.51920975e+02]
 [  1.85941470e+00]
 [  3.95046272e+01]
 [  6.49384165e+00]]
DEBUG:root:training time = %d0.203616
INFO:root:frame =6713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =6714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9841065
DEBUG:root: dqn, choose action rondomly, need time 0.000308999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =6717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =6718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.984097
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331163406372
INFO:root:training error  = [[  2.14157251e+03]
 [  1.28220306e+02]
 [  2.50314209e+02]
 [  7.91639832e+02]
 [  8.58602905e+01]
 [  2.76721172e+01]
 [  2.60017757e+01]
 [  2.89543579e+02]
 [  2.00374878e+03]
 [  5.30768156e+00]
 [  2.60017757e+01]
 [  1.23355981e+03]
 [  2.26250519e+02]
 [  1.64774609e+00]
 [  5.14882263e+02]
 [  8.58602905e+01]]
DEBUG:root:training time = %d0.21462
INFO:root:frame =6721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =6722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240087509155
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9840875
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =6725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000602960586548
INFO:root:frame =6726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288963317871
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.984078
DEBUG:root: dqn, choose action rondomly, need time 0.000450999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.34005920e+02]
 [  6.62300354e+02]
 [  8.54679932e+02]
 [  8.71924973e+01]
 [  6.78590012e+01]
 [  3.33426285e+00]
 [  5.19801880e+02]
 [  2.52122712e+00]
 [  4.59268127e+02]
 [  2.18718853e+01]
 [  2.99730591e+02]
 [  1.22997154e+02]
 [  6.34005920e+02]
 [  8.43081951e+00]
 [  2.43024960e+01]
 [  5.26309766e+03]]
DEBUG:root:training time = %d0.204826
INFO:root:frame =6729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =6730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame = 6731 State into memory, numbers recorded 162 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.00084400177002
INFO:root:random_action_porb = 0.9840685
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6732current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =6733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =6734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000678777694702
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:random_action_porb = 0.984059
DEBUG:root: dqn, choose action rondomly, need time 0.000500999999986
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185012817383
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.17282331e+00]
 [  1.57496924e+03]
 [  9.97868061e+00]
 [  1.44030166e+00]
 [  2.19358355e-01]
 [  3.12934570e+02]
 [  2.49013729e+01]
 [  2.43720093e+03]
 [  1.14999988e+03]
 [  2.29735596e+03]
 [  2.43720093e+03]
 [  1.82048599e+02]
 [  1.65462631e+02]
 [  3.58226967e+01]
 [  4.53633156e+01]
 [  3.27422729e+02]]
DEBUG:root:training time = %d0.212404
INFO:root:frame =6737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =6738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000541925430298
DEBUG:root: save sample needs time = 0.000206232070923
INFO:root:random_action_porb = 0.9840495
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =6741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000411987304688
INFO:root:frame =6742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470876693726
INFO:root:frame = 6743 State into memory, numbers recorded 163 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000612020492554
INFO:root:random_action_porb = 0.98404
DEBUG:root: dqn, choose action rondomly, need time 0.000369000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6744current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000176191329956
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.47959534e+02]
 [  2.08311672e+01]
 [  3.20306320e+01]
 [  1.37400636e-02]
 [  1.45826370e+02]
 [  1.05649866e+03]
 [  5.38154175e+02]
 [  2.31785183e+01]
 [  1.37657425e+02]
 [  2.19225000e+03]
 [  6.28133659e+01]
 [  1.20976162e+00]
 [  2.44682145e+00]
 [  1.07977772e-04]
 [  1.07977772e-04]
 [  1.70186111e+02]]
DEBUG:root:training time = %d0.200292
INFO:root:frame =6745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =6746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229835510254
DEBUG:root: save sample needs time = 0.000215768814087
INFO:root:random_action_porb = 0.9840305
DEBUG:root: dqn, choose action rondomly, need time 0.00039799999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =6749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000509977340698
INFO:root:frame =6750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.984021
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000358819961548
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.83643103e+03]
 [  6.56551895e+01]
 [  5.20816504e+03]
 [  8.27222839e+02]
 [  2.50704697e+02]
 [  4.15538666e+02]
 [  1.14583260e+02]
 [  3.60408440e+01]
 [  7.81180878e+01]
 [  6.04589111e+02]
 [  2.77811069e+01]
 [  1.08655037e+02]
 [  2.42473068e+02]
 [  4.00671673e+00]
 [  2.91107821e+00]
 [  1.14583260e+02]]
DEBUG:root:training time = %d0.207342
INFO:root:frame =6753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =6754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000385046005249
DEBUG:root: save sample needs time = 0.000155925750732
INFO:root:random_action_porb = 0.9840115
DEBUG:root: dqn, choose action rondomly, need time 0.000334000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000494956970215
INFO:root:frame =6758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.984002
DEBUG:root: dqn, choose action rondomly, need time 0.000317999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.74831543e+01]
 [  1.13366961e+00]
 [  3.61860704e+00]
 [  6.08333683e+00]
 [  8.29684830e+01]
 [  4.77858009e+01]
 [  9.67637539e+00]
 [  1.01813736e+01]
 [  1.52712002e+04]
 [  1.98721970e+02]
 [  8.68086670e+02]
 [  9.69452286e+01]
 [  7.62427551e+02]
 [  6.74831543e+01]
 [  2.04959736e+01]
 [  5.90179176e+01]]
DEBUG:root:training time = %d0.19546
INFO:root:frame =6761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:frame =6762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame = 6763 State into memory, numbers recorded 164 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000550031661987
INFO:root:random_action_porb = 0.9839925
DEBUG:root: dqn, choose action rondomly, need time 0.000157000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6764current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000178098678589
INFO:root:frame =6765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame =6766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000490188598633
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:random_action_porb = 0.983983
DEBUG:root: dqn, choose action rondomly, need time 0.000331999999986
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.97754383e+00]
 [  5.33876801e+00]
 [  1.44499316e+04]
 [  8.15692616e+00]
 [  9.82345764e+02]
 [  7.85708191e+02]
 [  4.43355408e+01]
 [  9.28191280e+00]
 [  9.40235547e+03]
 [  9.05464840e+00]
 [  9.82345764e+02]
 [  2.99712009e+01]
 [  1.19682148e-01]
 [  7.25093856e-02]
 [  1.79324677e+02]
 [  4.14447461e+03]]
DEBUG:root:training time = %d0.202679
INFO:root:frame =6769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:frame =6770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002281665802
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.9839735
DEBUG:root: dqn, choose action rondomly, need time 0.000176999999979
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:frame =6773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =6774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.983964
DEBUG:root: dqn, choose action rondomly, need time 0.000556999999986
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.73922791e+02]
 [  2.75090289e+00]
 [  2.75090289e+00]
 [  8.87667847e+01]
 [  2.20472831e-02]
 [  2.20472831e-02]
 [  9.89919662e+01]
 [  1.56162750e+02]
 [  1.95991573e+01]
 [  1.95939417e+03]
 [  8.52285995e+01]
 [  3.25955820e+00]
 [  2.18288403e+01]
 [  2.82278562e+00]
 [  5.98374817e+02]
 [  8.15405026e-02]]
DEBUG:root:training time = %d0.222038
INFO:root:frame =6777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =6778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9839545
DEBUG:root: dqn, choose action rondomly, need time 0.000781000000018
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =6781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000523805618286
INFO:root:frame =6782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000404119491577
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.983945
DEBUG:root: dqn, choose action rondomly, need time 0.000357000000008
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000391960144043
INFO:root:training error  = [[  1.73940750e+02]
 [  7.26610840e+03]
 [  1.15666359e+02]
 [  4.17716179e+01]
 [  2.43840759e+02]
 [  8.88746977e-02]
 [  5.31378860e+01]
 [  5.31378860e+01]
 [  9.48632908e+00]
 [  1.43598389e+03]
 [  8.88746977e-02]
 [  2.64383087e+02]
 [  7.96232700e-01]
 [  8.52634125e+01]
 [  5.76795675e-02]
 [  1.46006201e+03]]
DEBUG:root:training time = %d0.190463
INFO:root:frame =6785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =6786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.9839355
DEBUG:root: dqn, choose action rondomly, need time 0.000369000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000495195388794
INFO:root:frame =6790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.983926
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2467.52563477]
 [   11.77655697]
 [ 2467.52563477]
 [   79.27848816]
 [  111.92836761]
 [   77.14117432]
 [ 2467.52563477]
 [    6.99294043]
 [  188.83906555]
 [  159.76177979]
 [  710.24981689]
 [    3.76508975]
 [    5.54147816]
 [    6.24290657]
 [   93.04180145]
 [  490.25720215]]
DEBUG:root:training time = %d0.215887
INFO:root:frame =6793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =6794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298023223877
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9839165
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =6797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471830368042
INFO:root:frame =6798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:random_action_porb = 0.983907
DEBUG:root: dqn, choose action rondomly, need time 0.000224000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.66433582e+03]
 [  3.29711474e-06]
 [  4.29940771e+03]
 [  5.57708321e+01]
 [  6.25308289e+02]
 [  3.36086304e+02]
 [  6.25308289e+02]
 [  7.07941101e+02]
 [  7.05848291e+03]
 [  4.55186615e+01]
 [  3.29711474e-06]
 [  8.14645081e+02]
 [  5.30214643e+00]
 [  4.95807343e+01]
 [  3.42700104e+02]
 [  3.36086304e+02]]
DEBUG:root:training time = %d0.198027
INFO:root:frame =6801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =6802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.9838975
DEBUG:root: dqn, choose action rondomly, need time 0.000519999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =6805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00079607963562
INFO:root:frame =6806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000330924987793
DEBUG:root: save sample needs time = 0.000217199325562
INFO:root:random_action_porb = 0.983888
DEBUG:root: dqn, choose action rondomly, need time 0.000551999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.32652266e+04]
 [  3.49505591e+00]
 [  5.79570389e+00]
 [  1.45619287e+01]
 [  5.43483198e-01]
 [  2.72330078e+02]
 [  1.25679985e+02]
 [  1.48528885e+02]
 [  1.11406812e+03]
 [  8.24836373e-01]
 [  3.54918098e+01]
 [  2.53029175e+02]
 [  1.16850920e+01]
 [  1.32652266e+04]
 [  1.13376221e+02]
 [  1.47868790e+02]]
DEBUG:root:training time = %d0.202018
INFO:root:frame =6809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =6810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234842300415
DEBUG:root: save sample needs time = 9.41753387451e-05
INFO:root:random_action_porb = 0.9838785
DEBUG:root: dqn, choose action rondomly, need time 0.000271999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root:frame =6813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =6814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000674962997437
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:random_action_porb = 0.983869
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317811965942
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.00538855e+03]
 [  1.22357129e+03]
 [  8.88477356e+02]
 [  1.38131274e+03]
 [  1.65437012e+02]
 [  1.22357129e+03]
 [  3.19032502e+00]
 [  3.85931427e+02]
 [  4.08526688e+01]
 [  2.60728668e+02]
 [  3.42988861e+02]
 [  9.35405176e+03]
 [  2.61795624e+02]
 [  3.14769244e+00]
 [  1.89097702e+02]
 [  7.26865816e+00]]
DEBUG:root:training time = %d0.20101
INFO:root:frame =6817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =6818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000535011291504
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9838595
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =6822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487089157104
INFO:root:frame = 6823 State into memory, numbers recorded 165 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000595808029175
INFO:root:random_action_porb = 0.98385
DEBUG:root: dqn, choose action rondomly, need time 0.000219000000016
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6824current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.22853345e+03]
 [  5.84618988e+01]
 [  1.26696434e+02]
 [  3.20874805e+03]
 [  2.11179352e+02]
 [  4.19982290e+00]
 [  5.02645874e+01]
 [  3.35290100e+02]
 [  1.09578753e+00]
 [  5.32206909e+02]
 [  2.79345703e+00]
 [  1.89945145e+02]
 [  7.83971710e+01]
 [  1.51632141e+03]
 [  5.26144287e+02]
 [  4.93384369e+02]]
DEBUG:root:training time = %d0.212406
INFO:root:frame =6825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =6826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.9838405
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000019
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =6829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame =6830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.983831
DEBUG:root: dqn, choose action rondomly, need time 0.000404000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.77217159e+01]
 [  1.00758118e+02]
 [  7.47995898e+03]
 [  5.33889465e+01]
 [  1.71686327e+00]
 [  7.03140488e+01]
 [  2.61530781e+01]
 [  3.08125793e+02]
 [  1.33055954e+02]
 [  1.46791290e+02]
 [  2.29398779e+03]
 [  3.65929375e+01]
 [  2.51444042e-01]
 [  1.83453064e+01]
 [  2.72271149e+02]
 [  2.53830640e+03]]
DEBUG:root:training time = %d0.199085
INFO:root:frame =6833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:frame =6834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame = 6835 State into memory, numbers recorded 166 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000580072402954
INFO:root:random_action_porb = 0.9838215
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6836current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =6837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000591993331909
INFO:root:frame =6838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.983812
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.50740005e+02]
 [  4.74472847e+01]
 [  4.00631752e+01]
 [  3.37853760e+02]
 [  2.50219528e+02]
 [  5.97756836e+02]
 [  3.45018188e+02]
 [  4.68455518e+03]
 [  1.23006611e+01]
 [  4.30985594e+00]
 [  5.40699512e+03]
 [  7.69997482e+01]
 [  1.23054797e+03]
 [  8.33377659e-01]
 [  8.70938086e+03]
 [  1.68390903e+01]]
DEBUG:root:training time = %d0.204196
INFO:root:frame =6841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =6842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000326156616211
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:random_action_porb = 0.9838025
DEBUG:root: dqn, choose action rondomly, need time 0.000515999999976
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =6845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =6846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.983793
DEBUG:root: dqn, choose action rondomly, need time 0.000406999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.81593895e+00]
 [  1.03230829e+01]
 [  2.58732178e+03]
 [  5.72508717e+00]
 [  1.97727432e+01]
 [  2.84429245e+01]
 [  2.58732178e+03]
 [  2.60757751e+02]
 [  6.21532275e+03]
 [  5.80889761e-01]
 [  7.81593895e+00]
 [  2.03335133e+01]
 [  1.24223547e+01]
 [  5.80889761e-01]
 [  2.73980835e+03]
 [  1.16416788e+00]]
DEBUG:root:training time = %d0.197862
INFO:root:frame =6849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237226486206
INFO:root:frame =6850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:random_action_porb = 0.9837835
DEBUG:root: dqn, choose action rondomly, need time 0.000277000000011
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =6853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root:frame =6854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00055193901062
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.983774
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:training error  = [[  1.68102905e+03]
 [  2.27783066e+02]
 [  1.60113025e+03]
 [  4.71232910e+03]
 [  1.34427881e+04]
 [  8.17226929e+02]
 [  7.33159332e+01]
 [  8.24347977e-03]
 [  8.47948551e-01]
 [  9.68242836e+00]
 [  5.64670410e+02]
 [  1.60992017e+03]
 [  7.92039185e+01]
 [  7.47244895e-01]
 [  3.04155540e+01]
 [  1.02012720e+01]]
DEBUG:root:training time = %d0.202805
INFO:root:frame =6857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =6858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000320911407471
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:random_action_porb = 0.9837645
DEBUG:root: dqn, choose action rondomly, need time 0.000355000000013
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000417947769165
INFO:root:frame =6861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =6862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.983755
DEBUG:root: dqn, choose action rondomly, need time 0.000197999999983
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000173091888428
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.01736456e+03]
 [  1.92957973e+01]
 [  1.86893463e+02]
 [  3.06518158e+02]
 [  6.67309189e+00]
 [  8.12855530e+01]
 [  5.61464405e+00]
 [  8.83291931e+01]
 [  1.28558836e+01]
 [  1.27447236e+00]
 [  2.32657211e+02]
 [  1.78138748e+02]
 [  3.76563191e-01]
 [  9.76760127e-03]
 [  6.58327179e+01]
 [  1.27447236e+00]]
DEBUG:root:training time = %d0.196641
INFO:root:frame =6865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:frame =6866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234127044678
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.9837455
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:frame =6869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =6870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame = 6871 State into memory, numbers recorded 167 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.00062108039856
INFO:root:random_action_porb = 0.983736
INFO:root:dqn select action Tensor("ArgMax_18:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00958399999999
INFO:root:action choosen by dqn [2]
INFO:root:frame =6872current_observation done, NOT record action [2], reward = 0
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.17828484e+01]
 [  5.52752502e+02]
 [  3.80793524e+00]
 [  2.00612030e+01]
 [  3.26188302e+00]
 [  7.96001770e+02]
 [  3.21557159e+01]
 [  1.88307941e+00]
 [  1.51706650e+02]
 [  6.62942200e+01]
 [  2.74707397e+03]
 [  1.86875858e+01]
 [  1.23130965e+00]
 [  3.21557159e+01]
 [  4.22522766e+02]
 [  1.99621246e+02]]
DEBUG:root:training time = %d0.223081
INFO:root:frame =6873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =6874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 9.20295715332e-05
INFO:root:random_action_porb = 0.9837265
DEBUG:root: dqn, choose action rondomly, need time 0.000171999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:frame =6877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =6878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame = 6879 State into memory, numbers recorded 168 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000545978546143
INFO:root:random_action_porb = 0.983717
DEBUG:root: dqn, choose action rondomly, need time 0.000353999999987
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6880current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000353097915649
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.22157080e+03]
 [  4.23983574e-01]
 [  2.14651047e+02]
 [  5.22266797e+03]
 [  4.68422413e-01]
 [  9.30693817e+01]
 [  2.19909131e+03]
 [  1.28722034e+03]
 [  1.05973557e+02]
 [  5.43230896e+02]
 [  1.54127136e+02]
 [  3.13836575e-01]
 [  1.35359070e+02]
 [  1.64510291e-02]
 [  2.00872803e+03]
 [  8.08868103e+02]]
DEBUG:root:training time = %d0.217099
INFO:root:frame =6881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =6882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000270128250122
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:random_action_porb = 0.9837075
DEBUG:root: dqn, choose action rondomly, need time 0.000193999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000158071517944
INFO:root:frame =6885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000528812408447
INFO:root:frame =6886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root:random_action_porb = 0.983698
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:training error  = [[  3.47573727e-01]
 [  5.18178215e+01]
 [  9.47710800e+00]
 [  2.90580869e+00]
 [  2.45404758e+01]
 [  6.28050720e+02]
 [  1.07837654e+02]
 [  9.54747498e-01]
 [  5.84507866e+01]
 [  3.47573727e-01]
 [  1.50157373e+03]
 [  3.23618698e+01]
 [  4.74074936e+00]
 [  1.07837654e+02]
 [  4.32692810e+02]
 [  2.52213394e+02]]
DEBUG:root:training time = %d0.199225
INFO:root:frame =6889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =6890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame = 6891 State into memory, numbers recorded 169 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:random_action_porb = 0.9836885
DEBUG:root: dqn, choose action rondomly, need time 0.000257000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6892current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =6893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000368118286133
INFO:root:frame =6894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000527143478394
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.983679
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   151.23814392]
 [   379.43002319]
 [    24.18649101]
 [   481.65768433]
 [ 10304.40332031]
 [  6110.87060547]
 [   187.32180786]
 [   133.42953491]
 [   228.44148254]
 [   183.72479248]
 [    93.77908325]
 [    26.83856773]
 [   144.79824829]
 [   136.60206604]
 [  1203.18029785]
 [    19.31229401]]
DEBUG:root:training time = %d0.213467
INFO:root:frame =6897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:frame =6898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480175018311
DEBUG:root: save sample needs time = 0.000172853469849
INFO:root:random_action_porb = 0.9836695
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root:frame =6901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =6902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:random_action_porb = 0.98366
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.27852058e+00]
 [  3.22335510e+02]
 [  8.17946017e-01]
 [  2.63474882e-01]
 [  1.07068665e+02]
 [  1.26060371e+02]
 [  2.72426636e+02]
 [  1.57495972e+02]
 [  4.25910801e-01]
 [  3.76911759e+00]
 [  1.07068665e+02]
 [  2.22211761e+02]
 [  4.70207910e+03]
 [  9.83450603e+00]
 [  6.40003662e+02]
 [  7.46893463e+01]]
DEBUG:root:training time = %d0.20387
INFO:root:frame =6905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000188827514648
INFO:root:frame =6906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000242948532104
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.9836505
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000411987304688
INFO:root:frame =6909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =6910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000364780426025
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.983641
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.75006139e+00]
 [  6.18832767e-01]
 [  2.02566261e+01]
 [  1.17565903e+02]
 [  1.44130585e+02]
 [  5.22769043e+02]
 [  1.61508972e+02]
 [  1.14756874e+02]
 [  5.73468323e+01]
 [  2.80712799e+02]
 [  3.25041260e+03]
 [  1.01603994e+01]
 [  5.16517677e+01]
 [  4.04810190e+00]
 [  5.16517677e+01]
 [  1.45619922e+03]]
DEBUG:root:training time = %d0.202922
INFO:root:frame =6913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =6914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000238180160522
DEBUG:root: save sample needs time = 0.000108003616333
INFO:root:random_action_porb = 0.9836315
DEBUG:root: dqn, choose action rondomly, need time 0.00017200000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:frame =6917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =6918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000244140625
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.983622
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[  2.59873447e+01]
 [  2.33650925e+02]
 [  5.94456604e+02]
 [  1.01484734e+02]
 [  8.66776428e+02]
 [  2.33462738e+02]
 [  6.46462744e+03]
 [  8.35956633e-01]
 [  7.36722851e+00]
 [  1.21732582e+02]
 [  1.79619553e+02]
 [  1.79391040e+03]
 [  8.92355499e+01]
 [  5.19824158e+02]
 [  2.54826074e+03]
 [  5.43395805e+00]]
DEBUG:root:training time = %d0.191405
INFO:root:frame =6921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000361204147339
INFO:root:frame =6922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000335931777954
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.9836125
DEBUG:root: dqn, choose action rondomly, need time 0.000264000000016
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =6925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000525951385498
INFO:root:frame =6926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000304937362671
DEBUG:root: save sample needs time = 0.000172138214111
INFO:root:random_action_porb = 0.983603
DEBUG:root: dqn, choose action rondomly, need time 0.000534000000016
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.62300018e+02]
 [  3.42093620e+01]
 [  1.61307561e+00]
 [  1.09204504e+03]
 [  8.85820618e+01]
 [  2.62958008e+03]
 [  6.68612183e+02]
 [  1.62317725e+03]
 [  5.25523224e+01]
 [  1.83696008e+03]
 [  3.40954614e+00]
 [  2.21173462e+03]
 [  9.50896530e+01]
 [  9.18181705e+00]
 [  1.50121365e+01]
 [  3.42093620e+01]]
DEBUG:root:training time = %d0.201771
INFO:root:frame =6929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:frame =6930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259876251221
DEBUG:root: save sample needs time = 0.0002281665802
INFO:root:random_action_porb = 0.9835935
DEBUG:root: dqn, choose action rondomly, need time 0.000326000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294208526611
INFO:root:frame =6933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000481128692627
INFO:root:frame =6934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root:frame = 6935 State into memory, numbers recorded 170 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.00079607963562
INFO:root:random_action_porb = 0.983584
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6936current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.73130957e+03]
 [  1.27276011e+01]
 [  2.88394702e+03]
 [  1.02033434e+01]
 [  1.05447044e+01]
 [  6.13514160e+02]
 [  1.88848555e+00]
 [  1.49620193e+02]
 [  8.25044250e+02]
 [  2.42364792e+02]
 [  3.53984161e+02]
 [  1.20959885e+02]
 [  5.03436615e+02]
 [  4.87535248e+02]
 [  1.98570999e+02]
 [  8.30530834e+00]]
DEBUG:root:training time = %d0.210393
INFO:root:frame =6937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =6938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298023223877
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.9835745
DEBUG:root: dqn, choose action rondomly, need time 0.000236999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:frame =6941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =6942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:random_action_porb = 0.983565
DEBUG:root: dqn, choose action rondomly, need time 0.000237000000027
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:training error  = [[  2.12922168e+03]
 [  3.74911652e+01]
 [  1.83586044e+02]
 [  4.57105446e+00]
 [  7.34402893e+02]
 [  1.80616570e+01]
 [  1.21953728e+02]
 [  5.64678764e+01]
 [  3.19806981e+00]
 [  9.43075439e+02]
 [  1.75292725e+03]
 [  6.28254366e+00]
 [  6.51574768e+02]
 [  2.50312329e+03]
 [  3.32071609e+01]
 [  1.09213628e-01]]
DEBUG:root:training time = %d0.198789
INFO:root:frame =6945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =6946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000281095504761
DEBUG:root: save sample needs time = 0.000123977661133
INFO:root:random_action_porb = 0.9835555
DEBUG:root: dqn, choose action rondomly, need time 0.000332000000014
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =6949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =6950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000664949417114
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:random_action_porb = 0.983546
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000175952911377
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.40023560e+02]
 [  1.20398492e-01]
 [  2.11376801e+02]
 [  2.13442755e+00]
 [  5.25425842e+02]
 [  3.62059546e+00]
 [  1.01867157e+02]
 [  1.77469955e+02]
 [  8.04748291e+02]
 [  5.53257141e+01]
 [  1.80406909e+03]
 [  4.35498260e+02]
 [  1.26753116e+00]
 [  5.91397754e+03]
 [  2.54017532e+02]
 [  5.63598728e+00]]
DEBUG:root:training time = %d0.193758
INFO:root:frame =6953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =6954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9835365
DEBUG:root: dqn, choose action rondomly, need time 0.000239999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:frame =6957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00036096572876
INFO:root:frame =6958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.983527
DEBUG:root: dqn, choose action rondomly, need time 0.000689999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.03161764e+00]
 [  2.91795776e+02]
 [  3.82589132e-01]
 [  4.13225372e+02]
 [  4.84068642e+01]
 [  3.48789215e-01]
 [  5.09603081e+01]
 [  8.58126282e+02]
 [  6.81517506e+00]
 [  4.05117416e+01]
 [  6.12456207e+01]
 [  1.10414162e+01]
 [  2.51793060e+01]
 [  6.09481659e+01]
 [  1.58590765e+01]
 [  7.06659393e+01]]
DEBUG:root:training time = %d0.214217
INFO:root:frame =6961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =6962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000500917434692
INFO:root:frame = 6963 State into memory, numbers recorded 171 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000564098358154
INFO:root:random_action_porb = 0.9835175
DEBUG:root: dqn, choose action rondomly, need time 0.000548999999978
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6964current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =6965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000481128692627
INFO:root:frame =6966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000499963760376
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:random_action_porb = 0.983508
DEBUG:root: dqn, choose action rondomly, need time 0.000181999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000153779983521
INFO:root:training error  = [[  1.77375202e+01]
 [  2.91214676e+01]
 [  9.86311188e+01]
 [  1.63829193e+02]
 [  7.77299777e-02]
 [  9.22760437e+02]
 [  7.72273560e+02]
 [  3.19081217e-01]
 [  6.90625000e+02]
 [  2.01457653e+01]
 [  9.28684769e+01]
 [  8.63461731e+02]
 [  6.73380814e+01]
 [  3.95523567e+01]
 [  4.88688698e+01]
 [  2.43587187e-03]]
DEBUG:root:training time = %d0.223095
INFO:root:frame =6969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =6970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231981277466
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.9834985
DEBUG:root: dqn, choose action rondomly, need time 0.000211000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000209808349609
INFO:root:frame =6973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =6974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.983489
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.92209396e+01]
 [  1.26264001e+03]
 [  1.01053479e+03]
 [  7.76687622e+01]
 [  1.04770541e+00]
 [  1.19447889e+01]
 [  4.75194885e+02]
 [  1.34737873e+01]
 [  3.59313698e+01]
 [  5.84803939e-01]
 [  6.64981318e+00]
 [  1.01059980e+01]
 [  5.18819317e-03]
 [  9.55788696e+02]
 [  1.32965851e+02]
 [  7.76687622e+01]]
DEBUG:root:training time = %d0.207697
INFO:root:frame =6977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:frame =6978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9834795
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =6981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000341176986694
INFO:root:frame =6982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002601146698
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:random_action_porb = 0.98347
DEBUG:root: dqn, choose action rondomly, need time 0.000265999999982
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.80450022e-01]
 [  6.01401025e+03]
 [  1.75978235e+03]
 [  2.61541382e+02]
 [  8.44161987e+02]
 [  3.49006561e+02]
 [  1.57679947e+02]
 [  3.49006561e+02]
 [  2.87998462e+03]
 [  1.03660986e-01]
 [  3.17243286e+02]
 [  7.36784973e+01]
 [  1.96073987e+03]
 [  1.22130714e-01]
 [  4.15244434e+03]
 [  2.23674469e+01]]
DEBUG:root:training time = %d0.187794
INFO:root:frame =6985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =6986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000336170196533
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:random_action_porb = 0.9834605
DEBUG:root: dqn, choose action rondomly, need time 0.000196999999986
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =6989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000517129898071
INFO:root:frame =6990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480890274048
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.983451
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322818756104
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.46213379e+01]
 [  1.79067764e+02]
 [  2.63049946e+01]
 [  1.12847644e+03]
 [  2.63049946e+01]
 [  2.40444067e+03]
 [  1.13303932e+02]
 [  1.04299390e+00]
 [  1.02836108e+03]
 [  2.80145782e+02]
 [  2.29247437e+01]
 [  9.98540161e+02]
 [  1.27242175e+03]
 [  1.34099275e-01]
 [  9.98540161e+02]
 [  1.48471940e+00]]
DEBUG:root:training time = %d0.197707
INFO:root:frame =6993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000404119491577
INFO:root:frame =6994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486850738525
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:random_action_porb = 0.9834415
DEBUG:root: dqn, choose action rondomly, need time 0.000250000000023
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000356912612915
INFO:root:frame =6997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =6998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000495910644531
DEBUG:root: save sample needs time = 0.000217914581299
DEBUG:root:one frame running time = 0.006506
DEBUG:root:total training time = 175.816718
INFO:root:frame num = 7000 frame round: 0
INFO:root:random_action_porb = 0.983432
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  287.50003052]
 [  646.9732666 ]
 [  913.25079346]
 [  486.07528687]
 [  237.3846283 ]
 [   76.66624451]
 [  476.43774414]
 [  872.12670898]
 [   86.10967255]
 [   29.20807457]
 [   20.71200562]
 [  354.36843872]
 [   25.53876114]
 [ 1613.88012695]
 [   38.53183746]
 [   34.17853546]]
DEBUG:root:training time = %d0.201162
INFO:root:frame =7001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =7002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame = 7003 State into memory, numbers recorded 172 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:random_action_porb = 0.9834225
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7004current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =7005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =7006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.983413
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.12327118e+01]
 [  2.86418030e+02]
 [  1.90631962e+00]
 [  1.92771774e+02]
 [  1.72665192e+02]
 [  4.97207123e+02]
 [  9.73362000e+02]
 [  9.22317600e+00]
 [  1.32961804e+03]
 [  8.83220215e+01]
 [  1.06359299e+02]
 [  4.13211584e+00]
 [  1.83112686e+02]
 [  8.28974902e+03]
 [  3.11845869e-01]
 [  8.26299286e+00]]
DEBUG:root:training time = %d0.196146
INFO:root:frame =7009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:frame =7010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.9834035
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =7013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470161437988
INFO:root:frame =7014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.983394
DEBUG:root: dqn, choose action rondomly, need time 0.000201000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000150918960571
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.52884781e+02]
 [  4.53708315e+00]
 [  1.07566551e+02]
 [  2.42963362e+00]
 [  3.33345485e+00]
 [  1.71962976e+03]
 [  2.00575123e+01]
 [  1.39582382e+02]
 [  5.91863556e+01]
 [  1.38572876e+02]
 [  2.92274017e+02]
 [  8.69047754e+03]
 [  5.79262772e+01]
 [  1.63803463e+01]
 [  1.60621162e+04]
 [  1.64308777e+02]]
DEBUG:root:training time = %d0.196931
INFO:root:frame =7017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000383138656616
INFO:root:frame =7018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000157117843628
INFO:root:random_action_porb = 0.9833845
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =7021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441789627075
INFO:root:frame =7022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.983375
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.03948936e+01]
 [  1.79525085e+02]
 [  5.04102386e+02]
 [  1.40238815e+02]
 [  6.22577942e+02]
 [  4.62124348e+00]
 [  9.58829346e+02]
 [  3.34346924e+02]
 [  1.56419325e+00]
 [  6.23094130e+00]
 [  1.30527222e+03]
 [  1.05521533e+03]
 [  1.58279791e+01]
 [  5.53285480e-01]
 [  2.02276566e+02]
 [  4.82867622e+01]]
DEBUG:root:training time = %d0.208192
INFO:root:frame =7025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =7026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.9833655
DEBUG:root: dqn, choose action rondomly, need time 0.000294000000025
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =7029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =7030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000385999679565
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root:random_action_porb = 0.983356
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000011
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000373125076294
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.54261627e+01]
 [  5.40837463e+02]
 [  1.18771191e+01]
 [  5.97154602e+02]
 [  2.20708981e+01]
 [  1.01074047e+01]
 [  9.78761914e+03]
 [  9.12208462e+00]
 [  3.35209076e+02]
 [  7.96138550e+02]
 [  4.28380013e+01]
 [  3.54261627e+01]
 [  7.17590153e-01]
 [  1.25572240e+00]
 [  1.40448706e+03]
 [  2.21603943e+02]]
DEBUG:root:training time = %d0.207058
INFO:root:frame =7033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:frame =7034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.9833465
DEBUG:root: dqn, choose action rondomly, need time 0.000340999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =7037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =7038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:random_action_porb = 0.983337
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000337839126587
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.09100266e+01]
 [  3.14085369e+01]
 [  5.77185596e+03]
 [  1.34097319e+01]
 [  2.85281421e+03]
 [  6.84937057e+01]
 [  1.13918556e+02]
 [  6.40862122e+01]
 [  5.94155151e+02]
 [  1.47897840e-01]
 [  3.63476929e+03]
 [  1.29985992e+02]
 [  8.17587280e+00]
 [  9.52384583e+02]
 [  6.93212366e+00]
 [  1.76501053e+02]]
DEBUG:root:training time = %d0.197657
INFO:root:frame =7041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000199794769287
INFO:root:frame =7042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9833275
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999986
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =7045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =7046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame = 7047 State into memory, numbers recorded 173 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000547885894775
INFO:root:random_action_porb = 0.983318
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7048current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.35354209e-01]
 [  5.73668251e+01]
 [  3.68405418e+01]
 [  1.67506695e+01]
 [  3.25751251e+02]
 [  8.12140369e+00]
 [  8.12140369e+00]
 [  9.83869812e+02]
 [  4.54325439e+02]
 [  1.20301094e+01]
 [  8.09907303e+01]
 [  1.02452636e+00]
 [  2.76801437e-01]
 [  5.71907158e+01]
 [  9.83869812e+02]
 [  8.91773987e+01]]
DEBUG:root:training time = %d0.191092
INFO:root:frame =7049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00074315071106
INFO:root:frame =7050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248908996582
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9833085
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =7053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =7054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.983299
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:training error  = [[  6.20189209e+02]
 [  1.81634502e+01]
 [  7.53822784e+01]
 [  2.14893784e+02]
 [  4.86477315e-01]
 [  1.55629320e+01]
 [  1.88661972e+02]
 [  2.65290131e+02]
 [  7.52367676e+02]
 [  9.32340759e+02]
 [  1.08987122e+02]
 [  5.58806467e+00]
 [  3.76056055e+03]
 [  6.09327881e+03]
 [  1.66589403e+00]
 [  1.67043953e+01]]
DEBUG:root:training time = %d0.192371
INFO:root:frame =7057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =7058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000400066375732
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9832895
DEBUG:root: dqn, choose action rondomly, need time 0.000596000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =7061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =7062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049614906311
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:random_action_porb = 0.98328
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.31416550e+01]
 [  2.68008556e+01]
 [  1.75556641e+02]
 [  3.91017032e+00]
 [  2.91227844e+02]
 [  2.83732544e+02]
 [  2.34519971e+03]
 [  4.31824913e+01]
 [  2.91227844e+02]
 [  3.47996652e-01]
 [  2.65607667e+00]
 [  5.37582338e-01]
 [  1.54459219e+01]
 [  8.26164551e+01]
 [  7.10186386e+00]
 [  5.03634473e+03]]
DEBUG:root:training time = %d0.218435
INFO:root:frame =7065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000395059585571
INFO:root:frame =7066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241041183472
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:random_action_porb = 0.9832705
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000015
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:frame =7069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =7070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame = 7071 State into memory, numbers recorded 174 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00056791305542
INFO:root:random_action_porb = 0.983261
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7072current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.59527817e+01]
 [  8.32275295e+00]
 [  3.11079884e+01]
 [  5.73317322e+02]
 [  6.29494507e+02]
 [  7.68938370e+01]
 [  7.76467743e+01]
 [  1.20176229e+01]
 [  1.71508732e+01]
 [  4.05760101e+02]
 [  1.14782305e+01]
 [  2.10817263e-01]
 [  6.60434937e+02]
 [  6.43413687e+00]
 [  2.10817263e-01]
 [  1.32600946e+01]]
DEBUG:root:training time = %d0.206882
INFO:root:frame =7073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =7074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9832515
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999985
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =7077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =7078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame = 7079 State into memory, numbers recorded 175 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000595808029175
INFO:root:random_action_porb = 0.983242
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7080current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.81894455e+01]
 [  2.41290283e+03]
 [  4.94408464e+00]
 [  1.95813618e+01]
 [  2.18315994e+02]
 [  4.47334991e+02]
 [  8.01132843e-02]
 [  6.36211634e+00]
 [  5.33566570e+00]
 [  9.76180725e+02]
 [  9.69046712e-01]
 [  1.27975333e+00]
 [  4.53766174e+02]
 [  8.17899227e+00]
 [  2.41290283e+03]
 [  9.16079980e+03]]
DEBUG:root:training time = %d0.214605
INFO:root:frame =7081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =7082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494956970215
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9832325
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000394105911255
INFO:root:frame =7085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =7086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame = 7087 State into memory, numbers recorded 176 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00059986114502
INFO:root:random_action_porb = 0.983223
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7088current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.23913403e+01]
 [  2.23913403e+01]
 [  5.83322942e-01]
 [  1.67707910e+03]
 [  1.67707910e+03]
 [  5.46754028e+02]
 [  2.61624298e+02]
 [  8.36124039e+01]
 [  6.64792419e+02]
 [  5.32804565e+02]
 [  1.96090485e+02]
 [  8.86144165e+02]
 [  1.60999794e+01]
 [  1.09197014e+02]
 [  6.75588913e+01]
 [  2.40062576e+02]]
DEBUG:root:training time = %d0.193296
INFO:root:frame =7089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =7090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.00011420249939
INFO:root:random_action_porb = 0.9832135
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =7093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000502109527588
INFO:root:frame =7094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:random_action_porb = 0.983204
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.57102982e+02]
 [  3.43189880e+02]
 [  2.60952282e+01]
 [  7.24286572e+03]
 [  1.94477280e+02]
 [  8.50842667e+01]
 [  8.11071014e+00]
 [  3.71016174e+02]
 [  2.25685913e+02]
 [  4.90130249e+02]
 [  1.69145142e+03]
 [  2.76426258e+01]
 [  2.75583496e+03]
 [  2.68230200e+00]
 [  3.19210529e-01]
 [  3.39715672e+00]]
DEBUG:root:training time = %d0.222201
INFO:root:frame =7097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =7098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.9831945
DEBUG:root: dqn, choose action rondomly, need time 0.000370000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =7101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =7102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000498056411743
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.983185
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.18154907e+02]
 [  5.42499363e-01]
 [  6.95540085e+01]
 [  6.96057606e+00]
 [  2.37993335e+03]
 [  1.65057663e+02]
 [  1.29370593e+03]
 [  2.37334915e+02]
 [  3.53866529e+00]
 [  5.81181383e+00]
 [  2.78761711e+01]
 [  1.97900143e+01]
 [  1.02898951e+01]
 [  1.43596721e+00]
 [  1.46522427e+00]
 [  9.40933456e+01]]
DEBUG:root:training time = %d0.209808
INFO:root:frame =7105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000209808349609
INFO:root:frame =7106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.9831755
DEBUG:root: dqn, choose action rondomly, need time 0.000161999999989
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000140190124512
INFO:root:frame =7109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =7110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.983166
DEBUG:root: dqn, choose action rondomly, need time 0.000202000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000186920166016
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.55410797e+02]
 [  4.46300507e+01]
 [  4.03865021e+02]
 [  7.75645781e+00]
 [  1.19568157e+01]
 [  6.30813110e+02]
 [  5.68595508e+03]
 [  1.99123535e+01]
 [  2.18807697e+01]
 [  1.59990692e+02]
 [  4.76914793e-02]
 [  5.85744751e+02]
 [  2.12199036e+02]
 [  7.60601807e+01]
 [  2.61125736e+01]
 [  1.23659721e+02]]
DEBUG:root:training time = %d0.209284
INFO:root:frame =7113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =7114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239133834839
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9831565
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =7117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237226486206
INFO:root:frame =7118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:random_action_porb = 0.983147
DEBUG:root: dqn, choose action rondomly, need time 0.000159999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.00348523e-03]
 [  5.77492189e+00]
 [  4.63881226e+01]
 [  6.96984634e+01]
 [  6.35880661e+01]
 [  4.39603363e+02]
 [  4.39509552e+02]
 [  1.49227524e+02]
 [  2.18305801e+02]
 [  3.24212909e-01]
 [  8.94002051e+03]
 [  3.26798477e+01]
 [  1.27010590e+02]
 [  1.62401062e+02]
 [  4.43131790e+01]
 [  3.55626166e-01]]
DEBUG:root:training time = %d0.202436
INFO:root:frame =7121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:frame =7122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509977340698
DEBUG:root: save sample needs time = 9.29832458496e-05
INFO:root:random_action_porb = 0.9831375
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =7125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =7126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.983128
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000026
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[    3.55789423]
 [    2.98029351]
 [  256.60766602]
 [  172.78709412]
 [ 1019.33233643]
 [   32.93675995]
 [  152.40055847]
 [  229.33972168]
 [   36.11416626]
 [   20.75275421]
 [    5.60989952]
 [   12.94022083]
 [   10.90845776]
 [ 1384.46618652]
 [  604.38635254]
 [    2.13017178]]
DEBUG:root:training time = %d0.200159
INFO:root:frame =7129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00037693977356
INFO:root:frame =7130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:random_action_porb = 0.9831185
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999982
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root:frame =7133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049614906311
INFO:root:frame =7134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045919418335
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.983109
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  972.72772217]
 [ 1001.07531738]
 [   21.76646996]
 [   12.874547  ]
 [   68.72664642]
 [    7.56786156]
 [    3.56542444]
 [    3.56542444]
 [ 2050.27001953]
 [   79.12001801]
 [   35.26912689]
 [ 1251.46704102]
 [  151.0941925 ]
 [  430.78955078]
 [  518.60095215]
 [   14.72436905]]
DEBUG:root:training time = %d0.22453
INFO:root:frame =7137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =7138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002601146698
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.9830995
DEBUG:root: dqn, choose action rondomly, need time 0.00016100000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:frame =7141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =7142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.98309
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.42098331e+00]
 [  3.14508130e+03]
 [  2.81918213e+02]
 [  2.12246799e+01]
 [  3.78004028e+02]
 [  1.48827002e+03]
 [  6.34949875e+00]
 [  2.73725983e+02]
 [  3.13722038e+01]
 [  1.46505797e+00]
 [  7.72822754e+02]
 [  2.73725983e+02]
 [  6.29720020e+00]
 [  1.36383111e-03]
 [  2.51405776e-01]
 [  1.66313534e+01]]
DEBUG:root:training time = %d0.211513
INFO:root:frame =7145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =7146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424146652222
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:random_action_porb = 0.9830805
DEBUG:root: dqn, choose action rondomly, need time 0.000321000000014
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =7149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =7150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428915023804
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:random_action_porb = 0.983071
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.78032617e+03]
 [  8.14239111e+03]
 [  1.15959221e+02]
 [  3.72001410e+00]
 [  4.08652258e+00]
 [  6.65113342e+02]
 [  1.17438042e+02]
 [  1.06136284e+01]
 [  2.62875641e+02]
 [  1.06136284e+01]
 [  4.00040131e+02]
 [  5.14555908e+02]
 [  3.75006714e+01]
 [  1.56429245e+02]
 [  6.24803589e+02]
 [  6.81230211e+00]]
DEBUG:root:training time = %d0.204719
INFO:root:frame =7153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =7154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274181365967
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.9830615
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =7157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446796417236
INFO:root:frame =7158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000720977783203
INFO:root:frame = 7159 State into memory, numbers recorded 177 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000538110733032
INFO:root:random_action_porb = 0.983052
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7160current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.41730375e+01]
 [  5.96263390e+01]
 [  1.47340894e-01]
 [  8.99759445e+01]
 [  1.51063747e+01]
 [  3.56386597e+02]
 [  2.93218212e+01]
 [  1.30893689e+03]
 [  1.88976831e+03]
 [  1.49688889e+02]
 [  2.42980316e+02]
 [  1.51063747e+01]
 [  1.83077484e+02]
 [  8.66255569e+00]
 [  7.61346388e+00]
 [  2.61004712e+03]]
DEBUG:root:training time = %d0.195388
INFO:root:frame =7161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =7162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000123977661133
INFO:root:random_action_porb = 0.9830425
DEBUG:root: dqn, choose action rondomly, need time 0.000188000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000175952911377
INFO:root:frame =7165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =7166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277996063232
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.983033
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[  8.51732483e+01]
 [  1.81178253e+02]
 [  7.34120789e+01]
 [  3.07024023e+03]
 [  1.09628273e+02]
 [  4.51150146e+02]
 [  7.18136370e-01]
 [  8.05113316e+00]
 [  1.00697565e+03]
 [  1.22519812e+03]
 [  4.60530579e+02]
 [  1.06658240e+03]
 [  2.44466839e+01]
 [  2.17421143e+03]
 [  9.11482544e+02]
 [  4.60530579e+02]]
DEBUG:root:training time = %d0.206488
INFO:root:frame =7169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =7170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000523090362549
DEBUG:root: save sample needs time = 0.000130176544189
INFO:root:random_action_porb = 0.9830235
DEBUG:root: dqn, choose action rondomly, need time 0.000155000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000141143798828
INFO:root:frame =7173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame =7174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.983014
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root: ememy has been killed for 13 times 
INFO:root:enemies_left [0]
INFO:root:frame =7176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000511169433594
INFO:root:training error  = [[  7.23256287e+02]
 [  9.54547729e+01]
 [  2.13466808e-01]
 [  1.29151901e+02]
 [  7.83111145e+02]
 [  2.80159874e+01]
 [  1.48782599e+00]
 [  1.68767197e+02]
 [  1.02440825e+01]
 [  1.28940449e+01]
 [  5.98896423e+02]
 [  1.45928467e+03]
 [  2.41937866e+02]
 [  1.45032918e+00]
 [  8.05412903e+02]
 [  4.82780685e+01]]
DEBUG:root:training time = %d0.18661
INFO:root:frame =7177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =7178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame = 7179 State into memory, numbers recorded 178 action = 3, reward = 255
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root:random_action_porb = 0.9830045
DEBUG:root: dqn, choose action rondomly, need time 0.000203999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7180current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:frame =7181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000496864318848
INFO:root:frame =7182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000620126724243
INFO:root:frame = 7183 State into memory, numbers recorded 179 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:random_action_porb = 0.982995
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999982
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7184current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000279188156128
INFO:root:training error  = [[  3.23572044e+01]
 [  1.85181198e+01]
 [  2.37337204e+02]
 [  1.96072636e+01]
 [  3.13701080e+02]
 [  8.57655869e+01]
 [  1.86841888e+01]
 [  8.03631115e+00]
 [  3.13701080e+02]
 [  1.36501476e-01]
 [  5.75223160e+01]
 [  2.32106750e+02]
 [  1.96475494e+00]
 [  8.80752563e-01]
 [  5.77591919e+02]
 [  1.41267176e+01]]
DEBUG:root:training time = %d0.19459
INFO:root:frame =7185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =7186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049614906311
DEBUG:root: save sample needs time = 0.000382900238037
INFO:root:random_action_porb = 0.9829855
DEBUG:root: dqn, choose action rondomly, need time 0.000216999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =7189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =7190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.982976
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000380992889404
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.70173168e+00]
 [  1.14602127e+02]
 [  1.69284988e+02]
 [  4.33291614e-01]
 [  1.47724495e+01]
 [  4.51662093e-01]
 [  7.39989548e+01]
 [  2.67963734e+01]
 [  4.15895813e+02]
 [  8.06837006e+01]
 [  2.78075194e+00]
 [  1.47724495e+01]
 [  7.25447632e+02]
 [  9.01701431e+01]
 [  3.17719097e+01]
 [  5.84579102e+02]]
DEBUG:root:training time = %d0.203847
INFO:root:frame =7193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =7194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.9829665
DEBUG:root: dqn, choose action rondomly, need time 0.000200000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000193119049072
INFO:root:frame =7197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =7198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00052809715271
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.982957
DEBUG:root: dqn, choose action rondomly, need time 0.000357999999977
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.22066727e+01]
 [  2.28372526e+00]
 [  4.86640787e+00]
 [  9.56194077e+01]
 [  4.68348274e+01]
 [  8.42072754e+02]
 [  3.06509628e+01]
 [  7.00642242e+01]
 [  3.57304932e+02]
 [  5.85910950e+02]
 [  3.17679260e+02]
 [  3.43425385e+02]
 [  1.32612619e+01]
 [  5.68463793e-03]
 [  4.68348274e+01]
 [  1.99637264e-01]]
DEBUG:root:training time = %d0.197619
INFO:root:frame =7201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000399827957153
INFO:root:frame =7202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame = 7203 State into memory, numbers recorded 180 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000592947006226
INFO:root:random_action_porb = 0.9829475
DEBUG:root: dqn, choose action rondomly, need time 0.000165999999979
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7204current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:frame =7205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000425100326538
INFO:root:frame =7206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456809997559
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:random_action_porb = 0.982938
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.30597168e+03]
 [  2.84689732e+01]
 [  3.39761124e+01]
 [  3.45214142e+02]
 [  8.15312598e+03]
 [  1.67923415e+00]
 [  2.02950311e+00]
 [  1.00821078e+00]
 [  1.08050674e+04]
 [  1.64538116e+02]
 [  2.42315750e+01]
 [  5.90777168e+01]
 [  2.19092484e+02]
 [  9.94669571e+01]
 [  2.03852341e+02]
 [  1.39892673e+01]]
DEBUG:root:training time = %d0.214769
INFO:root:frame =7209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:frame =7210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240087509155
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.9829285
DEBUG:root: dqn, choose action rondomly, need time 0.000168000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:frame =7213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =7214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame = 7215 State into memory, numbers recorded 181 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000389099121094
INFO:root:random_action_porb = 0.982919
DEBUG:root: dqn, choose action rondomly, need time 0.000325999999973
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7216current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.41826515e+01]
 [  4.50968018e+02]
 [  1.68532448e+01]
 [  4.50968018e+02]
 [  3.77359192e+02]
 [  2.52162451e+03]
 [  8.25050684e+03]
 [  3.32312164e+02]
 [  6.50548477e+01]
 [  5.08356781e-04]
 [  1.13462842e+00]
 [  2.60411224e+01]
 [  3.25743854e-01]
 [  2.85361786e+02]
 [  4.55598235e-01]
 [  2.28107422e+02]]
DEBUG:root:training time = %d0.202583
INFO:root:frame =7217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =7218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9829095
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =7221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame =7222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441789627075
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9829
DEBUG:root: dqn, choose action rondomly, need time 0.000349999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:training error  = [[  3.13859215e+01]
 [  3.43218155e+01]
 [  3.92580505e+02]
 [  2.71451244e+01]
 [  1.83156471e+01]
 [  2.96944008e+01]
 [  1.79842987e+02]
 [  3.90933323e+00]
 [  1.10548944e+01]
 [  8.10923278e-02]
 [  1.10257417e-01]
 [  1.28776978e+03]
 [  1.10257417e-01]
 [  1.48086863e+01]
 [  4.88432199e-01]
 [  7.14518799e+02]]
DEBUG:root:training time = %d0.191983
INFO:root:frame =7225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000387191772461
INFO:root:frame =7226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000355005264282
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.9828905
DEBUG:root: dqn, choose action rondomly, need time 0.000166000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =7229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000362873077393
INFO:root:frame =7230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000519990921021
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:random_action_porb = 0.982881
DEBUG:root: dqn, choose action rondomly, need time 0.000214
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000182151794434
INFO:root:training error  = [[  3.37989922e+01]
 [  3.37989922e+01]
 [  2.95125427e+01]
 [  2.89196663e+01]
 [  5.27661816e+03]
 [  1.09428549e+01]
 [  6.43909210e-04]
 [  7.80805664e+01]
 [  9.43856049e+01]
 [  1.46581531e+00]
 [  4.38040848e+01]
 [  4.56385422e+01]
 [  4.82910042e+01]
 [  1.04726343e+01]
 [  3.69388223e+00]
 [  4.73868988e+02]]
DEBUG:root:training time = %d0.183154
INFO:root:frame =7233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =7234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274896621704
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:random_action_porb = 0.9828715
DEBUG:root: dqn, choose action rondomly, need time 0.000191000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000141859054565
INFO:root:frame =7237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root:frame =7238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame = 7239 State into memory, numbers recorded 182 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000396013259888
INFO:root:random_action_porb = 0.982862
DEBUG:root: dqn, choose action rondomly, need time 0.000231000000014
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7240current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.39852486e+01]
 [  2.26350128e+02]
 [  2.30003405e+00]
 [  1.97506152e+04]
 [  1.15727243e+01]
 [  2.64603329e+00]
 [  1.70056152e+02]
 [  3.29650078e+01]
 [  4.72973389e+02]
 [  9.93996525e+00]
 [  1.15564209e+03]
 [  3.92857635e+02]
 [  1.45931559e+01]
 [  6.12535059e-01]
 [  4.12676010e+01]
 [  4.10823746e+01]]
DEBUG:root:training time = %d0.194038
INFO:root:frame =7241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =7242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9828525
DEBUG:root: dqn, choose action rondomly, need time 0.000166000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:frame =7245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =7246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000225067138672
DEBUG:root: save sample needs time = 0.000105142593384
INFO:root:random_action_porb = 0.982843
DEBUG:root: dqn, choose action rondomly, need time 0.000241000000017
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000197172164917
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.67577893e-01]
 [  7.62824917e+00]
 [  2.37931557e+01]
 [  4.17094119e-03]
 [  3.33229785e+03]
 [  6.86283936e+02]
 [  3.24326660e+02]
 [  1.13850166e+02]
 [  3.53020263e+00]
 [  9.18445663e+01]
 [  1.71513426e+00]
 [  1.68324451e+03]
 [  1.13850166e+02]
 [  8.51210098e+01]
 [  3.04021705e-02]
 [  4.21141663e+02]]
DEBUG:root:training time = %d0.19755
INFO:root:frame =7249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =7250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 0.000130891799927
INFO:root:random_action_porb = 0.9828335
DEBUG:root: dqn, choose action rondomly, need time 0.000259
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =7253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root: ememy has been killed for 14 times 
INFO:root:enemies_left [0]
INFO:root:frame =7254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000166177749634
INFO:root:frame = 7255 State into memory, numbers recorded 183 action = 4, reward = 255
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:random_action_porb = 0.982824
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999985
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7256current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000185012817383
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.83265209e+01]
 [  1.66278467e+03]
 [  9.57107639e+00]
 [  2.58882809e+01]
 [  1.14668150e+01]
 [  1.51107239e+02]
 [  4.89917450e+02]
 [  6.01727173e+02]
 [  3.82776985e+01]
 [  1.05402203e+01]
 [  1.08375391e+03]
 [  1.09706140e+03]
 [  8.35845886e+02]
 [  1.00721716e+03]
 [  1.13429523e+00]
 [  5.61193287e-01]]
DEBUG:root:training time = %d0.186021
INFO:root:frame =7257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =7258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428915023804
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9828145
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =7261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000495195388794
INFO:root:frame =7262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:random_action_porb = 0.982805
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.30762711e+01]
 [  3.01209717e+02]
 [  5.34878299e-03]
 [  6.03039917e+02]
 [  2.05566553e+03]
 [  1.09649050e+00]
 [  2.21247598e+04]
 [  1.25267725e+01]
 [  2.21247598e+04]
 [  5.10563202e+01]
 [  3.01209717e+02]
 [  1.53398056e+02]
 [  1.46371098e+01]
 [  4.79916000e+01]
 [  1.68722200e+00]
 [  1.44949856e+01]]
DEBUG:root:training time = %d0.202726
INFO:root:frame =7265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:frame =7266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000250101089478
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:random_action_porb = 0.9827955
DEBUG:root: dqn, choose action rondomly, need time 0.000207999999986
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342845916748
INFO:root:frame =7269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00055193901062
INFO:root:frame =7270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:random_action_porb = 0.982786
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.64634155e+03]
 [  9.32118103e+02]
 [  1.52390766e+00]
 [  2.17445480e+02]
 [  3.30174072e+02]
 [  1.24383869e+01]
 [  2.50348015e+01]
 [  9.09053406e+02]
 [  2.14290375e+02]
 [  1.71648941e+02]
 [  7.13128760e+03]
 [  2.22988068e+02]
 [  5.64144775e+02]
 [  8.91487961e+01]
 [  1.71648941e+02]
 [  1.26693253e+02]]
DEBUG:root:training time = %d0.206177
INFO:root:frame =7273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =7274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame = 7275 State into memory, numbers recorded 184 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:random_action_porb = 0.9827765
INFO:root:dqn select action Tensor("ArgMax_19:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00791999999998
INFO:root:action choosen by dqn [2]
INFO:root:frame =7276current_observation done, NOT record action [2], reward = 0
DEBUG:root: save sample needs time = 0.000385046005249
INFO:root: ememy has been killed for 15 times 
INFO:root:enemies_left [0]
INFO:root:frame =7277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =7278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame = 7279 State into memory, numbers recorded 185 action = [2], reward = 255
DEBUG:root: save sample needs time = 0.000610828399658
INFO:root:random_action_porb = 0.982767
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7280current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[  1.41698718e+03]
 [  1.35704758e+02]
 [  5.90317726e+00]
 [  5.61578903e+01]
 [  8.30093460e+01]
 [  4.73223969e+02]
 [  2.97026825e+02]
 [  1.01334989e+00]
 [  2.06255865e+00]
 [  4.44536667e+01]
 [  6.93987122e+02]
 [  1.30827927e+02]
 [  1.27295300e+03]
 [  6.69506531e+02]
 [  6.79438400e+01]
 [  1.75787598e+02]]
DEBUG:root:training time = %d0.207765
INFO:root:frame =7281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285148620605
INFO:root:frame =7282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000280141830444
INFO:root:frame = 7283 State into memory, numbers recorded 186 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000391960144043
INFO:root:random_action_porb = 0.9827575
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7284current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:frame =7285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =7286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.982748
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000011
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.67990646e+02]
 [  3.17063408e+01]
 [  7.53189087e+02]
 [  4.89169350e+01]
 [  5.39265564e+02]
 [  2.55950439e+02]
 [  5.94333313e+02]
 [  5.63559341e+00]
 [  2.11114600e+03]
 [  2.99740753e+02]
 [  2.30271103e+02]
 [  7.58367737e+02]
 [  1.04802643e+02]
 [  1.72479153e-01]
 [  1.13991138e+03]
 [  3.56217861e-01]]
DEBUG:root:training time = %d0.204642
INFO:root:frame =7289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =7290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame = 7291 State into memory, numbers recorded 187 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000571966171265
INFO:root:random_action_porb = 0.9827385
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7292current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000326156616211
INFO:root:frame =7293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000388145446777
INFO:root:frame =7294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 0.000284194946289
INFO:root:random_action_porb = 0.982729
DEBUG:root: dqn, choose action rondomly, need time 0.000408000000022
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000423908233643
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.40076675e+01]
 [  4.10298729e+01]
 [  4.67094116e+02]
 [  4.67094116e+02]
 [  2.35514297e+01]
 [  5.23728905e+01]
 [  6.95788940e+02]
 [  2.57885933e+01]
 [  3.38757286e+01]
 [  8.36750641e+01]
 [  6.98271301e+02]
 [  1.28276730e+00]
 [  8.08437561e+02]
 [  4.35322896e-03]
 [  5.26636620e+01]
 [  9.11807556e+02]]
DEBUG:root:training time = %d0.213561
INFO:root:frame =7297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =7298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00030517578125
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:random_action_porb = 0.9827195
DEBUG:root: dqn, choose action rondomly, need time 0.000202000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:frame =7301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000555038452148
INFO:root:frame =7302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000823974609375
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:random_action_porb = 0.98271
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.55766083e+02]
 [  2.32756958e+03]
 [  1.05950586e+05]
 [  9.05634689e+00]
 [  5.22860664e+04]
 [  9.48715744e+01]
 [  4.94291449e+00]
 [  1.37530701e+02]
 [  7.83393433e+02]
 [  1.09240389e+00]
 [  1.80497913e+01]
 [  2.07159717e+03]
 [  4.32126760e+00]
 [  4.33388623e+03]
 [  1.86694932e+00]
 [  2.43058456e+02]]
DEBUG:root:training time = %d0.218123
INFO:root:frame =7305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:frame =7306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame = 7307 State into memory, numbers recorded 188 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000580072402954
INFO:root:random_action_porb = 0.9827005
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000023
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7308current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =7309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000515937805176
INFO:root:frame =7310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.982691
DEBUG:root: dqn, choose action rondomly, need time 0.000457999999981
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.50799902e+04]
 [  3.36291656e+02]
 [  4.83803975e-04]
 [  9.13810669e+02]
 [  2.85610819e+00]
 [  5.45625992e+01]
 [  1.20023928e+01]
 [  1.50799902e+04]
 [  9.45013123e+02]
 [  8.72094360e+02]
 [  9.09233551e+01]
 [  2.97025490e+01]
 [  7.52143372e+02]
 [  2.14333420e+01]
 [  5.81886597e+02]
 [  1.20023928e+01]]
DEBUG:root:training time = %d0.203221
INFO:root:frame =7313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:frame =7314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255107879639
DEBUG:root: save sample needs time = 0.000111103057861
INFO:root:random_action_porb = 0.9826815
DEBUG:root: dqn, choose action rondomly, need time 0.000175000000013
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:frame =7317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000403881072998
INFO:root:frame =7318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame = 7319 State into memory, numbers recorded 189 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000286817550659
INFO:root:random_action_porb = 0.982672
DEBUG:root: dqn, choose action rondomly, need time 0.000157999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7320current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.12262893e+00]
 [  1.39469248e+04]
 [  7.36245850e+02]
 [  2.01613794e+03]
 [  1.07962618e+01]
 [  4.09552826e+02]
 [  7.64766884e+00]
 [  3.60495453e+01]
 [  3.48209961e+02]
 [  1.28137805e+03]
 [  4.02991829e+01]
 [  4.82293129e-01]
 [  2.13303280e+01]
 [  4.04383575e+02]
 [  1.11833687e+01]
 [  4.82293129e-01]]
DEBUG:root:training time = %d0.213238
INFO:root:frame =7321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =7322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:random_action_porb = 0.9826625
DEBUG:root: dqn, choose action rondomly, need time 0.000347000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =7325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =7326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.982653
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.06734955e+02]
 [  1.79934363e+03]
 [  1.14034777e+01]
 [  3.52823761e+02]
 [  9.86790588e+02]
 [  3.05661499e+02]
 [  3.43897152e+00]
 [  3.75557289e+01]
 [  1.92696625e+02]
 [  1.62371143e+04]
 [  1.20836220e+01]
 [  2.41621094e+01]
 [  1.67730350e+01]
 [  7.75310645e+03]
 [  8.18642151e+02]
 [  2.49961255e+03]]
DEBUG:root:training time = %d0.21018
INFO:root:frame =7329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =7330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247001647949
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.9826435
DEBUG:root: dqn, choose action rondomly, need time 0.000169
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000126838684082
INFO:root:frame =7333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =7334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame = 7335 State into memory, numbers recorded 190 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000566959381104
INFO:root:random_action_porb = 0.982634
DEBUG:root: dqn, choose action rondomly, need time 0.000326999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7336current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.76299531e+04]
 [  6.17545532e+02]
 [  7.34025345e+01]
 [  2.32945684e+04]
 [  8.15770215e+03]
 [  4.08391937e+02]
 [  1.48246622e+01]
 [  7.38129211e+02]
 [  4.12747070e+02]
 [  1.40197546e+03]
 [  1.72106385e+00]
 [  1.34373993e+02]
 [  1.49776550e+02]
 [  2.14700098e+03]
 [  2.54597583e+03]
 [  1.33030252e+01]]
DEBUG:root:training time = %d0.211389
INFO:root:frame =7337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =7338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9826245
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000433206558228
INFO:root:frame =7341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440835952759
INFO:root:frame =7342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.982615
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.96119938e+01]
 [  5.27629242e+01]
 [  4.73338013e+02]
 [  4.58040390e+01]
 [  9.45842171e+00]
 [  1.85960205e+03]
 [  1.13589246e+03]
 [  1.49414636e+03]
 [  2.73799438e+02]
 [  4.03538818e+01]
 [  1.60889908e+02]
 [  1.11675545e+02]
 [  9.91639648e+02]
 [  1.43361084e+04]
 [  2.78554306e+01]
 [  7.15358057e+03]]
DEBUG:root:training time = %d0.201124
INFO:root:frame =7345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =7346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000266075134277
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:random_action_porb = 0.9826055
DEBUG:root: dqn, choose action rondomly, need time 0.000191999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180959701538
INFO:root:frame =7349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472784042358
INFO:root:frame =7350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438213348389
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.982596
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000021
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  499.47299194]
 [  595.38201904]
 [  492.78414917]
 [   67.40759277]
 [  961.0189209 ]
 [   16.05204391]
 [ 1013.61242676]
 [  712.22186279]
 [  132.6257019 ]
 [    2.5909965 ]
 [   23.60640717]
 [  279.3923645 ]
 [  120.02293396]
 [  358.67977905]
 [  152.17944336]
 [   33.59478378]]
DEBUG:root:training time = %d0.214445
INFO:root:frame =7353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =7354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9825865
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =7357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =7358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame = 7359 State into memory, numbers recorded 191 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:random_action_porb = 0.982577
DEBUG:root: dqn, choose action rondomly, need time 0.000709999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7360current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000367879867554
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.08948708e+01]
 [  2.61360657e+02]
 [  7.69285278e+02]
 [  2.34486866e+01]
 [  4.61479706e+02]
 [  1.95500106e-01]
 [  8.68697510e+02]
 [  2.22462292e+01]
 [  3.95818604e+03]
 [  8.86692932e+02]
 [  6.95950745e+02]
 [  2.34486866e+01]
 [  1.66053821e+03]
 [  2.88840759e+02]
 [  1.95770055e-01]
 [  1.65355682e+02]]
DEBUG:root:training time = %d0.201847
INFO:root:frame =7361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =7362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame = 7363 State into memory, numbers recorded 192 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000581979751587
INFO:root:random_action_porb = 0.9825675
DEBUG:root: dqn, choose action rondomly, need time 0.000317999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7364current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =7365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame =7366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000535011291504
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.982558
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999986
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.46874404e-01]
 [  1.95952368e+00]
 [  5.01089249e+01]
 [  1.12659485e+03]
 [  4.09617676e+02]
 [  2.02789392e+03]
 [  5.34369583e+01]
 [  5.58494873e+01]
 [  2.35102024e+01]
 [  9.40630035e+01]
 [  2.25383263e+01]
 [  2.60915470e+00]
 [  1.05015114e+02]
 [  1.88672364e-01]
 [  6.38122705e+03]
 [  1.49268021e+02]]
DEBUG:root:training time = %d0.188021
INFO:root:frame =7369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =7370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
DEBUG:root: save sample needs time = 9.29832458496e-05
INFO:root:random_action_porb = 0.9825485
DEBUG:root: dqn, choose action rondomly, need time 0.000500999999986
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =7373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =7374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049090385437
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.982539
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000018
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.35914679e+01]
 [  3.31627136e+02]
 [  1.97402267e+02]
 [  1.12281647e+01]
 [  5.63185692e+01]
 [  2.11188721e+02]
 [  9.53664627e+01]
 [  2.08121729e+03]
 [  7.43099915e+02]
 [  4.25940666e+01]
 [  3.31627136e+02]
 [  1.53193497e+02]
 [  4.81676904e+03]
 [  1.55314133e+02]
 [  9.04415905e-01]
 [  2.42480957e+02]]
DEBUG:root:training time = %d0.211275
INFO:root:frame =7377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304222106934
INFO:root:frame =7378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271797180176
DEBUG:root: save sample needs time = 0.000253200531006
INFO:root:random_action_porb = 0.9825295
DEBUG:root: dqn, choose action rondomly, need time 0.000167000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:frame =7381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000357866287231
INFO:root:frame =7382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.98252
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.64685425e+03]
 [  1.52627441e+02]
 [  4.37583476e-01]
 [  1.65297031e+01]
 [  2.39905566e+03]
 [  1.65297031e+01]
 [  1.00194525e+03]
 [  3.07488670e+01]
 [  7.38066650e+03]
 [  6.00923584e+02]
 [  4.46540928e+00]
 [  8.05804059e-02]
 [  4.57528830e+00]
 [  2.89016991e+01]
 [  1.77776420e+00]
 [  2.44273560e+03]]
DEBUG:root:training time = %d0.211597
INFO:root:frame =7385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:frame =7386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9825105
DEBUG:root: dqn, choose action rondomly, need time 0.000169
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:frame =7389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =7390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.982501
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000358104705811
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.23021102e+00]
 [  4.89986359e+02]
 [  2.23363257e+03]
 [  1.19624463e+03]
 [  1.49305429e+01]
 [  3.71853394e+02]
 [  1.37613989e+03]
 [  3.30459862e+01]
 [  1.18037069e+00]
 [  2.33499527e+02]
 [  2.00461761e+02]
 [  6.75724072e+03]
 [  1.59765833e+03]
 [  6.83282837e+02]
 [  6.21336230e+03]
 [  2.23363257e+03]]
DEBUG:root:training time = %d0.216123
INFO:root:frame =7393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000377893447876
INFO:root:frame =7394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
DEBUG:root: save sample needs time = 0.00011420249939
INFO:root:random_action_porb = 0.9824915
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304222106934
INFO:root:frame =7397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =7398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.982482
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.99310791e-01]
 [  8.19857597e+00]
 [  9.94123828e+03]
 [  3.04055424e+01]
 [  1.04288311e+01]
 [  8.32896423e+01]
 [  5.08768738e+02]
 [  1.80276928e+01]
 [  2.42997131e+01]
 [  1.43084119e+03]
 [  9.65904694e+01]
 [  6.54057383e+04]
 [  3.52388770e+03]
 [  4.62831497e+00]
 [  8.62791672e+01]
 [  1.73348867e+04]]
DEBUG:root:training time = %d0.202918
INFO:root:frame =7401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000331163406372
INFO:root:frame =7402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488996505737
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.9824725
DEBUG:root: dqn, choose action rondomly, need time 0.00018399999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:frame =7405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =7406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.982463
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.22884476e+02]
 [  3.04327750e+00]
 [  6.61312256e+02]
 [  1.22884476e+02]
 [  1.95814514e+02]
 [  1.95814514e+02]
 [  3.71907258e+00]
 [  1.11544967e+00]
 [  1.97423599e+02]
 [  8.06787598e+02]
 [  1.54491272e+03]
 [  4.52460498e+03]
 [  8.03671533e+03]
 [  6.13521729e+02]
 [  2.07255347e+03]
 [  2.64325513e+03]]
DEBUG:root:training time = %d0.210445
INFO:root:frame =7409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =7410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000258922576904
DEBUG:root: save sample needs time = 9.91821289062e-05
INFO:root:random_action_porb = 0.9824535
DEBUG:root: dqn, choose action rondomly, need time 0.00032299999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =7413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =7414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.982444
DEBUG:root: dqn, choose action rondomly, need time 0.000231000000014
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.68350830e+01]
 [  4.58496735e+02]
 [  8.96384430e+01]
 [  2.42474547e-04]
 [  9.66660645e+03]
 [  6.68480408e+02]
 [  2.42474547e-04]
 [  1.12738159e+03]
 [  7.42929932e+02]
 [  1.08963661e+01]
 [  1.03588098e+03]
 [  6.84358582e+02]
 [  7.61534607e+02]
 [  3.84450409e+02]
 [  3.95903467e+03]
 [  4.20167725e+02]]
DEBUG:root:training time = %d0.19715
INFO:root:frame =7417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:frame =7418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00036096572876
DEBUG:root: save sample needs time = 0.000141859054565
INFO:root:random_action_porb = 0.9824345
INFO:root:dqn select action Tensor("ArgMax_20:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012324
INFO:root:action choosen by dqn [2]
INFO:root:frame =7420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:frame =7421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =7422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049090385437
INFO:root:frame = 7423 State into memory, numbers recorded 193 action = [2], reward = 0
DEBUG:root: save sample needs time = 0.00121998786926
INFO:root:random_action_porb = 0.982425
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7424current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.60457886e+02]
 [  2.12802994e+02]
 [  1.15851336e+01]
 [  6.61826630e+01]
 [  1.77900553e+00]
 [  1.37676601e+01]
 [  7.04901978e+02]
 [  8.41565735e+02]
 [  1.77900553e+00]
 [  2.10350488e+03]
 [  2.94777781e-01]
 [  6.67930969e+02]
 [  4.95607529e+01]
 [  3.35026436e+01]
 [  8.41565735e+02]
 [  4.95021057e+00]]
DEBUG:root:training time = %d0.206645
INFO:root:frame =7425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:frame =7426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9824155
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =7429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =7430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:random_action_porb = 0.982406
DEBUG:root: dqn, choose action rondomly, need time 0.00034500000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000595092773438
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.80724780e+03]
 [  1.48019934e+03]
 [  2.80724780e+03]
 [  4.46797066e+01]
 [  7.37460279e+00]
 [  2.29162354e+02]
 [  5.52780457e+02]
 [  2.62576874e+02]
 [  2.06194775e+03]
 [  3.72192740e+00]
 [  1.85919647e+01]
 [  3.03667240e+01]
 [  1.42654037e+02]
 [  1.82084835e+00]
 [  2.34822876e+03]
 [  3.95386910e+00]]
DEBUG:root:training time = %d0.201394
INFO:root:frame =7433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =7434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049090385437
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:random_action_porb = 0.9823965
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =7437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000480890274048
INFO:root:frame =7438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.982387
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.81848839e-01]
 [  2.19099030e+02]
 [  9.63604797e+02]
 [  8.75716248e+01]
 [  1.81848839e-01]
 [  8.07218704e+01]
 [  3.42108307e+02]
 [  4.73019012e+02]
 [  8.80912876e+00]
 [  1.61928308e+00]
 [  1.33344324e+03]
 [  6.94434214e+00]
 [  4.90524578e+00]
 [  2.24621563e+01]
 [  5.50060425e+02]
 [  3.83990097e+01]]
DEBUG:root:training time = %d0.191955
INFO:root:frame =7441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =7442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.9823775
DEBUG:root: dqn, choose action rondomly, need time 0.000171999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:frame =7445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =7446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.982368
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:training error  = [[  3.82082415e+00]
 [  5.70941687e+00]
 [  2.48737311e+00]
 [  4.30486832e+01]
 [  2.62137241e+01]
 [  6.88217529e+03]
 [  2.63289280e+01]
 [  8.53949356e+00]
 [  1.37403320e+02]
 [  2.03631177e+03]
 [  2.34782886e+03]
 [  3.04496813e+00]
 [  1.67175247e+02]
 [  3.80840378e+01]
 [  5.98897583e+02]
 [  2.15347433e+00]]
DEBUG:root:training time = %d0.204881
INFO:root:frame =7449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:frame =7450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9823585
DEBUG:root: dqn, choose action rondomly, need time 0.000250999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =7453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:frame =7454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.982349
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00037407875061
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.43325078e-01]
 [  2.91967194e+02]
 [  2.73515106e+02]
 [  1.81418860e+03]
 [  6.36206818e+01]
 [  5.46984375e+02]
 [  9.91509705e+02]
 [  1.16061363e+02]
 [  9.45404602e+02]
 [  1.54275055e+01]
 [  3.16385651e+01]
 [  4.34498535e+03]
 [  1.81418860e+03]
 [  1.81418860e+03]
 [  1.70450806e+02]
 [  4.18428906e+03]]
DEBUG:root:training time = %d0.211251
INFO:root:frame =7457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =7458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame = 7459 State into memory, numbers recorded 194 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000566959381104
INFO:root:random_action_porb = 0.9823395
DEBUG:root: dqn, choose action rondomly, need time 0.000167000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7460current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:frame =7461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470161437988
INFO:root:frame =7462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488996505737
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.98233
DEBUG:root: dqn, choose action rondomly, need time 0.000178000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:training error  = [[  5.65164723e-04]
 [  4.63312912e+01]
 [  6.90930939e+01]
 [  1.38543365e+02]
 [  3.50164001e+02]
 [  2.54723877e+02]
 [  5.21742920e+02]
 [  7.35203648e+00]
 [  5.42455078e+02]
 [  1.67903046e+02]
 [  4.68769169e+00]
 [  2.77983418e+01]
 [  5.21742920e+02]
 [  3.87426758e+02]
 [  3.61019135e+02]
 [  5.10388613e-02]]
DEBUG:root:training time = %d0.192167
INFO:root:frame =7465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =7466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456809997559
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root:random_action_porb = 0.9823205
DEBUG:root: dqn, choose action rondomly, need time 0.000236000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =7469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000502109527588
INFO:root:frame =7470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.982311
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.23949957e+01]
 [  2.43697357e+00]
 [  7.03504089e+02]
 [  2.03076668e+01]
 [  4.94426056e+02]
 [  3.30660828e+02]
 [  1.94055756e+02]
 [  5.63889008e+01]
 [  1.02167496e+02]
 [  2.96547217e+03]
 [  8.61254578e+01]
 [  8.91154957e+00]
 [  1.30860329e+01]
 [  7.13671446e+00]
 [  1.12704115e+01]
 [  1.54549438e+02]]
DEBUG:root:training time = %d0.219521
INFO:root:frame =7473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:frame =7474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000342845916748
DEBUG:root: save sample needs time = 0.000180006027222
INFO:root:random_action_porb = 0.9823015
DEBUG:root: dqn, choose action rondomly, need time 0.000330000000019
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =7477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =7478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000495910644531
INFO:root:frame = 7479 State into memory, numbers recorded 195 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000595092773438
INFO:root:random_action_porb = 0.982292
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7480current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   49.79294586]
 [  195.80137634]
 [ 2624.99389648]
 [  157.06864929]
 [   29.19475746]
 [  427.26586914]
 [   34.53911591]
 [   13.15813732]
 [   55.71204758]
 [   13.15813732]
 [    3.04721832]
 [  282.17462158]
 [   11.59653664]
 [  156.12295532]
 [ 1013.0057373 ]
 [ 2660.9909668 ]]
DEBUG:root:training time = %d0.207767
INFO:root:frame =7481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =7482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00022292137146
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.9822825
DEBUG:root: dqn, choose action rondomly, need time 0.000184999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:frame =7485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =7486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00036096572876
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.982273
DEBUG:root: dqn, choose action rondomly, need time 0.000192999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.06194482e+03]
 [  8.17454243e+00]
 [  7.16910400e+01]
 [  1.11399174e+00]
 [  1.66151142e+01]
 [  2.93482147e+02]
 [  7.16910400e+01]
 [  1.36503860e+02]
 [  2.00515327e+01]
 [  2.05216904e+02]
 [  5.88857666e+03]
 [  3.13088298e+00]
 [  7.94421265e+02]
 [  1.85323914e+02]
 [  1.61381384e+03]
 [  1.57760441e+00]]
DEBUG:root:training time = %d0.192875
INFO:root:frame =7489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =7490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000357866287231
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9822635
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =7493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00051212310791
INFO:root:frame =7494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000451803207397
DEBUG:root: save sample needs time = 0.000104904174805
INFO:root:random_action_porb = 0.982254
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.11866522e+00]
 [  7.11019043e+02]
 [  5.85823059e+00]
 [  5.27038757e+02]
 [  1.36188774e+01]
 [  9.35475311e+01]
 [  2.46583343e+00]
 [  2.82264673e+03]
 [  2.76785620e+03]
 [  5.86862946e+01]
 [  2.46094246e+01]
 [  1.02132217e+02]
 [  1.36834228e+00]
 [  1.69645863e+01]
 [  1.40035217e+03]
 [  3.68839996e+02]]
DEBUG:root:training time = %d0.199506
INFO:root:frame =7497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =7498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9822445
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =7501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =7502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.982235
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.35499527e+02]
 [  6.27789497e-01]
 [  1.29166842e+01]
 [  1.22207466e+02]
 [  4.37095520e+02]
 [  6.56945631e-04]
 [  1.38305768e-03]
 [  1.86627136e+03]
 [  1.21304329e+02]
 [  1.18746006e+00]
 [  2.78473663e+02]
 [  3.18961090e+02]
 [  3.84105444e-01]
 [  1.07059793e+01]
 [  6.49329710e+00]
 [  7.75900793e+00]]
DEBUG:root:training time = %d0.203159
INFO:root:frame =7505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =7506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9822255
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =7509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =7510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000646114349365
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.982216
DEBUG:root: dqn, choose action rondomly, need time 0.000781999999987
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.34595044e+03]
 [  1.93137729e+00]
 [  5.95071602e+01]
 [  5.79400512e-04]
 [  3.51433716e+01]
 [  9.62284241e+02]
 [  1.63127905e+03]
 [  6.26416063e+00]
 [  9.47247863e-01]
 [  5.46484985e+02]
 [  3.00183147e-01]
 [  3.18334076e+02]
 [  1.77339268e+00]
 [  2.08062842e+03]
 [  6.66373291e+02]
 [  9.03812599e+00]]
DEBUG:root:training time = %d0.219229
INFO:root:frame =7513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:frame =7514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame = 7515 State into memory, numbers recorded 196 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00065803527832
INFO:root:random_action_porb = 0.9822065
DEBUG:root: dqn, choose action rondomly, need time 0.000204999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7516current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:frame =7517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =7518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.982197
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.16913110e+03]
 [  2.15622807e+01]
 [  5.97960701e+01]
 [  2.33498413e+02]
 [  8.60525436e+01]
 [  3.31350983e+02]
 [  6.96542788e+00]
 [  1.23287926e+01]
 [  2.91153383e+00]
 [  2.15622807e+01]
 [  7.99027939e+01]
 [  8.96058369e+00]
 [  8.91165257e-01]
 [  3.39824371e+02]
 [  2.54548931e+00]
 [  1.68258190e+01]]
DEBUG:root:training time = %d0.198287
INFO:root:frame =7521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:frame =7522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000555992126465
INFO:root:frame = 7523 State into memory, numbers recorded 197 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000541925430298
INFO:root:random_action_porb = 0.9821875
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000018
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7524current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =7525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =7526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480890274048
DEBUG:root: save sample needs time = 0.000126838684082
INFO:root:random_action_porb = 0.982178
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.57192236e+03]
 [  1.65295792e+01]
 [  1.68212509e+01]
 [  6.72876587e+02]
 [  3.64240319e-01]
 [  8.62034058e+02]
 [  5.27626762e+01]
 [  7.63246441e+00]
 [  1.02222150e+03]
 [  1.62807617e+01]
 [  5.67491493e+01]
 [  2.74779480e+02]
 [  1.31826043e+00]
 [  1.14534325e+02]
 [  1.12089481e+01]
 [  2.15489273e+01]]
DEBUG:root:training time = %d0.207124
INFO:root:frame =7529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =7530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 0.000104904174805
INFO:root:random_action_porb = 0.9821685
DEBUG:root: dqn, choose action rondomly, need time 0.000349
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =7533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =7534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509023666382
DEBUG:root: save sample needs time = 0.000251770019531
INFO:root:random_action_porb = 0.982159
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.82454639e+03]
 [  1.20045670e+02]
 [  5.89896851e+02]
 [  1.49070272e+01]
 [  1.01144612e-02]
 [  1.08169604e+03]
 [  2.33446660e+04]
 [  1.18673108e+03]
 [  5.78717285e+02]
 [  9.63293152e+02]
 [  2.23889017e+00]
 [  5.49834351e+02]
 [  2.23889017e+00]
 [  4.93607422e+03]
 [  3.69674206e+00]
 [  5.22573929e+01]]
DEBUG:root:training time = %d0.202816
INFO:root:frame =7537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:frame =7538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:random_action_porb = 0.9821495
DEBUG:root: dqn, choose action rondomly, need time 0.000326999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =7541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =7542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.98214
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.15723305e+02]
 [  6.54960394e+00]
 [  6.75836182e+02]
 [  7.72982275e+03]
 [  2.76520550e-01]
 [  4.27612257e+00]
 [  1.07000842e+03]
 [  1.82947128e+02]
 [  3.94081573e+01]
 [  5.56608086e+01]
 [  4.06463550e+03]
 [  3.35105934e+01]
 [  5.67424365e+03]
 [  3.30731163e+01]
 [  4.96965668e+02]
 [  1.02690514e+02]]
DEBUG:root:training time = %d0.199446
INFO:root:frame =7545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =7546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000355958938599
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9821305
DEBUG:root: dqn, choose action rondomly, need time 0.000455000000017
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000397205352783
INFO:root:frame =7549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000377893447876
INFO:root:frame =7550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.982121
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   1.78956342]
 [ 461.44134521]
 [ 493.23693848]
 [ 348.07131958]
 [ 586.68719482]
 [  20.92143631]
 [  39.27880478]
 [  13.21434975]
 [ 226.26324463]
 [  69.12644958]
 [  28.21933365]
 [ 208.39382935]
 [ 149.99801636]
 [ 448.5395813 ]
 [  40.03995132]
 [ 265.33056641]]
DEBUG:root:training time = %d0.197569
INFO:root:frame =7553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240802764893
INFO:root:frame =7554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000362873077393
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9821115
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000327825546265
INFO:root:frame =7557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00053882598877
INFO:root:frame =7558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488042831421
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.982102
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.35457754e+00]
 [  4.14799805e+03]
 [  1.84576035e+02]
 [  1.98392517e+02]
 [  1.89797544e+00]
 [  3.96849945e+02]
 [  2.08144547e+02]
 [  1.64174824e+01]
 [  1.27843896e+03]
 [  1.65943201e+03]
 [  8.58280087e+00]
 [  1.99536108e+03]
 [  1.01662341e+03]
 [  5.03211021e+00]
 [  1.10742321e+01]
 [  2.49194489e+02]]
DEBUG:root:training time = %d0.205862
INFO:root:frame =7561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:frame =7562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame = 7563 State into memory, numbers recorded 198 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000571012496948
INFO:root:random_action_porb = 0.9820925
DEBUG:root: dqn, choose action rondomly, need time 0.000383999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7564current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000507831573486
INFO:root:frame =7565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =7566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286817550659
DEBUG:root: save sample needs time = 0.000126838684082
INFO:root:random_action_porb = 0.982083
DEBUG:root: dqn, choose action rondomly, need time 0.000209999999981
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:training error  = [[  1.97742105e+00]
 [  2.84614010e+01]
 [  3.40434052e+02]
 [  6.96527634e+01]
 [  7.35280212e+02]
 [  5.90364990e+01]
 [  1.33991113e+03]
 [  4.96677494e+00]
 [  1.45391098e+02]
 [  1.23436356e+00]
 [  2.63561039e+01]
 [  1.49392109e+01]
 [  7.08878052e+02]
 [  7.86766815e+01]
 [  9.26476669e+00]
 [  1.33991113e+03]]
DEBUG:root:training time = %d0.193134
INFO:root:frame =7569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000392198562622
INFO:root:frame =7570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000276803970337
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.9820735
DEBUG:root: dqn, choose action rondomly, need time 0.000191000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174045562744
INFO:root:frame =7573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =7574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446796417236
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.982064
DEBUG:root: dqn, choose action rondomly, need time 0.000343000000015
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.13651611e+03]
 [  4.79133315e-02]
 [  7.38399124e+00]
 [  1.16662549e+03]
 [  2.17232452e+02]
 [  1.05750069e+02]
 [  9.67552722e-01]
 [  4.39733047e+01]
 [  1.58855811e-01]
 [  2.60223341e+00]
 [  2.16081381e+00]
 [  1.02225380e+02]
 [  1.23825893e+01]
 [  2.22952530e+02]
 [  3.13651611e+03]
 [  1.53320160e+02]]
DEBUG:root:training time = %d0.198278
INFO:root:frame =7577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =7578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame = 7579 State into memory, numbers recorded 199 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000391960144043
INFO:root:random_action_porb = 0.9820545
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7580current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000404119491577
INFO:root:frame =7581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000524997711182
INFO:root:frame =7582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame = 7583 State into memory, numbers recorded 200 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000602006912231
INFO:root:random_action_porb = 0.982045
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7584current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.13415995e-02]
 [  2.73189423e+02]
 [  1.88453045e+01]
 [  6.65422058e+02]
 [  3.73284197e+00]
 [  1.80024475e+03]
 [  1.18777494e+01]
 [  3.44406676e+00]
 [  3.00870304e+01]
 [  6.57639465e+01]
 [  7.38337860e+01]
 [  1.94231415e+01]
 [  1.35210724e+01]
 [  1.58850525e+02]
 [  1.44724869e+02]
 [  1.62589157e+00]]
DEBUG:root:training time = %d0.208617
INFO:root:frame =7585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =7586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.9820355
DEBUG:root: dqn, choose action rondomly, need time 0.000178999999974
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:frame =7589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =7590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000576972961426
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.982026
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000418901443481
INFO:root:training error  = [[  5.86409283e+00]
 [  4.88848066e+00]
 [  7.06580058e-02]
 [  1.02415752e+04]
 [  2.60572982e+00]
 [  2.60572982e+00]
 [  2.53926888e+01]
 [  3.25228210e+02]
 [  6.48101616e+00]
 [  4.98310272e+02]
 [  9.56913208e+02]
 [  8.30543976e+01]
 [  5.29901619e+01]
 [  1.54018890e+02]
 [  8.00325000e+03]
 [  1.17673303e+03]]
DEBUG:root:training time = %d0.201387
INFO:root:frame =7593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =7594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000312089920044
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.9820165
DEBUG:root: dqn, choose action rondomly, need time 0.000360999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =7597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471115112305
INFO:root:frame =7598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000597953796387
DEBUG:root: save sample needs time = 0.000281810760498
INFO:root:random_action_porb = 0.982007
DEBUG:root: dqn, choose action rondomly, need time 0.000161999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 172.98815918]
 [   9.14099026]
 [  10.53296471]
 [ 100.80862427]
 [ 975.69055176]
 [ 142.0198822 ]
 [  27.23121071]
 [  25.36009789]
 [   1.45490837]
 [  38.98986435]
 [  19.94068909]
 [  38.98986435]
 [  29.8572216 ]
 [ 649.53656006]
 [ 352.81588745]
 [  88.28015137]]
DEBUG:root:training time = %d0.196374
INFO:root:frame =7601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =7602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:random_action_porb = 0.9819975
DEBUG:root: dqn, choose action rondomly, need time 0.000319999999988
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000356912612915
INFO:root:frame =7605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =7606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000536918640137
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.981988
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.41162427e+03]
 [  2.06320776e+03]
 [  4.89098936e-01]
 [  8.09846191e+01]
 [  6.60287704e+01]
 [  5.68655357e+01]
 [  4.89098936e-01]
 [  2.29414368e+02]
 [  2.90482693e+01]
 [  1.52737532e+01]
 [  1.26508291e+04]
 [  1.18424365e+03]
 [  1.94933777e+01]
 [  1.40107925e+02]
 [  6.06604614e+01]
 [  2.41162427e+03]]
DEBUG:root:training time = %d0.214706
INFO:root:frame =7609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =7610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9819785
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =7613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =7614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.981969
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.61742859e+01]
 [  2.66554089e+01]
 [  1.41389143e+00]
 [  2.85196838e+02]
 [  3.01699097e+02]
 [  6.37886963e+02]
 [  9.93103516e+03]
 [  4.30143509e+01]
 [  1.79696035e+00]
 [  9.93103516e+03]
 [  1.12780404e+00]
 [  6.78471527e+01]
 [  3.67342285e+02]
 [  3.25209625e+02]
 [  1.00527344e+01]
 [  6.36688888e-01]]
DEBUG:root:training time = %d0.209809
INFO:root:frame =7617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =7618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000401973724365
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:random_action_porb = 0.9819595
DEBUG:root: dqn, choose action rondomly, need time 0.000235000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000187158584595
INFO:root:frame =7621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000482082366943
INFO:root:frame =7622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.98195
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000021
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.11779816e+02]
 [  6.71810303e+01]
 [  2.65508919e+01]
 [  1.39905750e+03]
 [  1.07493767e+02]
 [  3.67570734e+00]
 [  1.66084824e+02]
 [  4.21887255e+00]
 [  9.61755905e+01]
 [  4.90218468e+01]
 [  3.52212085e+03]
 [  3.31198578e+01]
 [  2.58496895e+01]
 [  4.05960754e-02]
 [  6.24359274e+00]
 [  3.83620491e+01]]
DEBUG:root:training time = %d0.199008
INFO:root:frame =7625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:frame =7626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000219821929932
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root:random_action_porb = 0.9819405
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =7629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =7630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430822372437
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.981931
DEBUG:root: dqn, choose action rondomly, need time 0.000265000000013
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  190.26535034]
 [  347.68597412]
 [  125.04649353]
 [  239.65861511]
 [  955.10479736]
 [  149.60209656]
 [ 3932.88378906]
 [  621.91693115]
 [   15.51772785]
 [  955.10479736]
 [  486.67041016]
 [ 2141.15087891]
 [ 1098.34753418]
 [ 3031.09326172]
 [   30.1448307 ]
 [   20.03749466]]
DEBUG:root:training time = %d0.221857
INFO:root:frame =7633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =7634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000258922576904
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:random_action_porb = 0.9819215
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =7637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =7638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.981912
DEBUG:root: dqn, choose action rondomly, need time 0.000461000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.76258926e+01]
 [  8.74856873e+01]
 [  1.56813635e+03]
 [  6.04782343e+00]
 [  1.97668076e-02]
 [  4.95681648e+01]
 [  1.00554657e+00]
 [  6.61970642e+02]
 [  6.31425110e+02]
 [  4.72533531e+01]
 [  1.50667553e+01]
 [  3.22729309e+02]
 [  8.86028671e+01]
 [  3.77450806e+02]
 [  3.68304482e+01]
 [  8.74856873e+01]]
DEBUG:root:training time = %d0.206242
INFO:root:frame =7641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000373125076294
INFO:root:frame =7642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042986869812
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9819025
DEBUG:root: dqn, choose action rondomly, need time 0.000347000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:frame =7645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =7646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.981893
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.26616113e+03]
 [  4.90600586e+00]
 [  1.19836864e+01]
 [  1.48307431e+00]
 [  1.36335098e+02]
 [  7.73875977e+02]
 [  2.70558289e+02]
 [  1.48307431e+00]
 [  1.12266736e+03]
 [  7.16289355e+03]
 [  3.91742889e+02]
 [  1.19836864e+01]
 [  4.84032571e-01]
 [  6.59566284e+02]
 [  1.79156845e+02]
 [  8.63143921e+02]]
DEBUG:root:training time = %d0.199065
INFO:root:frame =7649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:frame =7650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9818835
DEBUG:root: dqn, choose action rondomly, need time 0.000196999999986
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root:frame =7653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456809997559
INFO:root:frame =7654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000627994537354
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.981874
DEBUG:root: dqn, choose action rondomly, need time 0.000346000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.07801843e+03]
 [  4.10615463e+01]
 [  4.86784935e+01]
 [  3.39471221e-01]
 [  1.86558723e+01]
 [  2.68902254e+00]
 [  1.38912378e+03]
 [  1.82636375e+01]
 [  4.23885101e+02]
 [  8.39992737e+02]
 [  2.95171547e+00]
 [  4.56882965e+02]
 [  3.54342896e+02]
 [  3.28935127e+01]
 [  8.82816895e+02]
 [  2.98138390e+01]]
DEBUG:root:training time = %d0.195409
INFO:root:frame =7657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =7658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000680208206177
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.9818645
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =7661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root:frame =7662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:random_action_porb = 0.981855
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.26993980e+01]
 [  1.25409683e+02]
 [  3.47511635e+01]
 [  8.28314960e-01]
 [  1.37327316e+02]
 [  1.92945221e+02]
 [  9.34693222e+01]
 [  1.87624365e+03]
 [  1.35927051e-01]
 [  3.12570810e+00]
 [  1.80888462e+00]
 [  1.18189140e+02]
 [  1.53823547e+03]
 [  1.35927051e-01]
 [  1.22347343e+02]
 [  1.37327316e+02]]
DEBUG:root:training time = %d0.215986
INFO:root:frame =7665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000320196151733
INFO:root:frame =7666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:random_action_porb = 0.9818455
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =7669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =7670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.981836
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:training error  = [[  9.89924812e+00]
 [  1.18276825e+02]
 [  7.97877991e+02]
 [  1.96004410e+01]
 [  4.25397110e+01]
 [  4.25397110e+01]
 [  7.92213440e+00]
 [  4.46266937e+00]
 [  2.93406519e+03]
 [  2.57145673e-01]
 [  2.93406519e+03]
 [  6.78539490e+02]
 [  4.18052063e+01]
 [  5.14410973e+01]
 [  1.82835315e+03]
 [  1.00299294e+02]]
DEBUG:root:training time = %d0.203403
INFO:root:frame =7673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =7674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9818265
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =7677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000624895095825
INFO:root:frame =7678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275135040283
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.981817
DEBUG:root: dqn, choose action rondomly, need time 0.000562000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:training error  = [[  3.85060382e+00]
 [  2.07322264e+00]
 [  5.39709961e+02]
 [  2.18318939e+00]
 [  6.12251465e+03]
 [  3.94994690e+02]
 [  5.17024994e+01]
 [  1.78709440e-02]
 [  1.29830215e+04]
 [  9.25999329e+02]
 [  1.19898148e+01]
 [  1.95980554e+03]
 [  1.22567359e-02]
 [  1.75713150e+02]
 [  3.92360687e+01]
 [  5.17024994e+01]]
DEBUG:root:training time = %d0.22351
INFO:root:frame =7681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:frame =7682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234842300415
DEBUG:root: save sample needs time = 9.91821289062e-05
INFO:root:random_action_porb = 0.9818075
DEBUG:root: dqn, choose action rondomly, need time 0.000158999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000141143798828
INFO:root:frame =7685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =7686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000242948532104
DEBUG:root: save sample needs time = 0.000120878219604
INFO:root:random_action_porb = 0.981798
DEBUG:root: dqn, choose action rondomly, need time 0.000192999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:training error  = [[  7.04256653e+02]
 [  1.13541937e+01]
 [  3.28347754e+03]
 [  3.30146606e+02]
 [  6.92013651e-04]
 [  4.01493721e+01]
 [  2.46577797e+01]
 [  4.22614453e+03]
 [  1.74027901e+01]
 [  9.04804321e+02]
 [  2.71186066e+02]
 [  1.51701752e+02]
 [  1.63550369e+02]
 [  3.16055664e+02]
 [  1.40675098e+03]
 [  1.51975525e+02]]
DEBUG:root:training time = %d0.222907
INFO:root:frame =7689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000400066375732
INFO:root:frame =7690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9817885
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =7693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =7694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.981779
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.33454390e+01]
 [  7.57583740e+02]
 [  1.16320419e+02]
 [  8.85923615e+01]
 [  4.34128685e+01]
 [  7.02473211e+00]
 [  5.56471191e+02]
 [  2.95272736e+02]
 [  1.17072558e+00]
 [  4.84999561e+00]
 [  8.85923615e+01]
 [  4.26190376e+00]
 [  5.82183472e+02]
 [  1.18006408e+00]
 [  1.94906831e-01]
 [  4.34128685e+01]]
DEBUG:root:training time = %d0.203239
INFO:root:frame =7697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =7698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:random_action_porb = 0.9817695
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =7701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000547885894775
INFO:root:frame =7702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000710964202881
DEBUG:root: save sample needs time = 0.000179052352905
INFO:root:random_action_porb = 0.98176
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.63485474e+02]
 [  5.53995544e+02]
 [  5.47929993e+01]
 [  8.89148331e+01]
 [  1.91599891e-01]
 [  6.06107979e+01]
 [  4.42208086e+04]
 [  3.97781396e+00]
 [  9.88212776e+00]
 [  1.01990059e-01]
 [  2.88515987e+01]
 [  1.26248215e+02]
 [  1.08835144e+02]
 [  3.54742241e+01]
 [  1.05718396e+03]
 [  2.67434967e+02]]
DEBUG:root:training time = %d0.20181
INFO:root:frame =7705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000347852706909
INFO:root:frame =7706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288009643555
DEBUG:root: save sample needs time = 0.000259160995483
INFO:root:random_action_porb = 0.9817505
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =7709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =7710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000607013702393
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.981741
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.15554161e+01]
 [  1.27228451e+01]
 [  3.73195465e+02]
 [  5.07707764e+03]
 [  1.26454720e+02]
 [  5.86018066e+02]
 [  8.77819419e-01]
 [  6.20605225e+02]
 [  5.16529907e+02]
 [  3.73195465e+02]
 [  8.13093872e+01]
 [  1.42917871e+04]
 [  4.99936371e+02]
 [  7.77752930e+02]
 [  2.22814926e+02]
 [  1.10678967e+03]]
DEBUG:root:training time = %d0.206568
INFO:root: ememy has been killed for 16 times 
INFO:root:enemies_left [0]
INFO:root:frame =7713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000209808349609
INFO:root:frame =7714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame = 7715 State into memory, numbers recorded 201 action = 2, reward = 255
DEBUG:root: save sample needs time = 0.000514030456543
INFO:root:random_action_porb = 0.9817315
DEBUG:root: dqn, choose action rondomly, need time 0.000335000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7716current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =7717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root:frame =7718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482082366943
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.981722
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000019
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.60246677e+01]
 [  3.60691895e+02]
 [  1.14920059e+02]
 [  2.36459610e+02]
 [  2.94392675e-01]
 [  5.43610878e+01]
 [  6.00272461e+02]
 [  8.20268262e+03]
 [  7.11408844e+01]
 [  1.96076012e+01]
 [  1.96076012e+01]
 [  7.58248711e+00]
 [  3.30234802e+02]
 [  3.49234543e+01]
 [  1.33374023e+02]
 [  3.42040436e+02]]
DEBUG:root:training time = %d0.225224
INFO:root:frame =7721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =7722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491142272949
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9817125
DEBUG:root: dqn, choose action rondomly, need time 0.000180999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142812728882
INFO:root:frame =7725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000475883483887
INFO:root:frame =7726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000238180160522
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.981703
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.01493909e+03]
 [  4.71333027e+00]
 [  3.35890228e+02]
 [  6.88458801e+02]
 [  1.73705475e+02]
 [  1.37199500e+03]
 [  1.47540747e+03]
 [  2.30420135e+02]
 [  6.10695312e+02]
 [  2.20906030e+03]
 [  5.00982788e+02]
 [  1.81967578e+04]
 [  7.67250748e+01]
 [  5.77783020e+02]
 [  5.52833557e+02]
 [  1.10206749e+02]]
DEBUG:root:training time = %d0.193625
INFO:root:frame =7729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:frame =7730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229120254517
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.9816935
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =7733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =7734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000415086746216
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.981684
DEBUG:root: dqn, choose action rondomly, need time 0.000180999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.31448221e+00]
 [  7.79025781e+03]
 [  3.55184975e+01]
 [  3.04875824e+02]
 [  1.73269806e+01]
 [  7.73254211e+02]
 [  8.05097961e+01]
 [  7.73254211e+02]
 [  4.26054907e+00]
 [  1.19088806e+03]
 [  7.47219043e+03]
 [  1.09627716e+02]
 [  5.51346008e+02]
 [  8.18580246e+01]
 [  3.78443665e+02]
 [  9.50776005e+00]]
DEBUG:root:training time = %d0.195564
INFO:root:frame =7737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =7738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 0.000168085098267
INFO:root:random_action_porb = 0.9816745
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =7741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =7742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:random_action_porb = 0.981665
DEBUG:root: dqn, choose action rondomly, need time 0.000336000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000424146652222
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.83955116e+01]
 [  2.02653160e+01]
 [  5.32564209e+02]
 [  1.55267358e+00]
 [  1.49075699e+02]
 [  3.88048462e+02]
 [  5.03418579e+01]
 [  1.75652786e+02]
 [  3.72124146e+02]
 [  1.65494227e+00]
 [  1.31631302e+02]
 [  3.09964081e+02]
 [  1.31631302e+02]
 [  1.14090100e+03]
 [  3.29417953e+01]
 [  7.41269336e+03]]
DEBUG:root:training time = %d0.212736
INFO:root:frame =7745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =7746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324964523315
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:random_action_porb = 0.9816555
DEBUG:root: dqn, choose action rondomly, need time 0.000320999999985
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331163406372
INFO:root:frame =7749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =7750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:random_action_porb = 0.981646
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000416040420532
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.67365980e+00]
 [  6.40331497e+01]
 [  6.54011774e+00]
 [  2.20383663e+01]
 [  6.10445679e+02]
 [  8.50350876e+01]
 [  3.89460022e+02]
 [  7.55193253e+01]
 [  9.55399170e+01]
 [  3.67628441e+01]
 [  1.53533374e+03]
 [  1.73634853e+01]
 [  9.88143387e+01]
 [  9.00729614e+02]
 [  2.02202153e+00]
 [  2.26823389e+03]]
DEBUG:root:training time = %d0.213016
INFO:root:frame =7753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =7754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9816365
DEBUG:root: dqn, choose action rondomly, need time 0.000159000000025
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =7757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =7758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:random_action_porb = 0.981627
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.77589297e+00]
 [  5.91834290e+02]
 [  3.18771179e+02]
 [  1.25858974e+01]
 [  2.85509247e+02]
 [  2.14645340e+02]
 [  4.71517677e+01]
 [  5.82081909e+02]
 [  2.90542316e+01]
 [  6.46440659e+01]
 [  1.91695423e+01]
 [  2.57045728e+03]
 [  5.53823624e+01]
 [  5.60746216e+02]
 [  7.78417969e+01]
 [  4.00247223e+02]]
DEBUG:root:training time = %d0.203159
INFO:root:frame =7761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:frame =7762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241041183472
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.9816175
DEBUG:root: dqn, choose action rondomly, need time 0.000171999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:frame =7765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =7766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.981608
DEBUG:root: dqn, choose action rondomly, need time 0.00017299999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.07547714e+02]
 [  5.04015717e+02]
 [  1.53258289e+03]
 [  2.49580562e-01]
 [  5.15801239e+00]
 [  3.90815859e+04]
 [  3.25770874e+01]
 [  5.98382592e-01]
 [  5.98382592e-01]
 [  6.59656799e+02]
 [  5.40125488e+02]
 [  2.25489185e+03]
 [  1.61055908e+02]
 [  1.37628159e+02]
 [  2.20948886e-02]
 [  1.13229477e+02]]
DEBUG:root:training time = %d0.208315
INFO:root:frame =7769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:frame =7770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241041183472
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9815985
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =7773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =7774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486850738525
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:random_action_porb = 0.981589
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.15687542e+01]
 [  7.61354858e+02]
 [  8.34400208e+02]
 [  2.59338440e+02]
 [  1.25422656e+03]
 [  1.10047821e+02]
 [  6.66285629e+01]
 [  3.69750977e+01]
 [  1.31075525e+00]
 [  3.94298431e+02]
 [  1.77018887e+04]
 [  2.82935486e+01]
 [  1.20422583e+01]
 [  5.44698429e+00]
 [  3.74267044e+01]
 [  1.30664093e+02]]
DEBUG:root:training time = %d0.201324
INFO:root:frame =7777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =7778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9815795
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999976
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =7781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000494003295898
INFO:root:frame =7782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494956970215
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:random_action_porb = 0.98157
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000018
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.42723083e+00]
 [  1.46040939e+02]
 [  2.07097321e+01]
 [  3.81672287e+01]
 [  9.59542465e+01]
 [  1.43011169e+03]
 [  1.00627612e+03]
 [  3.27457031e+03]
 [  1.36969165e+03]
 [  4.26226898e+02]
 [  2.70659417e-01]
 [  8.40319763e+02]
 [  1.14672218e+02]
 [  2.07833385e+00]
 [  1.62658238e+00]
 [  1.22845205e+04]]
DEBUG:root:training time = %d0.212438
INFO:root:frame =7785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =7786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000296831130981
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.9815605
DEBUG:root: dqn, choose action rondomly, need time 0.000384999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =7789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =7790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.981551
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.07768257e+02]
 [  4.65747510e+03]
 [  3.08068490e+00]
 [  5.94369751e+02]
 [  3.42908020e+01]
 [  1.38364685e+02]
 [  1.11311255e-03]
 [  1.85595093e+01]
 [  7.62756470e+02]
 [  2.58415451e+01]
 [  2.73464142e+02]
 [  2.82572937e+02]
 [  5.33733978e+01]
 [  1.79151382e+01]
 [  2.82572937e+02]
 [  6.64132004e+01]]
DEBUG:root:training time = %d0.199485
INFO:root:frame =7793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:frame =7794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:frame = 7795 State into memory, numbers recorded 202 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:random_action_porb = 0.9815415
DEBUG:root: dqn, choose action rondomly, need time 0.000174999999984
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7796current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000145196914673
INFO:root:frame =7797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =7798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame = 7799 State into memory, numbers recorded 203 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:random_action_porb = 0.981532
DEBUG:root: dqn, choose action rondomly, need time 0.000378000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7800current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.86654949e+00]
 [  1.13725483e+00]
 [  8.97415447e+00]
 [  2.49347607e+03]
 [  2.49347607e+03]
 [  2.27214038e+03]
 [  3.25496399e+02]
 [  2.05448132e+01]
 [  8.85310364e+02]
 [  5.20905266e+01]
 [  1.56479871e+03]
 [  2.90384521e+02]
 [  1.23537455e+01]
 [  1.30247391e+02]
 [  1.73115021e+02]
 [  1.13824902e+01]]
DEBUG:root:training time = %d0.206425
INFO:root:frame =7801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =7802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411033630371
INFO:root:frame = 7803 State into memory, numbers recorded 204 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000540018081665
INFO:root:random_action_porb = 0.9815225
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999986
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7804current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =7805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000341892242432
INFO:root:frame =7806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.981513
DEBUG:root: dqn, choose action rondomly, need time 0.000279000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.85859261e+01]
 [  5.17689575e+02]
 [  5.15050850e+01]
 [  1.60166055e-01]
 [  1.87626785e+02]
 [  2.83399944e+01]
 [  4.15010681e+02]
 [  2.15617347e+00]
 [  1.63086653e+00]
 [  2.22069874e+01]
 [  2.00778687e+02]
 [  4.13759827e+02]
 [  6.03888550e+01]
 [  5.19621964e+01]
 [  2.98701878e+01]
 [  3.05616512e+01]]
DEBUG:root:training time = %d0.188528
INFO:root:frame =7809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =7810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.9815035
DEBUG:root: dqn, choose action rondomly, need time 0.000177000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000193119049072
INFO:root:frame =7813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =7814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000514030456543
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.981494
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.24407539e-01]
 [  8.64375569e-03]
 [  7.91376572e+01]
 [  1.46812477e+01]
 [  1.68836403e+01]
 [  5.50017595e+00]
 [  7.91376572e+01]
 [  3.29330368e+01]
 [  3.99431366e+02]
 [  6.60762402e+03]
 [  2.72328835e+01]
 [  1.66461536e+03]
 [  1.08132648e+01]
 [  7.58563852e+00]
 [  1.83407257e+02]
 [  4.86055279e+00]]
DEBUG:root:training time = %d0.209319
INFO:root:frame =7817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000389099121094
INFO:root:frame =7818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:random_action_porb = 0.9814845
DEBUG:root: dqn, choose action rondomly, need time 0.000202999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:frame =7821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =7822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 0.000109910964966
INFO:root:random_action_porb = 0.981475
DEBUG:root: dqn, choose action rondomly, need time 0.000192999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000178098678589
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.84387115e+02]
 [  5.55340983e-02]
 [  1.80453835e+01]
 [  2.46759003e+02]
 [  9.10161133e+02]
 [  3.21284637e+01]
 [  2.30429387e+00]
 [  1.71833875e+03]
 [  3.75548897e+01]
 [  4.36358276e+02]
 [  4.35250092e+02]
 [  1.35685144e+03]
 [  1.07082239e+03]
 [  7.05856628e+01]
 [  4.02934814e+02]
 [  3.63735847e+01]]
DEBUG:root:training time = %d0.197893
INFO:root:frame =7825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =7826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000209808349609
INFO:root:random_action_porb = 0.9814655
DEBUG:root: dqn, choose action rondomly, need time 0.00041299999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =7829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444173812866
INFO:root:frame =7830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.981456
DEBUG:root: dqn, choose action rondomly, need time 0.000163000000015
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000160217285156
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.48330641e+01]
 [  6.79992199e+00]
 [  2.55071152e+02]
 [  1.07909920e+02]
 [  3.94773193e+02]
 [  1.51625839e+02]
 [  1.64033691e+02]
 [  1.27107434e+03]
 [  1.72831287e+03]
 [  8.97294846e+01]
 [  5.26341736e+02]
 [  4.53164141e+04]
 [  9.03542908e+02]
 [  1.50111438e+03]
 [  1.94044177e+03]
 [  3.59044629e+03]]
DEBUG:root:training time = %d0.194783
INFO:root:frame =7833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =7834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494956970215
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9814465
DEBUG:root: dqn, choose action rondomly, need time 0.000318000000021
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =7837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =7838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00051212310791
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.981437
DEBUG:root: dqn, choose action rondomly, need time 0.000210999999979
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.55135071e+02]
 [  9.84599219e+03]
 [  1.53657996e+03]
 [  4.35553467e+03]
 [  2.11875801e+01]
 [  2.54718723e+01]
 [  2.75083710e+02]
 [  1.03744030e+01]
 [  4.32981049e+02]
 [  5.70061157e+02]
 [  7.99694836e-01]
 [  4.74089279e+01]
 [  6.00188684e+00]
 [  2.79606253e-01]
 [  3.41704845e+00]
 [  3.30647095e+02]]
DEBUG:root:training time = %d0.211424
INFO:root:frame =7841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:frame =7842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000261068344116
DEBUG:root: save sample needs time = 0.000185012817383
INFO:root:random_action_porb = 0.9814275
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =7845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =7846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.981418
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:training error  = [[  2.46231567e+03]
 [  4.44052148e+03]
 [  1.19316855e+04]
 [  3.70260060e-01]
 [  1.12751331e+03]
 [  1.42080536e+02]
 [  4.44052148e+03]
 [  1.95310608e+02]
 [  1.05587411e+00]
 [  2.87892603e+03]
 [  7.57289124e+02]
 [  5.95042908e+02]
 [  9.10591602e+00]
 [  5.78305664e+03]
 [  1.41740982e+02]
 [  3.64777222e+03]]
DEBUG:root:training time = %d0.226545
INFO:root:frame =7849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =7850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247955322266
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9814085
DEBUG:root: dqn, choose action rondomly, need time 0.000189000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:frame =7853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =7854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.981399
DEBUG:root: dqn, choose action rondomly, need time 0.00020600000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000176906585693
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.55666675e+03]
 [  3.92268188e+03]
 [  4.84529209e+00]
 [  1.53770254e+04]
 [  1.26521645e+02]
 [  4.40554543e+01]
 [  1.36266943e+03]
 [  2.47709824e+02]
 [  5.89470177e+01]
 [  1.57762161e+02]
 [  5.60887549e+03]
 [  8.15244263e+02]
 [  1.33191089e+03]
 [  2.33066654e+01]
 [  1.22690198e+03]
 [  9.22356993e-02]]
DEBUG:root:training time = %d0.195508
INFO:root:frame =7857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =7858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame = 7859 State into memory, numbers recorded 205 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000588178634644
INFO:root:random_action_porb = 0.9813895
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7860current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =7861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =7862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.98138
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.10377531e+01]
 [  7.26831970e+01]
 [  2.64526538e+03]
 [  1.83877884e+02]
 [  2.43942344e+04]
 [  1.33748840e+02]
 [  4.88714827e-03]
 [  9.36853504e+00]
 [  8.50078869e+00]
 [  2.62651440e+03]
 [  6.75213909e+00]
 [  1.14643869e+01]
 [  6.06653687e+02]
 [  1.62154785e+02]
 [  8.98317566e+02]
 [  2.39258865e+02]]
DEBUG:root:training time = %d0.21041
INFO:root:frame =7865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:frame =7866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000282049179077
DEBUG:root: save sample needs time = 0.000158071517944
INFO:root:random_action_porb = 0.9813705
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =7869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =7870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485897064209
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.981361
DEBUG:root: dqn, choose action rondomly, need time 0.000241999999986
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:training error  = [[  4.83293962e+00]
 [  7.74005830e-01]
 [  1.66269341e+01]
 [  1.54553650e+02]
 [  7.39521637e+01]
 [  5.33962517e+01]
 [  1.01981151e+00]
 [  2.67698402e+01]
 [  1.71749710e+02]
 [  6.04930992e+01]
 [  2.80461287e+00]
 [  4.17353436e-02]
 [  1.25961716e+02]
 [  1.54553650e+02]
 [  7.74005830e-01]
 [  9.21249756e+02]]
DEBUG:root:training time = %d0.200006
INFO:root:frame =7873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =7874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root:random_action_porb = 0.9813515
DEBUG:root: dqn, choose action rondomly, need time 0.000486000000024
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000359773635864
INFO:root:frame =7877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000408887863159
INFO:root:frame =7878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000518083572388
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.981342
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:training error  = [[  2.60203648e-02]
 [  2.03997467e+02]
 [  8.14103088e+01]
 [  9.65332127e+00]
 [  1.85611099e+02]
 [  2.08839127e+02]
 [  1.02581917e+02]
 [  5.46141672e+00]
 [  1.99623627e+02]
 [  2.03997467e+02]
 [  1.01934320e+03]
 [  1.05853987e+01]
 [  1.99623627e+02]
 [  7.25065063e+02]
 [  2.83572113e+02]
 [  7.51454067e+00]]
DEBUG:root:training time = %d0.216734
INFO:root:frame =7881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =7882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239133834839
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:random_action_porb = 0.9813325
DEBUG:root: dqn, choose action rondomly, need time 0.000380000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root:frame =7885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =7886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.981323
DEBUG:root: dqn, choose action rondomly, need time 0.00034500000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355958938599
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.98495392e+02]
 [  1.44657913e+02]
 [  5.46294312e+02]
 [  3.64719604e+02]
 [  2.36143115e+03]
 [  2.09901230e+02]
 [  8.47795508e+03]
 [  1.93768051e+02]
 [  8.52315918e+02]
 [  4.09523633e+03]
 [  2.47253373e-01]
 [  1.29216747e+01]
 [  6.12493753e+00]
 [  7.56887952e-04]
 [  7.95562561e+02]
 [  3.46650940e+02]]
DEBUG:root:training time = %d0.208988
INFO:root:frame =7889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =7890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411987304688
INFO:root:frame = 7891 State into memory, numbers recorded 206 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:random_action_porb = 0.9813135
DEBUG:root: dqn, choose action rondomly, need time 0.000371999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7892current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =7893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =7894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000511169433594
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.981304
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.24447105e+02]
 [  4.66205692e+00]
 [  1.16099209e+04]
 [  2.81771698e+02]
 [  9.10556580e+02]
 [  9.76295471e+02]
 [  1.51888626e+02]
 [  1.25771355e+02]
 [  2.46885347e+00]
 [  5.88382072e+01]
 [  8.40101074e+02]
 [  2.14595551e+02]
 [  1.92107841e-01]
 [  1.01297211e+02]
 [  1.71452286e+02]
 [  2.20645190e+03]]
DEBUG:root:training time = %d0.20788
INFO:root:frame =7897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =7898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000224828720093
DEBUG:root: save sample needs time = 0.00010085105896
INFO:root:random_action_porb = 0.9812945
DEBUG:root: dqn, choose action rondomly, need time 0.000317999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =7901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00040078163147
INFO:root:frame =7902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488042831421
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:random_action_porb = 0.981285
DEBUG:root: dqn, choose action rondomly, need time 0.000166000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000173091888428
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.67037220e+01]
 [  5.59277415e-01]
 [  1.05363007e+02]
 [  2.57425244e+03]
 [  5.90259521e+02]
 [  9.41737854e+02]
 [  1.32850464e+02]
 [  2.63589120e+00]
 [  3.75739670e+01]
 [  1.37741146e+01]
 [  5.19825506e+00]
 [  9.22836685e+00]
 [  1.70955139e+02]
 [  2.24131805e+02]
 [  1.44105737e+03]
 [  7.65775909e+01]]
DEBUG:root:training time = %d0.194525
INFO:root:frame =7905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =7906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247955322266
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:random_action_porb = 0.9812755
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =7909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000494956970215
INFO:root:frame =7910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000580072402954
INFO:root:frame = 7911 State into memory, numbers recorded 207 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000582933425903
INFO:root:random_action_porb = 0.981266
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7912current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:training error  = [[  3.71342468e+02]
 [  4.57573738e+01]
 [  7.02348404e+01]
 [  5.98264111e+03]
 [  2.14561295e+02]
 [  1.99000409e-04]
 [  1.15365210e+01]
 [  5.82728744e-01]
 [  1.10176956e+02]
 [  2.09866219e+01]
 [  5.87013741e+01]
 [  5.60248596e+02]
 [  5.60248596e+02]
 [  3.78096619e+01]
 [  8.85983372e+00]
 [  4.38035278e+01]]
DEBUG:root:training time = %d0.219656
INFO:root:frame =7913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00063419342041
INFO:root:frame =7914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319004058838
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9812565
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999983
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =7917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =7918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000595092773438
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.981247
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.48015404e+00]
 [  2.98605144e-01]
 [  8.02072937e+02]
 [  4.26763649e+01]
 [  1.03036584e+03]
 [  1.40038528e+01]
 [  1.56406750e+03]
 [  2.37364761e+02]
 [  1.56406750e+03]
 [  3.14058857e+01]
 [  2.42681313e+00]
 [  3.37624550e-01]
 [  8.83976966e-02]
 [  5.59971428e+01]
 [  2.66810962e+03]
 [  2.19339066e+01]]
DEBUG:root:training time = %d0.196693
INFO:root:frame =7921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:frame =7922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000517129898071
INFO:root:frame = 7923 State into memory, numbers recorded 208 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000574827194214
INFO:root:random_action_porb = 0.9812375
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7924current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =7925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =7926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.981228
INFO:root:dqn select action Tensor("ArgMax_21:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00968400000002
INFO:root:action choosen by dqn [2]
INFO:root:frame =7928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000156164169312
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.29525805e+00]
 [  1.02207792e+00]
 [  3.01252014e+02]
 [  1.21565361e+04]
 [  7.84719661e-02]
 [  9.13626328e+01]
 [  1.18746006e+00]
 [  2.41325439e+02]
 [  1.50289886e+02]
 [  1.80236890e+03]
 [  8.19115479e+02]
 [  1.20556860e+03]
 [  2.07073624e+02]
 [  3.81641197e+01]
 [  2.20807422e+03]
 [  2.04885223e+02]]
DEBUG:root:training time = %d0.20347
INFO:root:frame =7929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =7930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486135482788
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9812185
DEBUG:root: dqn, choose action rondomly, need time 0.000404000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =7933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =7934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.981209
DEBUG:root: dqn, choose action rondomly, need time 0.000542999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.38152695e+02]
 [  9.45049286e+00]
 [  9.26478195e+01]
 [  8.96042099e+01]
 [  1.64336243e+03]
 [  9.83868652e+02]
 [  5.64466980e+02]
 [  4.62375336e+02]
 [  1.77141815e+02]
 [  5.18853271e+02]
 [  8.59111771e-02]
 [  1.52230473e+01]
 [  1.19623566e+02]
 [  3.61029150e+03]
 [  2.96852234e+02]
 [  2.48083176e+02]]
DEBUG:root:training time = %d0.188011
INFO:root:frame =7937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:frame =7938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000253915786743
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.9811995
DEBUG:root: dqn, choose action rondomly, need time 0.000231000000014
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:frame =7941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =7942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.98119
DEBUG:root: dqn, choose action rondomly, need time 0.000521999999989
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  730.37091064]
 [   65.84291077]
 [  120.32519531]
 [  300.00564575]
 [   22.72179985]
 [ 1838.47631836]
 [  119.76779938]
 [ 2369.84838867]
 [  711.67462158]
 [  217.868927  ]
 [  433.43585205]
 [   64.39281464]
 [   97.97121429]
 [    8.80713558]
 [  201.048172  ]
 [ 2263.57788086]]
DEBUG:root:training time = %d0.202244
INFO:root:frame =7945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:frame =7946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9811805
INFO:root:dqn select action Tensor("ArgMax_22:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011357
INFO:root:action choosen by dqn [2]
INFO:root:frame =7948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:frame =7949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =7950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.981171
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.34148499e+02]
 [  1.57676125e+00]
 [  3.29617828e+02]
 [  2.77535686e+01]
 [  5.15687939e+03]
 [  1.48586853e+02]
 [  1.11160622e+01]
 [  1.74796271e+00]
 [  2.35076122e+01]
 [  1.11160622e+01]
 [  7.35996780e+01]
 [  3.76084900e+01]
 [  3.50445728e+03]
 [  9.02552187e-01]
 [  6.10696045e+02]
 [  6.62574768e+02]]
DEBUG:root:training time = %d0.196435
INFO:root:frame =7953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:frame =7954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000284910202026
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9811615
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =7957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =7958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000309944152832
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:random_action_porb = 0.981152
DEBUG:root: dqn, choose action rondomly, need time 0.000344999999982
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.96266594e+01]
 [  1.13865471e+00]
 [  6.04212303e+01]
 [  2.57811546e-01]
 [  1.36514444e+01]
 [  9.07370361e+02]
 [  1.04640640e+02]
 [  1.26092415e+02]
 [  2.33991406e+03]
 [  8.86955547e+00]
 [  6.45639587e+02]
 [  2.11613571e+02]
 [  3.08883392e+02]
 [  5.67859554e+00]
 [  2.07383560e+02]
 [  1.33807201e+01]]
DEBUG:root:training time = %d0.211324
INFO:root:frame =7961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =7962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
DEBUG:root: save sample needs time = 9.51290130615e-05
INFO:root:random_action_porb = 0.9811425
DEBUG:root: dqn, choose action rondomly, need time 0.000168000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:frame =7965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000592947006226
INFO:root:frame =7966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame = 7967 State into memory, numbers recorded 209 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000604867935181
INFO:root:random_action_porb = 0.981133
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7968current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.61083588e+02]
 [  7.76117554e+01]
 [  4.14470612e+02]
 [  1.44905945e+03]
 [  3.18562207e+03]
 [  2.34416574e-02]
 [  6.64695679e+02]
 [  1.86558594e+02]
 [  1.88072021e+03]
 [  2.95632599e+02]
 [  1.23504456e+03]
 [  5.74344775e+03]
 [  3.24790955e+01]
 [  1.83472672e+01]
 [  1.43230762e+01]
 [  7.02546616e+01]]
DEBUG:root:training time = %d0.211996
INFO:root:frame =7969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:frame =7970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294923782349
DEBUG:root: save sample needs time = 0.0001060962677
INFO:root:random_action_porb = 0.9811235
DEBUG:root: dqn, choose action rondomly, need time 0.000169
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root:frame =7973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =7974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:random_action_porb = 0.981114
DEBUG:root: dqn, choose action rondomly, need time 0.000337000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000356912612915
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.40624428e+01]
 [  1.93420044e+03]
 [  1.28455566e+03]
 [  1.13973936e+04]
 [  4.27691126e+00]
 [  4.98717957e+01]
 [  1.24468908e+01]
 [  1.37044662e+02]
 [  7.72695740e+02]
 [  2.12430859e+03]
 [  4.10435547e+02]
 [  7.89992859e+02]
 [  1.93420044e+03]
 [  5.86422205e+00]
 [  8.12821533e+02]
 [  4.27691126e+00]]
DEBUG:root:training time = %d0.196332
INFO:root:frame =7977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =7978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9811045
DEBUG:root: dqn, choose action rondomly, need time 0.000339999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =7981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root:frame =7982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.981095
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.66651733e+02]
 [  2.62532353e+00]
 [  4.34931488e+02]
 [  5.76304382e+02]
 [  9.68679443e+02]
 [  3.93051071e+01]
 [  2.32255447e+02]
 [  2.94394341e+01]
 [  9.69735565e+01]
 [  3.09371471e+00]
 [  6.26096069e+02]
 [  6.24790192e+00]
 [  4.91954773e+02]
 [  1.15805119e-01]
 [  7.80999527e+01]
 [  3.81454224e+02]]
DEBUG:root:training time = %d0.215789
INFO:root:frame =7985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =7986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00029993057251
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9810855
INFO:root:dqn select action Tensor("ArgMax_23:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.01162
INFO:root:action choosen by dqn [2]
INFO:root:frame =7988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:frame =7989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:frame =7990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324010848999
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:random_action_porb = 0.981076
DEBUG:root: dqn, choose action rondomly, need time 0.000157999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  100.62873077]
 [ 1168.1529541 ]
 [   22.96041107]
 [   32.07486343]
 [   10.12871265]
 [  211.85603333]
 [  157.20207214]
 [ 3117.45092773]
 [   32.86617279]
 [   17.04219627]
 [   55.95832443]
 [   22.10654068]
 [  264.05606079]
 [   96.12082672]
 [   92.81459808]
 [  399.66741943]]
DEBUG:root:training time = %d0.202904
INFO:root:frame =7993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000419855117798
INFO:root:frame =7994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root:frame = 7995 State into memory, numbers recorded 210 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.00040602684021
INFO:root:random_action_porb = 0.9810665
DEBUG:root: dqn, choose action rondomly, need time 0.000193999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7996current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:frame =7997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375032424927
INFO:root:frame =7998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000318050384521
DEBUG:root: save sample needs time = 0.000164985656738
DEBUG:root:one frame running time = 0.00298999999998
DEBUG:root:total training time = 206.756855
INFO:root:frame num = 8000 frame round: 0
INFO:root:random_action_porb = 0.981057
DEBUG:root: dqn, choose action rondomly, need time 0.00031199999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:training error  = [[  2.91685272e+02]
 [  3.86498952e+00]
 [  5.70218933e+02]
 [  1.68263885e+02]
 [  3.86498952e+00]
 [  4.11521289e+03]
 [  1.71543396e+02]
 [  4.05524302e+00]
 [  7.97469482e+01]
 [  3.75622749e+01]
 [  1.81576880e+03]
 [  1.53144028e+02]
 [  3.72199402e+01]
 [  6.32729435e+00]
 [  4.37346802e+01]
 [  5.81940918e+02]]
DEBUG:root:training time = %d0.197186
INFO:root:frame =8001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =8002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247001647949
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:random_action_porb = 0.9810475
DEBUG:root: dqn, choose action rondomly, need time 0.000230000000016
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root:frame =8005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =8006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.981038
DEBUG:root: dqn, choose action rondomly, need time 0.000579000000016
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.47641992e+03]
 [  1.97246719e+04]
 [  4.15023308e+01]
 [  1.03088676e+02]
 [  4.08616943e+02]
 [  4.13451996e+01]
 [  9.57029819e+00]
 [  7.95432281e+01]
 [  2.01815033e+00]
 [  8.31396875e+03]
 [  1.02409050e+02]
 [  5.05042225e-02]
 [  4.12593933e+02]
 [  7.06311798e+01]
 [  2.15242554e+03]
 [  2.35303589e+03]]
DEBUG:root:training time = %d0.198221
INFO:root:frame =8009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =8010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.9810285
DEBUG:root: dqn, choose action rondomly, need time 0.000534999999985
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =8013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470876693726
INFO:root:frame =8014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
INFO:root:frame = 8015 State into memory, numbers recorded 211 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:random_action_porb = 0.981019
DEBUG:root: dqn, choose action rondomly, need time 0.000373999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8016current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000325202941895
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.21231421e+03]
 [  7.90050316e+00]
 [  2.07689331e+02]
 [  3.17729416e+01]
 [  4.80867844e+01]
 [  1.71452808e+01]
 [  1.77769356e+01]
 [  5.87444007e-03]
 [  2.29359741e+03]
 [  8.29479736e+02]
 [  2.71289082e+01]
 [  3.17878906e+02]
 [  6.42028809e+02]
 [  5.92423534e+00]
 [  5.64820679e+02]
 [  3.05707607e+01]]
DEBUG:root:training time = %d0.203711
INFO:root:frame =8017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =8018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9810095
DEBUG:root: dqn, choose action rondomly, need time 0.000279000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000356912612915
INFO:root:frame =8021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =8022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame = 8023 State into memory, numbers recorded 212 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000555992126465
INFO:root:random_action_porb = 0.981
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8024current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:training error  = [[  5.18000832e+01]
 [  2.23656425e+01]
 [  2.46795197e+02]
 [  6.40225977e+03]
 [  2.07200966e+01]
 [  3.08096485e+01]
 [  6.38453579e+00]
 [  1.26849678e+02]
 [  2.23656425e+01]
 [  7.64909515e+01]
 [  3.21615112e+03]
 [  1.41761279e+03]
 [  4.18545055e+00]
 [  1.06955729e+01]
 [  1.14070717e+02]
 [  3.80385685e+00]]
DEBUG:root:training time = %d0.216191
INFO:root:frame =8025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =8026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:frame = 8027 State into memory, numbers recorded 213 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:random_action_porb = 0.9809905
DEBUG:root: dqn, choose action rondomly, need time 0.000190000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8028current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000150203704834
INFO:root:frame =8029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =8030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000354051589966
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:random_action_porb = 0.980981
DEBUG:root: dqn, choose action rondomly, need time 0.000377999999984
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.36782532e+03]
 [  3.85293961e+00]
 [  6.15744568e+02]
 [  5.10128250e+01]
 [  4.62534485e+02]
 [  1.02329695e+00]
 [  8.93568516e+00]
 [  2.79849365e+02]
 [  1.91990082e+02]
 [  1.24488129e+02]
 [  3.86552954e+00]
 [  4.53416328e+01]
 [  5.10128250e+01]
 [  2.30115875e+02]
 [  5.04277466e+02]
 [  4.29147100e+00]]
DEBUG:root:training time = %d0.201127
INFO:root:frame =8033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =8034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:random_action_porb = 0.9809715
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =8037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000596046447754
INFO:root:frame =8038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.980962
DEBUG:root: dqn, choose action rondomly, need time 0.000321000000014
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.36701294e+02]
 [  1.39113428e+03]
 [  5.56387146e+02]
 [  3.07775574e+02]
 [  9.06640625e+00]
 [  1.96561451e+01]
 [  3.62951752e+02]
 [  1.38110628e+01]
 [  6.12474903e-02]
 [  7.83259338e+02]
 [  4.39557495e+01]
 [  5.10730103e+02]
 [  5.34252014e+02]
 [  9.42234955e+01]
 [  1.44384415e+02]
 [  3.40699226e-01]]
DEBUG:root:training time = %d0.201625
INFO:root:frame =8041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:frame =8042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227928161621
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.9809525
DEBUG:root: dqn, choose action rondomly, need time 0.000186999999983
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:frame =8045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456809997559
INFO:root:frame =8046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:random_action_porb = 0.980943
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000346183776855
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.94418335e+01]
 [  2.94418335e+01]
 [  2.21357322e+00]
 [  1.06128418e+02]
 [  1.07130762e+03]
 [  2.63154785e+02]
 [  6.77835770e+01]
 [  8.15801575e+02]
 [  2.89611847e+02]
 [  3.72331619e+01]
 [  3.37307617e+02]
 [  1.30726373e+00]
 [  7.51768036e+01]
 [  2.88261890e+03]
 [  2.63154785e+02]
 [  5.05661049e+01]]
DEBUG:root:training time = %d0.206663
INFO:root:frame =8049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =8050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9809335
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =8053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =8054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.980924
DEBUG:root: dqn, choose action rondomly, need time 0.000362999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000402212142944
INFO:root:training error  = [[  4.04189087e+02]
 [  1.56502914e+02]
 [  2.95893188e+02]
 [  4.88243439e+02]
 [  6.58319092e+00]
 [  7.84641846e+02]
 [  2.19496307e+01]
 [  4.55929413e+01]
 [  3.03075981e+01]
 [  5.10848880e-01]
 [  1.17843506e+04]
 [  7.84641846e+02]
 [  5.10848880e-01]
 [  1.77566767e-01]
 [  5.62089453e+03]
 [  3.09249420e+01]]
DEBUG:root:training time = %d0.194207
INFO:root:frame =8057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =8058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.9809145
DEBUG:root: dqn, choose action rondomly, need time 0.000179000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =8061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =8062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000314950942993
DEBUG:root: save sample needs time = 0.000155925750732
INFO:root:random_action_porb = 0.980905
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.58676636e+02]
 [  1.65878799e+02]
 [  1.60899490e+02]
 [  1.19682899e+02]
 [  1.69179846e+03]
 [  3.96275787e+02]
 [  1.17047134e+02]
 [  6.06786461e+01]
 [  5.23055847e+02]
 [  1.49447787e+00]
 [  2.21533574e+04]
 [  4.56106232e+02]
 [  5.03078690e+01]
 [  4.09111053e+02]
 [  1.65065098e+01]
 [  1.68881790e+02]]
DEBUG:root:training time = %d0.200942
INFO:root:frame =8065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:frame =8066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame = 8067 State into memory, numbers recorded 214 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000509023666382
INFO:root:random_action_porb = 0.9808955
DEBUG:root: dqn, choose action rondomly, need time 0.000159999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8068current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:frame =8069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:frame =8070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000355005264282
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.980886
DEBUG:root: dqn, choose action rondomly, need time 0.000347000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.85264673e+03]
 [  1.05792755e+02]
 [  3.33446075e+02]
 [  4.94587646e+03]
 [  2.55588547e+02]
 [  5.66071939e+00]
 [  1.97157898e+01]
 [  9.41177673e+01]
 [  2.16844009e+02]
 [  7.94855423e+01]
 [  1.84487319e+00]
 [  9.24301270e+03]
 [  2.68172363e+02]
 [  5.47882324e+03]
 [  2.68172363e+02]
 [  1.07569087e+00]]
DEBUG:root:training time = %d0.198222
INFO:root:frame =8073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =8074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00022292137146
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:random_action_porb = 0.9808765
DEBUG:root: dqn, choose action rondomly, need time 0.000356000000011
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00037407875061
INFO:root:frame =8077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000518083572388
INFO:root:frame =8078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000409126281738
DEBUG:root: save sample needs time = 0.000263214111328
INFO:root:random_action_porb = 0.980867
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000011
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000353813171387
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.53875732e+01]
 [  2.59605865e+02]
 [  2.59605865e+02]
 [  3.07359219e+01]
 [  2.05873337e+01]
 [  4.32862854e+01]
 [  7.50398026e+01]
 [  5.97776222e+00]
 [  1.78001297e+02]
 [  1.71730289e+01]
 [  2.27891312e+02]
 [  5.10589935e+02]
 [  3.66381885e+03]
 [  3.52908485e-02]
 [  1.57762219e+03]
 [  7.05247986e+02]]
DEBUG:root:training time = %d0.203205
INFO:root:frame =8081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =8082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.9808575
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =8085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =8086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.980848
DEBUG:root: dqn, choose action rondomly, need time 0.000257999999974
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   17.31870842]
 [   49.47614288]
 [  221.09225464]
 [  122.48628998]
 [ 5118.82226562]
 [  103.85574341]
 [   19.98316193]
 [  122.72147369]
 [  876.67486572]
 [  448.76663208]
 [   43.89558029]
 [  148.20394897]
 [   32.6512413 ]
 [    6.09841871]
 [  103.85574341]
 [  616.85693359]]
DEBUG:root:training time = %d0.201297
INFO:root:frame =8089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =8090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294923782349
DEBUG:root: save sample needs time = 0.000140190124512
INFO:root:random_action_porb = 0.9808385
DEBUG:root: dqn, choose action rondomly, need time 0.000466999999986
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root:frame =8093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =8094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.980829
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.36887952e+03]
 [  4.29634521e+02]
 [  6.22979443e+03]
 [  1.33117646e-01]
 [  8.35241089e+01]
 [  1.87567429e+02]
 [  1.43209338e+00]
 [  6.19123983e+00]
 [  6.19123983e+00]
 [  9.43323803e+00]
 [  1.95620880e+01]
 [  1.20873462e+03]
 [  1.41080856e+02]
 [  3.04833179e+03]
 [  1.36887952e+03]
 [  2.19283327e-01]]
DEBUG:root:training time = %d0.20961
INFO:root:frame =8097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =8098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249147415161
INFO:root:frame = 8099 State into memory, numbers recorded 215 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:random_action_porb = 0.9808195
DEBUG:root: dqn, choose action rondomly, need time 0.000161999999989
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8100current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =8101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440835952759
INFO:root:frame =8102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.98081
DEBUG:root: dqn, choose action rondomly, need time 0.000518999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.51773560e+02]
 [  9.73223694e+02]
 [  1.04623154e+02]
 [  1.06721811e+01]
 [  1.33410144e+00]
 [  4.28030273e+02]
 [  2.39853564e+03]
 [  4.52302094e+02]
 [  1.38329773e+02]
 [  1.08378157e-01]
 [  2.14799213e+01]
 [  6.56615479e+02]
 [  1.22737740e+02]
 [  1.10927332e+03]
 [  5.94274521e+00]
 [  2.34237427e+02]]
DEBUG:root:training time = %d0.200447
INFO:root:frame =8105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =8106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000523090362549
DEBUG:root: save sample needs time = 0.000178098678589
INFO:root:random_action_porb = 0.9808005
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =8109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000423192977905
INFO:root:frame =8110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265836715698
DEBUG:root: save sample needs time = 0.000120162963867
INFO:root:random_action_porb = 0.980791
DEBUG:root: dqn, choose action rondomly, need time 0.000214
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000237226486206
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[    5.32108355]
 [  345.82543945]
 [   33.72336578]
 [  181.31948853]
 [    9.32542992]
 [    2.92741156]
 [  131.07971191]
 [  166.93089294]
 [   75.12310028]
 [ 1724.33972168]
 [    5.44830227]
 [  522.49908447]
 [  360.18984985]
 [   10.70171165]
 [  623.74346924]
 [   37.26408005]]
DEBUG:root:training time = %d0.201937
INFO:root:frame =8113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000383853912354
INFO:root:frame =8114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000287055969238
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9807815
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =8117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =8118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.980772
DEBUG:root: dqn, choose action rondomly, need time 0.000193999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.99280334e+00]
 [  2.43232983e+03]
 [  2.10781113e+02]
 [  1.29983871e+02]
 [  6.00040833e+02]
 [  8.78280823e+02]
 [  2.39356827e+02]
 [  3.50042953e+01]
 [  2.43232983e+03]
 [  1.11441376e+02]
 [  1.32040015e+03]
 [  7.05582619e+00]
 [  2.41366357e+03]
 [  1.93391846e+02]
 [  6.51518631e+01]
 [  2.41366357e+03]]
DEBUG:root:training time = %d0.197028
INFO:root:frame =8121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =8122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298976898193
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.9807625
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000021
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =8125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =8126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000511169433594
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:random_action_porb = 0.980753
DEBUG:root: dqn, choose action rondomly, need time 0.000331999999986
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.16714287e+01]
 [  9.17062819e-01]
 [  7.47922659e+00]
 [  4.28906921e+02]
 [  2.43978524e+00]
 [  2.78003052e+02]
 [  5.27427554e-01]
 [  9.28128302e-01]
 [  7.63010383e-01]
 [  3.45342751e+01]
 [  7.25700607e+01]
 [  2.89140820e+04]
 [  2.69532337e+01]
 [  7.25903397e+01]
 [  1.01145073e+02]
 [  1.74271021e+03]]
DEBUG:root:training time = %d0.217777
INFO:root:frame =8129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =8130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249862670898
DEBUG:root: save sample needs time = 0.000180959701538
INFO:root:random_action_porb = 0.9807435
DEBUG:root: dqn, choose action rondomly, need time 0.00016100000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:frame =8133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000500917434692
INFO:root:frame =8134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.980734
DEBUG:root: dqn, choose action rondomly, need time 0.000250999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.47395248e+01]
 [  5.38261780e+02]
 [  3.70258242e-02]
 [  2.70241814e+01]
 [  2.01504016e+03]
 [  9.30284405e+00]
 [  1.06216955e+01]
 [  2.90599060e+02]
 [  1.60111713e+01]
 [  3.96978833e+03]
 [  5.69012108e+01]
 [  1.77777209e+03]
 [  1.08503234e+00]
 [  5.37755775e+01]
 [  1.56018539e+02]
 [  1.10515051e+03]]
DEBUG:root:training time = %d0.194657
INFO:root:frame =8137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =8138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.9807245
DEBUG:root: dqn, choose action rondomly, need time 0.000181999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:frame =8141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =8142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.980715
DEBUG:root: dqn, choose action rondomly, need time 0.000377999999984
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000540018081665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.45843506e+01]
 [  1.17664204e+01]
 [  3.49635681e+02]
 [  4.68504906e+00]
 [  3.48138214e+02]
 [  2.91484131e+02]
 [  1.50110722e+01]
 [  1.18186319e+00]
 [  4.13420601e+01]
 [  1.30699196e+01]
 [  4.22553558e+01]
 [  1.66817419e+03]
 [  3.77912750e+01]
 [  2.73828369e+02]
 [  1.81443420e+03]
 [  2.69257665e+00]]
DEBUG:root:training time = %d0.193216
INFO:root:frame =8145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000679969787598
INFO:root:frame =8146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274896621704
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9807055
DEBUG:root: dqn, choose action rondomly, need time 0.000184000000019
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:frame =8149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =8150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.980696
DEBUG:root: dqn, choose action rondomly, need time 0.000326999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.95830841e+02]
 [  1.39580383e+01]
 [  6.63273010e+01]
 [  1.55320969e+01]
 [  2.63044891e+02]
 [  2.53926086e+00]
 [  2.78262844e+01]
 [  1.48576393e+01]
 [  4.63760644e-03]
 [  2.33691455e+03]
 [  6.88685226e+01]
 [  4.35215393e+02]
 [  1.04122072e-01]
 [  1.39580383e+01]
 [  1.68104584e+02]
 [  2.99461250e+01]]
DEBUG:root:training time = %d0.190599
INFO:root:frame =8153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:frame =8154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.9806865
DEBUG:root: dqn, choose action rondomly, need time 0.00018799999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =8157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000510931015015
INFO:root:frame =8158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:random_action_porb = 0.980677
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999986
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.87431839e+02]
 [  1.69811497e+01]
 [  8.46063995e+01]
 [  5.58870509e-02]
 [  1.44582939e+01]
 [  1.75502454e+03]
 [  7.70889282e+00]
 [  3.53968994e+02]
 [  8.80809860e+01]
 [  1.48634624e+01]
 [  5.22673249e-01]
 [  9.34062672e+00]
 [  5.41626472e+01]
 [  9.58403873e+00]
 [  3.19221130e+02]
 [  1.21046143e+03]]
DEBUG:root:training time = %d0.216018
INFO:root:frame =8161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =8162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249862670898
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9806675
DEBUG:root: dqn, choose action rondomly, need time 0.000507999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000386953353882
INFO:root:frame =8165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =8166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:random_action_porb = 0.980658
DEBUG:root: dqn, choose action rondomly, need time 0.000361999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.33188385e-01]
 [  9.99037781e+01]
 [  6.69182739e+01]
 [  4.18045759e+00]
 [  1.86553440e+01]
 [  7.75985794e+01]
 [  2.43651398e+02]
 [  3.82983742e+01]
 [  2.55168647e-01]
 [  2.22658098e-01]
 [  7.70982456e+00]
 [  4.73018707e+02]
 [  1.45765588e+03]
 [  4.15932089e-01]
 [  4.63511318e-01]
 [  3.58136963e+02]]
DEBUG:root:training time = %d0.202655
INFO:root:frame =8169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:frame =8170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 0.0001060962677
INFO:root:random_action_porb = 0.9806485
INFO:root:dqn select action Tensor("ArgMax_24:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010715
INFO:root:action choosen by dqn [2]
INFO:root:frame =8172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:frame =8173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:frame =8174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000323057174683
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.980639
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7.67127563e+02]
 [  1.16665564e+01]
 [  2.00002599e+00]
 [  4.33563232e+00]
 [  1.18352442e+01]
 [  3.33198967e+01]
 [  1.18795395e+02]
 [  5.20559502e+01]
 [  1.38795239e+03]
 [  8.64090500e+01]
 [  8.98392944e+01]
 [  5.39239407e-01]
 [  9.35437988e+02]
 [  4.38794159e+02]
 [  3.29168653e+00]
 [  1.14838604e+04]]
DEBUG:root:training time = %d0.201795
INFO:root:frame =8177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:frame =8178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9806295
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:player has been killed for 9 times 
INFO:root:frame =8181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000516891479492
INFO:root:frame =8182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411987304688
INFO:root:frame = 8183 State into memory, numbers recorded 216 action = 1, reward = -255
DEBUG:root: save sample needs time = 0.000537872314453
INFO:root:random_action_porb = 0.98062
DEBUG:root: dqn, choose action rondomly, need time 0.00017299999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8184current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000141859054565
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.52749901e+01]
 [  1.29789795e+02]
 [  5.76700211e+01]
 [  8.56898575e+01]
 [  8.82741318e+01]
 [  4.69466496e+00]
 [  1.59433395e+02]
 [  2.42103073e+02]
 [  1.24781332e+01]
 [  1.03472620e+03]
 [  1.84129355e+04]
 [  5.52749901e+01]
 [  2.88931513e+00]
 [  5.08401642e+02]
 [  1.20323013e+02]
 [  5.27096741e+02]]
DEBUG:root:training time = %d0.207249
INFO:root:frame =8185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =8186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000574111938477
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.9806105
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000018
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root:frame =8189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =8190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000287055969238
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.980601
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000023
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.90208899e+03]
 [  9.69533264e+02]
 [  1.63381567e+03]
 [  1.91161972e+02]
 [  6.24618578e+00]
 [  1.57326937e-01]
 [  1.76344643e+01]
 [  2.72595654e+01]
 [  1.16114632e+02]
 [  2.70300503e+01]
 [  3.00473309e+01]
 [  1.50525436e+01]
 [  9.27525699e-01]
 [  5.20005066e+02]
 [  3.20784088e+02]
 [  6.14361191e+01]]
DEBUG:root:training time = %d0.216791
INFO:root:frame =8193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =8194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.9805915
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =8197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000545978546143
INFO:root:frame =8198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.980582
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.74059868e+01]
 [  1.07768679e+01]
 [  1.61267836e-02]
 [  7.10399048e+02]
 [  1.10767261e+03]
 [  7.13086853e+02]
 [  6.41244173e+00]
 [  1.82285059e+04]
 [  1.61267836e-02]
 [  1.36939561e+00]
 [  8.29381866e+01]
 [  1.17015442e+02]
 [  1.37024033e+02]
 [  2.45962925e+01]
 [  2.36860981e+01]
 [  2.17818253e+02]]
DEBUG:root:training time = %d0.192356
INFO:root:frame =8201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000206232070923
INFO:root:frame =8202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9805725
DEBUG:root: dqn, choose action rondomly, need time 0.000160999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:frame =8205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =8206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:random_action_porb = 0.980563
DEBUG:root: dqn, choose action rondomly, need time 0.000342999999987
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000408887863159
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.66233540e+01]
 [  1.23751812e+01]
 [  3.10021305e+00]
 [  1.65422180e+02]
 [  1.00875320e+02]
 [  1.23751812e+01]
 [  1.27043605e+00]
 [  3.86266518e+01]
 [  6.38955534e-01]
 [  4.98085594e+01]
 [  3.48422095e+03]
 [  2.52747208e+02]
 [  3.30943921e+03]
 [  7.23130493e+01]
 [  1.41055491e-02]
 [  8.84482861e+00]]
DEBUG:root:training time = %d0.211819
INFO:root:frame =8209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =8210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482082366943
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9805535
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000545978546143
INFO:root:frame =8213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471115112305
INFO:root:frame =8214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:random_action_porb = 0.980544
DEBUG:root: dqn, choose action rondomly, need time 0.000194999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.46518799e+03]
 [  3.69039307e+02]
 [  3.95923523e+02]
 [  2.04632816e+01]
 [  2.13043904e+00]
 [  4.03137255e+00]
 [  4.56182800e+02]
 [  6.25097656e+02]
 [  1.62707284e-01]
 [  2.37156998e+02]
 [  1.04784741e+03]
 [  8.74149084e-01]
 [  1.37331055e+03]
 [  4.64054794e+01]
 [  1.09181862e+01]
 [  1.27340286e+02]]
DEBUG:root:training time = %d0.202391
INFO:root:frame =8217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:frame =8218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9805345
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =8221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000418901443481
INFO:root:frame =8222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000418901443481
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.980525
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.75392742e+01]
 [  4.56374146e+02]
 [  9.00915718e+00]
 [  4.26903191e+01]
 [  4.78259308e+02]
 [  1.36862402e+03]
 [  1.21939743e+00]
 [  4.14950562e+01]
 [  1.34594299e+02]
 [  6.27104187e+01]
 [  7.01603985e+00]
 [  1.37592821e+01]
 [  2.75392742e+01]
 [  2.31209591e-01]
 [  3.13485327e+03]
 [  4.78259308e+02]]
DEBUG:root:training time = %d0.203893
INFO:root:frame =8225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =8226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226020812988
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9805155
DEBUG:root: dqn, choose action rondomly, need time 0.00029600000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =8229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000485897064209
INFO:root:frame =8230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488996505737
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.980506
DEBUG:root: dqn, choose action rondomly, need time 0.000413000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.09334503e+02]
 [  7.59592163e+02]
 [  7.66265988e-01]
 [  1.27186401e+02]
 [  9.10882617e+03]
 [  3.78584671e+01]
 [  6.19528542e+01]
 [  3.03148341e+00]
 [  2.64560181e+03]
 [  5.35135132e+02]
 [  1.67889801e+02]
 [  1.10500717e+00]
 [  3.02783298e+01]
 [  2.51172638e+02]
 [  8.54484558e+00]
 [  3.30925598e+02]]
DEBUG:root:training time = %d0.205065
INFO:root:frame =8233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:frame =8234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame = 8235 State into memory, numbers recorded 217 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000275135040283
INFO:root:random_action_porb = 0.9804965
DEBUG:root: dqn, choose action rondomly, need time 0.000158999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8236current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000130891799927
INFO:root:frame =8237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =8238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.980487
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[   6.66247368]
 [   3.74521947]
 [   3.12363124]
 [  12.0582819 ]
 [ 347.58413696]
 [  14.36312389]
 [ 108.50975037]
 [   1.82911432]
 [  37.59744644]
 [ 364.35180664]
 [   0.77422065]
 [ 126.72579956]
 [ 257.33096313]
 [  25.60882568]
 [  87.58161926]
 [  13.90575504]]
DEBUG:root:training time = %d0.211646
INFO:root:frame =8241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250816345215
INFO:root:frame =8242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466823577881
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.9804775
DEBUG:root: dqn, choose action rondomly, need time 0.000272999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =8245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042986869812
INFO:root:frame =8246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000297069549561
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.980468
DEBUG:root: dqn, choose action rondomly, need time 0.000259999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =8248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.55353241e+01]
 [  7.69562073e+01]
 [  1.99139881e+01]
 [  7.87618332e+01]
 [  1.43386519e+00]
 [  5.63548775e+01]
 [  2.12818718e+01]
 [  1.27857061e+04]
 [  1.49002502e+03]
 [  1.08426380e+01]
 [  5.73302002e+02]
 [  1.04022820e+02]
 [  1.07507362e+01]
 [  5.67431717e+01]
 [  4.38973331e+00]
 [  5.72075073e+02]]
DEBUG:root:training time = %d0.22631
INFO:root:frame =8249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =8250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00040602684021
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9804585
DEBUG:root: dqn, choose action rondomly, need time 0.000335000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =8253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =8254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000597953796387
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.980449
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.80956197e+00]
 [  2.21159863e+00]
 [  1.56344421e+02]
 [  1.24862961e+02]
 [  2.11484406e+02]
 [  7.63457642e+02]
 [  3.05248833e+01]
 [  7.85595520e+02]
 [  9.99968848e+03]
 [  8.36616669e+01]
 [  5.94549799e+00]
 [  1.78011341e+01]
 [  5.86259651e+00]
 [  9.09933281e+00]
 [  1.06436377e+01]
 [  4.60759491e+02]]
DEBUG:root:training time = %d0.210386
INFO:root:frame =8257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =8258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.9804395
DEBUG:root: dqn, choose action rondomly, need time 0.000178000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000192165374756
INFO:root:frame =8261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =8262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000312089920044
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.98043
DEBUG:root: dqn, choose action rondomly, need time 0.000156000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.00794821e+01]
 [  3.29839325e+01]
 [  7.49099255e-01]
 [  1.90006973e+02]
 [  3.02025848e+02]
 [  7.35312012e+03]
 [  1.00526360e+02]
 [  2.49416423e+00]
 [  5.72935425e+02]
 [  1.32248352e+03]
 [  4.60110168e+01]
 [  7.81258392e+01]
 [  5.55179167e+00]
 [  1.19982643e+02]
 [  1.11880264e+02]
 [  3.37836938e+03]]
DEBUG:root:training time = %d0.185513
INFO:root:frame =8265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:frame =8266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame = 8267 State into memory, numbers recorded 218 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:random_action_porb = 0.9804205
DEBUG:root: dqn, choose action rondomly, need time 0.000383999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8268current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =8269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000616073608398
INFO:root:frame =8270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:random_action_porb = 0.980411
DEBUG:root: dqn, choose action rondomly, need time 0.000382000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.26140442e+01]
 [  1.59424149e+02]
 [  4.84475459e-04]
 [  1.49253857e+00]
 [  1.58522614e+02]
 [  8.09523865e+02]
 [  1.30784159e+01]
 [  3.43346710e+02]
 [  1.43587291e-01]
 [  1.31155252e+01]
 [  2.81678369e+03]
 [  5.71446800e+00]
 [  2.83041504e+02]
 [  3.76748824e+00]
 [  4.54207840e+01]
 [  9.26140442e+01]]
DEBUG:root:training time = %d0.218761
INFO:root:frame =8273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:frame =8274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame = 8275 State into memory, numbers recorded 219 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000561952590942
INFO:root:random_action_porb = 0.9804015
DEBUG:root: dqn, choose action rondomly, need time 0.000198000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =8276current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root:frame =8277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =8278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000416994094849
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:random_action_porb = 0.980392
DEBUG:root: dqn, choose action rondomly, need time 0.000324000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =8280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:training error  = [[  1.95026760e+01]
 [  5.35890320e+02]
 [  6.29825745e+02]
 [  5.11544403e+02]
 [  3.90812256e+02]
 [  8.77974243e+02]
 [  1.46950500e+02]
 [  2.60339588e-01]
 [  4.53704071e+01]
 [  5.90586567e+00]
 [  8.20274925e+00]
 [  3.43484711e+02]
 [  1.53490448e+01]
 [  2.54312851e+02]
 [  3.22101318e+02]
 [  1.10774822e+01]]
DEBUG:root:training time = %d0.217395
INFO:root:frame =8281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =8282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 9.29832458496e-05
INFO:root:random_action_porb = 0.9803825
DEBUG:root: dqn, choose action rondomly, need time 0.000216999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =8284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =8285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =8286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame = 8287 State into memory, numbers recorded 220 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:random_action_porb = 0.980373
DEBUG:root: dqn, choose action rondomly, need time 0.000229000000019
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8288current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.12175491e+02]
 [  1.85623360e+01]
 [  1.20431671e+02]
 [  7.35449677e+01]
 [  2.97971802e+02]
 [  1.28568909e+03]
 [  1.53315932e-01]
 [  1.30983448e+01]
 [  4.38234528e+02]
 [  4.71690559e+01]
 [  2.92650852e+01]
 [  2.39713452e+03]
 [  4.21074982e+01]
 [  1.73935104e+02]
 [  1.69542358e+02]
 [  1.43980742e-01]]
DEBUG:root:training time = %d0.196545
INFO:root:frame =8289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =8290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411987304688
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root:random_action_porb = 0.9803635
DEBUG:root: dqn, choose action rondomly, need time 0.000194999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =8293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =8294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475883483887
DEBUG:root: save sample needs time = 0.000255823135376
INFO:root:random_action_porb = 0.980354
DEBUG:root: dqn, choose action rondomly, need time 0.000207999999986
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =8296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000188112258911
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.41817704e-03]
 [  3.94620898e+03]
 [  6.20480156e+00]
 [  6.50939882e-01]
 [  3.36570215e+03]
 [  2.19371367e+04]
 [  2.32715637e+02]
 [  1.41817704e-03]
 [  1.63704361e+02]
 [  3.77923645e+02]
 [  8.03133774e+00]
 [  1.20593822e+00]
 [  1.55709863e+04]
 [  8.79009033e+02]
 [  4.62197418e+02]
 [  9.26473846e+01]]
DEBUG:root:training time = %d0.184243
INFO:root:frame =8297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00051212310791
INFO:root:frame =8298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000307083129883
