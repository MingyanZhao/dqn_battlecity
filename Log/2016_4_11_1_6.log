INFO:root:enemies_left [0]
INFO:root:frame =0 recording current_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =1 recording current_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =2 recording current_observation no.2
DEBUG:root: save sample needs time = 0.00053596496582
INFO:root:frame =3 recording current_observation no.3
DEBUG:root: save sample needs time = 0.000481843948364
INFO:root:frame =4current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000419855117798
INFO:root:frame =5 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =6 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame = 7 State into memory, numbers recorded 1 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000562906265259
INFO:root:frame =8current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =9 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =10 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:frame =12 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000470876693726
INFO:root:frame =13 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame =14 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:frame =16 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =17 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453233718872
INFO:root:frame =18 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:random_action_porb = 0.999968333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =20 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =21 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =22 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000209808349609
INFO:root:random_action_porb = 0.999936666667
DEBUG:root: dqn, choose action rondomly, need time 0.000441
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =24 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =25 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =26 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 9.41753387451e-05
INFO:root:random_action_porb = 0.999905
DEBUG:root: dqn, choose action rondomly, need time 0.00036
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =28 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =29 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =30 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.999873333333
DEBUG:root: dqn, choose action rondomly, need time 0.000349
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =32 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:frame =33 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =34 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame = 35 State into memory, numbers recorded 2 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000612020492554
INFO:root:random_action_porb = 0.999841666667
DEBUG:root: dqn, choose action rondomly, need time 0.000171
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =36current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000136137008667
INFO:root:frame =37 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =38 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229835510254
INFO:root:frame = 39 State into memory, numbers recorded 3 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000286817550659
INFO:root:random_action_porb = 0.99981
DEBUG:root: dqn, choose action rondomly, need time 0.000169
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =40current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:frame =41 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002281665802
INFO:root:frame =42 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.999778333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =44 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =45 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:frame =46 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.999746666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =48 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =49 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =50 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 9.91821289062e-05
INFO:root:random_action_porb = 0.999715
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =52 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =53 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000560998916626
INFO:root:frame =54 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00030779838562
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.999683333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =56 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =57 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =58 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000281095504761
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.999651666667
DEBUG:root: dqn, choose action rondomly, need time 0.000233
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =60 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =61 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000480890274048
INFO:root:frame =62 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000123977661133
INFO:root:random_action_porb = 0.99962
DEBUG:root: dqn, choose action rondomly, need time 0.000181
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =64 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000152111053467
INFO:root:frame =65 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:frame =66 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.0002281665802
INFO:root:random_action_porb = 0.999588333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =68 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:frame =69 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =70 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.999556666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =72 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =73 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =74 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485181808472
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:random_action_porb = 0.999525
DEBUG:root: dqn, choose action rondomly, need time 0.00033
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =76 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =77 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =78 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000625848770142
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.999493333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =80 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00036096572876
INFO:root:frame =81 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465154647827
INFO:root:frame =82 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame = 83 State into memory, numbers recorded 4 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000663995742798
INFO:root:random_action_porb = 0.999461666667
DEBUG:root: dqn, choose action rondomly, need time 0.00031
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =84current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =85 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028920173645
INFO:root:frame =86 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000563859939575
INFO:root:frame = 87 State into memory, numbers recorded 5 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000638008117676
INFO:root:random_action_porb = 0.99943
DEBUG:root: dqn, choose action rondomly, need time 0.000231
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =88current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =89 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000494003295898
INFO:root:frame =90 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root:frame = 91 State into memory, numbers recorded 6 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000593185424805
INFO:root:random_action_porb = 0.999398333333
DEBUG:root: dqn, choose action rondomly, need time 0.00046
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =92current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =93 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =94 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470876693726
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.999366666667
DEBUG:root: dqn, choose action rondomly, need time 0.000326
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =96 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root:frame =97 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470876693726
INFO:root:frame =98 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.999335
DEBUG:root: dqn, choose action rondomly, need time 0.000494
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
DEBUG:root: save sample needs time = 0.000147104263306
INFO:root:random_action_porb = 0.999303333333
DEBUG:root: dqn, choose action rondomly, need time 0.000207
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000522136688232
INFO:root:frame =106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.999271666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.99924
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000730037689209
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.999208333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000485897064209
INFO:root:frame =118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000251054763794
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.999176666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000521898269653
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.999145
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000201225280762
INFO:root:random_action_porb = 0.999113333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.999081666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.99905
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000125885009766
INFO:root:random_action_porb = 0.999018333333
DEBUG:root: dqn, choose action rondomly, need time 0.000193
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174999237061
INFO:root:frame =141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454187393188
INFO:root:frame =142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000318050384521
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.998986666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240802764893
INFO:root:frame = 147 State into memory, numbers recorded 7 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000562906265259
INFO:root:random_action_porb = 0.998955
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =148current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436782836914
INFO:root:frame =150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000201225280762
INFO:root:random_action_porb = 0.998923333333
DEBUG:root: dqn, choose action rondomly, need time 0.00031
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456809997559
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.998891666667
DEBUG:root: dqn, choose action rondomly, need time 0.000317
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.99886
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame = 163 State into memory, numbers recorded 8 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000537157058716
INFO:root:random_action_porb = 0.998828333333
DEBUG:root: dqn, choose action rondomly, need time 0.00017
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =164current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000136852264404
INFO:root:frame =165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame =166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.998796666667
DEBUG:root: dqn, choose action rondomly, need time 0.000312
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456809997559
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.998765
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root:frame =174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.998733333333
DEBUG:root: dqn, choose action rondomly, need time 0.000341
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000353097915649
INFO:root:frame =177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000591993331909
INFO:root:frame =178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame = 179 State into memory, numbers recorded 9 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000562906265259
INFO:root:random_action_porb = 0.998701666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =180current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000380992889404
INFO:root:frame =182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308990478516
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.99867
DEBUG:root: dqn, choose action rondomly, need time 0.000165
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185012817383
INFO:root:frame =185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame = 187 State into memory, numbers recorded 10 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000794887542725
INFO:root:random_action_porb = 0.998638333333
DEBUG:root: dqn, choose action rondomly, need time 0.00031
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =188current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.998606666667
DEBUG:root: dqn, choose action rondomly, need time 0.000322
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491142272949
INFO:root:frame =194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.998575
DEBUG:root: dqn, choose action rondomly, need time 0.000286
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049901008606
INFO:root:frame =198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.998543333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428915023804
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.998511666667
DEBUG:root: dqn, choose action rondomly, need time 0.000363
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.99848
DEBUG:root: dqn, choose action rondomly, need time 0.0003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000524044036865
INFO:root:frame =210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002601146698
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:random_action_porb = 0.998448333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000423908233643
INFO:root:frame =214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.998416666667
DEBUG:root: dqn, choose action rondomly, need time 0.000311
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.998385
DEBUG:root: dqn, choose action rondomly, need time 0.000286
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233888626099
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.998353333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:frame =226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000546932220459
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.998321666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.99829
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.998258333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.998226666667
DEBUG:root: dqn, choose action rondomly, need time 0.000324
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.998195
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470876693726
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.998163333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:random_action_porb = 0.998131666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000631093978882
INFO:root:frame =254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308990478516
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.9981
DEBUG:root: dqn, choose action rondomly, need time 0.000536
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root:frame =257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000500917434692
INFO:root:frame =258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488042831421
INFO:root:frame = 259 State into memory, numbers recorded 11 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000600099563599
INFO:root:random_action_porb = 0.998068333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =260current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000486135482788
INFO:root:frame =262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000380039215088
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.998036666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449180603027
INFO:root:frame =266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.998005
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame = 271 State into memory, numbers recorded 12 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000574111938477
INFO:root:random_action_porb = 0.997973333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =272current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame = 275 State into memory, numbers recorded 13 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000538110733032
INFO:root:random_action_porb = 0.997941666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =276current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.99791
DEBUG:root: dqn, choose action rondomly, need time 0.0003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000513076782227
INFO:root:frame =282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487804412842
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.997878333333
DEBUG:root: dqn, choose action rondomly, need time 0.00031
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.997846666667
DEBUG:root: dqn, choose action rondomly, need time 0.000311
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485897064209
INFO:root:frame = 291 State into memory, numbers recorded 14 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000566005706787
INFO:root:random_action_porb = 0.997815
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =292current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000495195388794
INFO:root:frame =294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.997783333333
DEBUG:root: dqn, choose action rondomly, need time 0.000324
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root:frame =298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.997751666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000364065170288
INFO:root:frame =301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.99772
DEBUG:root: dqn, choose action rondomly, need time 0.000296
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.997688333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.997656666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:frame =313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.997625
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame = 319 State into memory, numbers recorded 15 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000602006912231
INFO:root:random_action_porb = 0.997593333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =320current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.997561666667
DEBUG:root: dqn, choose action rondomly, need time 0.0003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000494956970215
INFO:root:frame =326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000201225280762
INFO:root:random_action_porb = 0.99753
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470876693726
DEBUG:root: save sample needs time = 0.00017786026001
INFO:root:random_action_porb = 0.997498333333
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000495910644531
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.997466666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000481128692627
INFO:root:frame =338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.00010085105896
INFO:root:random_action_porb = 0.997435
DEBUG:root: dqn, choose action rondomly, need time 0.000464
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:frame =341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root:frame =342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.997403333333
DEBUG:root: dqn, choose action rondomly, need time 0.000321
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488042831421
INFO:root:frame =346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000243186950684
INFO:root:random_action_porb = 0.997371666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:random_action_porb = 0.99734
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame =354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.997308333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.997276666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000346183776855
INFO:root:frame =361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.997245
DEBUG:root: dqn, choose action rondomly, need time 0.000292
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.997213333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.997181666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000265836715698
INFO:root:random_action_porb = 0.99715
DEBUG:root: dqn, choose action rondomly, need time 0.000313
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.997118333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000108957290649
INFO:root:random_action_porb = 0.997086666667
DEBUG:root: dqn, choose action rondomly, need time 0.00017
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:frame =385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.997055
DEBUG:root: dqn, choose action rondomly, need time 0.0003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.997023333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.996991666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.99696
DEBUG:root: dqn, choose action rondomly, need time 0.000293
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:frame =401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000451803207397
INFO:root:frame =402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.996928333333
DEBUG:root: dqn, choose action rondomly, need time 0.000317
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000521898269653
DEBUG:root: save sample needs time = 0.000101804733276
INFO:root:random_action_porb = 0.996896666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000565052032471
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:random_action_porb = 0.996865
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491142272949
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.996833333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.996801666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.99677
DEBUG:root: dqn, choose action rondomly, need time 0.000176
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000162839889526
INFO:root:frame =425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:random_action_porb = 0.996738333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.996706666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000486850738525
INFO:root:frame =434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000543117523193
DEBUG:root: save sample needs time = 0.000235795974731
INFO:root:random_action_porb = 0.996675
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.996643333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.996611666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.99658
DEBUG:root: dqn, choose action rondomly, need time 0.00031
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:random_action_porb = 0.996548333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.996516666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.996485
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.996453333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000487804412842
INFO:root:frame =466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame = 467 State into memory, numbers recorded 16 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000593900680542
INFO:root:random_action_porb = 0.996421666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =468current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000343799591064
INFO:root:frame =469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.99639
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488042831421
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.996358333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.996326666667
DEBUG:root: dqn, choose action rondomly, need time 0.0003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.996295
DEBUG:root: dqn, choose action rondomly, need time 0.000185
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000176906585693
INFO:root:frame =485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000545978546143
INFO:root:frame =486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.996263333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.996231666667
DEBUG:root: dqn, choose action rondomly, need time 0.000183
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000173091888428
INFO:root:frame =493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:frame =494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.9962
DEBUG:root: dqn, choose action rondomly, need time 0.000525
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000508069992065
INFO:root:frame =498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.996168333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000499963760376
INFO:root:frame =502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000499963760376
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.996136666667
DEBUG:root: dqn, choose action rondomly, need time 0.000164
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:frame =505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000424861907959
INFO:root:frame =506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.996105
DEBUG:root: dqn, choose action rondomly, need time 0.000286
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233173370361
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.996073333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.996041666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.99601
DEBUG:root: dqn, choose action rondomly, need time 0.000314
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472784042358
INFO:root:frame =522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:random_action_porb = 0.995978333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482082366943
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.995946666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000487089157104
INFO:root:frame =530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.995915
DEBUG:root: dqn, choose action rondomly, need time 0.000305
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470876693726
INFO:root:frame =534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:random_action_porb = 0.995883333333
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.995851666667
DEBUG:root: dqn, choose action rondomly, need time 0.000316
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.99582
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:random_action_porb = 0.995788333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame =550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.995756666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.995725
DEBUG:root: dqn, choose action rondomly, need time 0.000319
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049090385437
INFO:root:frame = 559 State into memory, numbers recorded 17 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:random_action_porb = 0.995693333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =560current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000604867935181
INFO:root:frame =562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000497102737427
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.995661666667
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.99563
DEBUG:root: dqn, choose action rondomly, need time 0.000288
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000503063201904
DEBUG:root: save sample needs time = 0.000237226486206
INFO:root:random_action_porb = 0.995598333333
DEBUG:root: dqn, choose action rondomly, need time 0.0003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame =574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.995566666667
DEBUG:root: dqn, choose action rondomly, need time 0.0003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.995535
DEBUG:root: dqn, choose action rondomly, need time 0.000293
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411033630371
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.995503333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224828720093
INFO:root:frame =586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.995471666667
DEBUG:root: dqn, choose action rondomly, need time 0.000338
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428915023804
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:random_action_porb = 0.99544
DEBUG:root: dqn, choose action rondomly, need time 0.000324
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.995408333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000201225280762
INFO:root:random_action_porb = 0.995376666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.995345
DEBUG:root: dqn, choose action rondomly, need time 0.0003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:random_action_porb = 0.995313333333
DEBUG:root: dqn, choose action rondomly, need time 0.0003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491857528687
INFO:root:frame =610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.995281666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000594139099121
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.99525
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000336885452271
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.995218333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.995186666667
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root:frame =626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.995155
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000451803207397
INFO:root:frame =630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.995123333333
DEBUG:root: dqn, choose action rondomly, need time 0.000262999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:frame =633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root:frame = 635 State into memory, numbers recorded 18 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.00037407875061
INFO:root:random_action_porb = 0.995091666667
DEBUG:root: dqn, choose action rondomly, need time 0.0005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =636current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000515937805176
INFO:root:frame =638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.99506
DEBUG:root: dqn, choose action rondomly, need time 0.000563
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.995028333333
DEBUG:root: dqn, choose action rondomly, need time 0.000424
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049090385437
INFO:root:frame =646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.994996666667
DEBUG:root: dqn, choose action rondomly, need time 0.000538000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000494003295898
INFO:root:frame =650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491142272949
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.994965
DEBUG:root: dqn, choose action rondomly, need time 0.000547
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame = 655 State into memory, numbers recorded 19 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.00054407119751
INFO:root:random_action_porb = 0.994933333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =656current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.994901666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486850738525
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.99487
DEBUG:root: dqn, choose action rondomly, need time 0.000293
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.994838333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.994806666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465154647827
INFO:root:frame =674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.994775
DEBUG:root: dqn, choose action rondomly, need time 0.000316
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.994743333333
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491142272949
INFO:root:frame =682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000222206115723
INFO:root:random_action_porb = 0.994711666667
DEBUG:root: dqn, choose action rondomly, need time 0.000331
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000652074813843
INFO:root:frame =686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.99468
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355958938599
INFO:root:frame =689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame =690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488042831421
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.994648333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:random_action_porb = 0.994616666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.994585
DEBUG:root: dqn, choose action rondomly, need time 0.0003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000499963760376
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.994553333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491857528687
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.994521666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.99449
DEBUG:root: dqn, choose action rondomly, need time 0.000262
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:random_action_porb = 0.994458333333
DEBUG:root: dqn, choose action rondomly, need time 0.000321
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320196151733
INFO:root:frame =717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045919418335
DEBUG:root: save sample needs time = 0.000201225280762
INFO:root:random_action_porb = 0.994426666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000475883483887
INFO:root:frame =722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.994395
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466823577881
INFO:root:frame =726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:random_action_porb = 0.994363333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root:frame =729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.994331666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0003821849823
INFO:root:frame =733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.9943
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.994268333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486850738525
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.994236666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.994205
DEBUG:root: dqn, choose action rondomly, need time 0.0003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049901008606
INFO:root:frame =750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame = 751 State into memory, numbers recorded 20 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000553131103516
INFO:root:random_action_porb = 0.994173333333
DEBUG:root: dqn, choose action rondomly, need time 0.000319
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =752current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000494003295898
INFO:root:frame =754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:random_action_porb = 0.994141666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000417947769165
INFO:root:frame =758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.99411
DEBUG:root: dqn, choose action rondomly, need time 0.0003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.994078333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.994046666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.994015
DEBUG:root: dqn, choose action rondomly, need time 0.000315
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:frame =774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:random_action_porb = 0.993983333333
DEBUG:root: dqn, choose action rondomly, need time 0.00032
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466823577881
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.993951666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.99392
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.993888333333
DEBUG:root: dqn, choose action rondomly, need time 0.000201000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:frame =789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481128692627
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.993856666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000502824783325
INFO:root:frame =794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.993825
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454187393188
INFO:root:frame =798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.993793333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:player has been killed for 1 times 
INFO:root:frame =801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame = 803 State into memory, numbers recorded 21 action = 1, reward = -1
DEBUG:root: save sample needs time = 0.000572919845581
INFO:root:random_action_porb = 0.993761666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =804current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.99373
DEBUG:root: dqn, choose action rondomly, need time 0.000164
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:frame =809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433206558228
INFO:root:frame =810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423192977905
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.993698333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.993666666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231981277466
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.993635
DEBUG:root: dqn, choose action rondomly, need time 0.00031
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294208526611
INFO:root:frame =821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.993603333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.993571666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456809997559
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.99354
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame = 835 State into memory, numbers recorded 22 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.00056004524231
INFO:root:random_action_porb = 0.993508333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =836current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root:frame =837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame =838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.993476666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000492095947266
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.993445
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.993413333333
DEBUG:root: dqn, choose action rondomly, need time 0.000321
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame = 851 State into memory, numbers recorded 23 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000586032867432
INFO:root:random_action_porb = 0.993381666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =852current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.99335
DEBUG:root: dqn, choose action rondomly, need time 0.000349
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.993318333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000378131866455
INFO:root:frame =861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:random_action_porb = 0.993286666667
DEBUG:root: dqn, choose action rondomly, need time 0.000253
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000378847122192
INFO:root:frame =866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481128692627
INFO:root:frame = 867 State into memory, numbers recorded 24 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000511169433594
INFO:root:random_action_porb = 0.993255
DEBUG:root: dqn, choose action rondomly, need time 0.000548999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =868current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.993223333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000494003295898
INFO:root:frame =874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000519990921021
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.993191666667
DEBUG:root: dqn, choose action rondomly, need time 0.000312
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.99316
DEBUG:root: dqn, choose action rondomly, need time 0.000313
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.993128333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.993096666667
DEBUG:root: dqn, choose action rondomly, need time 0.000326
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000476837158203
INFO:root:frame =890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.993065
DEBUG:root: dqn, choose action rondomly, need time 0.000295
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440835952759
INFO:root:frame =894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235080718994
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.993033333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:random_action_porb = 0.993001666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.99297
DEBUG:root: dqn, choose action rondomly, need time 0.000265
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.992938333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.992906666667
DEBUG:root: dqn, choose action rondomly, need time 0.000318999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.992875
DEBUG:root: dqn, choose action rondomly, need time 0.000303
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.992843333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046181678772
INFO:root:frame =922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.992811666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000498056411743
INFO:root:frame = 927 State into memory, numbers recorded 25 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000336170196533
INFO:root:random_action_porb = 0.99278
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =928current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.992748333333
DEBUG:root: dqn, choose action rondomly, need time 0.00032
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:frame =934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:random_action_porb = 0.992716666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame = 939 State into memory, numbers recorded 26 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000569820404053
INFO:root:random_action_porb = 0.992685
DEBUG:root: dqn, choose action rondomly, need time 0.00027
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =940current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:frame =941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000484943389893
INFO:root:frame =942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.992653333333
DEBUG:root: dqn, choose action rondomly, need time 0.000166
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:frame =945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000498056411743
INFO:root:frame =946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:random_action_porb = 0.992621666667
DEBUG:root: dqn, choose action rondomly, need time 0.000549
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049901008606
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.99259
DEBUG:root: dqn, choose action rondomly, need time 0.000293
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000504016876221
INFO:root:frame =954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.992558333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.992526666667
DEBUG:root: dqn, choose action rondomly, need time 0.000324
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.992495
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.992463333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.992431666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9924
DEBUG:root: dqn, choose action rondomly, need time 0.000317
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440835952759
INFO:root:frame =978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000209808349609
INFO:root:random_action_porb = 0.992368333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:random_action_porb = 0.992336666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame =986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000501871109009
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:random_action_porb = 0.992305
DEBUG:root: dqn, choose action rondomly, need time 0.000311
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:random_action_porb = 0.992273333333
DEBUG:root: dqn, choose action rondomly, need time 0.000328
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:random_action_porb = 0.992241666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428915023804
DEBUG:root: save sample needs time = 0.000198125839233
DEBUG:root:one frame running time = 0.006279
DEBUG:root:total training time = 6.329701
INFO:root:frame num = 1000 frame round: 0
INFO:root:random_action_porb = 0.99221
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =1001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =1002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:random_action_porb = 0.992178333333
DEBUG:root: dqn, choose action rondomly, need time 0.000166
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =1005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =1006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 9.58442687988e-05
INFO:root:random_action_porb = 0.992146666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =1009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042986869812
INFO:root:frame =1010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.992115
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =1013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453233718872
INFO:root:frame =1014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.992083333333
DEBUG:root: dqn, choose action rondomly, need time 0.000271000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000194787979126
INFO:root:frame =1017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =1018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:random_action_porb = 0.992051666667
DEBUG:root: dqn, choose action rondomly, need time 0.000547
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =1021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =1022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.99202
DEBUG:root: dqn, choose action rondomly, need time 0.000291
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root:frame =1026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.991988333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =1029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471115112305
INFO:root:frame =1030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.991956666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =1033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000424861907959
INFO:root:frame =1034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430822372437
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.991925
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root:frame =1037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =1038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.991893333333
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =1041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:frame =1042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
INFO:root:frame = 1043 State into memory, numbers recorded 27 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000549793243408
INFO:root:random_action_porb = 0.991861666667
DEBUG:root: dqn, choose action rondomly, need time 0.000164
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1044current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =1045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =1046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 9.41753387451e-05
INFO:root:random_action_porb = 0.99183
DEBUG:root: dqn, choose action rondomly, need time 0.000296
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =1050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.991798333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000392913818359
INFO:root:frame =1053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:frame =1054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229835510254
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.991766666667
DEBUG:root: dqn, choose action rondomly, need time 0.000163
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000130176544189
INFO:root:frame =1057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =1058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.991735
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =1061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =1062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.991703333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =1065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =1066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.991671666667
DEBUG:root: dqn, choose action rondomly, need time 0.0003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =1069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =1070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.99164
DEBUG:root: dqn, choose action rondomly, need time 0.00033
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =1073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =1074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.991608333333
DEBUG:root: dqn, choose action rondomly, need time 0.00028
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000419139862061
INFO:root:frame =1078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000425100326538
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.991576666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =1081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame =1082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.991545
DEBUG:root: dqn, choose action rondomly, need time 0.000298
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =1085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456809997559
INFO:root:frame =1086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.991513333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =1090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.991481666667
DEBUG:root: dqn, choose action rondomly, need time 0.000199
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000146865844727
INFO:root:frame =1093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root:frame =1094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.99145
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000315189361572
INFO:root:frame =1097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430822372437
INFO:root:frame =1098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.991418333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =1101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000423908233643
INFO:root:frame =1102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.991386666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =1105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =1106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.991355
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000315189361572
INFO:root:frame =1109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000486135482788
INFO:root:frame =1110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:random_action_porb = 0.991323333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =1113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =1114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456809997559
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.991291666667
DEBUG:root: dqn, choose action rondomly, need time 0.000327
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =1118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000356912612915
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:random_action_porb = 0.99126
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root: ememy has been killed for 1 times 
INFO:root:enemies_left [0]
INFO:root:frame =1120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:frame =1121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049090385437
INFO:root:frame =1122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame = 1123 State into memory, numbers recorded 28 action = 0, reward = 1
DEBUG:root: save sample needs time = 0.000579833984375
INFO:root:random_action_porb = 0.991228333333
DEBUG:root: dqn, choose action rondomly, need time 0.00027
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1124current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =1125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =1126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.991196666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =1129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =1130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.991165
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =1133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =1134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame = 1135 State into memory, numbers recorded 29 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000565052032471
INFO:root:random_action_porb = 0.991133333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1136current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =1137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =1138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.991101666667
DEBUG:root: dqn, choose action rondomly, need time 0.000210000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =1141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =1142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.99107
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =1145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =1146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:random_action_porb = 0.991038333333
DEBUG:root: dqn, choose action rondomly, need time 0.000271999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =1149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =1150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.991006666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root:frame =1153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436782836914
INFO:root:frame =1154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.990975
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root:frame =1157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =1158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000431060791016
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.990943333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =1161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =1162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.990911666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000341892242432
INFO:root:frame =1165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =1166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000833034515381
INFO:root:random_action_porb = 0.99088
DEBUG:root: dqn, choose action rondomly, need time 0.000211
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000135183334351
INFO:root:frame =1169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =1170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.990848333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =1173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =1174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.990816666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =1177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =1178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.990785
DEBUG:root: dqn, choose action rondomly, need time 0.000323
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =1181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =1182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:random_action_porb = 0.990753333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =1185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =1186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000497817993164
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.990721666667
INFO:root:dqn select action Tensor("ArgMax:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013912
INFO:root:action choosen by dqn [1]
INFO:root:frame =1188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000167846679688
INFO:root:frame =1189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =1190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.99069
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =1194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438213348389
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.990658333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465154647827
INFO:root:frame =1198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.990626666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =1201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449180603027
INFO:root:frame =1202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.990595
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =1205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =1206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.990563333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =1209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =1210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.990531666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =1214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.9905
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =1217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =1218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.990468333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:frame =1222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.990436666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =1225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:player has been killed for 2 times 
INFO:root:frame =1226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame = 1227 State into memory, numbers recorded 30 action = 3, reward = -1
DEBUG:root: save sample needs time = 0.000539064407349
INFO:root:random_action_porb = 0.990405
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1228current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000695943832397
INFO:root:frame =1229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =1230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000555038452148
INFO:root:frame = 1231 State into memory, numbers recorded 31 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000560998916626
INFO:root:random_action_porb = 0.990373333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1232current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =1233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000407934188843
INFO:root:frame =1234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.990341666667
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =1237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =1238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.99031
DEBUG:root: dqn, choose action rondomly, need time 0.000335
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =1242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:random_action_porb = 0.990278333333
DEBUG:root: dqn, choose action rondomly, need time 0.000226
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =1245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000545024871826
INFO:root:frame =1246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:random_action_porb = 0.990246666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =1249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =1250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.990215
DEBUG:root: dqn, choose action rondomly, need time 0.000306
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:frame =1253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame =1254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438213348389
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.990183333333
DEBUG:root: dqn, choose action rondomly, need time 0.000318999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =1257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488996505737
INFO:root:frame =1258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.990151666667
DEBUG:root: dqn, choose action rondomly, need time 0.000342
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =1261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000496864318848
INFO:root:frame =1262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.99012
DEBUG:root: dqn, choose action rondomly, need time 0.000318999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =1265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000493049621582
INFO:root:frame =1266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.990088333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000351905822754
INFO:root:frame =1269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =1270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.990056666667
DEBUG:root: dqn, choose action rondomly, need time 0.000316
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =1273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =1274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000425100326538
INFO:root:player has been killed for 3 times 
INFO:root:frame = 1275 State into memory, numbers recorded 32 action = -1, reward = -1
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:random_action_porb = 0.990025
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1276current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =1278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame = 1279 State into memory, numbers recorded 33 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000570058822632
INFO:root:random_action_porb = 0.989993333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1280current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =1281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =1282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame = 1283 State into memory, numbers recorded 34 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000541925430298
INFO:root:random_action_porb = 0.989961666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1284current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =1285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =1286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.98993
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =1289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =1290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475883483887
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.989898333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =1293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =1294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.989866666667
DEBUG:root: dqn, choose action rondomly, need time 0.000174999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =1297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =1298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.989835
INFO:root:dqn select action Tensor("ArgMax_1:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013698
INFO:root:action choosen by dqn [1]
INFO:root:frame =1300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00017786026001
INFO:root:frame =1301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =1302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.989803333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =1305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =1306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.989771666667
DEBUG:root: dqn, choose action rondomly, need time 0.000332999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000367879867554
INFO:root:frame =1309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =1310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.98974
DEBUG:root: dqn, choose action rondomly, need time 0.000316
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =1313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =1314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488042831421
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.989708333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =1317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000493049621582
INFO:root:frame =1318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00041389465332
DEBUG:root: save sample needs time = 0.000104904174805
INFO:root:random_action_porb = 0.989676666667
DEBUG:root: dqn, choose action rondomly, need time 0.000278000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =1322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000532150268555
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:random_action_porb = 0.989645
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =1325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000482082366943
INFO:root:frame =1326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:random_action_porb = 0.989613333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =1329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444173812866
INFO:root:frame =1330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.989581666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =1334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000103950500488
INFO:root:random_action_porb = 0.98955
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =1337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000476121902466
INFO:root:frame =1338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000242948532104
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.989518333333
DEBUG:root: dqn, choose action rondomly, need time 0.000313
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =1341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =1342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:random_action_porb = 0.989486666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =1345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =1346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.989455
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =1349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root:frame =1350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.989423333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331163406372
INFO:root:frame =1353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =1354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481128692627
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:random_action_porb = 0.989391666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000362873077393
INFO:root:frame =1357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =1358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047492980957
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.98936
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =1361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =1362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:random_action_porb = 0.989328333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =1365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =1366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame = 1367 State into memory, numbers recorded 35 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000587940216064
INFO:root:random_action_porb = 0.989296666667
DEBUG:root: dqn, choose action rondomly, need time 0.000323
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1368current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =1369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000504016876221
INFO:root:frame =1370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.989265
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =1373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000492095947266
INFO:root:frame =1374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.989233333333
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =1377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =1378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000499963760376
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.989201666667
DEBUG:root: dqn, choose action rondomly, need time 0.000334000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =1381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000494003295898
INFO:root:frame =1382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.98917
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =1385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =1386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root: ememy has been killed for 2 times 
INFO:root:enemies_left [0]
INFO:root:frame = 1387 State into memory, numbers recorded 36 action = 1, reward = 1
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root:random_action_porb = 0.989138333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1388current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =1390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.989106666667
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =1393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =1394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.989075
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =1397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000591993331909
INFO:root:frame =1398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000299215316772
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:random_action_porb = 0.989043333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =1401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =1402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.989011666667
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =1405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =1406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.98898
DEBUG:root: dqn, choose action rondomly, need time 0.000313
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000377178192139
INFO:root:frame =1409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462770462036
INFO:root:frame =1410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.988948333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =1413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470161437988
INFO:root:frame =1414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.988916666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322818756104
INFO:root:frame =1417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000485181808472
INFO:root:frame =1418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame = 1419 State into memory, numbers recorded 37 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000571966171265
INFO:root:random_action_porb = 0.988885
DEBUG:root: dqn, choose action rondomly, need time 0.000278999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1420current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =1421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =1422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.988853333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =1425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =1426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.988821666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =1429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000509023666382
INFO:root:frame =1430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488996505737
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.98879
DEBUG:root: dqn, choose action rondomly, need time 0.000418000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =1433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =1434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00053596496582
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.988758333333
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =1437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000484943389893
INFO:root:frame =1438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.988726666667
DEBUG:root: dqn, choose action rondomly, need time 0.000334000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =1441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =1442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.988695
INFO:root:dqn select action Tensor("ArgMax_2:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011856
INFO:root:action choosen by dqn [1]
INFO:root:frame =1444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000166177749634
INFO:root:frame =1445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =1446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000266790390015
INFO:root:frame = 1447 State into memory, numbers recorded 38 action = [1], reward = 0
DEBUG:root: save sample needs time = 0.00125098228455
INFO:root:random_action_porb = 0.988663333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1448current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root:frame =1449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =1450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449180603027
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:random_action_porb = 0.988631666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000363111495972
INFO:root:frame =1453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =1454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485897064209
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.9886
DEBUG:root: dqn, choose action rondomly, need time 0.000181
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:frame =1457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =1458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.988568333333
DEBUG:root: dqn, choose action rondomly, need time 0.000280999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =1462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.988536666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =1465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root:frame =1466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.988505
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =1469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame =1470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:random_action_porb = 0.988473333333
DEBUG:root: dqn, choose action rondomly, need time 0.000178999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000181913375854
INFO:root:frame =1473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =1474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame = 1475 State into memory, numbers recorded 39 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000600814819336
INFO:root:random_action_porb = 0.988441666667
DEBUG:root: dqn, choose action rondomly, need time 0.000164999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1476current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:frame =1477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:frame =1478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.98841
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =1481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =1482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.988378333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =1485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =1486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.988346666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =1489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =1490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.988315
DEBUG:root: dqn, choose action rondomly, need time 0.000306
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =1493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =1494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.988283333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =1497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000498056411743
INFO:root:frame =1498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:random_action_porb = 0.988251666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =1501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =1502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.98822
DEBUG:root: dqn, choose action rondomly, need time 0.000169
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =1505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =1506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.988188333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =1509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =1510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.988156666667
DEBUG:root: dqn, choose action rondomly, need time 0.000316000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000383853912354
INFO:root:frame =1514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000408887863159
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.988125
DEBUG:root: dqn, choose action rondomly, need time 0.000314999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =1517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =1518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.00010085105896
INFO:root:random_action_porb = 0.988093333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =1521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000540018081665
INFO:root:frame =1522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025486946106
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.988061666667
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =1525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root:frame =1526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.98803
DEBUG:root: dqn, choose action rondomly, need time 0.000292
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =1529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =1530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.987998333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =1533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =1534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241041183472
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.987966666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =1537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =1538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.987935
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root:frame =1541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =1542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.987903333333
DEBUG:root: dqn, choose action rondomly, need time 0.000317000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =1546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487089157104
INFO:root:frame = 1547 State into memory, numbers recorded 40 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000611066818237
INFO:root:random_action_porb = 0.987871666667
DEBUG:root: dqn, choose action rondomly, need time 0.000168
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1548current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000152111053467
INFO:root:frame =1549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =1550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.98784
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =1553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =1554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.987808333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =1557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469207763672
INFO:root:frame =1558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.987776666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =1561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =1562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.987745
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =1565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =1566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.987713333333
DEBUG:root: dqn, choose action rondomly, need time 0.000313
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =1570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00051212310791
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.987681666667
DEBUG:root: dqn, choose action rondomly, need time 0.000325999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000516891479492
INFO:root:frame =1574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047492980957
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.98765
DEBUG:root: dqn, choose action rondomly, need time 0.000327
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =1577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000485897064209
INFO:root:frame =1578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:random_action_porb = 0.987618333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =1582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.987586666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =1585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000423908233643
INFO:root:frame =1586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.987555
DEBUG:root: dqn, choose action rondomly, need time 0.000289
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =1589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000370025634766
INFO:root:frame =1590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.987523333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =1593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =1594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 9.58442687988e-05
INFO:root:random_action_porb = 0.987491666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =1597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =1598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.98746
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000368118286133
INFO:root:frame =1602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.987428333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =1606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.987396666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.50316238e+01]
 [  2.79074162e-02]
 [  7.82762617e-02]
 [  1.55173750e+01]
 [  1.05991125e+01]
 [  1.05937109e+01]
 [  9.77268964e-02]
 [  3.59596038e+00]
 [  4.22870970e+00]
 [  5.92518486e-02]
 [  1.55173750e+01]
 [  2.73709641e+01]
 [  3.63965893e+00]
 [  2.84226856e+01]
 [  2.50316238e+01]
 [  7.45179594e-01]]
DEBUG:root:training time = %d0.235735
INFO:root:frame =1609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =1610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000341892242432
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.987365
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =1613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225782394409
INFO:root:frame =1614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.987333333333
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029182434082
INFO:root:training error  = [[  3.89433615e-02]
 [  7.41639137e+00]
 [  3.11956363e-04]
 [  4.46868515e+01]
 [  1.85790136e-02]
 [  4.24136581e+01]
 [  1.36916056e+01]
 [  7.41639137e+00]
 [  4.14900208e+01]
 [  1.71437120e+00]
 [  4.46868515e+01]
 [  1.61178589e+00]
 [  6.58906746e+00]
 [  3.03125242e-03]
 [  2.05126023e+00]
 [  1.90967155e+00]]
DEBUG:root:training time = %d0.225086
INFO:root:frame =1617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =1618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000362873077393
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.987301666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =1621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000378847122192
INFO:root:frame =1622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.98727
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.84903669e-01]
 [  3.26867104e+01]
 [  3.26867104e+01]
 [  2.45034928e-03]
 [  2.18460467e-02]
 [  2.14175072e+01]
 [  2.05435162e+01]
 [  8.73598397e-01]
 [  4.63761787e+01]
 [  2.17890873e+01]
 [  3.25709343e+01]
 [  3.32774658e+01]
 [  1.19070101e+00]
 [  4.63761787e+01]
 [  2.23775463e+01]
 [  3.28050041e+01]]
DEBUG:root:training time = %d0.247866
INFO:root:frame =1625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =1626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000416994094849
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.987238333333
DEBUG:root: dqn, choose action rondomly, need time 0.000265000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:frame =1629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame =1630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.987206666667
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  0.09495102]
 [  8.36495972]
 [ 10.76601601]
 [  7.94026852]
 [ 28.79651642]
 [ 28.79651642]
 [  0.07569857]
 [  0.40123931]
 [ 42.61184311]
 [  7.69598961]
 [  7.69598961]
 [ 10.76601601]
 [ 17.91769028]
 [  0.19783694]
 [  0.40123931]
 [ 41.08682632]]
DEBUG:root:training time = %d0.222049
INFO:root:frame =1633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =1634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.987175
DEBUG:root: dqn, choose action rondomly, need time 0.00052
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =1637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000579833984375
INFO:root:frame =1638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.987143333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.86651111e+00]
 [  1.57715130e+01]
 [  2.67053528e+01]
 [  9.20685959e+00]
 [  4.02914276e+01]
 [  9.20685959e+00]
 [  1.20463778e-06]
 [  4.51489353e+00]
 [  9.20685959e+00]
 [  4.44895601e+00]
 [  1.64679451e+01]
 [  1.64679451e+01]
 [  3.96621361e+01]
 [  4.44895601e+00]
 [  4.44895601e+00]
 [  4.55691576e+00]]
DEBUG:root:training time = %d0.215772
INFO:root:frame =1641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =1642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263214111328
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.987111666667
DEBUG:root: dqn, choose action rondomly, need time 0.000351999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =1645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =1646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000512838363647
INFO:root:frame = 1647 State into memory, numbers recorded 41 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:random_action_porb = 0.98708
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1648current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.33211124e+00]
 [  1.91356468e+01]
 [  4.36209738e-02]
 [  1.92535439e+01]
 [  1.23324168e+00]
 [  1.00452719e+01]
 [  2.16240957e-02]
 [  9.94152260e+00]
 [  1.53250623e+00]
 [  1.95835686e+01]
 [  1.41586518e+00]
 [  1.31818700e+00]
 [  1.00552816e+01]
 [  9.87859821e+00]
 [  1.01688843e+01]
 [  8.44146777e-03]]
DEBUG:root:training time = %d0.211089
INFO:root:frame =1649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =1650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.987048333333
DEBUG:root: dqn, choose action rondomly, need time 0.000376999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =1653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000514984130859
INFO:root:frame =1654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.987016666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  0.08538312]
 [  0.52284008]
 [  1.25517213]
 [  7.16818047]
 [  7.93634558]
 [ 11.13867092]
 [  7.0530653 ]
 [ 11.94201374]
 [  6.78425884]
 [  0.02258823]
 [  8.35419369]
 [  0.1319809 ]
 [  0.02258823]
 [  0.04842509]
 [ 11.94201374]
 [  7.0530653 ]]
DEBUG:root:training time = %d0.220417
INFO:root:frame =1657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =1658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000617980957031
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.986985
DEBUG:root: dqn, choose action rondomly, need time 0.000331000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000696897506714
INFO:root:frame =1661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root:frame =1662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:random_action_porb = 0.986953333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:training error  = [[ 5.38677788]
 [ 3.26909018]
 [ 0.07236436]
 [ 3.02925062]
 [ 0.04146186]
 [ 4.08687353]
 [ 0.04619083]
 [ 4.00792694]
 [ 0.04619083]
 [ 5.39331865]
 [ 4.77607965]
 [ 0.04619083]
 [ 5.19602919]
 [ 3.19991899]
 [ 3.22073126]
 [ 3.02925062]]
DEBUG:root:training time = %d0.225826
INFO:root:frame =1665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:frame =1666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000399112701416
INFO:root:frame = 1667 State into memory, numbers recorded 42 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.00058388710022
INFO:root:random_action_porb = 0.986921666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1668current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:frame =1669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =1670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.98689
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3.05888939]
 [ 1.94456577]
 [ 2.19595766]
 [ 2.21094203]
 [ 1.49525213]
 [ 5.33992481]
 [ 1.69637156]
 [ 3.46165848]
 [ 1.93262994]
 [ 3.290555  ]
 [ 0.51287466]
 [ 1.94456577]
 [ 1.3530407 ]
 [ 0.08689933]
 [ 2.21094203]
 [ 3.46165848]]
DEBUG:root:training time = %d0.220309
INFO:root:frame =1673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =1674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.986858333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =1677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =1678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
DEBUG:root: save sample needs time = 9.29832458496e-05
INFO:root:random_action_porb = 0.986826666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.18829766]
 [ 0.15732163]
 [ 1.89423537]
 [ 0.21501575]
 [ 1.80185366]
 [ 1.36026645]
 [ 1.34368205]
 [ 5.59614515]
 [ 5.44800854]
 [ 5.03384733]
 [ 2.31993651]
 [ 5.30681849]
 [ 0.17829528]
 [ 0.21501575]
 [ 5.94923782]
 [ 0.08384076]]
DEBUG:root:training time = %d0.234314
INFO:root:frame =1681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =1682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.986795
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =1685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =1686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.986763333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 6.37693787]
 [ 1.26442575]
 [ 3.97730613]
 [ 1.89816332]
 [ 1.26442575]
 [ 1.15690029]
 [ 1.15690029]
 [ 6.18446684]
 [ 1.35393488]
 [ 4.04413128]
 [ 0.13737845]
 [ 5.44871426]
 [ 1.89816332]
 [ 1.15690029]
 [ 0.11118053]
 [ 3.97730613]]
DEBUG:root:training time = %d0.245254
INFO:root:frame =1689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =1690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000332117080688
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.986731666667
DEBUG:root: dqn, choose action rondomly, need time 0.000271
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =1693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =1694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9867
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5.48230219]
 [ 3.25991297]
 [ 2.99444795]
 [ 5.15693808]
 [ 2.6007874 ]
 [ 0.15099986]
 [ 8.69212627]
 [ 3.69786429]
 [ 3.58074212]
 [ 2.68397212]
 [ 0.2227526 ]
 [ 0.30077907]
 [ 0.09308454]
 [ 0.15919429]
 [ 0.11906993]
 [ 0.20458183]]
DEBUG:root:training time = %d0.214329
INFO:root:frame =1697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:frame =1698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000306844711304
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.986668333333
DEBUG:root: dqn, choose action rondomly, need time 0.000398000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame =1701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =1702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471830368042
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.986636666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:training error  = [[ 6.88113022]
 [ 3.12453461]
 [ 3.12453461]
 [ 0.15000573]
 [ 3.32973838]
 [ 7.19142675]
 [ 2.47318435]
 [ 2.55880213]
 [ 2.32818413]
 [ 2.68702888]
 [ 3.32973838]
 [ 3.18420744]
 [ 6.57464933]
 [ 2.64541125]
 [ 4.09680271]
 [ 6.57464933]]
DEBUG:root:training time = %d0.238199
INFO:root:frame =1705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =1706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000260829925537
DEBUG:root: save sample needs time = 0.000120878219604
INFO:root:random_action_porb = 0.986605
DEBUG:root: dqn, choose action rondomly, need time 0.000317999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000183820724487
INFO:root:frame =1709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =1710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485897064209
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.986573333333
DEBUG:root: dqn, choose action rondomly, need time 0.000344
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 6.73109674]
 [ 0.26244006]
 [ 6.53082418]
 [ 2.47478199]
 [ 0.23982134]
 [ 2.29969859]
 [ 0.13748983]
 [ 0.16760601]
 [ 0.30846691]
 [ 0.36440611]
 [ 0.2028158 ]
 [ 0.23982134]
 [ 0.43141666]
 [ 0.26244006]
 [ 0.35483155]
 [ 0.41748101]]
DEBUG:root:training time = %d0.220789
INFO:root:frame =1713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:frame =1714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:random_action_porb = 0.986541666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =1717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000663995742798
INFO:root:frame =1718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.98651
DEBUG:root: dqn, choose action rondomly, need time 0.000316
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4.79042339]
 [ 4.79042339]
 [ 4.44757605]
 [ 2.93792915]
 [ 0.73780435]
 [ 6.35837889]
 [ 0.77908176]
 [ 6.35837889]
 [ 0.22260949]
 [ 6.2568779 ]
 [ 3.49108815]
 [ 0.24011753]
 [ 3.05365443]
 [ 0.8856461 ]
 [ 0.22260949]
 [ 4.44757605]]
DEBUG:root:training time = %d0.234608
INFO:root:frame =1721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =1722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:random_action_porb = 0.986478333333
DEBUG:root: dqn, choose action rondomly, need time 0.000426999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =1725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =1726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.986446666667
DEBUG:root: dqn, choose action rondomly, need time 0.000382
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000425100326538
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1.8158561 ]
 [ 7.56312943]
 [ 1.76085472]
 [ 7.09949017]
 [ 1.66337907]
 [ 5.54048586]
 [ 1.84969246]
 [ 1.74889088]
 [ 1.56984949]
 [ 2.1169138 ]
 [ 1.80916166]
 [ 0.18733425]
 [ 0.17757882]
 [ 2.14360809]
 [ 0.19264659]
 [ 6.53014183]]
DEBUG:root:training time = %d0.222712
INFO:root:frame =1729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =1730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259160995483
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:random_action_porb = 0.986415
DEBUG:root: dqn, choose action rondomly, need time 0.000350000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =1733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000614166259766
INFO:root:frame =1734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.986383333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.28945827e+00]
 [  6.28945827e+00]
 [  6.63071728e+00]
 [  1.85603511e+00]
 [  5.85591555e+00]
 [  3.60772200e-03]
 [  6.24743509e+00]
 [  1.23588820e+01]
 [  9.27950084e-01]
 [  6.24743509e+00]
 [  1.61588681e+00]
 [  6.50571156e+00]
 [  5.80568171e+00]
 [  1.24049747e+00]
 [  6.28945827e+00]
 [  1.09910643e+00]]
DEBUG:root:training time = %d0.228673
INFO:root:frame =1737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =1738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:random_action_porb = 0.986351666667
DEBUG:root: dqn, choose action rondomly, need time 0.000195000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:frame =1741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =1742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000545978546143
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:random_action_porb = 0.98632
DEBUG:root: dqn, choose action rondomly, need time 0.000297
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.05953550e+00]
 [  2.35250562e-01]
 [  2.05953550e+00]
 [  2.03953823e-03]
 [  1.90816355e+00]
 [  1.37929225e+00]
 [  5.24713278e-01]
 [  2.21373796e+00]
 [  2.35250562e-01]
 [  1.24469233e+00]
 [  7.76039243e-01]
 [  3.06913763e-01]
 [  1.08897934e+01]
 [  2.13470626e+00]
 [  1.22030544e+00]
 [  2.98093617e-01]]
DEBUG:root:training time = %d0.228208
INFO:root:frame =1745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =1746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.986288333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000286817550659
INFO:root:frame =1749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =1750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.986256666667
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:training error  = [[  1.83941352]
 [ 11.1723175 ]
 [  0.19822763]
 [  0.25543752]
 [  0.38673303]
 [  6.87753868]
 [ 11.67109108]
 [  0.41758576]
 [  1.83612716]
 [  1.93596566]
 [  0.38673303]
 [  1.83941352]
 [ 11.67109108]
 [  1.86248243]
 [  1.98946333]
 [  6.2762537 ]]
DEBUG:root:training time = %d0.217027
INFO:root:frame =1753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =1754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000325918197632
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.986225
DEBUG:root: dqn, choose action rondomly, need time 0.000563
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =1757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000484943389893
INFO:root:frame =1758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000821828842163
INFO:root: ememy has been killed for 3 times 
INFO:root:enemies_left [0]
INFO:root:frame = 1759 State into memory, numbers recorded 43 action = 4, reward = 1
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:random_action_porb = 0.986193333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1760current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.44913143]
 [ 7.55048275]
 [ 0.73997343]
 [ 0.33267772]
 [ 2.48525286]
 [ 0.02618862]
 [ 2.79602075]
 [ 2.85898757]
 [ 0.32689008]
 [ 0.32723913]
 [ 2.99063206]
 [ 4.35372162]
 [ 6.73731327]
 [ 7.31637955]
 [ 3.56197143]
 [ 0.42188728]]
DEBUG:root:training time = %d0.213007
INFO:root:frame =1761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =1762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480890274048
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.986161666667
INFO:root:dqn select action Tensor("ArgMax_3:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015694
INFO:root:action choosen by dqn [1]
INFO:root:frame =1764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =1765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000393867492676
INFO:root:frame =1766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000421047210693
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.98613
DEBUG:root: dqn, choose action rondomly, need time 0.000539
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.62201118]
 [  8.89815712]
 [  0.34518382]
 [ 10.87603855]
 [  0.30897987]
 [ 16.63334465]
 [  8.92324257]
 [  0.40070757]
 [  8.75920677]
 [  8.78977299]
 [  0.40070757]
 [  0.35050014]
 [ 10.87603855]
 [  8.39881706]
 [  5.58384991]
 [ 16.63334465]]
DEBUG:root:training time = %d0.224207
INFO:root:frame =1769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =1770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000631093978882
DEBUG:root: save sample needs time = 0.000158071517944
INFO:root:random_action_porb = 0.986098333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =1773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =1774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480890274048
INFO:root:frame = 1775 State into memory, numbers recorded 44 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000560998916626
INFO:root:random_action_porb = 0.986066666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1776current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.68491101]
 [  0.44931296]
 [  5.03647089]
 [  1.71979606]
 [  0.33754477]
 [ 14.38794994]
 [  0.44931296]
 [  2.71324468]
 [ 13.45436573]
 [  4.25974989]
 [  0.38845482]
 [ 10.32324219]
 [  5.20709562]
 [  0.36831284]
 [  4.52030373]
 [  0.33754477]]
DEBUG:root:training time = %d0.227789
INFO:root:frame =1777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =1778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000131130218506
INFO:root:random_action_porb = 0.986035
DEBUG:root: dqn, choose action rondomly, need time 0.000404999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000191926956177
INFO:root:frame =1781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000337839126587
INFO:root:frame =1782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.986003333333
DEBUG:root: dqn, choose action rondomly, need time 0.000533000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.71757317]
 [  8.32176304]
 [  1.77412689]
 [  4.43834925]
 [  3.85678172]
 [  3.52946091]
 [  8.17442226]
 [  1.77412689]
 [  0.35488495]
 [  2.29122567]
 [  3.31245446]
 [  2.15055037]
 [  3.3139751 ]
 [  3.31245446]
 [  0.30164585]
 [ 12.82655525]]
DEBUG:root:training time = %d0.217519
INFO:root:frame =1785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =1786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame = 1787 State into memory, numbers recorded 45 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000593900680542
INFO:root:random_action_porb = 0.985971666667
DEBUG:root: dqn, choose action rondomly, need time 0.000420999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1788current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000373125076294
INFO:root:frame =1789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446796417236
INFO:root:frame =1790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434160232544
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.98594
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000371932983398
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.67135042]
 [ 0.55552942]
 [ 0.61358196]
 [ 5.9803462 ]
 [ 0.7129879 ]
 [ 0.35426709]
 [ 5.83547258]
 [ 0.88130754]
 [ 5.9803462 ]
 [ 3.71329975]
 [ 0.78057581]
 [ 6.63937426]
 [ 8.51738548]
 [ 0.55552942]
 [ 0.39971453]
 [ 0.70428389]]
DEBUG:root:training time = %d0.227829
INFO:root:frame =1793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =1794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00040602684021
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:random_action_porb = 0.985908333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =1797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000598907470703
INFO:root:frame =1798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509977340698
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.985876666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[  6.94251251]
 [ 11.52063465]
 [  6.69240046]
 [  0.3433764 ]
 [  2.71571159]
 [  0.44255859]
 [  3.19392347]
 [  3.11343884]
 [  3.2558713 ]
 [ 11.10234356]
 [  6.95661163]
 [  7.60188484]
 [  3.03205132]
 [  0.37509808]
 [  9.51747799]
 [  0.51884681]]
DEBUG:root:training time = %d0.234836
INFO:root:frame =1801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =1802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000278949737549
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.985845
DEBUG:root: dqn, choose action rondomly, need time 0.000474999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =1805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00037407875061
INFO:root:frame =1806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame = 1807 State into memory, numbers recorded 46 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000560998916626
INFO:root:random_action_porb = 0.985813333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1808current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000411033630371
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.51562119]
 [  5.22276306]
 [  1.22704649]
 [  0.53597671]
 [  4.50469208]
 [  9.21379471]
 [ 10.33757496]
 [  4.50469208]
 [  0.53597671]
 [ 10.15245438]
 [  4.24934816]
 [  9.45090866]
 [  9.40969181]
 [  0.46019557]
 [  5.10183096]
 [  4.82544088]]
DEBUG:root:training time = %d0.224315
INFO:root:frame =1809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:frame =1810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000615835189819
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.985781666667
DEBUG:root: dqn, choose action rondomly, need time 0.000198000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000191926956177
INFO:root:frame =1813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =1814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488996505737
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.98575
DEBUG:root: dqn, choose action rondomly, need time 0.000329000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000401020050049
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  0.05822459]
 [  0.57295799]
 [  1.57616246]
 [  1.63514411]
 [  0.05822459]
 [  0.58473974]
 [ 11.03751183]
 [ 10.71335793]
 [  0.68719912]
 [  1.52099407]
 [ 11.32654858]
 [  1.90258718]
 [  0.60247803]
 [  1.57616246]
 [  4.93031549]
 [  0.51207244]]
DEBUG:root:training time = %d0.215958
INFO:root:frame =1817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290155410767
INFO:root:frame =1818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504016876221
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.985718333333
DEBUG:root: dqn, choose action rondomly, need time 0.000323000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =1821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00075101852417
INFO:root:frame =1822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.985686666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.13729882]
 [  0.55408168]
 [  6.36958981]
 [  0.80632305]
 [ 12.30147743]
 [  9.32098675]
 [  6.01968002]
 [  0.44669583]
 [  3.34233403]
 [  3.16321683]
 [  8.11236191]
 [  6.42870474]
 [  6.56224251]
 [  2.82714224]
 [  8.36269951]
 [  3.22469974]]
DEBUG:root:training time = %d0.250366
INFO:root:frame =1825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =1826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame = 1827 State into memory, numbers recorded 47 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.00056791305542
INFO:root:random_action_porb = 0.985655
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1828current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =1829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000534057617188
INFO:root:frame =1830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480890274048
DEBUG:root: save sample needs time = 0.000609874725342
INFO:root:random_action_porb = 0.985623333333
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 0.50397277]
 [ 4.66631603]
 [ 6.53774738]
 [ 1.92996991]
 [ 1.85044217]
 [ 4.66631603]
 [ 6.43274832]
 [ 6.43274832]
 [ 7.27633762]
 [ 0.75586468]
 [ 2.65007734]
 [ 6.70239115]
 [ 7.29968882]
 [ 4.98441839]
 [ 1.92996991]
 [ 7.27633762]]
DEBUG:root:training time = %d0.209328
INFO:root:frame =1833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =1834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000220060348511
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.985591666667
DEBUG:root: dqn, choose action rondomly, need time 0.000349999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =1837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =1838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.98556
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000346183776855
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.47736335]
 [  8.27903748]
 [ 17.16963005]
 [  0.62076384]
 [ 14.36885643]
 [  6.7231369 ]
 [ 16.93084526]
 [  6.97859287]
 [ 17.16963005]
 [  3.4922359 ]
 [  0.60017365]
 [  3.42200732]
 [ 17.06221771]
 [  6.79701281]
 [  0.88652408]
 [  6.97859287]]
DEBUG:root:training time = %d0.241084
INFO:root:frame =1841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000260829925537
INFO:root:frame =1842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.985528333333
DEBUG:root: dqn, choose action rondomly, need time 0.000430999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =1845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =1846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:random_action_porb = 0.985496666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000315189361572
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.47374439]
 [  8.49651909]
 [ 13.83732319]
 [ 14.37354946]
 [  0.64554662]
 [  8.49651909]
 [ 15.44942284]
 [ 13.78699398]
 [  4.66786575]
 [  0.0226225 ]
 [  4.74239016]
 [  8.11659431]
 [  8.11659431]
 [ 14.37354946]
 [ 14.21229267]
 [  7.45227289]]
DEBUG:root:training time = %d0.216487
INFO:root:frame =1849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =1850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259876251221
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.985465
DEBUG:root: dqn, choose action rondomly, need time 0.000316000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:frame =1853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000482082366943
INFO:root:frame =1854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame = 1855 State into memory, numbers recorded 48 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000547885894775
INFO:root:random_action_porb = 0.985433333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1856current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:training error  = [[ 14.55853748]
 [  3.99274015]
 [  7.94771957]
 [ 14.55853748]
 [  4.26582623]
 [  3.83216643]
 [ 16.10435677]
 [  4.24427366]
 [ 14.85224342]
 [  0.68142271]
 [ 16.10435677]
 [  4.27718735]
 [  3.7755115 ]
 [  3.83216643]
 [  0.78545177]
 [  9.09713459]]
DEBUG:root:training time = %d0.228089
INFO:root:frame =1857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:frame =1858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.985401666667
DEBUG:root: dqn, choose action rondomly, need time 0.000170000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000141143798828
INFO:root:frame =1861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =1862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.98537
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.74376488]
 [ 11.08680344]
 [ 12.85035896]
 [  5.38919783]
 [  6.81740093]
 [ 13.77707386]
 [  4.73599148]
 [  6.1641326 ]
 [  6.1641326 ]
 [  6.58130217]
 [ 13.47613907]
 [ 11.08680344]
 [  6.64761353]
 [  1.81220567]
 [  1.80463386]
 [  5.38919783]]
DEBUG:root:training time = %d0.217167
INFO:root:frame =1865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =1866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:random_action_porb = 0.985338333333
DEBUG:root: dqn, choose action rondomly, need time 0.000416999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =1869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466823577881
INFO:root:frame =1870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485897064209
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:random_action_porb = 0.985306666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[  4.02096987]
 [  2.51894403]
 [  4.02096987]
 [  2.45161533]
 [  4.15985298]
 [  0.75243431]
 [ 15.32836723]
 [  0.76368028]
 [ 16.36494255]
 [  2.14491224]
 [  2.51894403]
 [  2.40134478]
 [ 15.67926693]
 [ 10.49382877]
 [  0.76368028]
 [  4.25137329]]
DEBUG:root:training time = %d0.224638
INFO:root:frame =1873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:frame =1874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000550985336304
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.985275
DEBUG:root: dqn, choose action rondomly, need time 0.000328
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =1877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =1878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.985243333333
DEBUG:root: dqn, choose action rondomly, need time 0.000591
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.16010082]
 [ 14.78891945]
 [  7.78634024]
 [  3.00231004]
 [ 14.8000555 ]
 [  0.96198481]
 [  5.23805189]
 [ 15.13055229]
 [  0.87271947]
 [  1.16010082]
 [ 14.94425392]
 [  0.82346499]
 [ 15.13055229]
 [  2.97537637]
 [ 13.76337147]
 [  3.16586351]]
DEBUG:root:training time = %d0.23992
INFO:root:frame =1881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =1882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.985211666667
DEBUG:root: dqn, choose action rondomly, need time 0.000584999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000387907028198
INFO:root:frame =1885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =1886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000500917434692
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.98518
DEBUG:root: dqn, choose action rondomly, need time 0.000477
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000402927398682
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.81996441]
 [  8.5117588 ]
 [  9.47119045]
 [ 12.65668106]
 [ 12.53500938]
 [ 20.55501556]
 [  0.91211593]
 [ 11.71789742]
 [ 13.15173149]
 [ 14.1992445 ]
 [ 11.71537781]
 [  4.07794428]
 [ 12.53500938]
 [ 11.71789742]
 [ 11.95243645]
 [  9.74558449]]
DEBUG:root:training time = %d0.21586
INFO:root:frame =1889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =1890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255107879639
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.985148333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =1893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000494003295898
INFO:root:frame =1894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000571966171265
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.985116666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:training error  = [[  3.2411716 ]
 [  2.96404314]
 [  9.55465603]
 [  1.24911392]
 [  2.24716854]
 [  9.6997776 ]
 [  1.01801324]
 [  1.02448583]
 [  3.2411716 ]
 [  1.30880809]
 [  2.4737289 ]
 [  3.38662553]
 [  1.03441358]
 [  1.24911392]
 [  3.00503373]
 [ 10.62826061]]
DEBUG:root:training time = %d0.225006
INFO:root:frame =1897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =1898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:random_action_porb = 0.985085
DEBUG:root: dqn, choose action rondomly, need time 0.000335
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342845916748
INFO:root:frame =1901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000385999679565
INFO:root:frame =1902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.985053333333
DEBUG:root: dqn, choose action rondomly, need time 0.000190999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2.0705595 ]
 [ 2.45220661]
 [ 6.68873024]
 [ 4.12872791]
 [ 2.30256295]
 [ 2.03678107]
 [ 2.45220661]
 [ 1.77976871]
 [ 1.81766856]
 [ 9.97907829]
 [ 9.92693233]
 [ 0.91704088]
 [ 9.13898277]
 [ 2.54755306]
 [ 8.99067593]
 [ 1.524454  ]]
DEBUG:root:training time = %d0.227866
INFO:root:frame =1905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =1906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.985021666667
DEBUG:root: dqn, choose action rondomly, need time 0.000339
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =1909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =1910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000518083572388
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root:random_action_porb = 0.98499
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.94141388]
 [  1.24513495]
 [  1.47716177]
 [  0.93457079]
 [  1.79663825]
 [  8.06339073]
 [  1.20046079]
 [  1.24627173]
 [  1.24513495]
 [  7.31024694]
 [  1.28297031]
 [  5.44378853]
 [ 11.94141388]
 [ 11.60682774]
 [  5.4474473 ]
 [  1.79663825]]
DEBUG:root:training time = %d0.219172
INFO:root:frame =1913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =1914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000498056411743
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.984958333333
DEBUG:root: dqn, choose action rondomly, need time 0.000552000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =1917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =1918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000429153442383
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.984926666667
DEBUG:root: dqn, choose action rondomly, need time 0.000415
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5.08686209]
 [ 2.28354073]
 [ 5.13964462]
 [ 6.83792448]
 [ 7.07181501]
 [ 1.11515558]
 [ 1.56099355]
 [ 2.28354073]
 [ 1.21892154]
 [ 0.9866969 ]
 [ 1.97973907]
 [ 6.68149042]
 [ 5.29417372]
 [ 1.21764576]
 [ 1.97973907]
 [ 2.35287642]]
DEBUG:root:training time = %d0.223469
INFO:root:frame =1921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =1922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:random_action_porb = 0.984895
DEBUG:root: dqn, choose action rondomly, need time 0.000209999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =1925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000369071960449
INFO:root:frame =1926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000406980514526
INFO:root:frame = 1927 State into memory, numbers recorded 49 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000565052032471
INFO:root:random_action_porb = 0.984863333333
DEBUG:root: dqn, choose action rondomly, need time 0.000171999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1928current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root:training error  = [[ 2.71287084]
 [ 9.67705154]
 [ 1.18281305]
 [ 4.83918095]
 [ 9.53972149]
 [ 9.78075886]
 [ 1.11366165]
 [ 1.24301612]
 [ 1.28513169]
 [ 9.53972149]
 [ 2.4218061 ]
 [ 2.63799739]
 [ 2.61731315]
 [ 5.17801857]
 [ 1.32242453]
 [ 2.71287084]]
DEBUG:root:training time = %d0.231118
INFO:root:frame =1929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =1930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root:random_action_porb = 0.984831666667
DEBUG:root: dqn, choose action rondomly, need time 0.000274000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =1933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000581979751587
INFO:root:frame =1934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:random_action_porb = 0.9848
DEBUG:root: dqn, choose action rondomly, need time 0.000274999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000362873077393
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.55548668]
 [  3.90410042]
 [  2.36891294]
 [  1.53534389]
 [ 10.72907066]
 [  2.82927537]
 [  6.84671545]
 [  1.18172216]
 [ 10.74358273]
 [  1.39884961]
 [  6.62262583]
 [  7.00879717]
 [  1.14590371]
 [ 10.72907066]
 [  6.89860821]
 [  2.53983235]]
DEBUG:root:training time = %d0.223488
INFO:root:frame =1937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =1938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000343084335327
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.984768333333
DEBUG:root: dqn, choose action rondomly, need time 0.000401999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =1941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000351905822754
INFO:root:frame =1942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000228881835938
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:random_action_porb = 0.984736666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.54321361]
 [  6.41248035]
 [ 14.51076221]
 [  5.88409996]
 [  5.88409996]
 [  1.43025887]
 [  1.88655686]
 [  6.19346094]
 [ 12.81537533]
 [ 13.49088955]
 [  1.2728579 ]
 [  5.72502327]
 [  6.41248035]
 [ 12.60713959]
 [  6.6354723 ]
 [  2.50063872]]
DEBUG:root:training time = %d0.215835
INFO:root:frame =1945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =1946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:random_action_porb = 0.984705
DEBUG:root: dqn, choose action rondomly, need time 0.000484
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =1949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047779083252
INFO:root:frame =1950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.984673333333
DEBUG:root: dqn, choose action rondomly, need time 0.000313999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.69615293]
 [  7.43955278]
 [  1.63332272]
 [  1.36126542]
 [ 11.46007347]
 [ 17.60448837]
 [  1.37931466]
 [  3.08473706]
 [ 11.46007347]
 [ 11.70269012]
 [  1.26701581]
 [  1.21648836]
 [  1.69615293]
 [  1.68011415]
 [  1.45521665]
 [  1.21648836]]
DEBUG:root:training time = %d0.216992
INFO:root:frame =1953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =1954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000659942626953
DEBUG:root: save sample needs time = 0.000176906585693
INFO:root:random_action_porb = 0.984641666667
DEBUG:root: dqn, choose action rondomly, need time 0.000537999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =1957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000424861907959
INFO:root:frame =1958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.98461
DEBUG:root: dqn, choose action rondomly, need time 0.000165000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  0.4326641 ]
 [  2.35927629]
 [ 14.73597908]
 [  1.37351012]
 [  7.53977394]
 [ 15.38583183]
 [ 18.32443047]
 [  0.4326641 ]
 [ 11.98916817]
 [  1.16180253]
 [ 12.08317184]
 [  1.56133199]
 [ 11.15848064]
 [  2.91524506]
 [  1.80235934]
 [  2.50006557]]
DEBUG:root:training time = %d0.234493
INFO:root:frame =1961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =1962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269174575806
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.984578333333
DEBUG:root: dqn, choose action rondomly, need time 0.000275000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root:frame =1965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000392913818359
INFO:root:frame =1966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000579118728638
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.984546666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000343799591064
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.49860322]
 [  8.68575668]
 [ 12.02447414]
 [ 16.11865807]
 [ 15.69417858]
 [ 11.43049431]
 [ 14.70970535]
 [  1.57962215]
 [ 15.33001041]
 [ 11.02633667]
 [ 16.1598053 ]
 [ 14.56725693]
 [  1.52804983]
 [ 14.88500118]
 [  7.55032539]
 [  7.89745855]]
DEBUG:root:training time = %d0.220968
INFO:root:frame =1969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =1970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000576972961426
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.984515
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =1973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =1974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000560998916626
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.984483333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:training error  = [[  3.91395807]
 [  4.33519554]
 [  5.51272583]
 [  4.96550846]
 [ 13.29655647]
 [  4.21721172]
 [  5.71883678]
 [ 13.26601315]
 [ 13.66183376]
 [  4.44428253]
 [  5.13060236]
 [  4.26054907]
 [  3.90147781]
 [  3.91395807]
 [  4.21721172]
 [  5.4405942 ]]
DEBUG:root:training time = %d0.231845
INFO:root:frame =1977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =1978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.984451666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =1980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =1981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =1982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.98442
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =1984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000405073165894
INFO:root:training error  = [[ 10.0503149 ]
 [  3.0379827 ]
 [  9.95649719]
 [  3.0379827 ]
 [  3.22620344]
 [  1.59413934]
 [  1.74000823]
 [  1.3962971 ]
 [ 16.6348381 ]
 [ 10.60802364]
 [  1.58776879]
 [  9.95649719]
 [  1.56734359]
 [  1.59413934]
 [  3.0379827 ]
 [  1.50517154]]
DEBUG:root:training time = %d0.222138
INFO:root:frame =1985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000328779220581
INFO:root:frame =1986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.984388333333
DEBUG:root: dqn, choose action rondomly, need time 0.000410000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =1988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =1989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471115112305
INFO:root:frame =1990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.984356666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =1992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14.86525726]
 [  3.50816178]
 [ 14.48066902]
 [  8.03189945]
 [ 25.08030701]
 [ 13.96768856]
 [  8.4241972 ]
 [  8.03189945]
 [  8.18314934]
 [ 13.09955978]
 [  1.69735038]
 [ 15.6109457 ]
 [  7.88758802]
 [ 14.56303501]
 [ 14.92788982]
 [  8.18314934]]
DEBUG:root:training time = %d0.210208
INFO:root:frame =1993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =1994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000357151031494
DEBUG:root: save sample needs time = 0.000111103057861
INFO:root:random_action_porb = 0.984325
DEBUG:root: dqn, choose action rondomly, need time 0.000173
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =1996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:frame =1997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =1998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000142097473145
DEBUG:root:one frame running time = 0.00361
DEBUG:root:total training time = 23.643067
INFO:root:frame num = 2000 frame round: 0
INFO:root:random_action_porb = 0.984293333333
DEBUG:root: dqn, choose action rondomly, need time 0.000413999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000412940979004
INFO:root:training error  = [[  9.95244026]
 [  5.40560198]
 [  5.6775775 ]
 [ 11.34228039]
 [ 10.15526867]
 [ 10.05298805]
 [  9.58006001]
 [  5.6775775 ]
 [  1.70768857]
 [  5.70435905]
 [ 10.15526867]
 [  5.17503309]
 [  9.58006001]
 [  9.58006001]
 [  1.83278942]
 [ 11.08643532]]
DEBUG:root:training time = %d0.216574
INFO:root:frame =2001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286817550659
INFO:root:frame =2002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000997066497803
DEBUG:root: save sample needs time = 0.00018310546875
INFO:root:random_action_porb = 0.984261666667
DEBUG:root: dqn, choose action rondomly, need time 0.000311
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000387907028198
INFO:root:frame =2005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =2006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame = 2007 State into memory, numbers recorded 50 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000563859939575
INFO:root:random_action_porb = 0.98423
DEBUG:root: dqn, choose action rondomly, need time 0.000346
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2008current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000363826751709
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  1.68140984]
 [  6.68248653]
 [ 19.52153206]
 [ 11.73784637]
 [  8.25830078]
 [  1.932374  ]
 [  1.98976195]
 [  7.24946976]
 [ 15.44173908]
 [ 14.00623703]
 [ 15.93383026]
 [  7.15148878]
 [ 19.52153206]
 [  6.68248653]
 [  7.15148878]
 [ 13.06542397]]
DEBUG:root:training time = %d0.20062
INFO:root:frame =2009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =2010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.984198333333
DEBUG:root: dqn, choose action rondomly, need time 0.000233000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root:frame =2013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042986869812
INFO:root:frame =2014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000382900238037
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.984166666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.78957844]
 [ 12.7896328 ]
 [  1.84485257]
 [ 12.04528999]
 [  2.06083322]
 [  8.30907917]
 [  2.14980912]
 [ 12.8211937 ]
 [  2.32276845]
 [  1.93987954]
 [  1.93987954]
 [  1.84485257]
 [ 12.36937046]
 [  8.90752983]
 [  1.84485257]
 [  5.9147687 ]]
DEBUG:root:training time = %d0.233565
INFO:root:frame =2017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =2018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.984135
DEBUG:root: dqn, choose action rondomly, need time 0.000294
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =2021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =2022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame = 2023 State into memory, numbers recorded 51 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000611066818237
INFO:root:random_action_porb = 0.984103333333
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2024current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.66457748]
 [ 17.3380661 ]
 [ 12.24897194]
 [  6.90999508]
 [  4.66457748]
 [  6.38062334]
 [ 12.38050938]
 [ 12.19033813]
 [ 16.85028458]
 [ 11.73925781]
 [ 17.58117485]
 [ 12.38050938]
 [  1.74064732]
 [  7.56198597]
 [ 26.53296852]
 [ 17.12360001]]
DEBUG:root:training time = %d0.231686
INFO:root:frame =2025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290155410767
INFO:root:frame =2026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.984071666667
DEBUG:root: dqn, choose action rondomly, need time 0.000349999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000357866287231
INFO:root:frame =2029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =2030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000617980957031
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.98404
DEBUG:root: dqn, choose action rondomly, need time 0.000192000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  4.00211382]
 [  4.42107153]
 [  3.4954195 ]
 [  3.65341282]
 [  2.04700708]
 [  3.82159972]
 [  4.15073156]
 [  9.68439865]
 [  3.74103475]
 [  4.42107153]
 [  4.03387737]
 [  4.41868162]
 [  4.21454048]
 [ 16.7504673 ]
 [ 16.52393532]
 [  3.4954195 ]]
DEBUG:root:training time = %d0.219207
INFO:root:frame =2033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame =2034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000156164169312
INFO:root:random_action_porb = 0.984008333333
DEBUG:root: dqn, choose action rondomly, need time 0.000178999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000130891799927
INFO:root:frame =2037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =2038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000334978103638
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:random_action_porb = 0.983976666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.1804564 ]
 [ 13.62732506]
 [  3.29221249]
 [  2.1804564 ]
 [ 15.4572134 ]
 [  2.5868535 ]
 [  2.3368125 ]
 [  0.41877356]
 [  0.41877356]
 [  2.95240378]
 [  2.86101007]
 [  0.59865409]
 [ 14.75749779]
 [  0.41877356]
 [  2.94897652]
 [  2.822824  ]]
DEBUG:root:training time = %d0.208981
INFO:root:frame =2041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =2042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308036804199
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:random_action_porb = 0.983945
DEBUG:root: dqn, choose action rondomly, need time 0.000270999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000346183776855
INFO:root:frame =2045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466823577881
INFO:root:frame =2046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
DEBUG:root: save sample needs time = 0.000176906585693
INFO:root:random_action_porb = 0.983913333333
DEBUG:root: dqn, choose action rondomly, need time 0.000266
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.36644459]
 [  9.11702728]
 [ 11.46266937]
 [  2.37704587]
 [  9.9767046 ]
 [ 11.70780563]
 [  0.53248173]
 [  3.15147018]
 [  9.9767046 ]
 [ 10.95434189]
 [  9.9767046 ]
 [  2.37704587]
 [  2.26219869]
 [ 12.34601021]
 [  2.72466445]
 [ 10.55575657]]
DEBUG:root:training time = %d0.22659
INFO:root:frame =2049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame =2050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000451803207397
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:random_action_porb = 0.983881666667
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =2053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =2054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:random_action_porb = 0.98385
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11.63754463]
 [ 12.22553921]
 [  2.28925705]
 [ 13.55706215]
 [ 12.70790958]
 [ 24.35293961]
 [ 24.48098564]
 [ 11.53587246]
 [ 16.20682526]
 [ 24.35293961]
 [ 13.55706215]
 [ 12.30238056]
 [ 12.94518948]
 [ 25.26730156]
 [ 25.72118378]
 [ 11.65821934]]
DEBUG:root:training time = %d0.219189
INFO:root:frame =2057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =2058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame = 2059 State into memory, numbers recorded 52 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000562906265259
INFO:root:random_action_porb = 0.983818333333
DEBUG:root: dqn, choose action rondomly, need time 0.000327000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2060current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =2061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =2062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234842300415
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.983786666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.95620656]
 [  9.24099064]
 [  2.48368049]
 [  2.73478007]
 [  3.20148182]
 [ 13.89286995]
 [  2.50221944]
 [  6.12421083]
 [  2.39197254]
 [  2.5256083 ]
 [  8.55057812]
 [ 22.68433952]
 [  2.48368049]
 [  7.41045809]
 [ 14.42160511]
 [  3.24262762]]
DEBUG:root:training time = %d0.226478
INFO:root:frame =2065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =2066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298023223877
DEBUG:root: save sample needs time = 0.000131130218506
INFO:root:random_action_porb = 0.983755
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =2069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000640153884888
INFO:root:frame =2070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.983723333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:training error  = [[  3.52965093]
 [  2.48446798]
 [  9.47700214]
 [  3.14238191]
 [  3.15247917]
 [  3.59343433]
 [  2.61958456]
 [ 11.1890583 ]
 [  2.61958456]
 [  3.01690221]
 [  9.18662643]
 [  3.59343433]
 [  3.9192729 ]
 [  9.77069187]
 [  9.45849228]
 [  6.98268509]]
DEBUG:root:training time = %d0.205534
INFO:root:frame =2073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =2074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274181365967
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.983691666667
DEBUG:root: dqn, choose action rondomly, need time 0.000183
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:frame =2077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =2078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
INFO:root:frame = 2079 State into memory, numbers recorded 53 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000564813613892
INFO:root:random_action_porb = 0.98366
DEBUG:root: dqn, choose action rondomly, need time 0.000249999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2080current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  2.56862044]
 [  2.56862044]
 [  6.41603565]
 [  2.1827836 ]
 [ 19.06183243]
 [ 15.44277382]
 [  5.10695457]
 [  6.41603565]
 [  9.45926666]
 [  2.4893229 ]
 [ 10.69133091]
 [  8.73789883]
 [  3.29374933]
 [ 19.06183243]
 [ 10.75417614]
 [ 10.78121376]]
DEBUG:root:training time = %d0.184687
INFO:root:frame =2081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =2082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427007675171
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:random_action_porb = 0.983628333333
DEBUG:root: dqn, choose action rondomly, need time 0.000154000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:frame =2085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002281665802
INFO:root:frame =2086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame = 2087 State into memory, numbers recorded 54 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:random_action_porb = 0.983596666667
DEBUG:root: dqn, choose action rondomly, need time 0.000170000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2088current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10.92842388]
 [ 16.68537903]
 [  4.34718943]
 [ 10.10219002]
 [ 15.85998821]
 [  6.51279163]
 [  3.41596961]
 [  5.64105988]
 [ 10.21760464]
 [  4.34718943]
 [  2.49224877]
 [  2.56528354]
 [ 10.22492218]
 [  2.92677188]
 [  2.92677188]
 [  3.10880971]]
DEBUG:root:training time = %d0.185815
INFO:root:frame =2089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =2090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.983565
DEBUG:root: dqn, choose action rondomly, need time 0.000183
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000145196914673
INFO:root:frame =2093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =2094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000266075134277
DEBUG:root: save sample needs time = 0.000126838684082
INFO:root:random_action_porb = 0.983533333333
DEBUG:root: dqn, choose action rondomly, need time 0.000213000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9.43288708]
 [  2.96070099]
 [ 11.38187218]
 [  2.79375029]
 [  9.43288708]
 [ 30.42384529]
 [ 30.42384529]
 [  3.59740543]
 [ 19.95019531]
 [ 11.35277939]
 [ 11.38187218]
 [  3.32129169]
 [ 10.13021755]
 [ 11.21947384]
 [  4.11787558]
 [ 22.33740044]]
DEBUG:root:training time = %d0.203204
INFO:root:frame =2097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =2098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.983501666667
DEBUG:root: dqn, choose action rondomly, need time 0.000353
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =2101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =2102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000525951385498
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:random_action_porb = 0.98347
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.83909321]
 [ 12.52350521]
 [ 22.42362595]
 [ 12.53036404]
 [  7.54444647]
 [  9.3978653 ]
 [ 12.7305479 ]
 [ 34.01903915]
 [ 22.46653175]
 [ 32.56180191]
 [ 13.87666512]
 [ 10.36803913]
 [ 31.88269997]
 [ 10.36803913]
 [ 34.01903915]
 [ 31.70326996]]
DEBUG:root:training time = %d0.226628
INFO:root:frame =2105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =2106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000586032867432
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.983438333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:frame =2109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000503063201904
INFO:root:frame =2110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.983406666667
DEBUG:root: dqn, choose action rondomly, need time 0.000331000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12.56501102]
 [ 18.7185688 ]
 [ 12.55084324]
 [ 13.27868748]
 [ 17.03445053]
 [  4.54288673]
 [ 12.36256981]
 [  3.27748609]
 [ 13.05092239]
 [ 16.89034843]
 [ 16.02705002]
 [  4.87150908]
 [  5.10019827]
 [ 19.77633858]
 [ 16.96848297]
 [ 21.61158943]]
DEBUG:root:training time = %d0.234603
INFO:root:frame =2113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243186950684
INFO:root:frame =2114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:random_action_porb = 0.983375
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =2117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =2118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000401020050049
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.983343333333
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.03227425]
 [ 14.95752907]
 [ 15.48333549]
 [  7.50951147]
 [ 26.62209511]
 [ 12.58346176]
 [ 12.58346176]
 [ 19.40566063]
 [  3.17100358]
 [  8.44974804]
 [ 12.69078159]
 [ 15.68410015]
 [ 15.68410015]
 [ 14.95752907]
 [  2.67117405]
 [ 15.61727619]]
DEBUG:root:training time = %d0.226027
INFO:root:frame =2121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =2122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000304937362671
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:random_action_porb = 0.983311666667
DEBUG:root: dqn, choose action rondomly, need time 0.000239000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root:frame =2125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000502824783325
INFO:root:frame =2126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.98328
INFO:root:dqn select action Tensor("ArgMax_4:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014624
INFO:root:action choosen by dqn [2]
INFO:root:frame =2128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000191926956177
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.53632617]
 [ 16.64675713]
 [  3.83397388]
 [ 14.03764915]
 [ 17.45518494]
 [ 16.81740189]
 [ 10.36192322]
 [ 10.67153358]
 [  5.33131361]
 [ 11.48674297]
 [ 18.15727234]
 [ 18.15727234]
 [ 15.09128571]
 [  3.46471286]
 [ 17.15374756]
 [  9.59455299]]
DEBUG:root:training time = %d0.19343
INFO:root:frame =2129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000357151031494
INFO:root:frame =2130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame = 2131 State into memory, numbers recorded 55 action = [2], reward = 0
DEBUG:root: save sample needs time = 0.000854969024658
INFO:root:random_action_porb = 0.983248333333
DEBUG:root: dqn, choose action rondomly, need time 0.000191000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2132current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =2133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000627994537354
INFO:root:frame =2134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025486946106
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:random_action_porb = 0.983216666667
DEBUG:root: dqn, choose action rondomly, need time 0.000384999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  3.65269113]
 [  4.22456264]
 [  0.9979564 ]
 [ 17.13842583]
 [  5.61116457]
 [  5.46994305]
 [  3.93441415]
 [ 16.69638252]
 [ 11.0938158 ]
 [  6.89294815]
 [  3.9104495 ]
 [  3.59212565]
 [  4.08249807]
 [  3.74433374]
 [  4.18148708]
 [  5.46994305]]
DEBUG:root:training time = %d0.215949
INFO:root:frame =2137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =2138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275850296021
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.983185
DEBUG:root: dqn, choose action rondomly, need time 0.000346
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000414133071899
INFO:root:frame =2141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000609874725342
INFO:root:frame =2142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:random_action_porb = 0.983153333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 15.07999516]
 [  3.70938277]
 [  8.40529728]
 [  6.84210491]
 [  3.79035783]
 [  3.99211502]
 [  4.64429903]
 [ 14.87205315]
 [  2.55082369]
 [ 20.97557831]
 [ 13.98524475]
 [  7.16864777]
 [ 14.19861221]
 [  3.76692557]
 [  4.28077793]
 [  4.28077793]]
DEBUG:root:training time = %d0.221257
INFO:root:frame =2145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =2146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000270843505859
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.983121666667
DEBUG:root: dqn, choose action rondomly, need time 0.000204
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016713142395
INFO:root:frame =2149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =2150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000519037246704
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.98309
DEBUG:root: dqn, choose action rondomly, need time 0.000243000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.54574394]
 [ 15.27891254]
 [  4.80348206]
 [  8.70432758]
 [  6.7722168 ]
 [  8.70432758]
 [  3.50243378]
 [  4.93714905]
 [  3.97787499]
 [ 15.27891254]
 [  4.79270267]
 [ 15.11987019]
 [  7.3339467 ]
 [  1.27179515]
 [  4.93714905]
 [ 15.56305313]]
DEBUG:root:training time = %d0.189535
INFO:root:frame =2153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =2154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000289916992188
DEBUG:root: save sample needs time = 0.000131845474243
INFO:root:random_action_porb = 0.983058333333
DEBUG:root: dqn, choose action rondomly, need time 0.000233000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:frame =2157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =2158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.983026666667
DEBUG:root: dqn, choose action rondomly, need time 0.000226999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174045562744
INFO:root:training error  = [[  7.09495258]
 [ 11.2570715 ]
 [  4.24088717]
 [ 19.26780701]
 [ 13.06895447]
 [ 11.37723923]
 [  6.45683813]
 [  3.96044064]
 [  4.42254734]
 [ 18.11860657]
 [  6.92465305]
 [  8.00344849]
 [  4.60805035]
 [  4.65984964]
 [  5.33453798]
 [  5.12652493]]
DEBUG:root:training time = %d0.188528
INFO:root:frame =2161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =2162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000130891799927
INFO:root:random_action_porb = 0.982995
INFO:root:dqn select action Tensor("ArgMax_5:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012479
INFO:root:action choosen by dqn [3]
INFO:root:frame =2164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root:frame =2165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =2166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235080718994
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.982963333333
DEBUG:root: dqn, choose action rondomly, need time 0.000398000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 19.77328682]
 [ 12.48039722]
 [ 20.06219292]
 [ 13.67586708]
 [ 26.11265182]
 [  3.93509507]
 [ 14.0973978 ]
 [ 17.17631721]
 [ 26.32113838]
 [ 12.74762154]
 [ 14.0973978 ]
 [  3.64693379]
 [  9.05242157]
 [  8.22457123]
 [  3.93202353]
 [  8.84521484]]
DEBUG:root:training time = %d0.18102
INFO:root:frame =2169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000386953353882
INFO:root:frame =2170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000637054443359
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.982931666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root:frame =2173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280857086182
INFO:root:frame =2174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028920173645
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.9829
DEBUG:root: dqn, choose action rondomly, need time 0.000189000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 27.94074059]
 [  8.59668636]
 [ 14.92553139]
 [  3.91885757]
 [ 14.97901726]
 [ 16.4972744 ]
 [  3.71605682]
 [  3.91885757]
 [  8.5428381 ]
 [  4.66139793]
 [ 15.0103035 ]
 [ 25.41856956]
 [  4.38129759]
 [ 12.31816006]
 [ 14.88061619]
 [ 14.87676048]]
DEBUG:root:training time = %d0.181158
INFO:root:frame =2177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:frame =2178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233173370361
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.982868333333
DEBUG:root: dqn, choose action rondomly, need time 0.000216999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =2181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =2182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000223875045776
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.982836666667
DEBUG:root: dqn, choose action rondomly, need time 0.000163999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000147104263306
INFO:root:training error  = [[  4.10288715]
 [  4.10288715]
 [  4.39828968]
 [ 22.71881676]
 [ 11.85065556]
 [  4.19194651]
 [ 26.46965599]
 [  4.28292465]
 [ 11.73182201]
 [  3.62142301]
 [ 12.70494556]
 [ 26.46965599]
 [  4.10288715]
 [ 24.17414856]
 [ 22.71881676]
 [  4.26259661]]
DEBUG:root:training time = %d0.207044
INFO:root:frame =2185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375032424927
INFO:root:frame =2186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000334978103638
DEBUG:root: save sample needs time = 0.000109910964966
INFO:root:random_action_porb = 0.982805
DEBUG:root: dqn, choose action rondomly, need time 0.000308
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:frame =2189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =2190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:random_action_porb = 0.982773333333
DEBUG:root: dqn, choose action rondomly, need time 0.000523999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.83897686]
 [ 16.98332024]
 [ 20.75803757]
 [ 17.45560074]
 [ 18.2444706 ]
 [  4.22105122]
 [  9.33141899]
 [ 17.16414642]
 [  4.43707991]
 [  4.63810253]
 [ 13.99477577]
 [ 18.89786911]
 [  6.02141619]
 [ 17.16414642]
 [ 16.62712097]
 [  5.47190571]]
DEBUG:root:training time = %d0.238728
INFO:root:frame =2193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:frame =2194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047779083252
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.982741666667
DEBUG:root: dqn, choose action rondomly, need time 0.000419999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =2197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =2198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:random_action_porb = 0.98271
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 21.05252075]
 [  4.43060541]
 [ 13.64794922]
 [ 16.22432137]
 [ 28.09088135]
 [ 15.30474854]
 [  4.57767105]
 [ 29.62364197]
 [ 12.79899311]
 [ 14.46754932]
 [ 15.19040966]
 [ 15.44445229]
 [  4.43060541]
 [ 29.80026054]
 [ 16.5324955 ]
 [ 17.05331612]]
DEBUG:root:training time = %d0.240627
INFO:root:frame =2201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =2202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488996505737
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.982678333333
DEBUG:root: dqn, choose action rondomly, need time 0.000313999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =2205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =2206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.982646666667
DEBUG:root: dqn, choose action rondomly, need time 0.000336999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  5.14018059]
 [  6.73929882]
 [  6.55347013]
 [  4.62660837]
 [  1.58954787]
 [  4.75913954]
 [  7.45123148]
 [ 20.85530663]
 [  6.00074673]
 [ 21.07521057]
 [  5.98548746]
 [ 13.31825066]
 [  5.99970007]
 [  5.50026512]
 [ 32.78338242]
 [ 16.29745102]]
DEBUG:root:training time = %d0.216427
INFO:root:frame =2209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =2210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000296831130981
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:random_action_porb = 0.982615
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =2213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000370025634766
INFO:root:frame =2214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.982583333333
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 24.3596611 ]
 [  5.32742119]
 [  5.38583279]
 [ 25.03999329]
 [ 12.08465672]
 [ 15.36450195]
 [ 13.2873354 ]
 [ 24.3596611 ]
 [ 14.48551846]
 [  5.76678419]
 [ 14.19550705]
 [  5.12063599]
 [ 15.4520092 ]
 [ 24.25231171]
 [ 12.08465672]
 [ 26.63004684]]
DEBUG:root:training time = %d0.21376
INFO:root:frame =2217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =2218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424146652222
DEBUG:root: save sample needs time = 0.000274181365967
INFO:root:random_action_porb = 0.982551666667
DEBUG:root: dqn, choose action rondomly, need time 0.000204
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:frame =2221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root:frame =2222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:random_action_porb = 0.98252
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8.41045094]
 [ 14.48560524]
 [ 29.2360363 ]
 [ 27.08779526]
 [ 31.13722992]
 [ 14.39940548]
 [  8.41045094]
 [ 14.89415741]
 [ 27.37903786]
 [  5.1275959 ]
 [  5.76255274]
 [ 27.37903786]
 [ 15.14396858]
 [ 14.74170494]
 [ 39.57342148]
 [ 14.38157749]]
DEBUG:root:training time = %d0.216876
INFO:root:frame =2225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =2226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000571012496948
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.982488333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =2229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =2230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000671863555908
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:random_action_porb = 0.982456666667
DEBUG:root: dqn, choose action rondomly, need time 0.000397
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000363111495972
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 19.03855705]
 [ 19.10706139]
 [ 13.8900547 ]
 [ 23.85556984]
 [ 23.31126976]
 [ 22.48023796]
 [  5.39321899]
 [  6.98348141]
 [ 35.38108444]
 [ 11.35822964]
 [ 13.77626705]
 [ 23.79367638]
 [ 15.14601803]
 [ 13.8900547 ]
 [ 19.72043037]
 [ 23.79367638]]
DEBUG:root:training time = %d0.204883
INFO:root:frame =2233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375032424927
INFO:root:frame =2234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame = 2235 State into memory, numbers recorded 56 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000378131866455
INFO:root:random_action_porb = 0.982425
DEBUG:root: dqn, choose action rondomly, need time 0.000341999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2236current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame =2237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046706199646
INFO:root:frame =2238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000571966171265
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.982393333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:training error  = [[ 31.78464127]
 [ 19.18213654]
 [ 21.68361282]
 [  5.21867943]
 [ 19.50978661]
 [ 14.92791939]
 [ 19.18213654]
 [ 19.50978661]
 [ 19.50978661]
 [ 19.18213654]
 [ 18.16439247]
 [ 17.33112526]
 [  5.425354  ]
 [ 32.47209549]
 [  5.49391508]
 [ 18.27482224]]
DEBUG:root:training time = %d0.236124
INFO:root:frame =2241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =2242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00036096572876
INFO:root:frame = 2243 State into memory, numbers recorded 57 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000648021697998
INFO:root:random_action_porb = 0.982361666667
DEBUG:root: dqn, choose action rondomly, need time 0.000418999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2244current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =2245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =2246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.98233
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 22.68028641]
 [  6.64930534]
 [ 10.17263603]
 [ 18.22156906]
 [ 24.01782799]
 [  6.55892038]
 [  6.13527012]
 [ 23.45504189]
 [  5.72202063]
 [ 11.01115417]
 [ 24.19035721]
 [  6.20761442]
 [  7.39382124]
 [ 23.45504189]
 [  9.99744034]
 [ 21.0223217 ]]
DEBUG:root:training time = %d0.211515
INFO:root:frame =2249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =2250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000242948532104
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:random_action_porb = 0.982298333333
DEBUG:root: dqn, choose action rondomly, need time 0.000206999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =2253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00055193901062
INFO:root:frame =2254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.982266666667
DEBUG:root: dqn, choose action rondomly, need time 0.000349
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:training error  = [[  6.0010457 ]
 [  6.77185965]
 [ 20.25360489]
 [ 21.67728996]
 [  6.9650054 ]
 [ 32.61698532]
 [ 31.2823143 ]
 [ 19.81941795]
 [  6.9650054 ]
 [  5.97401381]
 [ 31.2823143 ]
 [ 21.80874062]
 [  7.2589736 ]
 [ 30.56877899]
 [  6.77775717]
 [ 31.2823143 ]]
DEBUG:root:training time = %d0.198547
INFO:root:frame =2257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000418901443481
INFO:root:frame =2258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000419855117798
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.982235
DEBUG:root: dqn, choose action rondomly, need time 0.000442
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000366926193237
INFO:root:frame =2261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =2262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000537872314453
DEBUG:root: save sample needs time = 0.000141859054565
INFO:root:random_action_porb = 0.982203333333
DEBUG:root: dqn, choose action rondomly, need time 0.000422999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000361919403076
INFO:root:training error  = [[ 17.01861572]
 [ 14.47114849]
 [ 30.71376228]
 [ 15.58482075]
 [ 30.71376228]
 [ 21.76493835]
 [ 15.77930069]
 [ 17.23834801]
 [ 15.77930069]
 [ 21.333395  ]
 [  6.76586485]
 [ 29.8391304 ]
 [ 14.71274853]
 [ 30.50393677]
 [ 14.71274853]
 [  6.35821056]]
DEBUG:root:training time = %d0.228575
INFO:root:frame =2265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =2266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.982171666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =2269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =2270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.98214
DEBUG:root: dqn, choose action rondomly, need time 0.000346
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 28.06545258]
 [ 13.30516815]
 [ 28.49637604]
 [  6.37378359]
 [ 12.86223125]
 [ 21.91386604]
 [  6.07378101]
 [ 30.48615837]
 [  6.35540199]
 [ 28.34373093]
 [ 29.61633301]
 [ 28.07681084]
 [ 24.85323524]
 [ 21.33892632]
 [  6.45887375]
 [  6.76695633]]
DEBUG:root:training time = %d0.21606
INFO:root:frame =2273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =2274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame = 2275 State into memory, numbers recorded 58 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000559091567993
INFO:root:random_action_porb = 0.982108333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2276current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =2277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000581979751587
INFO:root:frame =2278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000425100326538
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.982076666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 33.46313477]
 [ 33.46313477]
 [ 18.42303085]
 [ 22.74045944]
 [ 22.96717453]
 [  6.49203348]
 [  6.49203348]
 [ 19.73249435]
 [ 31.13863373]
 [  6.14385271]
 [ 23.54906082]
 [ 32.81916809]
 [ 34.18116379]
 [ 12.85134315]
 [ 46.7297821 ]
 [ 22.24601364]]
DEBUG:root:training time = %d0.237168
INFO:root:frame =2281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =2282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000296115875244
DEBUG:root: save sample needs time = 0.000209808349609
INFO:root:random_action_porb = 0.982045
DEBUG:root: dqn, choose action rondomly, need time 0.000328000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =2285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =2286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288009643555
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:random_action_porb = 0.982013333333
DEBUG:root: dqn, choose action rondomly, need time 0.000335
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 18.31150055]
 [ 12.4231348 ]
 [ 13.8278532 ]
 [  9.95059967]
 [ 23.06402206]
 [  9.40268326]
 [  7.72754478]
 [ 27.39552689]
 [ 23.52807236]
 [ 27.8569603 ]
 [ 33.44429016]
 [ 28.01547813]
 [ 10.80338287]
 [ 27.349823  ]
 [ 23.52807236]
 [ 22.58247185]]
DEBUG:root:training time = %d0.242695
INFO:root:frame =2289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00104117393494
INFO:root:frame =2290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.981981666667
DEBUG:root: dqn, choose action rondomly, need time 0.000444000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =2293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =2294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.98195
DEBUG:root: dqn, choose action rondomly, need time 0.000273
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6.8743124 ]
 [ 17.70424843]
 [ 31.74353409]
 [ 24.09573746]
 [  6.8743124 ]
 [ 24.90221024]
 [ 41.43732834]
 [ 31.74353409]
 [ 30.3710537 ]
 [ 16.90725327]
 [ 24.09573746]
 [ 42.33151627]
 [ 16.90725327]
 [ 36.35586929]
 [ 23.67674255]
 [  7.11482096]]
DEBUG:root:training time = %d0.221993
INFO:root:frame =2297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000377178192139
INFO:root:frame =2298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:random_action_porb = 0.981918333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:frame =2301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000476121902466
INFO:root:frame =2302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.981886666667
DEBUG:root: dqn, choose action rondomly, need time 0.000278000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000209808349609
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16.31951141]
 [  8.88358021]
 [  7.78116798]
 [  9.04035091]
 [  7.07521343]
 [ 16.4815979 ]
 [ 18.05076408]
 [ 12.79440784]
 [  7.33340979]
 [  8.28695869]
 [ 21.43556786]
 [  7.58641624]
 [ 12.71530819]
 [ 21.83382988]
 [ 30.75487328]
 [ 19.57406998]]
DEBUG:root:training time = %d0.224638
INFO:root:frame =2305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =2306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.981855
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =2309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =2310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000515937805176
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:random_action_porb = 0.981823333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:training error  = [[ 38.27241135]
 [  7.88453531]
 [ 24.82734108]
 [ 21.00759697]
 [  7.87016678]
 [ 39.79715347]
 [ 25.37615967]
 [ 14.32833195]
 [  7.39685011]
 [ 28.5984478 ]
 [ 37.11988831]
 [  7.54750633]
 [ 13.3130722 ]
 [ 25.56861115]
 [ 26.76182747]
 [ 19.48185921]]
DEBUG:root:training time = %d0.225446
INFO:root:frame =2313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:frame =2314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298976898193
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:random_action_porb = 0.981791666667
DEBUG:root: dqn, choose action rondomly, need time 0.000364000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =2317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =2318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000566005706787
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.98176
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 24.08319473]
 [ 31.15741158]
 [  7.65731382]
 [ 13.73809338]
 [ 32.77971268]
 [ 20.74403191]
 [ 13.44529343]
 [  7.7684679 ]
 [ 29.42043495]
 [  7.96552801]
 [ 24.04576683]
 [ 15.6786623 ]
 [ 31.15741158]
 [ 14.99304676]
 [ 13.73809338]
 [ 29.42043495]]
DEBUG:root:training time = %d0.219159
INFO:root:frame =2321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =2322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000405073165894
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.981728333333
DEBUG:root: dqn, choose action rondomly, need time 0.000568999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =2325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =2326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00048303604126
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.981696666667
DEBUG:root: dqn, choose action rondomly, need time 0.000175999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14.24646091]
 [ 10.17373085]
 [  8.82466888]
 [  8.82466888]
 [ 16.11452293]
 [  8.89374828]
 [ 20.90899658]
 [ 20.99347305]
 [  8.82466888]
 [  8.31925392]
 [  8.37619114]
 [ 28.66262054]
 [ 16.07023621]
 [ 17.18896675]
 [  8.15716648]
 [ 16.11452293]]
DEBUG:root:training time = %d0.218268
INFO:root:frame =2329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =2330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:random_action_porb = 0.981665
DEBUG:root: dqn, choose action rondomly, need time 0.000536000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =2333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =2334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.981633333333
DEBUG:root: dqn, choose action rondomly, need time 0.000572000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 31.66801071]
 [ 23.01158333]
 [ 48.19223022]
 [  8.32158661]
 [  8.17292786]
 [  8.4220047 ]
 [ 36.15658951]
 [ 23.45393181]
 [ 14.77508831]
 [  8.87246418]
 [  8.11786079]
 [ 48.19223022]
 [ 29.66692543]
 [ 21.92761803]
 [ 20.78505516]
 [ 37.36959457]]
DEBUG:root:training time = %d0.221802
INFO:root:frame =2337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =2338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000598907470703
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:random_action_porb = 0.981601666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root: ememy has been killed for 4 times 
INFO:root:enemies_left [0]
INFO:root:frame =2340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000492095947266
INFO:root:frame =2341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491857528687
INFO:root:frame =2342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000492095947266
INFO:root:frame = 2343 State into memory, numbers recorded 59 action = 4, reward = 1
DEBUG:root: save sample needs time = 0.000411033630371
INFO:root:random_action_porb = 0.98157
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2344current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.87814331]
 [ 26.71062088]
 [ 25.02201653]
 [ 24.1192627 ]
 [  9.12425137]
 [  9.17252636]
 [ 23.13996696]
 [  9.13331032]
 [ 10.19786072]
 [ 23.47976685]
 [ 15.29579639]
 [ 17.43396378]
 [ 24.1192627 ]
 [ 16.06057358]
 [ 23.83086967]
 [  4.33995438]]
DEBUG:root:training time = %d0.229915
INFO:root:frame =2345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:frame =2346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000357151031494
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:random_action_porb = 0.981538333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =2349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =2350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000499963760376
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root:random_action_porb = 0.981506666667
INFO:root:dqn select action Tensor("ArgMax_6:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014032
INFO:root:action choosen by dqn [2]
INFO:root:frame =2352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17.77484512]
 [  8.68340683]
 [ 42.93532944]
 [ 17.29290581]
 [ 17.77484512]
 [ 17.19440842]
 [ 60.43890381]
 [ 23.75569534]
 [ 17.78436852]
 [ 15.84844398]
 [ 43.02616119]
 [ 17.54790497]
 [ 17.19440842]
 [  8.68340683]
 [  8.82374001]
 [ 19.03379631]]
DEBUG:root:training time = %d0.233668
INFO:root:frame =2353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000393867492676
INFO:root:frame =2354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324964523315
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.981475
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =2357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame =2358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000581979751587
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.981443333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000341892242432
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 34.68593597]
 [ 19.19670868]
 [ 11.18045998]
 [ 18.59413528]
 [ 35.36393356]
 [ 26.55674934]
 [ 26.72043991]
 [ 19.32890701]
 [ 33.59571075]
 [  9.23870659]
 [  9.23870659]
 [ 35.94755936]
 [ 25.3539505 ]
 [ 17.50124359]
 [ 11.13891602]
 [ 17.50124359]]
DEBUG:root:training time = %d0.204498
INFO:root:frame =2361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =2362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000822067260742
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.981411666667
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =2365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =2366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000492095947266
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:random_action_porb = 0.98138
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:training error  = [[ 22.66172409]
 [  8.83391857]
 [ 41.11196518]
 [ 33.78959274]
 [ 31.24899673]
 [ 15.20331764]
 [ 38.60242844]
 [ 23.63744354]
 [ 14.16126347]
 [ 14.99162865]
 [ 22.66172409]
 [ 31.3209877 ]
 [  9.5944109 ]
 [ 22.51494217]
 [  9.71402836]
 [ 30.46737289]]
DEBUG:root:training time = %d0.206422
INFO:root:frame =2369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =2370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame = 2371 State into memory, numbers recorded 60 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000576972961426
INFO:root:random_action_porb = 0.981348333333
DEBUG:root: dqn, choose action rondomly, need time 0.000444000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2372current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =2373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049614906311
INFO:root:frame =2374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.981316666667
DEBUG:root: dqn, choose action rondomly, need time 0.000318999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 32.49827194]
 [  9.52764893]
 [  9.87944221]
 [ 20.80770493]
 [ 31.49432373]
 [  9.60942268]
 [ 44.73086929]
 [ 40.82838821]
 [ 19.98674393]
 [ 31.86564255]
 [ 46.40516663]
 [ 32.59746933]
 [ 32.3014183 ]
 [ 13.26323509]
 [ 61.12811661]
 [ 33.13689804]]
DEBUG:root:training time = %d0.216166
INFO:root:frame =2377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =2378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:random_action_porb = 0.981285
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =2381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000494956970215
INFO:root:frame =2382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 9.29832458496e-05
INFO:root:random_action_porb = 0.981253333333
DEBUG:root: dqn, choose action rondomly, need time 0.000537000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:training error  = [[ 25.85034943]
 [ 25.4951725 ]
 [ 26.0633564 ]
 [ 10.03402042]
 [  9.94763947]
 [ 22.11798477]
 [ 23.83574867]
 [ 24.16548347]
 [ 23.6632309 ]
 [ 25.38442421]
 [ 10.22589874]
 [ 25.44330788]
 [  9.64578438]
 [ 25.44330788]
 [ 26.0633564 ]
 [ 22.81233597]]
DEBUG:root:training time = %d0.217349
INFO:root:frame =2385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =2386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.981221666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame =2389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =2390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00066089630127
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.98119
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 29.64129257]
 [ 19.02550888]
 [  5.51209879]
 [ 19.62594986]
 [ 19.99738693]
 [ 28.00445366]
 [ 19.02550888]
 [ 10.07800388]
 [ 11.04310226]
 [ 14.83230019]
 [ 10.57457924]
 [ 41.55130005]
 [ 15.33825588]
 [ 10.73870659]
 [ 10.66764545]
 [ 19.48930359]]
DEBUG:root:training time = %d0.237797
INFO:root:frame =2393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =2394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 9.91821289062e-05
INFO:root:random_action_porb = 0.981158333333
DEBUG:root: dqn, choose action rondomly, need time 0.000160999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:frame =2397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =2398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.981126666667
DEBUG:root: dqn, choose action rondomly, need time 0.000162000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 22.77114105]
 [ 43.45133209]
 [ 20.51466751]
 [ 22.88191605]
 [ 40.58276749]
 [ 21.99211502]
 [ 22.77114105]
 [ 22.05574036]
 [ 14.07592106]
 [ 11.07009411]
 [ 10.31560802]
 [ 13.68080425]
 [ 13.73263645]
 [ 10.94861031]
 [ 21.99211502]
 [ 13.68080425]]
DEBUG:root:training time = %d0.2312
INFO:root:frame =2401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280857086182
INFO:root:frame =2402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000355005264282
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:random_action_porb = 0.981095
INFO:root:dqn select action Tensor("ArgMax_7:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013401
INFO:root:action choosen by dqn [0]
INFO:root:frame =2404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root:frame =2405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root:frame =2406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000367164611816
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.981063333333
DEBUG:root: dqn, choose action rondomly, need time 0.000171999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00013279914856
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 35.45250702]
 [ 24.10813522]
 [ 36.56409836]
 [ 14.06521797]
 [ 35.45250702]
 [ 26.40398788]
 [ 19.34309769]
 [ 11.77278042]
 [ 19.34309769]
 [ 11.41540909]
 [ 11.27118015]
 [ 14.6015501 ]
 [ 15.74401283]
 [ 24.10813522]
 [ 10.72531033]
 [ 14.6015501 ]]
DEBUG:root:training time = %d0.226273
INFO:root:frame =2409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =2410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000311136245728
DEBUG:root: save sample needs time = 0.000121831893921
INFO:root:random_action_porb = 0.981031666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root:frame =2413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame =2414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264883041382
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:player has been killed for 4 times 
INFO:root:frame =2416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000401973724365
INFO:root:training error  = [[ 51.46047211]
 [ 47.19190598]
 [ 11.61634254]
 [ 10.73913193]
 [ 47.19190598]
 [ 19.1303463 ]
 [ 44.10448837]
 [ 12.485816  ]
 [ 12.18575764]
 [ 43.50274658]
 [ 47.19190598]
 [ 20.87712288]
 [ 10.73913193]
 [ 11.09373951]
 [ 11.22990322]
 [ 40.71619415]]
DEBUG:root:training time = %d0.216228
INFO:root:frame =2417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000368118286133
INFO:root:frame =2418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame = 2419 State into memory, numbers recorded 61 action = 0, reward = -1
DEBUG:root: save sample needs time = 0.000558137893677
INFO:root:random_action_porb = 0.981
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2420current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =2421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =2422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000561952590942
DEBUG:root: save sample needs time = 9.51290130615e-05
INFO:root:random_action_porb = 0.980968333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 31.84531784]
 [ 38.36545181]
 [ 11.43454361]
 [ 38.37414551]
 [ 11.52859211]
 [ 44.00695419]
 [ 28.23976326]
 [ 30.46960449]
 [ 29.77644157]
 [ 36.8468399 ]
 [ 32.29075241]
 [ 43.95129776]
 [ 30.46960449]
 [ 11.56820869]
 [ 31.56376648]
 [ 33.52640915]]
DEBUG:root:training time = %d0.219554
INFO:root:frame =2425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:frame =2426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000246047973633
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.980936666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =2429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame =2430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480175018311
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.980905
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13.71533871]
 [ 11.88169384]
 [ 15.80959129]
 [ 16.19369888]
 [ 12.84138966]
 [ 33.48780823]
 [ 10.71679211]
 [ 32.89005661]
 [ 17.49084091]
 [ 14.37093163]
 [ 17.02513123]
 [ 15.7150259 ]
 [ 13.04229736]
 [ 12.46913433]
 [ 16.07222557]
 [ 23.5800972 ]]
DEBUG:root:training time = %d0.227666
INFO:root:frame =2433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =2434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.980873333333
DEBUG:root: dqn, choose action rondomly, need time 0.000599000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000420808792114
INFO:root:frame =2437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000484943389893
INFO:root:frame =2438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.980841666667
DEBUG:root: dqn, choose action rondomly, need time 0.000609000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 32.91859055]
 [ 15.26528645]
 [ 26.01216316]
 [ 12.65034389]
 [ 17.36102676]
 [ 33.14792252]
 [ 39.34108734]
 [ 13.75984764]
 [ 16.69625664]
 [ 16.51835251]
 [ 26.74174118]
 [ 33.14792252]
 [ 13.05635262]
 [ 12.93879414]
 [ 13.75984764]
 [ 20.17625237]]
DEBUG:root:training time = %d0.212451
INFO:root:frame =2441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root:frame =2442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:random_action_porb = 0.98081
DEBUG:root: dqn, choose action rondomly, need time 0.000205000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000189065933228
INFO:root:frame =2445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000503778457642
INFO:root:frame =2446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.980778333333
DEBUG:root: dqn, choose action rondomly, need time 0.000374000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 18.90735626]
 [ 18.63933372]
 [ 12.54214191]
 [ 24.45211601]
 [ 13.71839046]
 [ 29.18696594]
 [ 17.79688644]
 [ 23.82398033]
 [ 23.82398033]
 [ 29.18696594]
 [ 18.71160507]
 [ 13.71839046]
 [ 21.55501938]
 [ 18.90735626]
 [ 21.08172607]
 [ 18.19698906]]
DEBUG:root:training time = %d0.215585
INFO:root:frame =2449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:frame =2450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000121831893921
INFO:root:random_action_porb = 0.980746666667
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =2453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000332832336426
INFO:root:frame =2454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.980715
DEBUG:root: dqn, choose action rondomly, need time 0.000326999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 35.67581177]
 [ 35.67581177]
 [ 54.74557114]
 [ 52.49736023]
 [ 16.69207954]
 [ 52.55165863]
 [ 52.49736023]
 [ 20.18036461]
 [ 16.87185478]
 [ 12.87651825]
 [ 23.96577263]
 [ 52.55165863]
 [ 17.25431633]
 [ 13.97942448]
 [ 24.38146782]
 [ 13.32824802]]
DEBUG:root:training time = %d0.223709
INFO:root:frame =2457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =2458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.980683333333
DEBUG:root: dqn, choose action rondomly, need time 0.000251000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000185012817383
INFO:root:frame =2461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =2462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.980651666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309228897095
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 53.60618973]
 [ 17.24677467]
 [ 40.90544891]
 [ 38.83937454]
 [ 18.74158287]
 [ 53.66228485]
 [ 13.42669582]
 [ 15.06805801]
 [ 12.97927761]
 [ 15.25396156]
 [ 16.55365944]
 [ 40.15067673]
 [ 41.61407471]
 [ 21.28672791]
 [ 13.79808044]
 [ 52.91565704]]
DEBUG:root:training time = %d0.214638
INFO:root:frame =2465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =2466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.98062
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =2469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame =2470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000591993331909
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.980588333333
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 42.89584351]
 [ 20.24306488]
 [ 13.84573269]
 [ 56.79847336]
 [ 68.47918701]
 [ 63.61459732]
 [ 18.77812958]
 [ 45.05634689]
 [ 63.61459732]
 [ 66.39168549]
 [ 18.52002335]
 [ 21.29869843]
 [ 44.79013062]
 [ 67.53318024]
 [ 14.13394451]
 [ 45.28339386]]
DEBUG:root:training time = %d0.212555
INFO:root:frame =2473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =2474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.980556666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =2477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:frame =2478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.980525
DEBUG:root: dqn, choose action rondomly, need time 0.000420999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:training error  = [[ 49.67855835]
 [ 50.91184998]
 [ 50.09196854]
 [ 48.77169037]
 [ 48.77169037]
 [ 52.19718552]
 [ 51.34347153]
 [ 13.82456207]
 [ 50.27908325]
 [ 52.39448166]
 [ 48.07821274]
 [ 52.22144318]
 [ 49.63619232]
 [ 50.27908325]
 [ 52.19718552]
 [ 62.21826553]]
DEBUG:root:training time = %d0.223887
INFO:root:frame =2481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =2482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.980493333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000275850296021
INFO:root:frame =2485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =2486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509023666382
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:random_action_porb = 0.980461666667
DEBUG:root: dqn, choose action rondomly, need time 0.000321
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000270128250122
INFO:root:training error  = [[ 15.76745319]
 [ 15.63853931]
 [ 17.93167686]
 [ 20.61611176]
 [ 17.72691917]
 [ 32.53477097]
 [ 31.51740646]
 [ 20.80304146]
 [ 19.3162632 ]
 [ 17.59891891]
 [ 31.51740646]
 [ 18.40384674]
 [ 18.59969711]
 [ 25.51509285]
 [ 18.19484138]
 [ 17.93167686]]
DEBUG:root:training time = %d0.225598
INFO:root:frame =2489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =2490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308990478516
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:random_action_porb = 0.98043
DEBUG:root: dqn, choose action rondomly, need time 0.000332
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000348806381226
INFO:root:frame =2493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame =2494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame = 2495 State into memory, numbers recorded 62 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:random_action_porb = 0.980398333333
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2496current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 20.91949844]
 [ 33.4355545 ]
 [ 31.28005409]
 [ 31.28005409]
 [ 57.11181259]
 [ 33.62056732]
 [ 15.04348755]
 [ 57.1524086 ]
 [ 21.5812397 ]
 [ 33.4355545 ]
 [ 34.38701248]
 [ 25.45955086]
 [ 23.84297562]
 [ 73.25370789]
 [ 19.4920311 ]
 [ 33.18245697]]
DEBUG:root:training time = %d0.222003
INFO:root:frame =2497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029182434082
INFO:root:frame =2498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000365972518921
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:random_action_porb = 0.980366666667
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000341176986694
INFO:root:frame =2501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =2502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.980335
DEBUG:root: dqn, choose action rondomly, need time 0.000464999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000386953353882
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 39.60568237]
 [ 54.30895615]
 [ 60.4394989 ]
 [ 25.58064842]
 [ 26.00609398]
 [ 25.33236504]
 [ 16.53274345]
 [ 19.76019287]
 [ 40.83258057]
 [ 26.00609398]
 [ 17.56942177]
 [ 17.56942177]
 [ 19.57923317]
 [ 26.5595417 ]
 [ 16.34676933]
 [ 20.32979774]]
DEBUG:root:training time = %d0.220711
INFO:root:frame =2505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =2506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:random_action_porb = 0.980303333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =2509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000580072402954
INFO:root:frame =2510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.980271666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 45.18928528]
 [ 70.49671936]
 [ 65.41410065]
 [ 26.62555885]
 [ 17.12911034]
 [ 44.81903839]
 [ 70.49671936]
 [ 85.4376297 ]
 [ 16.25977325]
 [ 24.35435104]
 [ 85.4376297 ]
 [ 85.4376297 ]
 [ 85.4376297 ]
 [ 65.62468719]
 [ 16.72994232]
 [ 31.16290665]]
DEBUG:root:training time = %d0.215159
INFO:root:frame =2513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028395652771
INFO:root:frame =2514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.98024
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =2517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =2518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000289916992188
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.980208333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 44.48022461]
 [ 58.27834702]
 [ 59.26281357]
 [ 45.04774094]
 [ 33.15143967]
 [ 59.3537674 ]
 [ 33.20355606]
 [ 45.29017258]
 [ 61.82975388]
 [ 61.82975388]
 [ 60.74118423]
 [ 60.4157753 ]
 [ 60.74118423]
 [ 33.22862244]
 [ 45.5527153 ]
 [ 59.87792587]]
DEBUG:root:training time = %d0.212743
INFO:root:frame =2521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:frame =2522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.000121831893921
INFO:root:random_action_porb = 0.980176666667
DEBUG:root: dqn, choose action rondomly, need time 0.000437999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:frame =2525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000804901123047
INFO:root:frame =2526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000495910644531
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.980145
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 53.89794922]
 [ 18.76345444]
 [ 35.58609772]
 [ 25.37731361]
 [ 28.8555336 ]
 [ 41.0256691 ]
 [ 41.49033737]
 [ 36.93868637]
 [ 36.93868637]
 [ 42.95752716]
 [ 38.2592926 ]
 [ 29.70238304]
 [ 35.88500977]
 [ 41.95554733]
 [ 58.56642151]
 [ 54.17443848]]
DEBUG:root:training time = %d0.228336
INFO:root:frame =2529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =2530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000285863876343
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:random_action_porb = 0.980113333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =2533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462770462036
INFO:root:frame =2534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.980081666667
DEBUG:root: dqn, choose action rondomly, need time 0.000411
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 18.83702469]
 [ 13.11928272]
 [ 21.3991642 ]
 [ 49.43482971]
 [ 21.32095718]
 [ 36.78665924]
 [ 37.96632767]
 [ 21.38497925]
 [ 21.32095718]
 [ 51.69372177]
 [ 19.94068909]
 [ 50.01866913]
 [ 21.27405739]
 [ 20.6627655 ]
 [ 23.1625061 ]
 [ 18.83702469]]
DEBUG:root:training time = %d0.230922
INFO:root:frame =2537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =2538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000496864318848
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.98005
DEBUG:root: dqn, choose action rondomly, need time 0.000341999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =2541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =2542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423192977905
INFO:root:frame = 2543 State into memory, numbers recorded 63 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000525951385498
INFO:root:random_action_porb = 0.980018333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2544current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 18.59949875]
 [ 10.67158318]
 [ 20.5313282 ]
 [ 56.4394455 ]
 [ 28.36737633]
 [ 73.22772217]
 [ 18.72474098]
 [ 26.8884716 ]
 [ 20.01953506]
 [ 27.4826088 ]
 [ 56.00878906]
 [ 57.10304642]
 [ 42.18773651]
 [ 25.75009537]
 [ 26.23857498]
 [ 18.4297123 ]]
DEBUG:root:training time = %d0.213742
INFO:root:frame =2545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:frame =2546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame = 2547 State into memory, numbers recorded 64 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000417947769165
INFO:root:random_action_porb = 0.979986666667
DEBUG:root: dqn, choose action rondomly, need time 0.000364999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2548current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =2549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =2550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239849090576
DEBUG:root: save sample needs time = 0.000103950500488
INFO:root:random_action_porb = 0.979955
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 59.13191223]
 [ 37.7491684 ]
 [ 44.45488739]
 [ 58.70815277]
 [ 45.75912476]
 [ 19.42472267]
 [ 25.25823212]
 [ 59.25976181]
 [ 46.98563385]
 [ 20.42774963]
 [ 51.97528458]
 [ 45.97914505]
 [ 44.45488739]
 [ 20.42774963]
 [ 49.02318192]
 [ 59.13191223]]
DEBUG:root:training time = %d0.233459
INFO:root:frame =2553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:frame =2554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000278949737549
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:random_action_porb = 0.979923333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =2557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =2558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.979891666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 20.87527466]
 [ 41.31782913]
 [ 78.35866547]
 [ 25.8713398 ]
 [ 45.6413269 ]
 [ 45.6413269 ]
 [ 27.07012749]
 [ 41.06917572]
 [ 44.69827271]
 [ 46.31851578]
 [ 35.17015076]
 [ 46.31851578]
 [ 25.8713398 ]
 [ 46.8429718 ]
 [ 40.17804718]
 [ 73.21061707]]
DEBUG:root:training time = %d0.223864
INFO:root:frame =2561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271797180176
INFO:root:frame =2562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274896621704
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:random_action_porb = 0.97986
DEBUG:root: dqn, choose action rondomly, need time 0.000216000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000258207321167
INFO:root:frame =2565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =2566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:random_action_porb = 0.979828333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 24.7879734 ]
 [ 36.18416595]
 [ 21.52145386]
 [ 71.24897003]
 [ 64.02319336]
 [ 35.42262268]
 [ 35.19341278]
 [ 36.83897018]
 [ 20.3895607 ]
 [ 66.44776917]
 [ 54.42540359]
 [ 35.0794487 ]
 [ 36.83897018]
 [ 37.17741013]
 [ 35.05839539]
 [ 37.52301025]]
DEBUG:root:training time = %d0.244528
INFO:root:frame =2569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:frame =2570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:random_action_porb = 0.979796666667
DEBUG:root: dqn, choose action rondomly, need time 0.000317000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000395059585571
INFO:root:frame =2573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =2574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.979765
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 45.32858658]
 [ 56.1310463 ]
 [ 21.0452404 ]
 [ 21.322155  ]
 [ 26.02928734]
 [ 33.61013031]
 [ 58.14190674]
 [ 45.06228638]
 [ 21.9921875 ]
 [ 22.9993248 ]
 [ 56.23615265]
 [ 58.22663879]
 [ 22.1391964 ]
 [ 42.57803345]
 [ 58.12340546]
 [ 21.322155  ]]
DEBUG:root:training time = %d0.221366
INFO:root:frame =2577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =2578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241041183472
DEBUG:root: save sample needs time = 0.000116109848022
INFO:root:random_action_porb = 0.979733333333
DEBUG:root: dqn, choose action rondomly, need time 0.000166
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:frame =2581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =2582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.979701666667
DEBUG:root: dqn, choose action rondomly, need time 0.000311999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 61.24502563]
 [ 57.95217896]
 [ 56.25354767]
 [ 76.8217392 ]
 [ 43.05008698]
 [ 20.57594681]
 [ 60.44210815]
 [ 23.5301075 ]
 [ 53.07994843]
 [ 55.67105484]
 [ 60.03837967]
 [ 23.52426147]
 [ 78.84391785]
 [ 78.35894012]
 [ 53.07994843]
 [ 47.73908234]]
DEBUG:root:training time = %d0.215176
INFO:root:frame =2585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =2586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.97967
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =2589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000383138656616
INFO:root:frame =2590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.979638333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 30.03570557]
 [ 32.99707794]
 [ 26.81233025]
 [ 37.36493301]
 [ 29.01575279]
 [ 32.51501846]
 [ 30.22826767]
 [ 53.64440536]
 [ 23.91045189]
 [ 31.39212036]
 [ 54.72716904]
 [ 34.09905243]
 [ 43.72600555]
 [ 30.35861015]
 [ 23.9109745 ]
 [ 23.61493492]]
DEBUG:root:training time = %d0.213327
INFO:root:frame =2593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000188827514648
INFO:root:frame =2594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298023223877
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.979606666667
DEBUG:root: dqn, choose action rondomly, need time 0.000405999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =2597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000389099121094
INFO:root:frame =2598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:random_action_porb = 0.979575
DEBUG:root: dqn, choose action rondomly, need time 0.000165000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 49.81383896]
 [ 24.54161072]
 [ 49.22081375]
 [ 46.95603561]
 [ 36.86008835]
 [ 68.89650726]
 [ 49.22081375]
 [ 48.63240433]
 [ 48.63240433]
 [ 48.96305084]
 [ 25.21515274]
 [ 16.28778076]
 [ 48.96305084]
 [ 36.68991852]
 [ 22.99859238]
 [ 68.89650726]]
DEBUG:root:training time = %d0.231878
INFO:root:frame =2601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =2602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame = 2603 State into memory, numbers recorded 65 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000557899475098
INFO:root:random_action_porb = 0.979543333333
DEBUG:root: dqn, choose action rondomly, need time 0.000166
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2604current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000141859054565
INFO:root:frame =2605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000533103942871
INFO:root:frame =2606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.979511666667
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000341892242432
INFO:root:training error  = [[ 27.89909744]
 [ 28.76044846]
 [ 51.04454422]
 [ 46.10307693]
 [ 51.18450928]
 [ 23.9739151 ]
 [ 30.1548214 ]
 [ 37.94837189]
 [ 26.75847244]
 [ 48.53902435]
 [ 39.29621124]
 [ 48.46102524]
 [ 46.10307693]
 [ 28.76044846]
 [ 56.39520645]
 [ 24.58055496]]
DEBUG:root:training time = %d0.227907
INFO:root:frame =2609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =2610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000523090362549
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:random_action_porb = 0.97948
INFO:root:dqn select action Tensor("ArgMax_8:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011811
INFO:root:action choosen by dqn [2]
INFO:root:frame =2612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000396013259888
INFO:root:frame =2613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:frame =2614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000292062759399
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.979448333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 24.60204506]
 [ 50.06378555]
 [ 38.3554306 ]
 [ 41.1123085 ]
 [ 27.21409416]
 [ 40.36774063]
 [ 49.38431168]
 [ 27.0797348 ]
 [ 40.64617157]
 [ 36.91003799]
 [ 49.38431168]
 [ 27.0797348 ]
 [ 40.87129974]
 [ 37.71552277]
 [ 84.37091064]
 [ 25.58373642]]
DEBUG:root:training time = %d0.230181
INFO:root:frame =2617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029182434082
INFO:root:frame =2618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000519037246704
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.979416666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =2621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =2622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.979385
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 77.3985672 ]
 [ 75.48286438]
 [ 80.92269897]
 [ 72.16999817]
 [ 37.23688507]
 [ 37.2598877 ]
 [ 74.2455368 ]
 [ 40.72997284]
 [ 71.92417145]
 [ 70.44369507]
 [ 36.09518433]
 [ 44.19137573]
 [ 40.35339737]
 [ 24.26828194]
 [ 42.38956451]
 [ 43.20360184]]
DEBUG:root:training time = %d0.238123
INFO:root:frame =2625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224828720093
INFO:root:frame =2626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00030517578125
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.979353333333
DEBUG:root: dqn, choose action rondomly, need time 0.000226999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =2629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =2630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457763671875
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.979321666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 55.30312729]
 [ 40.21345139]
 [ 57.13741302]
 [ 96.18606567]
 [ 43.16589737]
 [ 27.19952965]
 [ 26.45662498]
 [ 77.72161865]
 [ 28.05607605]
 [ 43.91135025]
 [ 72.41143799]
 [ 81.74520874]
 [ 78.14891052]
 [ 55.95627213]
 [ 28.3690815 ]
 [ 27.39564705]]
DEBUG:root:training time = %d0.221331
INFO:root:frame =2633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:frame =2634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000343084335327
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.97929
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =2637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =2638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:random_action_porb = 0.979258333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 89.55294037]
 [ 45.47036362]
 [ 48.08075333]
 [ 89.25717163]
 [ 89.55294037]
 [ 72.3482132 ]
 [ 47.1393013 ]
 [ 42.08531952]
 [ 43.63010025]
 [ 94.48613739]
 [ 89.55294037]
 [ 70.24647522]
 [ 92.33216858]
 [ 46.55809021]
 [ 89.25717163]
 [ 71.70706177]]
DEBUG:root:training time = %d0.242177
INFO:root:frame =2641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =2642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000281810760498
INFO:root:random_action_porb = 0.979226666667
DEBUG:root: dqn, choose action rondomly, need time 0.000588
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000357151031494
INFO:root:frame =2645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000362157821655
INFO:root:frame =2646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.979195
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 78.57087708]
 [ 28.23895264]
 [ 29.35438538]
 [ 61.86407089]
 [ 28.23895264]
 [ 28.65637207]
 [ 21.1519146 ]
 [ 63.08108139]
 [ 63.08108139]
 [ 31.25360298]
 [ 77.94360352]
 [ 29.10302544]
 [ 29.07126045]
 [ 77.88070679]
 [ 42.54538345]
 [ 29.45897484]]
DEBUG:root:training time = %d0.237227
INFO:root:frame =2649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263214111328
INFO:root:frame =2650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000289916992188
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:random_action_porb = 0.979163333333
DEBUG:root: dqn, choose action rondomly, need time 0.000375999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =2653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =2654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000481128692627
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.979131666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 48.61665726]
 [ 27.74946976]
 [ 31.05949783]
 [ 39.81847763]
 [ 49.19747925]
 [ 27.74946976]
 [ 63.28278351]
 [ 31.05949783]
 [ 52.38012695]
 [ 66.88881683]
 [ 29.92525291]
 [ 49.06774139]
 [ 40.7865715 ]
 [ 31.81510162]
 [ 29.23983192]
 [ 66.36110687]]
DEBUG:root:training time = %d0.232388
INFO:root:frame =2657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232219696045
INFO:root:frame =2658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504016876221
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:random_action_porb = 0.9791
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =2661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =2662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root:frame = 2663 State into memory, numbers recorded 66 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000576019287109
INFO:root:random_action_porb = 0.979068333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2664current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000372171401978
INFO:root:training error  = [[ 57.52630997]
 [ 56.3997879 ]
 [ 94.10829163]
 [ 59.38563156]
 [ 94.89654541]
 [ 30.42186737]
 [ 28.66911507]
 [ 44.55097961]
 [ 57.52630997]
 [ 57.72751236]
 [ 57.72751236]
 [ 45.65720367]
 [ 28.39810371]
 [ 32.34531403]
 [ 94.10829163]
 [ 94.10829163]]
DEBUG:root:training time = %d0.230209
INFO:root:frame =2665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =2666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000554084777832
INFO:root:frame = 2667 State into memory, numbers recorded 67 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000569820404053
INFO:root:random_action_porb = 0.979036666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2668current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:frame =2669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =2670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000762939453125
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.979005
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  34.37225342]
 [  59.57497787]
 [  43.48166275]
 [ 106.08220673]
 [  32.015522  ]
 [  61.08463669]
 [  43.39970016]
 [  44.48694229]
 [  87.31378937]
 [  42.52100372]
 [  87.19648743]
 [  34.37225342]
 [  47.47156525]
 [  58.82489395]
 [  59.27280045]
 [  30.88702393]]
DEBUG:root:training time = %d0.217225
INFO:root:frame =2673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =2674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000222206115723
INFO:root:random_action_porb = 0.978973333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =2677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000481128692627
INFO:root:frame =2678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000246047973633
DEBUG:root: save sample needs time = 0.000107049942017
INFO:root:random_action_porb = 0.978941666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332832336426
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 101.12988281]
 [ 122.27680206]
 [  93.77656555]
 [  79.07835388]
 [  79.86418152]
 [  23.69998741]
 [  31.69308853]
 [  84.88298035]
 [ 101.14645386]
 [  32.68377304]
 [  31.69308853]
 [  85.03430939]
 [  84.98690033]
 [  39.55480194]
 [ 100.05615997]
 [  48.88567352]]
DEBUG:root:training time = %d0.209511
INFO:root:frame =2681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =2682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.97891
DEBUG:root: dqn, choose action rondomly, need time 0.000319999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =2685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =2686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000217199325562
INFO:root:random_action_porb = 0.978878333333
DEBUG:root: dqn, choose action rondomly, need time 0.000324999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  80.3010025 ]
 [  81.91442871]
 [ 115.65010834]
 [ 119.14673615]
 [ 115.01593781]
 [  82.651474  ]
 [  53.89929199]
 [  55.31141281]
 [  53.89929199]
 [  82.45543671]
 [  42.94232559]
 [ 122.33181763]
 [  82.45543671]
 [  53.89929199]
 [  82.45543671]
 [  65.15543365]]
DEBUG:root:training time = %d0.229272
INFO:root:frame =2689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =2690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000620126724243
INFO:root:frame = 2691 State into memory, numbers recorded 68 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000694036483765
INFO:root:random_action_porb = 0.978846666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2692current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =2693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =2694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:random_action_porb = 0.978815
DEBUG:root: dqn, choose action rondomly, need time 0.000323999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  93.21060181]
 [  35.73060989]
 [  66.1782608 ]
 [ 101.19909668]
 [  99.81529999]
 [  58.34185028]
 [  98.76694489]
 [  92.38980103]
 [ 100.84268188]
 [  63.20524216]
 [  63.39960861]
 [  61.88159561]
 [  35.22863388]
 [  66.76507568]
 [  92.38980103]
 [  82.42232513]]
DEBUG:root:training time = %d0.217939
INFO:root:frame =2697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000370979309082
INFO:root:frame =2698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
INFO:root:player has been killed for 5 times 
INFO:root:frame = 2699 State into memory, numbers recorded 69 action = -1, reward = -1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:random_action_porb = 0.978783333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2700current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =2701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000526189804077
INFO:root:frame =2702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000349044799805
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.978751666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  38.10494232]
 [  92.49323273]
 [ 104.06858063]
 [  36.53001404]
 [ 107.74845886]
 [  48.36334991]
 [  99.7695694 ]
 [  41.74371338]
 [  72.45039368]
 [ 125.63654327]
 [ 104.06858063]
 [ 103.96477509]
 [  99.85478973]
 [  33.03934097]
 [  42.93362808]
 [  31.4282093 ]]
DEBUG:root:training time = %d0.23381
INFO:root:frame =2705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266790390015
INFO:root:frame =2706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.97872
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =2709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =2710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.978688333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  70.90613556]
 [  73.72657776]
 [  59.3397789 ]
 [  83.67129517]
 [  36.1826973 ]
 [  61.33641052]
 [  73.72657776]
 [  70.44100189]
 [  37.6219635 ]
 [  72.23469543]
 [  68.08679962]
 [  97.61449432]
 [  51.00323486]
 [ 116.8529129 ]
 [ 100.45844269]
 [  74.54573822]]
DEBUG:root:training time = %d0.224256
INFO:root:frame =2713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:frame =2714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000222206115723
INFO:root:random_action_porb = 0.978656666667
DEBUG:root: dqn, choose action rondomly, need time 0.000349
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =2717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000624895095825
INFO:root:frame =2718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000541925430298
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.978625
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 44.14594269]
 [ 42.43925095]
 [ 40.58198929]
 [ 38.92614746]
 [ 43.47261047]
 [ 42.43925095]
 [ 43.47261047]
 [ 38.92614746]
 [ 45.83636856]
 [ 32.93356323]
 [ 41.54343033]
 [ 92.93827057]
 [ 93.11678314]
 [ 96.41261292]
 [ 48.72438812]
 [ 32.93356323]]
DEBUG:root:training time = %d0.203749
INFO:root:frame =2721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =2722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000158071517944
INFO:root:random_action_porb = 0.978593333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame =2725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:frame =2726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000385046005249
INFO:root:frame = 2727 State into memory, numbers recorded 70 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000591993331909
INFO:root:random_action_porb = 0.978561666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2728current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 54.98642349]
 [ 52.09702301]
 [ 92.56588745]
 [ 54.2170105 ]
 [ 99.16116333]
 [ 77.29470062]
 [ 39.99091721]
 [ 55.68790436]
 [ 51.04618073]
 [ 51.98331833]
 [ 75.37459564]
 [ 78.96495819]
 [ 80.57004547]
 [ 50.01672363]
 [ 93.85016632]
 [ 39.99091721]]
DEBUG:root:training time = %d0.218699
INFO:root:frame =2729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =2730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:random_action_porb = 0.97853
DEBUG:root: dqn, choose action rondomly, need time 0.000585000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =2733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =2734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000357151031494
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.978498333333
DEBUG:root: dqn, choose action rondomly, need time 0.000656999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  41.25272751]
 [ 111.96969604]
 [  62.96842575]
 [  56.07435608]
 [  62.65243149]
 [  47.1098671 ]
 [  39.09436035]
 [  56.07435608]
 [  42.57295609]
 [  61.67147827]
 [  44.04016113]
 [  43.47633362]
 [  58.97713089]
 [  44.31856537]
 [  91.22762299]
 [  41.25272751]]
DEBUG:root:training time = %d0.22491
INFO:root:frame =2737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250816345215
INFO:root:frame =2738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root:random_action_porb = 0.978466666667
DEBUG:root: dqn, choose action rondomly, need time 0.000157000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000140190124512
INFO:root:frame =2741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =2742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:random_action_porb = 0.978435
DEBUG:root: dqn, choose action rondomly, need time 0.000564000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 43.40603256]
 [ 46.58652115]
 [ 79.98640442]
 [ 72.97957611]
 [ 75.26692963]
 [ 45.27908325]
 [ 42.88565063]
 [ 53.73474121]
 [ 42.59735107]
 [ 42.59735107]
 [ 40.75519943]
 [ 65.74859619]
 [ 43.35809326]
 [ 41.06037521]
 [ 52.07312775]
 [ 51.18691254]]
DEBUG:root:training time = %d0.217631
INFO:root:frame =2745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =2746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.978403333333
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =2749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =2750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.978371666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  54.88090897]
 [  50.10773849]
 [ 138.60359192]
 [ 116.67549896]
 [  67.16389465]
 [  65.31861115]
 [  43.60339737]
 [  70.83985138]
 [ 114.8961792 ]
 [  50.58791733]
 [  51.5230484 ]
 [  63.53150177]
 [  51.5230484 ]
 [  69.80225372]
 [  68.81902313]
 [  43.07942581]]
DEBUG:root:training time = %d0.234633
INFO:root:frame =2753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =2754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00038480758667
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.97834
DEBUG:root: dqn, choose action rondomly, need time 0.000267000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =2757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =2758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000861883163452
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.978308333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  57.15321732]
 [ 101.2767868 ]
 [  58.356884  ]
 [ 121.87606049]
 [ 118.43344879]
 [ 119.73590851]
 [  42.31191254]
 [  54.82700348]
 [  53.68878174]
 [  50.74703598]
 [  50.74703598]
 [  99.64691925]
 [  99.39590454]
 [  50.66836929]
 [ 120.60085297]
 [  57.93185043]]
DEBUG:root:training time = %d0.220389
INFO:root:frame =2761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =2762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000790119171143
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:random_action_porb = 0.978276666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =2765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =2766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.978245
DEBUG:root: dqn, choose action rondomly, need time 0.000172999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00040602684021
INFO:root:training error  = [[  65.53299713]
 [  64.41191864]
 [ 140.44000244]
 [  45.47170258]
 [ 136.03398132]
 [ 166.02859497]
 [ 118.44706726]
 [  43.24703979]
 [ 117.07090759]
 [  41.70862579]
 [ 130.00021362]
 [ 118.51782227]
 [  43.24703979]
 [ 136.03398132]
 [ 114.95555878]
 [  68.36306763]]
DEBUG:root:training time = %d0.247964
INFO:root:frame =2769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265836715698
INFO:root:frame =2770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000365972518921
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.978213333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000175952911377
INFO:root:frame =2773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =2774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.978181666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 103.7021637 ]
 [  46.54413986]
 [  56.91571426]
 [ 101.25543976]
 [  74.93013763]
 [ 104.9865036 ]
 [  47.43950653]
 [ 102.33278656]
 [ 105.38149261]
 [  89.07447052]
 [  98.29740906]
 [ 110.79027557]
 [  46.54413986]
 [  87.73819733]
 [  88.62802124]
 [  89.07447052]]
DEBUG:root:training time = %d0.218839
INFO:root:frame =2777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root:frame =2778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
DEBUG:root: save sample needs time = 0.000116109848022
INFO:root:random_action_porb = 0.97815
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:frame =2781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =2782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.978118333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 142.09472656]
 [ 142.09472656]
 [  83.66348267]
 [ 124.99700928]
 [  83.27453613]
 [  64.18347931]
 [ 100.38948059]
 [  85.23930359]
 [  81.74106598]
 [ 150.93406677]
 [ 142.21369934]
 [  81.68782806]
 [ 122.83407593]
 [ 150.93406677]
 [ 140.75590515]
 [  65.90631866]]
DEBUG:root:training time = %d0.243642
INFO:root:frame =2785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =2786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.978086666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =2789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =2790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.978055
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  98.54748535]
 [ 104.69652557]
 [ 129.77554321]
 [ 103.80070496]
 [  80.33586884]
 [  50.85067749]
 [  68.66809082]
 [ 129.77554321]
 [ 133.27359009]
 [  51.28837967]
 [  70.73046875]
 [  97.55209351]
 [  59.94004822]
 [  50.28146362]
 [  66.58316803]
 [ 133.76763916]]
DEBUG:root:training time = %d0.214603
INFO:root:frame =2793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:frame =2794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000327110290527
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.978023333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =2797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame =2798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000558853149414
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.977991666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  53.29204941]
 [  53.29204941]
 [  78.74124908]
 [ 122.84760284]
 [ 112.7091217 ]
 [ 117.07618713]
 [  53.12620544]
 [  85.98277283]
 [  81.02856445]
 [  81.8677597 ]
 [  52.31300354]
 [ 139.73854065]
 [  55.26330566]
 [  81.02856445]
 [  53.12620544]
 [  51.10212326]]
DEBUG:root:training time = %d0.215707
INFO:root:frame =2801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =2802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.97796
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =2805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =2806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488042831421
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.977928333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000373125076294
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  75.60076141]
 [  55.27238083]
 [ 112.87052155]
 [  56.74455261]
 [  74.2091217 ]
 [ 105.14853668]
 [ 102.19915771]
 [  74.2091217 ]
 [  75.58165741]
 [ 113.42984772]
 [ 113.42984772]
 [  96.92344666]
 [  54.33459854]
 [  86.35302734]
 [ 106.69002533]
 [  56.92147064]]
DEBUG:root:training time = %d0.232019
INFO:root:frame =2809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =2810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000312089920044
DEBUG:root: save sample needs time = 0.000163793563843
INFO:root:random_action_porb = 0.977896666667
DEBUG:root: dqn, choose action rondomly, need time 0.000330999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =2813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =2814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.977865
DEBUG:root: dqn, choose action rondomly, need time 0.000554000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  56.6383934 ]
 [ 120.16623688]
 [  71.47621918]
 [  55.81208801]
 [  55.65306473]
 [  55.56362915]
 [  88.94432831]
 [  56.25526428]
 [  65.48483276]
 [  70.9629364 ]
 [  57.55941391]
 [  57.92534637]
 [  65.48483276]
 [  56.44265366]
 [  56.44265366]
 [  67.5631485 ]]
DEBUG:root:training time = %d0.2072
INFO:root:frame =2817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =2818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00142192840576
DEBUG:root: save sample needs time = 0.000103950500488
INFO:root:random_action_porb = 0.977833333333
DEBUG:root: dqn, choose action rondomly, need time 0.000318999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =2821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00110697746277
INFO:root:frame =2822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000311136245728
DEBUG:root: save sample needs time = 0.000134944915771
INFO:root:random_action_porb = 0.977801666667
DEBUG:root: dqn, choose action rondomly, need time 0.000242
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:training error  = [[  57.3105545 ]
 [  57.89469147]
 [  56.22459793]
 [ 149.33328247]
 [  56.57593918]
 [ 146.15805054]
 [  66.19104767]
 [ 141.25346375]
 [  64.91486359]
 [  58.10432816]
 [ 120.13111115]
 [ 121.37189484]
 [  57.87704468]
 [  57.89469147]
 [  66.19104767]
 [ 123.5776062 ]]
DEBUG:root:training time = %d0.20335
INFO:root:frame =2825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =2826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000110149383545
INFO:root:random_action_porb = 0.97777
DEBUG:root: dqn, choose action rondomly, need time 0.000160000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =2829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:frame =2830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame = 2831 State into memory, numbers recorded 71 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000590085983276
INFO:root:random_action_porb = 0.977738333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2832current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 118.9116745 ]
 [  57.28329849]
 [ 100.89432526]
 [ 140.12915039]
 [ 166.74305725]
 [  59.47573853]
 [ 140.84680176]
 [ 101.82865906]
 [ 140.84680176]
 [ 101.74460602]
 [ 105.43632507]
 [  63.7775383 ]
 [ 144.44381714]
 [ 139.34236145]
 [ 102.2179718 ]
 [ 124.03058624]]
DEBUG:root:training time = %d0.204565
INFO:root:frame =2833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235795974731
INFO:root:frame =2834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.977706666667
DEBUG:root: dqn, choose action rondomly, need time 0.000345000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =2837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =2838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:random_action_porb = 0.977675
DEBUG:root: dqn, choose action rondomly, need time 0.000174999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000152111053467
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 192.83120728]
 [ 100.57791901]
 [  66.45523834]
 [  69.98429108]
 [  67.37640381]
 [ 167.53489685]
 [ 135.51516724]
 [ 167.66369629]
 [ 164.34124756]
 [  90.15116882]
 [  69.83349609]
 [ 134.95762634]
 [ 169.90814209]
 [ 135.77604675]
 [ 160.80969238]
 [  68.82952881]]
DEBUG:root:training time = %d0.19481
INFO:root:frame =2841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:frame =2842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504970550537
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:random_action_porb = 0.977643333333
DEBUG:root: dqn, choose action rondomly, need time 0.000324999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root:frame =2845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame =2846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.977611666667
DEBUG:root: dqn, choose action rondomly, need time 0.000343000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:training error  = [[ 102.4152298 ]
 [  61.50287247]
 [  59.38398361]
 [ 182.23805237]
 [  62.19792557]
 [ 134.36550903]
 [  62.34675598]
 [ 134.36550903]
 [  62.19792557]
 [ 174.29632568]
 [ 106.78555298]
 [ 174.18191528]
 [  61.50287247]
 [ 167.49461365]
 [  59.46655655]
 [ 135.38943481]]
DEBUG:root:training time = %d0.219645
INFO:root:frame =2849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:frame =2850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239133834839
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:random_action_porb = 0.97758
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =2853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =2854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame = 2855 State into memory, numbers recorded 72 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000561952590942
INFO:root:random_action_porb = 0.977548333333
DEBUG:root: dqn, choose action rondomly, need time 0.000436000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2856current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  82.47414398]
 [  77.98752594]
 [  77.98752594]
 [  74.04043579]
 [ 101.57167816]
 [  64.12090302]
 [  96.90872955]
 [ 108.71855164]
 [  69.83706665]
 [  64.83350372]
 [  68.90068817]
 [  75.92510223]
 [  64.11797333]
 [  85.84558868]
 [  65.22381592]
 [  82.47414398]]
DEBUG:root:training time = %d0.225029
INFO:root:frame =2857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =2858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411987304688
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.977516666667
DEBUG:root: dqn, choose action rondomly, need time 0.000167000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000168800354004
INFO:root:frame =2861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000580072402954
INFO:root:frame =2862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.977485
DEBUG:root: dqn, choose action rondomly, need time 0.000307999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 118.3874588 ]
 [  84.92684174]
 [  84.92684174]
 [  84.60934448]
 [ 158.05265808]
 [ 102.01875305]
 [ 134.33757019]
 [ 123.59593201]
 [  67.33282471]
 [  55.14381409]
 [ 169.09880066]
 [  66.70948029]
 [ 174.97828674]
 [ 113.31741333]
 [ 173.33111572]
 [ 118.05265808]]
DEBUG:root:training time = %d0.238907
INFO:root:frame =2865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =2866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.977453333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =2869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000539064407349
INFO:root:frame =2870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000514030456543
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.977421666667
DEBUG:root: dqn, choose action rondomly, need time 0.000347999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  86.50680542]
 [  65.47174072]
 [  72.44571686]
 [  69.31548309]
 [ 163.48246765]
 [ 119.42838287]
 [  65.47174072]
 [ 167.53213501]
 [  90.73277283]
 [ 128.27767944]
 [  88.5076828 ]
 [ 162.24864197]
 [ 114.61535645]
 [  68.75941467]
 [  70.91436005]
 [  67.25596619]]
DEBUG:root:training time = %d0.231077
INFO:root:frame =2873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =2874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.97739
DEBUG:root: dqn, choose action rondomly, need time 0.000321
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000422954559326
INFO:root:frame =2877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =2878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.977358333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000371932983398
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  83.23750305]
 [ 184.50762939]
 [ 130.59172058]
 [ 130.74661255]
 [  69.15727997]
 [ 205.75061035]
 [ 197.21826172]
 [  53.40751266]
 [ 190.95001221]
 [ 202.02056885]
 [ 207.33522034]
 [ 178.80450439]
 [ 223.96208191]
 [  70.08338928]
 [ 109.13324738]
 [  69.15727997]]
DEBUG:root:training time = %d0.224847
INFO:root:frame =2881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:frame =2882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288009643555
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.977326666667
DEBUG:root: dqn, choose action rondomly, need time 0.000498999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000396966934204
INFO:root:frame =2885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =2886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:random_action_porb = 0.977295
DEBUG:root: dqn, choose action rondomly, need time 0.000247999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 148.36746216]
 [  71.83943939]
 [  71.92637634]
 [ 140.6643219 ]
 [ 198.8217926 ]
 [  71.49866486]
 [ 120.25022125]
 [ 138.24830627]
 [ 195.35368347]
 [ 198.8217926 ]
 [ 135.81837463]
 [ 192.88587952]
 [ 156.39689636]
 [ 175.44970703]
 [ 154.47019958]
 [ 133.53372192]]
DEBUG:root:training time = %d0.205051
INFO:root:frame =2889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =2890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:random_action_porb = 0.977263333333
DEBUG:root: dqn, choose action rondomly, need time 0.000190000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root:frame =2893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =2894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00034499168396
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.977231666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 131.31251526]
 [  76.53579712]
 [ 132.19665527]
 [ 112.49927521]
 [  75.15670013]
 [  64.20939636]
 [ 101.32393646]
 [  85.4307251 ]
 [ 121.36988068]
 [  65.14915466]
 [ 111.28968811]
 [  79.82354736]
 [ 112.49927521]
 [  77.38742828]
 [  84.67082977]
 [ 109.31439972]]
DEBUG:root:training time = %d0.192977
INFO:root:frame =2897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:frame =2898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:random_action_porb = 0.9772
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000374794006348
INFO:root:frame =2901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =2902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000514030456543
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.977168333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 208.1242981 ]
 [ 132.18228149]
 [  78.18276978]
 [ 188.51907349]
 [ 121.57841492]
 [ 136.30107117]
 [ 209.81436157]
 [  77.74408722]
 [ 118.99721527]
 [  85.91119385]
 [  78.82170105]
 [  95.22920227]
 [ 106.57972717]
 [ 107.35933685]
 [ 126.727005  ]
 [  76.42931366]]
DEBUG:root:training time = %d0.226273
INFO:root:frame =2905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =2906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.977136666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =2909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =2910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.977105
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 164.58192444]
 [ 112.07176208]
 [ 159.36634827]
 [  96.0918045 ]
 [ 215.78944397]
 [ 185.97799683]
 [ 112.70619965]
 [ 188.7973938 ]
 [  98.57112122]
 [  95.83560181]
 [ 164.68492126]
 [ 103.41210175]
 [  80.3867569 ]
 [ 109.89268494]
 [  98.57112122]
 [ 100.23542786]]
DEBUG:root:training time = %d0.216184
INFO:root:frame =2913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =2914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293016433716
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.977073333333
DEBUG:root: dqn, choose action rondomly, need time 0.000318999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =2917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000596046447754
INFO:root:frame =2918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.977041666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 119.98464966]
 [ 191.79180908]
 [ 161.29147339]
 [ 174.25602722]
 [ 218.26573181]
 [ 194.61305237]
 [ 192.47836304]
 [ 170.00521851]
 [ 208.9342804 ]
 [ 194.43515015]
 [ 119.98464966]
 [ 124.91138458]
 [ 192.4707489 ]
 [ 161.29147339]
 [  81.65473175]
 [ 125.74294281]]
DEBUG:root:training time = %d0.232905
INFO:root:frame =2921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =2922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000405073165894
INFO:root:random_action_porb = 0.97701
INFO:root:dqn select action Tensor("ArgMax_9:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010907
INFO:root:action choosen by dqn [2]
INFO:root:frame =2924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000157833099365
INFO:root:frame =2925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:frame =2926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame = 2927 State into memory, numbers recorded 73 action = [2], reward = 0
DEBUG:root: save sample needs time = 0.00124216079712
INFO:root:random_action_porb = 0.976978333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2928current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:training error  = [[ 209.18800354]
 [ 165.6265564 ]
 [ 155.86228943]
 [ 160.29463196]
 [ 144.33821106]
 [ 147.08816528]
 [  88.0091095 ]
 [ 146.78887939]
 [ 151.30809021]
 [ 148.75244141]
 [ 158.72171021]
 [ 158.44270325]
 [ 189.13551331]
 [ 197.77793884]
 [ 160.59614563]
 [ 161.71070862]]
DEBUG:root:training time = %d0.220945
INFO:root:frame =2929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =2930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488996505737
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.976946666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =2933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =2934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:random_action_porb = 0.976915
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 158.12287903]
 [ 123.29686737]
 [  94.13967896]
 [ 158.12287903]
 [ 107.62321472]
 [  78.19895935]
 [  90.63135529]
 [ 102.75863647]
 [  78.19895935]
 [ 155.42634583]
 [  90.28740692]
 [ 106.04134369]
 [ 100.65934753]
 [  88.96217346]
 [  90.63774109]
 [  89.01197815]]
DEBUG:root:training time = %d0.223558
INFO:root:frame =2937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =2938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame = 2939 State into memory, numbers recorded 74 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000660181045532
INFO:root:random_action_porb = 0.976883333333
DEBUG:root: dqn, choose action rondomly, need time 0.000225999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2940current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =2941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000602960586548
INFO:root:frame =2942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031304359436
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:random_action_porb = 0.976851666667
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 143.1111145 ]
 [ 129.09399414]
 [  91.11805725]
 [ 137.34054565]
 [  88.90461731]
 [ 134.65644836]
 [ 127.19569397]
 [ 123.73778534]
 [  94.09320068]
 [ 134.65644836]
 [ 127.19569397]
 [  94.06774139]
 [  94.09320068]
 [ 103.58876038]
 [ 130.34213257]
 [  90.78278351]]
DEBUG:root:training time = %d0.232323
INFO:root:frame =2945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =2946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame = 2947 State into memory, numbers recorded 75 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000542879104614
INFO:root:random_action_porb = 0.97682
DEBUG:root: dqn, choose action rondomly, need time 0.000404000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =2948current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =2949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000476121902466
INFO:root:frame =2950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:random_action_porb = 0.976788333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 157.52479553]
 [ 134.34924316]
 [  90.81214905]
 [ 145.240448  ]
 [ 225.69725037]
 [ 148.30984497]
 [ 154.46412659]
 [ 253.3535614 ]
 [  87.8660202 ]
 [ 253.3535614 ]
 [ 144.33235168]
 [ 148.84141541]
 [ 253.3535614 ]
 [ 157.16496277]
 [  90.81214905]
 [ 253.51824951]]
DEBUG:root:training time = %d0.231657
INFO:root:frame =2953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000369071960449
INFO:root:frame =2954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000669002532959
INFO:root:frame = 2955 State into memory, numbers recorded 76 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000637054443359
INFO:root:random_action_porb = 0.976756666667
DEBUG:root: dqn, choose action rondomly, need time 0.000163999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2956current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:frame =2957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =2958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000108003616333
INFO:root:random_action_porb = 0.976725
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 103.94532776]
 [ 135.15304565]
 [  94.20157623]
 [  94.20157623]
 [ 159.98297119]
 [ 210.3132782 ]
 [ 163.686203  ]
 [  93.81099701]
 [ 190.14581299]
 [ 130.82025146]
 [  96.37980652]
 [ 199.56735229]
 [ 115.21305084]
 [ 191.10649109]
 [  95.77227783]
 [ 163.686203  ]]
DEBUG:root:training time = %d0.219963
INFO:root:frame =2961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root: ememy has been killed for 5 times 
INFO:root:enemies_left [0]
INFO:root:frame =2962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000392913818359
INFO:root:frame = 2963 State into memory, numbers recorded 77 action = 4, reward = 1
DEBUG:root: save sample needs time = 0.000545024871826
INFO:root:random_action_porb = 0.976693333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2964current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =2965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =2966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.976661666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 188.04336548]
 [ 103.7522049 ]
 [ 154.62763977]
 [ 191.2520752 ]
 [  98.25444794]
 [ 160.54586792]
 [ 163.80180359]
 [ 101.22964478]
 [ 108.18621826]
 [ 166.60832214]
 [ 175.13293457]
 [ 284.65386963]
 [ 198.6264801 ]
 [ 175.13293457]
 [ 178.68659973]
 [ 244.39389038]]
DEBUG:root:training time = %d0.209989
INFO:root:frame =2969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root:frame =2970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000250101089478
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.97663
INFO:root:dqn select action Tensor("ArgMax_10:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010099
INFO:root:action choosen by dqn [3]
INFO:root:frame =2972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:frame =2973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root:frame =2974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.976598333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =2976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  97.31050873]
 [  94.36603546]
 [  94.36603546]
 [ 174.96980286]
 [ 257.57858276]
 [  97.31050873]
 [ 184.73942566]
 [ 255.7832489 ]
 [ 151.08894348]
 [  97.31050873]
 [  97.63047791]
 [  98.60324097]
 [ 277.11865234]
 [ 186.93476868]
 [  94.36603546]
 [ 164.34515381]]
DEBUG:root:training time = %d0.212901
INFO:root:frame =2977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =2978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000391006469727
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.976566666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =2981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =2982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:random_action_porb = 0.976535
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =2984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000494003295898
INFO:root:training error  = [[ 122.75122833]
 [ 146.17022705]
 [ 118.1657486 ]
 [ 168.95993042]
 [ 221.72935486]
 [ 118.1657486 ]
 [ 128.9335022 ]
 [ 167.67160034]
 [ 172.52928162]
 [ 167.67160034]
 [ 202.10386658]
 [ 100.15966797]
 [ 214.54408264]
 [ 108.35388184]
 [ 117.96910858]
 [ 188.97439575]]
DEBUG:root:training time = %d0.217219
INFO:root:frame =2985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =2986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.976503333333
DEBUG:root: dqn, choose action rondomly, need time 0.000457000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =2989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =2990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame = 2991 State into memory, numbers recorded 78 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000547885894775
INFO:root:random_action_porb = 0.976471666667
DEBUG:root: dqn, choose action rondomly, need time 0.000318999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =2992current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000347852706909
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 192.91809082]
 [ 119.24602509]
 [ 157.01501465]
 [ 297.07049561]
 [ 218.64686584]
 [ 322.49771118]
 [ 179.96368408]
 [ 300.68289185]
 [ 106.80605316]
 [ 193.43598938]
 [ 297.07049561]
 [ 322.49771118]
 [ 296.18432617]
 [ 102.77162933]
 [ 163.01495361]
 [ 145.3195343 ]]
DEBUG:root:training time = %d0.209307
INFO:root:frame =2993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =2994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441789627075
DEBUG:root: save sample needs time = 0.000189065933228
INFO:root:random_action_porb = 0.97644
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =2996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =2997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =2998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000168800354004
DEBUG:root:one frame running time = 0.004573
DEBUG:root:total training time = 56.887786
INFO:root:frame num = 3000 frame round: 0
INFO:root:random_action_porb = 0.976408333333
DEBUG:root: dqn, choose action rondomly, need time 0.000318
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000370025634766
INFO:root:training error  = [[ 224.83660889]
 [ 233.09986877]
 [ 219.74751282]
 [ 133.46144104]
 [ 203.54418945]
 [ 197.52095032]
 [ 191.82478333]
 [ 191.82478333]
 [ 219.74751282]
 [ 133.46144104]
 [ 127.95780945]
 [ 224.83660889]
 [ 189.69497681]
 [ 230.06634521]
 [ 198.83857727]
 [ 196.8901062 ]]
DEBUG:root:training time = %d0.238555
INFO:root:frame =3001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =3002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000490188598633
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.976376666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =3005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:frame =3006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.976345
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 264.15475464]
 [ 264.51397705]
 [ 190.0052948 ]
 [ 176.70423889]
 [ 181.77076721]
 [ 113.01451874]
 [ 198.01577759]
 [ 272.6696167 ]
 [ 143.1056366 ]
 [ 210.39472961]
 [ 148.91886902]
 [ 264.15475464]
 [ 179.96450806]
 [ 176.1869812 ]
 [ 190.23251343]
 [ 274.44885254]]
DEBUG:root:training time = %d0.225374
INFO:root:frame =3009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame =3010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000380039215088
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.976313333333
DEBUG:root: dqn, choose action rondomly, need time 0.000171000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:frame =3013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =3014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.976281666667
DEBUG:root: dqn, choose action rondomly, need time 0.000318999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 163.7127533 ]
 [ 214.79537964]
 [ 157.86050415]
 [ 119.73574066]
 [ 223.88261414]
 [ 223.88261414]
 [ 217.21873474]
 [ 198.89796448]
 [ 114.25559998]
 [ 144.88098145]
 [ 110.9827652 ]
 [ 110.9827652 ]
 [ 254.63220215]
 [ 168.29219055]
 [ 166.85578918]
 [ 158.79629517]]
DEBUG:root:training time = %d0.202422
INFO:root:frame =3017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:frame =3018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:random_action_porb = 0.97625
DEBUG:root: dqn, choose action rondomly, need time 0.000408
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:frame =3021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =3022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.976218333333
DEBUG:root: dqn, choose action rondomly, need time 0.000197
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180006027222
INFO:root:training error  = [[ 163.47154236]
 [ 169.41722107]
 [ 129.0856781 ]
 [ 134.27037048]
 [ 118.03308868]
 [ 129.84124756]
 [ 158.63214111]
 [ 205.73529053]
 [ 141.31077576]
 [ 269.63739014]
 [ 135.5887146 ]
 [ 255.89015198]
 [ 141.31077576]
 [ 254.75737   ]
 [ 269.63739014]
 [ 119.40904236]]
DEBUG:root:training time = %d0.205036
INFO:root:frame =3025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =3026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000292062759399
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.976186666667
DEBUG:root: dqn, choose action rondomly, need time 0.000436999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =3029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =3030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.976155
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 336.61242676]
 [ 279.05911255]
 [ 246.95870972]
 [ 246.95870972]
 [ 198.50907898]
 [ 345.30435181]
 [ 196.38813782]
 [ 174.41116333]
 [ 227.24357605]
 [ 300.37179565]
 [ 182.52531433]
 [ 340.20761108]
 [ 226.40293884]
 [ 304.88861084]
 [ 368.77581787]
 [ 279.05911255]]
DEBUG:root:training time = %d0.211582
INFO:root:frame =3033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =3034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000297069549561
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:random_action_porb = 0.976123333333
DEBUG:root: dqn, choose action rondomly, need time 0.000362000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =3037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000641822814941
INFO:root:frame =3038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449180603027
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.976091666667
DEBUG:root: dqn, choose action rondomly, need time 0.000363
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 230.64254761]
 [ 228.80070496]
 [ 218.79716492]
 [ 252.82678223]
 [ 127.2094574 ]
 [ 243.13934326]
 [ 290.15078735]
 [ 252.82678223]
 [ 257.07290649]
 [ 215.70606995]
 [ 253.52845764]
 [ 234.80361938]
 [ 129.10162354]
 [ 248.42793274]
 [ 230.64254761]
 [ 253.28118896]]
DEBUG:root:training time = %d0.214055
INFO:root:frame =3041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =3042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:random_action_porb = 0.97606
DEBUG:root: dqn, choose action rondomly, need time 0.000351000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =3045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000600814819336
INFO:root:frame =3046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000256776809692
INFO:root:random_action_porb = 0.976028333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 283.94070435]
 [ 221.23248291]
 [ 139.55462646]
 [ 183.06045532]
 [ 185.43859863]
 [ 285.77484131]
 [ 133.11158752]
 [ 229.59860229]
 [ 287.78158569]
 [ 195.56658936]
 [ 186.41316223]
 [ 188.25350952]
 [ 285.77484131]
 [ 194.85835266]
 [ 285.77484131]
 [ 190.44725037]]
DEBUG:root:training time = %d0.22206
INFO:root:frame =3049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =3050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324010848999
DEBUG:root: save sample needs time = 0.000146150588989
INFO:root:random_action_porb = 0.975996666667
DEBUG:root: dqn, choose action rondomly, need time 0.000374000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root:frame =3053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =3054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.975965
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 222.91880798]
 [ 158.8782196 ]
 [ 136.12226868]
 [ 142.35240173]
 [ 137.97573853]
 [ 137.67048645]
 [ 140.70233154]
 [ 145.23014832]
 [ 171.35919189]
 [ 137.97573853]
 [ 136.38871765]
 [ 145.07316589]
 [ 258.07449341]
 [ 217.62957764]
 [ 135.79631042]
 [ 140.70233154]]
DEBUG:root:training time = %d0.206652
INFO:root:frame =3057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:frame =3058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:random_action_porb = 0.975933333333
DEBUG:root: dqn, choose action rondomly, need time 0.000184999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root:frame =3061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =3062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0963537693024
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:random_action_porb = 0.975901666667
DEBUG:root: dqn, choose action rondomly, need time 0.000251999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 137.57705688]
 [ 172.71533203]
 [ 131.56652832]
 [ 270.55471802]
 [ 280.80535889]
 [ 166.96144104]
 [ 189.2278595 ]
 [ 186.41273499]
 [ 233.29281616]
 [ 178.4659729 ]
 [ 287.79296875]
 [ 131.56652832]
 [ 279.85192871]
 [ 261.39187622]
 [ 170.95594788]
 [ 186.79251099]]
DEBUG:root:training time = %d0.185906
INFO:root:frame =3065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =3066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.97587
DEBUG:root: dqn, choose action rondomly, need time 0.000152
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:frame =3069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000338792800903
INFO:root:frame =3070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229120254517
DEBUG:root: save sample needs time = 0.000121831893921
INFO:root:random_action_porb = 0.975838333333
DEBUG:root: dqn, choose action rondomly, need time 0.000187000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 228.170578  ]
 [ 172.91311646]
 [ 172.91311646]
 [ 320.79501343]
 [ 142.8188324 ]
 [ 332.50189209]
 [ 341.31289673]
 [ 137.66404724]
 [ 238.06254578]
 [ 147.29512024]
 [ 342.09136963]
 [ 164.17697144]
 [ 360.81622314]
 [ 314.14175415]
 [ 326.22415161]
 [ 305.09326172]]
DEBUG:root:training time = %d0.1913
INFO:root:frame =3073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240802764893
INFO:root:frame =3074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000391006469727
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.975806666667
DEBUG:root: dqn, choose action rondomly, need time 0.000210000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =3077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:frame =3078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.975775
DEBUG:root: dqn, choose action rondomly, need time 0.000192999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 231.88955688]
 [ 234.42124939]
 [ 251.41137695]
 [ 255.3056488 ]
 [ 247.88661194]
 [ 221.45677185]
 [ 321.83984375]
 [ 351.32449341]
 [ 304.94134521]
 [ 145.08566284]
 [ 187.21861267]
 [ 179.30638123]
 [ 132.35986328]
 [ 296.75183105]
 [ 223.45405579]
 [ 257.855896  ]]
DEBUG:root:training time = %d0.183946
INFO:root:frame =3081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =3082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000315189361572
DEBUG:root: save sample needs time = 0.000111103057861
INFO:root:random_action_porb = 0.975743333333
DEBUG:root: dqn, choose action rondomly, need time 0.000160000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000141859054565
INFO:root:frame =3085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =3086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
DEBUG:root: save sample needs time = 0.000337839126587
INFO:root:random_action_porb = 0.975711666667
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 318.55136108]
 [ 313.8989563 ]
 [ 323.94342041]
 [ 323.94342041]
 [ 323.94342041]
 [ 184.85517883]
 [ 177.31814575]
 [ 190.38534546]
 [ 201.0315094 ]
 [ 154.31283569]
 [ 185.59280396]
 [ 328.01303101]
 [ 198.8523407 ]
 [ 323.38998413]
 [ 327.51080322]
 [ 180.0050354 ]]
DEBUG:root:training time = %d0.212227
INFO:root:frame =3089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249147415161
INFO:root:frame =3090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000227928161621
DEBUG:root: save sample needs time = 0.000104188919067
INFO:root:random_action_porb = 0.97568
DEBUG:root: dqn, choose action rondomly, need time 0.000229000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000147104263306
INFO:root:frame =3093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =3094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000566005706787
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.975648333333
DEBUG:root: dqn, choose action rondomly, need time 0.000629000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 327.88037109]
 [ 292.89102173]
 [ 253.23553467]
 [ 130.87715149]
 [ 162.09863281]
 [ 157.78036499]
 [ 342.09588623]
 [ 269.28921509]
 [ 292.79650879]
 [ 289.46035767]
 [ 163.33187866]
 [ 289.46035767]
 [ 261.87216187]
 [ 156.59388733]
 [ 169.95985413]
 [ 157.1026001 ]]
DEBUG:root:training time = %d0.214761
INFO:root:frame =3097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =3098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000310897827148
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.975616666667
DEBUG:root: dqn, choose action rondomly, need time 0.000605999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000337839126587
INFO:root:frame =3101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =3102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.975585
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 231.18093872]
 [ 147.77033997]
 [ 158.10983276]
 [ 159.77305603]
 [ 199.69671631]
 [ 316.71844482]
 [ 289.03942871]
 [ 314.82150269]
 [ 168.94882202]
 [ 306.87194824]
 [ 287.68789673]
 [ 159.77305603]
 [ 151.54318237]
 [ 270.37252808]
 [ 147.77033997]
 [ 320.44146729]]
DEBUG:root:training time = %d0.222968
INFO:root:frame =3105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:frame =3106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:random_action_porb = 0.975553333333
DEBUG:root: dqn, choose action rondomly, need time 0.000195999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame =3109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023078918457
INFO:root:frame =3110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.975521666667
DEBUG:root: dqn, choose action rondomly, need time 0.000438000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:training error  = [[ 390.45074463]
 [ 338.57269287]
 [ 268.42404175]
 [ 258.99307251]
 [ 405.72961426]
 [ 386.64593506]
 [ 182.28419495]
 [ 396.91635132]
 [ 316.07519531]
 [ 258.99307251]
 [ 386.64593506]
 [ 189.95439148]
 [ 170.48104858]
 [ 195.99615479]
 [ 365.95999146]
 [ 376.40771484]]
DEBUG:root:training time = %d0.192726
INFO:root:frame =3113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =3114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277042388916
DEBUG:root: save sample needs time = 0.000184059143066
INFO:root:random_action_porb = 0.97549
DEBUG:root: dqn, choose action rondomly, need time 0.000230000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =3117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000470161437988
INFO:root:frame =3118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000429153442383
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:random_action_porb = 0.975458333333
DEBUG:root: dqn, choose action rondomly, need time 0.000399999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000471830368042
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 242.94618225]
 [ 407.90487671]
 [ 163.53669739]
 [ 332.22314453]
 [ 308.52288818]
 [ 227.22241211]
 [ 403.49084473]
 [ 257.33621216]
 [ 324.96917725]
 [ 171.93772888]
 [ 170.41848755]
 [ 392.84780884]
 [ 372.80410767]
 [ 233.06866455]
 [ 231.02784729]
 [ 154.03129578]]
DEBUG:root:training time = %d0.213151
INFO:root:frame =3121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259160995483
INFO:root:frame =3122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000712156295776
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.975426666667
DEBUG:root: dqn, choose action rondomly, need time 0.000443000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000509023666382
INFO:root:frame =3125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000592947006226
INFO:root:frame =3126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488042831421
INFO:root:frame = 3127 State into memory, numbers recorded 79 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000419855117798
INFO:root:random_action_porb = 0.975395
DEBUG:root: dqn, choose action rondomly, need time 0.000366999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3128current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000360012054443
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 243.43731689]
 [ 243.91799927]
 [ 171.93293762]
 [ 250.95478821]
 [ 237.08837891]
 [ 359.38638306]
 [ 181.07279968]
 [ 258.30593872]
 [ 250.95478821]
 [ 258.95278931]
 [ 326.88537598]
 [ 237.08837891]
 [ 243.43731689]
 [ 181.07279968]
 [ 255.03607178]
 [ 318.31338501]]
DEBUG:root:training time = %d0.205501
INFO:root:frame =3129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000406980514526
INFO:root:frame =3130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000425100326538
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:random_action_porb = 0.975363333333
DEBUG:root: dqn, choose action rondomly, need time 0.000425999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000405073165894
INFO:root:frame =3133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000476121902466
INFO:root:frame =3134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000158071517944
INFO:root:random_action_porb = 0.975331666667
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00036096572876
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 182.26112366]
 [ 220.92076111]
 [ 209.55142212]
 [ 173.33955383]
 [ 247.33100891]
 [ 226.73643494]
 [ 218.71411133]
 [ 232.44523621]
 [ 214.32243347]
 [ 183.38224792]
 [ 220.92710876]
 [ 186.96606445]
 [ 181.33201599]
 [ 215.95713806]
 [ 201.33840942]
 [ 219.79455566]]
DEBUG:root:training time = %d0.234215
INFO:root:frame =3137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =3138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000366926193237
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.9753
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000371932983398
INFO:root:frame =3141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =3142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.975268333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:training error  = [[ 190.42619324]
 [ 333.93859863]
 [ 193.61387634]
 [ 216.49699402]
 [ 190.88633728]
 [ 188.2334137 ]
 [ 190.97573853]
 [ 204.03343201]
 [ 173.52079773]
 [ 207.81446838]
 [ 179.34480286]
 [ 320.60101318]
 [ 183.66999817]
 [ 333.93859863]
 [ 193.61473083]
 [ 172.92715454]]
DEBUG:root:training time = %d0.222728
INFO:root:frame =3145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240802764893
INFO:root:frame =3146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000330924987793
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:random_action_porb = 0.975236666667
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =3149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000425815582275
INFO:root:frame =3150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:random_action_porb = 0.975205
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:training error  = [[ 297.23095703]
 [ 274.25271606]
 [ 310.43734741]
 [ 203.87478638]
 [ 249.97338867]
 [ 248.11633301]
 [ 314.34030151]
 [ 224.2535553 ]
 [ 312.4515686 ]
 [ 249.97338867]
 [ 319.22766113]
 [ 186.06166077]
 [ 268.08966064]
 [ 199.60874939]
 [ 302.59094238]
 [ 260.55328369]]
DEBUG:root:training time = %d0.232234
INFO:root:frame =3153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =3154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00039005279541
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.975173333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =3157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =3158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.975141666667
DEBUG:root: dqn, choose action rondomly, need time 0.000261000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 457.7520752 ]
 [ 457.7520752 ]
 [ 300.23641968]
 [ 318.16748047]
 [ 195.78643799]
 [ 300.23641968]
 [ 192.95454407]
 [ 198.98835754]
 [ 196.91708374]
 [ 207.02947998]
 [ 207.02947998]
 [ 338.07702637]
 [ 505.13275146]
 [ 311.08184814]
 [ 449.14038086]
 [ 207.10414124]]
DEBUG:root:training time = %d0.204478
INFO:root:frame =3161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:frame =3162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.97511
DEBUG:root: dqn, choose action rondomly, need time 0.000164999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000130891799927
INFO:root:frame =3165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =3166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446796417236
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.975078333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 336.43829346]
 [ 448.09066772]
 [ 306.01611328]
 [ 492.79989624]
 [ 458.24191284]
 [ 224.09362793]
 [ 492.79989624]
 [ 336.43829346]
 [ 200.87231445]
 [ 475.87701416]
 [ 191.99430847]
 [ 488.49255371]
 [ 224.09362793]
 [ 336.43829346]
 [ 427.70755005]
 [ 318.77416992]]
DEBUG:root:training time = %d0.226291
INFO:root:frame =3169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =3170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000314950942993
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:random_action_porb = 0.975046666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000367879867554
INFO:root:frame =3173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000425100326538
INFO:root:frame =3174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.975015
DEBUG:root: dqn, choose action rondomly, need time 0.00029
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 242.68748474]
 [ 231.07933044]
 [ 340.23855591]
 [ 211.13505554]
 [ 246.79136658]
 [ 220.95796204]
 [ 340.23855591]
 [ 200.06863403]
 [ 401.27053833]
 [ 406.48236084]
 [ 232.0145874 ]
 [ 223.43261719]
 [ 223.43261719]
 [ 410.29983521]
 [ 399.11303711]
 [ 248.61074829]]
DEBUG:root:training time = %d0.217087
INFO:root:frame =3177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =3178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.974983333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =3181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000540971755981
INFO:root:frame =3182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.974951666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 385.14660645]
 [ 531.13592529]
 [ 283.87026978]
 [ 222.92108154]
 [ 269.54467773]
 [ 509.5760498 ]
 [ 222.92108154]
 [ 268.13562012]
 [ 242.78257751]
 [ 237.98109436]
 [ 270.7454834 ]
 [ 515.77557373]
 [ 248.31634521]
 [ 253.23406982]
 [ 198.85664368]
 [ 215.90916443]]
DEBUG:root:training time = %d0.235596
INFO:root:frame =3185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =3186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000276803970337
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.97492
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =3189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:frame =3190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.974888333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 431.28216553]
 [ 307.6262207 ]
 [ 452.56304932]
 [ 431.28216553]
 [ 450.31176758]
 [ 356.64013672]
 [ 295.6630249 ]
 [ 377.84725952]
 [ 453.17739868]
 [ 351.83377075]
 [ 218.56384277]
 [ 374.949646  ]
 [ 346.56332397]
 [ 431.28216553]
 [ 231.89375305]
 [ 200.14547729]]
DEBUG:root:training time = %d0.234347
INFO:root:frame =3193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =3194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:random_action_porb = 0.974856666667
DEBUG:root: dqn, choose action rondomly, need time 0.000325000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:frame =3197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =3198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.974825
DEBUG:root: dqn, choose action rondomly, need time 0.000346999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:training error  = [[ 407.78903198]
 [ 312.59509277]
 [ 295.80157471]
 [ 300.67123413]
 [ 407.78903198]
 [ 410.21948242]
 [ 444.28735352]
 [ 405.35961914]
 [ 443.12640381]
 [ 309.70544434]
 [ 227.92724609]
 [ 489.54129028]
 [ 484.44454956]
 [ 484.41098022]
 [ 214.92376709]
 [ 297.51617432]]
DEBUG:root:training time = %d0.221714
INFO:root:frame =3201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =3202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.974793333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000369071960449
INFO:root:frame =3205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000530958175659
INFO:root:frame =3206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000184059143066
INFO:root:random_action_porb = 0.974761666667
DEBUG:root: dqn, choose action rondomly, need time 0.000346000000008
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 230.34602356]
 [ 497.98794556]
 [ 259.20135498]
 [ 402.78436279]
 [ 407.46615601]
 [ 497.98794556]
 [ 238.47660828]
 [ 449.45861816]
 [ 490.27755737]
 [ 430.55743408]
 [ 268.20159912]
 [ 277.90969849]
 [ 208.27754211]
 [ 387.9954834 ]
 [ 282.33087158]
 [ 393.64724731]]
DEBUG:root:training time = %d0.223922
INFO:root:frame =3209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =3210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00023889541626
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:random_action_porb = 0.97473
DEBUG:root: dqn, choose action rondomly, need time 0.000273000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =3213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000404119491577
INFO:root:frame =3214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.974698333333
INFO:root:dqn select action Tensor("ArgMax_11:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010865
INFO:root:action choosen by dqn [1]
INFO:root:frame =3216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 431.97323608]
 [ 481.65835571]
 [ 484.52383423]
 [ 453.13583374]
 [ 473.08773804]
 [ 460.4133606 ]
 [ 291.55709839]
 [ 234.94018555]
 [ 456.5958252 ]
 [ 303.13265991]
 [ 485.61938477]
 [ 484.52383423]
 [ 321.99920654]
 [ 267.11917114]
 [ 240.59259033]
 [ 485.61938477]]
DEBUG:root:training time = %d0.21626
INFO:root:frame =3217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =3218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00032901763916
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:random_action_porb = 0.974666666667
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =3221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =3222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:random_action_porb = 0.974635
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 530.69152832]
 [ 513.98486328]
 [ 235.81854248]
 [ 246.43864441]
 [ 230.71855164]
 [ 587.77246094]
 [ 518.8894043 ]
 [ 260.63897705]
 [ 408.06390381]
 [ 391.70846558]
 [ 232.15963745]
 [ 244.52606201]
 [ 253.23406982]
 [ 235.93664551]
 [ 455.55307007]
 [ 262.49972534]]
DEBUG:root:training time = %d0.240018
INFO:root:frame =3225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000188827514648
INFO:root:frame =3226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000337839126587
INFO:root:frame = 3227 State into memory, numbers recorded 80 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000416040420532
INFO:root:random_action_porb = 0.974603333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3228current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =3229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =3230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame = 3231 State into memory, numbers recorded 81 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000567197799683
INFO:root:random_action_porb = 0.974571666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3232current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000424861907959
INFO:root:training error  = [[ 339.98303223]
 [ 496.63092041]
 [ 237.35253906]
 [ 450.17706299]
 [ 471.60998535]
 [ 476.20727539]
 [ 335.8664856 ]
 [ 355.05932617]
 [ 355.05932617]
 [ 335.8664856 ]
 [ 304.09725952]
 [ 252.38977051]
 [ 252.64678955]
 [ 438.34313965]
 [ 339.98303223]
 [ 335.8664856 ]]
DEBUG:root:training time = %d0.238174
INFO:root:frame =3233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =3234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.97454
DEBUG:root: dqn, choose action rondomly, need time 0.000311999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =3237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =3238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.974508333333
DEBUG:root: dqn, choose action rondomly, need time 0.000371999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 245.97798157]
 [ 496.83087158]
 [ 391.34735107]
 [ 247.60993958]
 [ 519.23706055]
 [ 531.89019775]
 [ 410.41482544]
 [ 524.29229736]
 [ 318.07931519]
 [ 294.6050415 ]
 [ 538.70513916]
 [ 257.60406494]
 [ 244.15016174]
 [ 436.49981689]
 [ 511.59515381]
 [ 391.22421265]]
DEBUG:root:training time = %d0.22161
INFO:root:frame =3241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274181365967
INFO:root:frame =3242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000591993331909
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root:random_action_porb = 0.974476666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =3245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00069785118103
INFO:root:frame =3246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000498056411743
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.974445
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 451.54434204]
 [ 332.84310913]
 [ 274.06375122]
 [ 465.1980896 ]
 [ 258.92727661]
 [ 334.12042236]
 [ 465.1980896 ]
 [ 256.90802002]
 [ 306.4102478 ]
 [ 349.57974243]
 [ 243.47445679]
 [ 477.06274414]
 [ 266.51898193]
 [ 301.16567993]
 [ 493.69589233]
 [ 298.09759521]]
DEBUG:root:training time = %d0.217641
INFO:root:frame =3249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312805175781
INFO:root:frame =3250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000339031219482
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.974413333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =3253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000523805618286
INFO:root:frame =3254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.974381666667
DEBUG:root: dqn, choose action rondomly, need time 0.000332999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00036096572876
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 353.85159302]
 [ 357.24206543]
 [ 411.67205811]
 [ 259.06970215]
 [ 415.23764038]
 [ 272.99777222]
 [ 485.24688721]
 [ 473.73312378]
 [ 446.06451416]
 [ 440.01745605]
 [ 272.99777222]
 [ 484.01477051]
 [ 451.68701172]
 [ 435.16827393]
 [ 259.06970215]
 [ 450.41796875]]
DEBUG:root:training time = %d0.246856
INFO:root:frame =3257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000363111495972
INFO:root:frame =3258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484228134155
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.97435
DEBUG:root: dqn, choose action rondomly, need time 0.000502999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =3261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000391960144043
INFO:root:frame =3262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.974318333333
DEBUG:root: dqn, choose action rondomly, need time 0.000515000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:training error  = [[ 374.12872314]
 [ 322.73452759]
 [ 281.86953735]
 [ 374.12872314]
 [ 516.96697998]
 [ 359.06594849]
 [ 374.12872314]
 [ 527.69244385]
 [ 527.69244385]
 [ 409.77334595]
 [ 351.60827637]
 [ 404.62142944]
 [ 395.18182373]
 [ 327.18392944]
 [ 518.12084961]
 [ 392.20266724]]
DEBUG:root:training time = %d0.220884
INFO:root:frame =3265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000282049179077
INFO:root:frame =3266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000416040420532
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.974286666667
DEBUG:root: dqn, choose action rondomly, need time 0.000529999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =3269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =3270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.974255
DEBUG:root: dqn, choose action rondomly, need time 0.000170999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 317.74954224]
 [ 293.40988159]
 [ 325.56082153]
 [ 419.909729  ]
 [ 301.91714478]
 [ 561.39550781]
 [ 280.99612427]
 [ 567.34765625]
 [ 477.80560303]
 [ 296.45275879]
 [ 312.08056641]
 [ 287.49743652]
 [ 443.22018433]
 [ 435.23956299]
 [ 439.17028809]
 [ 312.08056641]]
DEBUG:root:training time = %d0.231878
INFO:root:frame =3273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:player has been killed for 6 times 
INFO:root:frame =3274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame = 3275 State into memory, numbers recorded 82 action = 1, reward = -1
DEBUG:root: save sample needs time = 0.000561952590942
INFO:root:random_action_porb = 0.974223333333
DEBUG:root: dqn, choose action rondomly, need time 0.000585999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3276current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000363826751709
INFO:root:frame =3277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame =3278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480890274048
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:random_action_porb = 0.974191666667
DEBUG:root: dqn, choose action rondomly, need time 0.000318000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:training error  = [[ 489.05661011]
 [ 399.09597778]
 [ 401.18130493]
 [ 461.52459717]
 [ 398.00177002]
 [ 299.08477783]
 [ 457.21554565]
 [ 510.30792236]
 [ 493.74743652]
 [ 485.22268677]
 [ 515.42358398]
 [ 461.15753174]
 [ 293.08377075]
 [ 464.18365479]
 [ 476.9987793 ]
 [ 515.42358398]]
DEBUG:root:training time = %d0.219266
INFO:root:frame =3281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =3282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:random_action_porb = 0.97416
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root:frame =3285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000484943389893
INFO:root:frame =3286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.974128333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 405.2723999 ]
 [ 386.63815308]
 [ 364.64822388]
 [ 595.89447021]
 [ 417.23995972]
 [ 365.58239746]
 [ 397.21069336]
 [ 293.22592163]
 [ 396.50668335]
 [ 398.3890686 ]
 [ 365.58239746]
 [ 386.63815308]
 [ 370.9185791 ]
 [ 398.18807983]
 [ 301.27056885]
 [ 355.28475952]]
DEBUG:root:training time = %d0.230648
INFO:root:frame =3289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =3290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480890274048
DEBUG:root: save sample needs time = 0.000147819519043
INFO:root:random_action_porb = 0.974096666667
DEBUG:root: dqn, choose action rondomly, need time 0.000369000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =3293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000485181808472
INFO:root:frame =3294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.974065
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000423908233643
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 407.72122192]
 [ 696.28955078]
 [ 681.42858887]
 [ 400.61181641]
 [ 655.40875244]
 [ 440.02258301]
 [ 667.88677979]
 [ 549.67407227]
 [ 401.57748413]
 [ 344.89279175]
 [ 398.30990601]
 [ 658.78039551]
 [ 642.5423584 ]
 [ 338.11743164]
 [ 452.62145996]
 [ 439.52340698]]
DEBUG:root:training time = %d0.217817
INFO:root:frame =3297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =3298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.974033333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =3301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =3302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.974001666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 303.49832153]
 [ 308.08132935]
 [ 338.06582642]
 [ 596.2699585 ]
 [ 485.92611694]
 [ 317.83334351]
 [ 630.70446777]
 [ 430.33203125]
 [ 442.4777832 ]
 [ 308.08132935]
 [ 454.48156738]
 [ 317.64294434]
 [ 306.08447266]
 [ 321.26034546]
 [ 485.92611694]
 [ 448.4486084 ]]
DEBUG:root:training time = %d0.218466
INFO:root:frame =3305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =3306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.97397
DEBUG:root: dqn, choose action rondomly, need time 0.000326000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00036096572876
INFO:root:frame =3309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =3310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000410079956055
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:random_action_porb = 0.973938333333
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000341176986694
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 342.065979  ]
 [ 360.32537842]
 [ 534.41564941]
 [ 505.49633789]
 [ 350.46588135]
 [ 492.33392334]
 [ 511.95690918]
 [ 343.44116211]
 [ 482.36453247]
 [ 332.96115112]
 [ 356.36355591]
 [ 315.72805786]
 [ 349.19415283]
 [ 527.36303711]
 [ 464.99536133]
 [ 323.3543396 ]]
DEBUG:root:training time = %d0.207989
INFO:root:frame =3313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =3314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.000142812728882
INFO:root:random_action_porb = 0.973906666667
DEBUG:root: dqn, choose action rondomly, need time 0.000185999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root:frame =3317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =3318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.973875
DEBUG:root: dqn, choose action rondomly, need time 0.000346000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000407934188843
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 372.27868652]
 [ 617.2376709 ]
 [ 338.78778076]
 [ 633.12408447]
 [ 622.09960938]
 [ 323.37298584]
 [ 625.16174316]
 [ 340.80621338]
 [ 600.01824951]
 [ 384.01431274]
 [ 326.3024292 ]
 [ 619.15893555]
 [ 335.9828186 ]
 [ 309.33712769]
 [ 635.05444336]
 [ 382.27124023]]
DEBUG:root:training time = %d0.225621
INFO:root:frame =3321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268220901489
INFO:root:frame =3322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000312089920044
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:random_action_porb = 0.973843333333
DEBUG:root: dqn, choose action rondomly, need time 0.000543999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =3325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =3326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441789627075
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.973811666667
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 754.6529541 ]
 [ 342.78430176]
 [ 674.07330322]
 [ 740.90020752]
 [ 760.54290771]
 [ 309.21044922]
 [ 728.46453857]
 [ 668.67730713]
 [ 409.56332397]
 [ 328.59750366]
 [ 723.37164307]
 [ 743.35107422]
 [ 337.13052368]
 [ 332.92773438]
 [ 341.87973022]
 [ 786.84973145]]
DEBUG:root:training time = %d0.200706
INFO:root:frame =3329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =3330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000346899032593
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:random_action_porb = 0.97378
DEBUG:root: dqn, choose action rondomly, need time 0.000202999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =3333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000425815582275
INFO:root:frame =3334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494003295898
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:random_action_porb = 0.973748333333
DEBUG:root: dqn, choose action rondomly, need time 0.000575999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 643.61340332]
 [ 367.98919678]
 [ 626.80792236]
 [ 654.54180908]
 [ 384.90109253]
 [ 370.9185791 ]
 [ 405.39404297]
 [ 508.81304932]
 [ 659.13604736]
 [ 661.2767334 ]
 [ 386.4977417 ]
 [ 405.39404297]
 [ 548.21258545]
 [ 535.49981689]
 [ 669.57879639]
 [ 370.9185791 ]]
DEBUG:root:training time = %d0.219991
INFO:root:frame =3337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =3338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226020812988
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.973716666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =3341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000720024108887
INFO:root:frame =3342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486135482788
INFO:root:frame = 3343 State into memory, numbers recorded 83 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000550031661987
INFO:root:random_action_porb = 0.973685
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3344current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 761.37969971]
 [ 501.48770142]
 [ 621.09069824]
 [ 761.37969971]
 [ 792.96173096]
 [ 641.2588501 ]
 [ 362.73693848]
 [ 505.39480591]
 [ 589.19238281]
 [ 654.77453613]
 [ 394.02758789]
 [ 696.42156982]
 [ 798.98181152]
 [ 362.73693848]
 [ 739.44061279]
 [ 780.21063232]]
DEBUG:root:training time = %d0.209176
INFO:root:frame =3345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root:frame =3346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00091814994812
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.973653333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =3349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =3350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame = 3351 State into memory, numbers recorded 84 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:random_action_porb = 0.973621666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3352current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000327825546265
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 705.28271484]
 [ 440.93591309]
 [ 440.93591309]
 [ 510.25692749]
 [ 722.16882324]
 [ 585.42346191]
 [ 359.32507324]
 [ 369.83557129]
 [ 487.24420166]
 [ 686.29193115]
 [ 383.01385498]
 [ 626.86907959]
 [ 395.83123779]
 [ 486.87646484]
 [ 686.29193115]
 [ 369.83557129]]
DEBUG:root:training time = %d0.217143
INFO:root:frame =3353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =3354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:random_action_porb = 0.97359
DEBUG:root: dqn, choose action rondomly, need time 0.000326000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00039005279541
INFO:root:frame =3357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000368118286133
INFO:root:frame =3358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000141859054565
INFO:root:random_action_porb = 0.973558333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 526.203125  ]
 [ 624.60638428]
 [ 502.81710815]
 [ 650.92877197]
 [ 624.60638428]
 [ 400.00732422]
 [ 524.66412354]
 [ 495.60449219]
 [ 501.59020996]
 [ 528.36004639]
 [ 650.92877197]
 [ 486.47790527]
 [ 374.40975952]
 [ 592.59442139]
 [ 536.77880859]
 [ 585.22558594]]
DEBUG:root:training time = %d0.22501
INFO:root:frame =3361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =3362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000306129455566
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:random_action_porb = 0.973526666667
DEBUG:root: dqn, choose action rondomly, need time 0.000200000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:frame =3365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000540971755981
INFO:root:frame =3366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486850738525
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.973495
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 439.46325684]
 [ 457.84088135]
 [ 741.54162598]
 [ 479.29968262]
 [ 705.43023682]
 [ 732.55731201]
 [ 439.46325684]
 [ 382.22351074]
 [ 463.4593811 ]
 [ 382.22351074]
 [ 458.49932861]
 [ 479.29968262]
 [ 382.96847534]
 [ 469.29458618]
 [ 387.93658447]
 [ 667.87731934]]
DEBUG:root:training time = %d0.230899
INFO:root:frame =3369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =3370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.973463333333
DEBUG:root: dqn, choose action rondomly, need time 0.000399000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =3373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =3374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00073504447937
DEBUG:root: save sample needs time = 9.91821289062e-05
INFO:root:random_action_porb = 0.973431666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:training error  = [[ 477.88565063]
 [ 558.85894775]
 [ 914.29644775]
 [ 532.7956543 ]
 [ 739.1618042 ]
 [ 503.38388062]
 [ 789.7869873 ]
 [ 435.08297729]
 [ 483.11013794]
 [ 567.484375  ]
 [ 917.43469238]
 [ 917.43469238]
 [ 757.1986084 ]
 [ 893.60089111]
 [ 567.484375  ]
 [ 479.90518188]]
DEBUG:root:training time = %d0.222875
INFO:root:frame =3377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =3378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.9734
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =3381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000504016876221
INFO:root:frame =3382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.973368333333
DEBUG:root: dqn, choose action rondomly, need time 0.000195999999988
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 816.05004883]
 [ 681.92260742]
 [ 416.45489502]
 [ 826.23968506]
 [ 913.16918945]
 [ 440.15444946]
 [ 691.54327393]
 [ 791.2010498 ]
 [ 719.16217041]
 [ 663.12695312]
 [ 644.24536133]
 [ 834.99798584]
 [ 492.00488281]
 [ 664.4085083 ]
 [ 663.12695312]
 [ 791.2010498 ]]
DEBUG:root:training time = %d0.218564
INFO:root:frame =3385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =3386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319957733154
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:random_action_porb = 0.973336666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =3389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000556945800781
INFO:root:frame =3390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.973305
DEBUG:root: dqn, choose action rondomly, need time 0.000319999999988
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 544.9463501 ]
 [ 618.70184326]
 [ 879.41894531]
 [ 569.71691895]
 [ 599.4831543 ]
 [ 613.53875732]
 [ 822.01690674]
 [ 426.38946533]
 [ 585.91534424]
 [ 713.3682251 ]
 [ 645.79547119]
 [ 868.9666748 ]
 [ 572.67523193]
 [ 530.82373047]
 [ 674.0970459 ]
 [ 415.2923584 ]]
DEBUG:root:training time = %d0.228189
INFO:root:frame =3393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =3394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:random_action_porb = 0.973273333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =3397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000416994094849
INFO:root:frame =3398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.973241666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 526.67926025]
 [ 447.44616699]
 [ 862.09295654]
 [ 423.96929932]
 [ 423.96929932]
 [ 747.90930176]
 [ 510.30654907]
 [ 426.40335083]
 [ 561.50689697]
 [ 873.85296631]
 [ 682.21746826]
 [ 421.64501953]
 [ 648.33081055]
 [ 643.44000244]
 [ 884.64489746]
 [ 561.50689697]]
DEBUG:root:training time = %d0.217586
INFO:root:frame =3401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =3402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:random_action_porb = 0.97321
DEBUG:root: dqn, choose action rondomly, need time 0.000418999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =3405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =3406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:random_action_porb = 0.973178333333
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 732.41357422]
 [ 641.56646729]
 [ 677.62121582]
 [ 861.58410645]
 [ 715.79437256]
 [ 535.15240479]
 [ 732.41357422]
 [ 447.03182983]
 [ 467.49545288]
 [ 449.7472229 ]
 [ 698.7074585 ]
 [ 872.39398193]
 [ 954.7869873 ]
 [ 698.7074585 ]
 [ 715.79437256]
 [ 709.3895874 ]]
DEBUG:root:training time = %d0.207408
INFO:root:frame =3409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000363111495972
INFO:root:frame =3410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480890274048
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.973146666667
DEBUG:root: dqn, choose action rondomly, need time 0.000568000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =3413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =3414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:random_action_porb = 0.973115
DEBUG:root: dqn, choose action rondomly, need time 0.000289999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0003821849823
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 775.9798584 ]
 [ 767.79455566]
 [ 704.81921387]
 [ 554.76867676]
 [ 553.39086914]
 [ 462.74484253]
 [ 445.55160522]
 [ 962.89868164]
 [ 549.91021729]
 [ 737.88793945]
 [ 575.94287109]
 [ 679.19348145]
 [ 875.5949707 ]
 [ 920.74871826]
 [ 445.55160522]
 [ 767.79455566]]
DEBUG:root:training time = %d0.224188
INFO:root:frame =3417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =3418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.973083333333
DEBUG:root: dqn, choose action rondomly, need time 0.000488000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =3421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =3422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.973051666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 657.50738525]
 [ 684.66998291]
 [ 672.92016602]
 [ 693.36303711]
 [ 480.26223755]
 [ 684.66998291]
 [ 968.66876221]
 [ 623.8850708 ]
 [ 610.31524658]
 [ 612.44470215]
 [ 612.44470215]
 [ 455.206604  ]
 [ 684.66998291]
 [ 476.07943726]
 [ 671.3425293 ]
 [ 684.66998291]]
DEBUG:root:training time = %d0.225989
INFO:root:frame =3425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =3426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000261068344116
DEBUG:root: save sample needs time = 0.000126838684082
INFO:root:random_action_porb = 0.97302
DEBUG:root: dqn, choose action rondomly, need time 0.000280000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =3429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000347137451172
INFO:root:frame =3430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000498056411743
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.972988333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000356912612915
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 468.19250488]
 [ 757.28594971]
 [ 485.20925903]
 [ 477.51480103]
 [ 488.79882812]
 [ 476.17532349]
 [ 498.08328247]
 [ 556.73706055]
 [ 498.08328247]
 [ 482.76812744]
 [ 465.47589111]
 [ 496.56427002]
 [ 548.68572998]
 [ 550.90539551]
 [ 556.73706055]
 [ 467.66043091]]
DEBUG:root:training time = %d0.218272
INFO:root:frame =3433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:frame =3434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438213348389
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:random_action_porb = 0.972956666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000377893447876
INFO:root:frame =3437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =3438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:random_action_porb = 0.972925
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  846.65759277]
 [  985.18359375]
 [ 1020.06237793]
 [  754.81225586]
 [ 1023.09588623]
 [ 1035.20629883]
 [  994.88574219]
 [  500.68295288]
 [ 1006.57672119]
 [  453.60366821]
 [  844.45153809]
 [  998.56231689]
 [ 1020.06237793]
 [  694.52545166]
 [ 1033.90856934]
 [  500.68295288]]
DEBUG:root:training time = %d0.226788
INFO:root:frame =3441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000254154205322
INFO:root:frame =3442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.972893333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root:frame =3445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =3446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000595808029175
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.972861666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  949.63018799]
 [  835.81652832]
 [  855.2644043 ]
 [  707.40283203]
 [ 1034.44641113]
 [  851.24755859]
 [  490.01403809]
 [  851.24755859]
 [ 1028.45996094]
 [  876.67352295]
 [  508.69326782]
 [  792.77783203]
 [  770.70965576]
 [  470.54492188]
 [  876.03930664]
 [  649.45648193]]
DEBUG:root:training time = %d0.230978
INFO:root:frame =3449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245809555054
INFO:root:frame =3450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.97283
DEBUG:root: dqn, choose action rondomly, need time 0.000276999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =3453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =3454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.972798333333
DEBUG:root: dqn, choose action rondomly, need time 0.000203999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000155925750732
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  806.59777832]
 [  620.41247559]
 [  882.01818848]
 [  533.17895508]
 [  848.16607666]
 [  624.43249512]
 [  620.41247559]
 [ 1036.50280762]
 [  516.67285156]
 [  848.16607666]
 [  937.29632568]
 [  967.70587158]
 [  937.29632568]
 [ 1048.17614746]
 [  823.09350586]
 [  532.22949219]]
DEBUG:root:training time = %d0.202697
INFO:root:frame =3457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =3458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000354051589966
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:random_action_porb = 0.972766666667
DEBUG:root: dqn, choose action rondomly, need time 0.000170999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root:frame =3461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000565052032471
INFO:root:frame =3462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000414133071899
DEBUG:root: save sample needs time = 0.000155925750732
INFO:root:random_action_porb = 0.972735
DEBUG:root: dqn, choose action rondomly, need time 0.000329999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 735.89147949]
 [ 723.33551025]
 [ 766.52160645]
 [ 699.84857178]
 [ 782.93908691]
 [ 998.56616211]
 [ 813.98175049]
 [ 999.18731689]
 [ 692.92755127]
 [ 798.79376221]
 [ 782.93908691]
 [ 722.14916992]
 [ 590.34405518]
 [ 805.38311768]
 [ 944.35235596]
 [ 544.68133545]]
DEBUG:root:training time = %d0.218409
INFO:root:frame =3465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:frame =3466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411033630371
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.972703333333
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =3469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =3470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.972671666667
DEBUG:root: dqn, choose action rondomly, need time 0.000345999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000346899032593
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 824.5737915 ]
 [ 541.48242188]
 [ 560.9631958 ]
 [ 576.52453613]
 [ 868.18963623]
 [ 575.597229  ]
 [ 824.5737915 ]
 [ 552.15820312]
 [ 566.07775879]
 [ 614.95465088]
 [ 631.49719238]
 [ 581.03540039]
 [ 578.03057861]
 [ 631.49719238]
 [ 822.91137695]
 [ 557.38531494]]
DEBUG:root:training time = %d0.225812
INFO:root:frame =3473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000368118286133
INFO:root:frame =3474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049090385437
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.97264
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =3477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =3478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:random_action_porb = 0.972608333333
DEBUG:root: dqn, choose action rondomly, need time 0.000331000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  770.35894775]
 [  954.28729248]
 [  995.75994873]
 [  792.20568848]
 [  551.730896  ]
 [  562.2635498 ]
 [  793.83337402]
 [  969.7746582 ]
 [  957.35931396]
 [  970.43237305]
 [  721.40472412]
 [  941.2956543 ]
 [  843.1005249 ]
 [  794.96014404]
 [ 1020.24755859]
 [  720.70977783]]
DEBUG:root:training time = %d0.201907
INFO:root:frame =3481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =3482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000612020492554
INFO:root:frame = 3483 State into memory, numbers recorded 85 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000446796417236
INFO:root:random_action_porb = 0.972576666667
DEBUG:root: dqn, choose action rondomly, need time 0.000435999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3484current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000379085540771
INFO:root:frame =3485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =3486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000533103942871
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.972545
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 661.51062012]
 [ 556.87243652]
 [ 581.46502686]
 [ 701.53045654]
 [ 566.41033936]
 [ 640.33337402]
 [ 702.59619141]
 [ 591.29949951]
 [ 688.52105713]
 [ 640.33337402]
 [ 972.25286865]
 [ 643.81164551]
 [ 724.12530518]
 [ 622.93414307]
 [ 994.84912109]
 [ 696.3024292 ]]
DEBUG:root:training time = %d0.221466
INFO:root:frame =3489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =3490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000388145446777
INFO:root:frame = 3491 State into memory, numbers recorded 86 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000658988952637
INFO:root:random_action_porb = 0.972513333333
DEBUG:root: dqn, choose action rondomly, need time 0.000381000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3492current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.00037693977356
INFO:root:frame =3493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =3494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00053882598877
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.972481666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  805.56848145]
 [ 1111.63269043]
 [  852.37872314]
 [ 1256.29663086]
 [  584.36956787]
 [ 1014.73980713]
 [  788.50964355]
 [  592.7310791 ]
 [  728.4151001 ]
 [  784.02905273]
 [ 1021.14263916]
 [  769.78814697]
 [  858.19421387]
 [  803.89416504]
 [ 1050.76843262]
 [ 1225.84399414]]
DEBUG:root:training time = %d0.219477
INFO:root:frame =3497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =3498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.97245
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =3501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471115112305
INFO:root:frame =3502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.972418333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  624.49353027]
 [  673.35247803]
 [  713.13024902]
 [  860.30004883]
 [  840.66375732]
 [  911.81585693]
 [  873.65093994]
 [  708.85162354]
 [  963.81182861]
 [  611.65795898]
 [ 1066.14367676]
 [  895.11224365]
 [  624.49353027]
 [  713.13024902]
 [  669.43823242]
 [  885.40393066]]
DEBUG:root:training time = %d0.205937
INFO:root:frame =3505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =3506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame = 3507 State into memory, numbers recorded 87 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000545024871826
INFO:root:random_action_porb = 0.972386666667
DEBUG:root: dqn, choose action rondomly, need time 0.000512999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3508current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =3509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000550031661987
INFO:root:frame =3510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.972355
DEBUG:root: dqn, choose action rondomly, need time 0.000355999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1210.61645508]
 [  628.0769043 ]
 [  813.04516602]
 [  634.3102417 ]
 [ 1095.46899414]
 [  833.35327148]
 [  814.71673584]
 [  753.94384766]
 [  868.00256348]
 [  875.12548828]
 [  923.62719727]
 [ 1198.07287598]
 [  628.80371094]
 [  814.71673584]
 [ 1210.61645508]
 [  628.0769043 ]]
DEBUG:root:training time = %d0.23442
INFO:root:frame =3513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =3514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000322103500366
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.972323333333
INFO:root:dqn select action Tensor("ArgMax_12:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013953
INFO:root:action choosen by dqn [1]
INFO:root:frame =3516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =3517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:frame =3518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.972291666667
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  723.40447998]
 [  651.20751953]
 [ 1053.5123291 ]
 [ 1005.48095703]
 [  976.8371582 ]
 [  711.3059082 ]
 [  616.80255127]
 [  973.9473877 ]
 [  782.28851318]
 [ 1213.85083008]
 [ 1005.48095703]
 [  897.0982666 ]
 [ 1260.07019043]
 [  897.0982666 ]
 [  786.88226318]
 [  648.61834717]]
DEBUG:root:training time = %d0.212799
INFO:root:frame =3521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000545024871826
INFO:root:frame =3522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000379085540771
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.97226
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =3525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000430107116699
INFO:root:frame =3526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.972228333333
DEBUG:root: dqn, choose action rondomly, need time 0.000236999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  883.00457764]
 [  876.89221191]
 [  634.98986816]
 [ 1222.98205566]
 [  914.25585938]
 [ 1073.16027832]
 [  906.92364502]
 [ 1063.14245605]
 [ 1179.70910645]
 [ 1018.30480957]
 [ 1025.48486328]
 [  853.03643799]
 [ 1319.3380127 ]
 [ 1039.29699707]
 [ 1260.35400391]
 [ 1073.16027832]]
DEBUG:root:training time = %d0.223348
INFO:root:frame =3529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =3530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000313997268677
DEBUG:root: save sample needs time = 0.000152111053467
INFO:root:random_action_porb = 0.972196666667
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root:frame =3533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000618934631348
INFO:root:frame =3534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00029993057251
DEBUG:root: save sample needs time = 0.000146865844727
INFO:root:random_action_porb = 0.972165
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1092.18676758]
 [  704.44659424]
 [ 1232.4753418 ]
 [ 1048.94104004]
 [ 1089.04833984]
 [ 1062.96728516]
 [ 1119.63024902]
 [ 1184.36547852]
 [ 1176.53308105]
 [  693.62982178]
 [ 1061.20300293]
 [  801.20373535]
 [  855.74102783]
 [  856.52148438]
 [  855.74102783]
 [  662.61621094]]
DEBUG:root:training time = %d0.208393
INFO:root:frame =3537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232219696045
INFO:root:frame =3538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:random_action_porb = 0.972133333333
DEBUG:root: dqn, choose action rondomly, need time 0.000440999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000394105911255
INFO:root:frame =3541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =3542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.972101666667
DEBUG:root: dqn, choose action rondomly, need time 0.000351000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  995.97375488]
 [  995.0802002 ]
 [  885.94519043]
 [  947.24487305]
 [  903.88232422]
 [  933.40618896]
 [ 1223.66088867]
 [  933.40991211]
 [ 1231.78979492]
 [  902.71014404]
 [  905.22424316]
 [  697.14013672]
 [  912.30621338]
 [  697.14013672]
 [  929.40692139]
 [  995.97375488]]
DEBUG:root:training time = %d0.219683
INFO:root:frame =3545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =3546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame = 3547 State into memory, numbers recorded 88 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000574111938477
INFO:root:random_action_porb = 0.97207
DEBUG:root: dqn, choose action rondomly, need time 0.00029099999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3548current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =3549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000760078430176
INFO:root:frame =3550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.972038333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  994.66241455]
 [  717.90570068]
 [  676.23168945]
 [  722.03436279]
 [  804.15722656]
 [ 1130.9074707 ]
 [  718.30639648]
 [  707.32818604]
 [ 1077.81799316]
 [ 1065.24304199]
 [  995.09942627]
 [  681.53216553]
 [ 1130.9074707 ]
 [  997.93170166]
 [  713.3225708 ]
 [  739.3427124 ]]
DEBUG:root:training time = %d0.224975
INFO:root:frame =3553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:frame =3554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000258922576904
DEBUG:root: save sample needs time = 0.000179052352905
INFO:root:random_action_porb = 0.972006666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root:frame =3557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000497817993164
INFO:root:frame =3558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame = 3559 State into memory, numbers recorded 89 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000572919845581
INFO:root:random_action_porb = 0.971975
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3560current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  810.3081665 ]
 [  847.91192627]
 [  810.3081665 ]
 [  706.05932617]
 [  779.81005859]
 [ 1009.38647461]
 [  907.05603027]
 [  735.26574707]
 [ 1000.38000488]
 [ 1187.5814209 ]
 [  941.9418335 ]
 [  911.05303955]
 [ 1191.12609863]
 [  871.02978516]
 [ 1168.75805664]
 [  809.50390625]]
DEBUG:root:training time = %d0.211922
INFO:root:frame =3561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:player has been killed for 7 times 
INFO:root:frame =3562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000347852706909
INFO:root:frame = 3563 State into memory, numbers recorded 90 action = 1, reward = -1
DEBUG:root: save sample needs time = 0.000550985336304
INFO:root:random_action_porb = 0.971943333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3564current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =3565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =3566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.971911666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1010.72686768]
 [ 1051.17407227]
 [ 1039.35791016]
 [  900.41387939]
 [  671.32672119]
 [ 1339.48669434]
 [ 1345.72192383]
 [ 1026.99829102]
 [  736.94488525]
 [ 1010.72686768]
 [  935.9588623 ]
 [  707.47753906]
 [  719.19165039]
 [  748.45861816]
 [  736.15307617]
 [ 1395.14379883]]
DEBUG:root:training time = %d0.233473
INFO:root:frame =3569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =3570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame = 3571 State into memory, numbers recorded 91 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000555992126465
INFO:root:random_action_porb = 0.97188
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3572current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =3573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000595092773438
INFO:root:frame =3574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.971848333333
DEBUG:root: dqn, choose action rondomly, need time 0.000333999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1100.57165527]
 [ 1568.95581055]
 [ 1547.4263916 ]
 [ 1100.57165527]
 [ 1308.4708252 ]
 [  838.73236084]
 [ 1513.04101562]
 [ 1523.67199707]
 [ 1542.47485352]
 [ 1514.59399414]
 [ 1156.61853027]
 [  769.90332031]
 [  746.83642578]
 [  838.73236084]
 [ 1344.77270508]
 [ 1139.34680176]]
DEBUG:root:training time = %d0.230288
INFO:root:frame =3577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =3578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000410079956055
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.971816666667
DEBUG:root: dqn, choose action rondomly, need time 0.000354000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =3581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =3582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000492811203003
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.971785
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1142.46801758]
 [ 1082.52807617]
 [ 1151.75390625]
 [  879.09136963]
 [  971.50317383]
 [  733.99523926]
 [ 1500.44641113]
 [ 1159.6385498 ]
 [ 1088.64147949]
 [  798.23492432]
 [  902.32330322]
 [ 1415.92993164]
 [ 1124.52893066]
 [  864.69885254]
 [  919.76922607]
 [ 1114.70153809]]
DEBUG:root:training time = %d0.247527
INFO:root:frame =3585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =3586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00050687789917
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.971753333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =3589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =3590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.971721666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000391960144043
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  813.5760498 ]
 [ 1271.015625  ]
 [  764.83441162]
 [  800.6060791 ]
 [  941.32189941]
 [  986.82415771]
 [  842.50872803]
 [  960.65942383]
 [  805.74688721]
 [  844.1819458 ]
 [ 1413.00549316]
 [  932.60449219]
 [ 1313.13781738]
 [ 1398.47424316]
 [  932.60449219]
 [  776.33520508]]
DEBUG:root:training time = %d0.233523
INFO:root:frame =3593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:frame =3594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:random_action_porb = 0.97169
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000416994094849
INFO:root:frame =3597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =3598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.971658333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1063.36730957]
 [ 1535.07177734]
 [ 1063.36730957]
 [  922.24389648]
 [ 1573.63000488]
 [ 1119.75683594]
 [  805.80230713]
 [ 1556.18786621]
 [  861.79370117]
 [  896.52069092]
 [ 1553.22290039]
 [  866.3939209 ]
 [  861.56079102]
 [ 1543.90380859]
 [  953.29956055]
 [ 1633.4888916 ]]
DEBUG:root:training time = %d0.240289
INFO:root:frame =3601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =3602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000351190567017
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.971626666667
DEBUG:root: dqn, choose action rondomly, need time 0.000399999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =3605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =3606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.971595
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  799.43560791]
 [ 1613.66186523]
 [  794.80700684]
 [ 1752.86132812]
 [ 1203.64611816]
 [ 1428.40075684]
 [ 1048.12878418]
 [ 1523.27648926]
 [ 1613.66186523]
 [ 1752.86132812]
 [ 1432.13098145]
 [  839.45373535]
 [ 1380.20593262]
 [ 1432.13098145]
 [ 1432.13098145]
 [ 1451.0826416 ]]
DEBUG:root:training time = %d0.219398
INFO:root:frame =3609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =3610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000358104705811
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root:random_action_porb = 0.971563333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =3613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000492095947266
INFO:root:frame =3614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000521898269653
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.971531666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330209732056
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1008.95025635]
 [ 1392.49145508]
 [ 1312.15161133]
 [ 1290.0916748 ]
 [ 1514.1427002 ]
 [ 1390.97033691]
 [ 1575.55310059]
 [ 1057.19836426]
 [  845.47344971]
 [ 1011.17321777]
 [ 1011.17321777]
 [ 1392.49145508]
 [ 1543.07897949]
 [ 1374.3347168 ]
 [ 1390.97033691]
 [ 1418.09423828]]
DEBUG:root:training time = %d0.219094
INFO:root:frame =3617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =3618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000392913818359
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:random_action_porb = 0.9715
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =3621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000507116317749
INFO:root:frame =3622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.971468333333
DEBUG:root: dqn, choose action rondomly, need time 0.000324000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1643.29187012]
 [ 1283.03356934]
 [ 1180.0592041 ]
 [  901.72570801]
 [ 1143.52868652]
 [ 1524.54882812]
 [ 1216.49121094]
 [ 1159.35595703]
 [ 1155.18249512]
 [ 1230.80029297]
 [ 1180.0592041 ]
 [ 1151.48876953]
 [ 1341.59631348]
 [ 1632.49243164]
 [ 1545.71740723]
 [  895.14691162]]
DEBUG:root:training time = %d0.235167
INFO:root:frame =3625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =3626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:random_action_porb = 0.971436666667
DEBUG:root: dqn, choose action rondomly, need time 0.000356999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =3629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =3630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.971405
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  983.15777588]
 [ 1380.89086914]
 [  859.49462891]
 [  817.50830078]
 [  945.86657715]
 [  979.80383301]
 [  948.68060303]
 [  944.60552979]
 [ 1177.72888184]
 [  855.27331543]
 [  919.0289917 ]
 [  863.64379883]
 [ 1025.33251953]
 [ 1284.25817871]
 [  979.80383301]
 [  875.23016357]]
DEBUG:root:training time = %d0.223047
INFO:root:frame =3633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =3634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308036804199
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.971373333333
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =3637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =3638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000574827194214
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.971341666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1101.44262695]
 [  990.55114746]
 [ 1008.31054688]
 [ 1621.34509277]
 [  935.54064941]
 [  952.24450684]
 [  935.85430908]
 [ 1282.93737793]
 [  983.44866943]
 [ 1345.32336426]
 [  989.59088135]
 [  926.41168213]
 [ 1706.81848145]
 [ 1008.45013428]
 [ 1635.29504395]
 [ 1296.33837891]]
DEBUG:root:training time = %d0.214694
INFO:root:frame =3641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000380992889404
INFO:root:frame =3642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000428915023804
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.97131
DEBUG:root: dqn, choose action rondomly, need time 0.000323999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =3645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =3646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491142272949
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.971278333333
DEBUG:root: dqn, choose action rondomly, need time 0.000564999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1625.72265625]
 [ 1455.47558594]
 [  954.03839111]
 [ 1325.58837891]
 [ 1559.45935059]
 [ 1740.63745117]
 [ 1317.05114746]
 [ 1658.44909668]
 [ 1073.81420898]
 [ 1378.45141602]
 [  937.21411133]
 [ 1563.34716797]
 [ 1564.3704834 ]
 [  913.36468506]
 [ 1469.92492676]
 [ 1081.83337402]]
DEBUG:root:training time = %d0.230405
INFO:root:frame =3649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =3650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000658988952637
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.971246666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000353813171387
INFO:root:frame =3653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471830368042
INFO:root:frame =3654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000507116317749
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.971215
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1788.06030273]
 [ 1844.59863281]
 [ 1202.87976074]
 [ 1455.22875977]
 [ 1186.44592285]
 [ 1455.22875977]
 [ 1139.02539062]
 [ 1473.58703613]
 [ 1795.03027344]
 [ 1357.73632812]
 [ 1845.14916992]
 [ 1888.29077148]
 [  975.64337158]
 [ 1455.22875977]
 [ 1783.73730469]
 [ 1881.69775391]]
DEBUG:root:training time = %d0.219234
INFO:root:frame =3657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000347852706909
INFO:root:frame =3658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.971183333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =3661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root:frame =3662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.971151666667
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1667.49401855]
 [  994.40063477]
 [ 1661.06494141]
 [  994.40063477]
 [ 1171.59960938]
 [ 1026.45068359]
 [ 1202.03308105]
 [ 1766.92358398]
 [ 1615.0645752 ]
 [ 1235.44274902]
 [ 1017.03143311]
 [ 1092.9675293 ]
 [ 1661.06494141]
 [ 1191.89306641]
 [ 1696.10852051]
 [ 1631.43212891]]
DEBUG:root:training time = %d0.217594
INFO:root:frame =3665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =3666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:random_action_porb = 0.97112
DEBUG:root: dqn, choose action rondomly, need time 0.000314999999986
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =3669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =3670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.971088333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1079.1048584 ]
 [ 1634.18457031]
 [ 1634.18457031]
 [  999.4921875 ]
 [ 1800.81188965]
 [ 1520.390625  ]
 [ 1551.23193359]
 [ 1699.42810059]
 [ 1755.71948242]
 [ 1800.81188965]
 [ 1757.84277344]
 [ 1179.46801758]
 [ 1000.93218994]
 [ 1627.14538574]
 [ 1167.65026855]
 [ 1096.59448242]]
DEBUG:root:training time = %d0.219436
INFO:root:frame =3673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =3674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249862670898
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.971056666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =3677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =3678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488042831421
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.971025
DEBUG:root: dqn, choose action rondomly, need time 0.000448000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1942.12255859]
 [  967.0111084 ]
 [ 1575.8729248 ]
 [ 1387.14416504]
 [ 1502.55126953]
 [ 1076.28771973]
 [ 1313.96069336]
 [ 1025.47705078]
 [ 1992.78540039]
 [ 1906.36914062]
 [ 1990.80773926]
 [ 1569.79724121]
 [ 1503.32739258]
 [  995.30541992]
 [ 1868.44067383]
 [ 1938.31030273]]
DEBUG:root:training time = %d0.234812
INFO:root:frame =3681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =3682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.970993333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root:frame =3685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =3686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000561952590942
INFO:root:frame = 3687 State into memory, numbers recorded 92 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000560998916626
INFO:root:random_action_porb = 0.970961666667
DEBUG:root: dqn, choose action rondomly, need time 0.000168000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3688current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1422.671875  ]
 [ 1103.55029297]
 [ 1301.01464844]
 [ 1099.62426758]
 [ 1543.1796875 ]
 [ 1045.55358887]
 [ 1276.83215332]
 [ 1340.57263184]
 [ 1099.62426758]
 [ 1088.8026123 ]
 [ 1295.859375  ]
 [ 1606.76989746]
 [ 1022.76599121]
 [ 1071.93493652]
 [ 1450.48754883]
 [ 1183.37011719]]
DEBUG:root:training time = %d0.218816
INFO:root:frame =3689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =3690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247955322266
DEBUG:root: save sample needs time = 0.000121831893921
INFO:root:random_action_porb = 0.97093
DEBUG:root: dqn, choose action rondomly, need time 0.000191000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000175952911377
INFO:root:frame =3693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =3694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.970898333333
DEBUG:root: dqn, choose action rondomly, need time 0.000318000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1327.04211426]
 [ 1723.04541016]
 [ 1169.91223145]
 [ 1274.32092285]
 [ 1298.94165039]
 [ 1723.04541016]
 [ 1105.4407959 ]
 [ 1227.88134766]
 [ 1158.39599609]
 [ 1152.76501465]
 [ 1047.2911377 ]
 [ 1098.57617188]
 [ 1092.84643555]
 [ 1674.56494141]
 [ 1318.8104248 ]
 [ 1557.55102539]]
DEBUG:root:training time = %d0.206291
INFO:root:frame =3697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =3698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.970866666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =3701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =3702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000312089920044
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.970835
INFO:root:dqn select action Tensor("ArgMax_13:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00819999999999
INFO:root:action choosen by dqn [4]
INFO:root:frame =3704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:training error  = [[ 1808.39331055]
 [ 1369.52844238]
 [ 1539.91101074]
 [ 1565.18652344]
 [ 1080.69335938]
 [ 1155.38586426]
 [ 1121.35461426]
 [ 1515.10717773]
 [ 1247.8392334 ]
 [ 1635.25561523]
 [ 1174.26269531]
 [ 1115.06433105]
 [ 1126.80603027]
 [ 1291.03015137]
 [ 1576.37695312]
 [ 1126.80603027]]
DEBUG:root:training time = %d0.224549
INFO:root:frame =3705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =3706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000259876251221
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.970803333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =3709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00044584274292
INFO:root:frame =3710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.970771666667
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1343.13037109]
 [ 1410.00622559]
 [ 1468.83459473]
 [ 1410.00158691]
 [ 1478.07495117]
 [ 1449.52062988]
 [ 1410.00622559]
 [ 1501.02331543]
 [ 1716.71240234]
 [ 1501.02331543]
 [ 1440.29602051]
 [ 1405.00061035]
 [ 1634.7175293 ]
 [ 1410.00158691]
 [ 1100.58789062]
 [ 1161.38513184]]
DEBUG:root:training time = %d0.228173
INFO:root:frame =3713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =3714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:random_action_porb = 0.97074
DEBUG:root: dqn, choose action rondomly, need time 0.000184000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =3717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame =3718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427007675171
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.970708333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000382900238037
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1187.3963623 ]
 [ 2062.61450195]
 [ 1275.70703125]
 [ 1180.2689209 ]
 [ 1875.07397461]
 [ 1203.58679199]
 [ 1210.22363281]
 [ 1460.46289062]
 [ 1175.0994873 ]
 [ 1275.70703125]
 [ 1238.54675293]
 [ 2018.7755127 ]
 [ 1354.93103027]
 [ 1170.30053711]
 [ 2018.7755127 ]
 [ 1290.55651855]]
DEBUG:root:training time = %d0.21596
INFO:root:frame =3721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =3722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.970676666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =3725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =3726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.970645
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1538.96740723]
 [ 1930.64868164]
 [ 1682.70214844]
 [ 1485.55578613]
 [ 1134.46520996]
 [ 1719.18139648]
 [ 1683.53845215]
 [ 1200.61999512]
 [ 1690.88916016]
 [ 1142.09680176]
 [ 1645.37084961]
 [ 1640.59606934]
 [ 1918.70092773]
 [ 1177.01257324]
 [ 1950.74475098]
 [ 1441.06982422]]
DEBUG:root:training time = %d0.228532
INFO:root:frame =3729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237226486206
INFO:root:frame =3730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000416040420532
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.970613333333
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =3733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =3734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame = 3735 State into memory, numbers recorded 93 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000586032867432
INFO:root:random_action_porb = 0.970581666667
DEBUG:root: dqn, choose action rondomly, need time 0.000337000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3736current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1987.70446777]
 [ 2048.33032227]
 [ 1255.47900391]
 [ 1418.25976562]
 [ 1481.4934082 ]
 [ 1466.18786621]
 [ 1255.47900391]
 [ 2046.54626465]
 [ 1481.4934082 ]
 [ 1703.15905762]
 [ 1433.64196777]
 [ 1947.12878418]
 [ 1790.29089355]
 [ 1694.56542969]
 [ 1947.12878418]
 [ 1465.56628418]]
DEBUG:root:training time = %d0.227319
INFO:root:frame =3737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =3738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame = 3739 State into memory, numbers recorded 94 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000602960586548
INFO:root:random_action_porb = 0.97055
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3740current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =3741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =3742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.970518333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000406980514526
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1298.36975098]
 [ 1318.74841309]
 [ 1414.59362793]
 [ 1308.84606934]
 [ 1266.03747559]
 [ 1825.31921387]
 [ 2160.43408203]
 [ 1296.37353516]
 [ 1789.33032227]
 [ 1791.43762207]
 [ 1414.40539551]
 [ 1318.74841309]
 [ 1283.79016113]
 [ 1130.32458496]
 [ 2068.37304688]
 [ 1704.06103516]]
DEBUG:root:training time = %d0.222166
INFO:root:frame =3745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =3746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:random_action_porb = 0.970486666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root:frame =3749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000537157058716
INFO:root:frame =3750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:random_action_porb = 0.970455
DEBUG:root: dqn, choose action rondomly, need time 0.000522000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1208.21582031]
 [ 1780.9440918 ]
 [ 1960.4777832 ]
 [ 1882.99523926]
 [ 1917.45532227]
 [ 1235.52856445]
 [ 1334.02832031]
 [ 1446.23669434]
 [ 2078.80126953]
 [ 1286.49450684]
 [ 1587.71411133]
 [ 2062.17651367]
 [ 1901.26123047]
 [ 1578.14648438]
 [ 1855.40930176]
 [ 1563.02380371]]
DEBUG:root:training time = %d0.225205
INFO:root:frame =3753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:frame =3754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:random_action_porb = 0.970423333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000385046005249
INFO:root:frame =3757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000422954559326
INFO:root:frame =3758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root:frame = 3759 State into memory, numbers recorded 95 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000534057617188
INFO:root:random_action_porb = 0.970391666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3760current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1856.30859375]
 [ 1878.40551758]
 [ 1350.7598877 ]
 [ 1324.02880859]
 [ 1868.03967285]
 [ 1877.1730957 ]
 [ 1315.18664551]
 [ 1350.7598877 ]
 [ 2297.84594727]
 [ 2244.55249023]
 [ 1244.65026855]
 [ 2346.84179688]
 [ 1314.65991211]
 [ 1878.40551758]
 [ 1331.51489258]
 [ 1299.08679199]]
DEBUG:root:training time = %d0.233551
INFO:root:frame =3761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:frame =3762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000516176223755
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.97036
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =3765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000571012496948
INFO:root:frame =3766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.970328333333
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1352.51013184]
 [ 1786.78552246]
 [ 1875.37524414]
 [ 1817.22888184]
 [ 1900.61730957]
 [ 1801.36108398]
 [ 1423.37646484]
 [ 1244.62451172]
 [ 1523.30029297]
 [ 1943.44067383]
 [ 1213.69140625]
 [ 1885.27905273]
 [ 1842.48120117]
 [ 1891.50134277]
 [ 1298.93286133]
 [ 1441.53796387]]
DEBUG:root:training time = %d0.209493
INFO:root:frame =3769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:frame =3770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000320911407471
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.970296666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =3773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =3774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491142272949
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.970265
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:training error  = [[ 2124.27368164]
 [ 1490.81103516]
 [ 1767.11340332]
 [ 1611.06884766]
 [ 1397.30578613]
 [ 1385.92602539]
 [ 1611.06884766]
 [ 1734.7244873 ]
 [ 1317.61816406]
 [ 2292.2902832 ]
 [ 1490.81103516]
 [ 1670.0970459 ]
 [ 2483.36523438]
 [ 1520.41918945]
 [ 1607.93945312]
 [ 1589.35375977]]
DEBUG:root:training time = %d0.241638
INFO:root:frame =3777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =3778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.970233333333
DEBUG:root: dqn, choose action rondomly, need time 0.000433000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000389099121094
INFO:root:frame =3781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =3782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.970201666667
DEBUG:root: dqn, choose action rondomly, need time 0.00029099999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000337839126587
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2244.04370117]
 [ 2331.36206055]
 [ 1621.32543945]
 [ 1588.73571777]
 [ 2742.21362305]
 [ 1637.60119629]
 [ 1631.92529297]
 [ 1685.64770508]
 [ 2855.12280273]
 [ 1627.64282227]
 [ 2739.15258789]
 [ 1545.86621094]
 [ 1609.11450195]
 [ 1637.60119629]
 [ 2742.21362305]
 [ 1518.75854492]]
DEBUG:root:training time = %d0.237331
INFO:root:frame =3785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285148620605
INFO:root:frame =3786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame = 3787 State into memory, numbers recorded 96 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000579118728638
INFO:root:random_action_porb = 0.97017
DEBUG:root: dqn, choose action rondomly, need time 0.000337000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3788current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =3789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000492095947266
INFO:root:frame =3790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:random_action_porb = 0.970138333333
DEBUG:root: dqn, choose action rondomly, need time 0.000169
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000131845474243
INFO:root:training error  = [[ 1488.28112793]
 [ 2589.38989258]
 [ 1421.87084961]
 [ 2644.27832031]
 [ 2571.24633789]
 [ 2620.45385742]
 [ 1573.93029785]
 [ 1360.8326416 ]
 [ 1396.42980957]
 [ 1450.02258301]
 [ 1361.81005859]
 [ 1432.07092285]
 [ 2597.20996094]
 [ 2121.50097656]
 [ 2597.20996094]
 [ 2182.45922852]]
DEBUG:root:training time = %d0.235901
INFO:root:frame =3793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =3794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.970106666667
DEBUG:root: dqn, choose action rondomly, need time 0.000444000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000368118286133
INFO:root:frame =3797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000809907913208
INFO:root:frame =3798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.970075
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2832.35229492]
 [ 2546.85449219]
 [ 2553.24682617]
 [ 1689.71972656]
 [ 1860.14465332]
 [ 2679.66723633]
 [ 1841.74768066]
 [ 2698.61352539]
 [ 2679.66723633]
 [ 2807.12402344]
 [ 2558.38134766]
 [ 2785.26757812]
 [ 1860.14465332]
 [ 2767.30957031]
 [ 2707.41601562]
 [ 1450.20861816]]
DEBUG:root:training time = %d0.220087
INFO:root:frame =3801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =3802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000339984893799
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:random_action_porb = 0.970043333333
DEBUG:root: dqn, choose action rondomly, need time 0.000557000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =3805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00119686126709
INFO:root:frame =3806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491857528687
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.970011666667
DEBUG:root: dqn, choose action rondomly, need time 0.000624000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:training error  = [[ 1449.48815918]
 [ 2090.27099609]
 [ 2088.35717773]
 [ 2088.35717773]
 [ 2226.13598633]
 [ 2488.94042969]
 [ 2037.41699219]
 [ 2113.67602539]
 [ 2178.16137695]
 [ 1989.78942871]
 [ 2536.01757812]
 [ 2130.96289062]
 [ 2130.47827148]
 [ 2113.88916016]
 [ 1449.48815918]
 [ 2118.80859375]]
DEBUG:root:training time = %d0.243348
INFO:root:frame =3809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:frame =3810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233888626099
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.96998
DEBUG:root: dqn, choose action rondomly, need time 0.000173000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000161170959473
INFO:root:frame =3813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000475883483887
INFO:root:frame =3814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.969948333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1769.1973877 ]
 [ 1641.70874023]
 [ 1755.6427002 ]
 [ 1529.23291016]
 [ 1775.95568848]
 [ 1560.21142578]
 [ 1781.34594727]
 [ 1765.54870605]
 [ 1501.95507812]
 [ 1728.19238281]
 [ 2594.71606445]
 [ 1536.64575195]
 [ 2155.82348633]
 [ 2065.38183594]
 [ 1728.19238281]
 [ 2608.18310547]]
DEBUG:root:training time = %d0.216164
INFO:root:frame =3817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:frame =3818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000253915786743
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.969916666667
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =3821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000565052032471
INFO:root:frame =3822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000632047653198
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.969885
DEBUG:root: dqn, choose action rondomly, need time 0.000311999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:training error  = [[ 1749.35717773]
 [ 2460.44213867]
 [ 1603.47351074]
 [ 1763.5847168 ]
 [ 1745.98913574]
 [ 2189.82763672]
 [ 2267.12915039]
 [ 2811.13549805]
 [ 2677.87304688]
 [ 1802.89489746]
 [ 1637.73950195]
 [ 1781.67053223]
 [ 1953.92163086]
 [ 1763.5847168 ]
 [ 2315.43994141]
 [ 2905.1862793 ]]
DEBUG:root:training time = %d0.21621
INFO:root:frame =3825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =3826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:random_action_porb = 0.969853333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =3829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =3830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.969821666667
INFO:root:dqn select action Tensor("ArgMax_14:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010943
INFO:root:action choosen by dqn [3]
INFO:root:frame =3832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000166177749634
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1542.53234863]
 [ 1851.90380859]
 [ 1635.93688965]
 [ 2985.86474609]
 [ 2222.91186523]
 [ 2383.41088867]
 [ 1769.1307373 ]
 [ 1542.53234863]
 [ 1616.90478516]
 [ 2260.27001953]
 [ 2089.12158203]
 [ 1567.95019531]
 [ 2985.86474609]
 [ 1983.03222656]
 [ 1747.35632324]
 [ 2383.41088867]]
DEBUG:root:training time = %d0.228376
INFO:root:frame =3833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =3834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000540971755981
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.96979
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =3837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000397920608521
INFO:root:frame =3838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000548839569092
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.969758333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2080.83862305]
 [ 3179.81298828]
 [ 2065.11010742]
 [ 1586.97485352]
 [ 2202.28100586]
 [ 1671.42431641]
 [ 1711.890625  ]
 [ 3156.81567383]
 [ 3182.97338867]
 [ 2031.79528809]
 [ 2031.79528809]
 [ 1664.52941895]
 [ 1580.98461914]
 [ 2603.1171875 ]
 [ 2559.90673828]
 [ 1632.58117676]]
DEBUG:root:training time = %d0.205976
INFO:root:frame =3841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =3842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000322103500366
DEBUG:root: save sample needs time = 0.000116109848022
INFO:root:random_action_porb = 0.969726666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =3845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =3846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025486946106
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.969695
DEBUG:root: dqn, choose action rondomly, need time 0.000559999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000366926193237
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2630.59912109]
 [ 2542.66088867]
 [ 2378.12792969]
 [ 2546.76196289]
 [ 2543.3503418 ]
 [ 1744.68859863]
 [ 2723.72631836]
 [ 2324.07666016]
 [ 2535.20605469]
 [ 2548.92480469]
 [ 2199.29174805]
 [ 1959.09436035]
 [ 2236.90771484]
 [ 1687.88378906]
 [ 2378.12792969]
 [ 2131.84765625]]
DEBUG:root:training time = %d0.225908
INFO:root:frame =3849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =3850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494003295898
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.969663333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =3853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =3854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000527143478394
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.969631666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3175.48486328]
 [ 3125.6862793 ]
 [ 2493.52832031]
 [ 1697.16442871]
 [ 2082.77148438]
 [ 3187.26538086]
 [ 2645.03149414]
 [ 2217.55688477]
 [ 1695.21875   ]
 [ 2300.16967773]
 [ 1706.27380371]
 [ 2426.48242188]
 [ 2592.51513672]
 [ 2496.65649414]
 [ 2645.03149414]
 [ 2391.03320312]]
DEBUG:root:training time = %d0.207161
INFO:root:frame =3857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =3858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275850296021
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:random_action_porb = 0.9696
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =3861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491142272949
INFO:root:frame =3862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000568151473999
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.969568333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1788.42163086]
 [ 2501.28808594]
 [ 2255.76293945]
 [ 2707.20654297]
 [ 2140.32739258]
 [ 2776.0949707 ]
 [ 1687.28198242]
 [ 1762.93884277]
 [ 2620.29760742]
 [ 1795.34057617]
 [ 3103.54541016]
 [ 2847.85473633]
 [ 2486.        ]
 [ 2510.55810547]
 [ 2265.97851562]
 [ 1795.34057617]]
DEBUG:root:training time = %d0.240252
INFO:root:frame =3865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000367879867554
INFO:root:frame =3866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.969536666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =3869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =3870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.969505
DEBUG:root: dqn, choose action rondomly, need time 0.000185999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1828.84643555]
 [ 2832.99560547]
 [ 2103.75976562]
 [ 2103.28369141]
 [ 1948.59411621]
 [ 2832.99560547]
 [ 2438.8972168 ]
 [ 1841.17150879]
 [ 1899.97338867]
 [ 2103.75976562]
 [ 2441.65307617]
 [ 1829.98986816]
 [ 1948.59411621]
 [ 1815.22595215]
 [ 2364.9309082 ]
 [ 1879.96130371]]
DEBUG:root:training time = %d0.224093
INFO:root:frame =3873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =3874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:random_action_porb = 0.969473333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =3877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =3878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000602006912231
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.969441666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1756.6607666 ]
 [ 2487.515625  ]
 [ 1984.70690918]
 [ 1872.08337402]
 [ 2365.07324219]
 [ 2089.21630859]
 [ 1989.45178223]
 [ 2378.07421875]
 [ 2377.15161133]
 [ 2435.17919922]
 [ 2028.40722656]
 [ 1984.70690918]
 [ 2385.50927734]
 [ 1891.55444336]
 [ 1952.46508789]
 [ 1940.15942383]]
DEBUG:root:training time = %d0.211762
INFO:root:frame =3881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =3882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00036883354187
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.96941
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root:frame =3885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =3886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.969378333333
DEBUG:root: dqn, choose action rondomly, need time 0.000183000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000130176544189
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2632.84741211]
 [ 2060.59155273]
 [ 2016.39038086]
 [ 2402.18457031]
 [ 2534.21655273]
 [ 1836.1361084 ]
 [ 2432.87255859]
 [ 2704.77441406]
 [ 3522.69482422]
 [ 2131.18823242]
 [ 2016.39038086]
 [ 1923.52697754]
 [ 1974.96801758]
 [ 2542.04541016]
 [ 1969.64440918]
 [ 3526.42724609]]
DEBUG:root:training time = %d0.213089
INFO:root:frame =3889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =3890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.969346666667
DEBUG:root: dqn, choose action rondomly, need time 0.000323999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =3893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000508069992065
INFO:root:frame =3894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.969315
DEBUG:root: dqn, choose action rondomly, need time 0.00029099999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000399112701416
INFO:root:training error  = [[ 3165.0925293 ]
 [ 2055.3527832 ]
 [ 1932.67675781]
 [ 2931.1081543 ]
 [ 2899.80664062]
 [ 2902.48925781]
 [ 3165.0925293 ]
 [ 2894.80639648]
 [ 2931.1081543 ]
 [ 2899.80664062]
 [ 2964.89013672]
 [ 2353.68896484]
 [ 1932.67675781]
 [ 2965.9206543 ]
 [ 3165.0925293 ]
 [ 2964.87695312]]
DEBUG:root:training time = %d0.222695
INFO:root:frame =3897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:frame =3898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000587224960327
INFO:root: ememy has been killed for 6 times 
INFO:root:enemies_left [0]
INFO:root:frame = 3899 State into memory, numbers recorded 97 action = 4, reward = 1
DEBUG:root: save sample needs time = 0.000689029693604
INFO:root:random_action_porb = 0.969283333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3900current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =3901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =3902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.969251666667
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1950.69628906]
 [ 1903.86499023]
 [ 3801.74902344]
 [ 3069.45361328]
 [ 3080.26367188]
 [ 3768.77148438]
 [ 3005.78857422]
 [ 3770.86254883]
 [ 2100.9387207 ]
 [ 2197.1796875 ]
 [ 3770.86254883]
 [ 2197.1796875 ]
 [ 2109.12133789]
 [ 3463.09692383]
 [ 3801.74902344]
 [ 2802.60498047]]
DEBUG:root:training time = %d0.222981
INFO:root:frame =3905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =3906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.96922
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =3909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000451803207397
INFO:root:frame =3910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 0.000131845474243
INFO:root:random_action_porb = 0.969188333333
DEBUG:root: dqn, choose action rondomly, need time 0.000275000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 1922.39221191]
 [ 3608.56713867]
 [ 2766.14746094]
 [ 3551.81518555]
 [ 3420.84326172]
 [ 3566.11767578]
 [ 2017.61291504]
 [ 3432.34790039]
 [ 3455.83813477]
 [ 3608.56713867]
 [ 3562.26245117]
 [ 3391.78271484]
 [ 3003.05883789]
 [ 3486.95141602]
 [ 3378.02612305]
 [ 2028.6270752 ]]
DEBUG:root:training time = %d0.228428
INFO:root:frame =3913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261783599854
INFO:root:frame =3914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:random_action_porb = 0.969156666667
DEBUG:root: dqn, choose action rondomly, need time 0.000524999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame =3917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =3918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471830368042
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.969125
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2211.79492188]
 [ 2543.15332031]
 [ 2771.62011719]
 [ 2543.15332031]
 [ 2057.40649414]
 [ 2119.06713867]
 [ 2676.42651367]
 [ 2798.54174805]
 [ 2614.35864258]
 [ 2806.07641602]
 [ 2211.79492188]
 [ 2654.56396484]
 [ 2172.77514648]
 [ 2074.33984375]
 [ 2172.77514648]
 [ 2883.52099609]]
DEBUG:root:training time = %d0.227913
INFO:root:frame =3921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =3922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:random_action_porb = 0.969093333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =3925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =3926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame = 3927 State into memory, numbers recorded 98 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000566005706787
INFO:root:random_action_porb = 0.969061666667
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3928current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2049.08740234]
 [ 4181.06982422]
 [ 4056.44750977]
 [ 2713.9050293 ]
 [ 2824.39306641]
 [ 1877.15185547]
 [ 3030.66918945]
 [ 4181.06982422]
 [ 2244.0090332 ]
 [ 2115.11279297]
 [ 2106.49291992]
 [ 4106.20947266]
 [ 3137.29223633]
 [ 2939.97729492]
 [ 2984.13745117]
 [ 2895.27929688]]
DEBUG:root:training time = %d0.219455
INFO:root:frame =3929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:frame =3930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.96903
DEBUG:root: dqn, choose action rondomly, need time 0.00024599999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame =3933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000577926635742
INFO:root:frame =3934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485897064209
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.968998333333
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2150.40844727]
 [ 2524.35717773]
 [ 2998.0637207 ]
 [ 2086.91259766]
 [ 2215.00537109]
 [ 2805.84375   ]
 [ 2868.54248047]
 [ 2324.48291016]
 [ 2082.55419922]
 [ 2275.76855469]
 [ 3102.1105957 ]
 [ 2802.97998047]
 [ 2632.85986328]
 [ 2985.43115234]
 [ 2360.80688477]
 [ 2248.5390625 ]]
DEBUG:root:training time = %d0.22412
INFO:root:frame =3937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =3938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031590461731
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.968966666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =3941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000539064407349
INFO:root:frame =3942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.968935
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3423.54272461]
 [ 2593.51611328]
 [ 2227.8815918 ]
 [ 3680.92822266]
 [ 3626.44482422]
 [ 2616.21264648]
 [ 2886.07788086]
 [ 3516.68408203]
 [ 2816.44506836]
 [ 2868.22216797]
 [ 2893.64404297]
 [ 3516.68408203]
 [ 2345.07397461]
 [ 2221.70336914]
 [ 2241.5       ]
 [ 2854.27490234]]
DEBUG:root:training time = %d0.242556
INFO:root:frame =3945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =3946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000280857086182
INFO:root:frame = 3947 State into memory, numbers recorded 99 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000571966171265
INFO:root:random_action_porb = 0.968903333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3948current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =3949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =3950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame = 3951 State into memory, numbers recorded 100 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000561952590942
INFO:root:random_action_porb = 0.968871666667
DEBUG:root: dqn, choose action rondomly, need time 0.000174000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3952current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:training error  = [[ 2614.97021484]
 [ 2645.7409668 ]
 [ 2261.16381836]
 [ 2799.59448242]
 [ 2295.11987305]
 [ 2799.59448242]
 [ 2270.41430664]
 [ 3068.35791016]
 [ 2293.93286133]
 [ 2877.08081055]
 [ 2527.07495117]
 [ 2567.01416016]
 [ 2798.83886719]
 [ 2798.83886719]
 [ 2707.00317383]
 [ 2572.97363281]]
DEBUG:root:training time = %d0.219848
INFO:root:frame =3953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =3954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:random_action_porb = 0.96884
DEBUG:root: dqn, choose action rondomly, need time 0.000322999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:frame =3957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =3958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:random_action_porb = 0.968808333333
DEBUG:root: dqn, choose action rondomly, need time 0.000326000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:training error  = [[ 3021.98632812]
 [ 2929.21166992]
 [ 2892.9152832 ]
 [ 3120.37207031]
 [ 3006.49145508]
 [ 2917.82617188]
 [ 2831.73510742]
 [ 2907.97021484]
 [ 2935.09472656]
 [ 2889.65307617]
 [ 2270.86230469]
 [ 3193.45703125]
 [ 4281.57128906]
 [ 2185.12890625]
 [ 4316.203125  ]
 [ 2307.56396484]]
DEBUG:root:training time = %d0.228712
INFO:root:frame =3961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =3962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.968776666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000347852706909
INFO:root:frame =3965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =3966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.968745
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =3968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:training error  = [[ 2539.61499023]
 [ 2892.9152832 ]
 [ 2665.70776367]
 [ 2672.24121094]
 [ 3868.24169922]
 [ 3523.02099609]
 [ 2892.9152832 ]
 [ 2553.38867188]
 [ 2792.46191406]
 [ 2722.36938477]
 [ 2606.71826172]
 [ 2628.16430664]
 [ 3614.13500977]
 [ 3790.99365234]
 [ 2375.25341797]
 [ 2612.51147461]]
DEBUG:root:training time = %d0.225689
INFO:root:frame =3969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =3970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.968713333333
DEBUG:root: dqn, choose action rondomly, need time 0.000274999999988
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =3972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =3973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000511169433594
INFO:root:frame =3974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000503063201904
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.968681666667
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 4012.22192383]
 [ 4115.42919922]
 [ 2415.02294922]
 [ 3483.49951172]
 [ 3169.82617188]
 [ 2434.26367188]
 [ 3257.53613281]
 [ 4217.42578125]
 [ 2551.30419922]
 [ 2456.90112305]
 [ 3317.13134766]
 [ 2404.91943359]
 [ 2403.8840332 ]
 [ 3849.19360352]
 [ 3164.28222656]
 [ 2445.68408203]]
DEBUG:root:training time = %d0.215774
INFO:root:frame =3977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =3978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.96865
DEBUG:root: dqn, choose action rondomly, need time 0.000318000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =3981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =3982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.968618333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:training error  = [[ 3041.99658203]
 [ 2883.45532227]
 [ 2519.52026367]
 [ 2607.67822266]
 [ 2467.08911133]
 [ 2716.3984375 ]
 [ 3207.77319336]
 [ 2482.51367188]
 [ 2409.32739258]
 [ 2586.1730957 ]
 [ 3336.76879883]
 [ 2340.3828125 ]
 [ 2829.37768555]
 [ 2535.2121582 ]
 [ 2508.76611328]
 [ 2442.17797852]]
DEBUG:root:training time = %d0.21969
INFO:root:frame =3985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =3986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324964523315
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.968586666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =3988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =3989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488042831421
INFO:root:frame =3990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.968555
DEBUG:root: dqn, choose action rondomly, need time 0.000321000000014
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =3992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000419855117798
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3366.04638672]
 [ 3434.98022461]
 [ 2530.72119141]
 [ 3325.98168945]
 [ 2489.76879883]
 [ 3401.46533203]
 [ 3380.53808594]
 [ 2393.45141602]
 [ 2604.71801758]
 [ 3478.53735352]
 [ 3530.89404297]
 [ 2526.24658203]
 [ 2447.81542969]
 [ 3631.48217773]
 [ 3116.77270508]
 [ 3395.09643555]]
DEBUG:root:training time = %d0.24025
INFO:root:frame =3993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =3994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000382900238037
INFO:root:frame = 3995 State into memory, numbers recorded 101 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000607967376709
INFO:root:random_action_porb = 0.968523333333
DEBUG:root: dqn, choose action rondomly, need time 0.000327999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =3996current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =3997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =3998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241994857788
DEBUG:root: save sample needs time = 0.000203132629395
DEBUG:root:one frame running time = 0.00623
DEBUG:root:total training time = 90.369313
INFO:root:frame num = 4000 frame round: 0
INFO:root:random_action_porb = 0.968491666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2455.57641602]
 [ 2984.35742188]
 [ 4359.09423828]
 [ 2998.71875   ]
 [ 3265.07885742]
 [ 2496.35131836]
 [ 3705.72851562]
 [ 3635.97802734]
 [ 2591.46484375]
 [ 3731.6706543 ]
 [ 3785.86181641]
 [ 2966.2331543 ]
 [ 2875.48364258]
 [ 2453.81030273]
 [ 3040.47509766]
 [ 4087.98046875]]
DEBUG:root:training time = %d0.228773
INFO:root:frame =4001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =4002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.96846
INFO:root:dqn select action Tensor("ArgMax_15:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010242
INFO:root:action choosen by dqn [2]
INFO:root:frame =4004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000197887420654
INFO:root:frame =4005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:frame =4006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000229835510254
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.968428333333
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3061.59985352]
 [ 3078.45483398]
 [ 3119.23339844]
 [ 3061.59985352]
 [ 3109.49853516]
 [ 3781.55175781]
 [ 3092.26000977]
 [ 4380.78515625]
 [ 4629.08984375]
 [ 2844.61816406]
 [ 4458.51269531]
 [ 2784.77148438]
 [ 4458.51269531]
 [ 3033.59301758]
 [ 2972.7121582 ]
 [ 4301.49121094]]
DEBUG:root:training time = %d0.230845
INFO:root:frame =4009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:frame =4010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000332832336426
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:random_action_porb = 0.968396666667
DEBUG:root: dqn, choose action rondomly, need time 0.000369000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =4013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =4014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:random_action_porb = 0.968365
DEBUG:root: dqn, choose action rondomly, need time 0.000164999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000136137008667
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4139.56054688]
 [ 2796.05615234]
 [ 3621.10253906]
 [ 2839.48999023]
 [ 2644.49804688]
 [ 4605.35888672]
 [ 3723.18212891]
 [ 2980.35766602]
 [ 2866.28735352]
 [ 4139.56054688]
 [ 4699.83740234]
 [ 2964.55786133]
 [ 4400.02734375]
 [ 2747.73291016]
 [ 2684.02929688]
 [ 2669.24462891]]
DEBUG:root:training time = %d0.223942
INFO:root:frame =4017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000387907028198
INFO:root:frame =4018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000344038009644
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:random_action_porb = 0.968333333333
DEBUG:root: dqn, choose action rondomly, need time 0.000219000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:frame =4021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root:frame =4022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.968301666667
DEBUG:root: dqn, choose action rondomly, need time 0.000520000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00035285949707
INFO:root:training error  = [[ 4078.39404297]
 [ 4555.26953125]
 [ 4377.24707031]
 [ 2634.37597656]
 [ 4890.53662109]
 [ 2809.34936523]
 [ 2663.86157227]
 [ 2751.13183594]
 [ 2726.12866211]
 [ 4067.49511719]
 [ 4120.49755859]
 [ 4631.99707031]
 [ 2638.43115234]
 [ 2662.58276367]
 [ 3076.83642578]
 [ 4555.26953125]]
DEBUG:root:training time = %d0.221739
INFO:root:frame =4025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =4026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.96827
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =4029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =4030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.968238333333
INFO:root:dqn select action Tensor("ArgMax_16:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010099
INFO:root:action choosen by dqn [0]
INFO:root:frame =4032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2885.93359375]
 [ 4265.31591797]
 [ 3776.62158203]
 [ 4742.60546875]
 [ 4462.62158203]
 [ 4686.60742188]
 [ 3167.53100586]
 [ 4751.89941406]
 [ 4252.45849609]
 [ 4275.39111328]
 [ 4519.78808594]
 [ 4373.59716797]
 [ 2625.50537109]
 [ 4263.45068359]
 [ 2708.47705078]
 [ 4275.39111328]]
DEBUG:root:training time = %d0.218663
INFO:root:frame =4033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =4034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000178098678589
INFO:root:random_action_porb = 0.968206666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =4037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00046181678772
INFO:root:frame =4038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000243186950684
INFO:root:random_action_porb = 0.968175
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4711.51855469]
 [ 3358.45849609]
 [ 4497.09228516]
 [ 3353.26098633]
 [ 3288.47363281]
 [ 3088.57519531]
 [ 3093.95043945]
 [ 4498.11572266]
 [ 2768.64550781]
 [ 2961.71386719]
 [ 3694.96142578]
 [ 3369.85766602]
 [ 2768.64550781]
 [ 3052.34667969]
 [ 3378.50854492]
 [ 4713.01025391]]
DEBUG:root:training time = %d0.214415
INFO:root:frame =4041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =4042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame = 4043 State into memory, numbers recorded 102 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000715970993042
INFO:root:random_action_porb = 0.968143333333
DEBUG:root: dqn, choose action rondomly, need time 0.000261999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4044current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =4045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =4046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000538110733032
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.968111666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4696.08886719]
 [ 4528.5078125 ]
 [ 3964.80224609]
 [ 3753.89550781]
 [ 4758.64208984]
 [ 3123.95288086]
 [ 3706.59790039]
 [ 3569.88012695]
 [ 4033.1027832 ]
 [ 4609.68408203]
 [ 3799.70214844]
 [ 4753.75927734]
 [ 3649.37231445]
 [ 4213.05908203]
 [ 3136.94335938]
 [ 4234.54296875]]
DEBUG:root:training time = %d0.205199
INFO:root:frame =4049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =4050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000537157058716
DEBUG:root: save sample needs time = 0.000225782394409
INFO:root:random_action_porb = 0.96808
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =4053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =4054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:random_action_porb = 0.968048333333
DEBUG:root: dqn, choose action rondomly, need time 0.000264000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4914.45166016]
 [ 2966.49902344]
 [ 2958.85791016]
 [ 3460.27441406]
 [ 3051.84765625]
 [ 2970.25      ]
 [ 3910.40161133]
 [ 3187.03808594]
 [ 2970.62255859]
 [ 4715.59179688]
 [ 3522.66601562]
 [ 2966.49902344]
 [ 2989.66796875]
 [ 4455.64404297]
 [ 5052.68994141]
 [ 4888.18115234]]
DEBUG:root:training time = %d0.238762
INFO:root:frame =4057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =4058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303983688354
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:random_action_porb = 0.968016666667
DEBUG:root: dqn, choose action rondomly, need time 0.000230000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:frame =4061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000504016876221
INFO:root:frame =4062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.967985
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 2946.0300293 ]
 [ 4900.2734375 ]
 [ 4839.29785156]
 [ 4234.22509766]
 [ 4949.85742188]
 [ 4419.83105469]
 [ 4419.83105469]
 [ 3017.65942383]
 [ 3042.38696289]
 [ 3099.27612305]
 [ 3039.03491211]
 [ 4036.49902344]
 [ 4651.56640625]
 [ 3223.91625977]
 [ 4923.85205078]
 [ 3163.7878418 ]]
DEBUG:root:training time = %d0.225758
INFO:root:frame =4065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =4066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319004058838
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.967953333333
DEBUG:root: dqn, choose action rondomly, need time 0.000485999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:frame =4069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =4070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.967921666667
DEBUG:root: dqn, choose action rondomly, need time 0.000536999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3668.00854492]
 [ 3596.35351562]
 [ 3183.09741211]
 [ 4017.84521484]
 [ 4094.921875  ]
 [ 3814.43457031]
 [ 3850.43579102]
 [ 4765.49902344]
 [ 3100.90722656]
 [ 3850.43579102]
 [ 3141.78588867]
 [ 4763.24072266]
 [ 3142.03222656]
 [ 3986.73852539]
 [ 3650.0949707 ]
 [ 3558.44580078]]
DEBUG:root:training time = %d0.21503
INFO:root:frame =4073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame =4074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000502109527588
DEBUG:root: save sample needs time = 0.000174999237061
INFO:root:random_action_porb = 0.96789
DEBUG:root: dqn, choose action rondomly, need time 0.000561000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =4077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00049090385437
INFO:root:frame =4078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.967858333333
DEBUG:root: dqn, choose action rondomly, need time 0.000339000000011
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304222106934
INFO:root:training error  = [[ 3792.46679688]
 [ 3069.37915039]
 [ 3796.57250977]
 [ 5686.96777344]
 [ 4506.84716797]
 [ 5389.53515625]
 [ 4582.29150391]
 [ 5167.98095703]
 [ 3880.87011719]
 [ 5618.46484375]
 [ 4087.09863281]
 [ 5326.73681641]
 [ 3853.66333008]
 [ 5590.99414062]
 [ 4686.08105469]
 [ 3303.84985352]]
DEBUG:root:training time = %d0.228251
INFO:root:frame =4081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =4082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456809997559
INFO:root:frame = 4083 State into memory, numbers recorded 103 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000885963439941
INFO:root:random_action_porb = 0.967826666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4084current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000342845916748
INFO:root:frame =4085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =4086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.967795
DEBUG:root: dqn, choose action rondomly, need time 0.000296000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000419139862061
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4941.54785156]
 [ 5155.19433594]
 [ 4174.21337891]
 [ 4533.06005859]
 [ 3908.95117188]
 [ 4941.54785156]
 [ 4988.78710938]
 [ 4941.54785156]
 [ 4319.06640625]
 [ 4492.04296875]
 [ 4515.93164062]
 [ 3287.77368164]
 [ 4927.34765625]
 [ 4443.70654297]
 [ 3387.17749023]
 [ 4190.72900391]]
DEBUG:root:training time = %d0.227952
INFO:root:frame =4089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =4090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.967763333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =4093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame =4094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.967731666667
DEBUG:root: dqn, choose action rondomly, need time 0.000369000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4109.98046875]
 [ 4532.86279297]
 [ 4465.72070312]
 [ 4575.78271484]
 [ 4109.98046875]
 [ 3117.8972168 ]
 [ 3808.81225586]
 [ 3582.12182617]
 [ 2954.80883789]
 [ 3786.33520508]
 [ 3885.90600586]
 [ 4422.12011719]
 [ 4946.90380859]
 [ 3900.89599609]
 [ 3453.65698242]
 [ 3769.63330078]]
DEBUG:root:training time = %d0.221946
INFO:root:frame =4097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =4098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000311851501465
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:random_action_porb = 0.9677
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =4101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =4102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame = 4103 State into memory, numbers recorded 104 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000540971755981
INFO:root:random_action_porb = 0.967668333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4104current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4998.46582031]
 [ 5255.52441406]
 [ 3191.44995117]
 [ 3306.81152344]
 [ 4527.96582031]
 [ 4916.67675781]
 [ 5660.67041016]
 [ 5606.02783203]
 [ 4556.05224609]
 [ 5848.87011719]
 [ 4525.41992188]
 [ 5118.08203125]
 [ 5699.82617188]
 [ 4530.93994141]
 [ 5699.82617188]
 [ 4527.96582031]]
DEBUG:root:training time = %d0.221013
INFO:root:frame =4105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =4106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047492980957
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:random_action_porb = 0.967636666667
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =4109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =4110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.967605
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3381.11303711]
 [ 3969.92285156]
 [ 3547.73510742]
 [ 3458.40771484]
 [ 3633.87329102]
 [ 4067.31591797]
 [ 3360.10717773]
 [ 4092.06347656]
 [ 3668.15649414]
 [ 3768.86889648]
 [ 4067.31591797]
 [ 3673.86621094]
 [ 4158.67529297]
 [ 3316.92749023]
 [ 4655.24707031]
 [ 4375.03417969]]
DEBUG:root:training time = %d0.217454
INFO:root:frame =4113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000314235687256
INFO:root:frame =4114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:random_action_porb = 0.967573333333
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =4117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =4118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.967541666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4948.43212891]
 [ 4698.25585938]
 [ 4888.65869141]
 [ 3552.38989258]
 [ 5229.82128906]
 [ 6216.58691406]
 [ 3633.07861328]
 [ 4103.95703125]
 [ 4948.43212891]
 [ 3504.7644043 ]
 [ 4948.43212891]
 [ 4538.09130859]
 [ 3365.5012207 ]
 [ 4227.55517578]
 [ 4366.59277344]
 [ 3486.98046875]]
DEBUG:root:training time = %d0.215649
INFO:root:frame =4121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =4122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293016433716
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:random_action_porb = 0.96751
DEBUG:root: dqn, choose action rondomly, need time 0.000170000000011
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000130176544189
INFO:root:frame =4125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root:frame =4126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047492980957
DEBUG:root: save sample needs time = 9.82284545898e-05
INFO:root:random_action_porb = 0.967478333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5247.93408203]
 [ 5307.45703125]
 [ 4017.3190918 ]
 [ 3653.68017578]
 [ 4183.17773438]
 [ 4067.20703125]
 [ 5153.75732422]
 [ 4310.96777344]
 [ 3975.41650391]
 [ 3870.99047852]
 [ 5233.42382812]
 [ 5323.77929688]
 [ 4997.84423828]
 [ 3870.99047852]
 [ 5328.96435547]
 [ 4183.17773438]]
DEBUG:root:training time = %d0.219432
INFO:root:frame =4129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =4130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:random_action_porb = 0.967446666667
DEBUG:root: dqn, choose action rondomly, need time 0.000277999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =4134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:random_action_porb = 0.967415
DEBUG:root: dqn, choose action rondomly, need time 0.000191999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root:training error  = [[ 3991.16381836]
 [ 3614.38452148]
 [ 5193.33837891]
 [ 4582.27539062]
 [ 5528.26367188]
 [ 5021.15478516]
 [ 3693.02490234]
 [ 3513.60083008]
 [ 4804.89941406]
 [ 3486.40380859]
 [ 3615.64672852]
 [ 4495.34912109]
 [ 4765.63378906]
 [ 5182.11914062]
 [ 4536.82470703]
 [ 4988.75292969]]
DEBUG:root:training time = %d0.185697
INFO:root:frame =4137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:frame =4138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.967383333333
DEBUG:root: dqn, choose action rondomly, need time 0.000305000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =4141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =4142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.967351666667
DEBUG:root: dqn, choose action rondomly, need time 0.000339999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4610.99365234]
 [ 4787.97460938]
 [ 4139.42675781]
 [ 4302.8125    ]
 [ 4190.12841797]
 [ 3347.96142578]
 [ 5333.81298828]
 [ 3963.60327148]
 [ 4452.66210938]
 [ 3999.21923828]
 [ 3712.84326172]
 [ 5839.50048828]
 [ 4631.97216797]
 [ 4322.29199219]
 [ 4401.83349609]
 [ 4520.70751953]]
DEBUG:root:training time = %d0.23555
INFO:root:frame =4145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000368118286133
INFO:root:frame =4146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000404119491577
INFO:root:frame = 4147 State into memory, numbers recorded 105 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000592947006226
INFO:root:random_action_porb = 0.96732
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4148current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =4149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =4150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame = 4151 State into memory, numbers recorded 106 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000562906265259
INFO:root:random_action_porb = 0.967288333333
DEBUG:root: dqn, choose action rondomly, need time 0.000368000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4152current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3837.10083008]
 [ 4433.58935547]
 [ 6448.41162109]
 [ 4158.65966797]
 [ 4382.35253906]
 [ 4174.13476562]
 [ 4197.1953125 ]
 [ 4454.53564453]
 [ 4207.84716797]
 [ 4296.87304688]
 [ 4318.11962891]
 [ 3802.14038086]
 [ 5068.73779297]
 [ 4498.18115234]
 [ 5942.31689453]
 [ 6028.19921875]]
DEBUG:root:training time = %d0.224071
INFO:root:frame =4153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:frame =4154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.967256666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169992446899
INFO:root:frame =4157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =4158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame = 4159 State into memory, numbers recorded 107 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:random_action_porb = 0.967225
DEBUG:root: dqn, choose action rondomly, need time 0.000230999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4160current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.00062894821167
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 3916.70922852]
 [ 3720.03198242]
 [ 3869.41088867]
 [ 3916.70922852]
 [ 3907.24194336]
 [ 6611.70263672]
 [ 5609.24560547]
 [ 5127.23828125]
 [ 6193.39404297]
 [ 6611.70263672]
 [ 5985.68164062]
 [ 6419.42871094]
 [ 3870.94506836]
 [ 3888.88964844]
 [ 5623.00439453]
 [ 5815.10498047]]
DEBUG:root:training time = %d0.183475
INFO:root:frame =4161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =4162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025200843811
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.967193333333
DEBUG:root: dqn, choose action rondomly, need time 0.000184000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =4165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270128250122
INFO:root:frame =4166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000676870346069
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:random_action_porb = 0.967161666667
DEBUG:root: dqn, choose action rondomly, need time 0.000202000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4323.36767578]
 [ 5304.39794922]
 [ 5450.97070312]
 [ 4357.74023438]
 [ 3982.68530273]
 [ 5784.72412109]
 [ 5396.67089844]
 [ 5280.20800781]
 [ 5453.92724609]
 [ 5608.33154297]
 [ 5195.83691406]
 [ 5540.75976562]
 [ 4381.73876953]
 [ 5700.95068359]
 [ 3815.14331055]
 [ 5184.7734375 ]]
DEBUG:root:training time = %d0.186592
INFO:root:frame =4169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =4170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000679016113281
INFO:root:frame = 4171 State into memory, numbers recorded 108 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000573873519897
INFO:root:random_action_porb = 0.96713
DEBUG:root: dqn, choose action rondomly, need time 0.000227999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4172current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =4173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00059700012207
INFO:root:frame =4174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00040602684021
INFO:root:frame = 4175 State into memory, numbers recorded 109 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000586032867432
INFO:root:random_action_porb = 0.967098333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4176current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000367879867554
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5696.50878906]
 [ 4796.32324219]
 [ 4700.04638672]
 [ 5184.65039062]
 [ 3862.09448242]
 [ 5476.21679688]
 [ 6555.26660156]
 [ 5794.17919922]
 [ 4506.09326172]
 [ 4929.30126953]
 [ 6590.69677734]
 [ 4491.83007812]
 [ 7091.60546875]
 [ 5506.06738281]
 [ 6263.39306641]
 [ 3882.04150391]]
DEBUG:root:training time = %d0.190203
INFO:root:frame =4177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =4178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234842300415
DEBUG:root: save sample needs time = 0.0001060962677
INFO:root:random_action_porb = 0.967066666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root:frame =4181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =4182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
INFO:root:frame = 4183 State into memory, numbers recorded 110 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000571012496948
INFO:root:random_action_porb = 0.967035
DEBUG:root: dqn, choose action rondomly, need time 0.000275999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4184current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 6413.69873047]
 [ 4919.26220703]
 [ 4106.77246094]
 [ 6281.58789062]
 [ 5244.89257812]
 [ 4667.81542969]
 [ 5836.96386719]
 [ 4473.42480469]
 [ 5666.54980469]
 [ 5863.77929688]
 [ 6345.81835938]
 [ 6406.83789062]
 [ 4779.00830078]
 [ 5688.05419922]
 [ 6481.25244141]
 [ 5968.07177734]]
DEBUG:root:training time = %d0.204399
INFO:root:frame =4185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root:frame =4186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486850738525
DEBUG:root: save sample needs time = 0.000105142593384
INFO:root:random_action_porb = 0.967003333333
DEBUG:root: dqn, choose action rondomly, need time 0.000169999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000150918960571
INFO:root:frame =4189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:frame =4190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.966971666667
DEBUG:root: dqn, choose action rondomly, need time 0.000350999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00049901008606
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4502.83251953]
 [ 6818.98535156]
 [ 5055.53613281]
 [ 4211.03076172]
 [ 6252.19140625]
 [ 6101.89453125]
 [ 4457.30615234]
 [ 4479.69726562]
 [ 4364.22167969]
 [ 5125.43798828]
 [ 6818.98535156]
 [ 5325.86376953]
 [ 6252.19140625]
 [ 4916.83105469]
 [ 7197.57128906]
 [ 4316.41943359]]
DEBUG:root:training time = %d0.199536
INFO:root:frame =4193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =4194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.96694
DEBUG:root: dqn, choose action rondomly, need time 0.000917999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame =4197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491142272949
INFO:root:frame =4198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456809997559
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.966908333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5257.73681641]
 [ 4178.85205078]
 [ 6117.63818359]
 [ 5131.73193359]
 [ 6240.17089844]
 [ 4170.19238281]
 [ 5269.99414062]
 [ 5302.28222656]
 [ 5296.13330078]
 [ 6058.43310547]
 [ 4354.63037109]
 [ 6084.15234375]
 [ 5198.65283203]
 [ 5372.25292969]
 [ 5363.43457031]
 [ 6033.24267578]]
DEBUG:root:training time = %d0.217628
INFO:root:frame =4201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =4202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000101804733276
INFO:root:random_action_porb = 0.966876666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000372171401978
INFO:root:frame =4205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =4206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.966845
DEBUG:root: dqn, choose action rondomly, need time 0.000236000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 6368.86621094]
 [ 4271.97558594]
 [ 4739.66357422]
 [ 5058.17529297]
 [ 4778.14746094]
 [ 4599.94238281]
 [ 5004.68164062]
 [ 4744.47167969]
 [ 4464.17138672]
 [ 4394.14257812]
 [ 6599.49951172]
 [ 4599.94238281]
 [ 4465.31298828]
 [ 6876.15869141]
 [ 4394.14257812]
 [ 6278.39550781]]
DEBUG:root:training time = %d0.22046
INFO:root:frame =4209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491857528687
INFO:root:frame =4210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430822372437
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:random_action_porb = 0.966813333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00039005279541
INFO:root:frame =4213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =4214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.966781666667
DEBUG:root: dqn, choose action rondomly, need time 0.000377999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 6760.42480469]
 [ 4715.60839844]
 [ 6052.77148438]
 [ 4715.60839844]
 [ 6199.23632812]
 [ 4730.94433594]
 [ 4637.24072266]
 [ 6535.02099609]
 [ 6094.68798828]
 [ 6589.01220703]
 [ 4873.92138672]
 [ 4592.49414062]
 [ 5002.03955078]
 [ 6288.74951172]
 [ 6094.68798828]
 [ 4315.12011719]]
DEBUG:root:training time = %d0.222759
INFO:root:frame =4217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:frame =4218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:random_action_porb = 0.96675
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =4221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =4222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.966718333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5488.12939453]
 [ 7459.01708984]
 [ 5903.14208984]
 [ 5536.68945312]
 [ 7656.99755859]
 [ 5599.01074219]
 [ 5522.02099609]
 [ 4605.97167969]
 [ 5465.97753906]
 [ 6002.48535156]
 [ 5536.68945312]
 [ 5575.45117188]
 [ 6638.11181641]
 [ 4543.61914062]
 [ 5306.99462891]
 [ 4842.88232422]]
DEBUG:root:training time = %d0.215834
INFO:root:frame =4225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:frame =4226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.966686666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =4229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =4230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000571966171265
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.966655
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4878.64404297]
 [ 5064.4453125 ]
 [ 7512.01367188]
 [ 4878.64404297]
 [ 7387.45703125]
 [ 7373.67724609]
 [ 7271.87158203]
 [ 7148.17382812]
 [ 7077.42626953]
 [ 6915.99755859]
 [ 6993.36523438]
 [ 4710.41259766]
 [ 5269.58691406]
 [ 5042.83740234]
 [ 5337.14794922]
 [ 7343.54003906]]
DEBUG:root:training time = %d0.221348
INFO:root:frame =4233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =4234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00030517578125
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.966623333333
DEBUG:root: dqn, choose action rondomly, need time 0.000379999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =4237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000558853149414
INFO:root:frame =4238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.966591666667
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 6960.69628906]
 [ 6676.49755859]
 [ 4978.6875    ]
 [ 4915.23876953]
 [ 4561.01367188]
 [ 5282.95800781]
 [ 8342.87792969]
 [ 5102.32226562]
 [ 7002.73974609]
 [ 7119.61425781]
 [ 5062.93408203]
 [ 6466.48046875]
 [ 4891.16845703]
 [ 6988.52734375]
 [ 6918.59619141]
 [ 5043.16699219]]
DEBUG:root:training time = %d0.223503
INFO:root: ememy has been killed for 7 times 
INFO:root:enemies_left [0]
INFO:root:frame =4241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000175952911377
INFO:root:frame =4242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame = 4243 State into memory, numbers recorded 111 action = 0, reward = 1
DEBUG:root: save sample needs time = 0.000576019287109
INFO:root:random_action_porb = 0.96656
DEBUG:root: dqn, choose action rondomly, need time 0.000358000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4244current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =4245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =4246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000514984130859
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.966528333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336170196533
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4761.74121094]
 [ 4650.95019531]
 [ 7824.21435547]
 [ 7107.93896484]
 [ 7818.47119141]
 [ 6334.32958984]
 [ 4955.39013672]
 [ 6110.74658203]
 [ 6284.49072266]
 [ 8022.40332031]
 [ 6779.85009766]
 [ 7490.80517578]
 [ 8005.77148438]
 [ 7720.64257812]
 [ 4801.58300781]
 [ 4803.08886719]]
DEBUG:root:training time = %d0.220972
INFO:root:frame =4249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =4250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279903411865
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.966496666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =4253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =4254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.966465
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 4990.63232422]
 [ 6518.51220703]
 [ 7353.35546875]
 [ 6874.43798828]
 [ 6110.02148438]
 [ 6366.97607422]
 [ 5051.18017578]
 [ 6462.20117188]
 [ 6961.32763672]
 [ 5016.43310547]
 [ 4900.76904297]
 [ 6366.97607422]
 [ 6651.38623047]
 [ 5014.41015625]
 [ 4833.25390625]
 [ 6357.55126953]]
DEBUG:root:training time = %d0.224864
INFO:root:frame =4257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =4258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame = 4259 State into memory, numbers recorded 112 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:random_action_porb = 0.966433333333
DEBUG:root: dqn, choose action rondomly, need time 0.000178000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4260current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000180959701538
INFO:root:frame =4261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:frame =4262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235080718994
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.966401666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5671.16357422]
 [ 5671.16357422]
 [ 5289.95214844]
 [ 6218.49316406]
 [ 5120.40527344]
 [ 5111.63916016]
 [ 6218.49316406]
 [ 6903.73974609]
 [ 4970.43945312]
 [ 5996.92578125]
 [ 6896.90527344]
 [ 6888.41259766]
 [ 5425.13525391]
 [ 5353.71240234]
 [ 5362.59423828]
 [ 6315.4375    ]]
DEBUG:root:training time = %d0.232632
INFO:root:frame =4265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root:frame =4266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.96637
DEBUG:root: dqn, choose action rondomly, need time 0.000562000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root:frame =4269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000607967376709
INFO:root:frame =4270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472784042358
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.966338333333
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5425.94433594]
 [ 6924.22265625]
 [ 5921.06933594]
 [ 4953.19042969]
 [ 6188.38037109]
 [ 6924.40527344]
 [ 5218.95117188]
 [ 6499.60351562]
 [ 6041.38037109]
 [ 5831.83544922]
 [ 6241.23144531]
 [ 5298.88720703]
 [ 5100.16015625]
 [ 5332.99316406]
 [ 5063.62890625]
 [ 6884.46191406]]
DEBUG:root:training time = %d0.213355
INFO:root:frame =4273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =4274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000372886657715
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.966306666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =4277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =4278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000267028808594
INFO:root:random_action_porb = 0.966275
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 6654.05419922]
 [ 5774.29296875]
 [ 5876.76074219]
 [ 6759.10009766]
 [ 8306.50195312]
 [ 8306.50195312]
 [ 5582.01611328]
 [ 5846.6484375 ]
 [ 5990.10253906]
 [ 7095.4296875 ]
 [ 5313.75488281]
 [ 5675.39306641]
 [ 5582.01611328]
 [ 5833.02880859]
 [ 5777.55859375]
 [ 7012.71289062]]
DEBUG:root:training time = %d0.2399
INFO:root:frame =4281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =4282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000402927398682
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.966243333333
INFO:root:dqn select action Tensor("ArgMax_17:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015727
INFO:root:action choosen by dqn [4]
INFO:root:frame =4284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root:frame =4285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:frame =4286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000394821166992
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.966211666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5179.95800781]
 [ 5342.30371094]
 [ 6045.82177734]
 [ 5729.33691406]
 [ 6047.43554688]
 [ 8680.90722656]
 [ 7442.453125  ]
 [ 5159.20947266]
 [ 6244.91601562]
 [ 8232.68261719]
 [ 5342.30371094]
 [ 5496.43408203]
 [ 6355.81884766]
 [ 5353.37304688]
 [ 7442.453125  ]
 [ 7710.60644531]]
DEBUG:root:training time = %d0.22763
INFO:root:frame =4289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =4290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.96618
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =4294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:random_action_porb = 0.966148333333
DEBUG:root: dqn, choose action rondomly, need time 0.000337999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000315189361572
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 7885.96875   ]
 [ 6677.71484375]
 [ 7233.57324219]
 [ 6918.02783203]
 [ 5252.48046875]
 [ 7163.29150391]
 [ 6969.04980469]
 [ 6510.84716797]
 [ 7084.63720703]
 [ 7192.14550781]
 [ 8259.61914062]
 [ 8137.48486328]
 [ 5145.43505859]
 [ 7418.14648438]
 [ 8245.75683594]
 [ 6403.49658203]]
DEBUG:root:training time = %d0.220644
INFO:root:frame =4297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =4298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000261068344116
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:random_action_porb = 0.966116666667
DEBUG:root: dqn, choose action rondomly, need time 0.000336000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =4301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00068998336792
INFO:root:frame =4302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.966085
DEBUG:root: dqn, choose action rondomly, need time 0.000327999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 9497.9921875 ]
 [ 9070.44628906]
 [ 9196.83789062]
 [ 8703.8515625 ]
 [ 6766.78955078]
 [ 6769.66162109]
 [ 6964.83154297]
 [ 5623.27880859]
 [ 5662.45214844]
 [ 5623.27880859]
 [ 6632.46386719]
 [ 6936.1328125 ]
 [ 6894.75585938]
 [ 7505.94238281]
 [ 6776.41259766]
 [ 7089.52880859]]
DEBUG:root:training time = %d0.232868
INFO:root:frame =4305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:frame =4306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000530004501343
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.966053333333
DEBUG:root: dqn, choose action rondomly, need time 0.000169999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000152111053467
INFO:root:frame =4309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =4310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.966021666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5881.90869141]
 [ 5917.23779297]
 [ 5449.88916016]
 [ 5877.84619141]
 [ 5999.93212891]
 [ 5708.54785156]
 [ 8610.44433594]
 [ 5790.53759766]
 [ 5575.83398438]
 [ 7084.16455078]
 [ 5999.93212891]
 [ 5762.42578125]
 [ 7851.40478516]
 [ 7348.93896484]
 [ 8543.1796875 ]
 [ 5696.47216797]]
DEBUG:root:training time = %d0.213339
INFO:root:frame =4313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =4314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
DEBUG:root: save sample needs time = 0.000111818313599
INFO:root:random_action_porb = 0.96599
DEBUG:root: dqn, choose action rondomly, need time 0.00036200000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =4317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000497817993164
INFO:root:frame =4318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482082366943
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.965958333333
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:training error  = [[ 6893.92480469]
 [ 8261.28320312]
 [ 7522.87304688]
 [ 8008.89550781]
 [ 8093.32177734]
 [ 7073.56542969]
 [ 8224.77636719]
 [ 7296.47949219]
 [ 7334.79736328]
 [ 7400.34667969]
 [ 7304.19775391]
 [ 7966.91357422]
 [ 6384.15039062]
 [ 7657.25390625]
 [ 7303.82226562]
 [ 5975.08984375]]
DEBUG:root:training time = %d0.241428
INFO:root:frame =4321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:frame =4322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000525951385498
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.965926666667
DEBUG:root: dqn, choose action rondomly, need time 0.000240000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =4325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =4326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000325918197632
DEBUG:root: save sample needs time = 0.000209808349609
INFO:root:random_action_porb = 0.965895
DEBUG:root: dqn, choose action rondomly, need time 0.000548000000009
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 6898.22314453]
 [ 6428.3515625 ]
 [ 9110.90332031]
 [ 9619.62988281]
 [ 6806.45166016]
 [ 5730.68603516]
 [ 6565.37109375]
 [ 6593.64990234]
 [ 7561.78027344]
 [ 7553.56640625]
 [ 7839.46826172]
 [ 6855.26171875]
 [ 7378.45751953]
 [ 6054.84228516]
 [ 5948.30322266]
 [ 7729.76220703]]
DEBUG:root:training time = %d0.216605
INFO:root:frame =4329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:frame =4330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000391006469727
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.965863333333
DEBUG:root: dqn, choose action rondomly, need time 0.000168000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =4333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =4334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.965831666667
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 5837.59814453]
 [ 6127.6484375 ]
 [ 6136.42333984]
 [ 6261.67382812]
 [ 6251.12988281]
 [ 9879.9765625 ]
 [ 6013.65039062]
 [ 9879.9765625 ]
 [ 5982.22558594]
 [ 9252.52832031]
 [ 8764.31445312]
 [ 5815.12353516]
 [ 6603.98291016]
 [ 6127.6484375 ]
 [ 6173.7734375 ]
 [ 8068.96044922]]
DEBUG:root:training time = %d0.223586
INFO:root:frame =4337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame =4338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269174575806
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:random_action_porb = 0.9658
DEBUG:root: dqn, choose action rondomly, need time 0.000399999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00107288360596
INFO:root:frame =4341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440835952759
INFO:root:frame =4342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.965768333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6199.62060547]
 [ 11425.13574219]
 [  8827.28125   ]
 [  5906.91308594]
 [  6044.62597656]
 [  5930.50390625]
 [  9492.63867188]
 [  6540.29199219]
 [ 10202.43066406]
 [  9457.75292969]
 [  6559.69482422]
 [  6166.71630859]
 [  5930.50390625]
 [  8976.15136719]
 [  6707.15429688]
 [  8906.13378906]]
DEBUG:root:training time = %d0.208641
INFO:root:frame =4345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =4346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293016433716
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.965736666667
DEBUG:root: dqn, choose action rondomly, need time 0.000311999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =4350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000524044036865
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.965705
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:training error  = [[  6210.71728516]
 [  9390.11132812]
 [  9223.85351562]
 [ 10286.84277344]
 [  9305.25390625]
 [  9608.11523438]
 [  9036.15917969]
 [ 10588.08886719]
 [  6232.51660156]
 [  6299.05371094]
 [ 10482.11523438]
 [  8104.26318359]
 [ 10732.12011719]
 [  9290.63476562]
 [  9290.63476562]
 [  6244.14404297]]
DEBUG:root:training time = %d0.218556
INFO:root:frame =4353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000342845916748
INFO:root:frame =4354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000266075134277
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.965673333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =4357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00059986114502
INFO:root:frame =4358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:random_action_porb = 0.965641666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 8906.54882812]
 [ 6490.8671875 ]
 [ 9088.84765625]
 [ 8244.84863281]
 [ 6459.00244141]
 [ 6659.29296875]
 [ 8114.11279297]
 [ 8106.37353516]
 [ 8655.35839844]
 [ 7690.83203125]
 [ 6709.97363281]
 [ 9203.81640625]
 [ 8238.06640625]
 [ 7831.92578125]
 [ 7891.93212891]
 [ 8791.76367188]]
DEBUG:root:training time = %d0.229276
INFO:root:frame =4361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =4362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000317096710205
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:random_action_porb = 0.96561
DEBUG:root: dqn, choose action rondomly, need time 0.00072999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =4365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =4366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:random_action_porb = 0.965578333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10892.81542969]
 [  8742.66113281]
 [  9124.21386719]
 [  8967.01757812]
 [ 10992.54492188]
 [  6713.79394531]
 [ 10992.54492188]
 [ 10892.81542969]
 [  6426.76611328]
 [  7668.23876953]
 [  6320.15283203]
 [  6437.16308594]
 [  8980.01464844]
 [  8647.11523438]
 [  7742.7109375 ]
 [  8918.07226562]]
DEBUG:root:training time = %d0.217866
INFO:root:frame =4369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:frame =4370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000395059585571
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:random_action_porb = 0.965546666667
DEBUG:root: dqn, choose action rondomly, need time 0.000356000000011
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =4373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =4374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000360012054443
INFO:root:frame = 4375 State into memory, numbers recorded 113 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root:random_action_porb = 0.965515
DEBUG:root: dqn, choose action rondomly, need time 0.000180999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4376current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 9628.22851562]
 [ 6854.55419922]
 [ 6580.90917969]
 [ 8998.41699219]
 [ 6772.63476562]
 [ 7197.36425781]
 [ 9689.50878906]
 [ 7672.0234375 ]
 [ 7137.54785156]
 [ 9362.26367188]
 [ 8998.41699219]
 [ 8998.41699219]
 [ 9298.96679688]
 [ 9318.47070312]
 [ 8998.41699219]
 [ 8790.64160156]]
DEBUG:root:training time = %d0.238989
INFO:root:frame =4377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =4378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000540018081665
INFO:root:frame = 4379 State into memory, numbers recorded 114 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000693082809448
INFO:root:random_action_porb = 0.965483333333
DEBUG:root: dqn, choose action rondomly, need time 0.000358999999989
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4380current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =4381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =4382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.965451666667
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10428.91699219]
 [  7037.57568359]
 [ 11063.30566406]
 [  9507.29785156]
 [  7182.83154297]
 [ 10519.29199219]
 [ 11055.19238281]
 [ 10575.93261719]
 [  6984.52783203]
 [  8728.69628906]
 [  6078.15527344]
 [ 11100.34082031]
 [  6870.39013672]
 [ 11668.82617188]
 [  6674.30371094]
 [  6856.71728516]]
DEBUG:root:training time = %d0.202795
INFO:root:frame =4385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =4386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame = 4387 State into memory, numbers recorded 115 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000566005706787
INFO:root:random_action_porb = 0.96542
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4388current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =4389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000540971755981
INFO:root:frame =4390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.965388333333
DEBUG:root: dqn, choose action rondomly, need time 0.000379999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:training error  = [[ 7569.97705078]
 [ 6945.75341797]
 [ 8554.01464844]
 [ 8808.20703125]
 [ 9265.68359375]
 [ 7081.53466797]
 [ 8968.79785156]
 [ 8957.98046875]
 [ 7286.59814453]
 [ 7454.6953125 ]
 [ 7012.61083984]
 [ 6780.71435547]
 [ 8878.85253906]
 [ 7519.54882812]
 [ 6728.18457031]
 [ 9252.64550781]]
DEBUG:root:training time = %d0.208553
INFO:root:frame =4393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271797180176
INFO:root:frame =4394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000658988952637
INFO:root:frame = 4395 State into memory, numbers recorded 116 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000602006912231
INFO:root:random_action_porb = 0.965356666667
DEBUG:root: dqn, choose action rondomly, need time 0.000227999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4396current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =4397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =4398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509023666382
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:random_action_porb = 0.965325
DEBUG:root: dqn, choose action rondomly, need time 0.000181999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8550.78613281]
 [  7568.63916016]
 [ 10967.06445312]
 [  7288.30712891]
 [  8629.66601562]
 [  8220.96875   ]
 [  8430.34179688]
 [  8343.83691406]
 [  7256.36962891]
 [  7119.53222656]
 [  8172.20849609]
 [  8389.70605469]
 [  8121.96533203]
 [  8323.51074219]
 [  7240.51025391]
 [  7664.00634766]]
DEBUG:root:training time = %d0.228034
INFO:root:frame =4401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =4402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame = 4403 State into memory, numbers recorded 117 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000567197799683
INFO:root:random_action_porb = 0.965293333333
DEBUG:root: dqn, choose action rondomly, need time 0.00028300000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4404current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =4405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =4406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000198841094971
INFO:root:random_action_porb = 0.965261666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000356912612915
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  6586.79248047]
 [  8467.27929688]
 [ 11008.08789062]
 [ 11065.33496094]
 [  8280.        ]
 [  6849.36083984]
 [  6735.27587891]
 [  8512.33691406]
 [ 11051.95898438]
 [  6735.27587891]
 [  8434.93847656]
 [ 11473.43847656]
 [  8382.39453125]
 [  7234.67382812]
 [  8340.1796875 ]
 [ 10678.56835938]]
DEBUG:root:training time = %d0.235358
INFO:root:frame =4409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root:frame =4410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.96523
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =4413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000663995742798
INFO:root:frame =4414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000576972961426
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.965198333333
DEBUG:root: dqn, choose action rondomly, need time 0.000281000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10815.54296875]
 [ 10774.50097656]
 [  7604.55517578]
 [  7473.95263672]
 [ 11861.68847656]
 [  7361.22949219]
 [  7509.30566406]
 [ 11427.82421875]
 [  7351.32519531]
 [ 11289.37402344]
 [ 11118.22460938]
 [  8081.22412109]
 [ 11661.046875  ]
 [  7762.70263672]
 [ 10518.41503906]
 [  7731.50097656]]
DEBUG:root:training time = %d0.2238
INFO:root:frame =4417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =4418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.965166666667
DEBUG:root: dqn, choose action rondomly, need time 0.000553999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =4421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488996505737
INFO:root:frame =4422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.965135
DEBUG:root: dqn, choose action rondomly, need time 0.000253000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9481.98535156]
 [  9999.78027344]
 [ 10389.26269531]
 [ 11437.63964844]
 [  9369.94238281]
 [ 10008.37597656]
 [  7704.90478516]
 [ 11854.61621094]
 [ 10046.24511719]
 [ 10358.47851562]
 [  7157.21777344]
 [  7145.80029297]
 [ 10137.45605469]
 [  7136.04199219]
 [  9715.57714844]
 [  9526.94628906]]
DEBUG:root:training time = %d0.237792
INFO:root:frame =4425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =4426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279188156128
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:random_action_porb = 0.965103333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =4429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =4430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.965071666667
DEBUG:root: dqn, choose action rondomly, need time 0.000332999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  7817.15429688]
 [ 10463.37695312]
 [  9713.91699219]
 [  7489.55859375]
 [  7441.82128906]
 [  7931.4765625 ]
 [  7723.64599609]
 [  9921.66308594]
 [  8543.04394531]
 [ 10625.02441406]
 [  7750.25341797]
 [  7625.96679688]
 [ 10625.02441406]
 [ 10053.734375  ]
 [  9947.45703125]
 [  7441.82128906]]
DEBUG:root:training time = %d0.220428
INFO:root:frame =4433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:frame =4434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504970550537
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:random_action_porb = 0.96504
DEBUG:root: dqn, choose action rondomly, need time 0.000442000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =4437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:frame =4438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000289916992188
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:random_action_porb = 0.965008333333
DEBUG:root: dqn, choose action rondomly, need time 0.000225
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000127077102661
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10736.62304688]
 [  9280.00097656]
 [  9578.22558594]
 [  9377.57714844]
 [  9265.98925781]
 [ 11107.69824219]
 [  9161.98535156]
 [  7962.46875   ]
 [  9226.66699219]
 [  7406.39648438]
 [  9593.35644531]
 [  9265.98925781]
 [ 11107.69824219]
 [ 11122.44726562]
 [  7828.20996094]
 [  9682.25292969]]
DEBUG:root:training time = %d0.23183
INFO:root:frame =4441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229835510254
INFO:root:frame =4442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000521183013916
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.964976666667
DEBUG:root: dqn, choose action rondomly, need time 0.000513999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =4445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =4446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470876693726
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.964945
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9909.96875   ]
 [  7848.72265625]
 [ 12315.82421875]
 [ 11622.58789062]
 [  8364.20996094]
 [ 11607.08984375]
 [  8500.22363281]
 [  7899.11279297]
 [  8523.55859375]
 [  8349.36816406]
 [  7807.70263672]
 [  8100.28564453]
 [  9520.77539062]
 [  8770.12109375]
 [ 11251.765625  ]
 [ 11622.58789062]]
DEBUG:root:training time = %d0.216802
INFO:root:frame =4449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =4450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.964913333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =4453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame =4454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000355005264282
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.964881666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11733.36914062]
 [ 11013.49316406]
 [  7768.21044922]
 [ 10867.40039062]
 [  8548.79882812]
 [  8548.79882812]
 [  8468.49316406]
 [ 11026.41015625]
 [  8378.86328125]
 [ 11039.4375    ]
 [ 10982.94824219]
 [ 11387.796875  ]
 [  8027.39013672]
 [  9094.69042969]
 [  9769.09765625]
 [ 10695.65527344]]
DEBUG:root:training time = %d0.206331
INFO:root:frame =4457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =4458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.96485
DEBUG:root: dqn, choose action rondomly, need time 0.000310999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =4461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000611066818237
INFO:root:frame =4462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509023666382
DEBUG:root: save sample needs time = 0.000188827514648
INFO:root:random_action_porb = 0.964818333333
DEBUG:root: dqn, choose action rondomly, need time 0.000546999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336170196533
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10512.43164062]
 [  8412.26171875]
 [  8486.79101562]
 [  8877.33398438]
 [  8509.79199219]
 [  7823.82568359]
 [ 11090.72265625]
 [  8212.40429688]
 [  8441.28515625]
 [ 10359.2734375 ]
 [  7975.95947266]
 [ 10563.13183594]
 [  9265.04980469]
 [ 10826.28613281]
 [ 10803.94238281]
 [  8571.68066406]]
DEBUG:root:training time = %d0.226627
INFO:root:frame =4465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =4466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:random_action_porb = 0.964786666667
DEBUG:root: dqn, choose action rondomly, need time 0.000508999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000571966171265
INFO:root:frame =4469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =4470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475883483887
INFO:root:frame = 4471 State into memory, numbers recorded 118 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000746011734009
INFO:root:random_action_porb = 0.964755
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4472current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8395.09570312]
 [ 12279.05859375]
 [ 13130.77636719]
 [  8640.1015625 ]
 [ 11999.98339844]
 [ 11967.27050781]
 [  8329.19140625]
 [  8788.03222656]
 [  8378.61816406]
 [  8190.93505859]
 [ 10850.38085938]
 [  9941.75976562]
 [  8120.46923828]
 [  8378.61816406]
 [  8104.28515625]
 [ 11970.23535156]]
DEBUG:root:training time = %d0.209682
INFO:root:frame =4473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:frame =4474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025200843811
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.964723333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000341176986694
INFO:root:frame =4477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =4478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000245809555054
INFO:root:random_action_porb = 0.964691666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  8555.91113281]
 [  8595.95214844]
 [ 11925.90917969]
 [ 11925.90917969]
 [ 13517.92285156]
 [ 10592.13378906]
 [  7604.40625   ]
 [ 12506.59472656]
 [ 12162.60058594]
 [ 10491.96582031]
 [  8982.86035156]
 [  9688.35546875]
 [  8528.63085938]
 [ 13065.39453125]
 [ 11112.43359375]
 [ 11889.46386719]]
DEBUG:root:training time = %d0.22397
INFO:root:frame =4481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:frame =4482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470876693726
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.96466
DEBUG:root: dqn, choose action rondomly, need time 0.000389999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =4485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =4486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.964628333333
DEBUG:root: dqn, choose action rondomly, need time 0.000338999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 12798.14941406]
 [ 10353.45996094]
 [ 10709.7734375 ]
 [ 13861.64160156]
 [ 10898.49804688]
 [ 13193.48925781]
 [ 13183.45214844]
 [ 10736.59765625]
 [ 10477.1171875 ]
 [ 11072.01269531]
 [ 13861.64160156]
 [ 13141.68945312]
 [ 13183.45214844]
 [ 13071.53417969]
 [ 14529.10644531]
 [ 13806.62304688]]
DEBUG:root:training time = %d0.213848
INFO:root:frame =4489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame =4490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000380039215088
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.964596666667
DEBUG:root: dqn, choose action rondomly, need time 0.000360999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =4493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280141830444
INFO:root:frame =4494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000108003616333
INFO:root:random_action_porb = 0.964565
DEBUG:root: dqn, choose action rondomly, need time 0.000358000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  9828.42773438]
 [  8991.12304688]
 [ 12467.41796875]
 [  8922.66113281]
 [ 11810.61132812]
 [ 12061.57324219]
 [  8576.74511719]
 [  8721.74023438]
 [  8872.06738281]
 [ 11648.10644531]
 [ 11920.81738281]
 [ 11985.59863281]
 [ 12390.77148438]
 [ 10929.07910156]
 [  9481.34375   ]
 [ 11934.015625  ]]
DEBUG:root:training time = %d0.214015
INFO:root:frame =4497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =4498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000305891036987
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.964533333333
DEBUG:root: dqn, choose action rondomly, need time 0.000387000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000531911849976
INFO:root:frame =4501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000415086746216
INFO:root:frame =4502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000346183776855
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:random_action_porb = 0.964501666667
DEBUG:root: dqn, choose action rondomly, need time 0.000241000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13282.984375  ]
 [ 13913.74609375]
 [ 10663.15917969]
 [ 10486.21484375]
 [ 11145.19433594]
 [ 13913.74609375]
 [ 10693.53417969]
 [ 14627.1484375 ]
 [ 11258.94042969]
 [  9301.46289062]
 [ 11253.08691406]
 [ 14627.1484375 ]
 [  9173.90722656]
 [ 11031.99902344]
 [  8539.29882812]
 [ 10829.91894531]]
DEBUG:root:training time = %d0.235458
INFO:root:frame =4505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =4506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:random_action_porb = 0.96447
DEBUG:root: dqn, choose action rondomly, need time 0.000342000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =4509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464200973511
INFO:root:frame =4510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460863113403
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:random_action_porb = 0.964438333333
DEBUG:root: dqn, choose action rondomly, need time 0.000206999999989
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10616.44433594]
 [ 13321.19433594]
 [  9557.01953125]
 [  8824.96484375]
 [ 11155.22265625]
 [  9232.24902344]
 [  8824.96484375]
 [  9731.32128906]
 [ 11059.890625  ]
 [ 11932.30859375]
 [  9643.25390625]
 [ 10494.46679688]
 [ 11520.87207031]
 [  8824.96484375]
 [  8951.02636719]
 [  9275.36914062]]
DEBUG:root:training time = %d0.2317
INFO:root:frame =4513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =4514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470876693726
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.964406666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365972518921
INFO:root:frame =4517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000489950180054
INFO:root:frame =4518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.964375
DEBUG:root: dqn, choose action rondomly, need time 0.000415000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000414133071899
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 11269.90136719]
 [ 11596.30859375]
 [  9295.10644531]
 [ 11558.90136719]
 [ 11912.18261719]
 [  9312.81542969]
 [  9196.18261719]
 [ 14385.35546875]
 [ 13309.61621094]
 [  9406.06347656]
 [ 11852.19726562]
 [ 11187.55566406]
 [  9610.60449219]
 [ 11558.90136719]
 [  9610.60449219]
 [  9806.60839844]]
DEBUG:root:training time = %d0.207778
INFO:root:frame =4521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =4522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000600099563599
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.964343333333
DEBUG:root: dqn, choose action rondomly, need time 0.000167000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000178098678589
INFO:root:frame =4525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root:frame =4526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000239133834839
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:random_action_porb = 0.964311666667
DEBUG:root: dqn, choose action rondomly, need time 0.000203999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:training error  = [[ 15643.25488281]
 [ 11575.44335938]
 [ 11575.44335938]
 [ 14935.24511719]
 [ 14993.18359375]
 [ 13949.91113281]
 [ 14745.08007812]
 [ 15244.17089844]
 [ 12385.39160156]
 [ 12496.57617188]
 [  9835.23046875]
 [  9744.64453125]
 [ 15643.25488281]
 [ 11118.91992188]
 [ 14912.96484375]
 [ 15102.70605469]]
DEBUG:root:training time = %d0.195024
INFO:root:frame =4529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000331878662109
INFO:root:frame =4530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000416994094849
INFO:root:frame = 4531 State into memory, numbers recorded 119 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000869035720825
INFO:root:random_action_porb = 0.96428
DEBUG:root: dqn, choose action rondomly, need time 0.000329999999991
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4532current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =4533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000486850738525
INFO:root:frame =4534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.964248333333
DEBUG:root: dqn, choose action rondomly, need time 0.000195000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14387.43457031]
 [ 13253.84960938]
 [  8561.94140625]
 [ 11641.51953125]
 [ 14763.55566406]
 [ 15567.89257812]
 [ 13318.57421875]
 [ 11445.05566406]
 [ 11239.7265625 ]
 [  9382.21191406]
 [ 13151.85058594]
 [ 12952.64648438]
 [ 14442.30664062]
 [ 11161.92773438]
 [  9212.2734375 ]
 [ 11899.50195312]]
DEBUG:root:training time = %d0.213357
INFO:root:frame =4537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =4538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000278949737549
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:random_action_porb = 0.964216666667
DEBUG:root: dqn, choose action rondomly, need time 0.00023800000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =4541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000391006469727
INFO:root:frame =4542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000306844711304
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:random_action_porb = 0.964185
DEBUG:root: dqn, choose action rondomly, need time 0.000169000000014
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016713142395
INFO:root:training error  = [[ 12320.32226562]
 [ 11824.2265625 ]
 [ 13805.93457031]
 [ 13497.60644531]
 [ 12025.72460938]
 [ 13613.72265625]
 [ 13146.        ]
 [ 14039.44433594]
 [ 11387.35449219]
 [ 13912.39257812]
 [ 11649.21289062]
 [ 12906.75683594]
 [ 11613.71972656]
 [ 11563.546875  ]
 [ 12036.0078125 ]
 [ 13011.92480469]]
DEBUG:root:training time = %d0.211331
INFO:root:frame =4545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:frame =4546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000500917434692
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.964153333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =4549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =4550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045919418335
DEBUG:root: save sample needs time = 0.000280857086182
INFO:root:random_action_porb = 0.964121666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10395.90820312]
 [ 10616.41992188]
 [ 11445.94335938]
 [ 12295.13378906]
 [ 10839.60058594]
 [ 12217.10351562]
 [ 10301.45703125]
 [ 10301.45703125]
 [ 11320.05566406]
 [ 10464.60058594]
 [ 11290.80078125]
 [ 13988.75      ]
 [  9698.25878906]
 [ 11445.94335938]
 [ 11677.68847656]
 [ 13828.8359375 ]]
DEBUG:root:training time = %d0.213185
INFO:root:frame =4553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =4554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000348091125488
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:random_action_porb = 0.96409
DEBUG:root: dqn, choose action rondomly, need time 0.000209000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =4557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000364780426025
INFO:root:frame =4558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000284194946289
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.964058333333
DEBUG:root: dqn, choose action rondomly, need time 0.000180999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12670.81152344]
 [ 11692.49414062]
 [ 12737.34863281]
 [ 12297.00097656]
 [ 12648.91796875]
 [ 14915.61914062]
 [ 15048.47851562]
 [ 14706.65429688]
 [ 14706.65429688]
 [ 11692.49414062]
 [ 10050.13574219]
 [  9496.70703125]
 [ 12255.58691406]
 [ 14547.79882812]
 [ 10516.21191406]
 [ 13994.93066406]]
DEBUG:root:training time = %d0.2266
INFO:root:frame =4561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =4562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424146652222
INFO:root:frame = 4563 State into memory, numbers recorded 120 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000572919845581
INFO:root:random_action_porb = 0.964026666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4564current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =4565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =4566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000249147415161
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.963995
DEBUG:root: dqn, choose action rondomly, need time 0.000219000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 10214.44335938]
 [ 10506.57519531]
 [  9781.48046875]
 [ 14017.20703125]
 [ 12738.203125  ]
 [  9919.49902344]
 [ 12175.71582031]
 [ 12867.59570312]
 [ 16121.62109375]
 [  9334.83398438]
 [  9334.83398438]
 [ 12655.78320312]
 [ 12738.203125  ]
 [ 12175.71582031]
 [ 14362.34863281]
 [ 11895.37402344]]
DEBUG:root:training time = %d0.194975
INFO:root:frame =4569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =4570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000349044799805
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.963963333333
DEBUG:root: dqn, choose action rondomly, need time 0.000396999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =4573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =4574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.963931666667
DEBUG:root: dqn, choose action rondomly, need time 0.000521000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12245.91308594]
 [ 12246.96679688]
 [ 12733.65722656]
 [ 12888.73535156]
 [ 11806.84375   ]
 [ 12245.91308594]
 [ 10546.82910156]
 [ 10608.04492188]
 [ 12606.94238281]
 [ 10904.00488281]
 [ 13210.71289062]
 [ 10904.00488281]
 [ 10566.87109375]
 [ 12331.19140625]
 [ 12257.99316406]
 [ 11606.35351562]]
DEBUG:root:training time = %d0.221395
INFO:root:frame =4577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =4578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000549077987671
DEBUG:root: save sample needs time = 0.000270128250122
INFO:root:random_action_porb = 0.9639
DEBUG:root: dqn, choose action rondomly, need time 0.000591999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =4581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000474214553833
INFO:root:frame =4582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475883483887
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.963868333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17771.44140625]
 [ 16637.75585938]
 [ 11351.22167969]
 [ 16693.35351562]
 [ 12395.20214844]
 [ 16684.6484375 ]
 [ 10134.015625  ]
 [ 11629.66894531]
 [ 11755.48828125]
 [ 11871.36816406]
 [ 14254.82128906]
 [ 11315.45898438]
 [ 17067.9296875 ]
 [ 16693.35351562]
 [ 12994.55273438]
 [ 12152.72070312]]
DEBUG:root:training time = %d0.220826
INFO:root:frame =4585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000363111495972
INFO:root:frame =4586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000108003616333
INFO:root:random_action_porb = 0.963836666667
DEBUG:root: dqn, choose action rondomly, need time 0.000204999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000186204910278
INFO:root:frame =4589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =4590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447034835815
DEBUG:root: save sample needs time = 0.000129222869873
INFO:root:random_action_porb = 0.963805
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13056.13085938]
 [ 11045.41503906]
 [ 12258.83105469]
 [ 18126.5859375 ]
 [ 16515.32421875]
 [ 16232.5078125 ]
 [ 16704.8359375 ]
 [ 17094.60546875]
 [ 17251.1171875 ]
 [ 18538.29101562]
 [ 17799.76757812]
 [ 11063.76855469]
 [ 17799.76757812]
 [ 17662.93554688]
 [ 16987.234375  ]
 [ 19006.92382812]]
DEBUG:root:training time = %d0.220286
INFO:root:frame =4593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root:frame =4594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000373840332031
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root:random_action_porb = 0.963773333333
DEBUG:root: dqn, choose action rondomly, need time 0.000326000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:frame =4597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:frame =4598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000647068023682
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.963741666667
DEBUG:root: dqn, choose action rondomly, need time 0.000267000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16877.15625   ]
 [ 17536.65234375]
 [ 11364.51757812]
 [ 10746.59179688]
 [ 15633.72949219]
 [ 16877.15625   ]
 [ 11483.01171875]
 [ 14421.83398438]
 [ 14645.22460938]
 [ 14639.75976562]
 [ 11199.4375    ]
 [ 11368.47460938]
 [ 14924.59472656]
 [ 14662.95703125]
 [ 11228.21191406]
 [ 10784.38671875]]
DEBUG:root:training time = %d0.242675
INFO:root:frame =4601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =4602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
DEBUG:root: save sample needs time = 0.000120162963867
INFO:root:random_action_porb = 0.96371
DEBUG:root: dqn, choose action rondomly, need time 0.000219000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000422954559326
INFO:root:frame =4605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =4606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000199794769287
INFO:root:random_action_porb = 0.963678333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 13197.58398438]
 [ 14131.17871094]
 [ 12674.46679688]
 [ 11564.72851562]
 [ 13036.02539062]
 [ 13315.390625  ]
 [ 12130.23144531]
 [ 11784.75585938]
 [ 12979.25097656]
 [ 11160.94726562]
 [ 12306.56054688]
 [ 12314.36132812]
 [ 14055.79296875]
 [ 13440.51367188]
 [ 12844.86914062]
 [ 11932.17578125]]
DEBUG:root:training time = %d0.22134
INFO:root:frame =4609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:frame =4610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264883041382
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.963646666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =4613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450849533081
INFO:root:frame =4614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.963615
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14064.04296875]
 [ 14332.28710938]
 [ 13924.66308594]
 [ 11883.23535156]
 [ 17470.82421875]
 [ 17592.56445312]
 [ 13250.50585938]
 [ 12768.28320312]
 [ 18580.63085938]
 [ 12996.61230469]
 [ 17334.39648438]
 [ 11793.61035156]
 [ 12319.265625  ]
 [ 12981.69824219]
 [ 18376.79492188]
 [ 17581.1015625 ]]
DEBUG:root:training time = %d0.232636
INFO:root:frame =4617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:frame =4618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000302076339722
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.963583333333
DEBUG:root: dqn, choose action rondomly, need time 0.000403000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =4621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =4622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.963551666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17946.7109375 ]
 [ 17513.76953125]
 [ 12086.46875   ]
 [ 12361.57421875]
 [ 13808.71679688]
 [ 11352.44433594]
 [ 11429.67675781]
 [ 12944.17285156]
 [ 15951.14746094]
 [ 17736.04882812]
 [ 15815.08886719]
 [ 15815.08886719]
 [ 11939.88378906]
 [ 15951.14746094]
 [ 12944.17285156]
 [ 17736.04882812]]
DEBUG:root:training time = %d0.232032
INFO:root:frame =4625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271081924438
INFO:root:frame =4626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000591993331909
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.96352
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =4629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =4630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.963488333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000292778015137
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17580.51953125]
 [ 11953.91992188]
 [ 16470.80273438]
 [ 16898.4140625 ]
 [ 12100.16113281]
 [ 12730.51660156]
 [ 17341.66210938]
 [ 17345.45507812]
 [ 12186.73730469]
 [ 12319.10351562]
 [ 17036.81445312]
 [ 15973.97265625]
 [ 16470.80273438]
 [ 17207.66210938]
 [ 17738.45507812]
 [ 11986.5078125 ]]
DEBUG:root:training time = %d0.244177
INFO:root:frame =4633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =4634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000565052032471
DEBUG:root: save sample needs time = 0.000131845474243
INFO:root:random_action_porb = 0.963456666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =4637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466823577881
INFO:root:frame =4638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.963425
DEBUG:root: dqn, choose action rondomly, need time 0.000185000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14403.515625  ]
 [ 16341.09082031]
 [ 20294.5625    ]
 [ 14822.58691406]
 [ 15452.50488281]
 [ 15118.01171875]
 [ 15121.9140625 ]
 [ 19703.2890625 ]
 [ 15275.95800781]
 [ 16980.6484375 ]
 [ 12569.71582031]
 [ 18791.95117188]
 [ 18669.99414062]
 [ 17613.23046875]
 [ 15222.77636719]
 [ 18879.13476562]]
DEBUG:root:training time = %d0.20656
INFO:root:frame =4641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame =4642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000370025634766
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.963393333333
DEBUG:root: dqn, choose action rondomly, need time 0.000337999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335216522217
INFO:root:frame =4645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000479221343994
INFO:root:frame =4646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.963361666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000197172164917
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 15501.95214844]
 [ 14626.41015625]
 [ 15000.8671875 ]
 [ 16513.50585938]
 [ 13304.18066406]
 [ 15643.37695312]
 [ 12609.21777344]
 [ 14730.46875   ]
 [ 17455.66015625]
 [ 18029.81445312]
 [ 16095.22167969]
 [ 15144.55957031]
 [ 16513.50585938]
 [ 12334.12011719]
 [ 15501.95214844]
 [ 17894.28710938]]
DEBUG:root:training time = %d0.208266
INFO:root:frame =4649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232219696045
INFO:root:frame =4650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.96333
DEBUG:root: dqn, choose action rondomly, need time 0.000327000000013
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =4653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =4654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000425100326538
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:random_action_porb = 0.963298333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 12294.45703125]
 [ 15943.87109375]
 [ 18365.34570312]
 [ 14557.98925781]
 [ 14557.98925781]
 [ 16625.25585938]
 [ 17737.86914062]
 [ 12864.74316406]
 [ 18678.33398438]
 [ 15613.64941406]
 [ 18678.33398438]
 [ 18321.10351562]
 [ 12899.87988281]
 [ 12750.90917969]
 [ 13179.27539062]
 [ 13541.54980469]]
DEBUG:root:training time = %d0.220923
INFO:root:frame =4657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000328779220581
INFO:root:frame =4658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:random_action_porb = 0.963266666667
DEBUG:root: dqn, choose action rondomly, need time 0.000414000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000402927398682
INFO:root:frame =4661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =4662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000424146652222
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:random_action_porb = 0.963235
DEBUG:root: dqn, choose action rondomly, need time 0.000186999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000167846679688
INFO:root:training error  = [[ 20122.97460938]
 [ 17637.92773438]
 [ 20969.24609375]
 [ 21676.09179688]
 [ 16108.48046875]
 [ 15819.203125  ]
 [ 14126.62207031]
 [ 12395.58203125]
 [ 13688.31445312]
 [ 19675.19921875]
 [ 19316.38476562]
 [ 14255.40429688]
 [ 16168.21484375]
 [ 21534.20117188]
 [ 14466.28710938]
 [ 21040.5078125 ]]
DEBUG:root:training time = %d0.215865
INFO:root:frame =4665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =4666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000399112701416
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.963203333333
DEBUG:root: dqn, choose action rondomly, need time 0.000276999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =4669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00056004524231
INFO:root:frame =4670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000611066818237
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.963171666667
DEBUG:root: dqn, choose action rondomly, need time 0.000613000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 19504.34570312]
 [ 18989.79492188]
 [ 14468.16601562]
 [ 18134.54101562]
 [ 13336.80957031]
 [ 13818.93261719]
 [ 13072.59472656]
 [ 18763.71484375]
 [ 18989.45898438]
 [ 19466.65429688]
 [ 19512.52929688]
 [ 16738.39648438]
 [ 19981.36914062]
 [ 18744.2578125 ]
 [ 18063.13671875]
 [ 13915.24316406]]
DEBUG:root:training time = %d0.220499
INFO:root:frame =4673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000418901443481
INFO:root:frame = 4675 State into memory, numbers recorded 121 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root:random_action_porb = 0.96314
DEBUG:root: dqn, choose action rondomly, need time 0.000523999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4676current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000504970550537
INFO:root:frame =4677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440835952759
INFO:root:frame =4678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
INFO:root:frame = 4679 State into memory, numbers recorded 122 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000549793243408
INFO:root:random_action_porb = 0.963108333333
DEBUG:root: dqn, choose action rondomly, need time 0.000541000000013
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4680current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:training error  = [[ 15391.08007812]
 [ 17087.390625  ]
 [ 17806.34765625]
 [ 13761.87890625]
 [ 13683.85839844]
 [ 19915.57617188]
 [ 16769.36523438]
 [ 20906.08203125]
 [ 18794.6953125 ]
 [ 17157.41796875]
 [ 18510.8125    ]
 [ 17806.34765625]
 [ 19915.5078125 ]
 [ 14301.26367188]
 [ 18121.39257812]
 [ 20591.83007812]]
DEBUG:root:training time = %d0.233403
INFO:root:frame =4681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =4682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423192977905
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:random_action_porb = 0.963076666667
DEBUG:root: dqn, choose action rondomly, need time 0.000598999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =4685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000607967376709
INFO:root:frame =4686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000425100326538
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.963045
DEBUG:root: dqn, choose action rondomly, need time 0.000531000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:training error  = [[ 17365.39648438]
 [ 14025.12792969]
 [ 17365.39648438]
 [ 17389.08398438]
 [ 17389.08398438]
 [ 17666.53710938]
 [ 13399.984375  ]
 [ 17365.39648438]
 [ 19048.44726562]
 [ 17546.74023438]
 [ 17335.49023438]
 [ 18896.1796875 ]
 [ 16559.59375   ]
 [ 14569.71582031]
 [ 21492.87695312]
 [ 12458.06933594]]
DEBUG:root:training time = %d0.214467
INFO:root:frame =4689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000367879867554
INFO:root:frame =4690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000398874282837
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.963013333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =4693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =4694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.962981666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294000000011
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14163.32421875]
 [ 13989.01074219]
 [ 15086.1484375 ]
 [ 13507.30859375]
 [ 18210.69921875]
 [ 16950.375     ]
 [ 18299.43164062]
 [ 15671.60449219]
 [ 15218.80078125]
 [ 13839.48925781]
 [ 14102.95410156]
 [ 17699.91210938]
 [ 14466.63964844]
 [ 18091.62890625]
 [ 18633.78320312]
 [ 16950.375     ]]
DEBUG:root:training time = %d0.201328
INFO:root:frame =4697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =4698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000387907028198
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:random_action_porb = 0.96295
DEBUG:root: dqn, choose action rondomly, need time 0.000252000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =4701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000541925430298
INFO:root:frame =4702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00040602684021
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.962918333333
DEBUG:root: dqn, choose action rondomly, need time 0.00031700000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309228897095
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17995.21289062]
 [ 14316.79980469]
 [ 14126.21582031]
 [ 14447.6171875 ]
 [ 14117.45410156]
 [ 14395.01953125]
 [ 17548.48632812]
 [ 18563.06445312]
 [ 17053.77148438]
 [ 14122.09570312]
 [ 17412.14257812]
 [ 17053.77148438]
 [ 16181.13183594]
 [ 14115.94628906]
 [ 16037.22949219]
 [ 13989.18359375]]
DEBUG:root:training time = %d0.216306
INFO:root:frame =4705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00037693977356
INFO:root:frame =4706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:random_action_porb = 0.962886666667
DEBUG:root: dqn, choose action rondomly, need time 0.000202999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:frame =4709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =4710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000307083129883
DEBUG:root: save sample needs time = 0.000134944915771
INFO:root:random_action_porb = 0.962855
DEBUG:root: dqn, choose action rondomly, need time 0.000190000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000150918960571
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14568.890625  ]
 [ 14970.14355469]
 [ 19121.23242188]
 [ 18108.1171875 ]
 [ 15477.15820312]
 [ 18684.60742188]
 [ 17462.56445312]
 [ 15477.15820312]
 [ 14568.890625  ]
 [ 17939.64648438]
 [ 19075.68359375]
 [ 18108.1171875 ]
 [ 14970.14355469]
 [ 18144.66796875]
 [ 14462.1171875 ]
 [ 19075.68359375]]
DEBUG:root:training time = %d0.191462
INFO:root:frame =4713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =4714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000474214553833
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:random_action_porb = 0.962823333333
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =4717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =4718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000385999679565
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.962791666667
DEBUG:root: dqn, choose action rondomly, need time 0.000321
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 15626.89257812]
 [ 15134.82617188]
 [ 16719.828125  ]
 [ 21713.05859375]
 [ 15592.24121094]
 [ 17710.69726562]
 [ 15083.75      ]
 [ 17177.5703125 ]
 [ 16289.82324219]
 [ 17500.39648438]
 [ 14829.0078125 ]
 [ 13636.37792969]
 [ 16423.2109375 ]
 [ 17757.70898438]
 [ 18353.50195312]
 [ 15134.82617188]]
DEBUG:root:training time = %d0.191045
INFO:root:frame =4721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =4722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00040602684021
DEBUG:root: save sample needs time = 0.000157117843628
INFO:root:random_action_porb = 0.96276
DEBUG:root: dqn, choose action rondomly, need time 0.000249000000011
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:frame =4725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000486135482788
INFO:root:frame =4726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.962728333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 14777.85644531]
 [ 19181.57421875]
 [ 16183.74023438]
 [ 23281.94726562]
 [ 21286.42578125]
 [ 13411.68652344]
 [ 22849.91015625]
 [ 19687.4609375 ]
 [ 14816.16699219]
 [ 19363.71484375]
 [ 16662.73828125]
 [ 21455.74023438]
 [ 14909.86425781]
 [ 18478.2734375 ]
 [ 17458.43554688]
 [ 16624.25      ]]
DEBUG:root:training time = %d0.240919
INFO:root:frame =4729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000269174575806
INFO:root:frame =4730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000280141830444
DEBUG:root: save sample needs time = 0.000188827514648
INFO:root:random_action_porb = 0.962696666667
DEBUG:root: dqn, choose action rondomly, need time 0.000220999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016713142395
INFO:root:frame =4733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268220901489
INFO:root:frame =4734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486850738525
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.962665
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000359058380127
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17255.66992188]
 [ 17681.921875  ]
 [ 20329.77539062]
 [ 15431.57128906]
 [ 16493.49414062]
 [ 18994.37109375]
 [ 18001.76367188]
 [ 20593.65234375]
 [ 14595.71875   ]
 [ 17074.4375    ]
 [ 18869.40820312]
 [ 21611.79882812]
 [ 19153.45117188]
 [ 21743.57617188]
 [ 18290.05273438]
 [ 20613.20507812]]
DEBUG:root:training time = %d0.206086
INFO:root:frame =4737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:frame =4738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427007675171
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:random_action_porb = 0.962633333333
DEBUG:root: dqn, choose action rondomly, need time 0.000399999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =4741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00041389465332
INFO:root:frame =4742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000125885009766
INFO:root:random_action_porb = 0.962601666667
DEBUG:root: dqn, choose action rondomly, need time 0.000191000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180959701538
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 21733.42578125]
 [ 16517.01953125]
 [ 18385.20117188]
 [ 17329.31835938]
 [ 18410.43554688]
 [ 17376.53125   ]
 [ 18410.43554688]
 [ 14967.515625  ]
 [ 24742.53710938]
 [ 15347.97949219]
 [ 14910.63964844]
 [ 22583.72070312]
 [ 17376.53125   ]
 [ 18591.015625  ]
 [ 17870.19335938]
 [ 17591.72265625]]
DEBUG:root:training time = %d0.20835
INFO:root:frame =4745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =4746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324964523315
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:random_action_porb = 0.96257
DEBUG:root: dqn, choose action rondomly, need time 0.000507999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root:frame =4749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000608921051025
INFO:root:frame =4750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319004058838
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.962538333333
DEBUG:root: dqn, choose action rondomly, need time 0.000414000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000407934188843
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 20282.11328125]
 [ 17328.74023438]
 [ 21319.49414062]
 [ 20050.2421875 ]
 [ 16662.61132812]
 [ 16561.79296875]
 [ 15851.15429688]
 [ 17852.96484375]
 [ 19240.18164062]
 [ 19730.8515625 ]
 [ 22184.8515625 ]
 [ 16318.25390625]
 [ 22398.6015625 ]
 [ 17043.06054688]
 [ 18454.91796875]
 [ 22128.23242188]]
DEBUG:root:training time = %d0.203413
INFO:root:frame =4753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =4754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308036804199
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.962506666667
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =4757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000540018081665
INFO:root:frame =4758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:random_action_porb = 0.962475
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 16521.41210938]
 [ 24266.65625   ]
 [ 16521.41210938]
 [ 18245.04492188]
 [ 16027.08984375]
 [ 15259.96972656]
 [ 15738.42578125]
 [ 22948.69921875]
 [ 21976.90429688]
 [ 16382.125     ]
 [ 15640.62890625]
 [ 23927.24023438]
 [ 19544.18945312]
 [ 19413.4140625 ]
 [ 21696.36914062]
 [ 15119.87207031]]
DEBUG:root:training time = %d0.206
INFO:root:frame =4761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265121459961
INFO:root:frame =4762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000401020050049
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.962443333333
DEBUG:root: dqn, choose action rondomly, need time 0.00023800000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00019097328186
INFO:root:frame =4765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =4766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000505924224854
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:random_action_porb = 0.962411666667
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:training error  = [[ 24273.12304688]
 [ 23748.796875  ]
 [ 17628.26757812]
 [ 21400.56054688]
 [ 20635.64453125]
 [ 21309.44140625]
 [ 24915.8046875 ]
 [ 14412.24902344]
 [ 21094.22851562]
 [ 23141.49609375]
 [ 22922.59570312]
 [ 25497.7578125 ]
 [ 25060.52929688]
 [ 18230.93359375]
 [ 24273.12304688]
 [ 19060.71484375]]
DEBUG:root:training time = %d0.227166
INFO:root:frame =4769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000422954559326
INFO:root:frame =4770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:random_action_porb = 0.96238
DEBUG:root: dqn, choose action rondomly, need time 0.000467
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000494003295898
INFO:root:frame =4773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000381946563721
INFO:root:frame =4774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.962348333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 20673.890625  ]
 [ 20999.30664062]
 [ 16412.44921875]
 [ 22664.58203125]
 [ 18814.11328125]
 [ 20552.890625  ]
 [ 18514.86328125]
 [ 19456.1640625 ]
 [ 19435.0546875 ]
 [ 18631.984375  ]
 [ 18674.39648438]
 [ 19742.72070312]
 [ 20064.140625  ]
 [ 21576.78320312]
 [ 19742.72070312]
 [ 15815.15039062]]
DEBUG:root:training time = %d0.233846
INFO:root:frame =4777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =4778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000340938568115
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.962316666667
DEBUG:root: dqn, choose action rondomly, need time 0.000208999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180959701538
INFO:root:frame =4781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000500917434692
INFO:root:frame =4782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame = 4783 State into memory, numbers recorded 123 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000572919845581
INFO:root:random_action_porb = 0.962285
DEBUG:root: dqn, choose action rondomly, need time 0.000312999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4784current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:training error  = [[ 18453.921875  ]
 [ 20775.04101562]
 [ 21690.6875    ]
 [ 18046.34179688]
 [ 18086.11328125]
 [ 24680.59375   ]
 [ 18839.50585938]
 [ 23804.28515625]
 [ 25597.1875    ]
 [ 21573.91601562]
 [ 16921.65234375]
 [ 18879.94140625]
 [ 19060.78125   ]
 [ 17743.33203125]
 [ 18879.94140625]
 [ 18453.921875  ]]
DEBUG:root:training time = %d0.223013
INFO:root:frame =4785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =4786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000350952148438
DEBUG:root: save sample needs time = 0.000201225280762
INFO:root:random_action_porb = 0.962253333333
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =4789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00053596496582
INFO:root:frame =4790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
INFO:root:frame = 4791 State into memory, numbers recorded 124 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000566005706787
INFO:root:random_action_porb = 0.962221666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4792current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 20504.12890625]
 [ 18174.14648438]
 [ 17543.70117188]
 [ 17865.23242188]
 [ 19094.7734375 ]
 [ 21303.52539062]
 [ 18784.92382812]
 [ 22660.171875  ]
 [ 17104.24609375]
 [ 21383.34960938]
 [ 18135.19921875]
 [ 16448.125     ]
 [ 20170.44921875]
 [ 25327.21484375]
 [ 21737.09570312]
 [ 17191.97265625]]
DEBUG:root:training time = %d0.211567
INFO:root:frame =4793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =4794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame = 4795 State into memory, numbers recorded 125 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.00065803527832
INFO:root:random_action_porb = 0.96219
INFO:root:dqn select action Tensor("ArgMax_18:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015344
INFO:root:action choosen by dqn [0]
INFO:root:frame =4796current_observation done, NOT record action [0], reward = 0
DEBUG:root: save sample needs time = 0.000824928283691
INFO:root:frame =4797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =4798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275135040283
DEBUG:root: save sample needs time = 0.000119924545288
INFO:root:random_action_porb = 0.962158333333
DEBUG:root: dqn, choose action rondomly, need time 0.000192999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174999237061
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 17293.79101562]
 [ 20402.24414062]
 [ 21819.890625  ]
 [ 24772.80859375]
 [ 24884.13867188]
 [ 17934.21875   ]
 [ 19979.22851562]
 [ 26639.32421875]
 [ 17604.02929688]
 [ 29175.82617188]
 [ 21842.83398438]
 [ 27066.67578125]
 [ 15757.84960938]
 [ 20968.609375  ]
 [ 24950.34570312]
 [ 19983.9921875 ]]
DEBUG:root:training time = %d0.220089
INFO:root:frame =4801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248193740845
INFO:root:frame =4802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000278949737549
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:random_action_porb = 0.962126666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =4805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000501871109009
INFO:root:frame =4806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504016876221
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root:random_action_porb = 0.962095
DEBUG:root: dqn, choose action rondomly, need time 0.000324000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:training error  = [[ 17503.3671875 ]
 [ 22825.484375  ]
 [ 27024.51757812]
 [ 24973.64453125]
 [ 23014.06054688]
 [ 17433.4765625 ]
 [ 20089.46289062]
 [ 19608.4765625 ]
 [ 24557.859375  ]
 [ 20089.46289062]
 [ 23704.796875  ]
 [ 24136.83789062]
 [ 15689.21386719]
 [ 19796.20117188]
 [ 17433.4765625 ]
 [ 24283.7734375 ]]
DEBUG:root:training time = %d0.231486
INFO:root:frame =4809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =4810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000316143035889
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.962063333333
DEBUG:root: dqn, choose action rondomly, need time 0.000337000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000509977340698
INFO:root:frame =4813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =4814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.962031666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 21442.65429688]
 [ 20883.63671875]
 [ 20060.13085938]
 [ 22071.32421875]
 [ 24587.48046875]
 [ 21475.27148438]
 [ 18248.27734375]
 [ 21597.51757812]
 [ 20043.74414062]
 [ 21208.34765625]
 [ 20602.34179688]
 [ 22435.66601562]
 [ 25317.890625  ]
 [ 20724.11914062]
 [ 20399.59375   ]
 [ 26402.125     ]]
DEBUG:root:training time = %d0.201206
INFO:root:frame =4817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250816345215
INFO:root:frame =4818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000353097915649
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.962
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =4821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =4822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000385046005249
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.961968333333
DEBUG:root: dqn, choose action rondomly, need time 0.00029099999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 18134.86914062]
 [ 21983.56445312]
 [ 19184.2109375 ]
 [ 21844.56640625]
 [ 24874.51171875]
 [ 18815.99023438]
 [ 18680.3359375 ]
 [ 19795.30859375]
 [ 20065.6640625 ]
 [ 24770.73242188]
 [ 17711.08789062]
 [ 22135.06054688]
 [ 18934.32421875]
 [ 25320.6875    ]
 [ 20586.43554688]
 [ 18767.66210938]]
DEBUG:root:training time = %d0.215134
INFO:root:frame =4825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00041389465332
INFO:root:frame =4826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000493049621582
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:random_action_porb = 0.961936666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =4829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000425100326538
INFO:root:frame =4830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000385046005249
INFO:root:frame = 4831 State into memory, numbers recorded 126 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:random_action_porb = 0.961905
DEBUG:root: dqn, choose action rondomly, need time 0.000439
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4832current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 22574.76953125]
 [ 21052.9765625 ]
 [ 23654.98046875]
 [ 17924.08398438]
 [ 18869.34179688]
 [ 23026.58007812]
 [ 21156.89648438]
 [ 23191.2890625 ]
 [ 22556.9453125 ]
 [ 23051.25976562]
 [ 18615.125     ]
 [ 19145.34375   ]
 [ 23026.58007812]
 [ 20334.92773438]
 [ 23982.40820312]
 [ 20168.23046875]]
DEBUG:root:training time = %d0.204231
INFO:root:frame =4833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =4834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000518083572388
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:random_action_porb = 0.961873333333
DEBUG:root: dqn, choose action rondomly, need time 0.000225999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =4837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =4838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.961841666667
DEBUG:root: dqn, choose action rondomly, need time 0.000592999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 18851.57226562]
 [ 18773.28125   ]
 [ 28668.04492188]
 [ 23045.40429688]
 [ 22702.6015625 ]
 [ 18811.90429688]
 [ 21593.140625  ]
 [ 18838.56835938]
 [ 22501.97851562]
 [ 23178.27929688]
 [ 19274.12890625]
 [ 18851.57226562]
 [ 22045.94140625]
 [ 18950.65429688]
 [ 28015.453125  ]
 [ 23572.0703125 ]]
DEBUG:root:training time = %d0.220615
INFO:root:frame =4841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232219696045
INFO:root:frame =4842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.96181
INFO:root:dqn select action Tensor("ArgMax_19:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.016639
INFO:root:action choosen by dqn [2]
INFO:root:frame =4844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =4845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =4846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000329971313477
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:random_action_porb = 0.961778333333
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000280141830444
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 23127.23632812]
 [ 22148.21289062]
 [ 19569.04492188]
 [ 22985.7734375 ]
 [ 22908.69921875]
 [ 22139.12890625]
 [ 23127.23632812]
 [ 19962.80664062]
 [ 21616.46484375]
 [ 19169.60546875]
 [ 24215.72070312]
 [ 21693.4921875 ]
 [ 20178.42382812]
 [ 21681.91601562]
 [ 24215.72070312]
 [ 18513.26953125]]
DEBUG:root:training time = %d0.203728
INFO:root:frame =4849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002281665802
INFO:root:frame =4850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439167022705
DEBUG:root: save sample needs time = 0.000156164169312
INFO:root:random_action_porb = 0.961746666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =4853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =4854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:random_action_porb = 0.961715
DEBUG:root: dqn, choose action rondomly, need time 0.000227999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:training error  = [[ 21696.9453125 ]
 [ 24873.27929688]
 [ 22918.90039062]
 [ 24742.921875  ]
 [ 19877.6953125 ]
 [ 25368.9609375 ]
 [ 25003.515625  ]
 [ 22536.63671875]
 [ 18716.59179688]
 [ 24507.45898438]
 [ 25642.04882812]
 [ 22918.90039062]
 [ 19151.01953125]
 [ 25316.33789062]
 [ 18790.546875  ]
 [ 23886.62304688]]
DEBUG:root:training time = %d0.209553
INFO:root:frame =4857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =4858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:random_action_porb = 0.961683333333
DEBUG:root: dqn, choose action rondomly, need time 0.000357999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =4861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =4862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.961651666667
DEBUG:root: dqn, choose action rondomly, need time 0.000274000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 19877.41992188]
 [ 19792.21679688]
 [ 20942.52734375]
 [ 22318.5078125 ]
 [ 21724.06835938]
 [ 21896.26757812]
 [ 21568.82421875]
 [ 21216.81054688]
 [ 20402.38476562]
 [ 19606.2890625 ]
 [ 21375.99609375]
 [ 21515.50390625]
 [ 28393.23828125]
 [ 19938.32226562]
 [ 20373.9375    ]
 [ 27022.02929688]]
DEBUG:root:training time = %d0.227384
INFO:root:frame =4865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000332832336426
INFO:root:frame =4866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame = 4867 State into memory, numbers recorded 127 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000540971755981
INFO:root:random_action_porb = 0.96162
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4868current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =4869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000650882720947
INFO:root:frame =4870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00029993057251
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.961588333333
DEBUG:root: dqn, choose action rondomly, need time 0.000164000000012
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000167846679688
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 19096.0546875 ]
 [ 31086.01171875]
 [ 23063.19726562]
 [ 22418.99414062]
 [ 21178.5625    ]
 [ 29045.27929688]
 [ 29534.5546875 ]
 [ 31897.73242188]
 [ 19057.546875  ]
 [ 22699.0703125 ]
 [ 22130.84765625]
 [ 31086.01171875]
 [ 21469.68945312]
 [ 30219.1875    ]
 [ 30034.515625  ]
 [ 30017.84570312]]
DEBUG:root:training time = %d0.211434
INFO:root:frame =4873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =4874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.961556666667
DEBUG:root: dqn, choose action rondomly, need time 0.000262000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =4877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449180603027
INFO:root:frame =4878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00089693069458
INFO:root:frame = 4879 State into memory, numbers recorded 128 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000576019287109
INFO:root:random_action_porb = 0.961525
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4880current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:training error  = [[ 21523.24023438]
 [ 28720.98046875]
 [ 20898.81054688]
 [ 28986.80859375]
 [ 21129.13476562]
 [ 28801.71875   ]
 [ 29479.11328125]
 [ 28379.41601562]
 [ 28379.41601562]
 [ 28501.53515625]
 [ 22487.76953125]
 [ 21129.13476562]
 [ 20664.1328125 ]
 [ 30099.62304688]
 [ 29462.8515625 ]
 [ 27731.03125   ]]
DEBUG:root:training time = %d0.213689
INFO:root:frame =4881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =4882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000242948532104
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.961493333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =4885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000474214553833
INFO:root:frame =4886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000155925750732
INFO:root:random_action_porb = 0.961461666667
DEBUG:root: dqn, choose action rondomly, need time 0.000233999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 29200.76953125]
 [ 34230.78125   ]
 [ 20207.9140625 ]
 [ 29598.53125   ]
 [ 27995.43359375]
 [ 26867.41992188]
 [ 21775.12304688]
 [ 30513.76171875]
 [ 20929.52734375]
 [ 30900.76367188]
 [ 27228.46484375]
 [ 29661.06445312]
 [ 33242.4765625 ]
 [ 31309.0390625 ]
 [ 27930.68359375]
 [ 27995.43359375]]
DEBUG:root:training time = %d0.211018
INFO:root:frame =4889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =4890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000338077545166
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.96143
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame =4893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =4894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000384092330933
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:random_action_porb = 0.961398333333
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000168085098267
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 27765.51757812]
 [ 25594.765625  ]
 [ 21719.17382812]
 [ 23060.52734375]
 [ 29676.11914062]
 [ 27506.49804688]
 [ 22233.2421875 ]
 [ 27765.51757812]
 [ 20970.37695312]
 [ 23253.79296875]
 [ 27584.21484375]
 [ 22093.01953125]
 [ 20540.57226562]
 [ 26562.31445312]
 [ 21386.13476562]
 [ 21670.55664062]]
DEBUG:root:training time = %d0.22582
INFO:root:frame =4897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =4898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000282049179077
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:random_action_porb = 0.961366666667
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000361919403076
INFO:root:frame =4901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =4902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame = 4903 State into memory, numbers recorded 129 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000542163848877
INFO:root:random_action_porb = 0.961335
DEBUG:root: dqn, choose action rondomly, need time 0.000191000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4904current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000187873840332
INFO:root:training error  = [[ 25622.89648438]
 [ 21826.671875  ]
 [ 23794.79492188]
 [ 19620.9921875 ]
 [ 22240.66796875]
 [ 31737.6484375 ]
 [ 19282.671875  ]
 [ 22863.27148438]
 [ 20742.046875  ]
 [ 24514.875     ]
 [ 22439.46875   ]
 [ 19620.9921875 ]
 [ 24587.7109375 ]
 [ 21537.99804688]
 [ 24400.7890625 ]
 [ 20917.02539062]]
DEBUG:root:training time = %d0.230564
INFO:root:frame =4905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =4906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00030517578125
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:random_action_porb = 0.961303333333
DEBUG:root: dqn, choose action rondomly, need time 0.000231999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =4909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000377178192139
INFO:root:frame =4910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000350952148438
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.961271666667
DEBUG:root: dqn, choose action rondomly, need time 0.000331000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322818756104
INFO:root:training error  = [[ 31471.50585938]
 [ 23581.59179688]
 [ 31276.734375  ]
 [ 21463.53710938]
 [ 22495.60546875]
 [ 26589.140625  ]
 [ 31635.60742188]
 [ 20751.61328125]
 [ 34465.61328125]
 [ 27574.80859375]
 [ 25790.66601562]
 [ 32346.3203125 ]
 [ 31635.60742188]
 [ 23454.96679688]
 [ 33258.76953125]
 [ 19959.70117188]]
DEBUG:root:training time = %d0.213628
INFO:root:frame =4913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000419855117798
INFO:root:frame =4914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432968139648
INFO:root:frame = 4915 State into memory, numbers recorded 130 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000541925430298
INFO:root:random_action_porb = 0.96124
DEBUG:root: dqn, choose action rondomly, need time 0.000350999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4916current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000609159469604
INFO:root:frame =4917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000477075576782
INFO:root:frame =4918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000220775604248
DEBUG:root: save sample needs time = 0.000103235244751
INFO:root:random_action_porb = 0.961208333333
DEBUG:root: dqn, choose action rondomly, need time 0.000257000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000179052352905
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 29073.4140625 ]
 [ 30404.9375    ]
 [ 25103.6015625 ]
 [ 29898.25976562]
 [ 23527.93554688]
 [ 23686.68359375]
 [ 30659.18945312]
 [ 31939.60546875]
 [ 31921.1953125 ]
 [ 23567.49609375]
 [ 31007.1171875 ]
 [ 28331.31640625]
 [ 29073.4140625 ]
 [ 29590.97070312]
 [ 31198.20117188]
 [ 32903.08984375]]
DEBUG:root:training time = %d0.188483
INFO:root:frame =4921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:frame =4922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504016876221
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root:random_action_porb = 0.961176666667
DEBUG:root: dqn, choose action rondomly, need time 0.000335000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000354766845703
INFO:root:frame =4925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root:frame =4926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.961145
DEBUG:root: dqn, choose action rondomly, need time 0.000518
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 29838.8515625 ]
 [ 31431.15234375]
 [ 26928.6015625 ]
 [ 31173.0234375 ]
 [ 27576.91601562]
 [ 28229.33203125]
 [ 28836.53320312]
 [ 27988.8984375 ]
 [ 28906.97265625]
 [ 29838.8515625 ]
 [ 32311.99414062]
 [ 33047.17578125]
 [ 28855.44140625]
 [ 22569.046875  ]
 [ 28180.37695312]
 [ 28855.44140625]]
DEBUG:root:training time = %d0.204567
INFO:root:frame =4929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000422954559326
INFO:root:frame =4930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000561952590942
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.961113333333
DEBUG:root: dqn, choose action rondomly, need time 0.000334000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =4933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464200973511
INFO:root:frame =4934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame = 4935 State into memory, numbers recorded 131 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000581026077271
INFO:root:random_action_porb = 0.961081666667
DEBUG:root: dqn, choose action rondomly, need time 0.000333999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4936current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 29129.97265625]
 [ 23585.11523438]
 [ 23593.58984375]
 [ 23674.73632812]
 [ 23107.93359375]
 [ 22511.28125   ]
 [ 25172.42578125]
 [ 20866.28125   ]
 [ 28655.06640625]
 [ 23423.046875  ]
 [ 29167.73632812]
 [ 23316.0078125 ]
 [ 24617.11914062]
 [ 23064.23632812]
 [ 29682.25976562]
 [ 30005.83398438]]
DEBUG:root:training time = %d0.219283
INFO:root:frame =4937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:frame =4938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000292062759399
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.96105
DEBUG:root: dqn, choose action rondomly, need time 0.000338000000013
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000420093536377
INFO:root:frame =4941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257015228271
INFO:root:frame =4942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00031590461731
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.961018333333
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000011
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 26979.34570312]
 [ 27010.95507812]
 [ 35329.40625   ]
 [ 31550.7265625 ]
 [ 31301.17773438]
 [ 23835.86132812]
 [ 22451.5390625 ]
 [ 28956.63867188]
 [ 29753.5546875 ]
 [ 27990.20507812]
 [ 31980.6328125 ]
 [ 25895.22070312]
 [ 27833.0078125 ]
 [ 35329.40625   ]
 [ 23190.17382812]
 [ 21276.59570312]]
DEBUG:root:training time = %d0.226378
INFO:root:frame =4945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =4946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000296115875244
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:random_action_porb = 0.960986666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =4949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =4950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000576019287109
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.960955
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 24687.19140625]
 [ 24986.609375  ]
 [ 24452.8359375 ]
 [ 33554.6171875 ]
 [ 34717.16796875]
 [ 26209.20703125]
 [ 23619.24804688]
 [ 30283.4765625 ]
 [ 25755.93945312]
 [ 25388.5625    ]
 [ 25881.47265625]
 [ 27436.57421875]
 [ 24815.55664062]
 [ 26742.15039062]
 [ 25881.47265625]
 [ 31398.87109375]]
DEBUG:root:training time = %d0.205283
INFO:root:frame =4953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame =4954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000323057174683
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:random_action_porb = 0.960923333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =4957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =4958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504970550537
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.960891666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 28610.61523438]
 [ 26417.51757812]
 [ 29229.5625    ]
 [ 31007.1171875 ]
 [ 27244.90429688]
 [ 24306.7578125 ]
 [ 23702.16601562]
 [ 24270.53710938]
 [ 26017.54882812]
 [ 29444.75      ]
 [ 34456.55078125]
 [ 30698.95898438]
 [ 26208.09960938]
 [ 34912.046875  ]
 [ 31007.1171875 ]
 [ 27211.546875  ]]
DEBUG:root:training time = %d0.233912
INFO:root:frame =4961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =4962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.96086
DEBUG:root: dqn, choose action rondomly, need time 0.000208000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =4965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =4966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000699043273926
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:random_action_porb = 0.960828333333
DEBUG:root: dqn, choose action rondomly, need time 0.000211000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 23499.85742188]
 [ 38278.50390625]
 [ 23477.78125   ]
 [ 36981.09375   ]
 [ 32519.02539062]
 [ 29639.37109375]
 [ 23510.48632812]
 [ 24860.34375   ]
 [ 23546.8125    ]
 [ 25964.01953125]
 [ 24393.23828125]
 [ 31780.37304688]
 [ 28288.26757812]
 [ 23477.78125   ]
 [ 30181.76757812]
 [ 39088.84375   ]]
DEBUG:root:training time = %d0.183693
INFO:root:frame =4969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:frame =4970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274896621704
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:random_action_porb = 0.960796666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =4972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =4973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000495195388794
INFO:root:frame =4974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427007675171
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.960765
DEBUG:root: dqn, choose action rondomly, need time 0.000238999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =4976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:training error  = [[ 34727.1796875 ]
 [ 28095.52148438]
 [ 35514.94921875]
 [ 32512.0703125 ]
 [ 34714.984375  ]
 [ 34660.6953125 ]
 [ 32002.29296875]
 [ 30816.70507812]
 [ 33693.48828125]
 [ 29429.50390625]
 [ 30816.70507812]
 [ 33525.5546875 ]
 [ 33193.265625  ]
 [ 32270.66601562]
 [ 26143.40039062]
 [ 32163.7421875 ]]
DEBUG:root:training time = %d0.187976
INFO:root:frame =4977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =4978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000259160995483
INFO:root:random_action_porb = 0.960733333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =4980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =4981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =4982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456809997559
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:random_action_porb = 0.960701666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 29504.60351562]
 [ 26056.390625  ]
 [ 36564.984375  ]
 [ 33190.59375   ]
 [ 34713.4375    ]
 [ 37804.234375  ]
 [ 37083.23046875]
 [ 37207.828125  ]
 [ 24593.60546875]
 [ 25073.671875  ]
 [ 34635.3359375 ]
 [ 31357.61328125]
 [ 31996.43945312]
 [ 29356.16992188]
 [ 33075.49609375]
 [ 33059.8671875 ]]
DEBUG:root:training time = %d0.22334
INFO:root:frame =4985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =4986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000502109527588
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.96067
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =4988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000359773635864
INFO:root:frame =4989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root:frame =4990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308990478516
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.960638333333
DEBUG:root: dqn, choose action rondomly, need time 0.000249999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000141143798828
INFO:root:training error  = [[ 28925.48828125]
 [ 31259.12109375]
 [ 30728.22460938]
 [ 29876.14257812]
 [ 29595.08789062]
 [ 36131.45703125]
 [ 34132.29296875]
 [ 30762.47070312]
 [ 30902.91015625]
 [ 30190.9296875 ]
 [ 29612.05664062]
 [ 30307.69921875]
 [ 29641.13671875]
 [ 31116.40820312]
 [ 30307.69921875]
 [ 34549.3359375 ]]
DEBUG:root:training time = %d0.184303
INFO:root:frame =4993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:frame =4994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233888626099
DEBUG:root: save sample needs time = 0.000101089477539
INFO:root:random_action_porb = 0.960606666667
DEBUG:root: dqn, choose action rondomly, need time 0.000182999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =4996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:frame =4997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248193740845
INFO:root:frame =4998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000309944152832
DEBUG:root: save sample needs time = 9.98973846436e-05
DEBUG:root:one frame running time = 0.00290699999999
DEBUG:root:total training time = 123.354855
INFO:root:frame num = 5000 frame round: 0
INFO:root:random_action_porb = 0.960575
DEBUG:root: dqn, choose action rondomly, need time 0.000169000000014
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 30675.265625  ]
 [ 30675.265625  ]
 [ 28211.53320312]
 [ 27537.84765625]
 [ 26216.00585938]
 [ 32051.05273438]
 [ 27463.83789062]
 [ 25458.40039062]
 [ 36044.8203125 ]
 [ 31950.25390625]
 [ 30534.15039062]
 [ 27234.0234375 ]
 [ 30186.09375   ]
 [ 27659.9296875 ]
 [ 27218.3125    ]
 [ 39128.9140625 ]]
DEBUG:root:training time = %d0.182607
INFO:root:frame =5001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =5002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
DEBUG:root: save sample needs time = 0.000136852264404
INFO:root:random_action_porb = 0.960543333333
DEBUG:root: dqn, choose action rondomly, need time 0.000236000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:frame =5005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =5006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
DEBUG:root: save sample needs time = 0.000135898590088
INFO:root:random_action_porb = 0.960511666667
DEBUG:root: dqn, choose action rondomly, need time 0.000174999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000150918960571
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 26582.61132812]
 [ 26560.8828125 ]
 [ 34437.7890625 ]
 [ 27963.08984375]
 [ 28363.37890625]
 [ 28308.47265625]
 [ 27787.81640625]
 [ 27100.90820312]
 [ 28832.63671875]
 [ 30783.28515625]
 [ 27177.88867188]
 [ 29187.91992188]
 [ 27015.52929688]
 [ 37500.09375   ]
 [ 34437.7890625 ]
 [ 35307.75      ]]
DEBUG:root:training time = %d0.176934
INFO:root:frame =5009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =5010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root:random_action_porb = 0.96048
DEBUG:root: dqn, choose action rondomly, need time 0.000181999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174045562744
INFO:root:frame =5013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =5014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000289916992188
DEBUG:root: save sample needs time = 0.000142097473145
INFO:root:random_action_porb = 0.960448333333
DEBUG:root: dqn, choose action rondomly, need time 0.000219999999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 26711.73632812]
 [ 27374.97851562]
 [ 28703.35742188]
 [ 31515.00390625]
 [ 33502.76171875]
 [ 35935.23828125]
 [ 31813.72070312]
 [ 36096.84765625]
 [ 26605.38476562]
 [ 25252.98046875]
 [ 38141.7265625 ]
 [ 27149.3203125 ]
 [ 27149.3203125 ]
 [ 35872.32421875]
 [ 39203.80859375]
 [ 27078.64648438]]
DEBUG:root:training time = %d0.190403
INFO:root:frame =5017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000363826751709
INFO:root:frame =5018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000516891479492
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.960416666667
DEBUG:root: dqn, choose action rondomly, need time 0.00065699999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =5021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000605821609497
INFO:root:frame =5022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.960385
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000369071960449
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 26269.08203125]
 [ 37253.05078125]
 [ 28778.43945312]
 [ 36579.55078125]
 [ 31566.08007812]
 [ 36102.96875   ]
 [ 35146.36328125]
 [ 35920.80078125]
 [ 38525.9453125 ]
 [ 30056.18164062]
 [ 33635.078125  ]
 [ 30826.90625   ]
 [ 35842.64453125]
 [ 36361.3515625 ]
 [ 36558.7265625 ]
 [ 29729.21875   ]]
DEBUG:root:training time = %d0.229437
INFO:root:frame =5025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =5026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000517845153809
DEBUG:root: save sample needs time = 0.000108003616333
INFO:root:random_action_porb = 0.960353333333
DEBUG:root: dqn, choose action rondomly, need time 0.000474999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =5029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000597953796387
INFO:root:frame =5030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame = 5031 State into memory, numbers recorded 132 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000737905502319
INFO:root:random_action_porb = 0.960321666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5032current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 30039.        ]
 [ 33926.7421875 ]
 [ 38115.31640625]
 [ 26660.92578125]
 [ 36397.30078125]
 [ 33473.54296875]
 [ 36082.00390625]
 [ 36811.23828125]
 [ 32974.87109375]
 [ 29414.34375   ]
 [ 34960.234375  ]
 [ 34751.0234375 ]
 [ 31704.77539062]
 [ 38889.16796875]
 [ 34284.5546875 ]
 [ 38478.6171875 ]]
DEBUG:root:training time = %d0.218924
INFO:root:frame =5033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =5034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.96029
INFO:root:dqn select action Tensor("ArgMax_20:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014698
INFO:root:action choosen by dqn [3]
INFO:root:frame =5036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =5037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000662088394165
INFO:root:frame =5038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame = 5039 State into memory, numbers recorded 133 action = [3], reward = 0
DEBUG:root: save sample needs time = 0.0012469291687
INFO:root:random_action_porb = 0.960258333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5040current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 44599.4375    ]
 [ 28168.57421875]
 [ 39122.63671875]
 [ 29830.24804688]
 [ 35884.90234375]
 [ 31178.45507812]
 [ 42258.65234375]
 [ 41167.37890625]
 [ 32347.375     ]
 [ 37393.41796875]
 [ 40606.0859375 ]
 [ 28666.14453125]
 [ 35621.40234375]
 [ 30606.88671875]
 [ 37850.765625  ]
 [ 40747.99609375]]
DEBUG:root:training time = %d0.212795
INFO:root:frame =5041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:frame =5042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000168085098267
INFO:root:random_action_porb = 0.960226666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000500917434692
INFO:root:frame =5045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root:frame =5046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:random_action_porb = 0.960195
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000378131866455
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 28859.2578125 ]
 [ 32528.359375  ]
 [ 41022.86328125]
 [ 29532.62304688]
 [ 32512.68554688]
 [ 27455.58398438]
 [ 32435.51757812]
 [ 41926.26171875]
 [ 40320.3671875 ]
 [ 40974.71484375]
 [ 31098.41015625]
 [ 42322.01171875]
 [ 37997.296875  ]
 [ 30992.15820312]
 [ 36154.10546875]
 [ 29148.05859375]]
DEBUG:root:training time = %d0.221441
INFO:root:frame =5049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000385999679565
INFO:root:frame =5050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000367879867554
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.960163333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:frame =5053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000449180603027
INFO:root:frame =5054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504016876221
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.960131666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 42805.75      ]
 [ 36279.5546875 ]
 [ 32483.63867188]
 [ 44753.734375  ]
 [ 40331.9375    ]
 [ 41900.76953125]
 [ 45023.7421875 ]
 [ 44753.734375  ]
 [ 49625.39453125]
 [ 40156.109375  ]
 [ 41641.703125  ]
 [ 28643.4140625 ]
 [ 33542.45703125]
 [ 29723.41015625]
 [ 45597.3671875 ]
 [ 44339.23828125]]
DEBUG:root:training time = %d0.238297
INFO:root:frame =5057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =5058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000347137451172
DEBUG:root: save sample needs time = 0.000209808349609
INFO:root:random_action_porb = 0.9601
INFO:root:dqn select action Tensor("ArgMax_21:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.009992
INFO:root:action choosen by dqn [1]
INFO:root:frame =5060 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000354051589966
INFO:root:frame =5061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042200088501
INFO:root:frame =5062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.960068333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 38105.40234375]
 [ 40081.78125   ]
 [ 40217.1875    ]
 [ 38351.80859375]
 [ 37113.890625  ]
 [ 30336.94726562]
 [ 41096.87109375]
 [ 38624.72265625]
 [ 28966.69335938]
 [ 30144.62304688]
 [ 38209.75      ]
 [ 38027.37890625]
 [ 38120.2734375 ]
 [ 35818.51953125]
 [ 39950.50390625]
 [ 38053.37890625]]
DEBUG:root:training time = %d0.226225
INFO:root:frame =5065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =5066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000332117080688
DEBUG:root: save sample needs time = 0.000137805938721
INFO:root:random_action_porb = 0.960036666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root:frame =5069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =5070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.960005
DEBUG:root: dqn, choose action rondomly, need time 0.000329000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00035285949707
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 38024.33203125]
 [ 30588.26757812]
 [ 34473.68359375]
 [ 36487.52734375]
 [ 40927.0859375 ]
 [ 37506.2421875 ]
 [ 41658.7421875 ]
 [ 35507.21875   ]
 [ 36299.0859375 ]
 [ 36049.640625  ]
 [ 36519.33984375]
 [ 28871.78515625]
 [ 39939.671875  ]
 [ 33368.92578125]
 [ 35635.1328125 ]
 [ 34840.73828125]]
DEBUG:root:training time = %d0.234704
INFO:root:frame =5073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =5074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324010848999
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.959973333333
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =5077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =5078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:random_action_porb = 0.959941666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 33053.83203125]
 [ 31832.796875  ]
 [ 31124.50585938]
 [ 42688.54296875]
 [ 35900.07421875]
 [ 30704.43359375]
 [ 30144.79296875]
 [ 37657.03125   ]
 [ 31264.47265625]
 [ 35158.90625   ]
 [ 37342.26171875]
 [ 31323.46875   ]
 [ 32272.859375  ]
 [ 31452.10546875]
 [ 29545.96679688]
 [ 30998.43359375]]
DEBUG:root:training time = %d0.212748
INFO:root:frame =5081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =5082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000360012054443
DEBUG:root: save sample needs time = 0.000265836715698
INFO:root:random_action_porb = 0.95991
DEBUG:root: dqn, choose action rondomly, need time 0.000469999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =5085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000396966934204
INFO:root:frame =5086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.959878333333
DEBUG:root: dqn, choose action rondomly, need time 0.000275999999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 35154.0546875 ]
 [ 36389.66015625]
 [ 31767.75390625]
 [ 39289.02734375]
 [ 31226.49609375]
 [ 38823.046875  ]
 [ 44660.81640625]
 [ 35468.5859375 ]
 [ 34352.48828125]
 [ 33900.0390625 ]
 [ 39289.02734375]
 [ 43008.54296875]
 [ 32527.12695312]
 [ 43299.859375  ]
 [ 39232.52734375]
 [ 31226.49609375]]
DEBUG:root:training time = %d0.208426
INFO:root:frame =5089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root:frame =5090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000560998916626
DEBUG:root: save sample needs time = 0.000141859054565
INFO:root:random_action_porb = 0.959846666667
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root:frame =5093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000380992889404
INFO:root:frame =5094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00030517578125
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.959815
DEBUG:root: dqn, choose action rondomly, need time 0.000191000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00015115737915
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 31191.30273438]
 [ 33544.421875  ]
 [ 34842.1953125 ]
 [ 40667.015625  ]
 [ 37200.578125  ]
 [ 35154.96875   ]
 [ 38033.5703125 ]
 [ 38687.31640625]
 [ 32131.52539062]
 [ 37769.68359375]
 [ 40667.015625  ]
 [ 39415.625     ]
 [ 40588.4765625 ]
 [ 31443.4453125 ]
 [ 39534.66015625]
 [ 31337.125     ]]
DEBUG:root:training time = %d0.212831
INFO:root:frame =5097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =5098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427007675171
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.959783333333
DEBUG:root: dqn, choose action rondomly, need time 0.000459000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =5101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =5102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 0.000131130218506
INFO:root:random_action_porb = 0.959751666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302999999988
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:training error  = [[ 38899.375     ]
 [ 38328.9609375 ]
 [ 34332.578125  ]
 [ 37330.08984375]
 [ 40262.734375  ]
 [ 36814.515625  ]
 [ 33935.37890625]
 [ 35115.15625   ]
 [ 35167.23828125]
 [ 35160.27734375]
 [ 32958.46875   ]
 [ 35449.09375   ]
 [ 37492.15234375]
 [ 39037.2109375 ]
 [ 32670.20898438]
 [ 34901.5546875 ]]
DEBUG:root:training time = %d0.216284
INFO:root:frame =5105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =5106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294923782349
DEBUG:root: save sample needs time = 0.000149011611938
INFO:root:random_action_porb = 0.95972
DEBUG:root: dqn, choose action rondomly, need time 0.000352000000021
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00035285949707
INFO:root:frame =5109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =5110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root:random_action_porb = 0.959688333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000015
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 32813.07421875]
 [ 49913.40625   ]
 [ 34633.06640625]
 [ 33338.87109375]
 [ 39637.640625  ]
 [ 36197.5703125 ]
 [ 35721.4609375 ]
 [ 45117.5546875 ]
 [ 38995.64453125]
 [ 36451.0703125 ]
 [ 47091.01171875]
 [ 32385.32421875]
 [ 47091.01171875]
 [ 34578.47265625]
 [ 40376.37109375]
 [ 35721.4609375 ]]
DEBUG:root:training time = %d0.226326
INFO:root:frame =5113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =5114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000461101531982
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.959656666667
DEBUG:root: dqn, choose action rondomly, need time 0.000397000000021
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root:frame =5117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00042986869812
INFO:root:frame =5118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319004058838
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.959625
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000385999679565
INFO:root:training error  = [[ 45678.625     ]
 [ 37492.71875   ]
 [ 50753.40234375]
 [ 29462.59960938]
 [ 46556.91015625]
 [ 37492.71875   ]
 [ 38720.171875  ]
 [ 47899.        ]
 [ 39118.09765625]
 [ 39172.296875  ]
 [ 48304.55078125]
 [ 31468.04101562]
 [ 51571.68359375]
 [ 37492.71875   ]
 [ 47102.03515625]
 [ 51102.046875  ]]
DEBUG:root:training time = %d0.225158
INFO:root:frame =5121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =5122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame = 5123 State into memory, numbers recorded 134 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000584125518799
INFO:root:random_action_porb = 0.959593333333
DEBUG:root: dqn, choose action rondomly, need time 0.000243000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5124current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =5125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000481843948364
INFO:root:frame =5126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.959561666667
DEBUG:root: dqn, choose action rondomly, need time 0.000323000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 42905.62109375]
 [ 46779.796875  ]
 [ 46139.1640625 ]
 [ 39215.50390625]
 [ 45788.7890625 ]
 [ 44536.96875   ]
 [ 42392.35546875]
 [ 40879.8828125 ]
 [ 44261.234375  ]
 [ 40485.94140625]
 [ 45916.03515625]
 [ 33569.6484375 ]
 [ 45788.7890625 ]
 [ 33639.28515625]
 [ 40391.3828125 ]
 [ 36946.359375  ]]
DEBUG:root:training time = %d0.218242
INFO:root:frame =5129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =5130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.95953
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312805175781
INFO:root:frame =5133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456809997559
INFO:root:frame =5134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:random_action_porb = 0.959498333333
DEBUG:root: dqn, choose action rondomly, need time 0.000337000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000140190124512
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 43387.3828125 ]
 [ 35895.81640625]
 [ 41285.2578125 ]
 [ 45028.40625   ]
 [ 32842.44921875]
 [ 41408.47265625]
 [ 50615.11328125]
 [ 44070.578125  ]
 [ 38770.53125   ]
 [ 33355.7265625 ]
 [ 44837.85546875]
 [ 51789.9140625 ]
 [ 51015.10546875]
 [ 34873.73828125]
 [ 44454.5703125 ]
 [ 44824.93359375]]
DEBUG:root:training time = %d0.221541
INFO:root:frame =5137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =5138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000314950942993
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.959466666667
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =5141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =5142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000487089157104
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.959435
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 47246.265625  ]
 [ 45309.83984375]
 [ 42795.8515625 ]
 [ 34721.35546875]
 [ 43852.41015625]
 [ 39356.12890625]
 [ 45256.12109375]
 [ 42998.921875  ]
 [ 39816.91015625]
 [ 38223.3984375 ]
 [ 38224.83203125]
 [ 38224.83203125]
 [ 35310.8671875 ]
 [ 42037.4140625 ]
 [ 32424.17382812]
 [ 34721.35546875]]
DEBUG:root:training time = %d0.202793
INFO:root:frame =5145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =5146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
DEBUG:root: save sample needs time = 0.000170946121216
INFO:root:random_action_porb = 0.959403333333
DEBUG:root: dqn, choose action rondomly, need time 0.000243999999981
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =5149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =5150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000354051589966
DEBUG:root: save sample needs time = 0.000144958496094
INFO:root:random_action_porb = 0.959371666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295000000023
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:training error  = [[ 33521.80078125]
 [ 34893.52734375]
 [ 44518.01171875]
 [ 45855.7890625 ]
 [ 33693.48828125]
 [ 35533.81640625]
 [ 30040.60742188]
 [ 51454.984375  ]
 [ 41283.76953125]
 [ 45873.35546875]
 [ 38926.34765625]
 [ 41304.30859375]
 [ 40417.09765625]
 [ 42689.55078125]
 [ 45664.64453125]
 [ 51927.79296875]]
DEBUG:root:training time = %d0.213727
INFO:root:frame =5153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =5154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00041389465332
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.95934
DEBUG:root: dqn, choose action rondomly, need time 0.000355000000013
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000520944595337
INFO:root:frame =5157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440835952759
INFO:root:frame =5158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00051212310791
INFO:root:frame = 5159 State into memory, numbers recorded 135 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000428915023804
INFO:root:random_action_porb = 0.959308333333
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5160current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:training error  = [[ 49578.3046875 ]
 [ 43917.0546875 ]
 [ 42180.09375   ]
 [ 43227.2421875 ]
 [ 46876.265625  ]
 [ 43531.625     ]
 [ 31870.0078125 ]
 [ 44126.97265625]
 [ 43573.80859375]
 [ 48351.3515625 ]
 [ 44423.1796875 ]
 [ 35630.80078125]
 [ 53929.62890625]
 [ 43558.21875   ]
 [ 43531.625     ]
 [ 48314.53125   ]]
DEBUG:root:training time = %d0.218376
INFO:root:frame =5161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =5162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000316143035889
DEBUG:root: save sample needs time = 0.000100135803223
INFO:root:random_action_porb = 0.959276666667
DEBUG:root: dqn, choose action rondomly, need time 0.000214999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame =5165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =5166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.959245
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 38520.1953125 ]
 [ 46531.3125    ]
 [ 35486.98046875]
 [ 40976.98828125]
 [ 35778.515625  ]
 [ 35223.94140625]
 [ 43335.328125  ]
 [ 36032.5859375 ]
 [ 47737.44921875]
 [ 42080.671875  ]
 [ 37683.6640625 ]
 [ 39031.1328125 ]
 [ 47081.796875  ]
 [ 35516.14453125]
 [ 45754.109375  ]
 [ 34464.796875  ]]
DEBUG:root:training time = %d0.214866
INFO:root:frame =5169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =5170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000508069992065
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:random_action_porb = 0.959213333333
DEBUG:root: dqn, choose action rondomly, need time 0.000247999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000285863876343
INFO:root:frame =5173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =5174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000221014022827
DEBUG:root: save sample needs time = 0.000103950500488
INFO:root:random_action_porb = 0.959181666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5176 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 45105.21484375]
 [ 41416.32421875]
 [ 41281.88671875]
 [ 40165.50390625]
 [ 48687.34765625]
 [ 46614.2421875 ]
 [ 40072.296875  ]
 [ 51884.85546875]
 [ 48036.73828125]
 [ 35550.9375    ]
 [ 51706.828125  ]
 [ 36807.5859375 ]
 [ 38960.6484375 ]
 [ 42252.52734375]
 [ 53765.7890625 ]
 [ 40290.95703125]]
DEBUG:root:training time = %d0.220668
INFO:root:frame =5177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000417947769165
INFO:root:frame =5178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491142272949
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.95915
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =5181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000450134277344
INFO:root:frame =5182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440120697021
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.959118333333
DEBUG:root: dqn, choose action rondomly, need time 0.00044699999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 47504.94921875]
 [ 39717.78515625]
 [ 52264.8125    ]
 [ 49982.703125  ]
 [ 53141.6171875 ]
 [ 53141.6171875 ]
 [ 37795.59375   ]
 [ 41819.15234375]
 [ 47818.8828125 ]
 [ 46753.08203125]
 [ 49982.703125  ]
 [ 52188.82421875]
 [ 35982.921875  ]
 [ 41472.5859375 ]
 [ 48195.46875   ]
 [ 48085.015625  ]]
DEBUG:root:training time = %d0.230195
INFO:root:frame =5185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =5186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000243902206421
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:random_action_porb = 0.959086666667
DEBUG:root: dqn, choose action rondomly, need time 0.000166000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root:frame =5189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =5190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000379085540771
DEBUG:root: save sample needs time = 0.000102043151855
INFO:root:random_action_porb = 0.959055
DEBUG:root: dqn, choose action rondomly, need time 0.000240000000019
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 52141.42578125]
 [ 42522.546875  ]
 [ 36596.26953125]
 [ 36303.92578125]
 [ 50583.80859375]
 [ 53464.3671875 ]
 [ 34623.16015625]
 [ 51464.40234375]
 [ 50690.05859375]
 [ 53725.37890625]
 [ 48345.4453125 ]
 [ 47963.56640625]
 [ 43846.171875  ]
 [ 56260.2265625 ]
 [ 37042.71484375]
 [ 46264.0625    ]]
DEBUG:root:training time = %d0.183782
INFO:root:frame =5193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000401973724365
INFO:root:frame =5194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000251054763794
DEBUG:root: save sample needs time = 0.000108003616333
INFO:root:random_action_porb = 0.959023333333
DEBUG:root: dqn, choose action rondomly, need time 0.000421999999986
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =5197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:frame =5198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
DEBUG:root: save sample needs time = 0.000139951705933
INFO:root:random_action_porb = 0.958991666667
DEBUG:root: dqn, choose action rondomly, need time 0.000529
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000315189361572
INFO:root:training error  = [[ 47990.41015625]
 [ 38610.6171875 ]
 [ 49505.1640625 ]
 [ 49584.50390625]
 [ 39293.96484375]
 [ 38451.515625  ]
 [ 48718.3828125 ]
 [ 55240.26171875]
 [ 45799.13671875]
 [ 50890.66796875]
 [ 47737.6640625 ]
 [ 39588.078125  ]
 [ 45516.28515625]
 [ 45833.4140625 ]
 [ 52507.328125  ]
 [ 49584.50390625]]
DEBUG:root:training time = %d0.208136
INFO:root:frame =5201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =5202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000258922576904
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.95896
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =5205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000571012496948
INFO:root:frame =5206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449180603027
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.958928333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:training error  = [[ 41960.9609375 ]
 [ 49713.6484375 ]
 [ 41104.        ]
 [ 42242.99609375]
 [ 44647.609375  ]
 [ 48631.5546875 ]
 [ 37842.12109375]
 [ 41012.48046875]
 [ 44126.4609375 ]
 [ 41288.6328125 ]
 [ 44010.22265625]
 [ 42910.0703125 ]
 [ 54057.38671875]
 [ 38647.46875   ]
 [ 48784.796875  ]
 [ 39325.13671875]]
DEBUG:root:training time = %d0.241226
INFO:root:frame =5209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =5210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324010848999
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root:random_action_porb = 0.958896666667
DEBUG:root: dqn, choose action rondomly, need time 0.000324000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000155925750732
INFO:root:frame =5213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =5214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000280141830444
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.958865
DEBUG:root: dqn, choose action rondomly, need time 0.000325000000004
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 41755.26953125]
 [ 49311.86328125]
 [ 43603.4765625 ]
 [ 48314.1015625 ]
 [ 40337.03515625]
 [ 58218.41015625]
 [ 58467.3828125 ]
 [ 39745.1328125 ]
 [ 40636.890625  ]
 [ 44989.66015625]
 [ 40439.578125  ]
 [ 44124.3046875 ]
 [ 49311.86328125]
 [ 42015.9921875 ]
 [ 60544.109375  ]
 [ 48723.234375  ]]
DEBUG:root:training time = %d0.216573
INFO:root:frame =5217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =5218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000300884246826
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.958833333333
DEBUG:root: dqn, choose action rondomly, need time 0.000240999999988
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000192880630493
INFO:root:frame =5221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =5222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000124931335449
INFO:root:random_action_porb = 0.958801666667
DEBUG:root: dqn, choose action rondomly, need time 0.000209000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000172138214111
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 45373.3671875 ]
 [ 57490.24609375]
 [ 52697.484375  ]
 [ 51710.71484375]
 [ 42796.55859375]
 [ 52884.6171875 ]
 [ 53605.9296875 ]
 [ 56522.625     ]
 [ 58469.98046875]
 [ 54595.8125    ]
 [ 37393.984375  ]
 [ 54489.53125   ]
 [ 43410.984375  ]
 [ 46990.08984375]
 [ 44696.421875  ]
 [ 38726.703125  ]]
DEBUG:root:training time = %d0.186391
INFO:root:frame =5225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =5226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
DEBUG:root: save sample needs time = 0.000123977661133
INFO:root:random_action_porb = 0.95877
DEBUG:root: dqn, choose action rondomly, need time 0.000257000000005
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =5229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =5230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000872135162354
INFO:root:frame = 5231 State into memory, numbers recorded 136 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000547170639038
INFO:root:random_action_porb = 0.958738333333
DEBUG:root: dqn, choose action rondomly, need time 0.000410000000016
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5232current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:training error  = [[ 38235.4296875 ]
 [ 42465.6796875 ]
 [ 40317.62109375]
 [ 48085.23046875]
 [ 39889.04296875]
 [ 57318.2734375 ]
 [ 58378.15625   ]
 [ 54004.26953125]
 [ 39154.2265625 ]
 [ 39484.7734375 ]
 [ 53754.6953125 ]
 [ 52564.51953125]
 [ 56132.08984375]
 [ 60308.85546875]
 [ 45984.69921875]
 [ 48085.23046875]]
DEBUG:root:training time = %d0.230735
INFO:root:frame =5233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =5234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame = 5235 State into memory, numbers recorded 137 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000545978546143
INFO:root:random_action_porb = 0.958706666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5236current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =5237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000555992126465
INFO:root:frame =5238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000602960586548
DEBUG:root: save sample needs time = 0.000108957290649
INFO:root:random_action_porb = 0.958675
DEBUG:root: dqn, choose action rondomly, need time 0.000440999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 41937.16015625]
 [ 55338.08203125]
 [ 50791.140625  ]
 [ 52546.83203125]
 [ 54058.40625   ]
 [ 50366.6015625 ]
 [ 52546.83203125]
 [ 48372.3984375 ]
 [ 41621.37890625]
 [ 42371.1484375 ]
 [ 55838.63671875]
 [ 43717.64453125]
 [ 50444.765625  ]
 [ 39631.03125   ]
 [ 41621.37890625]
 [ 43822.25      ]]
DEBUG:root:training time = %d0.205546
INFO:root:frame =5241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00028920173645
INFO:root:frame =5242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000270843505859
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:random_action_porb = 0.958643333333
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =5245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00050687789917
INFO:root:frame =5246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000498056411743
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.958611666667
DEBUG:root: dqn, choose action rondomly, need time 0.000275000000016
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:training error  = [[ 43850.16015625]
 [ 50549.00390625]
 [ 51003.4140625 ]
 [ 50997.23828125]
 [ 42365.21875   ]
 [ 42350.64453125]
 [ 44799.40234375]
 [ 52270.6171875 ]
 [ 42446.05859375]
 [ 43219.52734375]
 [ 42201.15625   ]
 [ 47276.8359375 ]
 [ 46542.5859375 ]
 [ 43675.38671875]
 [ 43675.38671875]
 [ 42727.8984375 ]]
DEBUG:root:training time = %d0.214324
INFO:root:frame =5249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =5250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000333070755005
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.95858
DEBUG:root: dqn, choose action rondomly, need time 0.000376000000017
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000545024871826
INFO:root:frame =5253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =5254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:random_action_porb = 0.958548333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 50930.        ]
 [ 43824.19140625]
 [ 43353.3203125 ]
 [ 64067.94140625]
 [ 52004.0390625 ]
 [ 52147.78125   ]
 [ 42223.828125  ]
 [ 41929.66015625]
 [ 43433.1640625 ]
 [ 44638.83984375]
 [ 47717.609375  ]
 [ 45245.94140625]
 [ 64067.94140625]
 [ 65376.59765625]
 [ 47336.5234375 ]
 [ 52147.78125   ]]
DEBUG:root:training time = %d0.241014
INFO:root:frame =5257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root:frame =5258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root:random_action_porb = 0.958516666667
DEBUG:root: dqn, choose action rondomly, need time 0.000380999999976
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =5261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460863113403
INFO:root:frame =5262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.958485
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 44376.87890625]
 [ 50136.3046875 ]
 [ 41782.61328125]
 [ 55204.921875  ]
 [ 44122.765625  ]
 [ 44462.70703125]
 [ 61428.58203125]
 [ 45728.41796875]
 [ 56978.1328125 ]
 [ 41906.26953125]
 [ 41513.06640625]
 [ 51691.17578125]
 [ 58854.5703125 ]
 [ 50071.7109375 ]
 [ 59074.98828125]
 [ 42121.046875  ]]
DEBUG:root:training time = %d0.226693
INFO:root:frame =5265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263214111328
INFO:root:frame =5266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000385999679565
INFO:root:random_action_porb = 0.958453333333
DEBUG:root: dqn, choose action rondomly, need time 0.000231999999983
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000136137008667
INFO:root:frame =5269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =5270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.958421666667
INFO:root:dqn select action Tensor("ArgMax_22:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014209
INFO:root:action choosen by dqn [4]
INFO:root:frame =5272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 42736.17578125]
 [ 43687.6328125 ]
 [ 41474.57421875]
 [ 53954.91796875]
 [ 44339.13671875]
 [ 56406.1328125 ]
 [ 44232.375     ]
 [ 54372.87890625]
 [ 43067.69921875]
 [ 52846.109375  ]
 [ 58127.7265625 ]
 [ 61046.515625  ]
 [ 53852.09765625]
 [ 41058.375     ]
 [ 52937.8515625 ]
 [ 44878.6015625 ]]
DEBUG:root:training time = %d0.233054
INFO:root:frame =5273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =5274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000282049179077
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.95839
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5276 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =5277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =5278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000607013702393
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:random_action_porb = 0.958358333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 39482.8359375 ]
 [ 64329.23046875]
 [ 54648.078125  ]
 [ 42585.09765625]
 [ 46515.515625  ]
 [ 44536.8671875 ]
 [ 43099.421875  ]
 [ 58274.03125   ]
 [ 65115.67578125]
 [ 56652.25      ]
 [ 56383.17578125]
 [ 53509.19921875]
 [ 44536.8671875 ]
 [ 57757.9609375 ]
 [ 67886.203125  ]
 [ 44335.94921875]]
DEBUG:root:training time = %d0.228281
INFO:root:frame =5281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =5282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.958326666667
DEBUG:root: dqn, choose action rondomly, need time 0.000452999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:frame =5285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000467777252197
INFO:root:frame =5286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000343084335327
DEBUG:root: save sample needs time = 0.000229835510254
INFO:root:random_action_porb = 0.958295
DEBUG:root: dqn, choose action rondomly, need time 0.000317000000024
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5288 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 57518.23046875]
 [ 50122.640625  ]
 [ 58415.796875  ]
 [ 46173.6796875 ]
 [ 58795.7109375 ]
 [ 52321.984375  ]
 [ 57138.2734375 ]
 [ 51876.95703125]
 [ 62357.2578125 ]
 [ 60621.38671875]
 [ 43442.73046875]
 [ 50715.45703125]
 [ 50205.64453125]
 [ 50790.91796875]
 [ 56956.6875    ]
 [ 53225.05859375]]
DEBUG:root:training time = %d0.216382
INFO:root:frame =5289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =5290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000492095947266
INFO:root:frame = 5291 State into memory, numbers recorded 138 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000356912612915
INFO:root:random_action_porb = 0.958263333333
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5292current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000184059143066
INFO:root:frame =5293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =5294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame = 5295 State into memory, numbers recorded 139 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000576019287109
INFO:root:random_action_porb = 0.958231666667
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5296current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 43706.6171875 ]
 [ 48616.05078125]
 [ 65223.125     ]
 [ 50552.95703125]
 [ 46207.15625   ]
 [ 53982.9375    ]
 [ 53388.9765625 ]
 [ 46742.5234375 ]
 [ 53388.9765625 ]
 [ 51032.53125   ]
 [ 45335.1015625 ]
 [ 51995.69140625]
 [ 49851.24609375]
 [ 48055.46875   ]
 [ 53423.0546875 ]
 [ 50111.48828125]]
DEBUG:root:training time = %d0.211756
INFO:root:frame =5297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =5298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000157117843628
INFO:root:random_action_porb = 0.9582
DEBUG:root: dqn, choose action rondomly, need time 0.000237999999996
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:frame =5301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =5302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000254154205322
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:random_action_porb = 0.958168333333
DEBUG:root: dqn, choose action rondomly, need time 0.000360999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000385999679565
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 47075.6484375 ]
 [ 54052.6171875 ]
 [ 48138.67578125]
 [ 63470.04296875]
 [ 54052.6171875 ]
 [ 49344.2890625 ]
 [ 50918.09765625]
 [ 51798.46875   ]
 [ 48768.296875  ]
 [ 51994.91015625]
 [ 60322.765625  ]
 [ 60449.953125  ]
 [ 61889.1953125 ]
 [ 51382.3515625 ]
 [ 49273.8125    ]
 [ 47877.4140625 ]]
DEBUG:root:training time = %d0.228836
INFO:root:frame =5305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =5306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000377893447876
DEBUG:root: save sample needs time = 0.000123977661133
INFO:root:random_action_porb = 0.958136666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =5309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =5310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00062894821167
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.958105
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999981
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293970108032
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 49402.0078125 ]
 [ 59426.203125  ]
 [ 66530.4921875 ]
 [ 57196.4140625 ]
 [ 67281.7265625 ]
 [ 50137.7265625 ]
 [ 48024.96875   ]
 [ 50930.87890625]
 [ 57736.01953125]
 [ 58549.34765625]
 [ 70890.625     ]
 [ 58682.6953125 ]
 [ 65610.2734375 ]
 [ 58851.25390625]
 [ 66580.8828125 ]
 [ 58531.62890625]]
DEBUG:root:training time = %d0.215721
INFO:root:frame =5313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame =5314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262975692749
DEBUG:root: save sample needs time = 0.000285148620605
INFO:root:random_action_porb = 0.958073333333
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =5317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =5318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.958041666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 71679.8671875 ]
 [ 64701.42578125]
 [ 70857.0859375 ]
 [ 70898.421875  ]
 [ 73025.296875  ]
 [ 70857.0859375 ]
 [ 59718.42578125]
 [ 58204.15234375]
 [ 67494.4140625 ]
 [ 72109.296875  ]
 [ 73875.6640625 ]
 [ 64701.42578125]
 [ 48255.08984375]
 [ 50010.54296875]
 [ 46412.265625  ]
 [ 56181.03515625]]
DEBUG:root:training time = %d0.228087
INFO:root:frame =5321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =5322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
DEBUG:root: save sample needs time = 0.000274896621704
INFO:root:random_action_porb = 0.95801
DEBUG:root: dqn, choose action rondomly, need time 0.000369000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame =5325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =5326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:random_action_porb = 0.957978333333
DEBUG:root: dqn, choose action rondomly, need time 0.000325000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:training error  = [[ 65551.        ]
 [ 52325.890625  ]
 [ 59050.1875    ]
 [ 63352.7421875 ]
 [ 55833.67578125]
 [ 53373.40625   ]
 [ 57674.5546875 ]
 [ 60812.8125    ]
 [ 54034.2265625 ]
 [ 49922.3515625 ]
 [ 59957.0703125 ]
 [ 55833.67578125]
 [ 53292.89453125]
 [ 63820.87109375]
 [ 62416.53125   ]
 [ 58968.34375   ]]
DEBUG:root:training time = %d0.238563
INFO:root:frame =5329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:frame =5330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000284910202026
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.957946666667
DEBUG:root: dqn, choose action rondomly, need time 0.000204000000025
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5332 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000186920166016
INFO:root:frame =5333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =5334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.957915
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 68503.6015625 ]
 [ 58626.40625   ]
 [ 49768.64453125]
 [ 57540.953125  ]
 [ 53128.67578125]
 [ 57048.66796875]
 [ 57920.3671875 ]
 [ 49668.6953125 ]
 [ 55552.28125   ]
 [ 61704.453125  ]
 [ 58594.7265625 ]
 [ 51071.3671875 ]
 [ 62686.41796875]
 [ 70481.4375    ]
 [ 57911.19921875]
 [ 52932.125     ]]
DEBUG:root:training time = %d0.234349
INFO:root:frame =5337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000315189361572
INFO:root:frame =5338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000328779220581
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.957883333333
INFO:root:dqn select action Tensor("ArgMax_23:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.015382
INFO:root:action choosen by dqn [4]
INFO:root:frame =5340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159978866577
INFO:root:frame =5341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000432014465332
INFO:root:frame =5342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441789627075
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.957851666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:training error  = [[ 67838.8828125 ]
 [ 51556.71484375]
 [ 61670.98046875]
 [ 62999.0390625 ]
 [ 50280.8359375 ]
 [ 51077.98828125]
 [ 50562.17578125]
 [ 67674.1640625 ]
 [ 50550.1015625 ]
 [ 50989.30078125]
 [ 66962.4296875 ]
 [ 53214.01953125]
 [ 49768.20703125]
 [ 61694.9921875 ]
 [ 69644.4453125 ]
 [ 49465.41015625]]
DEBUG:root:training time = %d0.208717
INFO:root:frame =5345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:frame =5346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.95782
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =5349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000566959381104
INFO:root:frame =5350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:random_action_porb = 0.957788333333
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000018
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 57910.96484375]
 [ 56709.09765625]
 [ 63148.40234375]
 [ 47205.8359375 ]
 [ 68102.3984375 ]
 [ 53438.40234375]
 [ 55264.25      ]
 [ 43909.07421875]
 [ 60543.390625  ]
 [ 54051.02734375]
 [ 47205.8359375 ]
 [ 64484.99609375]
 [ 69255.8359375 ]
 [ 63575.6328125 ]
 [ 48001.        ]
 [ 60615.015625  ]]
DEBUG:root:training time = %d0.228544
INFO:root:frame =5353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =5354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame = 5355 State into memory, numbers recorded 140 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000572919845581
INFO:root:random_action_porb = 0.957756666667
DEBUG:root: dqn, choose action rondomly, need time 0.000360999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5356current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000326156616211
INFO:root:frame =5357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000594854354858
INFO:root:frame =5358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:random_action_porb = 0.957725
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000016
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 51168.515625  ]
 [ 58850.78125   ]
 [ 62333.36328125]
 [ 67732.6015625 ]
 [ 48648.89453125]
 [ 57621.09375   ]
 [ 67925.8984375 ]
 [ 51168.515625  ]
 [ 62928.95703125]
 [ 49123.26953125]
 [ 67732.6015625 ]
 [ 52555.33984375]
 [ 62239.28515625]
 [ 62934.8359375 ]
 [ 66525.9609375 ]
 [ 49860.40234375]]
DEBUG:root:training time = %d0.217593
INFO:root:frame =5361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:frame =5362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000496864318848
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.957693333333
INFO:root:dqn select action Tensor("ArgMax_24:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013726
INFO:root:action choosen by dqn [2]
INFO:root:frame =5364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:frame =5365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000491857528687
INFO:root:frame =5366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000645875930786
DEBUG:root: save sample needs time = 0.000156879425049
INFO:root:random_action_porb = 0.957661666667
DEBUG:root: dqn, choose action rondomly, need time 0.000537000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:training error  = [[ 53304.16796875]
 [ 50288.9375    ]
 [ 75323.7109375 ]
 [ 75350.515625  ]
 [ 50506.19921875]
 [ 57928.59375   ]
 [ 64182.5625    ]
 [ 68467.5703125 ]
 [ 61995.1640625 ]
 [ 59770.9375    ]
 [ 52722.03515625]
 [ 72041.65625   ]
 [ 64406.16015625]
 [ 76550.8359375 ]
 [ 65475.265625  ]
 [ 61161.78125   ]]
DEBUG:root:training time = %d0.220772
INFO:root:frame =5369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =5370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
INFO:root: ememy has been killed for 8 times 
INFO:root:enemies_left [0]
INFO:root:frame = 5371 State into memory, numbers recorded 141 action = 1, reward = 1
DEBUG:root: save sample needs time = 0.000366926193237
INFO:root:random_action_porb = 0.95763
DEBUG:root: dqn, choose action rondomly, need time 0.000416000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5372current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000845909118652
INFO:root:frame =5373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =5374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047492980957
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:random_action_porb = 0.957598333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:training error  = [[ 69321.8984375 ]
 [ 69674.34375   ]
 [ 58232.1953125 ]
 [ 51922.7890625 ]
 [ 63075.29296875]
 [ 53323.33203125]
 [ 62498.78125   ]
 [ 69669.1875    ]
 [ 70294.375     ]
 [ 53457.3671875 ]
 [ 53323.33203125]
 [ 53565.125     ]
 [ 58953.87890625]
 [ 58741.6171875 ]
 [ 61850.81640625]
 [ 66644.1484375 ]]
DEBUG:root:training time = %d0.222273
INFO:root:frame =5377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =5378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.957566666667
DEBUG:root: dqn, choose action rondomly, need time 0.000173000000018
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000152111053467
INFO:root:frame =5381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:frame =5382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.957535
DEBUG:root: dqn, choose action rondomly, need time 0.000308000000018
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:training error  = [[ 54755.54296875]
 [ 54778.3984375 ]
 [ 53934.62109375]
 [ 68184.2265625 ]
 [ 54503.78125   ]
 [ 64732.23046875]
 [ 70018.3828125 ]
 [ 57303.1953125 ]
 [ 56626.10546875]
 [ 61744.7265625 ]
 [ 53460.98046875]
 [ 58143.85546875]
 [ 54441.78515625]
 [ 60184.9296875 ]
 [ 56690.26171875]
 [ 58303.3828125 ]]
DEBUG:root:training time = %d0.220629
INFO:root:frame =5385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =5386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288963317871
DEBUG:root: save sample needs time = 0.000185012817383
INFO:root:random_action_porb = 0.957503333333
DEBUG:root: dqn, choose action rondomly, need time 0.000238999999993
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =5389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:frame =5390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000379085540771
DEBUG:root: save sample needs time = 0.00018310546875
INFO:root:random_action_porb = 0.957471666667
DEBUG:root: dqn, choose action rondomly, need time 0.000661000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 67354.1875    ]
 [ 48768.078125  ]
 [ 59848.796875  ]
 [ 67925.8984375 ]
 [ 59848.796875  ]
 [ 60874.71875   ]
 [ 58756.29296875]
 [ 52633.5       ]
 [ 59334.34765625]
 [ 61581.0390625 ]
 [ 53963.19921875]
 [ 64214.9765625 ]
 [ 69008.0546875 ]
 [ 56812.1640625 ]
 [ 53313.41015625]
 [ 65760.6953125 ]]
DEBUG:root:training time = %d0.215143
INFO:root:frame =5393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =5394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.95744
DEBUG:root: dqn, choose action rondomly, need time 0.000479000000013
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =5397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =5398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.957408333333
INFO:root:dqn select action Tensor("ArgMax_25:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013615
INFO:root:action choosen by dqn [2]
INFO:root:frame =5400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 56089.41015625]
 [ 53706.4765625 ]
 [ 59201.44921875]
 [ 60290.62890625]
 [ 60999.109375  ]
 [ 58299.61328125]
 [ 58732.38671875]
 [ 59837.80859375]
 [ 58795.59375   ]
 [ 62145.28125   ]
 [ 56608.2109375 ]
 [ 63286.640625  ]
 [ 61229.6640625 ]
 [ 69268.6875    ]
 [ 56839.63671875]
 [ 58299.61328125]]
DEBUG:root:training time = %d0.192995
INFO:root:frame =5401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =5402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000445127487183
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:random_action_porb = 0.957376666667
DEBUG:root: dqn, choose action rondomly, need time 0.00022899999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000131130218506
INFO:root:frame =5405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000496864318848
INFO:root:frame =5406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000356912612915
INFO:root:random_action_porb = 0.957345
DEBUG:root: dqn, choose action rondomly, need time 0.000483000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:training error  = [[ 68965.21875   ]
 [ 63506.21484375]
 [ 78169.390625  ]
 [ 55859.0625    ]
 [ 58386.1796875 ]
 [ 65117.91796875]
 [ 61285.7421875 ]
 [ 56773.53125   ]
 [ 72287.7265625 ]
 [ 81240.3046875 ]
 [ 59883.44140625]
 [ 57324.47265625]
 [ 57424.3515625 ]
 [ 56046.86328125]
 [ 61949.703125  ]
 [ 62126.05078125]]
DEBUG:root:training time = %d0.225005
INFO:root:frame =5409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000304222106934
INFO:root:frame =5410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324010848999
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.957313333333
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =5413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =5414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.957281666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 70765.3515625 ]
 [ 68017.5546875 ]
 [ 69226.546875  ]
 [ 68191.3671875 ]
 [ 64683.29296875]
 [ 72468.21875   ]
 [ 57819.11328125]
 [ 74424.265625  ]
 [ 58445.421875  ]
 [ 71627.5859375 ]
 [ 69204.1875    ]
 [ 69932.1015625 ]
 [ 57999.36328125]
 [ 57447.9921875 ]
 [ 70866.4453125 ]
 [ 70415.078125  ]]
DEBUG:root:training time = %d0.227684
INFO:root:frame =5417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =5418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231981277466
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:random_action_porb = 0.95725
DEBUG:root: dqn, choose action rondomly, need time 0.000382000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =5421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =5422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000588893890381
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.957218333333
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 76903.3046875 ]
 [ 60880.50390625]
 [ 54431.76171875]
 [ 61404.015625  ]
 [ 78902.2890625 ]
 [ 83865.671875  ]
 [ 53204.109375  ]
 [ 76503.8359375 ]
 [ 60880.50390625]
 [ 66891.1875    ]
 [ 59770.69921875]
 [ 78080.6796875 ]
 [ 59925.75      ]
 [ 66620.953125  ]
 [ 79231.8046875 ]
 [ 82167.609375  ]]
DEBUG:root:training time = %d0.225478
INFO:root:frame =5425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:frame =5426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
DEBUG:root: save sample needs time = 0.000239849090576
INFO:root:random_action_porb = 0.957186666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:frame =5429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000484943389893
INFO:root:frame =5430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456809997559
INFO:root:frame = 5431 State into memory, numbers recorded 142 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000565052032471
INFO:root:random_action_porb = 0.957155
DEBUG:root: dqn, choose action rondomly, need time 0.000325000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5432current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000244140625
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 61879.234375  ]
 [ 80106.96875   ]
 [ 65627.03125   ]
 [ 62720.65234375]
 [ 69753.25      ]
 [ 56736.54296875]
 [ 73303.4453125 ]
 [ 66067.828125  ]
 [ 79875.5078125 ]
 [ 81891.546875  ]
 [ 73606.5       ]
 [ 79434.25      ]
 [ 64404.67578125]
 [ 76274.953125  ]
 [ 65467.76953125]
 [ 83059.9140625 ]]
DEBUG:root:training time = %d0.191426
INFO:root:frame =5433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =5434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 9.91821289062e-05
INFO:root:random_action_porb = 0.957123333333
DEBUG:root: dqn, choose action rondomly, need time 0.000202999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000222206115723
INFO:root:frame =5437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00044584274292
INFO:root:frame =5438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000839948654175
DEBUG:root: save sample needs time = 0.000182151794434
INFO:root:random_action_porb = 0.957091666667
DEBUG:root: dqn, choose action rondomly, need time 0.00021799999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 83772.9375    ]
 [ 83548.6640625 ]
 [ 78086.1328125 ]
 [ 70180.7578125 ]
 [ 57353.93359375]
 [ 66751.5859375 ]
 [ 78086.1328125 ]
 [ 74940.6640625 ]
 [ 83131.421875  ]
 [ 78036.4765625 ]
 [ 71944.4375    ]
 [ 59775.953125  ]
 [ 68902.40625   ]
 [ 72987.828125  ]
 [ 60940.03125   ]
 [ 80548.984375  ]]
DEBUG:root:training time = %d0.174748
INFO:root:frame =5441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000357151031494
INFO:root:frame =5442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
DEBUG:root: save sample needs time = 0.00011682510376
INFO:root:random_action_porb = 0.95706
DEBUG:root: dqn, choose action rondomly, need time 0.000186000000014
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root:frame =5445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =5446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000280141830444
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.957028333333
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000148057937622
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 75851.0234375 ]
 [ 83333.703125  ]
 [ 82789.9453125 ]
 [ 84605.7109375 ]
 [ 83285.2265625 ]
 [ 85026.9140625 ]
 [ 79198.8203125 ]
 [ 59922.40234375]
 [ 69862.390625  ]
 [ 84340.046875  ]
 [ 83665.        ]
 [ 69479.609375  ]
 [ 73348.9296875 ]
 [ 58816.1953125 ]
 [ 73496.8515625 ]
 [ 61514.171875  ]]
DEBUG:root:training time = %d0.178861
INFO:root:frame =5449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =5450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433921813965
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.956996666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =5453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =5454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000225067138672
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.956965
DEBUG:root: dqn, choose action rondomly, need time 0.00017600000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5456 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000137805938721
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 62081.7578125 ]
 [ 67222.2109375 ]
 [ 62956.640625  ]
 [ 71415.515625  ]
 [ 74776.34375   ]
 [ 62803.34375   ]
 [ 72403.296875  ]
 [ 73100.53125   ]
 [ 68698.5078125 ]
 [ 68560.6171875 ]
 [ 68500.0234375 ]
 [ 60253.94921875]
 [ 61010.9296875 ]
 [ 75791.59375   ]
 [ 66002.828125  ]
 [ 80283.9609375 ]]
DEBUG:root:training time = %d0.188754
INFO:root:frame =5457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000385999679565
INFO:root:frame =5458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000317096710205
INFO:root:frame = 5459 State into memory, numbers recorded 143 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000389099121094
INFO:root:random_action_porb = 0.956933333333
DEBUG:root: dqn, choose action rondomly, need time 0.000191999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5460current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =5461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame =5462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000296115875244
DEBUG:root: save sample needs time = 0.000126838684082
INFO:root:random_action_porb = 0.956901666667
DEBUG:root: dqn, choose action rondomly, need time 0.000245000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000188112258911
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 71325.5078125 ]
 [ 66301.46875   ]
 [ 60715.80078125]
 [ 77020.34375   ]
 [ 86201.875     ]
 [ 88222.6328125 ]
 [ 67900.1953125 ]
 [ 71325.5078125 ]
 [ 88089.2578125 ]
 [ 71549.4609375 ]
 [ 90603.6484375 ]
 [ 61443.953125  ]
 [ 61443.953125  ]
 [ 88416.5       ]
 [ 71325.5078125 ]
 [ 85963.203125  ]]
DEBUG:root:training time = %d0.185355
INFO:root:frame =5465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000261783599854
INFO:root:frame =5466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000288009643555
DEBUG:root: save sample needs time = 0.00010085105896
INFO:root:random_action_porb = 0.95687
DEBUG:root: dqn, choose action rondomly, need time 0.000195000000019
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:frame =5469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =5470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000230073928833
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.956838333333
DEBUG:root: dqn, choose action rondomly, need time 0.000185000000016
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000174999237061
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 79442.78125   ]
 [ 81590.0078125 ]
 [ 74120.859375  ]
 [ 67443.9375    ]
 [ 64043.83984375]
 [ 80924.6953125 ]
 [ 64442.1015625 ]
 [ 79731.2265625 ]
 [ 64059.90625   ]
 [ 83298.46875   ]
 [ 73405.8046875 ]
 [ 68567.0078125 ]
 [ 71778.7265625 ]
 [ 63921.8125    ]
 [ 75083.7578125 ]
 [ 89100.2109375 ]]
DEBUG:root:training time = %d0.175403
INFO:root:frame =5473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =5474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000341892242432
DEBUG:root: save sample needs time = 0.000133037567139
INFO:root:random_action_porb = 0.956806666667
DEBUG:root: dqn, choose action rondomly, need time 0.000205999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000225782394409
INFO:root:frame =5477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =5478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame = 5479 State into memory, numbers recorded 144 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000358104705811
INFO:root:random_action_porb = 0.956775
DEBUG:root: dqn, choose action rondomly, need time 0.000189000000006
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5480current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000197172164917
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 87139.6953125 ]
 [ 88893.65625   ]
 [ 77838.        ]
 [ 89952.25      ]
 [ 82851.2109375 ]
 [ 76741.4453125 ]
 [ 94302.0703125 ]
 [ 65362.61328125]
 [ 87139.6953125 ]
 [ 76904.1171875 ]
 [ 82010.359375  ]
 [ 66248.9296875 ]
 [ 76741.4453125 ]
 [ 69589.5625    ]
 [ 79444.4296875 ]
 [ 87629.875     ]]
DEBUG:root:training time = %d0.201482
INFO:root:frame =5481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280141830444
INFO:root:frame =5482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000422954559326
DEBUG:root: save sample needs time = 9.91821289062e-05
INFO:root:random_action_porb = 0.956743333333
DEBUG:root: dqn, choose action rondomly, need time 0.000239999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =5485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =5486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000237941741943
DEBUG:root: save sample needs time = 0.000166893005371
INFO:root:random_action_porb = 0.956711666667
DEBUG:root: dqn, choose action rondomly, need time 0.000410999999986
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000375032424927
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 88371.7890625 ]
 [ 61563.8359375 ]
 [ 80481.921875  ]
 [ 67210.8125    ]
 [ 93531.140625  ]
 [ 90497.265625  ]
 [ 80662.65625   ]
 [ 94677.609375  ]
 [ 79029.34375   ]
 [ 90966.15625   ]
 [ 83140.9921875 ]
 [ 63986.51953125]
 [ 75656.6953125 ]
 [ 80693.7265625 ]
 [ 66024.65625   ]
 [ 64367.01171875]]
DEBUG:root:training time = %d0.235396
INFO:root:frame =5489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208139419556
INFO:root:frame =5490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482797622681
DEBUG:root: save sample needs time = 0.000189065933228
INFO:root:random_action_porb = 0.95668
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5492 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame =5493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000509023666382
INFO:root:frame =5494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.956648333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 79226.3046875 ]
 [ 76690.59375   ]
 [ 78985.1484375 ]
 [ 78985.1484375 ]
 [ 74359.8046875 ]
 [ 85332.453125  ]
 [ 79727.3671875 ]
 [ 64283.7890625 ]
 [ 76845.6328125 ]
 [ 79727.3671875 ]
 [ 79914.15625   ]
 [ 73895.0390625 ]
 [ 79810.109375  ]
 [ 81898.53125   ]
 [ 62955.41796875]
 [ 67642.9140625 ]]
DEBUG:root:training time = %d0.212608
INFO:root:frame =5497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =5498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000267028808594
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.956616666667
DEBUG:root: dqn, choose action rondomly, need time 0.000167000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000144004821777
INFO:root:frame =5501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000507831573486
INFO:root:frame =5502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame = 5503 State into memory, numbers recorded 145 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000605821609497
INFO:root:random_action_porb = 0.956585
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5504current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000369071960449
INFO:root:training error  = [[ 91099.921875 ]
 [ 68888.5625   ]
 [ 67021.828125 ]
 [ 77836.640625 ]
 [ 70404.7109375]
 [ 70736.515625 ]
 [ 80064.6796875]
 [ 69809.2265625]
 [ 81274.828125 ]
 [ 68935.4765625]
 [ 68805.796875 ]
 [ 72254.3828125]
 [ 99401.9609375]
 [ 76170.609375 ]
 [ 65662.0625   ]
 [ 78302.140625 ]]
DEBUG:root:training time = %d0.226808
INFO:root:frame =5505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000382900238037
INFO:root:frame =5506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000396013259888
DEBUG:root: save sample needs time = 0.000292062759399
INFO:root:random_action_porb = 0.956553333333
DEBUG:root: dqn, choose action rondomly, need time 0.000265000000013
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =5509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000582933425903
INFO:root:frame =5510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324010848999
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:random_action_porb = 0.956521666667
DEBUG:root: dqn, choose action rondomly, need time 0.000268000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 68241.8671875]
 [ 73571.       ]
 [ 86240.3046875]
 [ 73407.65625  ]
 [ 69413.7265625]
 [ 69566.3828125]
 [ 70443.0703125]
 [ 69377.1953125]
 [ 85340.15625  ]
 [ 68775.828125 ]
 [ 79718.546875 ]
 [ 89818.453125 ]
 [ 68605.8828125]
 [ 88598.6640625]
 [ 91762.546875 ]
 [ 75243.328125 ]]
DEBUG:root:training time = %d0.209562
INFO:root:frame =5513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000407934188843
INFO:root:frame =5514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000408887863159
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:random_action_porb = 0.95649
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =5517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000517129898071
INFO:root:frame =5518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000586032867432
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:random_action_porb = 0.956458333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000327825546265
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 84447.8515625]
 [ 77136.3828125]
 [ 86166.6171875]
 [ 74946.015625 ]
 [ 85003.       ]
 [ 82589.7265625]
 [ 79346.75     ]
 [ 85348.7109375]
 [ 84614.234375 ]
 [ 74946.015625 ]
 [ 86595.421875 ]
 [ 90989.71875  ]
 [ 88705.953125 ]
 [ 88281.5234375]
 [ 59420.25     ]
 [ 69432.25     ]]
DEBUG:root:training time = %d0.231213
INFO:root:frame =5521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =5522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame = 5523 State into memory, numbers recorded 146 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000668048858643
INFO:root:random_action_porb = 0.956426666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5524current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root:frame =5525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =5526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000499963760376
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.956395
DEBUG:root: dqn, choose action rondomly, need time 0.000381000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  81330.515625 ]
 [  81558.4921875]
 [  79654.8671875]
 [  78866.078125 ]
 [  67739.9765625]
 [  69558.140625 ]
 [  77528.2578125]
 [  72419.0703125]
 [  71129.2578125]
 [  74176.703125 ]
 [  74522.6015625]
 [ 102842.3515625]
 [  81444.1875   ]
 [  78886.1015625]
 [  89642.3515625]
 [  67413.5078125]]
DEBUG:root:training time = %d0.236257
INFO:root:frame =5529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =5530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000188112258911
INFO:root:random_action_porb = 0.956363333333
DEBUG:root: dqn, choose action rondomly, need time 0.000362999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000341176986694
INFO:root:frame =5533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =5534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:random_action_porb = 0.956331666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 77522.       ]
 [ 77819.4765625]
 [ 74373.921875 ]
 [ 80700.65625  ]
 [ 82189.71875  ]
 [ 77537.7734375]
 [ 80922.1953125]
 [ 73389.140625 ]
 [ 90833.65625  ]
 [ 72573.6796875]
 [ 95679.0546875]
 [ 78470.8359375]
 [ 92095.65625  ]
 [ 90833.65625  ]
 [ 92095.65625  ]
 [ 73866.109375 ]]
DEBUG:root:training time = %d0.23019
INFO:root:frame =5537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000253915786743
INFO:root:frame =5538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000565052032471
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:random_action_porb = 0.9563
DEBUG:root: dqn, choose action rondomly, need time 0.000298999999984
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =5541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =5542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:random_action_porb = 0.956268333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:training error  = [[ 89659.3046875]
 [ 88137.375    ]
 [ 74724.546875 ]
 [ 87892.8515625]
 [ 70145.578125 ]
 [ 78711.7578125]
 [ 89853.578125 ]
 [ 81802.1484375]
 [ 79232.078125 ]
 [ 86864.3203125]
 [ 73463.234375 ]
 [ 71774.0234375]
 [ 79232.078125 ]
 [ 81690.1796875]
 [ 85042.2890625]
 [ 77667.265625 ]]
DEBUG:root:training time = %d0.209532
INFO:root:frame =5545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =5546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000244855880737
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.956236666667
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5548 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =5549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00050687789917
INFO:root:frame =5550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.956205
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 71878.7109375]
 [ 83091.71875  ]
 [ 77066.421875 ]
 [ 63033.8515625]
 [ 86062.5859375]
 [ 71878.7109375]
 [ 75032.9296875]
 [ 89543.84375  ]
 [ 73747.515625 ]
 [ 87214.953125 ]
 [ 76969.125    ]
 [ 75032.9296875]
 [ 73074.125    ]
 [ 99211.15625  ]
 [ 76018.671875 ]
 [ 79457.6484375]]
DEBUG:root:training time = %d0.221719
INFO:root:frame =5553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000369071960449
INFO:root:frame =5554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454187393188
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.956173333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =5557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =5558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.956141666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  96789.953125 ]
 [  96652.984375 ]
 [  72244.671875 ]
 [  83996.6640625]
 [  75201.546875 ]
 [  72396.203125 ]
 [  81709.1640625]
 [  66882.59375  ]
 [  66882.59375  ]
 [  81765.5625   ]
 [  86233.9921875]
 [  93969.4921875]
 [  81765.5625   ]
 [ 103466.828125 ]
 [  93270.59375  ]
 [  94910.328125 ]]
DEBUG:root:training time = %d0.217432
INFO:root:frame =5561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240802764893
INFO:root:frame =5562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:random_action_porb = 0.95611
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =5565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000561952590942
INFO:root:frame =5566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
DEBUG:root: save sample needs time = 0.000168085098267
INFO:root:random_action_porb = 0.956078333333
DEBUG:root: dqn, choose action rondomly, need time 0.000262000000021
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:training error  = [[  79512.7109375]
 [ 103019.375    ]
 [  83384.4609375]
 [ 107236.421875 ]
 [  68792.4765625]
 [ 115562.8125   ]
 [  95103.5703125]
 [  75644.3359375]
 [  97673.6484375]
 [  83256.765625 ]
 [  75669.8515625]
 [  94472.484375 ]
 [  77189.5546875]
 [  95458.671875 ]
 [ 103746.5859375]
 [  76704.9296875]]
DEBUG:root:training time = %d0.209388
INFO:root:frame =5569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286817550659
INFO:root:frame =5570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame = 5571 State into memory, numbers recorded 147 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000348806381226
INFO:root:random_action_porb = 0.956046666667
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999985
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5572current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =5573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =5574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000490188598633
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.956015
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999981
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  87243.796875 ]
 [ 106329.4921875]
 [ 105672.609375 ]
 [ 107671.140625 ]
 [  70332.953125 ]
 [ 105501.5703125]
 [ 107773.0703125]
 [  86882.7421875]
 [ 100818.34375  ]
 [ 107495.2890625]
 [  77050.96875  ]
 [ 110817.140625 ]
 [  84291.5546875]
 [  76463.859375 ]
 [ 105659.9140625]
 [  72174.078125 ]]
DEBUG:root:training time = %d0.21216
INFO:root:frame =5577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =5578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000278949737549
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.955983333333
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =5581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =5582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000480890274048
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:random_action_porb = 0.955951666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 113067.015625 ]
 [  80113.6015625]
 [  77650.6640625]
 [ 102740.59375  ]
 [ 108565.7421875]
 [ 109339.046875 ]
 [  89988.28125  ]
 [ 102050.921875 ]
 [ 113060.78125  ]
 [  89614.8671875]
 [  95697.484375 ]
 [  97898.40625  ]
 [ 109612.7265625]
 [ 111717.1875   ]
 [ 107067.3203125]
 [  88927.4296875]]
DEBUG:root:training time = %d0.223102
INFO:root:frame =5585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =5586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000401973724365
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.95592
DEBUG:root: dqn, choose action rondomly, need time 0.000346000000008
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =5589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000671863555908
INFO:root:frame =5590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485897064209
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.955888333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  88629.4765625]
 [  88224.0859375]
 [  77768.2734375]
 [ 102353.1328125]
 [  93073.5546875]
 [  83145.21875  ]
 [  80492.171875 ]
 [  97154.2734375]
 [  96410.25     ]
 [  97154.2734375]
 [  90094.359375 ]
 [  93073.5546875]
 [  91942.5      ]
 [  76113.484375 ]
 [  98398.625    ]
 [ 105180.8125   ]]
DEBUG:root:training time = %d0.204064
INFO:root:frame =5593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =5594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000432014465332
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.955856666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =5597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =5598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.955825
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999983
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 106839.921875 ]
 [  79126.28125  ]
 [  90020.8046875]
 [ 108463.125    ]
 [ 106839.921875 ]
 [  92456.9765625]
 [  91395.2109375]
 [  80142.3515625]
 [ 108122.15625  ]
 [  85167.078125 ]
 [  87031.9140625]
 [ 108463.125    ]
 [  91410.859375 ]
 [  87777.078125 ]
 [ 100438.546875 ]
 [  87777.078125 ]]
DEBUG:root:training time = %d0.233332
INFO:root:frame =5601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =5602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:random_action_porb = 0.955793333333
DEBUG:root: dqn, choose action rondomly, need time 0.00055900000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5604 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000379085540771
INFO:root:frame =5605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00040602684021
INFO:root:frame =5606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:random_action_porb = 0.955761666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000166177749634
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  82017.0703125]
 [  80227.796875 ]
 [  79960.8203125]
 [  83203.796875 ]
 [ 102755.6171875]
 [  85073.90625  ]
 [ 101883.15625  ]
 [  88283.5546875]
 [  90120.7421875]
 [ 103442.640625 ]
 [  83487.703125 ]
 [  78585.5      ]
 [ 101689.0546875]
 [  77736.40625  ]
 [ 104337.515625 ]
 [  84588.3828125]]
DEBUG:root:training time = %d0.211472
INFO:root:frame =5609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =5610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000283002853394
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.95573
DEBUG:root: dqn, choose action rondomly, need time 0.000326999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =5613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000423908233643
INFO:root:frame =5614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000423908233643
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.955698333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000393152236938
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  96044.3046875]
 [  84069.4140625]
 [  93370.828125 ]
 [ 102741.84375  ]
 [ 102060.59375  ]
 [  96044.3046875]
 [  97523.546875 ]
 [ 107528.2734375]
 [ 101466.203125 ]
 [  98455.9140625]
 [  98118.5234375]
 [  93982.0625   ]
 [  97523.546875 ]
 [  79192.5      ]
 [ 115145.8984375]
 [ 107379.09375  ]]
DEBUG:root:training time = %d0.225409
INFO:root:frame =5617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =5618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.955666666667
DEBUG:root: dqn, choose action rondomly, need time 0.000336000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =5621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000499963760376
INFO:root:frame =5622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.955635
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5624 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000343084335327
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  89253.8984375]
 [  96986.015625 ]
 [  88854.9375   ]
 [ 111964.4140625]
 [  89083.8828125]
 [  95605.0625   ]
 [ 102114.5703125]
 [  98639.8515625]
 [  86457.53125  ]
 [  84069.984375 ]
 [  90824.828125 ]
 [  89785.0859375]
 [ 101558.296875 ]
 [ 101558.296875 ]
 [ 108890.9765625]
 [  79886.828125 ]]
DEBUG:root:training time = %d0.228316
INFO:root:frame =5625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root:frame =5626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000301837921143
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.955603333333
DEBUG:root: dqn, choose action rondomly, need time 0.000220999999982
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5628 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:frame =5629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =5630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000576019287109
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:random_action_porb = 0.955571666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  85998.140625 ]
 [  88043.171875 ]
 [  89269.0703125]
 [  84884.59375  ]
 [ 104499.0859375]
 [ 115537.2578125]
 [  97415.3125   ]
 [ 105122.8671875]
 [  85103.25     ]
 [  87783.15625  ]
 [ 106256.265625 ]
 [  83556.28125  ]
 [  92194.0703125]
 [  86033.65625  ]
 [  86087.515625 ]
 [  85687.125    ]]
DEBUG:root:training time = %d0.222603
INFO:root:frame =5633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029182434082
INFO:root:frame =5634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000255107879639
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:random_action_porb = 0.95554
DEBUG:root: dqn, choose action rondomly, need time 0.000320999999985
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root:frame =5637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =5638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000472068786621
INFO:root:frame = 5639 State into memory, numbers recorded 148 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000575065612793
INFO:root:random_action_porb = 0.955508333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5640current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:training error  = [[ 106344.140625 ]
 [  91487.34375  ]
 [ 110184.7734375]
 [ 101908.71875  ]
 [  86466.1484375]
 [ 118354.8125   ]
 [  80440.09375  ]
 [ 121536.6640625]
 [  96139.96875  ]
 [ 104656.359375 ]
 [ 125317.3828125]
 [  83245.2109375]
 [ 103795.6640625]
 [  91838.59375  ]
 [ 121294.7265625]
 [ 118138.890625 ]]
DEBUG:root:training time = %d0.212348
INFO:root:frame =5641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:frame =5642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470876693726
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.955476666667
DEBUG:root: dqn, choose action rondomly, need time 0.000319000000019
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =5645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454187393188
INFO:root:frame =5646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.955445
DEBUG:root: dqn, choose action rondomly, need time 0.000184000000019
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5648 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 122516.75     ]
 [  87118.9375   ]
 [ 119140.5859375]
 [ 122255.3984375]
 [ 101892.8203125]
 [  98528.859375 ]
 [  86639.96875  ]
 [ 117791.3984375]
 [ 112386.015625 ]
 [  88273.6875   ]
 [ 112689.046875 ]
 [ 114561.7578125]
 [ 111586.0078125]
 [ 121112.8359375]
 [  99747.40625  ]
 [  98503.7265625]]
DEBUG:root:training time = %d0.212817
INFO:root:frame =5649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =5650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000412940979004
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.955413333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5652 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000369071960449
INFO:root:frame =5653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000535011291504
INFO:root:frame =5654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000332117080688
DEBUG:root: save sample needs time = 0.000233173370361
INFO:root:random_action_porb = 0.955381666667
DEBUG:root: dqn, choose action rondomly, need time 0.000477999999987
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000409841537476
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 107457.515625 ]
 [  97123.53125  ]
 [ 106165.5546875]
 [ 101737.015625 ]
 [ 108544.1875   ]
 [ 104597.2890625]
 [ 113154.3828125]
 [ 111226.484375 ]
 [  99950.7578125]
 [  97895.3515625]
 [  90982.9453125]
 [ 108370.515625 ]
 [  91296.3359375]
 [ 120331.75     ]
 [  99712.25     ]
 [  85854.1484375]]
DEBUG:root:training time = %d0.209138
INFO:root:frame =5657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =5658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame = 5659 State into memory, numbers recorded 149 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000571966171265
INFO:root:random_action_porb = 0.95535
DEBUG:root: dqn, choose action rondomly, need time 0.000344000000013
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5660current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root:frame =5661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000401020050049
INFO:root:frame =5662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:random_action_porb = 0.955318333333
DEBUG:root: dqn, choose action rondomly, need time 0.00053299999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  87962.9296875]
 [ 114216.9375   ]
 [ 105628.8125   ]
 [ 100595.2109375]
 [  85950.3203125]
 [ 100259.4296875]
 [ 100356.859375 ]
 [  85404.640625 ]
 [ 119811.3046875]
 [ 100595.2109375]
 [ 118285.28125  ]
 [  97976.9453125]
 [ 105924.5078125]
 [  88228.140625 ]
 [ 107809.6171875]
 [ 120137.3828125]]
DEBUG:root:training time = %d0.233551
INFO:root:frame =5665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =5666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488042831421
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.955286666667
DEBUG:root: dqn, choose action rondomly, need time 0.000345999999979
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =5669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000511169433594
INFO:root:frame =5670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049090385437
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:random_action_porb = 0.955255
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root:training error  = [[  93481.8671875]
 [  91485.5703125]
 [  89593.5234375]
 [  94142.8984375]
 [ 122711.3203125]
 [  95569.1328125]
 [  97319.9296875]
 [ 116767.703125 ]
 [ 107270.       ]
 [ 114889.8828125]
 [  95558.265625 ]
 [  93366.6484375]
 [ 102999.9375   ]
 [  96972.328125 ]
 [ 107932.140625 ]
 [  94040.75     ]]
DEBUG:root:training time = %d0.220445
INFO:root:frame =5673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:frame =5674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:random_action_porb = 0.955223333333
INFO:root:dqn select action Tensor("ArgMax_26:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00940799999998
INFO:root:action choosen by dqn [3]
INFO:root:frame =5676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =5677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =5678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433206558228
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.955191666667
INFO:root:dqn select action Tensor("ArgMax_27:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014073
INFO:root:action choosen by dqn [3]
INFO:root:frame =5680 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 111057.515625 ]
 [ 131448.734375 ]
 [ 123287.0546875]
 [  90518.421875 ]
 [ 118255.0546875]
 [ 103416.5703125]
 [ 129805.390625 ]
 [  99906.       ]
 [ 117754.203125 ]
 [ 119188.4609375]
 [ 116935.28125  ]
 [ 131983.90625  ]
 [ 106493.234375 ]
 [  90347.2109375]
 [ 103774.5859375]
 [ 116368.9296875]]
DEBUG:root:training time = %d0.197468
INFO:root:frame =5681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:frame =5682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236034393311
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.95516
DEBUG:root: dqn, choose action rondomly, need time 0.000166000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:frame =5685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248193740845
INFO:root:frame =5686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000322818756104
DEBUG:root: save sample needs time = 0.00014591217041
INFO:root:random_action_porb = 0.955128333333
INFO:root:dqn select action Tensor("ArgMax_28:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00705099999999
INFO:root:action choosen by dqn [4]
INFO:root:frame =5688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000356912612915
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  96079.71875  ]
 [  98356.96875  ]
 [ 106025.9140625]
 [ 104271.9140625]
 [  97378.4296875]
 [ 128432.2890625]
 [ 127195.671875 ]
 [ 111277.625    ]
 [ 104563.1796875]
 [  98356.96875  ]
 [  97096.140625 ]
 [ 112675.28125  ]
 [ 117860.7890625]
 [ 106025.9140625]
 [ 125175.3359375]
 [ 124723.1328125]]
DEBUG:root:training time = %d0.202439
INFO:root:frame =5689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:frame =5690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231981277466
DEBUG:root: save sample needs time = 0.000116109848022
INFO:root:random_action_porb = 0.955096666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00015115737915
INFO:root:frame =5693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =5694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000235795974731
DEBUG:root: save sample needs time = 9.3936920166e-05
INFO:root:random_action_porb = 0.955065
DEBUG:root: dqn, choose action rondomly, need time 0.00018799999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  96367.5      ]
 [ 126023.265625 ]
 [ 102068.078125 ]
 [  90862.5078125]
 [ 113915.4765625]
 [ 118466.3828125]
 [ 101137.046875 ]
 [ 128345.859375 ]
 [ 122332.578125 ]
 [ 131380.40625  ]
 [  90862.5078125]
 [ 115272.515625 ]
 [ 121249.15625  ]
 [ 104134.15625  ]
 [ 122649.4140625]
 [ 101852.921875 ]]
DEBUG:root:training time = %d0.190984
INFO:root:frame =5697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =5698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00023889541626
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.955033333333
DEBUG:root: dqn, choose action rondomly, need time 0.00018399999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001540184021
INFO:root:frame =5701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =5702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame = 5703 State into memory, numbers recorded 150 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000279903411865
INFO:root:random_action_porb = 0.955001666667
DEBUG:root: dqn, choose action rondomly, need time 0.000167000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5704current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000137090682983
INFO:root:training error  = [[  91836.5234375]
 [  93630.3203125]
 [ 114536.6328125]
 [ 109743.7109375]
 [ 124787.6328125]
 [  84370.390625 ]
 [ 120428.9921875]
 [ 119012.875    ]
 [ 130458.171875 ]
 [ 121771.0078125]
 [ 122451.125    ]
 [ 121535.984375 ]
 [  84370.390625 ]
 [ 129964.125    ]
 [ 118211.0625   ]
 [ 112542.5546875]]
DEBUG:root:training time = %d0.190644
INFO:root:frame =5705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =5706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.95497
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =5709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =5710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449895858765
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.954938333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999983
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5712 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:training error  = [[ 108103.8515625]
 [  99635.171875 ]
 [ 103308.5703125]
 [ 110789.515625 ]
 [ 105397.875    ]
 [ 100098.0859375]
 [ 129332.25     ]
 [ 102459.3828125]
 [ 100028.890625 ]
 [ 103355.34375  ]
 [  96433.6015625]
 [ 105397.875    ]
 [ 104127.5390625]
 [ 110075.234375 ]
 [ 118575.6484375]
 [  95230.703125 ]]
DEBUG:root:training time = %d0.23682
INFO:root:frame =5713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288009643555
INFO:root:frame =5714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234842300415
DEBUG:root: save sample needs time = 0.000108957290649
INFO:root:random_action_porb = 0.954906666667
DEBUG:root: dqn, choose action rondomly, need time 0.000449000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000417947769165
INFO:root:frame =5717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =5718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.954875
DEBUG:root: dqn, choose action rondomly, need time 0.000226000000026
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  94881.4453125]
 [ 134911.65625  ]
 [  98327.2578125]
 [ 141381.515625 ]
 [  94827.609375 ]
 [ 136529.53125  ]
 [ 104954.484375 ]
 [ 107989.578125 ]
 [ 103785.90625  ]
 [ 130979.671875 ]
 [ 121268.5390625]
 [ 110983.6484375]
 [ 140609.984375 ]
 [  95325.359375 ]
 [ 127261.5078125]
 [ 103785.90625  ]]
DEBUG:root:training time = %d0.221649
INFO:root:frame =5721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270128250122
INFO:root:frame =5722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000130891799927
INFO:root:random_action_porb = 0.954843333333
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000363111495972
INFO:root:frame =5725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =5726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.954811666667
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:training error  = [[ 140172.734375 ]
 [ 119276.8046875]
 [ 106741.3125   ]
 [ 104055.703125 ]
 [  99986.578125 ]
 [ 131710.875    ]
 [ 126026.734375 ]
 [  99200.390625 ]
 [ 135693.671875 ]
 [  99017.7734375]
 [ 113457.7890625]
 [ 107315.109375 ]
 [ 134447.546875 ]
 [ 131730.359375 ]
 [ 135897.34375  ]
 [ 134408.875    ]]
DEBUG:root:training time = %d0.218693
INFO:root:frame =5729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =5730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:random_action_porb = 0.95478
DEBUG:root: dqn, choose action rondomly, need time 0.000332999999983
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000410079956055
INFO:root:frame =5733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000637054443359
INFO:root:frame =5734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00049901008606
DEBUG:root: save sample needs time = 0.000285148620605
INFO:root:random_action_porb = 0.954748333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 111955.265625 ]
 [ 137319.828125 ]
 [ 124191.5390625]
 [ 141020.421875 ]
 [ 130364.015625 ]
 [ 132524.078125 ]
 [ 132570.296875 ]
 [ 144445.640625 ]
 [ 101083.015625 ]
 [ 133000.890625 ]
 [ 106653.90625  ]
 [ 128983.0390625]
 [ 124985.0390625]
 [ 123662.8046875]
 [ 102172.       ]
 [ 141020.421875 ]]
DEBUG:root:training time = %d0.234322
INFO:root:frame =5737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =5738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000283002853394
INFO:root:random_action_porb = 0.954716666667
DEBUG:root: dqn, choose action rondomly, need time 0.000366000000014
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000494956970215
INFO:root:frame =5741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =5742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000231981277466
INFO:root:random_action_porb = 0.954685
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 134274.65625  ]
 [  95477.984375 ]
 [ 128519.796875 ]
 [ 133800.5625   ]
 [ 131031.984375 ]
 [ 100759.75     ]
 [ 136011.140625 ]
 [ 134793.671875 ]
 [ 130598.9453125]
 [ 105619.921875 ]
 [ 123323.0546875]
 [ 128519.796875 ]
 [ 140990.34375  ]
 [ 100362.421875 ]
 [ 127072.7578125]
 [ 145375.765625 ]]
DEBUG:root:training time = %d0.217381
INFO:root:frame =5745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =5746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000494003295898
DEBUG:root: save sample needs time = 0.00012993812561
INFO:root:random_action_porb = 0.954653333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =5749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000515937805176
INFO:root:frame =5750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.954621666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5752 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 122047.1953125]
 [ 108538.078125 ]
 [ 116281.6640625]
 [ 109949.5546875]
 [ 121165.859375 ]
 [ 107079.78125  ]
 [ 122244.8125   ]
 [ 116348.2734375]
 [ 108636.8671875]
 [ 110739.4609375]
 [ 121871.5625   ]
 [ 128732.046875 ]
 [ 110739.4609375]
 [ 105344.3046875]
 [ 119479.9296875]
 [ 112044.484375 ]]
DEBUG:root:training time = %d0.235955
INFO:root:frame =5753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =5754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298023223877
DEBUG:root: save sample needs time = 0.000225782394409
INFO:root:random_action_porb = 0.95459
DEBUG:root: dqn, choose action rondomly, need time 0.000349999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root:frame =5757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =5758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000492095947266
INFO:root:frame = 5759 State into memory, numbers recorded 151 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000571012496948
INFO:root:random_action_porb = 0.954558333333
DEBUG:root: dqn, choose action rondomly, need time 0.000337999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5760current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:training error  = [[ 115384.9453125]
 [ 101527.1796875]
 [ 110573.78125  ]
 [ 118100.9609375]
 [ 117051.8515625]
 [ 105702.140625 ]
 [ 146411.609375 ]
 [ 146411.609375 ]
 [ 112776.59375  ]
 [ 143286.28125  ]
 [ 106385.859375 ]
 [ 113947.453125 ]
 [ 120658.1953125]
 [ 108957.6953125]
 [ 108705.1171875]
 [ 105450.828125 ]]
DEBUG:root:training time = %d0.226235
INFO:root:frame =5761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =5762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
INFO:root:frame = 5763 State into memory, numbers recorded 152 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000581026077271
INFO:root:random_action_porb = 0.954526666667
DEBUG:root: dqn, choose action rondomly, need time 0.000536000000011
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5764current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root:frame =5765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000572919845581
INFO:root:frame =5766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:frame = 5767 State into memory, numbers recorded 153 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000564813613892
INFO:root:random_action_porb = 0.954495
DEBUG:root: dqn, choose action rondomly, need time 0.000493000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5768current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 112078.484375 ]
 [ 143158.03125  ]
 [ 146761.5625   ]
 [ 108413.921875 ]
 [ 139583.234375 ]
 [ 121388.2734375]
 [ 143979.109375 ]
 [ 118311.8125   ]
 [ 108217.2265625]
 [ 137619.265625 ]
 [ 125092.0859375]
 [ 156664.828125 ]
 [ 118261.4375   ]
 [ 133052.53125  ]
 [ 102292.21875  ]
 [ 106914.953125 ]]
DEBUG:root:training time = %d0.208135
INFO:root:frame =5769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =5770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.954463333333
DEBUG:root: dqn, choose action rondomly, need time 0.00041299999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000328063964844
INFO:root:frame =5773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =5774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000246047973633
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.954431666667
DEBUG:root: dqn, choose action rondomly, need time 0.000173999999987
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5776 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 133713.0625   ]
 [ 153473.796875 ]
 [ 160519.5625   ]
 [ 115369.0234375]
 [ 141342.59375  ]
 [ 149931.546875 ]
 [ 141999.796875 ]
 [ 147335.28125  ]
 [ 104974.734375 ]
 [ 138073.9375   ]
 [ 140109.84375  ]
 [ 108232.96875  ]
 [ 142994.03125  ]
 [ 109463.40625  ]
 [ 141999.796875 ]
 [ 112175.609375 ]]
DEBUG:root:training time = %d0.211482
INFO:root:frame =5777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000212907791138
INFO:root:frame =5778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000290155410767
INFO:root:frame = 5779 State into memory, numbers recorded 154 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000550985336304
INFO:root:random_action_porb = 0.9544
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5780current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:frame =5781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000431060791016
INFO:root:frame =5782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.954368333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309999999985
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 146680.03125  ]
 [ 102511.59375  ]
 [ 140892.46875  ]
 [ 152878.328125 ]
 [ 107149.1328125]
 [ 130434.1875   ]
 [ 134114.390625 ]
 [ 151569.171875 ]
 [ 134114.390625 ]
 [ 152545.171875 ]
 [ 104729.3515625]
 [ 146891.046875 ]
 [ 142509.9375   ]
 [ 147565.890625 ]
 [ 101926.171875 ]
 [ 111949.7109375]]
DEBUG:root:training time = %d0.230526
INFO:root:frame =5785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244140625
INFO:root:frame =5786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000418186187744
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.954336666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325918197632
INFO:root:frame =5789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =5790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:random_action_porb = 0.954305
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5792 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 112633.328125 ]
 [ 110371.890625 ]
 [ 111280.8828125]
 [ 119272.421875 ]
 [ 117047.1796875]
 [ 119993.234375 ]
 [ 109659.9375   ]
 [ 120626.6484375]
 [ 114769.09375  ]
 [ 113823.2109375]
 [ 111378.3046875]
 [ 114042.078125 ]
 [ 131714.0625   ]
 [ 131714.0625   ]
 [ 112900.921875 ]
 [ 107633.015625 ]]
DEBUG:root:training time = %d0.221208
INFO:root:frame =5793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00032901763916
INFO:root:frame =5794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00036883354187
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.954273333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =5797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000576019287109
INFO:root:frame =5798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.954241666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 117682.5      ]
 [ 153364.78125  ]
 [ 122725.3515625]
 [ 154856.46875  ]
 [ 117167.8203125]
 [ 112119.03125  ]
 [ 131354.921875 ]
 [ 122874.5546875]
 [ 125739.1484375]
 [ 114832.296875 ]
 [ 110504.625    ]
 [ 147110.453125 ]
 [ 112825.4609375]
 [ 114832.296875 ]
 [ 113769.1796875]
 [ 108121.8359375]]
DEBUG:root:training time = %d0.210705
INFO:root:frame =5801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000379085540771
INFO:root:frame =5802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000530004501343
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.95421
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =5805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =5806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.954178333333
INFO:root:dqn select action Tensor("ArgMax_29:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013819
INFO:root:action choosen by dqn [2]
INFO:root:frame =5808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000160932540894
INFO:root:training error  = [[ 119195.203125 ]
 [ 127341.640625 ]
 [ 140566.046875 ]
 [ 120505.9375   ]
 [ 142840.078125 ]
 [ 115396.5546875]
 [ 151588.171875 ]
 [ 121174.359375 ]
 [ 108958.015625 ]
 [ 144507.265625 ]
 [ 142724.203125 ]
 [ 122565.2890625]
 [ 122565.2890625]
 [ 115396.5546875]
 [ 143414.578125 ]
 [ 110562.421875 ]]
DEBUG:root:training time = %d0.213036
INFO:root:frame =5809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:frame =5810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000436067581177
DEBUG:root: save sample needs time = 0.000270128250122
INFO:root:random_action_porb = 0.954146666667
DEBUG:root: dqn, choose action rondomly, need time 0.000329999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =5813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00040602684021
INFO:root:frame =5814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000403881072998
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.954115
DEBUG:root: dqn, choose action rondomly, need time 0.000308999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 120327.6875  ]
 [ 143791.3125  ]
 [ 141739.75    ]
 [ 134642.765625]
 [ 149910.75    ]
 [ 135852.359375]
 [ 126002.8125  ]
 [ 142067.515625]
 [ 113810.03125 ]
 [ 140876.703125]
 [ 143293.296875]
 [ 141739.75    ]
 [ 141236.875   ]
 [ 141653.359375]
 [ 142067.515625]
 [ 141653.359375]]
DEBUG:root:training time = %d0.213463
INFO:root:frame =5817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:frame =5818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame = 5819 State into memory, numbers recorded 155 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000571012496948
INFO:root:random_action_porb = 0.954083333333
DEBUG:root: dqn, choose action rondomly, need time 0.000447000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5820current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =5821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000427007675171
INFO:root:frame =5822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000491142272949
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.954051666667
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339984893799
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 145343.375   ]
 [ 143789.453125]
 [ 166055.859375]
 [ 161919.78125 ]
 [ 159631.859375]
 [ 152753.109375]
 [ 151058.234375]
 [ 149440.375   ]
 [ 151058.234375]
 [ 140097.421875]
 [ 157554.34375 ]
 [ 144307.609375]
 [ 145459.1875  ]
 [ 159098.15625 ]
 [ 149123.0625  ]
 [ 121793.84375 ]]
DEBUG:root:training time = %d0.208088
INFO:root:frame =5825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =5826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:random_action_porb = 0.95402
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5828 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000342130661011
INFO:root:frame =5829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000404119491577
INFO:root:frame =5830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.953988333333
DEBUG:root: dqn, choose action rondomly, need time 0.000361999999996
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 115589.375    ]
 [ 130496.2734375]
 [ 123007.0703125]
 [ 132526.21875  ]
 [ 114723.7734375]
 [ 120849.9296875]
 [ 120206.1015625]
 [ 126619.5625   ]
 [ 118959.6484375]
 [ 127376.84375  ]
 [ 143996.15625  ]
 [ 120714.171875 ]
 [ 136354.21875  ]
 [ 136850.5      ]
 [ 143996.15625  ]
 [ 120496.4453125]]
DEBUG:root:training time = %d0.228568
INFO:root:frame =5833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000369071960449
INFO:root:frame =5834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000534057617188
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:random_action_porb = 0.953956666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999983
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =5837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =5838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000547885894775
DEBUG:root: save sample needs time = 0.0001220703125
INFO:root:random_action_porb = 0.953925
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 115887.71875  ]
 [ 127536.5234375]
 [ 141189.15625  ]
 [ 134494.8125   ]
 [ 124928.078125 ]
 [ 179811.609375 ]
 [ 163497.03125  ]
 [ 163438.203125 ]
 [ 128846.6484375]
 [ 127741.3203125]
 [ 126090.53125  ]
 [ 163470.96875  ]
 [ 120621.90625  ]
 [ 142548.640625 ]
 [ 141352.140625 ]
 [ 123653.53125  ]]
DEBUG:root:training time = %d0.214645
INFO:root:frame =5841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =5842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286817550659
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.953893333333
DEBUG:root: dqn, choose action rondomly, need time 0.000190000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000177145004272
INFO:root:frame =5845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =5846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame = 5847 State into memory, numbers recorded 156 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000638961791992
INFO:root:random_action_porb = 0.953861666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5848current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 172650.390625 ]
 [ 127749.6953125]
 [ 135100.390625 ]
 [ 172650.390625 ]
 [ 181877.265625 ]
 [ 119289.2890625]
 [ 160190.6875   ]
 [ 115152.8515625]
 [ 121100.6015625]
 [ 151986.90625  ]
 [ 172347.421875 ]
 [ 130909.34375  ]
 [ 121432.8515625]
 [ 181877.265625 ]
 [ 116940.625    ]
 [ 151943.5      ]]
DEBUG:root:training time = %d0.232428
INFO:root:frame =5849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =5850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:random_action_porb = 0.95383
DEBUG:root: dqn, choose action rondomly, need time 0.000336000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =5853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =5854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:random_action_porb = 0.953798333333
DEBUG:root: dqn, choose action rondomly, need time 0.000300999999979
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:training error  = [[ 151498.84375  ]
 [ 169116.921875 ]
 [ 131931.40625  ]
 [ 162592.84375  ]
 [ 162789.796875 ]
 [ 152637.484375 ]
 [ 121233.8515625]
 [ 132057.359375 ]
 [ 123676.5390625]
 [ 162789.796875 ]
 [ 123492.875    ]
 [ 153232.109375 ]
 [ 150916.6875   ]
 [ 139340.34375  ]
 [ 160070.703125 ]
 [ 162910.78125  ]]
DEBUG:root:training time = %d0.216522
INFO:root:frame =5857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =5858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.953766666667
DEBUG:root: dqn, choose action rondomly, need time 0.000467000000015
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root:frame =5861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =5862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000492095947266
DEBUG:root: save sample needs time = 0.000204801559448
INFO:root:random_action_porb = 0.953735
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 163739.96875  ]
 [ 160518.390625 ]
 [ 158532.28125  ]
 [ 146168.078125 ]
 [ 152311.0625   ]
 [ 119178.0078125]
 [ 154460.515625 ]
 [ 159321.8125   ]
 [ 154807.671875 ]
 [ 155078.28125  ]
 [ 125916.515625 ]
 [ 126493.1015625]
 [ 155454.234375 ]
 [ 167302.171875 ]
 [ 168528.296875 ]
 [ 119178.0078125]]
DEBUG:root:training time = %d0.214432
INFO:root:frame =5865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =5866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308036804199
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.953703333333
DEBUG:root: dqn, choose action rondomly, need time 0.000309000000016
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:frame =5869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000507116317749
INFO:root:frame =5870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.953671666667
DEBUG:root: dqn, choose action rondomly, need time 0.000248999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000249147415161
INFO:root:training error  = [[ 124188.1015625]
 [ 127134.7265625]
 [ 149672.640625 ]
 [ 143340.984375 ]
 [ 126147.40625  ]
 [ 146488.21875  ]
 [ 136702.0625   ]
 [ 146037.796875 ]
 [ 126883.796875 ]
 [ 124897.015625 ]
 [ 133971.734375 ]
 [ 131515.65625  ]
 [ 145694.296875 ]
 [ 133450.015625 ]
 [ 136717.953125 ]
 [ 124497.6796875]]
DEBUG:root:training time = %d0.219142
INFO:root:frame =5873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029182434082
INFO:root:frame =5874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00039005279541
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.95364
DEBUG:root: dqn, choose action rondomly, need time 0.000166000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000488042831421
INFO:root:frame =5877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00044322013855
INFO:root:frame =5878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000643014907837
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.953608333333
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000015
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 128195.8203125]
 [ 127514.5546875]
 [ 142316.09375  ]
 [ 135496.96875  ]
 [ 132148.21875  ]
 [ 124041.8828125]
 [ 172992.625    ]
 [ 175228.078125 ]
 [ 177040.421875 ]
 [ 190412.90625  ]
 [ 129104.7734375]
 [ 149670.       ]
 [ 135325.546875 ]
 [ 127168.15625  ]
 [ 125946.6640625]
 [ 131304.671875 ]]
DEBUG:root:training time = %d0.220405
INFO:root:frame =5881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:frame =5882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000407934188843
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:random_action_porb = 0.953576666667
DEBUG:root: dqn, choose action rondomly, need time 0.000326999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5884 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000386953353882
INFO:root:frame =5885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =5886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000108003616333
INFO:root:random_action_porb = 0.953545
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 139866.875    ]
 [ 181165.375    ]
 [ 173168.140625 ]
 [ 167977.90625  ]
 [ 181165.375    ]
 [ 162859.9375   ]
 [ 123942.84375  ]
 [ 172449.59375  ]
 [ 138044.171875 ]
 [ 163253.09375  ]
 [ 147547.140625 ]
 [ 139280.578125 ]
 [ 124773.8359375]
 [ 133497.46875  ]
 [ 168530.703125 ]
 [ 138353.484375 ]]
DEBUG:root:training time = %d0.22547
INFO:root:frame =5889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =5890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
INFO:root:frame = 5891 State into memory, numbers recorded 157 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.00059700012207
INFO:root:random_action_porb = 0.953513333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999986
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5892current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =5893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =5894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456809997559
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:random_action_porb = 0.953481666667
DEBUG:root: dqn, choose action rondomly, need time 0.000344999999982
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 170610.953125]
 [ 168983.21875 ]
 [ 164515.796875]
 [ 132455.125   ]
 [ 170306.546875]
 [ 176433.640625]
 [ 183600.109375]
 [ 165991.78125 ]
 [ 135882.234375]
 [ 162592.84375 ]
 [ 134365.203125]
 [ 162592.84375 ]
 [ 181382.828125]
 [ 169090.015625]
 [ 172577.359375]
 [ 163623.40625 ]]
DEBUG:root:training time = %d0.233443
INFO:root:frame =5897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249147415161
INFO:root:frame =5898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264883041382
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.95345
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =5901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =5902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000362873077393
DEBUG:root: save sample needs time = 0.000223875045776
INFO:root:random_action_porb = 0.953418333333
DEBUG:root: dqn, choose action rondomly, need time 0.000336000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5904 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000350952148438
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 187180.875    ]
 [ 182349.84375  ]
 [ 185846.453125 ]
 [ 161325.       ]
 [ 161325.       ]
 [ 134803.359375 ]
 [ 204678.484375 ]
 [ 164193.921875 ]
 [ 127196.3671875]
 [ 183703.90625  ]
 [ 132853.84375  ]
 [ 166499.859375 ]
 [ 158552.890625 ]
 [ 158552.890625 ]
 [ 168398.828125 ]
 [ 176367.59375  ]]
DEBUG:root:training time = %d0.202274
INFO:root:frame =5905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =5906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000369071960449
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:random_action_porb = 0.953386666667
DEBUG:root: dqn, choose action rondomly, need time 0.00031199999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =5909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000473022460938
INFO:root:frame =5910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:random_action_porb = 0.953355
DEBUG:root: dqn, choose action rondomly, need time 0.000320999999985
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 136234.15625  ]
 [ 154061.234375 ]
 [ 149684.734375 ]
 [ 145630.5625   ]
 [ 137209.109375 ]
 [ 122969.390625 ]
 [ 142096.96875  ]
 [ 138914.53125  ]
 [ 116078.2890625]
 [ 134263.921875 ]
 [ 144219.703125 ]
 [ 129435.171875 ]
 [ 136659.09375  ]
 [ 134166.25     ]
 [ 138485.015625 ]
 [ 138485.015625 ]]
DEBUG:root:training time = %d0.207478
INFO:root:frame =5913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:frame =5914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000360012054443
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:random_action_porb = 0.953323333333
DEBUG:root: dqn, choose action rondomly, need time 0.00053299999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =5917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =5918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.953291666667
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 147117.1875  ]
 [ 151207.0625  ]
 [ 168962.75    ]
 [ 158777.734375]
 [ 171179.765625]
 [ 150771.421875]
 [ 153055.546875]
 [ 136080.65625 ]
 [ 148692.703125]
 [ 166399.0625  ]
 [ 142586.625   ]
 [ 156662.125   ]
 [ 161533.734375]
 [ 138709.328125]
 [ 166607.46875 ]
 [ 152629.859375]]
DEBUG:root:training time = %d0.224156
INFO:root:frame =5921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =5922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000521898269653
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.95326
DEBUG:root: dqn, choose action rondomly, need time 0.000600999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5924 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000351905822754
INFO:root:frame =5925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000401020050049
INFO:root:frame =5926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000679969787598
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.953228333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290999999976
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 180670.234375]
 [ 144539.5625  ]
 [ 132261.5     ]
 [ 143172.8125  ]
 [ 156443.03125 ]
 [ 175295.140625]
 [ 155092.90625 ]
 [ 180670.234375]
 [ 135721.71875 ]
 [ 140167.609375]
 [ 145838.953125]
 [ 182547.5625  ]
 [ 145132.71875 ]
 [ 177230.71875 ]
 [ 153390.796875]
 [ 145132.71875 ]]
DEBUG:root:training time = %d0.211834
INFO:root:frame =5929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000288963317871
INFO:root:frame =5930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294923782349
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.953196666667
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =5933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =5934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463962554932
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.953165
DEBUG:root: dqn, choose action rondomly, need time 0.000371000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000449895858765
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 140744.046875 ]
 [ 139988.515625 ]
 [ 176062.1875   ]
 [ 146370.125    ]
 [ 182480.8125   ]
 [ 147418.125    ]
 [ 196446.328125 ]
 [ 141744.53125  ]
 [ 139284.953125 ]
 [ 187582.03125  ]
 [ 126371.5703125]
 [ 148719.4375   ]
 [ 159327.265625 ]
 [ 133583.46875  ]
 [ 147581.65625  ]
 [ 142702.8125   ]]
DEBUG:root:training time = %d0.215712
INFO:root:frame =5937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =5938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000191926956177
INFO:root:random_action_porb = 0.953133333333
DEBUG:root: dqn, choose action rondomly, need time 0.000252999999987
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =5941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000495910644531
INFO:root:frame =5942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.953101666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 198520.71875  ]
 [ 190523.71875  ]
 [ 194915.359375 ]
 [ 142250.890625 ]
 [ 189089.09375  ]
 [ 182163.484375 ]
 [ 196920.5625   ]
 [ 188828.4375   ]
 [ 124843.5234375]
 [ 190786.8125   ]
 [ 197558.109375 ]
 [ 195325.15625  ]
 [ 141276.875    ]
 [ 150342.109375 ]
 [ 182442.4375   ]
 [ 175365.0625   ]]
DEBUG:root:training time = %d0.231524
INFO:root:frame =5945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame =5946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000261068344116
INFO:root:frame = 5947 State into memory, numbers recorded 158 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000424861907959
INFO:root:random_action_porb = 0.95307
DEBUG:root: dqn, choose action rondomly, need time 0.000186000000014
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5948current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.00016713142395
INFO:root:frame =5949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =5950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000504970550537
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.953038333333
DEBUG:root: dqn, choose action rondomly, need time 0.000384999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000326156616211
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 177654.015625]
 [ 141056.      ]
 [ 185839.71875 ]
 [ 157235.875   ]
 [ 138521.71875 ]
 [ 170432.296875]
 [ 174011.59375 ]
 [ 181760.671875]
 [ 177082.34375 ]
 [ 174694.203125]
 [ 167479.171875]
 [ 143508.53125 ]
 [ 190273.59375 ]
 [ 187566.390625]
 [ 190491.75    ]
 [ 192159.375   ]]
DEBUG:root:training time = %d0.226911
INFO:root:frame =5953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:frame =5954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000281810760498
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:random_action_porb = 0.953006666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =5957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000607967376709
INFO:root:frame =5958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476121902466
DEBUG:root: save sample needs time = 0.000287771224976
INFO:root:random_action_porb = 0.952975
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5960 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 140695.328125]
 [ 182696.96875 ]
 [ 148777.828125]
 [ 156496.34375 ]
 [ 145958.703125]
 [ 147825.234375]
 [ 154208.84375 ]
 [ 154365.34375 ]
 [ 150345.890625]
 [ 144741.984375]
 [ 157493.875   ]
 [ 149798.484375]
 [ 148057.734375]
 [ 144918.890625]
 [ 184492.90625 ]
 [ 156084.796875]]
DEBUG:root:training time = %d0.232428
INFO:root:frame =5961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =5962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.952943333333
DEBUG:root: dqn, choose action rondomly, need time 0.000319999999988
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =5965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:frame =5966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame = 5967 State into memory, numbers recorded 159 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000607967376709
INFO:root:random_action_porb = 0.952911666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5968current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:training error  = [[ 159626.      ]
 [ 140831.25    ]
 [ 164700.828125]
 [ 152341.9375  ]
 [ 205113.90625 ]
 [ 168731.609375]
 [ 149262.25    ]
 [ 166538.921875]
 [ 143968.      ]
 [ 148069.765625]
 [ 198728.765625]
 [ 193331.109375]
 [ 150972.09375 ]
 [ 200843.15625 ]
 [ 149262.25    ]
 [ 200573.203125]]
DEBUG:root:training time = %d0.225146
INFO:root:frame =5969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =5970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame = 5971 State into memory, numbers recorded 160 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:random_action_porb = 0.95288
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =5972current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =5973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000818014144897
INFO:root:frame =5974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:random_action_porb = 0.952848333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000337839126587
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 202863.15625 ]
 [ 158771.890625]
 [ 194625.734375]
 [ 159256.71875 ]
 [ 165045.8125  ]
 [ 170326.28125 ]
 [ 169499.0625  ]
 [ 153025.75    ]
 [ 160553.21875 ]
 [ 147267.8125  ]
 [ 164803.09375 ]
 [ 200896.984375]
 [ 162481.8125  ]
 [ 190604.296875]
 [ 148863.71875 ]
 [ 157138.296875]]
DEBUG:root:training time = %d0.214051
INFO:root:frame =5977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:frame =5978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000370979309082
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.952816666667
DEBUG:root: dqn, choose action rondomly, need time 0.000349
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =5981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000229835510254
INFO:root:frame =5982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000549077987671
INFO:root:frame = 5983 State into memory, numbers recorded 161 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000545024871826
INFO:root:random_action_porb = 0.952785
DEBUG:root: dqn, choose action rondomly, need time 0.000359000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =5984current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 209361.65625 ]
 [ 148791.390625]
 [ 188659.578125]
 [ 203850.046875]
 [ 202876.78125 ]
 [ 196980.796875]
 [ 151983.859375]
 [ 162703.515625]
 [ 206243.703125]
 [ 192817.90625 ]
 [ 224629.71875 ]
 [ 200138.71875 ]
 [ 169917.859375]
 [ 203397.03125 ]
 [ 200866.78125 ]
 [ 152317.546875]]
DEBUG:root:training time = %d0.217838
INFO:root:frame =5985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000357866287231
INFO:root:frame =5986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.952753333333
DEBUG:root: dqn, choose action rondomly, need time 0.000333000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =5988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =5989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00051212310791
INFO:root:frame =5990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000617980957031
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:random_action_porb = 0.952721666667
DEBUG:root: dqn, choose action rondomly, need time 0.000355999999982
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =5992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 192191.484375]
 [ 170604.5     ]
 [ 185049.9375  ]
 [ 181418.59375 ]
 [ 174210.453125]
 [ 171440.46875 ]
 [ 171378.609375]
 [ 177826.9375  ]
 [ 172128.15625 ]
 [ 149221.5     ]
 [ 185481.203125]
 [ 181488.890625]
 [ 151466.90625 ]
 [ 169557.359375]
 [ 171790.015625]
 [ 193606.453125]]
DEBUG:root:training time = %d0.232993
INFO:root:frame =5993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =5994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:random_action_porb = 0.95269
DEBUG:root: dqn, choose action rondomly, need time 0.000346000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =5996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:frame =5997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =5998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
DEBUG:root: save sample needs time = 0.000204086303711
DEBUG:root:one frame running time = 0.00639700000002
DEBUG:root:total training time = 156.308416
INFO:root:frame num = 6000 frame round: 0
INFO:root:random_action_porb = 0.952658333333
DEBUG:root: dqn, choose action rondomly, need time 0.000326000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 189536.515625]
 [ 218218.53125 ]
 [ 158177.875   ]
 [ 194666.234375]
 [ 199696.828125]
 [ 173793.71875 ]
 [ 150586.8125  ]
 [ 158033.03125 ]
 [ 154287.84375 ]
 [ 168153.65625 ]
 [ 151296.3125  ]
 [ 160171.140625]
 [ 170037.03125 ]
 [ 202207.4375  ]
 [ 218218.53125 ]
 [ 194585.671875]]
DEBUG:root:training time = %d0.22585
INFO:root:frame =6001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =6002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.952626666667
DEBUG:root: dqn, choose action rondomly, need time 0.000405999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6004 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000535011291504
INFO:root:frame =6005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =6006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.952595
DEBUG:root: dqn, choose action rondomly, need time 0.000296999999989
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 172774.578125]
 [ 158049.734375]
 [ 166978.78125 ]
 [ 166808.828125]
 [ 172013.515625]
 [ 171902.15625 ]
 [ 167505.140625]
 [ 153888.40625 ]
 [ 179507.375   ]
 [ 169791.484375]
 [ 166808.828125]
 [ 156798.984375]
 [ 161313.234375]
 [ 162152.890625]
 [ 155893.109375]
 [ 178496.765625]]
DEBUG:root:training time = %d0.209933
INFO:root:frame =6009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =6010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293016433716
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:random_action_porb = 0.952563333333
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000498056411743
INFO:root:frame =6013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =6014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000263929367065
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.952531666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999981
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00034499168396
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 174380.46875 ]
 [ 166393.078125]
 [ 190673.375   ]
 [ 209292.84375 ]
 [ 167289.78125 ]
 [ 160673.359375]
 [ 161100.328125]
 [ 174470.59375 ]
 [ 190658.015625]
 [ 170306.546875]
 [ 160479.265625]
 [ 205219.171875]
 [ 159524.1875  ]
 [ 163644.734375]
 [ 190658.015625]
 [ 163315.046875]]
DEBUG:root:training time = %d0.227345
INFO:root:frame =6017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =6018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:random_action_porb = 0.9525
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325202941895
INFO:root:frame =6021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =6022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000439882278442
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.952468333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 137456.28125 ]
 [ 186164.859375]
 [ 213608.265625]
 [ 159474.65625 ]
 [ 210419.3125  ]
 [ 228993.09375 ]
 [ 188141.609375]
 [ 184338.578125]
 [ 194652.015625]
 [ 195420.546875]
 [ 222778.9375  ]
 [ 155246.390625]
 [ 215446.921875]
 [ 213608.265625]
 [ 216015.703125]
 [ 205575.015625]]
DEBUG:root:training time = %d0.21157
INFO:root:frame =6025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000265836715698
INFO:root:frame =6026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000282049179077
DEBUG:root: save sample needs time = 0.000114917755127
INFO:root:random_action_porb = 0.952436666667
DEBUG:root: dqn, choose action rondomly, need time 0.000227999999993
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000214099884033
INFO:root:frame =6029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000445127487183
INFO:root:frame =6030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.952405
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999983
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 181642.859375]
 [ 183054.03125 ]
 [ 176319.203125]
 [ 185080.1875  ]
 [ 179722.59375 ]
 [ 193031.078125]
 [ 180917.71875 ]
 [ 161998.390625]
 [ 159026.09375 ]
 [ 178502.53125 ]
 [ 177400.140625]
 [ 163947.890625]
 [ 178081.9375  ]
 [ 181695.71875 ]
 [ 195490.921875]
 [ 204810.171875]]
DEBUG:root:training time = %d0.22905
INFO:root:frame =6033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000278949737549
INFO:root:frame =6034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473022460938
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.952373333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030799999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6036 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =6037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:frame =6038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.952341666667
DEBUG:root: dqn, choose action rondomly, need time 0.000402000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6040 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 174268.328125]
 [ 172978.828125]
 [ 189698.109375]
 [ 178051.4375  ]
 [ 169308.9375  ]
 [ 169308.9375  ]
 [ 158064.484375]
 [ 188912.46875 ]
 [ 210396.015625]
 [ 199813.359375]
 [ 185225.15625 ]
 [ 175940.109375]
 [ 217839.609375]
 [ 171575.5625  ]
 [ 167938.6875  ]
 [ 163698.875   ]]
DEBUG:root:training time = %d0.244428
INFO:root:frame =6041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =6042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277996063232
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.95231
DEBUG:root: dqn, choose action rondomly, need time 0.000470000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =6045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =6046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486135482788
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.952278333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999976
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6048 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 168279.421875]
 [ 176181.453125]
 [ 176370.0625  ]
 [ 158344.921875]
 [ 207747.671875]
 [ 151844.9375  ]
 [ 226888.953125]
 [ 176421.734375]
 [ 208932.46875 ]
 [ 174346.609375]
 [ 176181.453125]
 [ 169068.734375]
 [ 167532.328125]
 [ 169973.40625 ]
 [ 222882.65625 ]
 [ 193616.765625]]
DEBUG:root:training time = %d0.24752
INFO:root:frame =6049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =6050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.000119209289551
INFO:root:random_action_porb = 0.952246666667
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355958938599
INFO:root:frame =6053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =6054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame = 6055 State into memory, numbers recorded 162 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000563859939575
INFO:root:random_action_porb = 0.952215
DEBUG:root: dqn, choose action rondomly, need time 0.000318000000021
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6056current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:training error  = [[ 213802.828125]
 [ 200169.734375]
 [ 206590.671875]
 [ 215127.46875 ]
 [ 182607.65625 ]
 [ 163713.09375 ]
 [ 161587.90625 ]
 [ 175700.96875 ]
 [ 217506.546875]
 [ 203037.8125  ]
 [ 196124.      ]
 [ 212945.296875]
 [ 208692.375   ]
 [ 149207.546875]
 [ 192603.125   ]
 [ 189924.875   ]]
DEBUG:root:training time = %d0.227582
INFO:root:frame =6057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =6058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame = 6059 State into memory, numbers recorded 163 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000722885131836
INFO:root:random_action_porb = 0.952183333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6060current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root:frame =6061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000509977340698
INFO:root:frame =6062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000199794769287
INFO:root:random_action_porb = 0.952151666667
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000016
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 207149.875   ]
 [ 191536.15625 ]
 [ 207149.875   ]
 [ 180146.78125 ]
 [ 156917.71875 ]
 [ 183645.3125  ]
 [ 175516.40625 ]
 [ 191591.71875 ]
 [ 172699.90625 ]
 [ 185915.921875]
 [ 190282.96875 ]
 [ 192248.421875]
 [ 186228.484375]
 [ 186445.171875]
 [ 181498.046875]
 [ 212098.921875]]
DEBUG:root:training time = %d0.226597
INFO:root:frame =6065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:frame =6066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000273942947388
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.95212
DEBUG:root: dqn, choose action rondomly, need time 0.000195000000019
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6068 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000385999679565
INFO:root:frame =6069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000525951385498
INFO:root:frame =6070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000489950180054
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.952088333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 169668.375   ]
 [ 202544.828125]
 [ 174532.609375]
 [ 242976.3125  ]
 [ 230555.65625 ]
 [ 182882.34375 ]
 [ 210134.5     ]
 [ 178947.171875]
 [ 187989.984375]
 [ 205527.203125]
 [ 233722.203125]
 [ 174276.890625]
 [ 166035.5625  ]
 [ 172648.359375]
 [ 232477.46875 ]
 [ 246646.09375 ]]
DEBUG:root:training time = %d0.225007
INFO:root:frame =6073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =6074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:random_action_porb = 0.952056666667
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000438928604126
INFO:root:frame =6078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
INFO:root:frame = 6079 State into memory, numbers recorded 164 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000633001327515
INFO:root:random_action_porb = 0.952025
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6080current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 248933.265625]
 [ 234003.671875]
 [ 190796.203125]
 [ 206562.265625]
 [ 179967.765625]
 [ 197726.125   ]
 [ 194265.734375]
 [ 179967.765625]
 [ 166556.453125]
 [ 234430.921875]
 [ 228901.046875]
 [ 231340.328125]
 [ 198670.859375]
 [ 198417.609375]
 [ 185073.890625]
 [ 225940.546875]]
DEBUG:root:training time = %d0.221696
INFO:root:frame =6081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000271797180176
INFO:root:frame =6082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.00025486946106
INFO:root:random_action_porb = 0.951993333333
DEBUG:root: dqn, choose action rondomly, need time 0.000583000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =6085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000446081161499
INFO:root:frame =6086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000553846359253
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:random_action_porb = 0.951961666667
DEBUG:root: dqn, choose action rondomly, need time 0.00031899999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:training error  = [[ 230922.015625]
 [ 189832.953125]
 [ 225047.859375]
 [ 220834.375   ]
 [ 192878.375   ]
 [ 251389.625   ]
 [ 241781.09375 ]
 [ 194583.078125]
 [ 228062.203125]
 [ 188791.515625]
 [ 183265.9375  ]
 [ 178081.53125 ]
 [ 214328.765625]
 [ 257615.71875 ]
 [ 196335.09375 ]
 [ 234322.171875]]
DEBUG:root:training time = %d0.21642
INFO:root:frame =6089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =6090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.00017786026001
INFO:root:random_action_porb = 0.95193
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =6093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478029251099
INFO:root:frame =6094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame = 6095 State into memory, numbers recorded 165 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000556945800781
INFO:root:random_action_porb = 0.951898333333
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6096current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000387191772461
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 205097.09375 ]
 [ 182615.171875]
 [ 233221.546875]
 [ 236702.203125]
 [ 229384.875   ]
 [ 199295.984375]
 [ 238924.296875]
 [ 230290.796875]
 [ 226881.96875 ]
 [ 239398.53125 ]
 [ 229754.515625]
 [ 223935.0625  ]
 [ 211774.78125 ]
 [ 211506.578125]
 [ 219547.609375]
 [ 230408.4375  ]]
DEBUG:root:training time = %d0.231442
INFO:root:frame =6097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =6098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000395059585571
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:random_action_porb = 0.951866666667
DEBUG:root: dqn, choose action rondomly, need time 0.000341999999989
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =6101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =6102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame = 6103 State into memory, numbers recorded 166 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000543117523193
INFO:root:random_action_porb = 0.951835
DEBUG:root: dqn, choose action rondomly, need time 0.000731000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6104current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000576019287109
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 200129.96875 ]
 [ 186489.03125 ]
 [ 218467.234375]
 [ 185976.984375]
 [ 195890.953125]
 [ 228446.1875  ]
 [ 200365.078125]
 [ 219225.140625]
 [ 232245.40625 ]
 [ 188584.515625]
 [ 206228.625   ]
 [ 192692.28125 ]
 [ 192692.28125 ]
 [ 220587.078125]
 [ 221498.921875]
 [ 202788.828125]]
DEBUG:root:training time = %d0.209007
INFO:root:frame =6105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:frame =6106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000290870666504
INFO:root:random_action_porb = 0.951803333333
DEBUG:root: dqn, choose action rondomly, need time 0.000349
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311851501465
INFO:root:frame =6109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000504970550537
INFO:root:frame =6110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000155925750732
INFO:root:random_action_porb = 0.951771666667
DEBUG:root: dqn, choose action rondomly, need time 0.000245000000007
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000325202941895
INFO:root:training error  = [[ 191065.03125 ]
 [ 233634.390625]
 [ 179390.296875]
 [ 177717.40625 ]
 [ 189107.34375 ]
 [ 189878.90625 ]
 [ 237854.34375 ]
 [ 200054.84375 ]
 [ 193114.75    ]
 [ 200054.84375 ]
 [ 172279.3125  ]
 [ 179074.4375  ]
 [ 198467.640625]
 [ 183153.484375]
 [ 193114.75    ]
 [ 229557.953125]]
DEBUG:root:training time = %d0.228073
INFO:root:frame =6113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000258922576904
INFO:root:frame =6114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00048303604126
INFO:root:frame = 6115 State into memory, numbers recorded 167 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000562906265259
INFO:root:random_action_porb = 0.95174
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000015
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6116current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =6117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =6118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000196933746338
INFO:root:random_action_porb = 0.951708333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 255598.375   ]
 [ 187737.71875 ]
 [ 203190.53125 ]
 [ 202309.328125]
 [ 189468.921875]
 [ 232889.1875  ]
 [ 219471.203125]
 [ 241838.234375]
 [ 180594.28125 ]
 [ 201852.765625]
 [ 199840.4375  ]
 [ 229075.34375 ]
 [ 201950.171875]
 [ 188117.890625]
 [ 266657.25    ]
 [ 183429.015625]]
DEBUG:root:training time = %d0.222742
INFO:root:frame =6121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:frame =6122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324964523315
DEBUG:root: save sample needs time = 0.000134944915771
INFO:root:random_action_porb = 0.951676666667
DEBUG:root: dqn, choose action rondomly, need time 0.000219000000016
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:frame =6125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =6126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000291109085083
DEBUG:root: save sample needs time = 0.000174999237061
INFO:root:random_action_porb = 0.951645
DEBUG:root: dqn, choose action rondomly, need time 0.000203999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000158071517944
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 180816.796875]
 [ 242091.875   ]
 [ 249103.34375 ]
 [ 246361.96875 ]
 [ 197007.671875]
 [ 182945.828125]
 [ 190462.34375 ]
 [ 259780.359375]
 [ 184402.3125  ]
 [ 184692.609375]
 [ 203165.      ]
 [ 197068.359375]
 [ 231519.796875]
 [ 258266.453125]
 [ 231519.796875]
 [ 249765.6875  ]]
DEBUG:root:training time = %d0.202957
INFO:root:frame =6129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000230073928833
INFO:root:frame =6130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000417947769165
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.951613333333
INFO:root:dqn select action Tensor("ArgMax_30:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00863200000001
INFO:root:action choosen by dqn [0]
INFO:root:frame =6132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000220060348511
INFO:root:frame =6133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262975692749
INFO:root:frame =6134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 0.000193119049072
INFO:root:random_action_porb = 0.951581666667
DEBUG:root: dqn, choose action rondomly, need time 0.00034100000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 238021.0625  ]
 [ 185052.890625]
 [ 190928.890625]
 [ 250410.328125]
 [ 262203.      ]
 [ 221600.96875 ]
 [ 244388.296875]
 [ 259825.15625 ]
 [ 225030.71875 ]
 [ 244388.296875]
 [ 250032.234375]
 [ 262203.      ]
 [ 235660.      ]
 [ 227127.640625]
 [ 254950.046875]
 [ 216712.078125]]
DEBUG:root:training time = %d0.202982
INFO:root:frame =6137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =6138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.95155
DEBUG:root: dqn, choose action rondomly, need time 0.00027399999999
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =6141 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00036096572876
INFO:root:frame =6142 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.951518333333
DEBUG:root: dqn, choose action rondomly, need time 0.000269000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6144 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:training error  = [[ 234535.890625]
 [ 239922.03125 ]
 [ 194699.84375 ]
 [ 219704.59375 ]
 [ 238852.703125]
 [ 214878.421875]
 [ 215309.59375 ]
 [ 229184.734375]
 [ 173994.078125]
 [ 218642.09375 ]
 [ 213165.265625]
 [ 228224.53125 ]
 [ 212220.375   ]
 [ 227459.125   ]
 [ 190528.84375 ]
 [ 208452.890625]]
DEBUG:root:training time = %d0.198227
INFO:root:frame =6145 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =6146 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444889068604
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:random_action_porb = 0.951486666667
DEBUG:root: dqn, choose action rondomly, need time 0.000310000000013
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6148 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000286817550659
INFO:root:frame =6149 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =6150 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.951455
DEBUG:root: dqn, choose action rondomly, need time 0.000282999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6152 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 205076.3125  ]
 [ 231438.046875]
 [ 232773.265625]
 [ 197824.28125 ]
 [ 200073.625   ]
 [ 244845.203125]
 [ 205076.3125  ]
 [ 206908.59375 ]
 [ 193080.421875]
 [ 218970.078125]
 [ 197488.234375]
 [ 247635.5     ]
 [ 233874.25    ]
 [ 211248.859375]
 [ 210552.828125]
 [ 206255.234375]]
DEBUG:root:training time = %d0.235736
INFO:root:frame =6153 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000385046005249
INFO:root:frame =6154 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269174575806
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.951423333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6156 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =6157 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444173812866
INFO:root:frame =6158 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000497817993164
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.951391666667
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6160 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 258490.8125  ]
 [ 195816.625   ]
 [ 266941.75    ]
 [ 202454.296875]
 [ 241475.296875]
 [ 201533.484375]
 [ 241427.3125  ]
 [ 201822.046875]
 [ 238918.5625  ]
 [ 203313.796875]
 [ 207877.21875 ]
 [ 265587.21875 ]
 [ 195532.375   ]
 [ 255395.      ]
 [ 196309.578125]
 [ 180828.421875]]
DEBUG:root:training time = %d0.217708
INFO:root:frame =6161 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =6162 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000355958938599
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.95136
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6164 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =6165 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466108322144
INFO:root:frame =6166 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:random_action_porb = 0.951328333333
DEBUG:root: dqn, choose action rondomly, need time 0.000323000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6168 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 233984.78125 ]
 [ 199480.      ]
 [ 229778.859375]
 [ 201093.5625  ]
 [ 189164.6875  ]
 [ 198888.125   ]
 [ 234102.890625]
 [ 267521.28125 ]
 [ 236688.90625 ]
 [ 239618.859375]
 [ 264291.375   ]
 [ 200158.375   ]
 [ 242550.484375]
 [ 199480.      ]
 [ 185099.9375  ]
 [ 239557.671875]]
DEBUG:root:training time = %d0.226016
INFO:root:frame =6169 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000257968902588
INFO:root:frame =6170 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275850296021
DEBUG:root: save sample needs time = 0.000333786010742
INFO:root:random_action_porb = 0.951296666667
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6172 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319004058838
INFO:root:frame =6173 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =6174 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000471115112305
INFO:root:frame = 6175 State into memory, numbers recorded 168 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000624179840088
INFO:root:random_action_porb = 0.951265
DEBUG:root: dqn, choose action rondomly, need time 0.000484999999998
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6176current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.00032114982605
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 239736.46875 ]
 [ 244041.796875]
 [ 233473.9375  ]
 [ 205531.1875  ]
 [ 206648.375   ]
 [ 247411.03125 ]
 [ 219668.890625]
 [ 219007.546875]
 [ 227121.125   ]
 [ 250544.234375]
 [ 214672.953125]
 [ 220287.21875 ]
 [ 210447.984375]
 [ 237538.203125]
 [ 227121.125   ]
 [ 227736.796875]]
DEBUG:root:training time = %d0.23196
INFO:root:frame =6177 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =6178 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000372886657715
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:random_action_porb = 0.951233333333
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6180 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000386953353882
INFO:root:frame =6181 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000633955001831
INFO:root:frame =6182 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.951201666667
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6184 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 249962.890625]
 [ 234860.4375  ]
 [ 227230.046875]
 [ 214536.328125]
 [ 209195.46875 ]
 [ 230085.109375]
 [ 222051.71875 ]
 [ 228858.53125 ]
 [ 224948.265625]
 [ 203330.53125 ]
 [ 209451.921875]
 [ 241124.15625 ]
 [ 205168.296875]
 [ 207009.      ]
 [ 213511.6875  ]
 [ 236117.21875 ]]
DEBUG:root:training time = %d0.225399
INFO:root:frame =6185 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =6186 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000271081924438
DEBUG:root: save sample needs time = 0.000225067138672
INFO:root:random_action_porb = 0.95117
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6188 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =6189 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000484943389893
INFO:root:frame =6190 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000223875045776
DEBUG:root: save sample needs time = 0.000104904174805
INFO:root:random_action_porb = 0.951138333333
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000021
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6192 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:training error  = [[ 220019.625   ]
 [ 222320.53125 ]
 [ 265518.78125 ]
 [ 206762.03125 ]
 [ 258455.0625  ]
 [ 216001.640625]
 [ 220430.25    ]
 [ 219744.875   ]
 [ 209557.421875]
 [ 225779.953125]
 [ 230659.765625]
 [ 227331.53125 ]
 [ 232703.546875]
 [ 206762.03125 ]
 [ 222668.78125 ]
 [ 237688.625   ]]
DEBUG:root:training time = %d0.227215
INFO:root:frame =6193 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:frame =6194 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.951106666667
DEBUG:root: dqn, choose action rondomly, need time 0.000284999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6196 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root:frame =6197 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =6198 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000447988510132
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.951075
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6200 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 213095.84375 ]
 [ 214631.328125]
 [ 213383.546875]
 [ 227501.046875]
 [ 226305.546875]
 [ 285055.875   ]
 [ 212486.78125 ]
 [ 210258.96875 ]
 [ 219113.59375 ]
 [ 260011.359375]
 [ 208981.125   ]
 [ 215948.09375 ]
 [ 282425.8125  ]
 [ 286471.65625 ]
 [ 245179.71875 ]
 [ 209238.34375 ]]
DEBUG:root:training time = %d0.237912
INFO:root:frame =6201 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:frame =6202 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00047492980957
DEBUG:root: save sample needs time = 0.0002121925354
INFO:root:random_action_porb = 0.951043333333
INFO:root:dqn select action Tensor("ArgMax_31:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.014107
INFO:root:action choosen by dqn [2]
INFO:root:frame =6204 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root:frame =6205 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00019907951355
INFO:root:frame =6206 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000236988067627
DEBUG:root: save sample needs time = 0.000155925750732
INFO:root:random_action_porb = 0.951011666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6208 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 286763.375   ]
 [ 277961.65625 ]
 [ 253078.75    ]
 [ 229918.375   ]
 [ 269608.40625 ]
 [ 286343.09375 ]
 [ 257826.921875]
 [ 234758.234375]
 [ 232846.78125 ]
 [ 281793.      ]
 [ 233292.78125 ]
 [ 256981.671875]
 [ 204055.125   ]
 [ 276326.8125  ]
 [ 220844.      ]
 [ 261561.328125]]
DEBUG:root:training time = %d0.218458
INFO:root:frame =6209 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00027322769165
INFO:root:frame =6210 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231981277466
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:random_action_porb = 0.95098
DEBUG:root: dqn, choose action rondomly, need time 0.000348000000002
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6212 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00069785118103
INFO:root:frame =6213 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =6214 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.950948333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6216 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 250957.953125]
 [ 230565.96875 ]
 [ 217485.59375 ]
 [ 270195.90625 ]
 [ 229406.390625]
 [ 236264.34375 ]
 [ 240227.296875]
 [ 236939.828125]
 [ 239503.1875  ]
 [ 244743.75    ]
 [ 270195.90625 ]
 [ 285551.4375  ]
 [ 214454.921875]
 [ 213393.46875 ]
 [ 229469.0625  ]
 [ 267724.375   ]]
DEBUG:root:training time = %d0.227732
INFO:root:frame =6217 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:frame =6218 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000312089920044
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.950916666667
DEBUG:root: dqn, choose action rondomly, need time 0.000308999999987
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6220 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root:frame =6221 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000460147857666
INFO:root:frame =6222 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455856323242
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.950885
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6224 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 250954.03125 ]
 [ 193618.90625 ]
 [ 259083.984375]
 [ 261447.46875 ]
 [ 293200.03125 ]
 [ 249448.546875]
 [ 287564.0625  ]
 [ 217577.609375]
 [ 281606.40625 ]
 [ 289314.78125 ]
 [ 278502.53125 ]
 [ 256052.796875]
 [ 219325.75    ]
 [ 240799.140625]
 [ 270687.5     ]
 [ 255464.109375]]
DEBUG:root:training time = %d0.206966
INFO:root:frame =6225 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277996063232
INFO:root:frame =6226 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000270128250122
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:random_action_porb = 0.950853333333
DEBUG:root: dqn, choose action rondomly, need time 0.000340000000023
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6228 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root:frame =6229 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000482797622681
INFO:root:frame =6230 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000235795974731
INFO:root:random_action_porb = 0.950821666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6232 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 273488.15625 ]
 [ 262707.3125  ]
 [ 245292.875   ]
 [ 237694.34375 ]
 [ 253028.65625 ]
 [ 283415.875   ]
 [ 245476.703125]
 [ 239660.921875]
 [ 270501.5625  ]
 [ 235626.8125  ]
 [ 216113.3125  ]
 [ 243991.625   ]
 [ 222983.171875]
 [ 247695.765625]
 [ 252989.359375]
 [ 264508.3125  ]]
DEBUG:root:training time = %d0.23264
INFO:root:frame =6233 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =6234 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000308036804199
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.95079
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6236 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312089920044
INFO:root:frame =6237 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000382900238037
INFO:root:frame =6238 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234127044678
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.950758333333
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6240 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:training error  = [[ 227870.109375]
 [ 298374.125   ]
 [ 266603.8125  ]
 [ 243486.34375 ]
 [ 221397.8125  ]
 [ 266603.8125  ]
 [ 230521.890625]
 [ 268811.875   ]
 [ 243486.34375 ]
 [ 251526.734375]
 [ 259511.640625]
 [ 262259.      ]
 [ 287119.09375 ]
 [ 251739.34375 ]
 [ 230016.71875 ]
 [ 239493.625   ]]
DEBUG:root:training time = %d0.212461
INFO:root:frame =6241 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:frame =6242 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247955322266
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.950726666667
DEBUG:root: dqn, choose action rondomly, need time 0.000410000000016
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6244 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00042986869812
INFO:root:frame =6245 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000504016876221
INFO:root:frame =6246 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000483989715576
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.950695
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000015
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6248 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 244209.703125]
 [ 223547.96875 ]
 [ 298462.6875  ]
 [ 319029.71875 ]
 [ 240937.171875]
 [ 273690.40625 ]
 [ 251256.453125]
 [ 287001.90625 ]
 [ 263138.9375  ]
 [ 311017.53125 ]
 [ 277619.90625 ]
 [ 222207.28125 ]
 [ 277025.40625 ]
 [ 318651.4375  ]
 [ 244209.703125]
 [ 278591.1875  ]]
DEBUG:root:training time = %d0.209974
INFO:root:frame =6249 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame =6250 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000433206558228
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.950663333333
DEBUG:root: dqn, choose action rondomly, need time 0.00040199999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6252 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000370025634766
INFO:root:frame =6253 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =6254 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000352144241333
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:random_action_porb = 0.950631666667
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6256 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 244032.140625]
 [ 282839.0625  ]
 [ 249079.953125]
 [ 278787.09375 ]
 [ 237465.859375]
 [ 289516.5     ]
 [ 280654.71875 ]
 [ 253013.90625 ]
 [ 237453.484375]
 [ 282929.46875 ]
 [ 261722.171875]
 [ 237694.34375 ]
 [ 270926.34375 ]
 [ 297323.125   ]
 [ 292559.5     ]
 [ 255171.984375]]
DEBUG:root:training time = %d0.222516
INFO:root:frame =6257 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:frame =6258 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000213146209717
INFO:root:random_action_porb = 0.9506
DEBUG:root: dqn, choose action rondomly, need time 0.000292999999999
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6260 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =6261 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =6262 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000704050064087
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.950568333333
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6264 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:training error  = [[ 285565.      ]
 [ 236798.1875  ]
 [ 231829.078125]
 [ 288756.15625 ]
 [ 214369.      ]
 [ 282569.0625  ]
 [ 265843.96875 ]
 [ 278198.5625  ]
 [ 205506.390625]
 [ 239917.234375]
 [ 284305.5625  ]
 [ 279878.1875  ]
 [ 284305.5625  ]
 [ 278198.5625  ]
 [ 309743.34375 ]
 [ 255389.078125]]
DEBUG:root:training time = %d0.224037
INFO:root:frame =6265 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:frame =6266 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:random_action_porb = 0.950536666667
INFO:root:dqn select action Tensor("ArgMax_32:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012343
INFO:root:action choosen by dqn [3]
INFO:root:frame =6268 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000193119049072
INFO:root:frame =6269 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000560998916626
INFO:root:frame =6270 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.950505
DEBUG:root: dqn, choose action rondomly, need time 0.000347000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6272 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000347852706909
INFO:root:training error  = [[ 228203.078125]
 [ 261550.34375 ]
 [ 268665.0625  ]
 [ 308431.625   ]
 [ 274292.59375 ]
 [ 256180.3125  ]
 [ 278129.53125 ]
 [ 275318.5     ]
 [ 293042.46875 ]
 [ 296711.0625  ]
 [ 228471.859375]
 [ 275896.78125 ]
 [ 277161.125   ]
 [ 256649.09375 ]
 [ 230568.78125 ]
 [ 239187.859375]]
DEBUG:root:training time = %d0.218128
INFO:root:frame =6273 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00050687789917
INFO:root:frame =6274 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000509977340698
INFO:root:frame = 6275 State into memory, numbers recorded 169 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000552892684937
INFO:root:random_action_porb = 0.950473333333
DEBUG:root: dqn, choose action rondomly, need time 0.000180999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6276current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000164031982422
INFO:root:frame =6277 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame =6278 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444173812866
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:random_action_porb = 0.950441666667
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6280 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 279219.34375 ]
 [ 240351.765625]
 [ 262159.      ]
 [ 272447.3125  ]
 [ 250627.34375 ]
 [ 245599.609375]
 [ 283524.      ]
 [ 244914.796875]
 [ 240158.375   ]
 [ 315499.4375  ]
 [ 339272.125   ]
 [ 293462.375   ]
 [ 323011.28125 ]
 [ 242927.6875  ]
 [ 304055.3125  ]
 [ 265393.      ]]
DEBUG:root:training time = %d0.208892
INFO:root:frame =6281 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:frame =6282 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000314950942993
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.95041
DEBUG:root: dqn, choose action rondomly, need time 0.000299999999982
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6284 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000380992889404
INFO:root:frame =6285 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00067400932312
INFO:root:frame =6286 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame = 6287 State into memory, numbers recorded 170 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000562906265259
INFO:root:random_action_porb = 0.950378333333
DEBUG:root: dqn, choose action rondomly, need time 0.00017299999999
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6288current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000133991241455
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 220699.921875]
 [ 261535.359375]
 [ 248170.359375]
 [ 243363.      ]
 [ 296460.03125 ]
 [ 258829.546875]
 [ 281181.625   ]
 [ 247405.203125]
 [ 260355.0625  ]
 [ 289377.8125  ]
 [ 279546.625   ]
 [ 242529.3125  ]
 [ 285536.8125  ]
 [ 292657.75    ]
 [ 245551.21875 ]
 [ 236553.046875]]
DEBUG:root:training time = %d0.234569
INFO:root:frame =6289 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:frame =6290 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000256061553955
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.950346666667
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6292 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =6293 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000444889068604
INFO:root:frame =6294 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.950315
DEBUG:root: dqn, choose action rondomly, need time 0.000167000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6296 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000154972076416
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 244157.578125]
 [ 301115.84375 ]
 [ 332438.96875 ]
 [ 259489.75    ]
 [ 286137.21875 ]
 [ 327442.125   ]
 [ 244398.921875]
 [ 257602.84375 ]
 [ 249562.6875  ]
 [ 337292.125   ]
 [ 249692.484375]
 [ 271017.84375 ]
 [ 281775.375   ]
 [ 280494.375   ]
 [ 323223.34375 ]
 [ 240962.09375 ]]
DEBUG:root:training time = %d0.237803
INFO:root:frame =6297 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =6298 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000226020812988
INFO:root:random_action_porb = 0.950283333333
INFO:root:dqn select action Tensor("ArgMax_33:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00813500000001
INFO:root:action choosen by dqn [0]
INFO:root:frame =6300 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =6301 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:frame =6302 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.950251666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000018
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6304 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000188827514648
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 331329.53125]
 [ 339695.46875]
 [ 303885.1875 ]
 [ 336747.875  ]
 [ 285376.09375]
 [ 337332.9375 ]
 [ 333167.96875]
 [ 288132.     ]
 [ 257249.0625 ]
 [ 257406.59375]
 [ 277275.25   ]
 [ 293855.03125]
 [ 293576.65625]
 [ 250209.03125]
 [ 251039.15625]
 [ 332452.46875]]
DEBUG:root:training time = %d0.212327
INFO:root:frame =6305 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000228881835938
INFO:root:frame =6306 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.95022
DEBUG:root: dqn, choose action rondomly, need time 0.000397000000021
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6308 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000448942184448
INFO:root:frame =6309 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =6310 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324010848999
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.950188333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6312 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 294591.34375 ]
 [ 267139.5625  ]
 [ 276043.53125 ]
 [ 276485.96875 ]
 [ 268750.09375 ]
 [ 279722.1875  ]
 [ 255040.78125 ]
 [ 303243.8125  ]
 [ 268060.      ]
 [ 298156.53125 ]
 [ 254994.421875]
 [ 300149.90625 ]
 [ 293669.78125 ]
 [ 268750.09375 ]
 [ 275397.40625 ]
 [ 275397.40625 ]]
DEBUG:root:training time = %d0.229178
INFO:root:frame =6313 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000248908996582
INFO:root:frame =6314 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000473976135254
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.950156666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6316 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297784805298
INFO:root:frame =6317 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame =6318 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.950125
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6320 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 347671.46875]
 [ 270266.96875]
 [ 283974.5    ]
 [ 257765.4375 ]
 [ 285708.     ]
 [ 268497.03125]
 [ 329767.5625 ]
 [ 330080.53125]
 [ 282352.125  ]
 [ 286574.125  ]
 [ 317261.5625 ]
 [ 282168.46875]
 [ 297735.40625]
 [ 280693.     ]
 [ 280841.     ]
 [ 275847.5625 ]]
DEBUG:root:training time = %d0.220735
INFO:root:frame =6321 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =6322 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000298023223877
DEBUG:root: save sample needs time = 0.000125169754028
INFO:root:random_action_porb = 0.950093333333
DEBUG:root: dqn, choose action rondomly, need time 0.000186999999983
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6324 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000327110290527
INFO:root:frame =6325 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame =6326 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.950061666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6328 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 237677.203125]
 [ 295183.15625 ]
 [ 263512.78125 ]
 [ 238907.109375]
 [ 284361.8125  ]
 [ 324249.0625  ]
 [ 264252.21875 ]
 [ 319026.40625 ]
 [ 267338.46875 ]
 [ 301983.53125 ]
 [ 331454.3125  ]
 [ 334160.78125 ]
 [ 286632.65625 ]
 [ 245466.0625  ]
 [ 300960.46875 ]
 [ 317491.53125 ]]
DEBUG:root:training time = %d0.234296
INFO:root:frame =6329 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:frame =6330 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000336170196533
INFO:root:frame = 6331 State into memory, numbers recorded 171 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000563144683838
INFO:root:random_action_porb = 0.95003
DEBUG:root: dqn, choose action rondomly, need time 0.000266000000011
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6332current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:frame =6333 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:frame =6334 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000443935394287
DEBUG:root: save sample needs time = 0.000118017196655
INFO:root:random_action_porb = 0.949998333333
DEBUG:root: dqn, choose action rondomly, need time 0.000187000000011
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6336 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000188827514648
INFO:root:training error  = [[ 249559.765625]
 [ 352300.21875 ]
 [ 300452.78125 ]
 [ 370507.59375 ]
 [ 339680.65625 ]
 [ 370507.59375 ]
 [ 257109.40625 ]
 [ 302373.25    ]
 [ 296753.625   ]
 [ 304156.5625  ]
 [ 334787.6875  ]
 [ 304156.5625  ]
 [ 326875.71875 ]
 [ 260245.453125]
 [ 312269.21875 ]
 [ 318917.1875  ]]
DEBUG:root:training time = %d0.218442
INFO:root:frame =6337 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =6338 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.949966666667
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999983
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6340 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =6341 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000518083572388
INFO:root:frame =6342 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000440835952759
DEBUG:root: save sample needs time = 0.000199794769287
INFO:root:random_action_porb = 0.949935
DEBUG:root: dqn, choose action rondomly, need time 0.000285000000019
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6344 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:training error  = [[ 313372.53125 ]
 [ 332128.21875 ]
 [ 326211.65625 ]
 [ 339511.0625  ]
 [ 338008.25    ]
 [ 257827.90625 ]
 [ 364964.65625 ]
 [ 283164.28125 ]
 [ 357331.90625 ]
 [ 254068.171875]
 [ 313372.53125 ]
 [ 324639.53125 ]
 [ 339596.4375  ]
 [ 236563.484375]
 [ 343904.375   ]
 [ 316842.5625  ]]
DEBUG:root:training time = %d0.209766
INFO:root:frame =6345 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =6346 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000293970108032
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.949903333333
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6348 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =6349 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =6350 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.949871666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6352 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 270317.75   ]
 [ 266927.625  ]
 [ 292711.65625]
 [ 298707.09375]
 [ 308027.15625]
 [ 264848.9375 ]
 [ 316409.53125]
 [ 292711.65625]
 [ 282128.     ]
 [ 300824.40625]
 [ 286411.03125]
 [ 303606.375  ]
 [ 292026.25   ]
 [ 303323.40625]
 [ 294840.53125]
 [ 310931.46875]]
DEBUG:root:training time = %d0.221
INFO:root:frame =6353 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =6354 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000338077545166
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.94984
DEBUG:root: dqn, choose action rondomly, need time 0.000349
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6356 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000407934188843
INFO:root:frame =6357 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =6358 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000265121459961
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.949808333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6360 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 277086.0625 ]
 [ 282795.4375 ]
 [ 281962.03125]
 [ 276848.625  ]
 [ 304202.875  ]
 [ 299562.71875]
 [ 290929.59375]
 [ 281962.03125]
 [ 382204.09375]
 [ 295493.09375]
 [ 274805.3125 ]
 [ 291662.21875]
 [ 270100.46875]
 [ 267960.90625]
 [ 352346.59375]
 [ 295437.90625]]
DEBUG:root:training time = %d0.231459
INFO:root:frame =6361 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =6362 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000351190567017
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.949776666667
DEBUG:root: dqn, choose action rondomly, need time 0.000189000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6364 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:frame =6365 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000277042388916
INFO:root:frame =6366 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000477075576782
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.949745
DEBUG:root: dqn, choose action rondomly, need time 0.000288999999981
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6368 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:training error  = [[ 281866.625  ]
 [ 293933.40625]
 [ 272724.65625]
 [ 349009.78125]
 [ 286251.125  ]
 [ 292421.125  ]
 [ 359071.3125 ]
 [ 343844.8125 ]
 [ 351365.3125 ]
 [ 358494.53125]
 [ 288528.4375 ]
 [ 279975.34375]
 [ 344700.84375]
 [ 281866.625  ]
 [ 359071.3125 ]
 [ 354577.21875]]
DEBUG:root:training time = %d0.205336
INFO:root:frame =6369 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286817550659
INFO:root:frame =6370 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00028395652771
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.949713333333
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6372 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =6373 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000645875930786
INFO:root:frame =6374 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000245094299316
INFO:root:random_action_porb = 0.949681666667
DEBUG:root: dqn, choose action rondomly, need time 0.000353999999987
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6376 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 287455.15625 ]
 [ 326759.59375 ]
 [ 341480.4375  ]
 [ 344226.28125 ]
 [ 260304.234375]
 [ 276164.625   ]
 [ 271345.34375 ]
 [ 363355.84375 ]
 [ 278929.4375  ]
 [ 334144.96875 ]
 [ 339192.5     ]
 [ 358252.53125 ]
 [ 287455.15625 ]
 [ 277866.9375  ]
 [ 314870.03125 ]
 [ 265342.6875  ]]
DEBUG:root:training time = %d0.227996
INFO:root:frame =6377 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =6378 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000515937805176
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.94965
DEBUG:root: dqn, choose action rondomly, need time 0.000366000000014
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6380 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000353097915649
INFO:root:frame =6381 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:frame =6382 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.949618333333
DEBUG:root: dqn, choose action rondomly, need time 0.000306000000023
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6384 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:training error  = [[ 286411.03125]
 [ 290587.3125 ]
 [ 289559.59375]
 [ 288796.03125]
 [ 339989.21875]
 [ 279701.53125]
 [ 289361.     ]
 [ 279701.53125]
 [ 268475.78125]
 [ 281277.96875]
 [ 295165.125  ]
 [ 305425.6875 ]
 [ 283578.09375]
 [ 281444.75   ]
 [ 283724.75   ]
 [ 312788.96875]]
DEBUG:root:training time = %d0.227812
INFO:root:frame =6385 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264167785645
INFO:root:frame =6386 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000279188156128
DEBUG:root: save sample needs time = 0.000220775604248
INFO:root:random_action_porb = 0.949586666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6388 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =6389 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000701189041138
INFO:root:frame =6390 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000446081161499
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.949555
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6392 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:training error  = [[ 289355.75   ]
 [ 295259.5625 ]
 [ 275965.53125]
 [ 301808.59375]
 [ 311311.6875 ]
 [ 283982.8125 ]
 [ 257939.     ]
 [ 295065.40625]
 [ 287624.8125 ]
 [ 276618.46875]
 [ 276873.28125]
 [ 293645.4375 ]
 [ 329353.8125 ]
 [ 289849.75   ]
 [ 287159.9375 ]
 [ 289932.8125 ]]
DEBUG:root:training time = %d0.222577
INFO:root:frame =6393 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =6394 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000264883041382
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.949523333333
DEBUG:root: dqn, choose action rondomly, need time 0.000334999999978
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6396 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root:frame =6397 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000536918640137
INFO:root:frame =6398 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482082366943
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.949491666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6400 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 347443.46875]
 [ 332536.9375 ]
 [ 288034.53125]
 [ 373435.5625 ]
 [ 305306.96875]
 [ 296002.9375 ]
 [ 299372.46875]
 [ 314672.78125]
 [ 307486.5    ]
 [ 290987.5625 ]
 [ 350689.5    ]
 [ 328279.75   ]
 [ 300054.65625]
 [ 285539.9375 ]
 [ 295306.28125]
 [ 334119.     ]]
DEBUG:root:training time = %d0.218396
INFO:root:frame =6401 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =6402 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466823577881
DEBUG:root: save sample needs time = 0.000199794769287
INFO:root:random_action_porb = 0.94946
DEBUG:root: dqn, choose action rondomly, need time 0.000333000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6404 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =6405 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00047492980957
INFO:root:frame =6406 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000486850738525
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.949428333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6408 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 352691.      ]
 [ 331140.6875  ]
 [ 290214.75    ]
 [ 259479.796875]
 [ 287596.53125 ]
 [ 289170.875   ]
 [ 322018.5625  ]
 [ 315834.125   ]
 [ 387882.03125 ]
 [ 330412.78125 ]
 [ 320494.1875  ]
 [ 291507.1875  ]
 [ 291507.1875  ]
 [ 287767.28125 ]
 [ 315834.125   ]
 [ 390404.09375 ]]
DEBUG:root:training time = %d0.22949
INFO:root:frame =6409 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root:frame =6410 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000580072402954
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.949396666667
INFO:root:dqn select action Tensor("ArgMax_34:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.010555
INFO:root:action choosen by dqn [2]
INFO:root:frame =6412 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000157833099365
INFO:root:frame =6413 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000338077545166
INFO:root:frame =6414 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.949365
DEBUG:root: dqn, choose action rondomly, need time 0.000422999999984
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6416 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 290619.96875]
 [ 393007.78125]
 [ 338780.84375]
 [ 398427.25   ]
 [ 350763.53125]
 [ 354405.125  ]
 [ 306449.8125 ]
 [ 288709.96875]
 [ 283210.03125]
 [ 385865.40625]
 [ 406407.5    ]
 [ 399667.21875]
 [ 416657.65625]
 [ 345788.78125]
 [ 280553.34375]
 [ 396073.5625 ]]
DEBUG:root:training time = %d0.223643
INFO:root:frame =6417 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000217914581299
INFO:root:frame =6418 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257968902588
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.949333333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6420 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =6421 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =6422 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450849533081
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.949301666667
DEBUG:root: dqn, choose action rondomly, need time 0.000565999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6424 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:training error  = [[ 363218.09375]
 [ 378953.25   ]
 [ 394587.625  ]
 [ 299252.8125 ]
 [ 308559.625  ]
 [ 382429.90625]
 [ 388742.5    ]
 [ 376445.75   ]
 [ 363108.625  ]
 [ 378316.28125]
 [ 305833.84375]
 [ 357423.     ]
 [ 309747.6875 ]
 [ 369835.03125]
 [ 388742.5    ]
 [ 384154.21875]]
DEBUG:root:training time = %d0.231563
INFO:root:frame =6425 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000208854675293
INFO:root:frame =6426 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000243186950684
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.94927
DEBUG:root: dqn, choose action rondomly, need time 0.000404000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6428 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:frame =6429 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458955764771
INFO:root:frame =6430 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000476121902466
DEBUG:root: save sample needs time = 0.00021505355835
INFO:root:random_action_porb = 0.949238333333
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6432 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:training error  = [[ 375966.5625 ]
 [ 300301.875  ]
 [ 297771.65625]
 [ 354616.75   ]
 [ 326593.28125]
 [ 310009.71875]
 [ 352214.4375 ]
 [ 294325.3125 ]
 [ 348354.71875]
 [ 366607.78125]
 [ 337612.0625 ]
 [ 369681.8125 ]
 [ 366607.78125]
 [ 380126.4375 ]
 [ 380913.1875 ]
 [ 329520.84375]]
DEBUG:root:training time = %d0.207617
INFO:root:frame =6433 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =6434 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000281095504761
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.949206666667
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6436 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =6437 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000505924224854
INFO:root:frame =6438 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000449180603027
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.949175
DEBUG:root: dqn, choose action rondomly, need time 0.000354999999985
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6440 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000421047210693
INFO:root:training error  = [[ 344265.25   ]
 [ 300896.1875 ]
 [ 371597.40625]
 [ 313369.25   ]
 [ 317641.21875]
 [ 320777.3125 ]
 [ 326829.9375 ]
 [ 321578.71875]
 [ 312578.1875 ]
 [ 343606.625  ]
 [ 304594.03125]
 [ 303963.78125]
 [ 382716.21875]
 [ 344870.59375]
 [ 298444.53125]
 [ 368803.5625 ]]
DEBUG:root:training time = %d0.214232
INFO:root:frame =6441 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =6442 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000277996063232
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.949143333333
DEBUG:root: dqn, choose action rondomly, need time 0.000372999999996
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6444 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000473976135254
INFO:root:frame =6445 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000571966171265
INFO:root:frame =6446 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:random_action_porb = 0.949111666667
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6448 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 414554.90625]
 [ 343430.34375]
 [ 340376.53125]
 [ 407234.6875 ]
 [ 343503.59375]
 [ 366512.     ]
 [ 367533.15625]
 [ 369252.0625 ]
 [ 343638.6875 ]
 [ 331980.78125]
 [ 329339.25   ]
 [ 329339.25   ]
 [ 377250.28125]
 [ 396970.125  ]
 [ 263536.84375]
 [ 378269.4375 ]]
DEBUG:root:training time = %d0.219307
INFO:root:frame =6449 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =6450 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.94908
DEBUG:root: dqn, choose action rondomly, need time 0.000358000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6452 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000521898269653
INFO:root:frame =6453 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000434160232544
INFO:root:frame =6454 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame = 6455 State into memory, numbers recorded 172 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000571012496948
INFO:root:random_action_porb = 0.949048333333
INFO:root:dqn select action Tensor("ArgMax_35:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011731
INFO:root:action choosen by dqn [2]
INFO:root:frame =6456current_observation done, NOT record action [2], reward = 0
DEBUG:root: save sample needs time = 0.000765085220337
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 343405.15625]
 [ 347659.9375 ]
 [ 321576.5    ]
 [ 341846.90625]
 [ 362590.96875]
 [ 375619.34375]
 [ 389155.4375 ]
 [ 396154.6875 ]
 [ 318858.75   ]
 [ 337480.4375 ]
 [ 342374.6875 ]
 [ 345122.96875]
 [ 339791.09375]
 [ 348033.15625]
 [ 333737.53125]
 [ 401746.75   ]]
DEBUG:root:training time = %d0.240579
INFO:root:frame =6457 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:frame =6458 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442981719971
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.949016666667
DEBUG:root: dqn, choose action rondomly, need time 0.000242999999983
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6460 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:frame =6461 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000462055206299
INFO:root:frame =6462 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248908996582
DEBUG:root: save sample needs time = 9.91821289062e-05
INFO:root:random_action_porb = 0.948985
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6464 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 394446.5625 ]
 [ 368694.4375 ]
 [ 343214.03125]
 [ 305691.28125]
 [ 379316.4375 ]
 [ 321630.75   ]
 [ 352042.90625]
 [ 417495.1875 ]
 [ 382329.65625]
 [ 359868.75   ]
 [ 344469.25   ]
 [ 351215.96875]
 [ 455911.125  ]
 [ 296072.     ]
 [ 358912.15625]
 [ 296072.     ]]
DEBUG:root:training time = %d0.223987
INFO:root:frame =6465 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =6466 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000353097915649
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.948953333333
INFO:root:dqn select action Tensor("ArgMax_36:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011749
INFO:root:action choosen by dqn [4]
INFO:root:frame =6468 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180006027222
INFO:root:frame =6469 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =6470 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452995300293
DEBUG:root: save sample needs time = 0.000199794769287
INFO:root:random_action_porb = 0.948921666667
DEBUG:root: dqn, choose action rondomly, need time 0.000625999999983
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6472 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 321873.375  ]
 [ 317150.46875]
 [ 393860.4375 ]
 [ 307780.0625 ]
 [ 327826.6875 ]
 [ 338070.6875 ]
 [ 415478.4375 ]
 [ 314704.5625 ]
 [ 312835.9375 ]
 [ 375017.5    ]
 [ 326025.375  ]
 [ 435866.875  ]
 [ 333695.78125]
 [ 322737.15625]
 [ 400131.625  ]
 [ 356764.71875]]
DEBUG:root:training time = %d0.223143
INFO:root:frame =6473 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:frame =6474 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000435829162598
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.94889
DEBUG:root: dqn, choose action rondomly, need time 0.000317000000024
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6476 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000301837921143
INFO:root:frame =6477 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000494003295898
INFO:root:frame =6478 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000280857086182
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.948858333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6480 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 372703.09375]
 [ 369150.     ]
 [ 355989.34375]
 [ 319061.6875 ]
 [ 344026.9375 ]
 [ 364713.375  ]
 [ 360729.28125]
 [ 362809.75   ]
 [ 328061.59375]
 [ 318869.78125]
 [ 303019.0625 ]
 [ 369810.0625 ]
 [ 319679.8125 ]
 [ 334872.4375 ]
 [ 321772.5625 ]
 [ 344152.9375 ]]
DEBUG:root:training time = %d0.228291
INFO:root:frame =6481 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000325202941895
INFO:root:frame =6482 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000349044799805
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:random_action_porb = 0.948826666667
DEBUG:root: dqn, choose action rondomly, need time 0.000330000000019
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6484 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000164985656738
INFO:root:frame =6485 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =6486 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000406980514526
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.948795
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6488 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 324605.0625 ]
 [ 352348.90625]
 [ 331283.4375 ]
 [ 349923.09375]
 [ 346174.8125 ]
 [ 356252.78125]
 [ 322511.96875]
 [ 450303.90625]
 [ 337046.     ]
 [ 377517.84375]
 [ 343501.3125 ]
 [ 362528.65625]
 [ 372285.875  ]
 [ 361963.21875]
 [ 363969.46875]
 [ 351778.71875]]
DEBUG:root:training time = %d0.206328
INFO:root:frame =6489 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:frame =6490 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000353097915649
INFO:root:frame = 6491 State into memory, numbers recorded 173 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000537872314453
INFO:root:random_action_porb = 0.948763333333
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000011
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6492current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:frame =6493 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000380039215088
INFO:root:frame =6494 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000281095504761
INFO:root:random_action_porb = 0.948731666667
DEBUG:root: dqn, choose action rondomly, need time 0.000167000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6496 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000132083892822
INFO:root:training error  = [[ 340501.875  ]
 [ 347182.1875 ]
 [ 358457.125  ]
 [ 379098.75   ]
 [ 349933.46875]
 [ 387056.53125]
 [ 359670.78125]
 [ 343545.9375 ]
 [ 438496.15625]
 [ 343545.9375 ]
 [ 339952.78125]
 [ 370825.09375]
 [ 384465.40625]
 [ 382635.28125]
 [ 327817.75   ]
 [ 397908.40625]]
DEBUG:root:training time = %d0.217081
INFO:root:frame =6497 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =6498 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000186920166016
INFO:root:random_action_porb = 0.9487
DEBUG:root: dqn, choose action rondomly, need time 0.000602999999984
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6500 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root:frame =6501 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000483989715576
INFO:root:frame =6502 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000411987304688
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.948668333333
DEBUG:root: dqn, choose action rondomly, need time 0.000249999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6504 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000169038772583
INFO:root:training error  = [[ 465473.0625 ]
 [ 445457.1875 ]
 [ 391685.28125]
 [ 425340.90625]
 [ 376152.21875]
 [ 337708.53125]
 [ 438700.53125]
 [ 465473.0625 ]
 [ 359629.78125]
 [ 349600.8125 ]
 [ 368985.0625 ]
 [ 417752.65625]
 [ 389517.375  ]
 [ 368636.34375]
 [ 328025.78125]
 [ 427947.21875]]
DEBUG:root:training time = %d0.211849
INFO:root:frame =6505 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221014022827
INFO:root:frame =6506 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000244855880737
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:random_action_porb = 0.948636666667
DEBUG:root: dqn, choose action rondomly, need time 0.000323000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6508 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000299215316772
INFO:root:frame =6509 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000461101531982
INFO:root:frame =6510 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.948605
DEBUG:root: dqn, choose action rondomly, need time 0.000248999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6512 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 316832.65625]
 [ 451853.09375]
 [ 359770.34375]
 [ 374638.4375 ]
 [ 327150.5    ]
 [ 380201.09375]
 [ 437481.46875]
 [ 382983.3125 ]
 [ 450907.     ]
 [ 403994.3125 ]
 [ 375660.0625 ]
 [ 372666.125  ]
 [ 341806.9375 ]
 [ 372142.90625]
 [ 395739.28125]
 [ 413882.375  ]]
DEBUG:root:training time = %d0.218053
INFO:root:frame =6513 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =6514 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000482797622681
DEBUG:root: save sample needs time = 0.000134229660034
INFO:root:random_action_porb = 0.948573333333
DEBUG:root: dqn, choose action rondomly, need time 0.000289000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6516 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308990478516
INFO:root:frame =6517 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000514030456543
INFO:root:frame =6518 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000545024871826
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.948541666667
DEBUG:root: dqn, choose action rondomly, need time 0.000360999999998
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6520 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000375986099243
INFO:root:training error  = [[ 341380.     ]
 [ 406407.5    ]
 [ 384075.53125]
 [ 375280.6875 ]
 [ 399240.09375]
 [ 341380.     ]
 [ 400582.6875 ]
 [ 394081.09375]
 [ 341138.125  ]
 [ 388287.1875 ]
 [ 330758.65625]
 [ 394714.     ]
 [ 384460.5625 ]
 [ 399240.09375]
 [ 382301.90625]
 [ 413217.96875]]
DEBUG:root:training time = %d0.224776
INFO:root:frame =6521 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000399112701416
INFO:root:frame =6522 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000441074371338
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.94851
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6524 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =6525 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame =6526 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00032901763916
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:random_action_porb = 0.948478333333
DEBUG:root: dqn, choose action rondomly, need time 0.000598999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6528 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000456809997559
INFO:root:training error  = [[ 425086.1875 ]
 [ 355887.96875]
 [ 408276.0625 ]
 [ 434790.84375]
 [ 429483.125  ]
 [ 374584.65625]
 [ 387246.09375]
 [ 405272.75   ]
 [ 351341.     ]
 [ 384091.28125]
 [ 397685.4375 ]
 [ 360371.59375]
 [ 441202.125  ]
 [ 330081.65625]
 [ 405272.75   ]
 [ 347816.59375]]
DEBUG:root:training time = %d0.213363
INFO:root:frame =6529 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00039005279541
INFO:root:frame =6530 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:random_action_porb = 0.948446666667
DEBUG:root: dqn, choose action rondomly, need time 0.000320000000016
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6532 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =6533 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000394105911255
INFO:root:frame =6534 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000499963760376
DEBUG:root: save sample needs time = 0.000152111053467
INFO:root:random_action_porb = 0.948415
DEBUG:root: dqn, choose action rondomly, need time 0.00022899999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6536 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:training error  = [[ 355220.65625]
 [ 346682.90625]
 [ 344063.59375]
 [ 385852.0625 ]
 [ 390943.65625]
 [ 356437.     ]
 [ 376834.125  ]
 [ 403459.4375 ]
 [ 350698.75   ]
 [ 338838.8125 ]
 [ 367645.625  ]
 [ 373787.75   ]
 [ 412436.15625]
 [ 366645.625  ]
 [ 412436.15625]
 [ 412436.15625]]
DEBUG:root:training time = %d0.185892
INFO:root:frame =6537 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =6538 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00121188163757
DEBUG:root: save sample needs time = 0.00013279914856
INFO:root:random_action_porb = 0.948383333333
DEBUG:root: dqn, choose action rondomly, need time 0.000278000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6540 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00193309783936
INFO:root:frame =6541 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00121092796326
INFO:root:frame =6542 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000417947769165
DEBUG:root: save sample needs time = 0.000143051147461
INFO:root:random_action_porb = 0.948351666667
DEBUG:root: dqn, choose action rondomly, need time 0.000331999999986
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6544 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:training error  = [[ 350815.59375]
 [ 445504.09375]
 [ 442961.75   ]
 [ 449291.34375]
 [ 351293.53125]
 [ 354720.28125]
 [ 377311.46875]
 [ 379648.53125]
 [ 389582.     ]
 [ 387775.     ]
 [ 352794.25   ]
 [ 404996.75   ]
 [ 442389.96875]
 [ 453815.375  ]
 [ 363121.59375]
 [ 377324.65625]]
DEBUG:root:training time = %d0.170671
INFO:root:frame =6545 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000329971313477
INFO:root:frame =6546 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame = 6547 State into memory, numbers recorded 174 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000289916992188
INFO:root:random_action_porb = 0.94832
DEBUG:root: dqn, choose action rondomly, need time 0.000241999999986
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6548current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root:frame =6549 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame =6550 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000319004058838
DEBUG:root: save sample needs time = 9.98973846436e-05
INFO:root:random_action_porb = 0.948288333333
DEBUG:root: dqn, choose action rondomly, need time 0.000197000000014
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6552 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000182151794434
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 383488.71875]
 [ 392639.3125 ]
 [ 377322.25   ]
 [ 363096.875  ]
 [ 482337.03125]
 [ 386263.46875]
 [ 391067.03125]
 [ 420969.0625 ]
 [ 390778.8125 ]
 [ 400104.4375 ]
 [ 390545.65625]
 [ 391067.03125]
 [ 391440.84375]
 [ 368985.0625 ]
 [ 343608.90625]
 [ 420969.0625 ]]
DEBUG:root:training time = %d0.183491
INFO:root:frame =6553 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000218868255615
INFO:root:frame =6554 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000429153442383
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:random_action_porb = 0.948256666667
DEBUG:root: dqn, choose action rondomly, need time 0.000190000000003
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6556 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000157833099365
INFO:root:frame =6557 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:frame =6558 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 9.48905944824e-05
INFO:root:random_action_porb = 0.948225
DEBUG:root: dqn, choose action rondomly, need time 0.000160000000022
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6560 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000136852264404
INFO:root:training error  = [[ 420832.21875]
 [ 409462.5    ]
 [ 465287.84375]
 [ 452307.46875]
 [ 415692.5    ]
 [ 466569.03125]
 [ 346725.46875]
 [ 417726.15625]
 [ 378839.0625 ]
 [ 427203.9375 ]
 [ 391843.     ]
 [ 391731.75   ]
 [ 470428.53125]
 [ 417726.15625]
 [ 473274.125  ]
 [ 416845.5    ]]
DEBUG:root:training time = %d0.185189
INFO:root:frame =6561 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000209093093872
INFO:root:frame =6562 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275850296021
DEBUG:root: save sample needs time = 0.000102996826172
INFO:root:random_action_porb = 0.948193333333
DEBUG:root: dqn, choose action rondomly, need time 0.000261999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6564 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:frame =6565 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000255107879639
INFO:root:frame =6566 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000353097915649
DEBUG:root: save sample needs time = 9.79900360107e-05
INFO:root:random_action_porb = 0.948161666667
DEBUG:root: dqn, choose action rondomly, need time 0.000166000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6568 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000179052352905
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 487221.71875]
 [ 464318.46875]
 [ 469729.53125]
 [ 469729.53125]
 [ 470645.5625 ]
 [ 452090.78125]
 [ 481603.46875]
 [ 465012.125  ]
 [ 467404.5625 ]
 [ 460038.96875]
 [ 462659.03125]
 [ 452508.46875]
 [ 404057.625  ]
 [ 487221.71875]
 [ 375910.28125]
 [ 455299.4375 ]]
DEBUG:root:training time = %d0.179095
INFO:root:frame =6569 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000301122665405
INFO:root:frame =6570 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000294923782349
DEBUG:root: save sample needs time = 0.000107049942017
INFO:root:random_action_porb = 0.94813
DEBUG:root: dqn, choose action rondomly, need time 0.000195999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6572 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000168085098267
INFO:root:frame =6573 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000400066375732
INFO:root:frame =6574 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000627994537354
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.948098333333
DEBUG:root: dqn, choose action rondomly, need time 0.000244000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6576 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 408343.46875]
 [ 418107.46875]
 [ 369848.09375]
 [ 434072.5    ]
 [ 389053.09375]
 [ 434421.3125 ]
 [ 417254.1875 ]
 [ 353165.5625 ]
 [ 423029.5625 ]
 [ 375590.625  ]
 [ 397324.625  ]
 [ 360986.21875]
 [ 363923.53125]
 [ 430901.21875]
 [ 402427.9375 ]
 [ 375174.1875 ]]
DEBUG:root:training time = %d0.181607
INFO:root:frame =6577 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame =6578 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427007675171
DEBUG:root: save sample needs time = 9.70363616943e-05
INFO:root:random_action_porb = 0.948066666667
DEBUG:root: dqn, choose action rondomly, need time 0.000366000000014
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6580 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =6581 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000259876251221
INFO:root:frame =6582 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000257015228271
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.948035
DEBUG:root: dqn, choose action rondomly, need time 0.000191999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6584 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000137805938721
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 379798.96875]
 [ 465406.4375 ]
 [ 393274.75   ]
 [ 368528.4375 ]
 [ 496806.09375]
 [ 401186.15625]
 [ 374297.8125 ]
 [ 405918.3125 ]
 [ 384619.21875]
 [ 372561.21875]
 [ 361453.40625]
 [ 379798.96875]
 [ 379486.09375]
 [ 374297.8125 ]
 [ 372561.21875]
 [ 377725.46875]]
DEBUG:root:training time = %d0.178489
INFO:root:frame =6585 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00030779838562
INFO:root:frame =6586 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000316858291626
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:random_action_porb = 0.948003333333
DEBUG:root: dqn, choose action rondomly, need time 0.000182999999993
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6588 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000195980072021
INFO:root:frame =6589 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root:frame =6590 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000324964523315
DEBUG:root: save sample needs time = 0.000149965286255
INFO:root:random_action_porb = 0.947971666667
DEBUG:root: dqn, choose action rondomly, need time 0.000184999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6592 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000198125839233
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 492873.9375 ]
 [ 508465.09375]
 [ 477031.6875 ]
 [ 386890.0625 ]
 [ 367817.375  ]
 [ 372809.21875]
 [ 449186.625  ]
 [ 489397.25   ]
 [ 444736.59375]
 [ 480716.0625 ]
 [ 384207.5    ]
 [ 370192.625  ]
 [ 532160.25   ]
 [ 466236.90625]
 [ 462307.03125]
 [ 359375.65625]]
DEBUG:root:training time = %d0.179753
INFO:root:frame =6593 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000264883041382
INFO:root:frame =6594 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000371932983398
DEBUG:root: save sample needs time = 0.000155925750732
INFO:root:random_action_porb = 0.94794
DEBUG:root: dqn, choose action rondomly, need time 0.00016100000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6596 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:frame =6597 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame =6598 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466823577881
DEBUG:root: save sample needs time = 0.000235080718994
INFO:root:random_action_porb = 0.947908333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6600 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000158071517944
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 414474.40625]
 [ 525945.0625 ]
 [ 497515.3125 ]
 [ 365489.90625]
 [ 517966.96875]
 [ 429365.375  ]
 [ 344511.6875 ]
 [ 387207.21875]
 [ 327806.5625 ]
 [ 381726.0625 ]
 [ 486481.71875]
 [ 367963.09375]
 [ 488479.5    ]
 [ 450556.90625]
 [ 419282.8125 ]
 [ 429067.21875]]
DEBUG:root:training time = %d0.215375
INFO:root:frame =6601 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =6602 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043511390686
INFO:root:frame = 6603 State into memory, numbers recorded 175 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:random_action_porb = 0.947876666667
DEBUG:root: dqn, choose action rondomly, need time 0.000337000000002
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6604current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =6605 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =6606 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.947845
DEBUG:root: dqn, choose action rondomly, need time 0.000312000000008
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6608 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 387689.875  ]
 [ 452805.4375 ]
 [ 492924.65625]
 [ 491357.1875 ]
 [ 467510.0625 ]
 [ 498582.1875 ]
 [ 436207.375  ]
 [ 465920.90625]
 [ 441027.     ]
 [ 485256.46875]
 [ 462813.125  ]
 [ 457344.4375 ]
 [ 490545.65625]
 [ 377615.0625 ]
 [ 510225.59375]
 [ 449138.1875 ]]
DEBUG:root:training time = %d0.235091
INFO:root:frame =6609 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:frame =6610 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000591993331909
DEBUG:root: save sample needs time = 0.000141859054565
INFO:root:random_action_porb = 0.947813333333
DEBUG:root: dqn, choose action rondomly, need time 0.000286999999986
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6612 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000294923782349
INFO:root:frame =6613 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:frame =6614 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000279188156128
INFO:root:random_action_porb = 0.947781666667
DEBUG:root: dqn, choose action rondomly, need time 0.000349999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6616 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302791595459
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 418784.65625]
 [ 455038.53125]
 [ 450782.40625]
 [ 427180.96875]
 [ 428939.28125]
 [ 388993.40625]
 [ 400687.75   ]
 [ 456112.9375 ]
 [ 451656.1875 ]
 [ 415289.625  ]
 [ 424772.96875]
 [ 460635.28125]
 [ 455038.53125]
 [ 371221.25   ]
 [ 451983.09375]
 [ 456624.875  ]]
DEBUG:root:training time = %d0.235562
INFO:root:frame =6617 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000330924987793
INFO:root:frame =6618 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.94775
DEBUG:root: dqn, choose action rondomly, need time 0.000329999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6620 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:frame =6621 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000411987304688
INFO:root:frame =6622 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000500202178955
INFO:root:frame = 6623 State into memory, numbers recorded 176 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000348091125488
INFO:root:random_action_porb = 0.947718333333
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6624current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000515937805176
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 415238.03125]
 [ 449726.09375]
 [ 462621.8125 ]
 [ 488502.71875]
 [ 500013.34375]
 [ 416607.21875]
 [ 514612.875  ]
 [ 466631.75   ]
 [ 441902.9375 ]
 [ 387534.21875]
 [ 515320.6875 ]
 [ 429132.46875]
 [ 478643.71875]
 [ 512826.625  ]
 [ 431532.25   ]
 [ 452725.28125]]
DEBUG:root:training time = %d0.215826
INFO:root:frame =6625 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =6626 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000232934951782
INFO:root:frame = 6627 State into memory, numbers recorded 177 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.00063681602478
INFO:root:random_action_porb = 0.947686666667
DEBUG:root: dqn, choose action rondomly, need time 0.000191999999998
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6628current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.00102210044861
INFO:root:frame =6629 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000341892242432
INFO:root:frame =6630 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00055193901062
DEBUG:root: save sample needs time = 0.000214815139771
INFO:root:random_action_porb = 0.947655
DEBUG:root: dqn, choose action rondomly, need time 0.000371000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6632 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000494003295898
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 520622.84375]
 [ 412565.34375]
 [ 500488.53125]
 [ 400340.4375 ]
 [ 434082.8125 ]
 [ 391426.1875 ]
 [ 456421.625  ]
 [ 435865.59375]
 [ 386665.34375]
 [ 399691.90625]
 [ 406931.84375]
 [ 516727.90625]
 [ 499705.40625]
 [ 434090.53125]
 [ 514933.78125]
 [ 418444.75   ]]
DEBUG:root:training time = %d0.213188
INFO:root:frame =6633 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000379085540771
INFO:root:frame =6634 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000434875488281
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.947623333333
DEBUG:root: dqn, choose action rondomly, need time 0.000595000000004
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6636 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000396966934204
INFO:root:frame =6637 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000558853149414
INFO:root:frame =6638 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000576972961426
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.947591666667
DEBUG:root: dqn, choose action rondomly, need time 0.000195999999988
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6640 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 422812.375  ]
 [ 498851.125  ]
 [ 507503.1875 ]
 [ 421862.9375 ]
 [ 506855.     ]
 [ 467284.40625]
 [ 474416.90625]
 [ 489259.25   ]
 [ 425800.84375]
 [ 474416.90625]
 [ 495448.25   ]
 [ 420022.96875]
 [ 502746.09375]
 [ 498851.125  ]
 [ 468601.75   ]
 [ 497575.9375 ]]
DEBUG:root:training time = %d0.217718
INFO:root:frame =6641 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000395059585571
INFO:root:frame =6642 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000406980514526
DEBUG:root: save sample needs time = 0.000224113464355
INFO:root:random_action_porb = 0.94756
INFO:root:dqn select action Tensor("ArgMax_37:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.012156
INFO:root:action choosen by dqn [4]
INFO:root:frame =6644 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000163078308105
INFO:root:frame =6645 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:frame =6646 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
INFO:root:frame = 6647 State into memory, numbers recorded 178 action = [4], reward = 0
DEBUG:root: save sample needs time = 0.00128602981567
INFO:root:random_action_porb = 0.947528333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6648current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000306129455566
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 409452.5    ]
 [ 488015.5    ]
 [ 517581.875  ]
 [ 494755.625  ]
 [ 522466.375  ]
 [ 475705.21875]
 [ 465418.4375 ]
 [ 488976.5    ]
 [ 402458.90625]
 [ 515050.125  ]
 [ 413803.21875]
 [ 546961.375  ]
 [ 468435.96875]
 [ 453527.28125]
 [ 494513.875  ]
 [ 460698.90625]]
DEBUG:root:training time = %d0.223977
INFO:root:frame =6649 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:frame =6650 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000475883483887
INFO:root:frame = 6651 State into memory, numbers recorded 179 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000574827194214
INFO:root:random_action_porb = 0.947496666667
INFO:root:dqn select action Tensor("ArgMax_38:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013916
INFO:root:action choosen by dqn [2]
INFO:root:frame =6652current_observation done, NOT record action [2], reward = 0
DEBUG:root: save sample needs time = 0.000874042510986
INFO:root:frame =6653 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00039005279541
INFO:root:frame =6654 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000448942184448
DEBUG:root: save sample needs time = 0.000177145004272
INFO:root:random_action_porb = 0.947465
DEBUG:root: dqn, choose action rondomly, need time 0.000305999999995
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6656 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:training error  = [[ 425653.03125]
 [ 486220.21875]
 [ 477424.3125 ]
 [ 441447.34375]
 [ 441010.125  ]
 [ 519626.96875]
 [ 420895.5625 ]
 [ 457102.75   ]
 [ 461094.0625 ]
 [ 417520.4375 ]
 [ 433731.59375]
 [ 425047.96875]
 [ 461094.0625 ]
 [ 414192.8125 ]
 [ 441447.34375]
 [ 435779.1875 ]]
DEBUG:root:training time = %d0.232818
INFO:root:frame =6657 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root:frame =6658 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.947433333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6660 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root:frame =6661 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463008880615
INFO:root:frame =6662 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000465154647827
DEBUG:root: save sample needs time = 0.000229120254517
INFO:root:random_action_porb = 0.947401666667
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6664 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 520419.9375 ]
 [ 455912.4375 ]
 [ 459636.34375]
 [ 462863.625  ]
 [ 513495.40625]
 [ 440081.9375 ]
 [ 425269.5625 ]
 [ 461515.90625]
 [ 501425.8125 ]
 [ 449629.1875 ]
 [ 453376.03125]
 [ 441308.5    ]
 [ 473877.625  ]
 [ 440081.9375 ]
 [ 430332.15625]
 [ 406503.375  ]]
DEBUG:root:training time = %d0.223847
INFO:root:frame =6665 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000369071960449
INFO:root:frame =6666 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000466108322144
DEBUG:root: save sample needs time = 0.000242948532104
INFO:root:random_action_porb = 0.94737
DEBUG:root: dqn, choose action rondomly, need time 0.000330000000019
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6668 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000341892242432
INFO:root:frame =6669 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000471115112305
INFO:root:frame =6670 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000459909439087
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.947338333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6672 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:training error  = [[ 493966.     ]
 [ 446943.1875 ]
 [ 543668.625  ]
 [ 529661.3125 ]
 [ 458061.9375 ]
 [ 460710.84375]
 [ 472092.46875]
 [ 550990.125  ]
 [ 495095.     ]
 [ 423068.9375 ]
 [ 414259.4375 ]
 [ 442916.25   ]
 [ 467093.5    ]
 [ 457240.09375]
 [ 511783.75   ]
 [ 480185.375  ]]
DEBUG:root:training time = %d0.203021
INFO:root:frame =6673 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00031304359436
INFO:root:frame =6674 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000455141067505
DEBUG:root: save sample needs time = 0.000209808349609
INFO:root:random_action_porb = 0.947306666667
DEBUG:root: dqn, choose action rondomly, need time 0.000551999999999
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6676 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00088906288147
INFO:root:frame =6677 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =6678 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000932216644287
INFO:root:frame = 6679 State into memory, numbers recorded 180 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000580072402954
INFO:root:random_action_porb = 0.947275
DEBUG:root: dqn, choose action rondomly, need time 0.000347000000005
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6680current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000341892242432
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 446580.25   ]
 [ 423705.65625]
 [ 447892.9375 ]
 [ 520928.6875 ]
 [ 413941.4375 ]
 [ 549525.375  ]
 [ 493981.09375]
 [ 433946.40625]
 [ 559039.5    ]
 [ 483406.5    ]
 [ 487159.     ]
 [ 521801.65625]
 [ 520908.96875]
 [ 447409.4375 ]
 [ 541880.     ]
 [ 425840.375  ]]
DEBUG:root:training time = %d0.221553
INFO:root:frame =6681 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =6682 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000597953796387
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.947243333333
DEBUG:root: dqn, choose action rondomly, need time 0.000386999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6684 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000519990921021
INFO:root:frame =6685 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045919418335
INFO:root:frame =6686 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000602006912231
DEBUG:root: save sample needs time = 0.000192880630493
INFO:root:random_action_porb = 0.947211666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297999999987
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6688 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 618639.0625 ]
 [ 569240.75   ]
 [ 509598.     ]
 [ 514873.53125]
 [ 523210.625  ]
 [ 486500.8125 ]
 [ 549128.75   ]
 [ 430744.8125 ]
 [ 563281.0625 ]
 [ 422593.9375 ]
 [ 455882.125  ]
 [ 514873.53125]
 [ 508618.3125 ]
 [ 618639.0625 ]
 [ 430603.8125 ]
 [ 463524.28125]]
DEBUG:root:training time = %d0.23152
INFO:root:frame =6689 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000237941741943
INFO:root:frame =6690 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.000419855117798
INFO:root:random_action_porb = 0.94718
DEBUG:root: dqn, choose action rondomly, need time 0.000279000000006
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6692 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000347852706909
INFO:root:frame =6693 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447988510132
INFO:root:frame =6694 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000501871109009
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.947148333333
DEBUG:root: dqn, choose action rondomly, need time 0.000331999999986
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6696 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000393152236938
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 446093.53125]
 [ 557101.875  ]
 [ 508136.46875]
 [ 506836.9375 ]
 [ 443938.5    ]
 [ 514334.09375]
 [ 442225.     ]
 [ 433941.28125]
 [ 426915.46875]
 [ 456664.46875]
 [ 475099.21875]
 [ 497232.9375 ]
 [ 515158.0625 ]
 [ 536167.1875 ]
 [ 504101.375  ]
 [ 434199.90625]]
DEBUG:root:training time = %d0.221312
INFO:root:frame =6697 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root:frame =6698 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00043797492981
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:random_action_porb = 0.947116666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6700 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000305891036987
INFO:root:frame =6701 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000586032867432
INFO:root:frame =6702 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000456094741821
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.947085
INFO:root:dqn select action Tensor("ArgMax_39:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.013169
INFO:root:action choosen by dqn [2]
INFO:root:frame =6704 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000339031219482
INFO:root:training error  = [[ 450289.5    ]
 [ 464414.3125 ]
 [ 447008.46875]
 [ 466290.25   ]
 [ 465158.625  ]
 [ 541931.75   ]
 [ 541931.75   ]
 [ 546905.     ]
 [ 547334.125  ]
 [ 509132.40625]
 [ 547334.125  ]
 [ 513373.65625]
 [ 480610.46875]
 [ 566567.875  ]
 [ 519273.65625]
 [ 566734.     ]]
DEBUG:root:training time = %d0.21947
INFO:root:frame =6705 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =6706 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000284910202026
DEBUG:root: save sample needs time = 0.000128030776978
INFO:root:random_action_porb = 0.947053333333
DEBUG:root: dqn, choose action rondomly, need time 0.000189000000006
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6708 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000182867050171
INFO:root:frame =6709 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =6710 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
INFO:root:frame = 6711 State into memory, numbers recorded 181 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000584125518799
INFO:root:random_action_porb = 0.947021666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6712current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 490485.46875]
 [ 570063.3125 ]
 [ 572070.625  ]
 [ 497906.625  ]
 [ 445102.6875 ]
 [ 431337.25   ]
 [ 482562.21875]
 [ 542238.0625 ]
 [ 534114.     ]
 [ 482562.21875]
 [ 468736.8125 ]
 [ 509454.40625]
 [ 426521.25   ]
 [ 467974.90625]
 [ 462668.3125 ]
 [ 572419.3125 ]]
DEBUG:root:training time = %d0.22351
INFO:root:frame =6713 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000326871871948
INFO:root:frame =6714 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0003981590271
DEBUG:root: save sample needs time = 0.00010085105896
INFO:root:random_action_porb = 0.94699
DEBUG:root: dqn, choose action rondomly, need time 0.000328999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6716 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000340938568115
INFO:root:frame =6717 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =6718 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000437021255493
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:random_action_porb = 0.946958333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6720 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root:training error  = [[ 464930.875  ]
 [ 407183.5625 ]
 [ 549144.6875 ]
 [ 509040.4375 ]
 [ 549858.4375 ]
 [ 448194.9375 ]
 [ 438231.0625 ]
 [ 526823.625  ]
 [ 560230.3125 ]
 [ 474688.71875]
 [ 407183.5625 ]
 [ 444448.78125]
 [ 521698.65625]
 [ 521698.65625]
 [ 500588.03125]
 [ 546486.25   ]]
DEBUG:root:training time = %d0.218384
INFO:root:frame =6721 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =6722 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000430107116699
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.946926666667
DEBUG:root: dqn, choose action rondomly, need time 0.000292000000002
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6724 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root:frame =6725 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000504970550537
INFO:root:frame =6726 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000508069992065
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.946895
DEBUG:root: dqn, choose action rondomly, need time 0.000381000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6728 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:training error  = [[ 444771.75   ]
 [ 460565.03125]
 [ 473913.90625]
 [ 491563.9375 ]
 [ 470044.15625]
 [ 470208.875  ]
 [ 491563.9375 ]
 [ 456547.     ]
 [ 470044.15625]
 [ 498773.875  ]
 [ 452458.5625 ]
 [ 470001.3125 ]
 [ 405087.5    ]
 [ 478631.5625 ]
 [ 476312.96875]
 [ 459522.46875]]
DEBUG:root:training time = %d0.207853
INFO:root:frame =6729 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00026798248291
INFO:root:frame =6730 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000266075134277
DEBUG:root: save sample needs time = 0.000233888626099
INFO:root:random_action_porb = 0.946863333333
DEBUG:root: dqn, choose action rondomly, need time 0.000299000000012
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6732 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000316858291626
INFO:root:frame =6733 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =6734 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000560998916626
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.946831666667
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6736 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000323057174683
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 502053.90625]
 [ 458126.71875]
 [ 550337.9375 ]
 [ 533461.875  ]
 [ 550343.75   ]
 [ 525626.4375 ]
 [ 475302.53125]
 [ 536287.3125 ]
 [ 449115.9375 ]
 [ 526433.875  ]
 [ 464816.34375]
 [ 415890.21875]
 [ 517661.96875]
 [ 501952.875  ]
 [ 473966.375  ]
 [ 545269.75   ]]
DEBUG:root:training time = %d0.24414
INFO:root:frame =6737 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000334024429321
INFO:root:frame =6738 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000261068344116
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.9468
DEBUG:root: dqn, choose action rondomly, need time 0.000193999999993
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6740 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000165939331055
INFO:root:frame =6741 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000465869903564
INFO:root:frame =6742 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.00061297416687
INFO:root:random_action_porb = 0.946768333333
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6744 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 492225.5625 ]
 [ 503793.59375]
 [ 606063.75   ]
 [ 510863.375  ]
 [ 452494.03125]
 [ 532079.0625 ]
 [ 522640.03125]
 [ 483130.875  ]
 [ 536466.125  ]
 [ 505040.625  ]
 [ 472452.15625]
 [ 549828.0625 ]
 [ 592313.625  ]
 [ 494307.875  ]
 [ 543400.75   ]
 [ 585380.375  ]]
DEBUG:root:training time = %d0.230173
INFO:root:frame =6745 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:frame =6746 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000339984893799
DEBUG:root: save sample needs time = 0.000213861465454
INFO:root:random_action_porb = 0.946736666667
DEBUG:root: dqn, choose action rondomly, need time 0.000297000000018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6748 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =6749 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000493049621582
INFO:root:frame =6750 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame = 6751 State into memory, numbers recorded 182 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000593185424805
INFO:root:random_action_porb = 0.946705
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6752current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:training error  = [[ 502743.3125 ]
 [ 534530.9375 ]
 [ 589609.5    ]
 [ 505069.78125]
 [ 482285.5    ]
 [ 451249.375  ]
 [ 529257.6875 ]
 [ 489912.5    ]
 [ 620610.0625 ]
 [ 627265.5625 ]
 [ 483048.0625 ]
 [ 592785.6875 ]
 [ 586911.625  ]
 [ 520025.5    ]
 [ 604597.375  ]
 [ 601565.375  ]]
DEBUG:root:training time = %d0.214112
INFO:root:frame =6753 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =6754 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000268936157227
DEBUG:root: save sample needs time = 0.000239133834839
INFO:root:random_action_porb = 0.946673333333
DEBUG:root: dqn, choose action rondomly, need time 0.000329999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6756 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000370979309082
INFO:root:frame =6757 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =6758 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00046706199646
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.946641666667
DEBUG:root: dqn, choose action rondomly, need time 0.000307000000021
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6760 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 486521.25   ]
 [ 488666.53125]
 [ 569721.25   ]
 [ 470629.5    ]
 [ 501117.4375 ]
 [ 527844.8125 ]
 [ 484141.4375 ]
 [ 484704.21875]
 [ 613815.625  ]
 [ 613815.625  ]
 [ 484943.59375]
 [ 608340.5625 ]
 [ 683912.875  ]
 [ 498027.9375 ]
 [ 583681.0625 ]
 [ 609088.8125 ]]
DEBUG:root:training time = %d0.234356
INFO:root:frame =6761 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000365972518921
INFO:root:frame =6762 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000225067138672
DEBUG:root: save sample needs time = 0.000180006027222
INFO:root:random_action_porb = 0.94661
DEBUG:root: dqn, choose action rondomly, need time 0.000326000000001
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6764 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000349998474121
INFO:root:frame =6765 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000493764877319
INFO:root:frame =6766 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000444173812866
DEBUG:root: save sample needs time = 0.000190019607544
INFO:root:random_action_porb = 0.946578333333
DEBUG:root: dqn, choose action rondomly, need time 0.000311000000011
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6768 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000385046005249
INFO:root:training error  = [[ 604971.     ]
 [ 627081.5    ]
 [ 478084.46875]
 [ 583303.625  ]
 [ 623367.3125 ]
 [ 592521.0625 ]
 [ 570427.625  ]
 [ 545214.9375 ]
 [ 612917.75   ]
 [ 630274.75   ]
 [ 477481.     ]
 [ 425334.53125]
 [ 573608.     ]
 [ 604971.     ]
 [ 571940.625  ]
 [ 626289.875  ]]
DEBUG:root:training time = %d0.230987
INFO:root:frame =6769 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000441074371338
INFO:root:frame =6770 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000269889831543
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.946546666667
DEBUG:root: dqn, choose action rondomly, need time 0.000484999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6772 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame =6773 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000447034835815
INFO:root:frame =6774 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root:frame = 6775 State into memory, numbers recorded 183 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000566959381104
INFO:root:random_action_porb = 0.946515
DEBUG:root: dqn, choose action rondomly, need time 0.000190000000003
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6776current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000167846679688
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 468167.3125 ]
 [ 541330.9375 ]
 [ 513284.09375]
 [ 542133.0625 ]
 [ 515428.65625]
 [ 496225.3125 ]
 [ 535848.3125 ]
 [ 490936.96875]
 [ 587025.3125 ]
 [ 590610.25   ]
 [ 600348.     ]
 [ 586005.1875 ]
 [ 595771.4375 ]
 [ 590997.5625 ]
 [ 589891.5    ]
 [ 529925.6875 ]]
DEBUG:root:training time = %d0.227843
INFO:root:frame =6777 recording following_observation no.1
DEBUG:root: save sample needs time = 0.0002601146698
INFO:root:frame =6778 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000617980957031
DEBUG:root: save sample needs time = 0.000216960906982
INFO:root:random_action_porb = 0.946483333333
DEBUG:root: dqn, choose action rondomly, need time 0.000608999999997
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6780 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =6781 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =6782 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000383138656616
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root:random_action_porb = 0.946451666667
DEBUG:root: dqn, choose action rondomly, need time 0.000473
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6784 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000381946563721
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 478855.90625]
 [ 511124.46875]
 [ 492795.78125]
 [ 503602.28125]
 [ 527173.875  ]
 [ 620230.0625 ]
 [ 561157.5625 ]
 [ 496799.21875]
 [ 516702.65625]
 [ 641854.4375 ]
 [ 519145.59375]
 [ 574515.125  ]
 [ 509365.1875 ]
 [ 496647.78125]
 [ 478607.25   ]
 [ 490086.125  ]]
DEBUG:root:training time = %d0.225947
INFO:root:frame =6785 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00025200843811
INFO:root:frame =6786 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427961349487
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.94642
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6788 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =6789 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454187393188
INFO:root:frame =6790 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root:frame = 6791 State into memory, numbers recorded 184 action = 3, reward = 0
DEBUG:root: save sample needs time = 0.000793933868408
INFO:root:random_action_porb = 0.946388333333
DEBUG:root: dqn, choose action rondomly, need time 0.000366999999983
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6792current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000362157821655
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 477163.90625]
 [ 630321.25   ]
 [ 605686.75   ]
 [ 649121.3125 ]
 [ 637539.875  ]
 [ 539686.8125 ]
 [ 554594.375  ]
 [ 504897.6875 ]
 [ 482623.28125]
 [ 454807.96875]
 [ 584249.75   ]
 [ 515371.15625]
 [ 630766.375  ]
 [ 527324.1875 ]
 [ 497261.875  ]
 [ 504068.09375]]
DEBUG:root:training time = %d0.231107
INFO:root:frame =6793 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =6794 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478029251099
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:random_action_porb = 0.946356666667
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6796 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312805175781
INFO:root:frame =6797 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440120697021
INFO:root:frame =6798 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000470876693726
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.946325
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6800 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296115875244
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 584956.0625 ]
 [ 610591.125  ]
 [ 726746.25   ]
 [ 483113.25   ]
 [ 610591.125  ]
 [ 634146.25   ]
 [ 500361.4375 ]
 [ 519687.53125]
 [ 526319.0625 ]
 [ 496982.3125 ]
 [ 584194.5    ]
 [ 496708.34375]
 [ 567637.1875 ]
 [ 588026.875  ]
 [ 512345.59375]
 [ 578593.5    ]]
DEBUG:root:training time = %d0.233574
INFO:root:frame =6801 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:frame =6802 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000241041183472
DEBUG:root: save sample needs time = 0.000123023986816
INFO:root:random_action_porb = 0.946293333333
DEBUG:root: dqn, choose action rondomly, need time 0.000191999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6804 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:frame =6805 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000459909439087
INFO:root:frame =6806 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.946261666667
DEBUG:root: dqn, choose action rondomly, need time 0.000303000000002
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6808 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000300168991089
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 523849.40625]
 [ 589747.5    ]
 [ 493768.34375]
 [ 560632.4375 ]
 [ 548826.3125 ]
 [ 560014.     ]
 [ 535310.875  ]
 [ 532810.1875 ]
 [ 593169.25   ]
 [ 511405.15625]
 [ 529522.     ]
 [ 518834.625  ]
 [ 498084.4375 ]
 [ 598056.     ]
 [ 571429.6875 ]
 [ 591272.375  ]]
DEBUG:root:training time = %d0.235293
INFO:root:frame =6809 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284910202026
INFO:root:frame =6810 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.94623
DEBUG:root: dqn, choose action rondomly, need time 0.000368999999978
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6812 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:frame =6813 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000458002090454
INFO:root:frame =6814 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000442028045654
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.946198333333
DEBUG:root: dqn, choose action rondomly, need time 0.000301000000007
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6816 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000296831130981
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 714665.5    ]
 [ 643575.3125 ]
 [ 514947.8125 ]
 [ 558804.4375 ]
 [ 630862.5625 ]
 [ 570045.625  ]
 [ 573600.625  ]
 [ 547091.375  ]
 [ 556894.875  ]
 [ 605236.875  ]
 [ 548278.0625 ]
 [ 557603.5    ]
 [ 515090.78125]
 [ 568250.9375 ]
 [ 611308.6875 ]
 [ 560043.1875 ]]
DEBUG:root:training time = %d0.225528
INFO:root:frame =6817 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:frame =6818 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000524044036865
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.946166666667
DEBUG:root: dqn, choose action rondomly, need time 0.000329999999991
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6820 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000313997268677
INFO:root:frame =6821 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000426054000854
INFO:root:frame =6822 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000233888626099
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.946135
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6824 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332117080688
INFO:root:training error  = [[ 529712.4375 ]
 [ 523853.65625]
 [ 660134.0625 ]
 [ 563569.875  ]
 [ 534950.8125 ]
 [ 628246.625  ]
 [ 660870.5625 ]
 [ 540504.9375 ]
 [ 688784.9375 ]
 [ 592025.0625 ]
 [ 482936.78125]
 [ 667217.75   ]
 [ 540504.9375 ]
 [ 546834.25   ]
 [ 509699.78125]
 [ 569041.875  ]]
DEBUG:root:training time = %d0.240327
INFO:root:frame =6825 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000238180160522
INFO:root:frame =6826 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
INFO:root:frame = 6827 State into memory, numbers recorded 185 action = 0, reward = 0
DEBUG:root: save sample needs time = 0.000633001327515
INFO:root:random_action_porb = 0.946103333333
DEBUG:root: dqn, choose action rondomly, need time 0.000188000000009
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6828current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000185966491699
INFO:root:frame =6829 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000535011291504
INFO:root:frame =6830 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000454902648926
DEBUG:root: save sample needs time = 0.000273942947388
INFO:root:random_action_porb = 0.946071666667
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999983
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6832 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000417947769165
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 675374.1875]
 [ 668414.8125]
 [ 516934.3125]
 [ 534165.4375]
 [ 629818.9375]
 [ 554953.6875]
 [ 517157.625 ]
 [ 706363.125 ]
 [ 532751.75  ]
 [ 604199.5625]
 [ 680642.75  ]
 [ 545499.0625]
 [ 684913.0625]
 [ 704145.5   ]
 [ 600497.875 ]
 [ 503875.375 ]]
DEBUG:root:training time = %d0.21523
INFO:root:frame =6833 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000262022018433
INFO:root:frame =6834 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000286102294922
DEBUG:root: save sample needs time = 0.000138998031616
INFO:root:random_action_porb = 0.94604
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6836 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00018310546875
INFO:root:frame =6837 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00022292137146
INFO:root:frame =6838 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000419139862061
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.946008333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287000000014
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6840 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000333070755005
INFO:root:training error  = [[ 591995.    ]
 [ 642273.875 ]
 [ 699193.1875]
 [ 661354.9375]
 [ 620856.25  ]
 [ 644823.125 ]
 [ 596949.375 ]
 [ 627881.375 ]
 [ 598658.8125]
 [ 580239.25  ]
 [ 695753.125 ]
 [ 638838.    ]
 [ 596949.375 ]
 [ 704294.6875]
 [ 576387.875 ]
 [ 620856.25  ]]
DEBUG:root:training time = %d0.227328
INFO:root:frame =6841 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =6842 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000275135040283
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:random_action_porb = 0.945976666667
DEBUG:root: dqn, choose action rondomly, need time 0.000473
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6844 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000380992889404
INFO:root:frame =6845 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000587940216064
INFO:root:frame =6846 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000496864318848
DEBUG:root: save sample needs time = 0.000221967697144
INFO:root:random_action_porb = 0.945945
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6848 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298976898193
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 608643.75   ]
 [ 533240.8125 ]
 [ 586890.625  ]
 [ 589917.     ]
 [ 640228.125  ]
 [ 521931.46875]
 [ 628067.0625 ]
 [ 600404.     ]
 [ 535899.75   ]
 [ 631445.9375 ]
 [ 547387.5625 ]
 [ 547384.6875 ]
 [ 533240.8125 ]
 [ 612083.125  ]
 [ 545615.9375 ]
 [ 651438.125  ]]
DEBUG:root:training time = %d0.214167
INFO:root:frame =6849 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:frame =6850 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.945913333333
DEBUG:root: dqn, choose action rondomly, need time 0.000544000000019
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6852 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000553846359253
INFO:root:frame =6853 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame =6854 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000460147857666
DEBUG:root: save sample needs time = 0.000120878219604
INFO:root:random_action_porb = 0.945881666667
DEBUG:root: dqn, choose action rondomly, need time 0.000193999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6856 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000194072723389
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 679140.1875]
 [ 611542.3125]
 [ 605416.1875]
 [ 555813.9375]
 [ 607739.    ]
 [ 669515.5   ]
 [ 550211.875 ]
 [ 681627.625 ]
 [ 539596.4375]
 [ 592348.1875]
 [ 744516.1875]
 [ 590251.5625]
 [ 678200.5   ]
 [ 678269.6875]
 [ 595283.0625]
 [ 565110.4375]]
DEBUG:root:training time = %d0.212389
INFO:root:frame =6857 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250101089478
INFO:root:frame =6858 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000247001647949
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.94585
DEBUG:root: dqn, choose action rondomly, need time 0.000160999999991
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6860 recording following_observation no.0
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:frame =6861 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000649213790894
INFO:root:frame =6862 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000484943389893
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.945818333333
DEBUG:root: dqn, choose action rondomly, need time 0.000522000000018
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6864 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000455856323242
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 570644.5   ]
 [ 544613.75  ]
 [ 574882.375 ]
 [ 661648.8125]
 [ 532728.9375]
 [ 580190.1875]
 [ 553945.875 ]
 [ 555461.625 ]
 [ 579486.6875]
 [ 585689.75  ]
 [ 545174.5625]
 [ 665029.125 ]
 [ 533987.    ]
 [ 665435.3125]
 [ 519873.375 ]
 [ 541908.75  ]]
DEBUG:root:training time = %d0.226344
INFO:root:frame =6865 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =6866 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000478982925415
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.945786666667
DEBUG:root: dqn, choose action rondomly, need time 0.00025100000002
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6868 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000219106674194
INFO:root:frame =6869 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000456094741821
INFO:root:frame =6870 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000488996505737
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.945755
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000011
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6872 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000295877456665
INFO:root:training error  = [[ 564554.125 ]
 [ 725652.75  ]
 [ 682326.    ]
 [ 624845.5   ]
 [ 692492.125 ]
 [ 618611.4375]
 [ 669505.875 ]
 [ 566753.125 ]
 [ 551983.6875]
 [ 735679.75  ]
 [ 614052.8125]
 [ 734939.5   ]
 [ 612663.9375]
 [ 551983.6875]
 [ 664533.875 ]
 [ 725652.75  ]]
DEBUG:root:training time = %d0.211021
INFO:root:frame =6873 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000268936157227
INFO:root:frame =6874 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000242948532104
DEBUG:root: save sample needs time = 0.000107049942017
INFO:root:random_action_porb = 0.945723333333
DEBUG:root: dqn, choose action rondomly, need time 0.000181999999995
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6876 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000189065933228
INFO:root:frame =6877 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =6878 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000287055969238
DEBUG:root: save sample needs time = 0.000140905380249
INFO:root:random_action_porb = 0.945691666667
DEBUG:root: dqn, choose action rondomly, need time 0.000239000000022
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6880 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000187158584595
INFO:root:training error  = [[ 613627.4375]
 [ 598899.125 ]
 [ 601851.6875]
 [ 572930.75  ]
 [ 570941.125 ]
 [ 659003.0625]
 [ 659003.0625]
 [ 585670.3125]
 [ 686150.125 ]
 [ 582799.5625]
 [ 565905.0625]
 [ 572533.125 ]
 [ 643287.    ]
 [ 553685.6875]
 [ 578121.125 ]
 [ 571115.25  ]]
DEBUG:root:training time = %d0.19051
INFO:root:frame =6881 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000200033187866
INFO:root:frame =6882 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000219821929932
INFO:root:frame = 6883 State into memory, numbers recorded 186 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000319957733154
INFO:root:random_action_porb = 0.94566
DEBUG:root: dqn, choose action rondomly, need time 0.000235000000004
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6884current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000231027603149
INFO:root:frame =6885 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =6886 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000262022018433
DEBUG:root: save sample needs time = 0.0001380443573
INFO:root:random_action_porb = 0.945628333333
DEBUG:root: dqn, choose action rondomly, need time 0.000238000000024
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6888 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000428915023804
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 525748.1875]
 [ 720671.6875]
 [ 512962.3125]
 [ 610061.6875]
 [ 733292.8125]
 [ 617418.4375]
 [ 638226.25  ]
 [ 647910.25  ]
 [ 609790.1875]
 [ 717830.9375]
 [ 594353.6875]
 [ 568573.4375]
 [ 588701.0625]
 [ 578003.8125]
 [ 579889.6875]
 [ 587432.4375]]
DEBUG:root:training time = %d0.192093
INFO:root:frame =6889 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root:frame =6890 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000367879867554
DEBUG:root: save sample needs time = 0.000117063522339
INFO:root:random_action_porb = 0.945596666667
DEBUG:root: dqn, choose action rondomly, need time 0.000315999999998
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6892 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:frame =6893 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000488042831421
INFO:root:frame =6894 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000211954116821
INFO:root:random_action_porb = 0.945565
DEBUG:root: dqn, choose action rondomly, need time 0.000286000000017
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6896 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000330209732056
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 773259.1875]
 [ 745197.1875]
 [ 552539.625 ]
 [ 606342.0625]
 [ 640271.875 ]
 [ 758016.8125]
 [ 608611.75  ]
 [ 611565.25  ]
 [ 614861.1875]
 [ 689021.5625]
 [ 625362.8125]
 [ 633308.1875]
 [ 758246.375 ]
 [ 709875.375 ]
 [ 745197.1875]
 [ 773393.125 ]]
DEBUG:root:training time = %d0.179043
INFO:root:frame =6897 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000227928161621
INFO:root:frame =6898 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.945533333333
DEBUG:root: dqn, choose action rondomly, need time 0.000234000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6900 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000172853469849
INFO:root:frame =6901 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame =6902 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000485897064209
INFO:root:frame = 6903 State into memory, numbers recorded 187 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000836133956909
INFO:root:random_action_porb = 0.945501666667
DEBUG:root: dqn, choose action rondomly, need time 0.000291000000004
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6904current_observation done, NOT record action 3, reward = 0
DEBUG:root: save sample needs time = 0.000365018844604
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 520277.625 ]
 [ 718574.125 ]
 [ 712210.75  ]
 [ 708488.8125]
 [ 619223.    ]
 [ 628197.125 ]
 [ 748772.5   ]
 [ 728745.6875]
 [ 743335.3125]
 [ 644316.625 ]
 [ 791516.0625]
 [ 554715.125 ]
 [ 833319.375 ]
 [ 802807.25  ]
 [ 655957.625 ]
 [ 658697.125 ]]
DEBUG:root:training time = %d0.226206
INFO:root:frame =6905 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240802764893
INFO:root:frame =6906 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000244855880737
INFO:root:random_action_porb = 0.94547
DEBUG:root: dqn, choose action rondomly, need time 0.000279000000006
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6908 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000322103500366
INFO:root:frame =6909 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442981719971
INFO:root:frame =6910 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000426054000854
DEBUG:root: save sample needs time = 0.000205039978027
INFO:root:random_action_porb = 0.945438333333
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6912 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000321865081787
INFO:root:training error  = [[ 666605.25  ]
 [ 708054.875 ]
 [ 755310.375 ]
 [ 749460.5   ]
 [ 608692.5625]
 [ 677775.9375]
 [ 708735.4375]
 [ 673980.0625]
 [ 667854.4375]
 [ 667967.8125]
 [ 722739.0625]
 [ 729244.25  ]
 [ 755310.375 ]
 [ 687650.6875]
 [ 718161.875 ]
 [ 660880.0625]]
DEBUG:root:training time = %d0.211719
INFO:root:frame =6913 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000286102294922
INFO:root:frame =6914 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.945406666667
DEBUG:root: dqn, choose action rondomly, need time 0.000214999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6916 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:frame =6917 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame =6918 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00023889541626
DEBUG:root: save sample needs time = 9.60826873779e-05
INFO:root:random_action_porb = 0.945375
DEBUG:root: dqn, choose action rondomly, need time 0.000186000000014
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6920 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000131130218506
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 633827.4375]
 [ 718814.1875]
 [ 606796.875 ]
 [ 709159.6875]
 [ 655337.6875]
 [ 604269.375 ]
 [ 657627.5625]
 [ 591015.625 ]
 [ 677140.9375]
 [ 659180.6875]
 [ 604343.75  ]
 [ 628667.8125]
 [ 664112.    ]
 [ 581114.375 ]
 [ 571465.125 ]
 [ 629617.4375]]
DEBUG:root:training time = %d0.222022
INFO:root:frame =6921 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00033712387085
INFO:root:frame =6922 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000457048416138
INFO:root:frame = 6923 State into memory, numbers recorded 188 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000560998916626
INFO:root:random_action_porb = 0.945343333333
DEBUG:root: dqn, choose action rondomly, need time 0.000304
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6924current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000304937362671
INFO:root:frame =6925 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000498056411743
INFO:root:frame =6926 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.945311666667
DEBUG:root: dqn, choose action rondomly, need time 0.000469999999979
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6928 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00031590461731
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 644368.375 ]
 [ 630819.125 ]
 [ 683228.1875]
 [ 623658.8125]
 [ 611070.4375]
 [ 751169.25  ]
 [ 653563.3125]
 [ 609236.625 ]
 [ 582319.5   ]
 [ 765500.25  ]
 [ 660357.8125]
 [ 627599.6875]
 [ 600986.8125]
 [ 749139.25  ]
 [ 772781.8125]
 [ 608779.375 ]]
DEBUG:root:training time = %d0.230134
INFO:root:frame =6929 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250816345215
INFO:root:frame =6930 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000417947769165
DEBUG:root: save sample needs time = 0.000203847885132
INFO:root:random_action_porb = 0.94528
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =6932 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =6933 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000433206558228
INFO:root:frame =6934 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000270843505859
DEBUG:root: save sample needs time = 0.000202178955078
INFO:root:random_action_porb = 0.945248333333
DEBUG:root: dqn, choose action rondomly, need time 0.000287999999983
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6936 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000314950942993
INFO:root:training error  = [[ 764482.125 ]
 [ 684867.75  ]
 [ 764482.125 ]
 [ 794070.6875]
 [ 720577.1875]
 [ 790279.3125]
 [ 785184.625 ]
 [ 582897.9375]
 [ 601392.6875]
 [ 778384.    ]
 [ 785184.625 ]
 [ 697298.375 ]
 [ 605642.6875]
 [ 807932.375 ]
 [ 641153.625 ]
 [ 585528.375 ]]
DEBUG:root:training time = %d0.21528
INFO:root:frame =6937 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000243902206421
INFO:root:frame =6938 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.945216666667
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6940 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00029993057251
INFO:root:frame =6941 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000463962554932
INFO:root:frame =6942 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000633001327515
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.945185
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6944 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[ 769985.6875]
 [ 617418.4375]
 [ 808829.75  ]
 [ 773049.625 ]
 [ 791149.4375]
 [ 616978.0625]
 [ 681724.375 ]
 [ 772560.3125]
 [ 770146.8125]
 [ 736418.75  ]
 [ 780147.8125]
 [ 747730.0625]
 [ 631148.    ]
 [ 613734.5625]
 [ 586219.    ]
 [ 745858.25  ]]
DEBUG:root:training time = %d0.220238
INFO:root:frame =6945 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236988067627
INFO:root:frame =6946 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458002090454
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.945153333333
DEBUG:root: dqn, choose action rondomly, need time 0.000338999999997
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =6948 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000311136245728
INFO:root:frame =6949 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000468969345093
INFO:root:frame =6950 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00044584274292
DEBUG:root: save sample needs time = 0.000206232070923
INFO:root:random_action_porb = 0.945121666667
DEBUG:root: dqn, choose action rondomly, need time 0.000283999999994
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6952 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310897827148
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 717026.9375]
 [ 802935.    ]
 [ 683707.75  ]
 [ 636110.625 ]
 [ 636838.3125]
 [ 759132.6875]
 [ 724480.25  ]
 [ 723446.625 ]
 [ 696812.4375]
 [ 697857.9375]
 [ 737622.625 ]
 [ 708779.8125]
 [ 671593.0625]
 [ 698626.625 ]
 [ 772380.0625]
 [ 642521.25  ]]
DEBUG:root:training time = %d0.217189
INFO:root:frame =6953 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00023889541626
INFO:root:frame =6954 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000303030014038
DEBUG:root: save sample needs time = 0.000113964080811
INFO:root:random_action_porb = 0.94509
DEBUG:root: dqn, choose action rondomly, need time 0.000301999999976
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6956 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000359058380127
INFO:root:frame =6957 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000486850738525
INFO:root:frame =6958 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000452041625977
INFO:root:frame = 6959 State into memory, numbers recorded 189 action = 2, reward = 0
DEBUG:root: save sample needs time = 0.000543832778931
INFO:root:random_action_porb = 0.945058333333
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6960current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000306844711304
INFO:root:training error  = [[ 648072.1875]
 [ 699696.3125]
 [ 659055.375 ]
 [ 716549.    ]
 [ 632334.0625]
 [ 685163.625 ]
 [ 707285.9375]
 [ 606530.6875]
 [ 608989.6875]
 [ 645901.0625]
 [ 618161.4375]
 [ 657567.375 ]
 [ 672396.8125]
 [ 663443.6875]
 [ 667532.0625]
 [ 618966.3125]]
DEBUG:root:training time = %d0.215477
INFO:root:frame =6961 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:frame =6962 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000464916229248
DEBUG:root: save sample needs time = 0.000287055969238
INFO:root:random_action_porb = 0.945026666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6964 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000393867492676
INFO:root:frame =6965 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000454902648926
INFO:root:frame =6966 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000450134277344
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.944995
DEBUG:root: dqn, choose action rondomly, need time 0.000161999999989
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6968 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000312805175781
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 776770.25  ]
 [ 666472.9375]
 [ 701905.25  ]
 [ 638784.9375]
 [ 631806.0625]
 [ 652573.6875]
 [ 727480.75  ]
 [ 743650.1875]
 [ 650109.9375]
 [ 657488.1875]
 [ 605937.5625]
 [ 751961.625 ]
 [ 706831.    ]
 [ 645514.9375]
 [ 675395.0625]
 [ 890039.3125]]
DEBUG:root:training time = %d0.22688
INFO:root:frame =6969 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000300884246826
INFO:root:frame =6970 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000313997268677
DEBUG:root: save sample needs time = 0.000216007232666
INFO:root:random_action_porb = 0.944963333333
DEBUG:root: dqn, choose action rondomly, need time 0.000337999999999
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6972 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000302076339722
INFO:root:frame =6973 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00045108795166
INFO:root:frame =6974 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000256061553955
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.944931666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =6976 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000318050384521
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 855655.6875]
 [ 828313.3125]
 [ 763452.6875]
 [ 661162.75  ]
 [ 710025.125 ]
 [ 756808.25  ]
 [ 668098.6875]
 [ 648422.875 ]
 [ 661162.75  ]
 [ 622160.4375]
 [ 717083.125 ]
 [ 710025.125 ]
 [ 597400.6875]
 [ 739865.4375]
 [ 739566.4375]
 [ 600503.9375]]
DEBUG:root:training time = %d0.208034
INFO:root:frame =6977 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250816345215
INFO:root:frame =6978 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:random_action_porb = 0.9449
INFO:root:dqn select action Tensor("ArgMax_40:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011279
INFO:root:action choosen by dqn [4]
INFO:root:frame =6980 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000355005264282
INFO:root:frame =6981 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000585079193115
INFO:root:frame =6982 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00042200088501
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.944868333333
INFO:root:dqn select action Tensor("ArgMax_41:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00968799999998
INFO:root:action choosen by dqn [4]
INFO:root:frame =6984 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000180006027222
INFO:root:training error  = [[ 808963.25  ]
 [ 912761.9375]
 [ 717465.25  ]
 [ 699214.4375]
 [ 684502.5   ]
 [ 652455.3125]
 [ 825077.75  ]
 [ 770637.0625]
 [ 773027.3125]
 [ 743402.625 ]
 [ 652455.3125]
 [ 719284.5625]
 [ 638916.0625]
 [ 667493.8125]
 [ 797715.875 ]
 [ 819967.375 ]]
DEBUG:root:training time = %d0.204943
INFO:root:frame =6985 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000270128250122
INFO:root:frame =6986 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000438928604126
DEBUG:root: save sample needs time = 0.000210046768188
INFO:root:random_action_porb = 0.944836666667
DEBUG:root: dqn, choose action rondomly, need time 0.000433999999984
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =6988 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000324010848999
INFO:root:frame =6989 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000443935394287
INFO:root:frame =6990 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000248908996582
DEBUG:root: save sample needs time = 0.00020694732666
INFO:root:random_action_porb = 0.944805
DEBUG:root: dqn, choose action rondomly, need time 0.000313000000006
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6992 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root:training error  = [[ 734197.9375]
 [ 737176.5   ]
 [ 718911.875 ]
 [ 693991.5   ]
 [ 724149.5   ]
 [ 691996.5   ]
 [ 649357.375 ]
 [ 729331.    ]
 [ 728857.375 ]
 [ 756144.0625]
 [ 731624.625 ]
 [ 738597.5625]
 [ 761239.1875]
 [ 649357.375 ]
 [ 728213.875 ]
 [ 657114.5   ]]
DEBUG:root:training time = %d0.206111
INFO:root:frame =6993 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284194946289
INFO:root:frame =6994 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000378847122192
DEBUG:root: save sample needs time = 0.000113010406494
INFO:root:random_action_porb = 0.944773333333
DEBUG:root: dqn, choose action rondomly, need time 0.000294999999994
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =6996 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root:frame =6997 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00043797492981
INFO:root:frame =6998 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000214099884033
DEBUG:root:one frame running time = 0.005843
DEBUG:root:total training time = 189.572595
INFO:root:frame num = 7000 frame round: 0
INFO:root:random_action_porb = 0.944741666667
DEBUG:root: dqn, choose action rondomly, need time 0.000304999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7000 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000422954559326
INFO:root:training error  = [[ 801334.4375]
 [ 718630.375 ]
 [ 723355.25  ]
 [ 684151.9375]
 [ 725800.8125]
 [ 684151.9375]
 [ 639318.9375]
 [ 706051.25  ]
 [ 642608.875 ]
 [ 663593.1875]
 [ 643567.4375]
 [ 658861.9375]
 [ 719234.875 ]
 [ 791357.9375]
 [ 673840.5625]
 [ 684013.    ]]
DEBUG:root:training time = %d0.214692
INFO:root:frame =7001 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000263929367065
INFO:root:frame =7002 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272035598755
INFO:root:frame = 7003 State into memory, numbers recorded 190 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000693082809448
INFO:root:random_action_porb = 0.94471
DEBUG:root: dqn, choose action rondomly, need time 0.000408999999991
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7004current_observation done, NOT record action 2, reward = 0
DEBUG:root: save sample needs time = 0.000468015670776
INFO:root:frame =7005 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000236034393311
INFO:root:frame =7006 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000401020050049
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:random_action_porb = 0.944678333333
DEBUG:root: dqn, choose action rondomly, need time 0.000233000000009
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7008 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000223159790039
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 776742.6875]
 [ 748934.75  ]
 [ 808661.125 ]
 [ 795077.    ]
 [ 713300.6875]
 [ 800986.5625]
 [ 700073.75  ]
 [ 677753.4375]
 [ 739994.75  ]
 [ 708694.3125]
 [ 726952.75  ]
 [ 829787.5625]
 [ 765008.1875]
 [ 674749.9375]
 [ 724965.75  ]
 [ 822861.5625]]
DEBUG:root:training time = %d0.23763
INFO:root:frame =7009 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000246047973633
INFO:root:frame =7010 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00026798248291
DEBUG:root: save sample needs time = 0.000166893005371
INFO:root:random_action_porb = 0.944646666667
DEBUG:root: dqn, choose action rondomly, need time 0.000498000000022
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7012 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000297069549561
INFO:root:frame =7013 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000440835952759
INFO:root:frame =7014 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000427007675171
DEBUG:root: save sample needs time = 0.000201940536499
INFO:root:random_action_porb = 0.944615
DEBUG:root: dqn, choose action rondomly, need time 0.000490000000013
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7016 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000320911407471
INFO:root:training error  = [[ 674690.5625]
 [ 671517.8125]
 [ 874718.125 ]
 [ 803871.625 ]
 [ 797937.4375]
 [ 680678.1875]
 [ 695764.5   ]
 [ 678313.125 ]
 [ 790062.3125]
 [ 787366.8125]
 [ 847345.4375]
 [ 719200.0625]
 [ 676634.75  ]
 [ 864801.9375]
 [ 791425.6875]
 [ 787366.8125]]
DEBUG:root:training time = %d0.226237
INFO:root:frame =7017 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000326156616211
INFO:root:frame =7018 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000469923019409
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.944583333333
DEBUG:root: dqn, choose action rondomly, need time 0.000192999999996
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7020 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000344038009644
INFO:root:frame =7021 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000316143035889
INFO:root:frame =7022 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000231027603149
DEBUG:root: save sample needs time = 9.89437103271e-05
INFO:root:random_action_porb = 0.944551666667
DEBUG:root: dqn, choose action rondomly, need time 0.000290000000007
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7024 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303030014038
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 678087.9375]
 [ 886552.8125]
 [ 809451.625 ]
 [ 809964.875 ]
 [ 789267.375 ]
 [ 823364.8125]
 [ 740092.25  ]
 [ 822450.625 ]
 [ 810218.    ]
 [ 790437.3125]
 [ 785039.25  ]
 [ 874016.8125]
 [ 810750.75  ]
 [ 841700.5   ]
 [ 820611.3125]
 [ 769242.0625]]
DEBUG:root:training time = %d0.219687
INFO:root:frame =7025 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000293016433716
INFO:root:frame =7026 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000301837921143
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.94452
DEBUG:root: dqn, choose action rondomly, need time 0.00018
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7028 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000175952911377
INFO:root:frame =7029 recording following_observation no.1
DEBUG:root: save sample needs time = 0.00030517578125
INFO:root:frame =7030 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000272989273071
DEBUG:root: save sample needs time = 0.000117778778076
INFO:root:random_action_porb = 0.944488333333
DEBUG:root: dqn, choose action rondomly, need time 0.000214999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7032 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 716651.5625]
 [ 719690.4375]
 [ 685019.6875]
 [ 816513.4375]
 [ 725005.6875]
 [ 737399.5625]
 [ 816513.4375]
 [ 776823.625 ]
 [ 725253.5   ]
 [ 828830.625 ]
 [ 650717.9375]
 [ 794659.0625]
 [ 724658.125 ]
 [ 727947.25  ]
 [ 785361.1875]
 [ 726463.25  ]]
DEBUG:root:training time = %d0.190933
INFO:root:frame =7033 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000291109085083
INFO:root:frame =7034 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000342845916748
INFO:root:frame = 7035 State into memory, numbers recorded 191 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000295162200928
INFO:root:random_action_porb = 0.944456666667
DEBUG:root: dqn, choose action rondomly, need time 0.000193999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7036current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000146150588989
INFO:root:frame =7037 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000324964523315
INFO:root:frame =7038 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00054407119751
INFO:root:frame = 7039 State into memory, numbers recorded 192 action = 4, reward = 0
DEBUG:root: save sample needs time = 0.000571012496948
INFO:root:random_action_porb = 0.944425
DEBUG:root: dqn, choose action rondomly, need time 0.000315000000001
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7040current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 706327.    ]
 [ 881495.4375]
 [ 748917.8125]
 [ 807268.9375]
 [ 746919.625 ]
 [ 783914.8125]
 [ 891163.6875]
 [ 778832.125 ]
 [ 829554.5   ]
 [ 723116.0625]
 [ 799283.125 ]
 [ 919205.3125]
 [ 838884.25  ]
 [ 810800.    ]
 [ 706629.0625]
 [ 774730.0625]]
DEBUG:root:training time = %d0.234155
INFO:root:frame =7041 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000241994857788
INFO:root:frame =7042 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00045108795166
DEBUG:root: save sample needs time = 0.000241041183472
INFO:root:random_action_porb = 0.944393333333
INFO:root:dqn select action Tensor("ArgMax_42:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.00896399999999
INFO:root:action choosen by dqn [4]
INFO:root: ememy has been killed for 9 times 
INFO:root:enemies_left [0]
INFO:root:frame =7044 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000159025192261
INFO:root:frame =7045 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000207901000977
INFO:root:frame =7046 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000559091567993
INFO:root:frame = 7047 State into memory, numbers recorded 193 action = [4], reward = 1
DEBUG:root: save sample needs time = 0.00117897987366
INFO:root:random_action_porb = 0.944361666667
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999983
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7048current_observation done, NOT record action 0, reward = 0
DEBUG:root: save sample needs time = 0.000349044799805
INFO:root:training error  = [[ 745445.0625]
 [ 794693.875 ]
 [ 886185.0625]
 [ 889232.4375]
 [ 892484.3125]
 [ 675969.8125]
 [ 784136.1875]
 [ 685061.75  ]
 [ 772076.25  ]
 [ 902082.5625]
 [ 737958.1875]
 [ 774776.4375]
 [ 705388.375 ]
 [ 760970.    ]
 [ 715028.8125]
 [ 812140.6875]]
DEBUG:root:training time = %d0.235433
INFO:root:frame =7049 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000252962112427
INFO:root:frame =7050 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000479936599731
DEBUG:root: save sample needs time = 0.000175952911377
INFO:root:random_action_porb = 0.94433
DEBUG:root: dqn, choose action rondomly, need time 0.00030000000001
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7052 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000310182571411
INFO:root:frame =7053 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000469923019409
INFO:root:frame =7054 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000462055206299
DEBUG:root: save sample needs time = 0.000204086303711
INFO:root:random_action_porb = 0.944298333333
DEBUG:root: dqn, choose action rondomly, need time 0.000316999999995
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7056 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 820857.25  ]
 [ 688645.5   ]
 [ 819399.75  ]
 [ 703165.75  ]
 [ 846712.6875]
 [ 848284.1875]
 [ 876635.375 ]
 [ 860596.875 ]
 [ 796899.6875]
 [ 883612.875 ]
 [ 759452.6875]
 [ 890986.6875]
 [ 735443.5625]
 [ 703771.875 ]
 [ 759745.4375]
 [ 733988.75  ]]
DEBUG:root:training time = %d0.228331
INFO:root:frame =7057 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000266075134277
INFO:root:frame =7058 recording following_observation no.2
DEBUG:root: save sample needs time = 0.0002760887146
INFO:root:frame = 7059 State into memory, numbers recorded 194 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000436067581177
INFO:root:random_action_porb = 0.944266666667
DEBUG:root: dqn, choose action rondomly, need time 0.000332000000014
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7060current_observation done, NOT record action 1, reward = 0
DEBUG:root: save sample needs time = 0.000425100326538
INFO:root:frame =7061 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000466823577881
INFO:root:frame =7062 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000458955764771
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.944235
DEBUG:root: dqn, choose action rondomly, need time 0.000314000000003
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7064 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000335931777954
INFO:root:training error  = [[  873321.25  ]
 [  721081.25  ]
 [  811403.3125]
 [  724176.0625]
 [  866608.25  ]
 [  819307.8125]
 [  894145.6875]
 [  722528.25  ]
 [  893885.3125]
 [ 1010146.6875]
 [  790930.5625]
 [  790930.5625]
 [  693187.9375]
 [  853732.6875]
 [  842118.0625]
 [  862455.    ]]
DEBUG:root:training time = %d0.221379
INFO:root:frame =7065 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000247955322266
INFO:root:frame =7066 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000453948974609
INFO:root:frame = 7067 State into memory, numbers recorded 195 action = 1, reward = 0
DEBUG:root: save sample needs time = 0.000603914260864
INFO:root:random_action_porb = 0.944203333333
DEBUG:root: dqn, choose action rondomly, need time 0.000302000000005
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7068current_observation done, NOT record action 4, reward = 0
DEBUG:root: save sample needs time = 0.000345945358276
INFO:root:frame =7069 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000442028045654
INFO:root:frame =7070 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000594854354858
DEBUG:root: save sample needs time = 0.000202894210815
INFO:root:random_action_porb = 0.944171666667
DEBUG:root: dqn, choose action rondomly, need time 0.000306999999992
INFO:root:random action 0
INFO:root:action choosen by dqn 0
INFO:root:frame =7072 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000382900238037
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 759112.3125]
 [ 831069.0625]
 [ 704258.625 ]
 [ 672122.9375]
 [ 726972.75  ]
 [ 773726.375 ]
 [ 763946.    ]
 [ 810029.875 ]
 [ 795827.75  ]
 [ 812945.25  ]
 [ 728452.25  ]
 [ 822119.4375]
 [ 706230.125 ]
 [ 832305.1875]
 [ 718570.8125]
 [ 708766.6875]]
DEBUG:root:training time = %d0.214134
INFO:root:frame =7073 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000234127044678
INFO:root:frame =7074 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000272989273071
INFO:root:random_action_porb = 0.94414
DEBUG:root: dqn, choose action rondomly, need time 0.000298000000015
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7076 recording following_observation no.0
DEBUG:root: save sample needs time = 0.00016188621521
INFO:root:frame =7077 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:frame =7078 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000495195388794
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.944108333333
DEBUG:root: dqn, choose action rondomly, need time 0.000288000000012
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7080 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000307083129883
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 883890.125 ]
 [ 784589.375 ]
 [ 991451.9375]
 [ 765486.5625]
 [ 948373.5625]
 [ 753985.25  ]
 [ 965388.75  ]
 [ 840004.5   ]
 [ 795491.5625]
 [ 723185.8125]
 [ 728573.9375]
 [ 804602.    ]
 [ 750999.9375]
 [ 830413.9375]
 [ 942431.375 ]
 [ 971658.8125]]
DEBUG:root:training time = %d0.227052
INFO:root:frame =7081 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000336885452271
INFO:root:frame =7082 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000348091125488
DEBUG:root: save sample needs time = 0.000118970870972
INFO:root:random_action_porb = 0.944076666667
DEBUG:root: dqn, choose action rondomly, need time 0.000192999999996
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7084 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000218152999878
INFO:root:frame =7085 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000387907028198
INFO:root:frame =7086 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00032901763916
DEBUG:root: save sample needs time = 0.000247001647949
INFO:root:random_action_porb = 0.944045
DEBUG:root: dqn, choose action rondomly, need time 0.000518
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7088 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000303983688354
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 775342.1875]
 [ 740709.    ]
 [ 856995.    ]
 [ 711498.8125]
 [ 769404.8125]
 [ 856995.    ]
 [ 764644.375 ]
 [ 922633.4375]
 [ 748448.    ]
 [ 867335.6875]
 [ 749452.0625]
 [ 857045.625 ]
 [ 938351.6875]
 [ 867335.6875]
 [ 796263.4375]
 [ 745642.375 ]]
DEBUG:root:training time = %d0.235589
INFO:root:frame =7089 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000250816345215
INFO:root:frame =7090 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000274896621704
DEBUG:root: save sample needs time = 0.000234842300415
INFO:root:random_action_porb = 0.944013333333
DEBUG:root: dqn, choose action rondomly, need time 0.000495000000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7092 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000452995300293
INFO:root:frame =7093 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000455141067505
INFO:root:frame =7094 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000463008880615
DEBUG:root: save sample needs time = 0.000211000442505
INFO:root:random_action_porb = 0.943981666667
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7096 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000334978103638
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 891453.125 ]
 [ 891386.75  ]
 [ 897560.125 ]
 [ 957863.625 ]
 [ 818215.625 ]
 [ 771868.625 ]
 [ 754719.75  ]
 [ 924925.5   ]
 [ 903190.375 ]
 [ 822401.    ]
 [ 926207.    ]
 [ 825869.1875]
 [ 782658.125 ]
 [ 791026.125 ]
 [ 822401.    ]
 [ 764070.625 ]]
DEBUG:root:training time = %d0.204321
INFO:root:frame =7097 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000280857086182
INFO:root:frame =7098 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000128984451294
INFO:root:random_action_porb = 0.94395
DEBUG:root: dqn, choose action rondomly, need time 0.000321999999983
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7100 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000298023223877
INFO:root:frame =7101 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000429153442383
INFO:root:frame =7102 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000226020812988
DEBUG:root: save sample needs time = 0.000205993652344
INFO:root:random_action_porb = 0.943918333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7104 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000309944152832
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 871218.0625]
 [ 882388.6875]
 [ 693755.625 ]
 [ 787271.5   ]
 [ 759151.4375]
 [ 817392.5625]
 [ 855476.875 ]
 [ 869505.25  ]
 [ 909925.9375]
 [ 849158.625 ]
 [ 849158.625 ]
 [ 805334.5   ]
 [ 924305.75  ]
 [ 773152.6875]
 [ 781027.875 ]
 [ 776074.9375]]
DEBUG:root:training time = %d0.218211
INFO:root:frame =7105 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000240087509155
INFO:root:frame =7106 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000252962112427
DEBUG:root: save sample needs time = 0.000153064727783
INFO:root:random_action_porb = 0.943886666667
DEBUG:root: dqn, choose action rondomly, need time 0.000173000000018
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7108 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000188112258911
INFO:root:frame =7109 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000290155410767
INFO:root:frame =7110 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000281810760498
DEBUG:root: save sample needs time = 0.000157117843628
INFO:root:random_action_porb = 0.943855
DEBUG:root: dqn, choose action rondomly, need time 0.000199000000009
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7112 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000380992889404
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 747525.75  ]
 [ 863832.3125]
 [ 830661.375 ]
 [ 824900.3125]
 [ 838412.0625]
 [ 824900.3125]
 [ 827652.1875]
 [ 795266.8125]
 [ 866226.5   ]
 [ 985451.75  ]
 [ 837039.125 ]
 [ 929883.5   ]
 [ 806098.875 ]
 [ 741845.75  ]
 [ 830992.5   ]
 [ 765037.25  ]]
DEBUG:root:training time = %d0.197147
INFO:root:frame =7113 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000224828720093
INFO:root:frame =7114 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000372886657715
DEBUG:root: save sample needs time = 0.000200986862183
INFO:root:random_action_porb = 0.943823333333
DEBUG:root: dqn, choose action rondomly, need time 0.000293999999997
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7116 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000416994094849
INFO:root:frame =7117 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000480175018311
INFO:root:frame =7118 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000238180160522
DEBUG:root: save sample needs time = 0.000112056732178
INFO:root:random_action_porb = 0.943791666667
DEBUG:root: dqn, choose action rondomly, need time 0.00016500000001
INFO:root:random action 3
INFO:root:action choosen by dqn 3
INFO:root:frame =7120 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000226974487305
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  801077.4375]
 [  942617.25  ]
 [  837149.9375]
 [  834289.5625]
 [  977352.375 ]
 [  941479.8125]
 [  801077.4375]
 [  810474.6875]
 [  956021.8125]
 [  885558.1875]
 [ 1026826.    ]
 [  811470.1875]
 [  787777.5625]
 [  977352.375 ]
 [  748900.9375]
 [  794385.75  ]]
DEBUG:root:training time = %d0.191938
INFO:root:frame =7121 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000249147415161
INFO:root:frame =7122 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000280141830444
DEBUG:root: save sample needs time = 0.000256061553955
INFO:root:random_action_porb = 0.94376
DEBUG:root: dqn, choose action rondomly, need time 0.000295999999992
INFO:root:random action 1
INFO:root:action choosen by dqn 1
INFO:root:frame =7124 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000332832336426
INFO:root:frame =7125 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000284194946289
INFO:root:frame =7126 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000468015670776
DEBUG:root: save sample needs time = 0.000249862670898
INFO:root:random_action_porb = 0.943728333333
INFO:root:dqn select action Tensor("ArgMax_43:0", shape=(1,), dtype=int64)
DEBUG:root: dqn, choose action by DQN, need time 0.011503
INFO:root:action choosen by dqn [2]
INFO:root:frame =7128 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000194072723389
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[ 819010.875 ]
 [ 792204.3125]
 [ 800829.25  ]
 [ 766168.5625]
 [ 915781.6875]
 [ 805250.3125]
 [ 948360.25  ]
 [ 918887.    ]
 [ 995894.875 ]
 [ 788356.6875]
 [ 781825.5   ]
 [ 950396.5   ]
 [ 870288.5625]
 [ 864329.75  ]
 [ 809518.4375]
 [ 785799.125 ]]
DEBUG:root:training time = %d0.205931
INFO:root:frame =7129 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000195026397705
INFO:root:frame =7130 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000234127044678
DEBUG:root: save sample needs time = 0.000203132629395
INFO:root:random_action_porb = 0.943696666667
DEBUG:root: dqn, choose action rondomly, need time 0.000285999999988
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7132 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root:frame =7133 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000437021255493
INFO:root:frame =7134 recording following_observation no.2
DEBUG:root: save sample needs time = 0.000222206115723
DEBUG:root: save sample needs time = 0.000207185745239
INFO:root:random_action_porb = 0.943665
DEBUG:root: dqn, choose action rondomly, need time 0.000317999999993
INFO:root:random action 4
INFO:root:action choosen by dqn 4
INFO:root:frame =7136 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000308036804199
INFO:root: picked a none-zero reward state !
INFO:root: picked a none-zero reward state !
INFO:root:training error  = [[  998231.25  ]
 [  771405.375 ]
 [ 1036892.75  ]
 [  708069.6875]
 [  999625.0625]
 [  946599.75  ]
 [ 1027051.625 ]
 [  813843.625 ]
 [  919767.1875]
 [ 1010790.6875]
 [  824474.625 ]
 [  798024.6875]
 [  989659.6875]
 [  910660.1875]
 [  964972.375 ]
 [  790220.3125]]
DEBUG:root:training time = %d0.22578
INFO:root:frame =7137 recording following_observation no.1
DEBUG:root: save sample needs time = 0.000251054763794
INFO:root:frame =7138 recording following_observation no.2
DEBUG:root: save sample needs time = 0.00025200843811
DEBUG:root: save sample needs time = 0.000199794769287
INFO:root:random_action_porb = 0.943633333333
DEBUG:root: dqn, choose action rondomly, need time 0.000322000000011
INFO:root:random action 2
INFO:root:action choosen by dqn 2
INFO:root:frame =7140 recording following_observation no.0
DEBUG:root: save sample needs time = 0.000353097915649
